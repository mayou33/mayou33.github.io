<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>张天师</title>
  
  
  <link href="http://zhangyu.info/atom.xml" rel="self"/>
  
  <link href="http://zhangyu.info/"/>
  <updated>2022-11-17T14:51:18.905Z</updated>
  <id>http://zhangyu.info/</id>
  
  <author>
    <name>张天师</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>网卡限速工具之WonderShaper</title>
    <link href="http://zhangyu.info/2022/11/17/%E7%BD%91%E5%8D%A1%E9%99%90%E9%80%9F%E5%B7%A5%E5%85%B7%E4%B9%8BWonderShaper/"/>
    <id>http://zhangyu.info/2022/11/17/%E7%BD%91%E5%8D%A1%E9%99%90%E9%80%9F%E5%B7%A5%E5%85%B7%E4%B9%8BWonderShaper/</id>
    <published>2022-11-16T16:00:00.000Z</published>
    <updated>2022-11-17T14:51:18.905Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.cnblogs.com/greatsql/p/16641935.html">https://www.cnblogs.com/greatsql/p/16641935.html</a></p><p><a href="https://www.cnblogs.com/greatsql/p/16641935.html">网卡限速工具之WonderShaper - GreatSQL - 博客园</a></p><blockquote><ul><li>  什么是WonderShaper</li><li>  如何安装WonderShaper</li><li>  WonderShaper使用帮助</li><li>WonderShaper使用示例<ul><li>  查看网卡状态</li><li>  限制网卡速度（单位Kbps）</li><li>  取消限速</li></ul></li><li>  WonderShaper在测试中的应用</li><li>  网速单位转换</li><li>  总结</li></ul><h2 id="1-什么是WonderShaper"><a href="#1-什么是WonderShaper" class="headerlink" title="1.什么是WonderShaper"></a>1.什么是WonderShaper</h2><p>WonderShaper是用来对特定网卡进行快速限速的工具，它实际是对linux的tc命令进行封装后的shell脚本，所以使用成本比tc更低，更容易上手，以下配合测速工具speedtest一起使用</p><h2 id="2-如何安装WonderShaper"><a href="#2-如何安装WonderShaper" class="headerlink" title="2.如何安装WonderShaper"></a>2.如何安装WonderShaper</h2><pre><code>#直接拉取WonderShaper，开箱即用git clone https://github.com/magnific0/wondershaper.gitroot@****-5491:/home/soft/wondershaper# ./wondershaper -vVersion 1.4.1root@****-5491:/home/soft/wondershaper# #网速测试工具speedtest安装(Ubuntu)apt install speedtest-cli--yum install speedtest-cli (centos) </code></pre><h2 id="3-WonderShaper使用帮助"><a href="#3-WonderShaper使用帮助" class="headerlink" title="3.WonderShaper使用帮助"></a>3.WonderShaper使用帮助</h2><pre><code>root@****-5491:/home/soft/wondershaper# ./wondershaper -hUSAGE: ./wondershaper [-hcs] [-a &lt;adapter&gt;] [-d &lt;rate&gt;] [-u &lt;rate&gt;]Limit the bandwidth of an adapterOPTIONS:   -h           Show this message 【帮助信息】   -a &lt;adapter&gt; Set the adapter  【指定网卡接口】   -d &lt;rate&gt;    Set maximum download rate (in Kbps) and/or 【限制下载速度(Kbps)】   -u &lt;rate&gt;    Set maximum upload rate (in Kbps)   【限制上传速度(Kbps)】   -p           Use presets in &quot;/etc/systemd/wondershaper.conf&quot;   -f &lt;file&gt;    Use alternative preset file   -c           Clear the limits from adapter 【清除指定网卡规则，用于取消限速】   -s           Show the current status of adapter 【显示当前网卡的状态】   -v           Show the current version  【显示当前版本】   Configure HIPRIODST in &quot;/etc/systemd/wondershaper.conf&quot; for hosts   requiring high priority i.e. in case ssh uses dport 443.MODES:   wondershaper -a &lt;adapter&gt; -d &lt;rate&gt; -u &lt;rate&gt;   wondershaper -c -a &lt;adapter&gt;   wondershaper -s -a &lt;adapter&gt;EXAMPLES: 【使用示例】   wondershaper -a eth0 -d 1024 -u 512  【设置网卡eth0的上行速度为512kbps，下行速度为1024kbps】   wondershaper -a eth0 -u 512 【只设置上行速度为512kbps】   wondershaper -c -a eth0 【清除网卡eth0的规则】   wondershaper -p -f foo.conf 【设置指定的配置文件】root@****-5491:/home/soft/wondershaper#</code></pre><h2 id="4-WonderShaper使用示例"><a href="#4-WonderShaper使用示例" class="headerlink" title="4.WonderShaper使用示例"></a>4.WonderShaper使用示例</h2><h3 id="4-1查看网卡状态"><a href="#4-1查看网卡状态" class="headerlink" title="4.1查看网卡状态"></a>4.1查看网卡状态</h3><pre><code>root@****-5491:/home/soft/wondershaper# ifconfig eno1eno1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 192.168.5.103  netmask 255.255.255.0  broadcast 192.168.5.255        inet6 fe80::2c93:21f9:1931:304  prefixlen 64  scopeid 0x20&lt;link&gt;        ether c8:f7:50:7e:50:48  txqueuelen 1000  (Ethernet)        RX packets 7748809  bytes 1034513376 (1.0 GB)        RX errors 0  dropped 439  overruns 0  frame 0        TX packets 15528838  bytes 4784318169 (4.7 GB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0        device interrupt 16  memory 0x91500000-91520000 root@****-5491:/home/soft/wondershaper# ./wondershaper -s -a eno1qdisc fq_codel 0: root refcnt 2 limit 10240p flows 1024 quantum 1514 target 5.0ms interval 100.0ms memory_limit 32Mb ecn  Sent 4528052159 bytes 14890189 pkt (dropped 0, overlimits 0 requeues 4224)  backlog 0b 0p requeues 4224  maxpacket 66616 drop_overlimit 0 new_flow_count 35953 ecn_mark 0  new_flows_len 0 old_flows_len 0--测试网速root@****-5491:/home/soft/wondershaper# speedtestRetrieving speedtest.net configuration...Testing from China Telecom (120.36.98.11)...Retrieving speedtest.net server list...Selecting best server based on ping...Hosted by Fuzhou China Mobile,Fujian (Fuzhou) [589.19 km]: 14.449 msTesting download speed................................................................................-- 下载网速是171.43 Mbit/s，Download: 171.43 Mbit/sTesting upload speed......................................................................................................-- 上传网速是4.15 Mbit/sUpload: 4.15 Mbit/s</code></pre><h3 id="4-2限制网卡速度（单位Kbps）"><a href="#4-2限制网卡速度（单位Kbps）" class="headerlink" title="4.2限制网卡速度（单位Kbps）"></a>4.2限制网卡速度（单位Kbps）</h3><pre><code>-- 下行2048kbps=2 Mbit/s,上行 1024kbps=1 Mbit/sroot@****-5491:/home/soft/wondershaper# ./wondershaper -a eno1 -d 2048 -u 1024--测试网速root@****-5491:/home/soft/wondershaper# speedtestRetrieving speedtest.net configuration...Testing from China Telecom (120.36.98.11)...Retrieving speedtest.net server list...Selecting best server based on ping...Hosted by Far EasTone Telecom (Miaoli City) [722.10 km]: 174.383 msTesting download speed................................................................................-- 下行速度Download: 1.80 Mbit/sTesting upload speed......................................................................................................--上行速度Upload: 1.28 Mbit/sroot@****-5491:/home/soft/wondershaper# </code></pre><h3 id="4-3取消限速"><a href="#4-3取消限速" class="headerlink" title="4.3取消限速"></a>4.3取消限速</h3><pre><code>--取消限速root@****-5491:/home/soft/wondershaper# ./wondershaper -c -a eno1-- 查看网卡状态root@****-5491:/home/soft/wondershaper# ./wondershaper -s -a eno1qdisc fq_codel 0: root refcnt 2 limit 10240p flows 1024 quantum 1514 target 5.0ms interval 100.0ms memory_limit 32Mb ecn  Sent 123022 bytes 471 pkt (dropped 0, overlimits 0 requeues 0)  backlog 0b 0p requeues 0  maxpacket 0 drop_overlimit 0 new_flow_count 0 ecn_mark 0  new_flows_len 0 old_flows_len 0-- 测试网速root@****-5491:/home/soft/wondershaper# speedtestRetrieving speedtest.net configuration...Testing from China Telecom (120.36.98.11)...Retrieving speedtest.net server list...Selecting best server based on ping...Hosted by Far EasTone Telecom (Miaoli City) [722.10 km]: 173.886 msTesting download speed................................................................................Download: 11.29 Mbit/sTesting upload speed......................................................................................................Upload: 2.93 Mbit/sroot@****-5491:/home/soft/wondershaper#</code></pre><h2 id="5-WonderShaper在测试中的应用"><a href="#5-WonderShaper在测试中的应用" class="headerlink" title="5.WonderShaper在测试中的应用"></a>5.WonderShaper在测试中的应用</h2><ul><li><p>  测试项目：某内部数据库迁移工具</p></li><li><p>  测试目的：数据迁移中，对目标端进行限速，当取消限速后，传输速度可以恢复</p></li><li><p>测试步骤：起迁移进程，在目标端服务器上用WonderShaper工具进行限速：</p><pre><code>  -- 只限制下行速度  [#22#root@**** ~/wondershaper 14:49:32]22  ./wondershaper -a enp0s3  -d 100</code></pre></li></ul><ul><li><p>测试结果：</p><p>  限速后，写目标库单位写入行数和单位写入字节数都急剧下降，如下图：</p></li></ul><p><img src="https://img2022.cnblogs.com/other/2630741/202208/2630741-20220831094736279-1706023113.png"></p><pre><code>取消限速，恢复网络后，传输速率慢慢恢复：</code></pre><p><img src="https://img2022.cnblogs.com/other/2630741/202208/2630741-20220831094736640-1476630909.png"></p><p><img src="https://img2022.cnblogs.com/other/2630741/202208/2630741-20220831094736914-1168193485.png"></p><h2 id="6-网速单位转换"><a href="#6-网速单位转换" class="headerlink" title="6.网速单位转换"></a>6.网速单位转换</h2><pre><code>1KB/s = 8kbps = 8kb/s比如一般100M的宽带，实际是100Mbps=(100/8) MB/s=12.5 MB/s</code></pre><h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7.总结"></a>7.总结</h2><p>使用WonderShaper对网卡进行限速，在测试时可以针对性的指定网卡，指定上传速度或者指定下载速度，在测试中上传和下载速度是互不影响的，可以只限制一方；且WonderShaper工具操作简单好入手，是个不错的工具。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/greatsql/p/16641935.html&quot;&gt;https://www.cnblogs.com/greatsql/p/16641935.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://w</summary>
      
    
    
    
    <category term="linux" scheme="http://zhangyu.info/categories/linux/"/>
    
    
    <category term="linux" scheme="http://zhangyu.info/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>OKR之剑·理念篇02-OKR布道之旅</title>
    <link href="http://zhangyu.info/2022/11/17/OKR%E4%B9%8B%E5%89%91.%E7%90%86%E5%BF%B5%E7%AF%8702-OKR%E5%B8%83%E9%81%93%E4%B9%8B%E6%97%85/"/>
    <id>http://zhangyu.info/2022/11/17/OKR%E4%B9%8B%E5%89%91.%E7%90%86%E5%BF%B5%E7%AF%8702-OKR%E5%B8%83%E9%81%93%E4%B9%8B%E6%97%85/</id>
    <published>2022-11-16T16:00:00.000Z</published>
    <updated>2022-11-17T15:00:04.490Z</updated>
    
    <content type="html"><![CDATA[<p>OKR之剑（理念篇）02—— OKR布道之旅 - 掘金</p><p><a href="https://juejin.cn/post/7145641312216154119">https://juejin.cn/post/7145641312216154119</a></p><blockquote><blockquote><p>作者：vivo互联网平台产品研发团队</p></blockquote><h1 id="1、我们是如何引入的"><a href="#1、我们是如何引入的" class="headerlink" title="1、我们是如何引入的"></a>1、我们是如何引入的</h1><h2 id="1-1、企业文化匹配"><a href="#1-1、企业文化匹配" class="headerlink" title="1.1、企业文化匹配"></a>1.1、企业文化匹配</h2><p>大概是在2013年底，一些创业者在硅谷深受OKR洗礼，并在自己的公司内小范围运用，以此OKR开始传入中国。而vivo初尝OKR则是在2019年，当时的互联网管理团队注意到OKR在Google和 MicroSoft等大型公司的成功实践，于是让部门内的管理层开展OKR的学习工作。</p><p>我们自此开始了，以在平台产品研发团队内大范围落地为目标的OKR调研工作，方式大致就是找资料、找案例，再做归纳总结。通读一遍当时市面上比较经典的OKR书籍，包括《这就是OKR》、《OKR工作法》、《OKR：源于英特尔和谷歌的目标管理利器》以及《OKR使用手册》；然后又联系有Google、MicroSoft、字节跳动工作背景的员工做了访谈。</p><p>结合国内运用OKR的一些企业的具体实践，我们总结出来适用OKR的企业，需要具备的5条<strong>基本特征</strong>：</p><p><strong>1.推崇内在驱动</strong></p><blockquote><p>OKR信奉内部动机的力量，鼓励员工自主制定挑战性目标，锻炼自己的能力。在胜任岗位与能力提升的过程中收获快乐，在相互赞赏与拥抱成功中得到满足。因此顺利推行OKR需要企业为员工营造开放性、创造性的氛围，保持员工勇于挑战的进取心，而不会因为没有达成OKR目标变得沮丧消沉。</p></blockquote><p><strong>2.组织结构扁平</strong></p><blockquote><p>OKR需要经常关注目标执行情况，当遇到问题时需要及时应对调整，快速获得上级资源支持，团队内外信息互通。这就要求简化管理层次，缩短决策路径。</p></blockquote><p><strong>3.信息透明公开</strong></p><blockquote><p>OKR提倡公开透明，鼓励积极反馈。参考张一鸣在字节跳动推行的”Context，not Control”，想要OKR能够成功高效地运转，离不开透明公开的Context上下文贯穿整个体系。</p></blockquote><p><strong>4.平等沟通氛围</strong></p><blockquote><p>制定OKR需要团队成员坦诚交流，充分了解彼此的看法，最终依据企业的战略目标达成共识，因此打造极致的沟通环境，就需要能够真正做到平等公开，打破组织成员中“层级分明”的沟通障碍。</p></blockquote><p><strong>5.利益风险共享</strong></p><blockquote><p>OKR能够促进组织和个人螺旋上升的关键，在于内在驱动，而能够让员工长期稳定的发光发热，靠”情怀和信仰”是不够的，还需要一套行之有效的人才管理机制，比如股权和上升通道，满足员工求名求利求本事的实际需求，实现精神和物质的双重驱动。</p></blockquote><p>我们把公司核心价值观“<strong>本分 用户导向 设计驱动 学习 团队</strong>”与之对照，发现契合度非常高：</p><blockquote><p><strong>本分</strong>，永远保持平常心，求责于己，坚守诚信、结果导向和主人翁精神；设计驱动，是创新解决用户潜在需求、推动社会进步的系统思维方式和价值观；学习，永远保持进取心，不满足现状。创造性的设计和主动意识，以及自我提升打破个体和群体局限，这一点和OKR的内驱力异曲同工。</p><p><strong>用户导向</strong>，一切工作须以用户的真实需求为原点而展开。而当用户需求发生变化时，我们需要及时判断并做好应对，这就要求我们扁平化的结构，减少信息传递误差，提高协作和管理效率。这又和企业文化，团队这一条相互呼应，坚持以广泛和而深入的团队协作，来应对市场需求的不确定性和复杂性。</p></blockquote><p>如果一直无法见到成效和回报，而没有其他推动力的情况下，势必会导致沮丧和畏难。如企业文化中的使命所述，通过服务好用户、员工、伙伴、股东这四个利益相关方，让四个利益相关方持续Happy。这里其实也就描述了外推力（利益共同体），与OKR利益风险共享不谋而合。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/63ba8ed7f9ed4e438ebcab83d1b40238~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p>企业文化论证完，我们再看团队管理方式。长久以来，平台产品研发领导团队始终保持较强战斗力，应对不确定性，以更Open的心态打造学习型高绩效团队。以这种理念贯穿管理行为，不断优化沉淀管理经验，总结方法论。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/490ab0bcf7a0429ca493b5e831ea3832~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p>迭代至今已逐渐形成以“开放+协同”作为方向路标，以“信任+凝聚”作为动力源泉，把“传承+发展”作为通往未来的武器和盾牌的独特管理风格。而团队中持续践行的管理方法，就是强调人性，弱化KPI和绩效结果，强化目标牵引和结果导向。这一点与OKR提倡的鼓励员工勇于挑战自我，与绩效解耦的理念一致。</p><p>作者有话说：</p><blockquote><p>“这里我们是以vivo公司的企业文化来进行论述，但其实类比到其他企业，也同样适用。在中国这片神奇土地上成长起来的人和企业，都必然会深受“<strong>儒皮道骨法治</strong>”思想的熏陶和影响，其核心价值观和文化底蕴都很相似。如果说KPI属于法家治理，那OKR更接近于道家管理。一个成熟的企业，需要在不同的阶段，不同的领域中，在道和法之间倾斜平衡，找到一个更适合自己当下实情的管理模式。</p><p>人法地，地法天，天法道，道法自然。过往我们倾向于KPI模式，在国力孱弱，需要勤劳奋斗翻身做主时，是适用的，虽然压抑了道性人性，但保证了基本效率，不会走偏。而如今局势已经截然不同，也是时候拥抱更加契合国人思想根源的，更加多元化的管理模式了。”</p></blockquote><h2 id="1-2、判断引入影响"><a href="#1-2、判断引入影响" class="headerlink" title="1.2、判断引入影响"></a>1.2、判断引入影响</h2><p>分析论证到这一步，公司企业文化、管理方式和OKR都没有发现冲突点，这样我们的调研就已经完成了一半。另外一半是，引入是否能够解决旧的问题，是否又会带来新的问题？我们根据在书本中学习到的OKR相关特性，结合OKR在字节、微软等公司的实践，汇总后得到以下可能的影响：</p><p><strong>1.群体目标一致（正向）</strong></p><blockquote><p>企业文化的深度践行，为员工打造出一个平等、透明、积极、自驱的氛围和环境，但从公司战略到平台产品研发团队战略，到项目规划，到个人目标，每个层级的分解和理解，都会因为角色、重心不同发生偏差。特别是出现偏差后，如果没有及时有效的沟通手段同步，那么很可能会在年底复盘时，才发现大团队在不重要的方向浪费了精力。OKR作为一种“目标沟通工具”，能够保证大方向的一致，细节处不断修正，最终达成团队目标趋同。</p></blockquote><p><strong>2.激发组织活力（正向）</strong></p><blockquote><p>当下企业内部门细分，职能也越来越多，每个团队只为自己的团队目标负责，就导致最终协作困难，没有阶段性胜利来鼓舞，员工只会越来越沉默。而OKR鼓励员工打破个体局限，不畏惧失败和困难，是基于氛围营造、绩效不与KR直接关联、教练式管理、 以及长期利益风险共享等手段。在这种环境下，员工都是向相同的目标努力，为他人的进步而欣喜，互相之间更加信任，协作更加顺畅。</p></blockquote><p><strong>3.绩效管理挑战（负向）</strong></p><blockquote><p>OKR的推行，从制定OKR、周报、庆功会、复盘这一整套循环，需要占用团队成员的大量时间精力。而且由于OKR与绩效评估脱钩，这就导致管理者无法从OKR的执行情况直接得到员工绩效，那么势必要带来额外的绩效考评流程和考核方式。这对很多在KPI模式下“躺赢”的管理者来说，是一个新的挑战。</p></blockquote><p><strong>4.短期效果不显（负向）</strong></p><blockquote><p>引入OKR，并不代表企业面临的环境、拥有的资源发生变化，只不过能够让企业更快的应对变化。而OKR的执行效果又和决策层的心态、参与者的认知、思维方式行为方式密切相关。从一个传统的目标管理工具切换到OKR，带来的是理念的巨大变化，而改变一个习惯很难，改变思维方式更难，只有长期实践运用OKR，保持团队氛围透明公开平等，才能让OKR的价值体现不断变大。</p></blockquote><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2eaf9102ee7a457da19a1bce22d96557~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p>（图片来源：<a href="https://link.juejin.cn/?target=https://pixabay.com/zh/photos/libra-weigh-balance-weigh-out-2759820/" title="https://pixabay.com/zh/photos/libra-weigh-balance-weigh-out-2759820/">pixabay</a>）</p><p>上述罗列的负向影响，我们认为，是可以通过其他手段来解决的。首先是弱化360环评、自评，强化管理者中间过程记录，来减轻员工的接受障碍。其次是面向管理者，做好知识培训，提供相关的辅助管理工具，提高管理者的能力和效率。至于短期效果不明显的问题，我们会对管理者和领导层做好预期管理，留下足够的操作空间和时间。</p><p>结合当前我司管理模式，和当下互联网形式急剧变化产生的冲突，我们分析判断，引入OKR替代原有KPI的管理模式后带来正向结果&gt;负向结果。因此引入OKR，是可行且合适的。</p><h1 id="2、团队的引入和实践"><a href="#2、团队的引入和实践" class="headerlink" title="2、团队的引入和实践"></a>2、团队的引入和实践</h1><h2 id="2-1、团队现状分析"><a href="#2-1、团队现状分析" class="headerlink" title="2.1、团队现状分析"></a>2.1、团队现状分析</h2><p>前序调研结论出来后，我们在团队负责人的带领下快速决定，主动出击，拥抱OKR，并且为实际落地OKR这一管理工具，进行了大量的准备工作。</p><p>我们将从书籍学习到的相关知识，包括核心原理、运转模式整理到PPT上，并开始在各职能团队间宣传。我们设想过很多人可能会针对OKR提出疑问，并且也做足了功课，自认为能够给予完美的解答，然后就能有条不紊的推行下去。然而现实却给我们浇了一盆冷水：</p><p><strong>书中学到的，终究只是抽象的结论，实操却是实实在在的难题。</strong></p><p>在宣传会议上，有管理者很认同OKR的管理理念，认为可以一试；也有管理者质疑OKR，在他们理解中现有的管理模式运行的很健康，并没有发现有什么问题；甚至于有人认为OKR只是一个舶来品，到我们团队内运行很大可能会水土不服。</p><p>我们没有想到同属一个平台产品研发团队，不同角色对于OKR的理解差异居然如此之大。在这种情况下，我们只好暂停推行计划，转而冷静思考分析，到底应该怎么去落地它。我们重新观察平台产品研发团队内现有的团队，了解他们内部运作和管理的方式，经过汇总我们发现：</p><ol><li><p> **管理方式差异较大：**不同的职能线，不同的业务线管理方法千差万别，部分团队的管理风格已经偏向于OKR，弱化了KPI；绝大部分团队重度依赖KPI。</p></li><li><p> **管理能力参差不齐：**平台产品研发团队管理层，有公司内部培养的，也有一些具有其他公司的工作经验，还有个别管理者具有创业经验，不同的履历导致他们对于管理的理解都不尽相同。</p></li><li><p> **团队人员组成不同：**有一些团队，成立了很久，团队成员也都深受企业文化熏陶；也有个别团队的员工，几乎都是最近从其他公司跳槽过来的，对于公司和平台产品研发团队的信任认可程度并不高。</p></li></ol><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e0c78e30212c436b900adad28fb34517~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p>（图片来源：<a href="https://pixabay.com/zh/photos/teamwork-team-board-chalk-hatching-2499638" title="https://pixabay.com/zh/photos/teamwork-team-board-chalk-hatching-2499638">pixabay</a>）</p><p>结合平台产品研发团队的这几大现状，以及当下各团队，都已经沉淀出了一套自洽的，能够良好运转的管理理念的实际情况。我们决定在引入OKR的过程中，抛弃大刀阔斧的变革，转而用相对柔性的、平缓的方式逐步推行。我们先选择在意向较强的团队中，进行OKR试点。给予他们支持和鼓励，包括培训支持、领导支持，排除使用的心理负担。深度参与，了解他们在落地中遇到的各种困难和疑惑，及时跟进解决。在“试点-复盘-改善-试点”的循环中，不断丰富完善属于我们的推广方式以及实操姿势。</p><p>在这样的推广方式下，我们不再以扩大推广范围和速度作为目标，而是希望能够兼顾不同团队的特点，不同角色的管理风格，避免出现截趾适履的错误认知，能够更加的本地化，从而形成基于公司和团队特色风格的OKR。</p><h2 id="2-2、推进问题收集"><a href="#2-2、推进问题收集" class="headerlink" title="2.2、推进问题收集"></a>2.2、推进问题收集</h2><p>伴随着OKR落地计划的开展，我们也从试点团队陆续收到了不少的反馈和质疑，我们对问题进行了总结和归纳，这里列几个比较典型的提问给大家参考下：</p><p><strong>1.能否用目标完成度决定绩效</strong></p><blockquote><p>与产研团队有所不同的是，部分职能团队原有绩效管理是强依赖于KPI模式。在制定目标和过程跟踪，管理者和员工都做的非常细致。从上层视角鸟瞰团队目标完成情况、员工进度非常直观，而且基于完成结果给予绩效评价也非常便捷。他们内部执行OKR一段时间下来，发现还是回到了KPI的老路，根据KR达成情况来评估员工绩效。但这一方式在各个权威书籍都不建议进行关联，而且也违背了鼓励员工大胆突破的初衷，这种情况该怎么解？</p><p>针对这种情况，我们的建议是，管理理念上还是要尽量契合OKR的本意，用目标牵引的方式来激发员工，淡化考核。实操上弱关联绩效，用类KPI的方式保证下限，进行人员管理和绩效评估，也未尝不可。关于这块的详细解读，我们后续章节会有交代，此处不做赘述。</p></blockquote><p><strong>2.OKR能否应用于劳务派遣员工</strong></p><blockquote><p>公司部分增量业务、创新型业务在快速扩张时期，为了降低用人成本和项目风险，会通过第三方劳务公司雇佣大量员工，公司不直接和员工签订劳务合同，一般称为“外聘”。这类员工的薪酬、晋升的激励政策和司内自有员工不同，公司不会有太强的培养预期，无法通过前文中描述的“利益风险共享”策略持续激发员工进取心。</p><p>提出此问题的团队，之前都是利用KPI，由自有员工下达任务目标，根据达成结果来评估员工绩效。此时施行OKR，如果一味通过成长、前景、发展来给员工打鸡血，最终又无法兑付，反而会导致员工消极怠工，心生嫌隙。因此，我们建议OKR的执行层级，可以落到能够建立长期稳定信任和利益关系的层级即可，更基层可以沿用原有模式。这里的实际执行方式就是，利用OKR管理自有员工，自有员工评估外聘员工绩效时，仍然依托于KPI。</p></blockquote><p><strong>3.OKR项目与职能方向权重衡量</strong></p><blockquote><p>部分研发团队反馈，在制定OKR时，发现O都是项目方向的，个人发展和技能提升等方向无法在OKR中得到体现，这样就很容易让员工在执行过程中感觉分裂：职能线重视的事情，在项目线看来可能并不重要，如果不在个人OKR中进行追踪跟进，那么势必导致员工和团队成长滞后。但实际上技能提升、影响力提升对组织与个人的长远发展非常重要，企业文化也是要员工坚持学习进取。</p><p>我们参考了8/2黄金法则，建议员工制定个人OKR时，80%精力投入到项目和业务方向，20%精力投入到创新、探索、学习方向，来契合职能线的发展规划与预期。这样既能够保留OKR目标牵引，利用群体力量完成挑战，又能够保证个人和组织的持续发展。</p></blockquote><p>从上面列举的三个问题，仅仅只是在实际落地时，发现的相对典型的一小部分问题。更多的实际案例，在后续文章中会有介绍。我们发现这些问题，给予相关的知识、可参考的案例，跟踪团队去尝试解决验证，直到OKR的使用趋于稳定。最终有的团队选择使用承诺型OKR，有的团队使用了挑战性OKR，还有一些团队分层使用OKR和KPI的模式，百花齐放各有千秋。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/db4ff3bb9a8748a6b4adde5cf3f219f7~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p>也有一些团队在尝试一段不短的时间，虽然我们不断调整，但仍然会持续出现水土不服的情况。我们总结后发现，OKR对于落地的团队是有一定要求的，匹配度不高的团队使用OKR，是无法真正将OKR的作用发挥出来的。经过一段时间的试点运行，收集各个团队的反馈结果，我们整理出来适合OKR的团队，需要具备的三个<strong>要素</strong>：</p><blockquote><ol><li><p> **团队特色：**自我驱动、敏捷团队、基于兴趣</p></li><li><p> **业务方向：**面对高创新、高不确定性业务和工作</p></li><li><p> **管理方式：**相互信任、敢于授权、教练型领导力</p></li></ol></blockquote><p>在试点运行后，部分不适合的团队切换回KPI管理模式，这些团队的员工反而变得很轻松，而另外一些团队，在具有团队特色OKR的管理模式帮助下，业绩实现突飞猛进式的提升。当然，也有一些难题，我们现在仍然在尝试解决，去找其他有实操经验的团队进行交流探讨，去迭代优化应对方式，保持着最初的热情。如果你也有很多困惑找不到答案，或者有相关经验可以分享，欢迎加入社群，让我们一起学习成长！</p><h1 id="3、引入OKR具体步骤"><a href="#3、引入OKR具体步骤" class="headerlink" title="3、引入OKR具体步骤"></a>3、引入OKR具体步骤</h1><blockquote><p>变革：改变事物的本质——《汉语大词典》。</p></blockquote><p>这一章的标题，我们团队内部讨论了许久。为什么最后我们不用“变革”这么个非常吸引眼球的词呢？这就得说回我们公司的文化理念。公司坚持“做正确的事，并把事情做正确”，而外在环境却是在不断变化的，我们需要不停的学习进步，来适应变化，做当下以及未来对的事情。由此我们认为，任何一家公司都不需要颠覆式、推倒式的“变革”，而是基于当下自有的逻辑和理论、不断完善和优化，提高应对变化的能力。具备迎接所谓的“V（易变） U（不确定）C（复杂）A（模糊）”的复杂环境的考验和冲击，而不会因为在错误的时间使用错误的方法，导致被时代抛弃。</p><p>我们认为，OKR并不仅仅是一个目标管理方法，更是一套理念。就像达摩祖师传之言“佛教吾本来兹土，传法救迷情，一花开五叶，结果自然成”，我们希望能够通过本系列文章 ，让更多的人去理解和践行它，并能从中收益。如果此刻遍览形形色色OKR书籍的你，能够在本文中有所得，并运用之于企业内部，通过推广OKR解决现存的一些问题，让管理者如获至宝，让员工如释重负，那么也就如达摩传佛法一样，是值得回味和自豪的成就了。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9f520d1c42f64e009315dda771e6ea66~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p>（图片来源：<a href="https://pixabay.com/zh/illustrations/jesus-gospel-sermon-on-the-mount-7220256/" title="https://pixabay.com/zh/illustrations/jesus-gospel-sermon-on-the-mount-7220256/">pixabay</a>）</p><p>下面我们就开始正式进入OKR的布道之旅，按照操作顺序，甄别选型—&gt;获取授权—&gt;认知对齐—&gt;环境准备，先从甄别选型讲起。</p><h2 id="3-1、你的团队适合OKR吗？"><a href="#3-1、你的团队适合OKR吗？" class="headerlink" title="3.1、你的团队适合OKR吗？"></a>3.1、你的团队适合OKR吗？</h2><p>公司内的管理者大多都肩负着团队季度或者年度的目标，数据、营收、利润、管理等等。引入一种新的团队目标管理方法，一旦遭遇失败，那么带来的打击和影响是管理者无法承受的。如果你的团队中没有对OKR理解比较深或实际参与使用过OKR的成员，那么在刚开始做选择的时候，肯定会有这样的疑问，我们这样的团队适不适合开展OKR？所以我们希望在采用OKR之前，首先确保你的团队或者企业属于以下几个类型：</p><p><strong>1.产品更新迅速的IT/互联网团队</strong></p><blockquote><p>对比传统企业，互联网行业更容易诞生新兴的事物和现象级的产品，产品的更迭迅速也是非常普遍的现象，这对于一个专业从事互联网的团队是一个非常大的挑战，团队不仅需要有较强的执行力，同时也需要不断突破自身的局限，产品、运营团队需要对市场环境拥有较高的敏感度，技术上需要勇于创新，抓住风口。这和OKR鼓励打破局限，突破自我不谋而合，因此这类团队非常适合引入OKR目标管理模式。</p></blockquote><p><strong>2.面对非确定性工作，注重自驱的团队</strong></p><blockquote><p>OKR在员工生产力的刺激作用，主要产生于非确定性工作。如果员工日常工作内容，是类似于计件/计时类的，要求遵守流程，相对比较死板时，OKR并不能对员工效率和生产力有提升。这种情况下，使用传统的KPI绩效管理方式，则更加合适。而如果团队需要处理的工作内容，更多的是非制式的、偏设计的、需要发挥主人翁意识和创新意识才能创造更大价值的，则比较贴合OKR适用场景。</p></blockquote><p><strong>3.承载传统企业数字化转型的团队</strong></p><blockquote><p>准备转型的团队需要思考过去的模式能否适应转型发展的需要，兵法有云：“上下同欲者胜”，转型中的团队需要上下齐心，需要目标更透明、更清晰，团队成员对目标有非常高的认同，这种情况下OKR是个非常好的目标牵引工具。OKR在这类团队中发挥的作用是很大的，首先能够有效避免转型过程中决策的模糊、队员没有方向感这类情况的发生，同时能够规范团队成员的工作内容，及时矫正偏离核心目标的行为。</p></blockquote><p><strong>4.准备大干一场的创业团队</strong></p><blockquote><p>相比于成熟的企业，创业团队面临生存的风险很高，“摸索”和“走弯路”是常态，“如何确认走在正确的路上”以及“如何及时修正方向”对创业团队来说是道难题。OKR对于目标和结果的紧密结合对于初创团队是个福音，它能确保目标能够走在正确的路上。同时，初创团队内部扁平化的管理结构相对简单，层级不多，OKR的目标和绩效管理方式能够非常好的贯彻和传达。</p></blockquote><p>在后续的文章中，我们会将企业文化要求、团队要求、员工能力以及氛围、业务等多重因素考量，融合到一份评分卡中。根据评分卡，你和你的团队可以快速验证当前团队是否能够无缝切换OKR，也可以发现哪里需要补足，此处不再列举说明。</p><h2 id="3-2、教你一招说服老板用OKR！"><a href="#3-2、教你一招说服老板用OKR！" class="headerlink" title="3.2、教你一招说服老板用OKR！"></a>3.2、教你一招说服老板用OKR！</h2><p>领导与变革领域教父人物，John P. Kotter 在《领导变革》说过：“变革只有在卓越的领导而不只是优秀的管理的推动下，才能有效实施”。这本书被《时代》杂志评为最权威的管理书籍之一，几乎是C字头的管理层必读书籍，当下华为也正是用的这套理论。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dff8451de9374e95aa32882f3c11d1f5~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p>仔细研读这本书，我们将变革理解为“落后变化太多导致需要整体革新，向死而生”。虽然很多时候企业并不会让自己落入到这样的境地，但书中说明的推动变革的思考和理念还是值得借鉴的，其核心思想用白话来讲就是：</p><blockquote><p>“<strong>领导是盘古，管理是斧，想要开天，缺一不可</strong>”。</p></blockquote><p>类比到OKR的推行，我们观察到失败案例中有70%以上都存在相同的问题，那就是顶层管理者参与度太低。有一些企业在引入OKR过程中可能只是口头上一句“你去用看看，用一段时间来汇报”，或者可能非常重视中基层和员工的参与，要求他们掌握OKR操作流程，理解其中的原理，但高层自身却并不参与OKR的实际执行过程。这样运转中就会逐渐凸显一些问题，包括企业战略目标拆解偏差总是修正不及时，部门与部门之间目标不对齐，导致基层之间协作变得非常困难。同时，中高层对于OKR的效果也会存疑，毕竟顶层目标不对齐不透明，OKR的执行就流于形式，最终被无奈放弃。</p><p>再看字节跳动的张一鸣，从一开始就不遗余力在企业内推行“Context, Not Control（情景管理，而不是控制管理 ）”。为了充分发挥集体智慧的力量，打造理想中的分布式决策中心，他每季度都会提前预留两天时间，用于构思自己的OKR，制定结束后即在飞书上发布，员工们都可以直接面向他的OKR来规划自己的OKR。同时，为了纠正“Context”在不同层级的理解偏差，字节定期举行Boss面对面会议，让员工和公司高层直面沟通对齐。 多种举措之下，让字节的开放文化深刻影响了员工的日常做事方式和思考方式，人与人之间更加信任，协作更加顺畅，优秀的人才也就能最大程度上发挥了自身价值。</p><p>所以<strong>获取领导的授权和支持，是引入OKR的必要条件</strong>。</p><p>一般来讲，获取授权会遇到两种情况：你就是老板，或者你的老板深入学习过OKR，理解其中的原理，且非常支持你；你的老板听说过这个目标管理工具，对于是否推广没有想法，对于运用后的成效也比较存疑，你需要说服老板。如果你是第一种情况，那么恭喜你，最大的困难已经解决，可以跳过这一小节了。如果你是第二种情况，我们就要做好充分的准备迎接来自领导的挑战了。</p><p><strong>首先，你要尽量收集和OKR相关的素材，包括但不限于：</strong></p><p>有哪些成功应用的知名企业及何时应用的：海外的有1999谷歌、2011YouTube、2014Uber、Facebook、Twitter、LinkedIn等，国内有2019vivo、2012字节、2014知乎、2015华为、2018美的，2018阿里，2019百度、小米、腾讯等。可以看到传统型企业、互联网企业都涵盖其中，涉及的行业更是千差万别，每个企业都是根据自身特性来调整OKR的使用姿势，因地制宜。</p><p>有哪些更加鲜活的，运用OKR后获得巨大提升的例子：陈鹏鹏卤鹅饭店（2016-2018实现深圳门店1-10）、北京好韵味餐饮（2019引入实现转亏为盈，并在广州、深圳、南京等城市扩展很多分店），还有更多的实际案例此处不再列举。</p><p><strong>其次，你需要整理推行OKR能够给你们企业带来什么，你可以按图索骥，看是否当前企业中有以下问题：</strong></p><ol><li><p> 目标不一致，追溯到上层只能不了了之</p></li><li><p> 跨团队协作难度大，资源难以调动</p></li><li><p> 外部环境变化快，战略调整组织应对总是不及时</p></li><li><p> 信息不透明，层层传达逐渐失真，只能靠猜</p></li><li><p> 唯上昧下，PPT文化盛行，管理层与基层对立</p></li><li><p> 员工没有激情，混吃等死，大锅饭躺平心态</p></li></ol><p>如果有这些情况那么你就可以针对性的向你的老板推介OKR了，基于OKR自身的特性，可以让这些问题逐步瓦解，让企业发展的更快，员工更有干劲。</p><p><strong>最后，设计一个推进OKR落地的计划，其中包括：</strong></p><ol><li> 圈定试点范围，这个范围内的团队，员工要有进取心、管理者有领导力、团队氛围积极向上，越契合OKR团队要求的越好；</li><li> 组建推广小队，小队成员需要有一定影响力，比如职能线高管、部门经理、还有你的老板，不仅仅是需要小队成员的认可支持，还需要他们深度参与，为了推广OKR这个目标也可以拟定一个目标，内部各个角色进行认领分解；</li><li> 安排推介会议，包括面向圈定范围全体的宣讲动员、中高管理层答疑、小团队内部推广，针对不同人群的侧重要有所差异；</li><li> 定期复盘总结，试点范围内要不断收集过程中的正向反向的声音，调整OKR的使用姿势，达成推广小目标要给予鼓励，让团队保持信心，让老板保持信心；</li><li> 扩大推广范围，试点范围OKR执行过一段不断的周期后，当团队稳定下来，并产生好的收益时，可以重新走一遍1-5的步骤循环，直到全公司都开始运用OKR</li></ol><p>当你准备好以上内容时，就可以向老板介绍OKR这一企业发展利器了。实在不行，拉你老板进群，我们会用实战经验来帮你说服老板。</p><h2 id="3-3、知行合一：OKR推行秘诀"><a href="#3-3、知行合一：OKR推行秘诀" class="headerlink" title="3.3、知行合一：OKR推行秘诀"></a>3.3、知行合一：OKR推行秘诀</h2><blockquote><p><strong>“道理我都懂，仍然过不好这一生”—— 这背后的真相就是知行不合一。</strong></p></blockquote><p>OKR的顺利执行，并不是简单的自上而下的安排，也不是自下而上的汇报，而是需要组织所有成员对OKR达成了基本一致的认知，并且认同OKR所倡导的管理理念，管理者切实认同OKR的执行对于团队战斗力的巨大推动力，而作为个体也能认识到践行OKR对自己成长和绩效的促进作用。只有这样才能避免机械式、任务式地执行，违背引入OKR的初衷。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7e3c3cb26e5748afb3a943418d47ff40~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p>（图片来源：<a href="https://link.juejin.cn/?target=https://pixabay.com/zh/photos/head-brain-thoughts-human-body-1965675" title="https://pixabay.com/zh/photos/head-brain-thoughts-human-body-1965675">pixabay</a>）</p><p>我们公司内部推行OKR时，很多管理者都会问：“OKR和其他绩效工具，比如KPI的差异是什么？有什么优势？能解决什么问题？”。有这样的疑问其实很正常，因为对组织做任何改变，都需要非常大的成本，而且管理方式的容错成本更是无法承受。</p><p>而在布道者或者顶层管理成员来看，更可怕的是中层基层管理者不提出质疑，认为OKR简单明了不需要集中学习，不需要格外注意就可以直接试运行。也许有个别的人之前使用过，或者很容易就能理解这套目标管理工具的底层逻辑，能够保证在个体使用时很快上手，但我们推行的目标群体里的绝大多数人都是初次接触OKR，并不知道该如何使用它。</p><p>因此面对这些问题，我们可以通过对员工进行一些基本原理的分享交流，组织推广活动，例如知识分享会、PPT或者视频、组建交流群等方式，广而告之，让大家能够初次接触OKR，在心中有一个大概的轮廓，这是做信息输入。让大家知道这是一个什么样的东西，它和KPI的区别是什么，它能给大家带来什么。这有助于拉齐员工的普遍认知，让大家对OKR的理解能够达成初步共识。</p><p>同时我们建议面向不同的角色，推介时需要带有一定的偏向性，站在不同角色的视角来反向思考，怎么去进行推广，制定不同的策略。</p><h3 id="3-3-1-面向管理者"><a href="#3-3-1-面向管理者" class="headerlink" title="3.3.1 面向管理者"></a>3.3.1 面向管理者</h3><p>OKR能够发挥团队力量，叔本华说：“单个的人是软弱无力的，就像漂流的鲁滨孙一样，只有同别人在一起，他才能完成许多事业。”打造一个高绩效团队，不是管理者一个人的事情，而是需要群力。所以我们需要向管理者阐明OKR在沟通协助、组织氛围、跨组织合作等方面的天然优势，以及OKR为何能够帮助管理者打造“高绩效团队”。</p><p>当然，作为OKR引入者，也不能报喜不报忧。管理者初次运用起OKR来进行团队管理，一定会遇到以前没有遇到的问题，如果没有提前做好心理预期和解决措施，难免对OKR有所失望。这里管理者面对的挑战主要是两个，一个是管理思想，一个是管理行为。对于习惯于使用KPI进行目标管理和绩效管理的管理者，只是行为的模仿是很容易的，但涉及到思维的转变却是非常困难，这需要深入学习和实践，并且在OKR运转过程中不断复盘总结，不断调整优化，来强化理念认同度，转化思维惯性。</p><p><strong>那么思想上有哪些需要改变认知和强化理解的呢？</strong></p><p><strong>1.高绩效团队不是管出来的</strong></p><blockquote><p>放弃对员工的控制，而要转变为激励员工不断向上成长的“教练型导师”。传统的管理方式，管理者给予任务，或者员工做出任务承诺，然后根据任务完成情况给予评价，这种模式下管理者和员工一起划出了一条绩效的下限和上限，员工当然会尽量避免绩效低于下限，但同时没有特别的助力，员工并不会打破约定的绩效天花板。而OKR能够更多的体现出员工对于目标实现的参与，对管理的参与，对高级需求的追求。所以想要让员工发挥能动性，更大程度上，需要管理者放弃控制式的管理方式，转变思维，拥抱变化。</p></blockquote><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b14c3f421aeb4cb49fbb56878b80cd57~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p><strong>2.考核不是目的，而是筛选培养人才</strong></p><blockquote><p>管理者为员工评估绩效时，不可以直接将OKR与绩效挂钩。因此管理者在评估员工绩效的过程，也是管理者评估员工的“人才画像”的过程，通过参考员工KR的完成情况，还需要查看员工周报、月报中的说明，观察其为达成KR付出的努力，以及个人的成长。</p><p>“他是不是一个有强烈成功欲的人？”</p><p>“他是不是很善于学习成长？”</p><p>“他是不是敢于担当，愿意承担责任？ ”</p><p>在制定OKR目标和实施OKR考评、以及最后的OKR复盘的过程中，管理者能够很容易地发现那些乐于设置挑战性目标并努力达成的员工，以及有热情但需要持续激励的员工，针对不同特质的人才进行培养，最终组建出一个有梯度的不断成长的团队。</p><p>当然，不用KR的完成情况作为考核依据并不代表不考核，我们最终目的是为了减少内耗，提高人效，提高绩效上限。实际去衡量员工的绩效时，需要更全面的评估，OKR的执行情况可以间接参考。</p></blockquote><p><strong>3.透明公开平等是高绩效团队的培养基</strong></p><blockquote><p>我们再次强调这一点，是因为这是最容易看懂，但却最难做到的。人们总是习惯于依附强者而践踏弱者，这种强弱关系，几乎贯穿每个人的一生。在家庭中的父母与小孩，在学生时代的学生和老师，在职场中的领导和员工中，这种情况普遍存在。那么在这种天然的关系中，想要营造出公开平等，像朋友一样相处，需要的是管理者先改变自己的思维惯性。</p><p>如果员工反馈OKR执行中遇到的问题，不是给予鼓励和提供资源，而是以上位者的姿态命令和责备，那必然所有人都会谨小慎微，少做少错，不做不错，很多优秀的创意就会被扼杀，组织就会出现停滞不前甚至倒退。只有在公开、透明和 共创中，每一位员工才能更清楚的知道组织正朝着哪个方向去，自己可以贡献些什么，如何在进程中实现自我超越。</p></blockquote><p><strong>在OKR实操过程中，有哪些关键行为需要格外注意的呢？</strong></p><p><strong>1.获取团队成员的支持有些小窍门</strong></p><blockquote><p>管理者在团队内部试用OKR时，尽量多介绍对其个人绩效、成长的推动效应。从一些名人名事、有趣的知识入手，这样很容易吸引员工的注意力，让他们感兴趣。比如脱口秀演员呼兰调侃OKR的段子，比如3.3.2面向参与者中推广的理论依据和个体成功的案例等等。</p><p>另外，在内部推广的过程中，讲明白一些总结出来的特征，能够让他们快速了解到，使用OKR自己能够得到什么，需要承担和改变什么，这对于降低员工戒备心、让OKR推行的顺畅非常关键。</p></blockquote><p><strong>2.培养OKR种子选手很关键</strong></p><blockquote><p>OKR自身没有办法去约束团队内员工的行为，它更多的是一个目标牵引和沟通工具，所以顺利推行，并实现预期中的推动力，就需要每一层级每一个成员的参与。所以作为管理者，在给下一层级管理者推广OKR时，也需要做3.3.1节中面向管理者的信息输入，保证每个层级的理解都是一致的。</p><p>同时管理者还需要在团队中培养种子选手，对他们进行理念的影响和灌输，让他们理解推行OKR的益处，拥护推行OKR这一举措。理想中的种子选手一般是团队中思维活跃、思路清晰、外向能够带动氛围的，具有领袖气质的人。让他们成为OKR教练，或者团队中OKR推行的骨干成员。他们的深入参与能够有效带动团队内其他成员，这样建设积极健康向上的氛围，和透明平等公开的团队文化，就变得更加容易。在榜样效应下，打消群众的抗拒和防备心理，就能更大程度上保证整体方向正确性。</p><p>当流程成熟之后，可以适当去中心化，每个人都能形成一个服务节点，让整个OKR织入的过程能够免于形式化、运动式、交作业式的错误调性。</p></blockquote><p><strong>3.氛围营造不是说说而已</strong></p><blockquote><p>作为管理者，需要将透明公开平等的沟通氛围营造作为长期投入的工作，需要持续践行，以身作则。管理者是一个团队的风向标，他们的行为方式会直接影响员工的做事方式。在我们团队中，从团队负责人，到一级大组，到二级小组，每层的领导会有在工作日最后一天，给下级发周报。我们也提倡跨层级沟通，包括部长一对一、OfficeHour一对一等等形式，将透明公开落在实处。</p><p>在带领成员完成一轮OKR的执行，管理者需要进行复盘和总结，目的是提高OKR的执行效果，如何更好的激发大家的热情，让大家明白团队或者领导对于OKR执行的“上下限”在哪里，让员工明白自己可以“开放”到什么程度。这就是信任和试探的过程，涉及到人性的一般来讲都是缓慢难以见效的，需要贯之以恒，让成员明白领导说的和做的也是一致的。</p></blockquote><p>实际执行时，还是以团队特性不同来进行调整，就像上文罗列的有大量劳务派遣员工的团队，持续贯彻OKR的精神让整个团队保持热情同样是非常好的，但可能就不用特别关注KR的执行情况，直接关注KPI完成结果就可以了。所以，作为布道者，我们要做的是给予足够的支持和帮助，给予足够的空间和时间，像栽种树苗一样，施肥和修剪，等待它自由成长。</p><h3 id="3-3-2-面向参与者"><a href="#3-3-2-面向参与者" class="headerlink" title="3.3.2 面向参与者"></a>3.3.2 面向参与者</h3><p>2015微软因为员工大量流失，做过了一次全员调研，他们发现最让员工无法忍受的不是薪资，也不是缺少晋升通道，而是绩效考核机制。通过KPI给员工贴标签分等级，这其实是一种心理奴役，完全不能给予员工正向激励。</p><p>再看当下，00后已经在“整顿”职场。他们是在信息爆炸环境中成长起来的一代，也是在物资丰富吃穿不愁的一代，相比于80或者90后，他们已经不是单纯地在“搞钱”，而是更加关注职业发展、工作体验和个人价值。所以面向参与者，我们要站在他们的视角来看，00后群体需求层次已经上升到高于归属，尊重，触及审美甚至自我实现。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/da7c2474206743a7a0778ecec7026061~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p>所以使用绩效薪酬来绑架员工职业生涯，很明显已经不可取。那么为了给公司更好更快的发展，为了组织更好的协同，为了员工实现个人价值和超越自我，从这个角度布道者向员工们推介OKR就显得非常有理论依据了。</p><p>有了理论的支持，我们再找一些实际的案例：苏珊·沃西，谷歌公司NO.16员工，她被《时代》杂志评为互联网行业最有影响力的女性企业家，谷歌当年刚诞生时的第一个办公室就是苏珊的车库。她曾用OKR帮助即将消失的 YouTube 完成了十倍速的增长。从2011年起，她更是每年都会入选《福布斯》的“年度100位最具影响力女性”，在她的成功背后，OKR 贡献了不可忽视的作用。这样的案例比比皆是，特别是在应用了OKR企业里，伴随着企业快速成长，也孵化出很多行业巨擘，包括谷歌、Facebook、字节跳动等等。</p><p>管理者、布道者在面向更大范围推广OKR的时候，除了上述理论和案例，也有一些推广的要点，在试运行阶段着重说明，员工的参与度和积极性会有一个较大的改善：</p><p><strong>1.你可以说：告诉我组织需要什么就行了！</strong></p><blockquote><p>OKR区别于其他目标管理工具和绩效管理工具，在于我们关注的是“去哪里”。从制定到执行的每个流程，都能够保证透明公开，每个人可见，让所有人的工作都更优参与感，提升了主人翁意识。为了达成战略目标，每个人都可以自发制定个人的目标，并为之付出努力和创意。</p><p>因为不强依赖于中间层级的传达解读，以及其个人的任务分解分派，下属层级都不再会有被“PUA”的负面情绪。组织内部工作思维的转变，由原来的被动接受任务变为现在的主动发起挑战，由原来死板执行命令的人变为一个有思想有追求的人，会让员工更加信赖企业。</p><p>原来，螺丝钉也可以有自己的想法，打工人也可以自己书写诗和远方。</p></blockquote><p><strong>2.你可以说：我可以！我能够做得更好！</strong></p><blockquote><p>OKR鼓励员工不断挑战自我，从自我提升和收获成功中得到乐趣和满足。由于不与绩效直接挂钩，所以他们就可以放下心理负担，不断突破，向更高的目标，更好的自己进发。</p><p>当员工掌握OKR的思维方式和底层逻辑后，就可以通过OKR来帮助自己聚焦于目标，基于其周期性复盘与修正的机制，让自己的进步和成长持续累积，以此向下一个目标不断迈进，最终实现个人价值的螺旋上升。</p></blockquote><p><strong>3.你可以说：拒绝内卷，从我做起！</strong></p><blockquote><p>传统绩效管理工具之下，干得好=升职加薪。所以想想当你拿到S级评价时，隔壁的兄弟：“哇塞，恭喜恭喜，实至名归啊！”，可能实际上他想的是“凭啥？明明我做的也很好！”。这是因为资源是有限的，当个人目标直接与薪酬挂钩后，一定会带来竞争&gt;合作，组织之间协同也会有利益纠纷导致内耗，效率都变得更低。</p><p>而现在我们推崇的是个人目标不再与绩效挂钩，每个人的工作都是为了公司项目的推进，竞争关系没有那么明显，大家都是一起努力的合作者。人与人之间的相处模式更融洽，协作关系会更强。当一个人取得阶段性的成功后，就能得到全员的发自内心的赞赏和鼓励。</p></blockquote><p>试问，这样的环境氛围，谁能不喜欢呢？</p><p>一般来讲，为大团队安排一次知识分享会，旨在从概念、理念上分析OKR，为所有人解读引入的动机；为管理者安排一次推广宣讲动员，旨在让管理者认同OKR对于管理工作的助益；管理者再面向团队成员进行一次内部集中学习，旨在让团队成员理解OKR对于个人绩效、目标达成的正向作用。有这三层解读，大团队就能够达成基本的认知对齐，然后就可以为OKR试运行做一些环境准备了。</p><h2 id="3-4、撸起袖子准备开干"><a href="#3-4、撸起袖子准备开干" class="headerlink" title="3.4、撸起袖子准备开干"></a>3.4、撸起袖子准备开干</h2><p>在获得老板授权、完成认知对齐后，你和你的小伙伴可能已经摩拳擦掌，准备轰轰烈烈的搞起来了。但冷静下来到这个节骨眼上，突然会有种无处下手的感觉：</p><blockquote><p><strong>怎么搞？</strong></p></blockquote><p>我们非常理解此时你的心态，因为和当初我们部门引入OKR的历程如出一辙：总经理认可支持推广，并在部门范围进行了宣导，团队负责人大力推动OKR落地，到达组这一层级就很挠头，因为没有谁能给出一套直接搬来就用的法门，结果就造就不同团队百花齐放，各有各样的做法，各有各的理解。</p><p>但总结下来，能让我们探索出因地制宜的OKR执行方式，最重要的就是：</p><blockquote><p><strong>思想上保持统一，行动上不设限制</strong></p></blockquote><ol><li><p> 不要将OKR当做解决所有问题的银弹，而只是尽力发挥其目标聚焦、信息透明、氛围营造的力量</p></li><li><p> 工具不设限，是用Excel，还是用在线文档，用OKR工具，甚至纸笔都可以</p></li><li><p> 最好有一个OKR教练，是管理者承接，还是额外找一个成员负责都可以，是几个团队共用还是团队内专属都可以</p></li><li><p> OKR每个周期多久合适？并没有明确的优劣定论，但建议不要少于2个月，不要多于6个月</p></li></ol><p>这里只是做一点简单的说明，在我们后续章节《OKR之剑（理念篇）-OKR理念认同》《OKR之剑（引入篇）-让OKR轻松上阵》中有更加详细的介绍。总而言之，放下负担，向上进发吧！</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;OKR之剑（理念篇）02—— OKR布道之旅 - 掘金&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://juejin.cn/post/7145641312216154119&quot;&gt;https://juejin.cn/post/7145641312216154119&lt;/a&gt;&lt;/p</summary>
      
    
    
    
    <category term="OKR" scheme="http://zhangyu.info/categories/OKR/"/>
    
    
    <category term="OKR" scheme="http://zhangyu.info/tags/OKR/"/>
    
  </entry>
  
  <entry>
    <title>搞懂MySQL是怎么加行级锁的</title>
    <link href="http://zhangyu.info/2022/11/17/%E6%90%9E%E6%87%82MySQL%E6%98%AF%E6%80%8E%E4%B9%88%E5%8A%A0%E8%A1%8C%E7%BA%A7%E9%94%81%E7%9A%84/"/>
    <id>http://zhangyu.info/2022/11/17/%E6%90%9E%E6%87%82MySQL%E6%98%AF%E6%80%8E%E4%B9%88%E5%8A%A0%E8%A1%8C%E7%BA%A7%E9%94%81%E7%9A%84/</id>
    <published>2022-11-16T16:00:00.000Z</published>
    <updated>2022-11-17T14:55:27.636Z</updated>
    
    <content type="html"><![CDATA[<p>保姆级教程！2 万字 + 30 张图搞懂 MySQL 是怎么加行级锁的？</p><p><a href="https://www.51cto.com/article/740013.html">https://www.51cto.com/article/740013.html</a></p><blockquote><h3 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h3><p>是不是很多人都对 MySQL 加行级锁的规则搞的迷迷糊糊，对记录一会加的是 next-key 锁，一会加是间隙锁，一会又是记录锁。</p><p>坦白说，确实还挺复杂的，但是好在我找点了点规律，也知道如何如何用命令分析加了什么类型的行级锁。</p><p>为了说清楚这三件事情：</p><p>1、MySQL 是怎么加行级锁的？有什么规则？</p><p>2、为什么 MySQL 要这么加行级锁？</p><p>3、如何用命令分析加了什么行级锁？</p><p>所以我重写了这篇文章。</p><p>目录结构如下：</p><p><img src="https://s3.51cto.com/oss/202211/17/22ba35f3845896364f69688c50b3e0595bef63.png" alt="图片" title="图片"></p><h3 id="什么-SQL-语句会加行级锁？"><a href="#什么-SQL-语句会加行级锁？" class="headerlink" title="什么 SQL 语句会加行级锁？"></a>什么 SQL 语句会加行级锁？</h3><p>InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁，所以后面的内容都是基于 InnoDB 引擎 的。</p><p>所以，在说 MySQL 是怎么加行级锁的时候，其实是在说 InnoDB 引擎是怎么加行级锁的。</p><p>普通的 select 语句是不会对记录加锁的，因为它属于快照读，是通过  MVCC（多版本并发控制）实现的。</p><p>如果要在查询时对记录加行级锁，可以使用下面这两个方式，这两种查询会加锁的语句称为锁定读。</p><pre><code>//对读取的记录加共享锁(S型锁)select ... lock in share mode;//对读取的记录加独占锁(X型锁)select ... for update;</code></pre><p>上面这两条语句必须在一个事务中，因为当事务提交了，锁就会被释放，所以在使用这两条语句的时候，要加上 begin 或者 start transaction 开启事务的语句。</p><p>**除了上面这两条锁定读语句会加行级锁之外，update 和 delete 操作都会加行级锁，且锁的类型都是独占锁(X型锁)**。</p><pre><code>//对操作的记录加独占锁(X型锁)updaet table .... where id = 1;//对操作的记录加独占锁(X型锁)delete from table where id = 1;</code></pre><p>共享锁（S锁）满足读读共享，读写互斥。独占锁（X锁）满足写写互斥、读写互斥。</p><p><img src="https://s4.51cto.com/oss/202211/17/497a3dc33343645a708825e3e6abd4cac48ff5.png" alt="图片" title="图片"></p><h3 id="行级锁有哪些种类？"><a href="#行级锁有哪些种类？" class="headerlink" title="行级锁有哪些种类？"></a>行级锁有哪些种类？</h3><p>不同隔离级别下，行级锁的种类是不同的。</p><p>在读已提交隔离级别下，行级锁的种类只有记录锁，也就是仅仅把一条记录锁上。</p><p>在可重复读隔离级别下，行级锁的种类除了有记录锁，还有间隙锁（目的是为了避免幻读），所以行级锁的种类主要有三类：</p><ul><li>  Record Lock，记录锁，也就是仅仅把一条记录锁上；</li><li>  Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；</li><li>  Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。</li></ul><p>接下来，分别介绍这三种行级锁。</p><h4 id="Record-Lock"><a href="#Record-Lock" class="headerlink" title="Record Lock"></a>Record Lock</h4><p>Record Lock 称为记录锁，锁住的是一条记录。而且记录锁是有 S 锁和 X 锁之分的：</p><ul><li>  当一个事务对一条记录加了 S 型记录锁后，其他事务也可以继续对该记录加 S 型记录锁（S 型与 S 锁兼容），但是不可以对该记录加 X 型记录锁（S 型与 X 锁不兼容）;</li><li>  当一个事务对一条记录加了 X 型记录锁后，其他事务既不可以对该记录加 S 型记录锁（S 型与 X 锁不兼容），也不可以对该记录加 X 型记录锁（X 型与 X 锁不兼容）。</li></ul><p>举个例子，当一个事务执行了下面这条语句：</p><pre><code>mysql &gt; begin;mysql &gt; select * from t_test where id = 1 for update;</code></pre><p>事务会对表中主键 id = 1 的这条记录加上 X 型的记录锁，如果这时候其他事务对这条记录进行删除或者更新操作，那么这些操作都会被阻塞。注意，其他事务插入一条 id = 1 的新记录并不会被阻塞，而是会报主键冲突的错误，这是因为主键有唯一性的约束。</p><p><img src="https://s2.51cto.com/oss/202211/17/67eff2c26578e6a34e83345845ca6c35594f0c.png" alt="图片" title="图片"></p><p>当事务执行 commit 后，事务过程中生成的锁都会被释放。</p><h4 id="Gap-Lock"><a href="#Gap-Lock" class="headerlink" title="Gap Lock"></a>Gap Lock</h4><p>Gap Lock 称为间隙锁，只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下幻读的现象。</p><p>假设，表中有一个范围 id 为（3，5）间隙锁，那么其他事务就无法插入 id = 4 这条记录了，这样就有效的防止幻读现象的发生。</p><p><img src="https://s8.51cto.com/oss/202211/17/350d0ad07ddb5b5f5b821628f2f62b7bc75ac9.png" alt="图片" title="图片"></p><p>间隙锁虽然存在 X 型间隙锁和 S 型间隙锁，但是并没有什么区别，间隙锁之间是兼容的，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出的。</p><h4 id="Next-Key-Lock"><a href="#Next-Key-Lock" class="headerlink" title="Next-Key Lock"></a>Next-Key Lock</h4><p>Next-Key Lock 称为临键锁，是 Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。</p><p>假设，表中有一个范围 id 为（3，5] 的 next-key lock，那么其他事务即不能插入 id = 4 记录，也不能修改和删除 id = 5 这条记录。</p><p><img src="https://s5.51cto.com/oss/202211/17/a4db4650124dd8d27f7625f154acf4b3a49d95.png" alt="图片" title="图片"></p><p>所以，next-key lock 即能保护该记录，又能阻止其他事务将新记录插入到被保护记录前面的间隙中。</p><p>next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的。</p><p>比如，一个事务持有了范围为 (1, 10] 的 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，就会被阻塞。</p><p>虽然相同范围的间隙锁是多个事务相互兼容的，但对于记录锁，我们是要考虑 X 型与 S 型关系，X 型的记录锁与 X 型的记录锁是冲突的。</p><h3 id="MySQL-是怎么加行级锁的？"><a href="#MySQL-是怎么加行级锁的？" class="headerlink" title="MySQL 是怎么加行级锁的？"></a>MySQL 是怎么加行级锁的？</h3><p>行级锁加锁规则比较复杂，不同的场景，加锁的形式是不同的。</p><p>加锁的对象是索引，加锁的基本单位是 next-key lock，它是由记录锁和间隙锁组合而成的，next-key lock 是前开后闭区间，而间隙锁是前开后开区间。</p><p>但是，next-key lock 在一些场景下会退化成记录锁或间隙锁。</p><p>那到底是什么场景呢？总结一句，在能使用记录锁或者间隙锁就能避免幻读现象的场景下， next-key lock  就会退化成退化成记录锁或间隙锁。</p><p>这次会以下面这个表结构来进行实验说明：</p><pre><code>CREATE TABLE `user` (  `id` bigint NOT NULL AUTO_INCREMENT,  `name` varchar(30) COLLATE utf8mb4_unicode_ci NOT NULL,  `age` int NOT NULL,  PRIMARY KEY (`id`),  KEY `index_age` (`age`) USING BTREE) ENGINE=InnoDB  DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;</code></pre><p>其中，id 是主键索引（唯一索引），age 是普通索引（非唯一索引），name 是普通的列。</p><p>表中的有这些行记录：</p><p><img src="https://s8.51cto.com/oss/202211/17/b8c11cf0949bda4061f031cd804b9fc1024723.png" alt="图片" title="图片"></p><p>这次实验环境的 MySQL 版本是 8.0.26，隔离级别是「可重复读」。</p><p>不同版本的加锁规则可能是不同的，但是大体上是相同的。</p><h4 id="唯一索引等值查询"><a href="#唯一索引等值查询" class="headerlink" title="唯一索引等值查询"></a>唯一索引等值查询</h4><p>当我们用唯一索引进行等值查询的时候，查询的记录存不存在，加锁的规则也会不同：</p><p>当查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的 next-key lock 会退化成「记录锁」。</p><p>当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的 next-key lock 会退化成「间隙锁」。</p><p>接下里用两个案例来说明。</p><p><strong>1、记录存在的情况</strong></p><p>假设事务 A 执行了这条等值查询语句，查询的记录是「存在」于表中的。</p><pre><code>mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user where id = 1 for update;+----+--------+-----+| id | name   | age |+----+--------+-----+|  1 | 路飞   |  19 |+----+--------+-----+1 row in set (0.02 sec)</code></pre><p>那么，事务 A 会为 id 为 1 的这条记录就会加上 X 型的记录锁。</p><p><img src="https://s8.51cto.com/oss/202211/17/335b7ad611ad93cfd1263812e5655f9006df4a.png" alt="图片" title="图片"></p><p>接下来，如果有其他事务，对 id 为 1 的记录进行更新或者删除操作的话，这些操作都会被阻塞，因为更新或者删除操作也会对记录加 X 型的记录锁，而 X 锁和 X 锁之间是互斥关系。</p><p>比如，下面这个例子：</p><p><img src="https://s2.51cto.com/oss/202211/17/93f69fb720cfdab30882855af09c5c29d995fd.png" alt="图片" title="图片"></p><p>因为事务 A 对 id = 1的记录加了 X 型的记录锁，所以事务 B 在修改 id=1 的记录时会被阻塞，事务 C 在删除 id=1 的记录时也会被阻塞。</p><p>有什么命令可以分析加了什么锁？</p><p><img src="https://s3.51cto.com/oss/202211/17/f104a2c17dda54ed0cc106adff7fe2cae5c59b.png" alt="图片" title="图片"></p><p>我们可以通过 select * from performance_schema.data_locks\G; 这条语句，查看事务执行 SQL 过程中加了什么锁。</p><p>我们以前面的事务 A 作为例子，分析下下它加了什么锁。</p><p>从上图可以看到，共加了两个锁，分别是：</p><ul><li>  表锁：X 类型的意向锁；</li><li>  行锁：X 类型的记录锁；</li></ul><p>这里我们重点关注行级锁，图中 LOCK_TYPE 中的 RECORD 表示行级锁，而不是记录锁的意思。</p><p>通过 LOCK_MODE 可以确认是 next-key 锁，还是间隙锁，还是记录锁：</p><ul><li>  如果 LOCK_MODE 为X，说明是 next-key 锁；</li><li>  如果 LOCK_MODE 为X, REC_NOT_GAP，说明是记录锁；</li><li>  如果 LOCK_MODE 为X, GAP，说明是间隙锁；</li></ul><p>因此，此时事务 A 在 id = 1 记录的主键索引上加的是记录锁，锁住的范围是 id 为 1 的这条记录。这样其他事务就无法对 id 为 1 的这条记录进行更新和删除操作了。</p><p>从这里我们也可以得知，加锁的对象是针对索引，因为这里查询语句扫描的 B+ 树是聚簇索引树，即主键索引树，所以是对主键索引加锁。将对应记录的主键索引加 记录锁后，就意味着其他事务无法对该记录进行更新和删除操作了。</p><p>为什么唯一索引等值查询并且查询记录存在的场景下，该记录的索引中的 next-key lock 会退化成记录锁？</p><p>原因就是在唯一索引等值查询并且查询记录存在的场景下，仅靠记录锁也能避免幻读的问题。</p><p>幻读的定义就是，当一个事务前后两次查询的结果集，不相同时，就认为发生幻读。所以，要避免幻读就是避免结果集某一条记录被其他事务删除，或者有其他事务插入了一条新记录，这样前后两次查询的结果集就不会出现不相同的情况。</p><ul><li>  由于主键具有唯一性，所以其他事务插入 id = 1 的时候，会因为主键冲突，导致无法插入 id = 1 的新记录。这样事务 A 在多次查询  id = 1 的记录的时候，不会出现前后两次查询的结果集不同，也就避免了幻读的问题。</li><li>  由于对 id = 1 加了记录锁，其他事务无法删除该记录，这样事务 A 在多次查询  id = 1 的记录的时候，不会出现前后两次查询的结果集不同，也就避免了幻读的问题。</li></ul><p><strong>2、记录不存在的情况</strong></p><p>假设事务 A 执行了这条等值查询语句，查询的记录是「不存在」于表中的。</p><pre><code>mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user where id = 2 for update;Empty set (0.03 sec)</code></pre><p>接下来，通过 select * from performance_schema.data_locks\G; 这条语句，查看事务执行 SQL 过程中加了什么锁。</p><p>从上图可以看到，共加了两个锁，分别是：</p><ul><li>  表锁：X 类型的意向锁；</li><li>  行锁：X 类型的间隙锁；</li></ul><p>因此，此时事务 A 在 id = 5 记录的主键索引上加的是间隙锁，锁住的范围是 (1, 5)。</p><p><img src="https://s8.51cto.com/oss/202211/17/c4b97ce51a7ae98d3d2902f3d8f0cda6666113.png" alt="图片" title="图片"></p><p>接下来，如果有其他事务插入 id 值为 2、3、4 这一些记录的话，这些插入语句都会发生阻塞。</p><p>注意，如果其他事务插入的 id = 1 或者 id = 5 的记录话，并不会发生阻塞，而是报主键冲突的错误，因为表中已经存在 id = 1 和 id = 5 的记录了。</p><p>比如，下面这个例子：</p><p><img src="https://s5.51cto.com/oss/202211/17/c217c4b120edd923a1a5875c998a1acf8942c5.png" alt="图片" title="图片"></p><p>因为事务 A 在 id = 5 记录的主键索引上加了范围为 (1, 5) 的 X 型间隙锁，所以事务 B 在插入一条 id 为 3 的记录时会被阻塞住，即无法插入 id = 3 的记录。</p><ul><li>  间隙锁的范围(1, 5) ，是怎么确定的？</li></ul><p>根据我的经验，如果 LOCK_MODE 是 next-key 锁或者间隙锁，那么 LOCK_DATA 就表示锁的范围「右边界」，此次的事务 A 的 LOCK_DATA 是 5。</p><p>然后锁范围的「左边界」是表中 id 为 5 的上一条记录的 id 值，即 1。</p><p>因此，间隙锁的范围(1, 5)。</p><ul><li>  为什么唯一索引等值查询并且查询记录「不存在」的场景下，在索引树找到第一条大于该查询记录的记录后，要将该记录的索引中的 next-key lock 会退化成「间隙锁」？</li></ul><p>原因就是在唯一索引等值查询并且查询记录不存在的场景下，仅靠间隙锁就能避免幻读的问题。</p><ul><li>  为什么 id = 5 记录上的主键索引的锁不可以是 next-key lock？如果是 next-key lock，就意味着其他事务无法删除 id = 5 这条记录，但是这次的案例是查询 id = 2 的记录，只要保证前后两次查询 id = 2 的结果集相同，就能避免幻读的问题了，所以即使 id =5 被删除，也不会有什么影响，那就没必须加 next-key lock，因此只需要在 id = 5 加间隙锁，避免其他事务插入 id = 2 的新记录就行了。</li><li>  为什么不可以针对不存在的记录加记录锁？锁是加在索引上的，而这个场景下查询的记录是不存在的，自然就没办法锁住这条不存在的记录。</li></ul><p><strong>唯一索引范围查询</strong></p><p>范围查询和等值查询的加锁规则是不同的。</p><p>当唯一索引进行范围查询时，会对每一个扫描到的索引加 next-key 锁，然后如果遇到下面这些情况，会退化成记录锁或者间隙锁：</p><ul><li>  情况一：针对「大于等于」的范围查询，因为存在等值查询的条件，那么如果等值查询的记录是存在于表中，那么该记录的索引中的 next-key 锁会退化成记录锁。</li><li>  情况二：针对「小于或者小于等于」的范围查询，要看条件值的记录是否存在于表中：</li></ul><p>当条件值的记录不在表中，那么不管是「小于」还是「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁。</p><p>当条件值的记录在表中，如果是「小于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁；如果「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引 next-key 锁不会退化成间隙锁。其他扫描到的记录，都是在这些记录的索引上加 next-key 锁。</p><p>接下来，通过几个实验，才验证我上面说的结论。</p><h4 id="1、针对「大于或者大于等于」的范围查询"><a href="#1、针对「大于或者大于等于」的范围查询" class="headerlink" title="1、针对「大于或者大于等于」的范围查询"></a>1、针对「大于或者大于等于」的范围查询</h4><ul><li>  实验一：针对「大于」的范围查询的情况。</li></ul><p>假设事务 A 执行了这条范围查询语句：</p><pre><code>mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user where id &gt; 15 for update;+----+-----------+-----+| id | name      | age |+----+-----------+-----+| 20 | 香克斯    |  39 |+----+-----------+-----+1 row in set (0.01 sec)</code></pre><p>事务 A 加锁变化过程如下：</p><ul><li>  最开始要找的第一行是 id = 20，由于查询该记录不是一个等值查询（不是大于等于条件查询），所以对该主键索引加的是范围为  (15, 20] 的 next-key 锁；</li><li>  由于是范围查找，就会继续往后找存在的记录，虽然我们看见表中最后一条记录是 id = 20 的记录，但是实际在 Innodb 存储引擎中，会用一个特殊的记录来标识最后一条记录，该特殊的记录的名字叫 supremum pseudo-record ，所以扫描第二行的时候，也就扫描到了这个特殊记录的时候，会对该主键索引加的是范围为  (20, +∞] 的 next-key 锁。</li><li>  停止扫描。</li></ul><p>可以得知，事务 A 在主键索引上加了两个 X 型 的 next-key 锁：</p><p><img src="https://s6.51cto.com/oss/202211/17/d3dd90488fa33b184d0224cdc4e0617f675df2.png" alt="图片" title="图片"></p><ul><li>  在 id = 20 这条记录的主键索引上，加了范围为 (15, 20] 的 next-key 锁，意味着其他事务即无法更新或者删除 id = 20 的记录，同时无法插入 id 值为 16、17、18、19 的这一些新记录。</li><li>  在特殊记录（ supremum pseudo-record）的主键索引上，加了范围为 (20, +∞] 的 next-key 锁，意味着其他事务无法插入 id 值大于 20 的这一些新记录。</li></ul><p>我们也可以通过 select * from performance_schema.data_locks\G; 这条语句来看看事务 A 加了什么锁。</p><p>输出结果如下，我这里只截取了行级锁的内容。</p><p><img src="https://s2.51cto.com/oss/202211/17/14c4ad39784c460a1d4786e7526e54eb1650c0.png" alt="图片" title="图片"></p><p>从上图中的分析中，也可以得到事务 A 在主键索引上加了两个 X 型 的next-key 锁：</p><p>在 id = 20 这条记录的主键索引上，加了范围为 (15, 20] 的 next-key 锁，意味着其他事务即无法更新或者删除 id = 20 的记录，同时无法插入 id 值为 16、17、18、19 的这一些新记录。</p><p>在特殊记录（ supremum pseudo-record）的主键索引上，加了范围为 (20, +∞] 的 next-key 锁，意味着其他事务无法插入 id 值大于 20 的这一些新记录。</p><ul><li>  实验二：针对「大于等于」的范围查询的情况。</li></ul><p>假设事务 A 执行了这条范围查询语句：</p><pre><code>mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user where id &gt;= 15 for update;+----+-----------+-----+| id | name      | age |+----+-----------+-----+| 15 | 乌索普    |  20 || 20 | 香克斯    |  39 |+----+-----------+-----+2 rows in set (0.00 sec)</code></pre><p>事务 A 加锁变化过程如下：</p><ul><li>  最开始要找的第一行是 id = 15，由于查询该记录是一个等值查询（等于 15），所以该主键索引的 next-key 锁会退化成记录锁，也就是仅锁住 id = 15 这一行记录。</li><li>  由于是范围查找，就会继续往后找存在的记录，扫描到的第二行是 id = 20，于是对该主键索引加的是范围为  (15, 20] 的 next-key 锁；</li><li>  接着扫描到第三行的时候，扫描到了特殊记录（ supremum pseudo-record），于是对该主键索引加的是范围为  (20, +∞] 的 next-key 锁。</li><li>  停止扫描。</li></ul><p>可以得知，事务 A 在主键索引上加了三个 X 型 的锁，分别是：</p><p><img src="https://s8.51cto.com/oss/202211/17/57176529152103ed5b4067775f2af7089d1f1a.png" alt="图片" title="图片"></p><ul><li>  在 id = 15 这条记录的主键索引上，加了记录锁，范围是 id = 15 这一行记录；意味着其他事务无法更新或者删除 id = 15 的这一条记录；</li><li>  在 id = 20 这条记录的主键索引上，加了 next-key 锁，范围是  (15, 20] 。意味着其他事务即无法更新或者删除 id = 20 的记录，同时无法插入 id 值为 16、17、18、19 的这一些新记录。</li><li>  在特殊记录（ supremum pseudo-record）的主键索引上，加了 next-key 锁，范围是  (20, +∞] 。意味着其他事务无法插入 id 值大于 20 的这一些新记录。</li></ul><p>我们也可以通过 select * from performance_schema.data_locks\G; 这条语句来看看事务 A 加了什么锁。</p><p>输出结果如下，我这里只截取了行级锁的内容。</p><p><img src="https://s8.51cto.com/oss/202211/17/78a4d3304504d635a224667c2cf4c56fb252e7.png" alt="图片" title="图片"></p><p>通过前面这个实验，我们证明了：</p><p>针对「大于等于」条件的唯一索引范围查询的情况下， 如果条件值的记录存在于表中，那么由于查询该条件值的记录是包含一个等值查询的操作，所以该记录的索引中的 next-key 锁会退化成记录锁。</p><p><strong>2、针对「小于或者小于等于」的范围查询</strong></p><p>实验一：针对「小于」的范围查询时，查询条件值的记录「不存在」表中的情况。</p><p>假设事务 A 执行了这条范围查询语句，注意查询条件值的记录（id 为 6）并不存在于表中。</p><pre><code>mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user where id &lt; 6 for update;+----+--------+-----+| id | name   | age |+----+--------+-----+|  1 | 路飞   |  19 ||  5 | 索隆   |  21 |+----+--------+-----+3 rows in set (0.00 sec)</code></pre><p>事务 A 加锁变化过程如下：</p><ul><li>  最开始要找的第一行是 id = 1，于是对该主键索引加的是范围为  (-∞, 1] 的 next-key 锁；</li><li>  由于是范围查找，就会继续往后找存在的记录，扫描到的第二行是 id = 5，所以对该主键索引加的是范围为  (1, 5] 的 next-key 锁；</li><li>  由于扫描到的第二行记录（id = 5），满足 id &lt; 6 条件，而且也没有达到终止扫描的条件，接着会继续扫描。</li><li>  扫描到的第三行是 id = 10，该记录不满足 id &lt; 6 条件的记录，所以 id = 10 这一行记录的锁会退化成间隙锁，于是对该主键索引加的是范围为  (5, 10) 的间隙锁。</li></ul><p>由于扫描到的第三行记录（id = 10），不满足 id &lt; 6 条件，达到了终止扫描的条件，于是停止扫描。</p><p>从上面的分析中，可以得知事务 A 在主键索引上加了三个 X 型的锁：</p><p><img src="https://s7.51cto.com/oss/202211/17/93b2613114d0c8f1ea12735833e9395efd1e5b.png" alt="图片" title="图片"></p><ul><li>  在 id = 1 这条记录的主键索引上，加了范围为  (-∞, 1] 的 next-key 锁，意味着其他事务即无法更新或者删除 id = 1 的这一条记录，同时也无法插入 id 小于 1 的这一些新记录。</li><li>  在 id = 5 这条记录的主键索引上，加了范围为  (1, 5] 的 next-key 锁，意味着其他事务即无法更新或者删除 id = 5 的这一条记录，同时也无法插入 id 值为 2、3、4 的这一些新记录。</li><li>  在 id = 10 这条记录的主键索引上，加了范围为 (5, 10) 的间隙锁，意味着其他事务无法插入 id 值为 6、7、8、9 的这一些新记录。</li></ul><p>我们也可以通过 select * from performance_schema.data_locks\G; 这条语句来看看事务 A 加了什么锁。</p><p>输出结果如下，我这里只截取了行级锁的内容。</p><p><img src="https://s4.51cto.com/oss/202211/17/e4655f1291d7b84d43d644a5b49ae8a65b2d14.png" alt="图片" title="图片"></p><p>从上图中的分析中，也可以得知事务 A 在主键索引加的三个锁，就是我们前面分析出那三个锁。</p><p>虽然这次范围查询的条件是「小于」，但是查询条件值的记录不存在于表中（ id 为 6 的记录不在表中），所以如果事务 A 的范围查询的条件改成 &lt;= 6 的话，加的锁还是和范围查询条件为 &lt; 6 是一样的。大家自己也验证下这个结论。</p><p>因此，针对「小于或者小于等于」的唯一索引范围查询，如果条件值的记录不在表中，那么不管是「小于」还是「小于等于」的范围查询，扫描到终止范围查询的记录时，该记录中索引的 next-key 锁会退化成间隙锁，其他扫描的记录，则是在这些记录的索引上加 next-key 锁。</p><ul><li>  实验二：针对「小于等于」的范围查询时，查询条件值的记录「存在」表中的情况。</li></ul><p>假设事务 A 执行了这条范围查询语句，注意查询条件值的记录（id 为 5）存在于表中。</p><pre><code>mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user where id &lt;= 5 for update;+----+--------+-----+| id | name   | age |+----+--------+-----+|  1 | 路飞   |  19 ||  5 | 索隆   |  21 |+----+--------+-----+2 rows in set (0.00 sec)</code></pre><p>事务 A 加锁变化过程如下：</p><ul><li>  最开始要找的第一行是 id = 1，于是对该记录加的是范围为  (-∞, 1] 的 next-key 锁；</li><li>  由于是范围查找，就会继续往后找存在的记录，扫描到的第二行是 id = 5，于是对该记录加的是范围为  (1, 5] 的 next-key 锁。</li><li>  由于主键索引具有唯一性，不会存在两个 id = 5 的记录，所以不会再继续扫描，于是停止扫描。</li></ul><p>从上面的分析中，可以得到事务 A 在主键索引上加了 2 个 X 型的锁：</p><p><img src="https://s2.51cto.com/oss/202211/17/f4e08bd9250f337a4eb212ab839ce2206c56ee.png" alt="图片" title="图片"></p><ul><li>  在 id = 1 这条记录的主键索引上，加了范围为  (-∞, 1] 的 next-key 锁。意味着其他事务即无法更新或者删除 id = 1 的这一条记录，同时也无法插入 id 小于 1 的这一些新记录。</li><li>  在 id = 5 这条记录的主键索引上，加了范围为  (1, 5] 的 next-key 锁。意味着其他事务即无法更新或者删除 id = 5 的这一条记录，同时也无法插入 id 值为 2、3、4 的这一些新记录。</li></ul><p>我们也可以通过 select * from performance_schema.data_locks\G; 这条语句来看看事务 A 加了什么锁。</p><p>输出结果如下，我这里只截取了行级锁的内容。</p><p><img src="https://s2.51cto.com/oss/202211/17/2605f4e85a7b1acf1f4827b2373544622c3fd9.png" alt="图片" title="图片"></p><p>从上图中的分析中，可以得到事务 A 在主键索引上加了两个 X 型 next-key 锁，分别是：</p><p>在 id = 1 这条记录的主键索引上，加了范围为  (-∞, 1] 的 next-key 锁；</p><p>在 id = 5 这条记录的主键索引上，加了范围为(1, 5 ] 的 next-key 锁。</p><ul><li>  实验三：再来看针对「小于」的范围查询时，查询条件值的记录「存在」表中的情况。</li></ul><p>如果事务 A 的查询语句是小于的范围查询，且查询条件值的记录（id 为 5）存在于表中。</p><pre><code>select * from user where id &lt; 5 for update;</code></pre><p>事务 A 加锁变化过程如下：</p><ul><li>  最开始要找的第一行是 id = 1，于是对该记录加的是范围为  (-∞, 1] 的 next-key 锁；</li><li>  由于是范围查找，就会继续往后找存在的记录，扫描到的第二行是 id = 5，该记录是第一条不满足 id &lt; 5 条件的记录，于是**该记录的锁会退化为间隙锁，锁范围是 (1,5)**。</li><li>  由于找到了第一条不满足 id &lt; 5 条件的记录，于是停止扫描。</li></ul><p>可以得知，此时事务 A 在主键索引上加了两种 X 型锁：</p><p><img src="https://s2.51cto.com/oss/202211/17/65e3022974ae9b602d3500e834f408f5e85668.png" alt="图片" title="图片"></p><ul><li>  在 id = 1 这条记录的主键索引上，加了范围为  (-∞, 1] 的 next-key 锁，意味着其他事务即无法更新或者删除 id = 1 的这一条记录，同时也无法插入 id 小于 1 的这一些新记录。</li><li>  在 id = 5 这条记录的主键索引上，加了范围为 (1,5) 的间隙锁，意味着其他事务无法插入 id 值为 2、3、4 的这一些新记录。</li></ul><p>我们也可以通过 select * from performance_schema.data_locks\G; 这条语句来看看事务 A 加了什么锁。</p><p>输出结果如下，我这里只截取了行级锁的内容。</p><p><img src="https://s4.51cto.com/oss/202211/17/572d3c51267ab0fdb086525e735d7db0bcc80b.png" alt="图片" title="图片"></p><p>从上图中的分析中，可以得到事务 A 在主键索引上加了 X 型的范围为  (-∞, 1] 的 next-key 锁，和 X 型的范围为 (1, 5) 的间隙锁。</p><p>因此，通过前面这三个实验，可以得知。</p><p>在针对「小于或者小于等于」的唯一索引（主键索引）范围查询时，存在这两种情况会将索引的 next-key 锁会退化成间隙锁的：</p><ul><li>  当条件值的记录「不在」表中时，那么不管是「小于」还是「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的主键索引中的 next-key 锁会退化成间隙锁，其他扫描到的记录，都是在这些记录的主键索引上加 next-key 锁。</li><li>  当条件值的记录「在」表中时：</li></ul><p>如果是「小于」条件的范围查询，扫描到终止范围查询的记录时，该记录的主键索引中的 next-key 锁会退化成间隙锁，其他扫描到的记录，都是在这些记录的主键索引上，加 next-key 锁。</p><p>如果是「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的主键索引中的 next-key 锁「不会」退化成间隙锁，其他扫描到的记录，都是在这些记录的主键索引上加 next-key 锁。</p><p><strong>非唯一索引等值查询</strong></p><p>当我们用非唯一索引进行等值查询的时候，因为存在两个索引，一个是主键索引，一个是非唯一索引（二级索引），所以在加锁时，同时会对这两个索引都加锁，但是对主键索引加锁的时候，只有满足查询条件的记录才会对它们的主键索引加锁。</p><p>针对非唯一索引等值查询时，查询的记录存不存在，加锁的规则也会不同：</p><ul><li>  当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的  next-key 锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁。</li><li>  当查询的记录「不存在」时，扫描到第一条不符合条件的二级索引记录，该二级索引的  next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁。</li></ul><p>接下里用两个实验来说明。</p><p><strong>1、记录不存在的情况</strong></p><p>实验一：针对非唯一索引等值查询时，查询的值不存在的情况。</p><p>先来说说非唯一索引等值查询时，查询的记录不存在的情况，因为这个比较简单。</p><p>假设事务 A 对非唯一索引（age）进行了等值查询，且表中不存在 age = 25 的记录。</p><pre><code>mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user where age = 25 for update;Empty set (0.00 sec)</code></pre><p>事务 A 加锁变化过程如下：</p><ul><li>  定位到第一条不符合查询条件的二级索引记录，即扫描到 age = 39，于是**该二级索引的  next-key 锁会退化成间隙锁，范围是 (22, 39)**。</li><li>  停止查询</li></ul><p>事务 A 在 age = 39 记录的二级索引上，加了 X 型的间隙锁，范围是  (22, 39)。意味着其他事务无法插入 age 值为 23、24、25、26、….、38 这些新记录。不过对于插入 age = 22 和 age = 39 记录的语句，在一些情况是可以成功插入的，而一些情况则无法成功插入，具体哪些情况，会在后面说。</p><p>我们也可以通过 select * from performance_schema.data_locks\G; 这条语句来看看事务 A 加了什么锁。</p><p>输出结果如下，我这里只截取了行级锁的内容。</p><p><img src="https://s3.51cto.com/oss/202211/17/2261b163874ebefc947749258155d65bff7b5f.png" alt="图片" title="图片"></p><p>从上图的分析，可以看到，事务 A 在 age = 39 记录的二级索引上（INDEX_NAME: index_age  ），加了范围为 (22, 39) 的 X 型间隙锁。</p><p>此时，如果有其他事务插入了 age 值为 23、24、25、26、….、38 这些新记录，那么这些插入语句都会发生阻塞。不过对于插入 age = 39 记录的语句，在一些情况是可以成功插入的，而一些情况则无法成功插入，具体哪些情况，接下来我们就说！</p><ul><li>  当有一个事务持有二级索引的间隙锁 (22, 39) 时，什么情况下，可以让其他事务的插入 age = 22 或者 age = 39 记录的语句成功？又是什么情况下，插入  age = 22 或者 age = 39 记录时的语句会被阻塞？</li></ul><p>我们先要清楚，什么情况下插入语句会发生阻塞。</p><p>插入语句在插入一条记录之前，需要先定位到该记录在 B+树 的位置，如果插入的位置的下一条记录的索引上有间隙锁，才会发生阻塞。</p><p>在分析二级索引的间隙锁是否可以成功插入记录时，我们要先要知道二级索引树是如何存放记录的？</p><p>二级索引树是按照二级索引值（age列）按顺序存放的，在相同的二级索引值情况下， 再按主键 id 的顺序存放。知道了这个前提，我们才能知道执行插入语句的时候，插入的位置的下一条记录是谁。</p><p>基于前面的实验，事务 A 是在 age = 39 记录的二级索引上，加了 X 型的间隙锁，范围是  (22, 39)。</p><p>插入 age = 22 记录的成功和失败的情况分别如下：</p><ul><li>  当其他事务插入一条 age = 22，id = 3 的记录的时候，在二级索引树上定位到插入的位置，而该位置的下一条是 id = 10、age = 22 的记录，该记录的二级索引上没有间隙锁，所以这条插入语句可以执行成功。</li><li>  当其他事务插入一条 age = 22，id = 12 的记录的时候，在二级索引树上定位到插入的位置，而该位置的下一条是 id = 20、age = 39 的记录，正好该记录的二级索引上有间隙锁，所以这条插入语句会被阻塞，无法插入成功。</li></ul><p>插入 age = 39 记录的成功和失败的情况分别如下：</p><ul><li>  当其他事务插入一条 age = 39，id = 3 的记录的时候，在二级索引树上定位到插入的位置，而该位置的下一条是 id = 20、age = 39 的记录，正好该记录的二级索引上有间隙锁，所以这条插入语句会被阻塞，无法插入成功。</li><li>  当其他事务插入一条 age = 39，id = 21 的记录的时候，在二级索引树上定位到插入的位置，而该位置的下一条记录不存在，也就没有间隙锁了，所以这条插入语句可以插入成功。</li></ul><p>所以，当有一个事务持有二级索引的间隙锁 (22, 39) 时，插入 age = 22 或者 age = 39 记录的语句是否可以执行成功，关键还要考虑插入记录的主键值，因为「二级索引值（age列）+主键值（id列）」才可以确定插入的位置，确定了插入位置后，就要看插入的位置的下一条记录是否有间隙锁，如果有间隙锁，就会发生阻塞，如果没有间隙锁，则可以插入成功。</p><p>知道了这个结论之后，我们再回过头看，非唯一索引等值查询时，查询的记录不存在时，执行select * from performance_schema.data_locks\G; 输出的结果。</p><p><img src="https://s9.51cto.com/oss/202211/17/49adbd824827c45e66f2863ef45d2027e7aa53.png" alt="图片" title="图片"></p><p>在前面分析输出结果的时候，我说的结论是：「事务 A 在 age = 39 记录的二级索引上（INDEX_NAME: index_age  ），加了范围为 (22, 39) 的 X 型间隙锁」。这个结论其实还不够准确，因为只考虑了 LOCK_DATA 第一个数值（39），没有考虑 LOCK_DATA 第二个数值（20）。</p><p>那 LOCK_DATA：39，20 是什么意思？</p><ul><li>  LOCK_DATA 第一个数值，也就是 39， 它代表的是 age 值。从前面我们也知道了，LOCK_DATA 第一个数值是 next-key 锁和间隙锁锁住的范围的右边界值。</li><li>  LOCK_DATA 第二个数值，也就是 20， 它代表的是 id 值。</li></ul><p>之所以 LOCK_DATA 要多显示一个数值（ID值），是因为针对「当某个事务持有非唯一索引的 (22, 39) 间隙锁的时候，其他事务是否可以插入 age = 39 新记录」的问题，还需要考虑插入记录的 id 值。而 LOCK_DATA 的第二个数值，就是说明在插入 age = 39 新记录时，哪些范围的 id 值是不可以插入的。</p><p>因此， LOCK_DATA：39，20 + LOCK_MODE : X, GAP 的意思是，事务 A 在 age = 39 记录的二级索引上（INDEX_NAME: index_age ），加了 age 值范围为 (22, 39) 的 X 型间隙锁，**同时针对其他事务插入 age 值为 39 的新记录时，不允许插入的新记录的 id 值小于 20 **。如果插入的新记录的 id 值大于 20，则可以插入成功。</p><p>但是我们无法从select * from performance_schema.data_locks\G; 输出的结果分析出「在插入 age =22 新记录时，哪些范围的 id 值是可以插入成功的」，这时候就得自己画出二级索引的 B+ 树的结构，然后确定插入位置后，看下该位置的下一条记录是否存在间隙锁，如果存在间隙锁，则无法插入成功，如果不存在间隙锁，则可以插入成功。</p><p><strong>2、记录存在的情况</strong></p><p>实验二：针对非唯一索引等值查询时，查询的值存在的情况。</p><p>假设事务 A 对非唯一索引（age）进行了等值查询，且表中存在 age = 22 的记录。</p><pre><code>mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user where age = 22 for update;+----+--------+-----+| id | name   | age |+----+--------+-----+| 10 | 山治   |  22 |+----+--------+-----+1 row in set (0.00 sec)</code></pre><p>事务 A 加锁变化过程如下：</p><ul><li>  由于不是唯一索引，所以肯定存在值相同的记录，于是非唯一索引等值查询的过程是一个扫描的过程，最开始要找的第一行是 age = 22，于是对该二级索引记录加上范围为 (21, 22] 的 next-key 锁。同时，因为 age = 22 符合查询条件，于是对 age = 22 的记录的主键索引加上记录锁，即对 id = 10 这一行加记录锁。</li><li>  接着继续扫描，扫描到的第二行是 age = 39，该记录是第一个不符合条件的二级索引记录，所以该二级索引的  next-key 锁会退化成间隙锁，范围是 (22, 39)。</li><li>  停止查询。</li></ul><p>可以看到，事务 A 对主键索引和二级索引都加了 X 型的锁：</p><p><img src="https://s4.51cto.com/oss/202211/17/a868f7775281584c26c092f6c22f69d28a5365.png" alt="图片" title="图片"></p><ul><li>  主键索引：</li></ul><p>在 id = 10 这条记录的主键索引上，加了记录锁，意味着其他事务无法更新或者删除 id = 10 的这一行记录。</p><ul><li>  二级索引（非唯一索引）：</li></ul><p>在 age = 22 这条记录的二级索引上，加了范围为 (21, 22] 的 next-key 锁，意味着其他事务无法更新或者删除 age = 22 的这一些新记录，不过对于插入 age = 20 和 age = 21 新记录的语句，在一些情况是可以成功插入的，而一些情况则无法成功插入，具体哪些情况，会在后面说。</p><p>在 age = 39 这条记录的二级索引上，加了范围 (22, 39) 的间隙锁。意味着其他事务无法插入 age 值为 23、24、….. 、38 的这一些新记录。不过对于插入 age = 22 和 age = 39 记录的语句，在一些情况是可以成功插入的，而一些情况则无法成功插入，具体哪些情况，会在后面说。</p><p>我们也可以通过 select * from performance_schema.data_locks\G; 这条语句来看看事务 A 加了什么锁。</p><p>输出结果如下，我这里只截取了行级锁的内容。</p><p><img src="https://s8.51cto.com/oss/202211/17/311cd2d870406820cba657eb3fe70597ca6959.png" alt="图片" title="图片"></p><p>从上图的分析，可以看到，事务 A 对二级索引（INDEX_NAME: index_age ）加了两个 X 型锁，分别是：</p><ul><li>  在 age = 22 这条记录的二级索引上，加了范围为 (21, 22] 的 next-key 锁，意味着其他事务无法更新或者删除 age = 22 的这一些新记录，针对是否可以插入 age = 21 和 age = 22 的新记录，分析如下：</li></ul><p>是否可以插入 age = 21 的新记录，还要看插入的新记录的 id 值，如果插入 age = 21 新记录的 id 值小于 5，那么就可以插入成功，因为此时插入的位置的下一条记录是 id = 5，age = 21 的记录，该记录的二级索引上没有间隙锁。如果插入 age = 21 新记录的 id 值大于 5，那么就无法插入成功，因为此时插入的位置的下一条记录是 id = 20，age = 39 的记录，该记录的二级索引上有间隙锁。</p><p>是否可以插入 age = 22 的新记录，还要看插入的新记录的 id 值，从LOCK_DATA : 22, 10 可以得知，其他事务插入 age 值为 22 的新记录时，如果插入的新记录的 id 值小于 10，那么插入语句会发生阻塞；如果插入的新记录的 id 大于 10，还要看该新记录插入的位置的下一条记录是否有间隙锁，如果没有间隙锁则可以插入成功，如果有间隙锁，则无法插入成功。</p><ul><li>  在 age = 39 这条记录的二级索引上，加了范围 (22, 39) 的间隙锁。意味着其他事务无法插入 age 值为 23、24、….. 、38 的这一些新记录，针对是否可以插入 age = 22 和 age = 39 的新记录，分析如下：</li></ul><p>是否可以插入 age = 22 的新记录，还要看插入的新记录的 id 值，如果插入 age = 22 新记录的 id 值小于 10，那么插入语句会被阻塞，无法插入，因为此时插入的位置的下一条记录是 id = 10，age = 22 的记录，该记录的二级索引上有间隙锁（ age = 22 这条记录的二级索引上有 next-key 锁）。如果插入 age = 21 新记录的 id 值大于 10，也无法插入，因为此时插入的位置的下一条记录是 id = 20，age = 39 的记录，该记录的二级索引上有间隙锁。</p><p>是否可以插入 age = 39 的新记录，还要看插入的新记录的 id 值，从 LOCK_DATA : 39, 20 可以得知，其他事务插入 age 值为 39 的新记录时，如果插入的新记录的 id 值小于 20，那么插入语句会发生阻塞，如果插入的新记录的 id 大于 20，则可以插入成功。</p><p>同时，事务 A  还对主键索引（INDEX_NAME: PRIMARY ）加了X 型的记录锁：</p><ul><li>  在 id = 10 这条记录的主键索引上，加了记录锁，意味着其他事务无法更新或者删除 id = 10 的这一行记录。</li></ul><p>为什么这个实验案例中，需要在二级索引索引上加范围 (22, 39) 的间隙锁？</p><p>要找到这个问题的答案，我们要明白 MySQL 在可重复读的隔离级别场景下，为什么要引入间隙锁？其实是为了避免幻读现象的发生。</p><p>如果这个实验案例中：</p><pre><code>select * from user where age = 22 for update;</code></pre><p>如果事务 A 不在二级索引索引上加范围 (22, 39) 的间隙锁，只在二级索引索引上加范围为 (21, 22] 的 next-key 锁的话，那么就会有幻读的问题。</p><p>前面我也说过，在非唯一索引上加了范围为 (21, 22] 的 next-key 锁，是无法完全锁住 age  = 22 新记录的插入，因为对于是否可以插入 age = 22 的新记录，还要看插入的新记录的 id 值，从 LOCK_DATA : 22, 10 可以得知，其他事务插入 age 值为 22 的新记录时，如果插入的新记录的 id 值小于 10，那么插入语句会发生阻塞，如果插入的新记录的 id 值大于 10，则可以插入成功。</p><p>也就是说，只在二级索引索引（非唯一索引）上加范围为 (21, 22] 的 next-key 锁，其他事务是有可能插入 age 值为 22 的新记录的（比如插入一个 age = 22，id = 12 的新记录），那么如果事务 A 再一次查询 age = 22 的记录的时候，前后两次查询 age = 22 的结果集就不一样了，这时就发生了幻读的现象。</p><p>那么当在 age = 39 这条记录的二级索引索引上加了范围为 (22, 39) 的间隙锁后，其他事务是无法插入一个 age = 22，id = 12 的新记录，因为当其他事务插入一条 age = 22，id = 12 的新记录的时候，在二级索引树上定位到插入的位置，而该位置的下一条是 id = 20、age = 39 的记录，正好该记录的二级索引上有间隙锁，所以这条插入语句会被阻塞，无法插入成功，这样就避免幻读现象的发生。</p><p>所以，为了避免幻读现象的发生，就需要在二级索引索引上加范围 (22, 39) 的间隙锁。</p><p><strong>非唯一索引范围查询</strong></p><p>非唯一索引和主键索引的范围查询的加锁也有所不同，不同之处在于非唯一索引范围查询，索引的 next-key lock 不会有退化为间隙锁和记录锁的情况，也就是非唯一索引进行范围查询时，对二级索引记录加锁都是加 next-key 锁。</p><p>就带大家简单分析一下，事务 A 的这条范围查询语句：</p><pre><code>mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user where age &gt;= 22  for update;+----+-----------+-----+| id | name      | age |+----+-----------+-----+| 10 | 山治      |  22 || 20 | 香克斯    |  39 |+----+-----------+-----+2 rows in set (0.01 sec)</code></pre><p>事务 A 的加锁变化：</p><ul><li>  最开始要找的第一行是 age = 22，虽然范围查询语句包含等值查询，但是这里不是唯一索引范围查询，所以是不会发生退化锁的现象，因此对该二级索引记录加 next-key 锁，范围是 (21, 22]。同时，对 age = 22 这条记录的主键索引加记录锁，即对 id = 10 这一行记录的主键索引加记录锁。</li><li>  由于是范围查询，接着继续扫描已经存在的二级索引记录。扫面的第二行是 age = 39 的二级索引记录，于是对该二级索引记录加 next-key 锁，范围是 (22, 39]，同时，对 age = 39 这条记录的主键索引加记录锁，即对 id = 20 这一行记录的主键索引加记录锁。</li><li>  虽然我们看见表中最后一条二级索引记录是 age = 39 的记录，但是实际在 Innodb 存储引擎中，会用一个特殊的记录来标识最后一条记录，该特殊的记录的名字叫 supremum pseudo-record ，所以扫描第二行的时候，也就扫描到了这个特殊记录的时候，会对该二级索引记录加的是范围为  (39, +∞] 的 next-key 锁。</li></ul><p>停止查询</p><p>可以看到，事务 A 对主键索引和二级索引都加了 X 型的锁：</p><p><img src="https://s7.51cto.com/oss/202211/17/d6ae507946974e2de34900959434cb668a11e2.png" alt="图片" title="图片"></p><ul><li>  主键索引（id 列）：</li></ul><p>在 id = 10 这条记录的主键索引上，加了记录锁，意味着其他事务无法更新或者删除 id = 10 的这一行记录。</p><p>在 id = 20 这条记录的主键索引上，加了记录锁，意味着其他事务无法更新或者删除 id = 20 的这一行记录。</p><ul><li>  二级索引（age 列）：</li></ul><p>在 age = 22 这条记录的二级索引上，加了范围为 (21, 22] 的 next-key 锁，意味着其他事务无法更新或者删除 age = 22 的这一些新记录，不过对于是否可以插入 age = 21 和 age = 22 的新记录，还需要看新记录的 id 值，有些情况是可以成功插入的，而一些情况则无法插入，具体哪些情况，我们前面也讲了。</p><p>在 age = 39 这条记录的二级索引上，加了范围为 (22, 39] 的 next-key 锁，意味着其他事务无法更新或者删除 age = 39 的这一些记录，也无法插入 age 值为 23、24、25、…、38 的这一些新记录。不过对于是否可以插入 age = 22 和 age = 39 的新记录，还需要看新记录的 id 值，有些情况是可以成功插入的，而一些情况则无法插入，具体哪些情况，我们前面也讲了。</p><ul><li>  在特殊的记录（supremum pseudo-record）的二级索引上，加了范围为 (39, +∞] 的 next-key 锁，意味着其他事务无法插入 age 值大于 39 的这些新记录。</li></ul><p>在 age &gt;= 22  的范围查询中，明明查询 age = 22 的记录存在并且属于等值查询，为什么不会像唯一索引那样，将 age = 22 记录的二级索引上的 next-key 锁退化为记录锁？</p><p>因为 age 字段是非唯一索引，不具有唯一性，所以如果只加记录锁（记录锁无法防止插入，只能防止删除或者修改），就会导致其他事务插入一条 age = 22 的记录，这样前后两次查询的结果集就不相同了，出现了幻读现象。</p><p><strong>没有加索引的查询</strong></p><p>前面的案例，我们的查询语句都有使用索引查询，也就是查询记录的时候，是通过索引扫描的方式查询的，然后对扫描出来的记录进行加锁。</p><p>如果锁定读查询语句，没有使用索引列作为查询条件，或者查询语句没有走索引查询，导致扫描是全表扫描。那么，每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表，这时如果其他事务对该表进行增、删、改操作的时候，都会被阻塞。</p><p>不只是锁定读查询语句不加索引才会导致这种情况，update 和 delete 语句如果查询条件不加索引，那么由于扫描的方式是全表扫描，于是就会对每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表。</p><p>因此，在线上在执行 update、delete、select … for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了，这是挺严重的问题。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这次我以 MySQL 8.0.26 版本，在可重复读隔离级别之下，做了几个实验，让大家了解了唯一索引和非唯一索引的行级锁的加锁规则。</p><p>我这里总结下，  MySQL 行级锁的加锁规则。</p><p>唯一索引等值查询：</p><ul><li>  当查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的 next-key lock 会退化成「记录锁」。</li><li>  当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的 next-key lock 会退化成「间隙锁」。</li></ul><p>非唯一索引等值查询：</p><ul><li>  当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁。</li><li>  当查询的记录「不存在」时，扫描到第一条不符合条件的二级索引记录，该二级索引的  next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁。</li></ul><p>非唯一索引和主键索引的范围查询的加锁规则不同之处在于：</p><ul><li>  唯一索引在满足一些条件的时候，索引的 next-key lock 退化为间隙锁或者记录锁。</li><li>  非唯一索引范围查询，索引的 next-key lock 不会退化为间隙锁和记录锁。</li></ul><p>其实理解 MySQL 为什么要这样加锁，主要要以避免幻读角度去分析，这样就很容易理解这些加锁的规则了。</p><p>还有一件很重要的事情，在线上在执行 update、delete、select … for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了，这是挺严重的问题。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;保姆级教程！2 万字 + 30 张图搞懂 MySQL 是怎么加行级锁的？&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.51cto.com/article/740013.html&quot;&gt;https://www.51cto.com/article/740013.html</summary>
      
    
    
    
    <category term="mysql" scheme="http://zhangyu.info/categories/mysql/"/>
    
    
    <category term="mysql" scheme="http://zhangyu.info/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>OKR之剑·理念篇01-OKR带给我们的改变我们的改变</title>
    <link href="http://zhangyu.info/2022/11/02/OKR%E4%B9%8B%E5%89%91%C2%B7%E7%90%86%E5%BF%B5%E7%AF%8701-OKR%E5%B8%A6%E7%BB%99%E6%88%91%E4%BB%AC%E7%9A%84%E6%94%B9%E5%8F%98%E6%88%91%E4%BB%AC%E7%9A%84%E6%94%B9%E5%8F%98/"/>
    <id>http://zhangyu.info/2022/11/02/OKR%E4%B9%8B%E5%89%91%C2%B7%E7%90%86%E5%BF%B5%E7%AF%8701-OKR%E5%B8%A6%E7%BB%99%E6%88%91%E4%BB%AC%E7%9A%84%E6%94%B9%E5%8F%98%E6%88%91%E4%BB%AC%E7%9A%84%E6%94%B9%E5%8F%98/</id>
    <published>2022-11-01T16:00:00.000Z</published>
    <updated>2022-11-17T14:59:35.032Z</updated>
    
    <content type="html"><![CDATA[<p>平台产品研发团队 vivo互联网技术 2022-11-02</p><p><a href="https://mp.weixin.qq.com/s/NLxg-4JUx-F-0NwPfO1qIw">https://mp.weixin.qq.com/s/NLxg-4JUx-F-0NwPfO1qIw</a></p><p>[OKR之剑（理念篇）01—— OKR带给我们的改变_<a href="https://blog.csdn.net/m0_56069948/article/details/126869001">虚幻私塾】的博客-CSDN博客_okr总是变化</a></p><blockquote><blockquote><p>作者：vivo互联网平台产品研发团队</p></blockquote><h1 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h1><p>OKR即目标与关键成果法，起源于英特尔，在谷歌发扬光大。近几年在国内比较火，很多企业都相继引入了OKR的管理方式，小到2-3人的小微初创公司，大到十几万名员工的大型企业，都因此而受益。vivo互联网团队经过三年的积极实践，证实这一目标管理工具对于业务和人员发展有非常强大的推动作用。</p><p>“众多企业争相追捧的OKR，到底是何方神圣？我可以用么？”</p><p>从各个渠道了解到OKR对企业有正向作用的你，一定也有这样的疑问。那么此小节，我们先简单解答下这个问题，同时也论述下本系列文章的核心理念，让你充满信心的深入学习OKR以及本系列文章的实践经验。</p><p>通俗来讲，OKR就是一套科学的目标管理工具和方法，它的特点在于重视员工内在动机，激发员工内在潜能，提升员工工作热情。与其他目标管理方法不同的是，OKR弱化了目标管理和绩效考核的关系，通过鼓励员工主动制定更有挑战性的目标，鼓励目标的开放透明，团队精诚合作对齐一致，最终达成大团队的目标。</p><p>本系列文章是基于我们团队中的具体OKR实践，讲述我们如何理解和运用OKR，以及在OKR运用过程中如何践行“团队管理”这一学问，并且在文章中分享我们的团队管理的心得和理念。我们认为OKR与管理的有机结合，归根结底还是对管理的理解要一致，正如德鲁克之言：“<strong>企业需要的管理原则，就是让个人充分发挥特长，凝聚共同的愿景和一致的努力方向，建立团队合作，调和个人目标和共同福祉</strong>”，这其中又包含了两个要点：</p><p><strong>1.目标一致，是战略目标达成的关键</strong></p><p>在信息不透明的情况下，员工和企业计划和战略没有对齐，团队之间规划和方向没有对齐，相互之间目标不一致，怎么可能协作顺畅？特别是当员工只专注个人成就，团队只在乎局部胜利，而非企业整体目标，这对于企业发展来说是非常致命的。</p><p><strong>2.管理之责，在于充分发挥员工才能</strong></p><p>经营企业其实就是经营人，团队管理也是一样。人尽其才，才尽其用，是企业管理的目标之一。OKR让员工自己制定挑战性任务，并在目标达成的推进过程中突破自我局限，收获成长和成就感。在目标制定阶段，员工可以切实的感受到是在掌控工作，而不是被支配。在目标执行过程中，员工可以获得实实在在的能力提升、成就感和相应的影响力，进而有更强的动力去挑战下一阶段的目标，以此进入良性循环。最终OKR高效激发了员工潜能，并逐步释放整个团队的潜力。</p><p>在本系列文章中，我们采用场景化方式进行讲述，让你能够在碎片化的时间里了解我们的执行细节，并从中有所收获，解除OKR实践和团队管理上的困惑。</p><h1 id="二、我们为何引入OKR？"><a href="#二、我们为何引入OKR？" class="headerlink" title="二、我们为何引入OKR？"></a>二、我们为何引入OKR？</h1><p>通过前面介绍，相信你对OKR已经有了一个初步的印象。本小节主要介绍我们是怎样的一个团队，并让大家更加清楚我们是在什么样的背景下开始接触并践行OKR的。</p><p>我们团队于2015年成立，最初只有几个人，主要负责业务方向是垂直电商。最开始的电商研发小队，接到这个时间紧任务重的从0到1的建设任务，也是鸭梨山大。好在团队梯队比较健全，有深耕互联网多年的老司机，有初出茅庐的应届大学生，在互帮互学的氛围引领下，逢山开路遇水架桥，逐渐在一片混沌的情况下开辟了新气象。最终我们把国内电商这块硬骨头啃了下来，收获了业务团队的信任和兄弟团队的称赞。</p><p>在这种团队风貌的影响下，越来越多的业务交接过来，小队也逐渐变成了小组，变成了大组，直至成长为如今的平台产品研发中心，负责整个vivo互联网平台类方向的研发工作。在这风云变幻的8年里，我们见证了互联网的飞速发展，也经历了组织架构调整，业务调整，团队合并，我们改变了很多，但始终保持着那份初心。</p><p>一路走来我们收获了非常多的荣誉，同时也遇到了相当多的困难，特别是在团队规模持续扩大的情况下，我们的团队管理面临着巨大的挑战：</p><p><strong>1.团队目标对不齐，项目协作总困难</strong></p><p>这是在当时非常常见的问题，多发生在上下游有依赖的项目中。比如某一个项目，同时有多个团队在支撑，而这些团队都有各自的产品规划和目标。这就导致在项目版本中，经常出现A团队觉得有个需求非常重要紧急，需要B团队配合，却发现B团队因为要执行自己的计划而出现资源冲突。</p><p><strong>2.角色视角有偏差，Roadmap拍脑袋</strong></p><p>即使在同一个项目团队，也会存在因为角色的不同而在一些事情上出现分歧，一个产品从研发的视角来看要让其稳定高性能的运行，此时他就会想着做对外接口的性能优化；从产品经理的视角来看就想让产品具备更完备的功能，不停的增加新功能。</p><p>因为资源的有限，是先进行接口性能优化还是开发产品新功能呢？两拨人争执不下，每个人都说自己的优先级高，这个时候我们怎么做决策呢？</p><p><strong>3.版本人力空转，资源协调不及时</strong></p><p>我们的团队负责的项目很多，大的项目十几人参与，小的项目一个人负责几个，出现“旱的旱死，涝的涝死”的情况再正常不过了，有些项目这段时间特别的忙，版本的排期都是根据最终交付时间进行倒排，而此时此刻另外一些项目却只有零星的小需求，不慌不忙。</p><p><strong>4.学习进取成空谈，完成任务是唯一</strong></p><p>为了打造一支学习型的团队，公司专门建设了一个线上学习平台，上面有各种类别的学习视频，并且规定每个员工每年必须参与学习多长时间，即使这样效果也不甚理想，每年到年底的时候很多人都需要进行冲刺，毕竟学习是痛苦的，让大家快乐的学习貌似变成了一件不可能的事情。</p><p><strong>5.绩效考核遭质疑，什么样才算是优秀？</strong></p><p>一个高绩效员工所产出的创新效果数倍于一个能力中等的人，同时优秀人才创造的出色成果还能感染激励更多的出色人才，可见优秀的人是多么的重要。</p><p>那么如何识别优秀的人才呢？以前我们用环评+自评+KPI三套组合拳的方式来评定优秀，导致员工比较质疑这个结果的公平性，因为环评+自评本身非常主观，并且KPI又不够透明，管理者总是需要直面这样的挑战：为什么这个人表现平平，绩效比我好？</p><p>上面列举了我们团队之前趟过的一些坑，其实说到底还是怎么管理团队的问题，包括如何调动员工积极性，如何发挥每个人的主观能动性，这也是我们一直在思考的方向。在16年，我们就已经逐渐意识到，原有的类KPI的绩效考核方法对于研发岗位变得不适用了。随后我们去寻找新的管理办法，调研了主流的管理方式，发现它们都与vivo互联网的文化和团队实际情况无法完美契合。</p><p>向外求无果的情况下，我们开始摸索新的管理理念来打造高绩效团队，同时积极寻找更加优秀的管理工具，期望能够将沉淀下来的经验更好地落地和推广。19年的夏天，部门开始学习、引入OKR管理工具。在学习OKR了相关理论书籍后，我们惊奇的发现原来一直苦苦找寻的，能解决我们痛点的工具，就这样出现了我们的面前，直叹相见恨晚。</p><h1 id="三、OKR带给我们的改变"><a href="#三、OKR带给我们的改变" class="headerlink" title="三、OKR带给我们的改变"></a>三、OKR带给我们的改变</h1><p>我们团队的愿景：持续成长为行业一流的技术团队，并打造出了一支自组织、高绩效的标杆团队。目前由三大互联网服务端研发团队组成，人员规模在两百人左右，业务整体可以划分三个方向（三驾马车）：平台产品，营销产品，创新产品。三大业务方向相辅相成，都有着各自的责任和使命。</p><p><strong>平台产品</strong>主要包括业务平台与效率中台两大模块，完善沉淀，稳定支撑业务发展的项目。</p><p><strong>营销产品</strong>主要包括线上营销与线下营销两个模块，主要是能力组合复用，助力营销变革。</p><p><strong>创新产品</strong>主要包括管理创新与技术创新两个模块，创新产品主要是源于业务，发掘新的可能。</p><p>无论团队人员规模还是业务复杂度，都不难看出，对于团队成员以及业务的管理面临着不小的挑战。从19年正式引入OKR起，为了应对不断变化的业务，以及不断调整的组织结构，在团队和业务发展中，我们不断实践和优化符合我们团队特色的管理方式，集百家之长，成一家之言，逐渐沉淀出一套逻辑清晰的管理理念。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/b761540df78dc20204c2d1eb91cfc975.png"></p><p>引入OKR三年多来，让我们一直坚持的“面向未来的组织”的管理理念遍地开花，给我们团队带来了方方面面的改变。团队的凝聚力、氛围以及生产力得到了极大提升，以下是我们认为比较重要的改变。</p><h2 id="3-1专注团队最重要目标"><a href="#3-1专注团队最重要目标" class="headerlink" title="3.1专注团队最重要目标"></a>3.1专注团队最重要目标</h2><blockquote><p>人生之要事在于确立伟大的目标与实现这目标的决心。——歌德</p></blockquote><p>首先，我们需要制定出好的目标，需要足够“伟大”，同时又要让所有人都能够有参与感。在引入OKR后，我们的目标是通过自上而下+自下而上双向产生。在公司确定年度规划和战略目标后，我们会根据自身业务和团队的特点，制定具有挑战性的目标以支撑战略的落地；接着团队成员主动去思考，制定出衡量实现此目标的关键结果，以此解决目标的制定与目标的执行割裂的问题，让团队成员都有参与感，自主感。</p><p>其次我们会为每条关键结果指定负责人，通常是由提出人负责，当然也可以协商由其他人负责。在负责人owner制度下，可以更好的发挥主观能动性，从心理学角度激发完成承诺的欲望。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/f4297458cc2da95c41e87590b4bd35f8.png"></p><p>最后使用在线的OKR管理工具来保证目标的透明性和公开性，通过每周OKR tips来提醒员工持续专注于自己的OKR目标，通过两周一次的OKR庆功会来持续激励和反馈困难。多措并举之下，团队成员自始至终都专注于最重要的目标。</p><h2 id="3-2聚焦价值挑战不可能"><a href="#3-2聚焦价值挑战不可能" class="headerlink" title="3.2聚焦价值挑战不可能"></a>3.2聚焦价值挑战不可能</h2><p>有的人可能会讲定目标那还不简单，但是我们认为，目标不能太多，需要集中优势兵力解决核心问题，让组织保持专注。资源是有限的，为了保证组织的专注，目标的制定必须要聚焦价值。这样事情就变得简单多了，当我们进行两个人目标PK的时候，就比较张三的目标与李四的目标的价值，每个人对自己提出的目标进行价值论证，同时论证的过程也逼迫着我们深入思考，思考我们的目标对用户的价值，对产品的价值，对组织的价值，然后大家一起评估，最终确定我们这个季度的目标。</p><p>这个时候有人就会反驳说，难道没有引入OKR，你们就不思考价值？目标的制定肯定会思考，参考上一节，没有引入OKR的时候，目标是少数人在制定，大部分是自己说服自己，而引入OKR之后，目标是大家一起制定的，那么这个时候就需要每个人都要对目标进行思考。如果你想要自己的目标脱颖而出，那你就要把你的目标的商业价值说的非常清楚，比如为产品提高百分之多少的日活，带来多少收入，节省多少开支。</p><p>目标制定聚焦于价值，也逐步改变了我们绩效评估的方式。以往我们绩效评估，看的是员工在一个绩效周期业务版本、上司任务的产出，员工被动接受任务；随着我们对目标价值的追求，绩效评估也变得更为简单，考察员工在绩效周期内带来的价值即可，员工主动挖掘任务，解决团队最核心的问题。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/440938b36da10fcb10e1d2f3a15638e6.png"></p><h2 id="3-3团队高效协作"><a href="#3-3团队高效协作" class="headerlink" title="3.3团队高效协作"></a>3.3团队高效协作</h2><p>季度初设定了有挑战的目标，那么如何在季度末保证目标的关键结果达成呢？制定目标容易，难的是目标的达成。从一个创意到可运行的产品或服务、再到让客户认可价值，然后客户开始使用，到最终愿意为之付费，整个过程的每个环节难度都在增大，每个环节都需要我们组建合适的团队来完成。</p><p>从前文中关于我们中心的介绍可看出，团队负责的业务形态不同，每个业务的优先级、重要性也不同，每个项目运行的周期都呈现出忙闲交替的现象，作为管理者通过什么手段来合理的调度人力资源？一个KR负责人评估当前KR完成需要的人力不足时该怎么办？一个团队战斗力爆表的成员，完成了自己负责的KR外还想做更多的事情怎么办？</p><p>针对上面的现象，我们建设了伙力平台：一个用于管理人力池、招募人才和认领任务的系统。我们期望能够通过这个平台解决上面的问题时，而此时面临的最大的问题，就是如何保证员工认领任务的积极性。对于普通员工来说，需要走出舒适圈，面对不了解的需求，不熟悉的伙伴，本身就是一件非常具有挑战的事情，如果没有一个好的团队氛围，必然会导致意愿下降，没有人参与，没有人发布，恶性循环，最终流于形式。</p><p>得益于OKR的目标公开透明，和层层分解的思路，员工对组织目标有更加清晰的认知，对于共同目标的达成有更强的意愿。只有大团队的胜利，才能证明小团队的努力是有价值的，才能证明个人的努力是成功的。在这样共赢的氛围下，强化了人与人的信任和协作，弱化了内耗和竞争，伙力平台的能力得到了最大程度的发挥。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/583f1b325028a4b43288273a91491b5a.png"></p><p>从伙力平台上线到现在一年多的时间里，一共发布了35个任务，共有72个同事申请，实现了408个人日的火力输出，不仅帮助我们协调了项目间的人力，更促进了团队共同成长，让优秀的人脱颖而出。不断的成功和胜利，让员工更加相信组织，相信队友，带来良性循环，实现了我们集中力量办大事的愿景。</p><h2 id="3-4浓厚的学习氛围"><a href="#3-4浓厚的学习氛围" class="headerlink" title="3.4浓厚的学习氛围"></a>3.4浓厚的学习氛围</h2><p>为了践行我们的核心价值观（学习是我们公司的核心价值观之一），为了更好的解决业务发展中的技术难题，同时也为了员工的自我成长，我们很有必要去营造一个浓厚的学习氛围。</p><p>作为一个管理者，建设一个学习型的团队是其工作内容的一部分，针对研发团队如何建设呢？通常的做法是：指定一个负责人，让其组织团队的成员轮流在固定的时间固定的场所给大家分享他的知识和经验，比如读书笔记，设计的方案，线上遇到的问题……。既然有现成的模型可以照搬，那对于我们这样执行力强的团队来说，说干就干，于是我们制定了一个规则：每周四晚上七点半大家轮流进行分享。一周一次，轮流分享，团队的人也比较多，一年下来一个人也分享不了几次，从明面上看，这个任务完成的难度不是很大，负责人也是拍着那坚实的胸脯信心满满。</p><p>半年后的一天负责人突然说：不行了，分享搞不下去了，首先是没有子弹了（没有可以分享的内容了），库存已搬空；其实是参与学习的人也没激情了，很多时候参加的人数都少于5个人，既没有想分享的人，也没有想学习的人。问了下不参加的理由，有要紧急发版的，有要配合测试的，都有各自的说法。</p><p>如何解决没有子弹的问题？我们决定换一种分享模式试试，于是我们又组织了读书会，大家一段时间内一起阅读同一本书，一个月分享一次读书心得，分享的形式就是口述，这非常轻量化了，我们想这样大家应该能坚持下去吧。事实证明我们还是太天真，这次比上次的分享会坚持的时间还要短，就搞了几期然后就悄无声息的结束了。</p><p>在我们遇到OKR之后，形势反转了，我们把“营造快乐进取的学习型团队氛围”作为一个目标来跟踪，每个季度制定不同的KR来支撑O的达成。在这种方式下，我们将原来的指派式转变为主动报名，同时OKR的目标牵引又能够让负责人专注于目标的执行和达成，学习的氛围发生了180°的大逆转，教与学变成了水到渠成的事情，很多新的思路和创意也在碰撞中产生。快闪分享、技术沙龙、源码领读、算法专题、读书会、好文分享等是中心内技术学习的专题活动，形式多样丰富，为中心内成员搭建学习交流平台。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/555f9be2e785a058dac1316474a51e57.png"></p><p>（读书会分享：《价值》读书心得）</p><h2 id="3-5持续的内部创新"><a href="#3-5持续的内部创新" class="headerlink" title="3.5持续的内部创新"></a>3.5持续的内部创新</h2><p>当今世界，新技术、新产品、新服务、新模式层出不穷，传统商业模式面临颠覆性的挑战，创新是企业的灵魂，创新是企业发展的不竭动力，对于手机行业公司来说，创新将显得更为重要。对我们团队而言创新主要体现在新能力和新项目的孵化。</p><p>我们首先是通过OKR的目标牵引和激励策略，来培育创新土壤，鼓励创新。众所周知，一个创意从诞生到落地，最大到难关是开始行动，99%的创意在行动之前就被自我扼杀了。所以我们需要建立鼓励创新、包容失败的氛围，降低员工踏出第一步的难度。</p><p>其次是聚焦创新目标，跟踪创新过程。通过持续的激励，让员工能够有足够的动力去长期投入创新目标的完成；通过阶段性的对齐，让团队能够了解目前的进展和瓶颈，利用群体智慧来共同解决困难。以此来呵护创新萌芽的成长壮大。</p><p>最后是关注创新结果，保持正向激励。因为创新这一目标，本身就是极具挑战和不确定性的，因此总结和复盘时，我们并不追求此OKR的完成度，而是以目标是否有价值、是否具备挑战性、员工是否付出足够的努力为衡量标准，即使最终这个KR没有完成，也并不影响到员工的绩效考核。在这样的理念下，保证了创新氛围的可信和持续，让创新变成一件水到渠成的事情。</p><p>三年来，在围绕着创新制定目标的牵引下，中心已经成功孵化出了6个组件和12个服务，在公司内部累计已经超过千余个系统使用，并且我们也在开源上面做探索，让这些组件和服务能为更多的人服务。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/360f8628e9997941686bbc0e7a82cb17.png"></p><p>通过OKR实践，我们扭转了曾经“畏惧犯错，不敢失败，不敢试错”的氛围，打造“乐于创新，敢于突破，勇于挑战”的文化。</p><h2 id="3-6-员工生产力提升"><a href="#3-6-员工生产力提升" class="headerlink" title="3.6 员工生产力提升"></a>3.6 员工生产力提升</h2><p>员工生产力的提升可以说是执行OKR科学管理的必然结果。OKR执行的一个特点：自下而上，即自主，是内在动机的一个基本心理需求。OKR理念强调在目标设定时，要有相当一部分目标是员工自己提出来的，而不是上级指派的。只有这样，员工才会感知到目标是自己的目标，不是他人强加给自己的目标，从而显著增强对目标的承诺感，最终带来员工生产力的提升。</p><p>海外商城的建设就是一个很好的案例。最初海外只有印度市场提出建设官方商城的需求，我们只需将内销商城系统复制一套，并部署到印度当地即可，这种方法简单高效，但是我们并未止步于此，当时我们预见到，海外其它市场需求也必将接踵而至，为了能够快速应对未来全球化业务的发展，我们做了充分的竞品分析、技术调研、架构设计、脑暴碰撞，经过一段时间的摸索和打磨，我们打造出了一套通用的全球化解决方案，包括多语言文案系统、多时区通用组件、多国家隔离框架、多机房域名部署方案等等，一套系统可满足多地区多品牌的需求，极大地提升了人效，在业务需求真正到来之时，可最快7天部署一套新商城。这些能力较好的支撑了商城当前业务的发展需要，同时赋能其它外销业务解决相关难题，多语言平台还一举获得公司级设计驱动奖。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/babd2223d926143ebfe0957ed6910080.png"></p><p>海外能力的建设，从设想到确立目标到落地，是员工自发自主自下而上去完成的，科技时代需要技术创新力，知识工作者需要突破既有经验和惯性束缚，OKR科学的管理机制给与了员工更大的发挥空间，生产力提升水到渠成。</p><h1 id="四、小结"><a href="#四、小结" class="headerlink" title="四、小结"></a>四、小结</h1><p>本章给大家讲述了我们在引入OKR之后发生的六点明显变化，这些变化既是因也是果，它们互相形成了一个良性循环的飞轮，朝着我们的愿景：“持续成长为行业一流的技术团队，并打造出了一支自组织、高绩效的标杆团队”不断前进。</p><p>如果你也想让你的团队有所改变，想更深入的了解OKR是怎么样一步一步的改变我们的，想进一步了解我们执行OKR的核心理念，想了解我们团队有哪些管理理念，那么这就是一本专门为你所写的系列文章。希望我们的团队一路走过来的经验，能为你打开一扇窗，让你有所启发，对你的团队管理有所帮助。</p><p>后续我们将会就以下话题和大家一起分享：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/594fd81198ad489a6443a714d1213152.png"></p><p>OKR给我们带来了很多改变，你们团队有引入OKR吗？为什么要引入OKR？它又给你们带来哪些改变呢？</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;平台产品研发团队 vivo互联网技术 2022-11-02&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/NLxg-4JUx-F-0NwPfO1qIw&quot;&gt;https://mp.weixin.qq.com/s/NLxg-4JUx-F-0</summary>
      
    
    
    
    <category term="OKR" scheme="http://zhangyu.info/categories/OKR/"/>
    
    
    <category term="OKR" scheme="http://zhangyu.info/tags/OKR/"/>
    
  </entry>
  
  <entry>
    <title>redis的大Key对持久化有什么影响</title>
    <link href="http://zhangyu.info/2022/10/26/redis%E7%9A%84%E5%A4%A7Key%E5%AF%B9%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%89%E4%BB%80%E4%B9%88%E5%BD%B1%E5%93%8D/"/>
    <id>http://zhangyu.info/2022/10/26/redis%E7%9A%84%E5%A4%A7Key%E5%AF%B9%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%89%E4%BB%80%E4%B9%88%E5%BD%B1%E5%93%8D/</id>
    <published>2022-10-25T16:00:00.000Z</published>
    <updated>2022-10-26T14:59:49.350Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/qq_34827674/article/details/126829220">https://blog.csdn.net/qq_34827674/article/details/126829220</a></p><p><a href="https://blog.csdn.net/qq_34827674/article/details/126829220">Redis 的大 Key 对持久化有什么影响？_小林coding的博客-CSDN博客_大key对redis的影响</a></p><blockquote><p>Redis 的持久化方式有两种：AOF 日志和 RDB <a href="https://so.csdn.net/so/search?q=%E5%BF%AB%E7%85%A7&spm=1001.2101.3001.7020">快照</a>。</p><p>所以接下来，针对这两种持久化方式具体分析分析。</p><h2 id="大-Key-对-AOF-日志的影响"><a href="#大-Key-对-AOF-日志的影响" class="headerlink" title="大 Key 对 AOF 日志的影响"></a>大 Key 对 AOF 日志的影响</h2><blockquote><p>先说说 AOF 日志三种写回磁盘的策略</p></blockquote><p>Redis 提供了 3 种 AOF 日志写回硬盘的策略，分别是：</p><ul><li>  Always，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；</li><li>  Everysec，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；</li><li>  No，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。</li></ul><p>这三种策略只是在控制 fsync() 函数的调用时机。</p><p>当应用程序向文件写入数据时，内核通常先将数据复制到内核缓冲区中，然后排入队列，然后由内核决定何时写入硬盘。</p><p><img src="https://img-blog.csdnimg.cn/def7d5328829470c9f3cfd15bbcc6814.png"></p><p>如果想要应用程序向文件写入数据后，能立马将数据同步到硬盘，就可以调用 fsync() 函数，这样内核就会将内核缓冲区的数据直接写入到硬盘，等到硬盘写操作完成后，该函数才会返回。</p><ul><li>  Always 策略就是每次写入 AOF 文件数据后，就执行 fsync() 函数；</li><li>  Everysec 策略就会创建一个异步任务来执行 fsync() 函数；</li><li>  No 策略就是永不执行 fsync() 函数;</li></ul><blockquote><p>分别说说这三种策略，在持久化大 Key 的时候，会影响什么？</p></blockquote><p>在使用 Always 策略的时候，主线程在执行完命令后，会把数据写入到 AOF 日志文件，然后会调用 fsync() 函数，将内核缓冲区的数据直接写入到硬盘，等到硬盘写操作完成后，该函数才会返回。</p><p><strong>当使用 Always 策略的时候，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的</strong>。</p><p>当使用 Everysec 策略的时候，由于是异步执行 fsync() 函数，所以大 Key 持久化的过程（数据同步磁盘）不会影响主线程。</p><p>当使用 No 策略的时候，由于永不执行 fsync() 函数，所以大 Key 持久化的过程不会影响主线程。</p><h2 id="大-Key-对-AOF-重写和-RDB-的影响"><a href="#大-Key-对-AOF-重写和-RDB-的影响" class="headerlink" title="大 Key 对 AOF 重写和 RDB 的影响"></a>大 Key 对 AOF 重写和 RDB 的影响</h2><p>当 AOF 日志写入了很多的大 Key，AOF 日志文件的大小会很大，那么很快就会触发 <strong>AOF 重写机制</strong>。</p><p>AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 <code>fork()</code> 函数创建一个子进程来处理任务。</p><p>在创建子进程的过程中，操作系统会把父进程的「<a href="https://so.csdn.net/so/search?q=%E9%A1%B5%E8%A1%A8&spm=1001.2101.3001.7020">页表</a>」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。</p><p><img src="https://img-blog.csdnimg.cn/06657cb93ffa4a24b8fc5b3069cb29bf.png"><br>这样一来，子进程就共享了父进程的物理内存数据了，这样能够节约物理内存资源，页表对应的页表项的属性会标记该物理内存的权限为<strong>只读</strong>。</p><p>随着 Redis 存在越来越多的大 Key，那么 Redis 就会占用很多内存，对应的页表就会越大。</p><p>在通过 <code>fork()</code> 函数创建子进程的时候，虽然不会复制父进程的物理内存，但是<strong>内核会把父进程的页表复制一份给子进程，如果页表很大，那么这个复制过程是会很耗时的，那么在执行 fork 函数的时候就会发生阻塞现象</strong>。</p><p>而且，fork 函数是由 Redis 主线程调用的，如果 fork 函数发生阻塞，那么意味着就会阻塞 Redis 主线程。由于 Redis 执行命令是在主线程处理的，所以当 Redis 主线程发生阻塞，就无法处理后续客户端发来的命令。</p><p>我们可以执行 <code>info</code> 命令获取到 latest_fork_usec 指标，表示 Redis 最近一次 fork 操作耗时。</p><pre><code># 最近一次 fork 操作耗时latest_fork_usec:315</code></pre><p>如果 fork 耗时很大，比如超过1秒，则需要做出优化调整：</p><ul><li>  单个实例的内存占用控制在 10 GB 以下，这样 fork 函数就能很快返回。</li><li>  如果 Redis 只是当作纯缓存使用，不关心 Redis 数据安全性问题，可以考虑关闭 AOF 和 AOF 重写，这样就不会调用 fork 函数了。</li><li>  在主从架构中，要适当调大 repl-backlog-size，避免因为 repl_backlog_buffer 不够大，导致主节点频繁地使用全量同步的方式，全量同步的时候，是会创建 RDB 文件的，也就是会调用 fork 函数。</li></ul><blockquote><p>那什么时候会发生物理内存的复制呢？</p></blockquote><p>当父进程或者子进程在向共享内存发起写操作时，CPU 就会触发<strong>缺页中断</strong>，这个缺页中断是由于违反权限导致的，然后操作系统会在「缺页异常处理函数」里进行物理内存的复制，并重新设置其内存映射关系，将父子进程的内存读写权限设置为可读写，最后才会对内存进行写操作，这个过程被称为「**写时复制(Copy On Write)**」。</p><p><img src="https://img-blog.csdnimg.cn/451024fe10374431aff6f93a8fed4638.png"></p><p>写时复制顾名思义，在发生写操作的时候，操作系统才会去复制物理内存，这样是为了防止 fork 创建子进程时，由于物理内存数据的复制时间过长而导致父进程长时间阻塞的问题。</p><p>如果创建完子进程后，<strong>父进程对共享内存中的大 Key 进行了修改，那么内核就会发生写时复制，会把物理内存复制一份，由于大 Key 占用的物理内存是比较大的，那么在复制物理内存这一过程中，也是比较耗时的，于是父进程（主线程）就会发生阻塞</strong>。</p><p>所以，有两个阶段会导致阻塞父进程：</p><ul><li>  创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；</li><li>  创建完子进程后，如果子进程或者父进程修改了共享数据，就会发生写时复制，这期间会拷贝物理内存，如果内存越大，自然阻塞的时间也越长；</li></ul><p>这里额外提一下， 如果 <strong>Linux 开启了内存大页，会影响 Redis 的性能的</strong>。</p><p>Linux 内核从 2.6.38 开始支持内存大页机制，该机制支持 2MB 大小的内存页分配，而常规的内存页分配是按 4KB 的粒度来执行的。</p><p>如果采用了内存大页，那么即使客户端请求只修改 100B 的数据，在发生写时复制后，Redis 也需要拷贝 2MB 的大页。相反，如果是常规内存页机制，只用拷贝 4KB。</p><p>两者相比，你可以看到，每次写命令引起的<strong>复制内存页单位放大了 512 倍，会拖慢写操作的执行时间，最终导致 Redis 性能变慢</strong>。</p><p>那该怎么办呢？很简单，关闭内存大页（默认是关闭的）。</p><p>禁用方法如下：</p><pre><code>echo never &gt;  /sys/kernel/mm/transparent_hugepage/enabled</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>当 AOF 写回策略配置了 Always 策略，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的。</p><p>AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 <code>fork()</code> 函数创建一个子进程来处理任务。会有两个阶段会导致阻塞父进程（主线程）：</p><ul><li>  创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；</li><li>  创建完子进程后，如果父进程修改了共享数据中的大 Key，就会发生写时复制，这期间会拷贝物理内存，由于大 Key 占用的物理内存会很大，那么在复制物理内存这一过程，就会比较耗时，所以有可能会阻塞父进程。</li></ul><p>大 key 除了会影响持久化之外，还会有以下的影响。</p><ul><li><p>  客户端超时阻塞。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</p></li><li><p>  引发网络阻塞。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</p></li><li><p>  阻塞工作线程。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</p></li><li><p>  内存分布不均。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。</p></li></ul><p>如何避免大 Key 呢？</p><p>最好在设计阶段，就把大 key 拆分成一个一个小 key。或者，定时检查 Redis 是否存在大 key ，如果该大 key 是可以删除的，不要使用 DEL 命令删除，因为该命令删除过程会阻塞主线程，而是用 unlink 命令（Redis 4.0+）删除大 key，因为该命令的删除过程是异步的，不会阻塞主线程。</p><p>完！</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/qq_34827674/article/details/126829220&quot;&gt;https://blog.csdn.net/qq_34827674/article/details/126829220&lt;/a&gt;&lt;/p&gt;</summary>
      
    
    
    
    <category term="redis" scheme="http://zhangyu.info/categories/redis/"/>
    
    
    <category term="redis" scheme="http://zhangyu.info/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis的常见使用场景</title>
    <link href="http://zhangyu.info/2022/10/26/redis%E7%9A%84%E5%B8%B8%E8%A7%81%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/"/>
    <id>http://zhangyu.info/2022/10/26/redis%E7%9A%84%E5%B8%B8%E8%A7%81%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/</id>
    <published>2022-10-25T16:00:00.000Z</published>
    <updated>2022-10-26T15:19:01.932Z</updated>
    
    <content type="html"><![CDATA[<p> <a href="https://blog.csdn.net/Number_oneEngineer/article/details/123229706">https://blog.csdn.net/Number_oneEngineer/article/details/123229706</a><br><a href="https://blog.csdn.net/agonie201218/article/details/123640871">https://blog.csdn.net/agonie201218/article/details/123640871</a></p><blockquote><h2 id="1-缓存"><a href="#1-缓存" class="headerlink" title="1. 缓存"></a>1. 缓存</h2><p>作为<code>Key-Value</code>形态的内存数据库，Redis 最先会被想到的应用场景便是作为数据缓存。而使用 Redis 缓存数据非常简单，只需要通过<code>string</code>类型将序列化后的对象存起来即可，不过也有一些需要注意的地方：</p><ul><li><p>  必须保证不同对象的 key 不会重复，并且使 key 尽量短，一般使用类名（表名）加主键拼接而成。</p></li><li><p>  选择一个优秀的序列化方式也很重要，目的是提高序列化的效率和减少内存占用。</p></li><li><p>缓存内容与数据库的一致性，这里一般有两种做法：</p><ol><li> 只在数据库查询后将对象放入缓存，如果对象发生了修改或删除操作，直接清除对应缓存（或设为过期）。</li><li> 在数据库新增和查询后将对象放入缓存，修改后更新缓存，删除后清除对应缓存（或设为过期）。</li></ol></li></ul><p>String类型</p><p>例如：热点数据缓存（例如报表、明星出轨），对象缓存、全页缓存、可以提升热点数据的访问数据。</p><h2 id="2-数据共享分布式"><a href="#2-数据共享分布式" class="headerlink" title="2. 数据共享分布式"></a>2. 数据共享分布式</h2><p>String 类型，因为 Redis 是分布式的独立服务，可以在多个应用之间共享</p><p>例如：分布式Session</p><pre><code>&lt;dependency&gt;  &lt;groupId&gt;org.springframework.session&lt;/groupId&gt;  &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; &lt;/dependency&gt;</code></pre><h2 id="3、分布式锁"><a href="#3、分布式锁" class="headerlink" title="3、分布式锁"></a>3、分布式锁</h2><p>如今都是分布式的环境下java自带的单体锁已经不适用的。在 Redis 2.6.12 版本开始，<code>string</code>的<code>set</code>命令增加了一些参数：</p><ul><li><p>  <code>EX</code>：设置键的过期时间（单位为秒）</p></li><li><p>  <code>PX</code>：设置键的过期时间（单位为毫秒）</p></li><li><p>  <code>NX</code> ：只在键不存在时，才对键进行设置操作。 <code>SET key value NX</code> 效果等同于 <code>SETNX key value</code> 。</p></li><li><p>  <code>XX</code> ：只在键已经存在时，才对键进行设置操作。</p></li></ul><p>由于这个操作是原子性的，可以简单地以此实现一个分布式的锁，例如：</p><pre><code>　　set lock_key locked NX EX 1 </code></pre><p>如果这个操作返回<code>false</code>，说明 key 的添加不成功，也就是当前有人在占用这把锁。而如果返回<code>true</code>，则说明得了锁，便可以继续进行操作，并且在操作后通过<code>del</code>命令释放掉锁。并且即使程序因为某些原因并没有释放锁，由于设置了过期时间，该锁也会在 1 秒后自动释放，不会影响到其他程序的运行。<br>　　<br>推荐使用 redisson 第三方库实现分布式锁。<br>参考 <a href="https://blog.csdn.net/agonie201218/article/details/122084140">java分布式锁终极解决方案之 redisson</a><br>String 类型setnx方法，只有不存在时才能添加成功，返回true</p><pre><code>public static boolean getLock(String key) &#123;    Long flag = jedis.setnx(key, &quot;1&quot;);    if (flag == 1) &#123;        jedis.expire(key, 10);    &#125;    return flag == 1;&#125;public static void releaseLock(String key) &#123;    jedis.del(key);&#125;</code></pre><h2 id="4、全局ID"><a href="#4、全局ID" class="headerlink" title="4、全局ID"></a>4、全局ID</h2><p>int类型，incrby，利用原子性</p><p><code>incrby userid 1000</code></p><p>分库分表的场景，一次性拿一段</p><h2 id="5、计数器"><a href="#5、计数器" class="headerlink" title="5、计数器"></a>5、计数器</h2><p>int类型，incr方法</p><p>例如：文章的阅读量、微博点赞数、允许一定的延迟，先写入Redis再定时同步到数据库</p><p>计数功能应该是最适合 Redis 的使用场景之一了，因为它高频率读写的特征可以完全发挥 Redis 作为内存数据库的高效。在 Redis 的<a href="https://so.csdn.net/so/search?q=%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84&spm=1001.2101.3001.7020">数据结构</a>中，<code>string</code>、<code>hash</code>和<code>sorted set</code>都提供了<code>incr</code>方法用于原子性的自增操作，下面举例说明一下它们各自的使用场景：</p><ul><li>  如果应用需要显示每天的注册用户数，便可以使用<code>string</code>作为计数器，设定一个名为<code>REGISTERED_COUNT_TODAY</code>的 key，并在初始化时给它设置一个到凌晨 0 点的过期时间，每当用户注册成功后便使用<code>incr</code>命令使该 key 增长 1，同时当每天凌晨 0 点后，这个计数器都会因为 key 过期使值清零。</li><li>  每条微博都有点赞数、评论数、转发数和浏览数四条属性，这时用<code>hash</code>进行计数会更好，将该计数器的 key 设为<code>weibo:weibo_id</code>，<code>hash</code>的 field 为<code>like_number</code>、<code>comment_number</code>、<code>forward_number</code>和<code>view_number</code>，在对应操作后通过<code>hincrby</code>使<code>hash 中</code>的 field 自增。</li><li>  如果应用有一个发帖排行榜的功能，便选择<code>sorted set</code>吧，将集合的 key 设为<code>POST_RANK</code>。当用户发帖后，使用<code>zincrby</code>将该用户 id 的 score 增长 1。<code>sorted set</code>会重新进行排序，用户所在排行榜的位置也就会得到实时的更新。</li></ul><h2 id="6、限流"><a href="#6、限流" class="headerlink" title="6、限流"></a>6、限流</h2><p>int类型，incr方法</p><p>以访问者的ip和其他信息作为key，访问一次增加一次计数，超过次数则返回false</p><h2 id="7、位统计"><a href="#7、位统计" class="headerlink" title="7、位统计"></a>7、位统计</h2><p>String类型的bitcount（1.6.6的bitmap数据结构介绍）</p><p>字符是以8位二进制存储的</p><pre><code>set k1 asetbit k1 6 1setbit k1 7 0get k1 /* 6 7 代表的a的二进制位的修改a 对应的ASCII码是97，转换为二进制数据是01100001b 对应的ASCII码是98，转换为二进制数据是01100010因为bit非常节省空间（1 MB=8388608 bit），可以用来做大数据量的统计。*/</code></pre><p>例如：在线用户统计，留存用户统计</p><pre><code>setbit onlineusers 01 setbit onlineusers 11 setbit onlineusers 20</code></pre><p>支持按位与、按位或等等操作</p><pre><code>BITOPANDdestkeykey[key...] ，对一个或多个 key 求逻辑并，并将结果保存到 destkey 。       BITOPORdestkeykey[key...] ，对一个或多个 key 求逻辑或，并将结果保存到 destkey 。 BITOPXORdestkeykey[key...] ，对一个或多个 key 求逻辑异或，并将结果保存到 destkey 。 BITOPNOTdestkeykey ，对给定 key 求逻辑非，并将结果保存到 destkey 。</code></pre><p>计算出7天都在线的用户</p><pre><code>BITOP &quot;AND&quot; &quot;7_days_both_online_users&quot; &quot;day_1_online_users&quot; &quot;day_2_online_users&quot; ...  &quot;day_7_online_users&quot;</code></pre><p>参考 <a href="https://blog.csdn.net/agonie201218/article/details/107161106">使用Redis的bitmaps统计用户留存率、活跃用户</a></p><p><a href="https://blog.csdn.net/agonie201218/article/details/108988577">用户日活月活怎么统计 - Redis HyperLogLog 详解</a></p><h2 id="8-时间轴（Timeline）"><a href="#8-时间轴（Timeline）" class="headerlink" title="8. 时间轴（Timeline）"></a>8. 时间轴（Timeline）</h2><p> <code>list</code>作为双向链表，不光可以作为队列使用。如果将它用作栈便可以成为一个公用的时间轴。当用户发完微博后，都通过<code>lpush</code>将它存放在一个 key 为<code>LATEST_WEIBO</code>的<code>list</code>中，之后便可以通过<code>lrange</code>取出当前最新的微博。</p><h2 id="9-消息队列"><a href="#9-消息队列" class="headerlink" title="9. 消息队列"></a>9. 消息队列</h2><p>Redis 中<code>list</code>的数据结构实现是双向链表，所以可以非常便捷的应用于消息队列（生产者 / 消费者模型）。消息的生产者只需要通过<code>lpush</code>将消息放入 list，消费者便可以通过<code>rpop</code>取出该消息，并且可以保证消息的有序性。如果需要实现带有优先级的消息队列也可以选择<code>sorted set</code>。而<code>pub/sub</code>功能也可以用作发布者 / 订阅者模型的消息。无论使用何种方式，由于 Redis 拥有持久化功能，也不需要担心由于服务器故障导致消息丢失的情况。</p><p>List提供了两个阻塞的弹出操作：blpop/brpop，可以设置超时时间</p><ul><li>  blpop：blpop key1 timeout 移除并获取列表的第一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。</li><li>  brpop：brpop key1 timeout 移除并获取列表的最后一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。</li></ul><p>上面的操作。其实就是java的阻塞队列。学习的东西越多。学习成本越低</p><ul><li>  队列：先进先除：rpush blpop，左头右尾，右边进入队列，左边出队列</li><li>  栈：先进后出：rpush brpop</li></ul><h3 id="10、抽奖"><a href="#10、抽奖" class="headerlink" title="10、抽奖"></a>10、抽奖</h3><p>利用set结构的无序性,通过 Spop（ Redis Spop 命令用于移除<a href="https://so.csdn.net/so/search?q=%E9%9B%86%E5%90%88&spm=1001.2101.3001.7020">集合</a>中的指定 key 的一个或多个随机元素，移除后会返回移除的元素。 ） 随机获得值</p><pre><code>redis&gt; SADD myset &quot;one&quot;(integer) 1redis&gt; SADD myset &quot;two&quot;(integer) 1redis&gt; SADD myset &quot;three&quot;(integer) 1redis&gt; SPOP myset&quot;one&quot;redis&gt; SMEMBERS myset1) &quot;three&quot;2) &quot;two&quot;redis&gt; SADD myset &quot;four&quot;(integer) 1redis&gt; SADD myset &quot;five&quot;(integer) 1redis&gt; SPOP myset 31) &quot;five&quot;2) &quot;four&quot;3) &quot;two&quot;redis&gt; SMEMBERS myset1) &quot;three&quot;redis&gt; </code></pre><h2 id="11、点赞、签到、打卡"><a href="#11、点赞、签到、打卡" class="headerlink" title="11、点赞、签到、打卡"></a>11、点赞、签到、打卡</h2><p><img src="https://img-blog.csdnimg.cn/img_convert/201157552a906cdee10942c9e3acc2c3.png" alt="图片"></p><p>假如上面的微博ID是t1001，用户ID是u3001</p><p>用 like:t1001 来维护 t1001 这条微博的所有点赞用户</p><ul><li>  点赞了这条微博：sadd like:t1001 u3001</li><li>  取消点赞：srem like:t1001 u3001</li><li>  是否点赞：sismember like:t1001 u3001</li><li>  点赞的所有用户：smembers like:t1001</li><li>  点赞数：scard like:t1001</li></ul><p>是不是比数据库简单多了。</p><h2 id="12-商品标签"><a href="#12-商品标签" class="headerlink" title="12 商品标签"></a>12 商品标签</h2><p><img src="https://img-blog.csdnimg.cn/img_convert/c3af93df9d330c0c490667e497a6846e.png" alt="图片"></p><p>老规矩，用 tags:i5001 来维护商品所有的标签。</p><ul><li>  sadd tags:i5001 画面清晰细腻</li><li>  sadd tags:i5001 真彩清晰显示屏</li><li>  sadd tags:i5001 流程至极</li></ul><h3 id="13、好友关系、用户关注、推荐模型"><a href="#13、好友关系、用户关注、推荐模型" class="headerlink" title="13、好友关系、用户关注、推荐模型"></a>13、好友关系、用户关注、推荐模型</h3><p>这个场景最开始是是一篇介绍微博 Redis 应用的 PPT 中看到的，其中提到微博的 Redis 主要是用在在计数和好友关系两方面上，当时对好友关系方面的用法不太了解，后来看到《Redis 设计与实现》中介绍到作者最开始去使用 Redis 便是希望能通过<code>set</code>解决传统数据库无法快速计算集合中交集这个功能。后来联想到微博当前的业务场景，确实能够以这种方式实现，所以姑且猜测一下：</p><p>对于一个用户 A，将它的关注和粉丝的用户 id 都存放在两个 set 中：</p><ul><li><p>  <code>A:follow</code>：存放 A 所有关注的用户 id</p></li><li><p><code>A:follower</code>：存放 A 所有粉丝的用户 id</p><p>  那么通过<code>sinter</code>命令便可以根据<code>A:follow</code>和<code>A:follower</code>的交集得到与 A 互相关注的用户。当 A 进入另一个用户 B 的主页后，<code>A:follow</code>和<code>B:follow</code>的交集便是 A 和 B 的共同专注，<code>A:follow</code>和<code>B:follower</code>的交集便是 A 关注的人也关注了 B。</p></li></ul><h3 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h3><p>follow 关注 fans 粉丝</p><p>相互关注：</p><ul><li>  sadd 1:follow 2</li><li>  sadd 2:fans 1</li><li>  sadd 1:fans 2</li><li>  sadd 2:follow 1</li></ul><p>我关注的人也关注了他(取交集)：</p><ul><li>  sinter 1:follow 2:fans</li></ul><p>可能认识的人：</p><ul><li>  用户1可能认识的人(差集)：sdiff 2:follow 1:follow</li><li>  用户2可能认识的人：sdiff 1:follow 2:follow</li></ul><h2 id="14-排行榜"><a href="#14-排行榜" class="headerlink" title="14 .排行榜"></a>14 .排行榜</h2><p>使用<code>sorted set</code>(有序set)和一个计算热度的算法便可以轻松打造一个热度排行榜，<code>zrevrangebyscore</code>可以得到以分数倒序排列的序列，<code>zrank</code>可以得到一个成员在该排行榜的位置（是分数正序排列时的位置，如果要获取倒序排列时的位置需要用<code>zcard</code>-<code>zrank</code>）。</p><p>id 为6001 的新闻点击数加1：</p><pre><code>zincrby hotNews:20190926 1 n6001</code></pre><p>获取今天点击最多的15条：</p><pre><code>zrevrange hotNews:20190926 0 15 withscores</code></pre><h3 id="15-倒排索引"><a href="#15-倒排索引" class="headerlink" title="15 .倒排索引"></a>15 .倒排索引</h3><p>倒排索引是构造搜索功能的最常见方式，在 Redis 中也可以通过<code>set</code>进行建立倒排索引，这里以简单的拼音 + 前缀搜索城市功能举例：</p><p>假设一个城市<code>北京</code>，通过拼音词库将<code>北京</code>转为<code>beijing</code>，再通过前缀分词将这两个词分为若干个前缀索引，有：<code>北</code>、<code>北京</code>、<code>b</code>、<code>be</code>…<code>beijin</code>和<code>beijing</code>。将这些索引分别作为<code>set</code>的 key（例如:<code>index:北</code>）并存储<code>北京</code>的 id，倒排索引便建立好了。接下来只需要在搜索时通过关键词取出对应的<code>set</code>并得到其中的 id 即可。</p><h2 id="16-显示最新的项目列表"><a href="#16-显示最新的项目列表" class="headerlink" title="16 .显示最新的项目列表"></a><strong>16 .显示最新的项目列表</strong></h2><p>比如说，我们的一个Web应用想要列出用户贴出的最新20条评论。在最新的评论边上我们有一个“显示全部”的链接，点击后就可以获得更多的评论。</p><p>每次新评论发表时，我们会将它的ID添加到一个Redis列表。可以限定列表的长度为5000</p><p>LPUSH latest.comments</p><p>在Redis中我们的最新ID使用了常驻缓存，这是一直更新的。但是我们做了限制不能超过5000个ID，因此我们的获取ID函数会一直询问Redis。只有在超出了这个范围的时候，才需要去访问数据库。</p><h1 id="17、购物车"><a href="#17、购物车" class="headerlink" title="17、购物车"></a>17、购物车</h1><p>String 或hash。所有String可以做的hash都可以做</p><p><img src="https://img-blog.csdnimg.cn/bf8b92966ab448d88c48f0b45a262e0c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5oiR5Lus5LiA6LW35Y675aSn5Y6C,size_9,color_FFFFFF,t_70,g_se,x_16" alt="图片"></p><ul><li>  key：用户id；field：商品id；value：商品数量。</li><li>  +1：hincr。-1：hdecr。删除：hdel。全选：hgetall。商品数：hlen。</li></ul><h1 id="18、商品筛选"><a href="#18、商品筛选" class="headerlink" title="18、商品筛选"></a>18、商品筛选</h1><pre><code>// 获取差集sdiff set1 set2// 获取交集（intersection ）sinter set1 set2// 获取并集sunion set1 set2</code></pre><p><img src="https://img-blog.csdnimg.cn/d8db8ebb604848bca9646dac0a21859c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5oiR5Lus5LiA6LW35Y675aSn5Y6C,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><p>假如：iPhone11 上市了</p><pre><code>sadd brand:apple iPhone11sadd brand:ios iPhone11sad screensize:6.0-6.24 iPhone11sad screentype:lcd iPhone 11</code></pre><p>赛选商品，苹果的、ios的、屏幕在6.0-6.24之间的，屏幕材质是LCD屏幕</p><pre><code>sinter brand:apple brand:ios screensize:6.0-6.24 screentype:lcd</code></pre><h1 id="19、排行榜"><a href="#19、排行榜" class="headerlink" title="19、排行榜"></a>19、排行榜</h1><p>id 为6001 的新闻点击数加1：</p><blockquote><p>zincrby hotNews:20190926 1 n6001</p></blockquote><p>获取今天点击最多的15条：</p><blockquote><p>zrevrange hotNews:20190926 0 15 withscores</p></blockquote><p><img src="https://img-blog.csdnimg.cn/e61eb794e182400da1aa9f84b00e7800.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5oiR5Lus5LiA6LW35Y675aSn5Y6C,size_7,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; &lt;a href=&quot;https://blog.csdn.net/Number_oneEngineer/article/details/123229706&quot;&gt;https://blog.csdn.net/Number_oneEngineer/article/details/12</summary>
      
    
    
    
    <category term="redis" scheme="http://zhangyu.info/categories/redis/"/>
    
    
    <category term="redis" scheme="http://zhangyu.info/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>云原生微服务最佳实践</title>
    <link href="http://zhangyu.info/2022/05/28/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
    <id>http://zhangyu.info/2022/05/28/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</id>
    <published>2022-05-27T16:00:00.000Z</published>
    <updated>2022-05-28T06:20:51.855Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://developer.aliyun.com/article/891714?spm=5176.21213303.J_6704733920.7.22db53c9yXA1Zr&amp;scm=20140722.S_community@@%E6%96%87%E7%AB%A0@@891714._.ID_community@@%E6%96%87%E7%AB%A0@@891714-RL_%E4%BA%91%E5%8E%9F%E7%94%9F%E6%9E%B6%E6%9E%84%E4%B8%8B%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%80%89%E5%9E%8B%E5%92%8C%E6%BC%94%E8%BF%9B-LOC_main-OR_ser-V_2-P0_0">https://developer.aliyun.com/article/891714?spm=5176.21213303.J_6704733920.7.22db53c9yXA1Zr&amp;scm=20140722.S_community%40%40%E6%96%87%E7%AB%A0%40%40891714._.ID_community%40%40%E6%96%87%E7%AB%A0%40%40891714-RL_%E4%BA%91%E5%8E%9F%E7%94%9F%E6%9E%B6%E6%9E%84%E4%B8%8B%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%80%89%E5%9E%8B%E5%92%8C%E6%BC%94%E8%BF%9B-LOC_main-OR_ser-V_2-P0_0</a></p><p>作者：彦林<br>本文整理自阿里云智能高级技术专家彦林的线上直播分享《云原生微服务最佳实践》。视频回放地址：<a href="https://yqh.aliyun.com/live/detail/28454">https://yqh.aliyun.com/live/detail/28454</a></p><p><a href="https://developer.aliyun.com/article/891714?spm=5176.21213303.J_6704733920.7.22db53c9yXA1Zr&scm=20140722.S_community@@%E6%96%87%E7%AB%A0@@891714._.ID_community@@%E6%96%87%E7%AB%A0@@891714-RL_%E4%BA%91%E5%8E%9F%E7%94%9F%E6%9E%B6%E6%9E%84%E4%B8%8B%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%80%89%E5%9E%8B%E5%92%8C%E6%BC%94%E8%BF%9B-LOC_main-OR_ser-V_2-P0_0">云原生架构下的微服务选型和演进-阿里云开发者社区</a></p><blockquote><p>随着云原生的演进，微服务作为主流应用架构被广泛使用，其落地的难题逐步从如何建好延伸到如何用好。今天跟各位小伙伴分享一下我在微服务领域 10 余年的实践经验，如何以更高效的姿势把微服务这件事做扎实。</p><h2 id="阿里微服务发展历程"><a href="#阿里微服务发展历程" class="headerlink" title="阿里微服务发展历程"></a>阿里微服务发展历程</h2><h3 id="微服务-1-0-（1w-实例-微服务拆分-同城容灾）"><a href="#微服务-1-0-（1w-实例-微服务拆分-同城容灾）" class="headerlink" title="微服务 1.0 （1w 实例/微服务拆分/同城容灾）"></a>微服务 1.0 （1w 实例/微服务拆分/同城容灾）</h3><p>2008 年随着阿里业务规模不断增大，单体胖应用+硬负载的架构逐渐暴露性能瓶颈；随着研发人员逐步增多，协调效率也逐步下降，不能满足日益复杂的业务挑战，因此急需技术升级解决这些问题。<br> <img src="https://ucc.alicdn.com/pic/developer-ecology/755e59619c8c46f19ca8886caf9b725b.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650460882673-b82ca6e7-297e-42a4-817d-badbf61b1604.png?x-oss-process=image/resize,w_1165,limit_0"> </p><p>在当时 SOA 架构非常流行，也就成为我们技术演进的主要方向，当时有两种解决方案，一个是 Server Based 的解决方案，这种模式侵入小、方便集中管控，但是这种中心化方案会带来成本高、稳定性风险高、扩展性差；一个是 Client Based 的解决方案，这种模式去中心化，扩展性强，成本低，但是会带来一定侵入性，比较难以管理；当然很多人会问为什么不直接用 DNS 呢？主要是 DNS 不能满足 IDC 内部服务发现实时性，服务列表更新不能及时通知下有业务会导致业务流量损失。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650461250591-19bfb292-1d8d-4f87-918c-9629d5fc7cbd.png?x-oss-process=image/resize,w_1177,limit_0"> </p><p>在评估两种方案利弊之后，我们在网关这种需要集中管理安全和简单路由场景采用了 Server Based 的方案，基于 Nginx 演进出了阿里 Tengine 网关技术体系，从入口处解决安全、高可用、简单路由能力；在 IDC 内部采用了 Client Base 模式，孵化出 HSF/Dubbo+Nacos 技术体系，支撑了业务微服务拆分。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650461729968-5cb9547c-cd5d-4b9f-9399-364b98176bc1.png?x-oss-process=image/resize,w_1188,limit_0"> </p><p>随着第一代微服务架构落地，由于引入注册中心带来了稳定性风险，注册中心挂会导致调用链路全部中断；业务集中发布的时候注册中心压力会比较大。</p><p> <img src="https://ucc.alicdn.com/pic/developer-ecology/25993cdf295a410fa086fb6ff888c54a.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650508584813-db5f3b84-d992-4d65-8ecd-9c681bdcafd8.png?x-oss-process=image/resize,w_1114,limit_0"> </p><p>针对可用性问题我们提供了推空保护能力，即使注册中心挂也不会影响业务正常运行；为了提供更好性能我们提供了全异步架构；为了支持同城容灾我们提供了 AP 一致性协议，具体协议可以参考《Nacos 架构与原理》电子书。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650508698563-3d6d07b7-6003-449f-97aa-3313a3748faa.png?x-oss-process=image/resize,w_937,limit_0"> </p><p>随着阿里微服务 1.0 架构落地，帮助业务完成微服务拆分，解决了扩展性和协同效率问题，同时支撑了阿里同城容灾能力。对于正在做微服务的小伙伴可能问阿里如何做微服务架构演进的：</p><p><strong>前后端分离是第一步</strong>，因为前端变化多，变化快，后端相对变化小，演进慢，因此需要解耦发展，让前端更快的适应市场变化，以便在竞争中保持先机；</p><p><strong>后端无状态改造是第二步，</strong>把内存状态外置到 Redis，把持久化状态外置到 Mysql，这样业务就可以随意进行切分；</p><p><strong>第三步是模块化拆分，</strong>这块是最考验架构师的，因为拆分一个是按照业务属性拆分，一个是按照应用复杂度进行拆分，这个是一个相对动态过程，建议拆分模块后 2-3 人负责一个模块，拆到太细会有比较高的运维成本，拆的太粗又会带来研发协同问题，阿里内部也经历过合久必分，分久必合的几波震荡，最终走到相对稳态。这里值得一提就是 HSF/Dubbo 的一个优势，因为早期采用 SOA 架构思想设计，一个接口就是一个服务，这样其实非常方便服务的拆分和合并，当然同时带来一个问题是对注册中心性能压力比较大，这是一个架构选择和平衡问题。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650462151116-d659464c-9abf-47c1-aea3-ada1738d921e.png?x-oss-process=image/resize,w_1178,limit_0"> </p><h3 id="微服务-2-0（10w-实例-业务中台-异地多活）"><a href="#微服务-2-0（10w-实例-业务中台-异地多活）" class="headerlink" title="微服务 2.0（10w 实例/业务中台/异地多活）"></a>微服务 2.0（10w 实例/业务中台/异地多活）</h3><p>微服务 1.0 架构帮助阿里极大缓解性能和效率问题，但是由于阿里双十一的成功，技术上面临一个洪峰的技术挑战，我们必须在用户体验、资源成本、高可用之间做一个平衡。这个阶段我们最大的挑战是扩展性和稳定性，扩展性是要支撑业务 10w+实例扩容，但是单地资源有限，双十一商家投入的资金越来越大，导致我们双十一当天也不能出严重问题，不然损失非常大，因此对业务稳定性提出非常高的要求。<br> <img src="https://ucc.alicdn.com/pic/developer-ecology/caa299c0e6e84c40ad3a9c70f56303a9.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650462646607-791462f4-595f-4dfd-b16b-457a33ff0972.png?x-oss-process=image/resize,w_937,limit_0"> </p><p>因此阿里演进到微服务 2.0 支撑了异地多活的高可用体系，让阿里业务可以按照 IDC 级别水平扩展，新的机房，新的技术体系都可以在单元中进行验证，也加速了阿里技术体系演进速度。<br> <img src="https://ucc.alicdn.com/pic/developer-ecology/80e28a96536640fea086b733e79b0e69.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650463572269-62635384-a842-42d6-b7b6-5e948f9a57ae.png?x-oss-process=image/resize,w_1188,limit_0"> </p><p>在此期间 Nacos Server 间水平通知压力巨大，业务发布窗口容易把网卡打满，频繁推送会消耗业务大量内存和 CPU，进而影响业务的稳定性。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650508924614-ec9806bf-df64-4e93-b898-48c2350b3e01.png?x-oss-process=image/resize,w_937,limit_0"> </p><p>针对上述问题，我们在 Nacos Server 间做了聚合推送，将一定时间窗的变更合并聚合推送，推送过程中做了压缩推送，从而解决了上述问题。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650508934970-0f10fd5f-038f-4d64-9baa-a1178df0b7a7.png?x-oss-process=image/resize,w_937,limit_0"> </p><p>在微服务解决扩展性和高可用的同时，业务系统变多，重复建设，业务孤岛也越来越多，协同效率也越来越低，因此阿里业务在这个时候推出了业务中台能力，将扁平的微服务抽象分层，将基础服务抽象为中台服务解决上述问题，业务分层后支撑了阿里业务高速增长，也加速了技术架构统一。 <img src="https://ucc.alicdn.com/pic/developer-ecology/a772d2e42c8e4db6bb050c6679da3997.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650463819661-fc69a6f1-fb7e-4b4d-b1c2-f00659a3e49a.png?x-oss-process=image/resize,w_1160,limit_0"> </p><h3 id="微服务-3-0（100w-实例-业务域拆分-云原生）"><a href="#微服务-3-0（100w-实例-业务域拆分-云原生）" class="headerlink" title="微服务 3.0（100w 实例/业务域拆分/云原生）"></a>微服务 3.0（100w 实例/业务域拆分/云原生）</h3><p>微服务 2.0 架构支撑了阿里双十一的技术奇迹，阿里也陆续开启业务扩张，构建更完整的互联网版图。在这个阶段阿里收购了比较多的公司，技术体系不统一如何形成合力；从线上走到线下后，线下系统对系统稳定性要求更高；云计算发展，如何利用好云的弹性做双十一，这个阶段我们也推出了微服务的云产品，期望通过云产品支撑阿里双十一。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650464151858-72dfe7f9-b5bc-42b7-827b-553bdbf9ce89.png?x-oss-process=image/resize,w_937,limit_0"> </p><p>业务域切分比较容易，切完之后如何更好的互联互通是一个关键，因此我们内部推出了 Nacos-sync 和云原生网关两个产品。Nacos-sync 适合业务流量超大，协议一致场景。云原生网关适合网络不通，协议不同，跨 Region 等场景。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650465807802-a2d8f5f6-79a3-4597-b79d-e7f4cadafba9.png?x-oss-process=image/resize,w_1128,limit_0"> </p><p>即使从顶层做了业务域拆分，但是最大的电商集群往百万实例演进过程中对注册中心的压力越来越大，我们把聚合窗口时间不断拉长，推送慢了会导致业务发布时间变长，推送快了会对业务消耗较大，因此陷入了两难境地。</p><p> <img src="https://ucc.alicdn.com/pic/developer-ecology/c32c246c55d2432cb4885199b476ebc4.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650509243198-6fe13d99-5b6d-4e41-9bde-cfc8a59d45ab.png?x-oss-process=image/resize,w_937,limit_0"> </p><p>这个阶段我们进行问题的分解，首先根据服务列表大小做了一个切分，服务列表多的可以推送慢一些问题也不大，服务列表小的需要及时推送，因此我们优化了聚合推送逻辑，根据服务列表大小做了分级推送。还有一个优化思路是变更只有几个列表变化，因此我们提供了增量推送能力，大幅降低服务变更推送数据量。<br> <img src="https://ucc.alicdn.com/pic/developer-ecology/f8db6f13fb54416091568489a31be669.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650509262172-e9fa62ae-463d-425b-9933-806d2a6e4e2d.png?x-oss-process=image/resize,w_1087,limit_0"> </p><p>通过微服务 3.0 架构演进很好的解决了跨域互通和平滑上云的问题，新业务可以先上云，或者部分业务上云，通过网关做云上云下互通等问题，同时支撑了百万实例微服务架构演进。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650465843769-f8d72e1a-68f4-4da3-8f5b-a52690bbf47e.png?x-oss-process=image/resize,w_1158,limit_0"> </p><p> <img src="https://ucc.alicdn.com/pic/developer-ecology/ca0536204d5c4512baa2b0a37345c6fc.gif" alt="image.gif" title="image.gif"> 期望通过我分享阿里微服务发展历程给大家做微服务架构演进提供一些思路和启发。</p><h3 id="云原生微服务趋势"><a href="#云原生微服务趋势" class="headerlink" title="云原生微服务趋势"></a>云原生微服务趋势</h3><p>随着云原生技术演进，容器以不可变基础设施为理念，解决运维标准和资源利用率问题；微服务以可变运行时为理念，解决研发效率问题，提升系统整体扩展性和高可用。经常有人问我，为什么有了容器的服务发现机制，还需要微服务的注册中心呢？从架构上首先是分层的，小的时候确实也看不到明显区别，大一些就会发现问题，如阿里中心最大微服务集群，底层是多个 Kubernetes 集群，防止一个 Kubernetes 出问题影响全局，底层 Kubernetes 也可以水平扩展，如果依赖了 Kubernetes 的服务发现机制，跨 Kubernetes 服务发现就成了第一个问题。当然底层是一个 Kubernetes 上面也可以是多个微服务环境，微服务可以按照业务域切分。两层可以做解耦，自由环境组合。还有就是阿里微服务体系积累了推空保护、服务治理完整体系，而 Kubernetes 的 CoreDNS 将服务发现强制拉到业务调用链路，每次调用都会做域名解析，因此 CoreDNS 挂的时候业务全部中断。</p><p>对于阿里整体正在从百万实例往千万实例的规模演进，这部分也是阿里微服务 4.0 的内容，这部分给大部分公司的借鉴意义有限，因此不做展开。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650466402749-bdc504d9-a794-418a-b894-e6fbab042065.png?x-oss-process=image/resize,w_937,limit_0"> </p><h2 id="微服务最佳实践"><a href="#微服务最佳实践" class="headerlink" title="微服务最佳实践"></a>微服务最佳实践</h2><p>阿里微服务体系经过 10 余年的发展，目前已经通过开源被广泛使用，通过阿里云支撑了成千上万家企业做数字化升级。借此机会把我们的最佳实践总结分享给大家，期望都对大家用好微服务有所帮助。</p><h3 id="阿里微服务体系简介"><a href="#阿里微服务体系简介" class="headerlink" title="阿里微服务体系简介"></a>阿里微服务体系简介</h3><p>通过 MSE + ACK 能够完成第一步云原生技术升级，释放云弹性红利，释放研发效率红利，可以通过可观测和高可用进一步用好微服务体系。</p><p> <img src="https://ucc.alicdn.com/pic/developer-ecology/fba1762c8d8741fb995606b1d9165143.gif" alt="image.gif" title="image.gif"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467432533-a4f4ad8f-3655-4d9c-8d73-4e1ebb10d8a9.png?x-oss-process=image/resize,w_1148,limit_0"> </p><h3 id="微服务最佳实践-1"><a href="#微服务最佳实践-1" class="headerlink" title="微服务最佳实践"></a>微服务最佳实践</h3><p>通过注册&amp;配置中心完成微服务拆分；通过网关统一入口，从入口处解决安全和高可用问题；最后通过服务治理提升用户微服务的问题。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467575338-9a9707a4-40a6-4bbf-9daa-368e995787ae.png?x-oss-process=image/resize,w_961,limit_0"> </p><h3 id="网关最佳实践"><a href="#网关最佳实践" class="headerlink" title="网关最佳实践"></a>网关最佳实践</h3><p>云原生网关作为下一代网关，提供高集成、高可用、高性能、安全的一站式网关解决方案。</p><ul><li>  <strong>统一接入</strong>：将流量网关、 微服务网关、 WAF 三合一大幅降低资源和运维成本，需要强调的是云原生网关集成 WAF 的方案有非常好的性能优势，WAF 做为控制面下发防护规则到云原生网关，流量直接在云原生网关清洗完毕直接路由到后端机器，RT 短，运维成本低。</li><li>  <strong>统一入口安全防线：</strong>自动更新证书防过期，支持 JWT/OAuth2/OIDC/IDaaS 认证机制，支持黑白名单机制。</li><li>  <strong>统一东西南北流量</strong>：统一解决跨域互通问题，包括跨网络域，跨业务域，跨地域，跨安全域等。</li><li>  <strong>统一服务发现机制：</strong>支持 Nacos/Kubernetes/DNS/ 固定 IP 多种服务发现方式。</li><li>  <strong>统一观测平台：</strong>从入口做好 tracing 埋点全链路诊断，丰富业务大盘和告警模板大幅降低网关运维成本。</li><li>  <strong>统一服务治理：</strong>从入口做限流、降级、熔断等高可用能力，提供全链路灰度方案控制变更风险。<strong>统一性能优化：</strong>采用硬件加速性能提升 80%，Ingress 场景比 Nginx 性能高 90%，参数调优+模块优化提升 40%。</li></ul><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467595709-6a151762-5c02-4d8b-90a6-8a289b90aeba.png?x-oss-process=image/resize,w_1151,limit_0"> </p><p>云原生网关支持 WASM 扩展网关自定义功能，并且通过插件市场提供丰富的插件能力。 <img src="https://ucc.alicdn.com/pic/developer-ecology/4c2169fee946427991df5e136e9d481a.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650468450175-eff9c375-9488-4000-820d-fed14a1c3e49.png?x-oss-process=image/resize,w_937,limit_0"> </p><h3 id="服务治理最佳实践"><a href="#服务治理最佳实践" class="headerlink" title="服务治理最佳实践"></a>服务治理最佳实践</h3><p>提供零业务侵入，开发，测试，运维全覆盖服务治理能力，提升系统高可用。如发布阶段即使注册中心是毫秒级推送也会有延迟，这个期间就会导致流量损失，因此我们提供了无损上下线能力解决这个痛点。本月我们将服务治理能力通过 OpenSergo 开源，欢迎各位小伙伴参与共建！  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467610712-ac9fe081-caa4-4fa7-aa61-cabf61532870.png?x-oss-process=image/resize,w_1161,limit_0"> </p><h3 id="日常环境隔离最佳实践"><a href="#日常环境隔离最佳实践" class="headerlink" title="日常环境隔离最佳实践"></a>日常环境隔离最佳实践</h3><p>共享一套环境联调开发相互影响，所有环境都独立联调机器成本太高，这个是一个矛盾，我们通过全链路打标能力将流量隔离，让大家可以在一套环境隔离多个逻辑联调环境，巧妙的解决这个问题。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467627252-58a7dbaa-86ef-45a1-81ff-8d3a43e43af2.png?x-oss-process=image/resize,w_1144,limit_0"> </p><h3 id="配置管理最佳实践"><a href="#配置管理最佳实践" class="headerlink" title="配置管理最佳实践"></a>配置管理最佳实践</h3><p>随着应用规模变大，到每个机器去修改配置运维成本太高，因此需要配置中心统一维护应用配置，将静态业务动态化，动态修改业务运行时行为，提升应用运行时灵活性。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467667752-93728a9e-18e2-41aa-8e60-b421c77fee36.png?x-oss-process=image/resize,w_1164,limit_0"> </p><h3 id="服务网格最佳实践"><a href="#服务网格最佳实践" class="headerlink" title="服务网格最佳实践"></a>服务网格最佳实践</h3><p>对于多语言开发有诉求和对服务网关感兴趣的小伙伴可以通过 MSE+ASM 快速构建服务网格解决方案，完成服务互通，快速体验新的技术。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467681962-8065a419-aa38-4cab-b693-af8e5734d2bd.png?x-oss-process=image/resize,w_1147,limit_0"> </p><h3 id="微服务高可用最佳实践"><a href="#微服务高可用最佳实践" class="headerlink" title="微服务高可用最佳实践"></a>微服务高可用最佳实践</h3><p>随着业务复杂度变高，业务峰值不可测，面对失败的设计和微服务高可用工具使用就非常重要，可以通过 Sentinel 完成限流、降级、熔断的保护，可以通过 PTS 完成压测，可以通过混沌工程完成破坏性测试，从体整体提升系统高可用。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467697257-018ce835-63b2-4909-a051-256c61514a0b.png?x-oss-process=image/resize,w_1150,limit_0"> </p><h3 id="注册中心平滑迁移实践"><a href="#注册中心平滑迁移实践" class="headerlink" title="注册中心平滑迁移实践"></a>注册中心平滑迁移实践</h3><p>目前大规模场景推荐双注册，如 1w 实例以上，这样发布周期长，稳定性更高一些。如果不到 1w 实例可以通过 Nacos-sync 同步完成注册中心平滑前一，这样通用型强一些。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467714583-9e9eae9a-32d5-4258-9424-a014718acbec.png?x-oss-process=image/resize,w_1186,limit_0"> </p><h3 id="网关平衡迁移实践"><a href="#网关平衡迁移实践" class="headerlink" title="网关平衡迁移实践"></a>网关平衡迁移实践</h3><p>由于前面云原生网关三合一和性能优势，大家可以通过入口 DNS 灰度切换到云原生网关。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467728539-22275719-f7b8-43ab-af41-e47adc147c78.png?x-oss-process=image/resize,w_1144,limit_0"> </p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="微服务标杆客户"><a href="#微服务标杆客户" class="headerlink" title="微服务标杆客户"></a>微服务标杆客户</h2><p>用户上云中有两类典型客户，一类是传统的单体胖应用客户，一类是已经采用了微服务需要用好微服务的用户，我们通过两个标杆客户分享一下。</p><h3 id="斯凯奇微服务＋业务中台实践"><a href="#斯凯奇微服务＋业务中台实践" class="headerlink" title="斯凯奇微服务＋业务中台实践"></a>斯凯奇微服务＋业务中台实践</h3><p>斯凯奇 2021 年找到我们做数字化升级时间非常紧急，需要双十一前 3 个月左右要完成数字化升级，采用 MSE 微服务+中台解决方案，斯凯奇借助云原生网关完成了东西南北流量的统一控制，借助南北向云原生网关完成安全认证和入口限流，从入口做好流量防护；借助东西向网关完成了多个业务域的互通，新老系统的互通，1 个月左右完成了整个系统的搭建，1 个月左右完成了整个系统压测和高可用验证，并且最终大促业务非常成功，助力斯凯奇双十一 12 亿营收规模。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467744650-35f4135b-1fe3-49a0-801e-dcfd3c275490.png?x-oss-process=image/resize,w_1166,limit_0"> </p><h3 id="来电微服务全链路灰度最佳实践"><a href="#来电微服务全链路灰度最佳实践" class="headerlink" title="来电微服务全链路灰度最佳实践"></a>来电微服务全链路灰度最佳实践</h3><h4 id="来电的技术挑战"><a href="#来电的技术挑战" class="headerlink" title="来电的技术挑战"></a><strong>来电的技术挑战</strong></h4><p>来电科技的业务场景丰富且系统众多，在技术架构上已完成容器化以及微服务化改造，微服务框架使用的是 Spring Cloud 与 Dubbo。随着近年来的高速发展，充电宝设备节点以及业务量都在快速增加，系统的稳定性面临几点挑战:</p><p>1.在系统服务的发布过程中如何避免业务流量的损失；2.系统缺少简单有效的灰度能力，每次系统发布都存在一定的稳定性风险。MSE 微服务治理提供了开箱即用且无侵入的线上发布稳定性解决方案以及全链路灰度解决方案，帮助来电科技消除发布风险、提升线上稳定性。</p><h4 id="来电全链路灰度最佳实践"><a href="#来电全链路灰度最佳实践" class="headerlink" title="来电全链路灰度最佳实践"></a><strong>来电全链路灰度最佳实践</strong></h4><p>1.来电科技选用 MSE 微服务治理专业版来实现无侵入微服务治理能力，无缝支持市面上近 5 年所有的 Spring Cloud 和 Dubbo 的版本，不用改一行代码，不需要改变业务的现有架构就可以使用，没有绑定。</p><p>2.MSE 微服务治理专业版提供了全链路灰度解决方案帮助来电科技快速落地可灰度、可观测、可回滚的安全生产三板斧能力，满足业务高速发展情况下快速迭代和小心验证的诉求；</p><p>3.MSE 微服务治理的无损上下线能力，对系统服务的全流程进行防护，通过服务预热、无损下线、与 Kubernetes 微服务生命周期对齐、延迟发布等一系列能力，保证在服务冷启动或销毁过程中，业务连续无损。</p><p>4.MSE 微服务治理的离群实例摘除能力，可以做到让服务消费者自动检测其所调用提供者实例的可用性并进行实时的权重动态调整，以保证服务调用的成功率，从而提升业务稳定性和服务质量。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467760065-7aab61b1-4829-4de9-9f6b-8ab9ce978922.png?x-oss-process=image/resize,w_1160,limit_0"> </p><h2 id="阿里云微服务生态与规划"><a href="#阿里云微服务生态与规划" class="headerlink" title="阿里云微服务生态与规划"></a>阿里云微服务生态与规划</h2><p>阿里开源微服务会贴着服务治理帮助开发者用户微服务，云产品做好产品集成提升大家的使用体验。</p><p>ACK+MSE = 云原生架构升级解决方案</p><p>ASM+MSE = 服务网格解决方案</p><p>AHAS + MSE = 微服务高可用解决方案</p><p>ARMS + MSE = 微服务可观测解决方案</p><p>EDAS + MSE = APaaS解决方案</p><p>SAE + MSE = 微服务 Serverless 解决方案</p><p>WAF + 云盾 + IDaaS + MSE = 微服务安全解决方案</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650511793071-9ba68377-ae2e-4b3c-b9a0-fb0e2dd07360.png?x-oss-process=image/resize,w_977,limit_0"></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://developer.aliyun.com/article/891714?spm=5176.21213303.J_6704733920.7.22db53c9yXA1Zr&amp;amp;scm=20140722.S_community@@%E6%96</summary>
      
    
    
    
    <category term="微服务" scheme="http://zhangyu.info/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
    <category term="微服务" scheme="http://zhangyu.info/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>微服务之间的最佳调用方式</title>
    <link href="http://zhangyu.info/2022/05/28/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B9%8B%E9%97%B4%E7%9A%84%E6%9C%80%E4%BD%B3%E8%B0%83%E7%94%A8%E6%96%B9%E5%BC%8F/"/>
    <id>http://zhangyu.info/2022/05/28/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B9%8B%E9%97%B4%E7%9A%84%E6%9C%80%E4%BD%B3%E8%B0%83%E7%94%A8%E6%96%B9%E5%BC%8F/</id>
    <published>2022-05-27T16:00:00.000Z</published>
    <updated>2022-05-28T06:23:50.040Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/weixin_38748858/article/details/101062272">https://blog.csdn.net/weixin_38748858/article/details/101062272</a></p><p><a href="https://blog.csdn.net/weixin_38748858/article/details/101062272">微服务之间的最佳调用方式_倚天码农的博客-CSDN博客_微服务调用</a></p><blockquote><p>在微服务架构中，需要调用很多服务才能完成一项功能。服务之间如何互相调用就变成微服务架构中的一个关键问题。服务调用有两种方式，一种是RPC方式，另一种是事件驱动（Event-driven）方式，也就是发消息方式。消息方式是松耦合方式，比紧耦合的RPC方式要优越，但RPC方式如果用在适合的场景也有它的一席之地.</p><p><strong>耦合的种类：</strong><br>我们总在谈耦合，那么耦合到底意味着什么呢？</p><ol><li> 时间耦合：客户端和服务端必须同时上线才能工作。发消息时，接受消息队列必须运行，但后台处理程序暂时不工作也不影响。</li><li> 容量耦合：客户端和服务端的处理容量必须匹配。发消息时，如果后台处理能力不足也不要紧，消息队列会起到缓冲的作用。</li><li> 接口耦合：RPC调用有函数标签，而消息队列只是一个消息。例如买了商品之后要调用发货服务，如果是发消息，那么就只需发送一个商品被买消息。</li><li> 发送方式耦合：RPC是点对点方式，需要知道对方是谁，它的好处是能够传回返回值。消息既可以点对点，也可以用广播的方式，这样减少了耦合，但也使返回值比较困难。</li></ol><p>下面我们来逐一分析这些耦合的影响。 第一，时间耦合，对于多数应用来讲，你希望能马上得到回答，因此即使使用消息队列，后台也需要一直工作。第二，容量耦合，如果你对回复有时间要求，那么消息队列的缓冲功能作用不大，因为你希望及时响应。真正需要的是自动伸缩（Auto-scaling），它能自动调整服务端处理能力去匹配请求数量。第三和第四，接口耦合和发送方式耦合，这两个确实是RPC方式的软肋。</p><h3 id="事件驱动（Event-Driven）方式："><a href="#事件驱动（Event-Driven）方式：" class="headerlink" title="事件驱动（Event-Driven）方式："></a>事件驱动（Event-Driven）方式：</h3><p>Martin Fowler把事件驱动分成四种方式(<a href="https://martinfowler.com/articles/201701-event-driven.html">What do you mean by “Event-Driven”</a>)，简化之后本质上只有两种方式。 一种就是我们熟悉的的事件通知（Event Notification），另一种是事件溯源（Event Sourcing）。事件通知就是微服务之间不直接调用，而是通过发消息来进行合作。事件溯源有点像记账，它把所有的事件都记录下来，作为永久存储层，再在它的基础之上构建应用程序。实际上从应用的角度来讲，它们并不应该分属一类，它们的用途完全不同。事件通知是微服务的调用（或集成）方式，应该和RPC分在一起。事件溯源是一种存储数据的方式，应该和数据库分在一起。</p><h4 id="事件通知（Event-Notification）方式："><a href="#事件通知（Event-Notification）方式：" class="headerlink" title="事件通知（Event Notification）方式："></a>事件通知（Event Notification）方式：</h4><p>让我们用具体的例子来看一下。在下面的例子中，有三个微服务，“Order Service”， “Customer Service” 和“Product Service”.</p><p><img src="https://img-blog.csdnimg.cn/20190920153708185.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODc0ODg1OA==,size_16,color_FFFFFF,t_70" alt="file"></p><p><a href="https://www.infoq.com/presentations/aggregates-modular-microservices/">图片来源</a></p><p>先说读数据，假设要创建一个“Order”，在这个过程中需要读取“Customer”的数据和“Product”数据。如果用事件通知的方式就只能在“Order Service”本地也创建只读“Customer”和“Product”表，并把数据用消息的方式同步过来。</p><p>再说写数据，如果在创建一个“Order”时需要创建一个新的“Customer”或要修改“Customer”的信息，那么可以在界面上跳转到用户创建页面，然后在“Customer Service”创建用户之后再发”用户已创建“的消息，“Order Service”接到消息，更新本地“Customer”表。</p><p>这并不是一个很好的使用事件驱动的例子，因为事件驱动的优点就是不同的程序之间可以独立运行，没有绑定关系。但现在“Order Service”需要等待“Customer Service”创建完了之后才能继续运行，来完成整个创建“Order”的工作。主要是因为“Order”和“Customer”本身从逻辑上来讲就是紧耦合关系，没有“Customer”你是不能创建“Order”的。</p><p>在这种紧耦合的情况下，也可以使用RPC。你可以建立一个更高层级的管理程序来管理这些微服务之间的调用，这样“Order Service”就不必直接调用“Customer Service”了。当然它从本质上来讲并没有解除耦合，只是把耦合转移到了上一层，但至少现在“order Service”和“Customer Service”可以互不影响了。之所以不能根除这种紧耦合关系是因为它们在业务上是紧耦合的。</p><p>再举一个购物的例子。用户选好商品之后进行“Checkout”，生成“Order”，然后需要“payment”，再从“Inventory”取货，最后由“Shipment”发货，它们每一个都是微服务。这个例子用RPC方式和事件通知方式都可以完成。当用RPC方式时，由“Order”服务调用其他几个服务来完成整个功能。用事件通知方式时，“Checkout”服务完成之后发送“Order Placed”消息，“Payment”服务收到消息，接收用户付款，发送“Payment received”消息。“Inventory”服务收到消息，从仓库里取货，并发送“Goods fetched”消息。“Shipment”服务得到消息，发送货物，并发送“Goods shipped”消息。</p><p><img src="https://img-blog.csdnimg.cn/20190920153708514.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODc0ODg1OA==,size_16,color_FFFFFF,t_70" alt="file"></p><p><a href="https://blog.bernd-ruecker.com/the-microservice-workflow-automation-cheat-sheet-fc0a80dc25aa">图片来源</a></p><p>对这个例子来讲，使用事件驱动是一个不错的选择，因为每个服务发消息之后它不需要任何反馈，这个消息由下一个模块接收来完成下一步动作，时间上的要求也比上一个要宽松。用事件驱动的好处是降低了耦合度，坏处是你现在不能在程序里找到整个购物过程的步骤。如果一个业务逻辑有它自己相对固定的流程和步骤，那么使用RPC或业务流程管理（BPM）能够更方便地管理这些流程。在这种情况下选哪种方案呢？在我看来好处和坏处是大致相当的。从技术上来讲要选事件驱动，从业务上来讲要选RPC。不过现在越来越多的人采用事件通知作为微服务的集成方式，它似乎已经成了微服务之间的标椎调用方式。</p><h4 id="事件溯源-Event-Sourcing-："><a href="#事件溯源-Event-Sourcing-：" class="headerlink" title="事件溯源(Event Sourcing)："></a>事件溯源(Event Sourcing)：</h4><p>这是一种具有颠覆性质的的设计，它把系统中所有的数据都以事件（Event）的方式记录下来，它的持久存储叫Event Store， 一般是建立在数据库或消息队列（例如Kafka）基础之上，并提供了对事件进行操作的接口，例如事件的读写和查询。事件溯源是由领域驱动设计(<a href="https://dddcommunity.org/book/evans_2003/">Domain-Driven Design</a>)提出来的。DDD中有一个很重要的概念，有界上下文（<a href="https://martinfowler.com/bliki/BoundedContext.html">Bounded Context</a>），可以用有界上下文来划分微服务，每个有界上下文都可以是一个微服务。 下面是有界上下文的示例。下图中有两个服务“Sales”和“Support”。有界上下文的一个关键是如何处理共享成员， 在图中是“Customer”和“Product”。在不同的有界上下文中，共享成员的含义、用法以及他们的对象属性都会有些不同，DDD建议这些共享成员在各自的有界上下文中都分别建自己的类（包括数据库表），而不是共享。可以通过数据同步的手段来保持数据的一致性。下面还会详细讲解。</p><p><img src="https://img-blog.csdnimg.cn/201909201537097.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODc0ODg1OA==,size_16,color_FFFFFF,t_70" alt="file"><br><a href="https://martinfowler.com/bliki/BoundedContext.html">图片来源</a></p><p>事件溯源是微服务的一种存储方式，它是微服务的内部实现细节。因此你可以决定哪些微服务采用事件溯源方式，哪些不采用，而不必所有的服务都变成事件溯源的。 通常整个应用程序只有一个Event Store， 不同的微服务都通过向Event Store发送和接受消息而互相通信。Event Store内部可以分成不同的stream（相当于消息队列中的Topic）， 供不同的微服务中的领域实体（Domain Entity）使用。</p><p>事件溯源的一个短板是数据查询，它有两种方式来解决。第一种是直接对stream进行查询，这只适合stream比较小并且查询比较简单的情况。查询复杂的话，就要采用第二种方式，那就是建立一个只读数据库，把需要的数据放在库中进行查询。数据库中的数据通过监听Event Store中相关的事件来更新。</p><p>数据库存储方式只能保存当前状态，而事件溯源则存储了所有的历史状态，因而能根据需要回放到历史上任何一点的状态，具有很大优势。但它也不是一点问题都没有。第一，它的程序比较复杂，因为事件是一等公民，你必须把业务逻辑按照事件的方式整理出来，然后用事件来驱动程序。第二，如果你要想修改事件或事件的格式就比较麻烦，因为旧的事件已经存储在Event Store里了（事件就像日志，是只读的），没有办法再改。</p><p>由于事件溯源和事件通知表面上看起来很像，不少人都搞不清楚它们的区别。事件通知只是微服务的集成方式，程序内部是不使用事件溯源的，内部实现仍然是传统的数据库方式。只有当要与其他微服务集成时才会发消息。而在事件溯源中，事件是一等公民，可以不要数据库，全部数据都是按照事件的方式存储的。</p><p>虽然事件溯源的践行者有不同的意见，但有不少人都认为事件溯源不是微服务的集成方式，而是微服务的一种内部实现方式。因此，在一个系统中，可以某些微服务用事件溯源，另外一些微服务用数据库。当你要集成这些微服务时，你可以用事件通知的方式。注意现在有两种不同的事件需要区分开，一种是微服务的内部事件，是颗粒度比较细的，这种事件只发送到这个微服务的stream中，只被事件溯源使用。另一种是其他微服务也关心的，是颗粒度比较粗的，这种事件会放到另外一个或几个stream中，被多个微服务使用，是用来做服务之间集成的。这样做的好处是限制了事件的作用范围，减少了不相关事件对程序的干扰。详见”<a href="https://www.innoq.com/en/blog/domain-events-versus-event-sourcing/">Domain Events vs. Event Sourcing</a>“.</p><p>事件溯源出现已经很长时间了，虽然热度一直在上升（尤其是这两年），但总的来说非常缓慢，谈论的人不少，但生产环境使用的不多。究其原因就是应为它对现在的体系结构颠覆太大，需要更改数据存储结构和程序的工作方式，还是有一定风险的。另外，微服务已经形成了一整套体系，从程序部署，服务发现与注册，到监控，服务韧性（Service Resilience），它们基本上都是针对RPC的，虽然也支持消息，但成熟度就差多了，因此有不少工作还是要自己来做。有意思的是Kafka一直在推动它作为事件驱动的工具，也取得了很大的成功。但它却没有得到事件溯源圈内的认可（详见<a href="https://stackoverflow.com/a/49868866">这里</a>）。<br>多数事件溯源都使用一个叫<a href="https://eventstore.org/">evenstore</a>的开源Event Store，或是基于某个数据库的Event Store，只有比较少的人用Kafka做Event Store。 但如果用Kafka实现事件通知就一点问题都没有。总的来说，对大多数公司来讲事件溯源是有一定挑战的，应用时需要找到合适的场景。如果你要尝试的话，可以先拿一个微服务试水。</p><p>虽然现在事件驱动还有些生涩，但从长远来讲，还是很看好它的。像其他全新的技术一样，事件溯源需要大规模的适用场景来推动。例如容器技术就是因为微服务的流行和推动，才走向主流。事件溯源以前的适用场景只限于记账和源代码库，局限性较大。区块链可能会成为它的下一个机遇，因为它用的也是事件溯源技术。另外AI今后会渗入到具体程序中，使程序具有学习功能。而RPC模式注定没有自适应功能。事件驱动本身就具有对事件进行反应的能力，这是自我学习的基础。因此，这项技术长远来讲定会大放异彩，但短期内（3-5年）大概不会成为主流。</p><h3 id="RPC方式："><a href="#RPC方式：" class="headerlink" title="RPC方式："></a>RPC方式：</h3><p>RPC的方式就是远程函数调用，像RESTFul，gRPC, DUBBO 都是这种方式。它一般是同步的，可以马上得到结果。在实际中，大多数应用都要求立刻得到结果，这时同步方式更有优势，代码也更简单。</p><h4 id="服务网关（API-Gateway）"><a href="#服务网关（API-Gateway）" class="headerlink" title="服务网关（API Gateway）:"></a>服务网关（API Gateway）:</h4><p>熟悉微服务的人可能都知道服务网关（API Gateway）。当UI需要调用很多微服务时，它需要了解每个服务的接口，这个工作量很大。于是就用服务网关创建了一个Facade，把几个微服务封装起来，这样UI就只调用服务网关就可以了，不需要去对付每一个微服务。下面是API Gateway示例图：</p><p><img src="https://img-blog.csdnimg.cn/20190920153709420.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODc0ODg1OA==,size_16,color_FFFFFF,t_70" alt="file"></p><p><a href="https://microservices.io/patterns/apigateway.html">图片来源</a></p><p>服务网关（API Gateway）不是为了解决微服务之间调用的紧耦合问题，它主要是为了简化客户端的工作。其实它还可以用来降低函数之间的耦合度。 有了API Gateway之后，一旦服务接口修改，你可能只需要修改API Gateway， 而不必修改每个调用这个函数的客户端，这样就减少了程序的耦合性。</p><h4 id="服务调用："><a href="#服务调用：" class="headerlink" title="服务调用："></a>服务调用：</h4><p>可以借鉴API Gateway的思路来减少RPC调用的耦合度，例如把多个微服务组织起来形成一个完整功能的服务组合，并对外提供统一的服务接口。这种想法跟上面的API Gateway有些相似，都是把服务集中起来提供粗颗粒（Coarse Granular）服务，而不是细颗粒的服务（Fine Granular）。但这样建立的服务组合可能只适合一个程序使用，没有多少共享价值。因此如果有合适的场景就采用，否侧也不必强求。虽然我们不能降低RPC服务之间的耦合度，却可以减少这种紧耦合带来的影响。</p><h3 id="降低紧耦合的影响："><a href="#降低紧耦合的影响：" class="headerlink" title="降低紧耦合的影响："></a>降低紧耦合的影响：</h3><p>什么是紧耦合的主要问题呢？就是客户端和服务端的升级不同步。服务端总是先升级，客户端可能有很多，如果要求它们同时升级是不现实的。它们有各自的部署时间表，一般都会选择在下一次部署时顺带升级。</p><p>一般有两个办法可以解决这个问题：</p><ol><li> 同时支持多个版本：这个工作量比较大，因此大多数公司都不会采用这种方式。</li><li> 服务端向后兼容：这是更通用的方式。例如你要加一个新功能或有些客户要求给原来的函数增加一个新的参数，但别的客户不需要这个参数。这时你只好新建一个函数，跟原来的功能差不多，只是多了一个参数。这样新旧客户的需求都能满足。它的好处是向后兼容（当然这取决于你使用的协议）。它的坏处是当以后新的客户来了，看到两个差不多的函数就糊涂了，不知道该用那个。而且时间越长越严重，你的服务端可能功能增加的不多，但相似的函数却越来越多，无法选择。</li></ol><p>它的解决办法就是使用一个支持向后兼容的RPC协议，现在最好的就是Protobuf gRPC，尤其是在向后兼容上。它给每个服务定义了一个接口，这个接口是与编程语言无关的中性接口，然后你可以用工具生成各个语言的实现代码，供不同语言使用。函数定义的变量都有编号，变量可以是可选类型的，这样就比较好地解决了函数兼容的问题。就用上面的例子，当你要增加一个可选参数时，你就定义一个新的可选变量。由于它是可选的，原来的客户端不需要提供这个参数，因此不需要修改程序。而新的客户端可以提供这个参数。你只要在服务端能同时处理这两种情况就行了。这样服务端并没有增加新的函数，但用户的新需求满足了，而且还是向后兼容的。</p><h3 id="微服务的数量有没有上限？"><a href="#微服务的数量有没有上限？" class="headerlink" title="微服务的数量有没有上限？"></a>微服务的数量有没有上限？</h3><p>总的来说微服务的数量不要太多，不然会有比较重的运维负担。有一点需要明确的是微服务的流行不是因为技术上的创新，而是为了满足管理上的需要。单体程序大了之后，各个模块的部署时间要求不同，对服务器的优化要求也不同，而且团队人数众多，很难协调管理。把程序拆分成微服务之后，每个团队负责几个服务，就容易管理了，而且每个团队也可以按照自己的节奏进行创新，但它给运维带来了巨大的麻烦。所以在微服务刚出来时，我一直觉得它是一个退步，弊大于利。但由于管理上的问题没有其他解决方案，只有硬着头皮上了。值得庆幸的是微服务带来的麻烦都是可解的。直到后来，微服务建立了全套的自动化体系，从程序集成到部署，从全链路跟踪到日志，以及服务检测，服务发现和注册，这样才把微服务的工作量降了下来。虽然微服务在技术上一无是处，但它的流行还是大大推动了容器技术，服务网格（Service Mesh）和全链路跟踪等新技术的发展。不过它本身在技术上还是没有发现任何优势。。直到有一天，我意识到单体程序其实性能调试是很困难的（很难分离出瓶颈点），而微服务配置了全链路跟踪之后，能很快找到症结所在。看来微服务从技术来讲也不全是缺点，总算也有好的地方。但微服务的颗粒度不宜过细，否则工作量还是太大。</p><p>一般规模的公司十几个或几十个微服务都是可以承受的，但如果有几百个甚至上千个，那么绝不是一般公司可以管理的。尽管现有的工具已经很齐全了，而且与微服务有关的整个流程也已经基本上全部自动化了，但它还是会增加很多工作。Martin Fowler几年以前建议先从单体程序开始（详见 <a href="https://martinfowler.com/bliki/MonolithFirst.html">MonolithFirst</a>），然后再逐步把功能拆分出去，变成一个个的微服务。但是后来有人反对这个建议，他也有些松口了。如果单体程序不是太大，这是个好主意。可以用数据额库表的数量来衡量程序的大小，我见过大的单体程序有几百张表，这就太多了，很难管理。正常情况下，一个微服务可以有两、三张表到五、六张表，一般不超过十张表。但如果要减少微服务数量的话，可以把这个标准放宽到不要超过二十张表。用这个做为大致的指标来创建微程序，如果使用一段时间之后还是觉得太大了，那么再逐渐拆分。当然，按照这个标准建立的服务更像是服务组合，而不是单个的微服务。不过它会为你减少工作量。只要不影响业务部门的创新进度，这是一个不错的方案。</p><p>到底应不应该选择微服务呢？如果单体程序已经没法管理了，那么你别无选择。如果没有管理上的问题，那么微服务带给你的只有问题和麻烦。其实，一般公司都没有太多选择，只能采用微服务，不过你可以选择建立比较少的微服务。如果还是没法决定，有一个折中的方案，“内部微服务设计”。</p><h4 id="内部微服务设计："><a href="#内部微服务设计：" class="headerlink" title="内部微服务设计："></a>内部微服务设计：</h4><p>这种设计表面上看起来是一个单体程序，它只有一个源代码存储仓库，一个数据库，一个部署，但在程序内部可以按照微服务的思想来进行设计。它可以分成多个模块，每个模块是一个微服务，可以由不同的团队管理。</p><p><img src="https://img-blog.csdnimg.cn/20190920153709762.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODc0ODg1OA==,size_16,color_FFFFFF,t_70" alt="file"></p><p><a href="https://docs.microsoft.com/en-us/dotnet/architecture/microservices/architect-microservice-container-applications/identify-microservice-domain-model-boundaries">图片来源</a></p><p>用这张图做例子。这个图里的每个圆角方块大致是一个微服务，但我们可以把它作为一个单体程序来设计，内部有五个微服务。每个模块都有自己的数据库表，它们都在一个数据库中，但模块之间不能跨数据库访问（不要建立模块之间数据库表的外键）。“User”（在Conference Management模块中）是一个共享的类，但在不同的模块中的名字不同，含义和用法也不同，成员也不一样（例如，在“Customer Service”里叫“Customer”）。DDD（Domain-Driven Design）建议不要共享这个类，而是在每一个有界上下文（模块）中都建一个新类，并拥有新的名字。虽然它们的数据库中的数据应该大致相同，但DDD建议每一个有界上下文中都建一个新表，它们之间再进行数据同步。</p><p>这个所谓的“内部微服务设计”其实就是DDD，但当时还没有微服务，因此外表看起来是单体程序，但内部已经是微服务的设计了。它的书在2003就出版了，当时就很有名。但它更偏重于业务逻辑的设计，践行起来也比较困难，因此大家谈论得很多，真正用的较少。直到十年之后，微服务出来之后，人们发现它其实内部就是微服务，而且微服务的设计需要用它的思想来指导，于是就又重新焕发了青春，而且这次更猛，已经到了每个谈论微服务的人都不得不谈论DDD的地步。不过一本软件书籍，在十年之后还能指导新技术的设计，非常令人钦佩。</p><p>这样设计的好处是它是一个单体程序，省去了多个微服务带来的部署、运维的麻烦。但它内部是按微服务设计的，如果以后要拆分成微服务会比较容易。至于什么时候拆分不是一个技术问题。如果负责这个单体程序的各个团队之间不能在部署时间表，服务器优化等方面达成一致，那么就需要拆分了。当然你也要应对随之而来的各种运维麻烦。内部微服务设计是一个折中的方案，如果你想试水微服务，但又不愿意冒太大风险时，这是一个不错的选择。<br>微服务的数据库设计也有很多内容，包括如何把服务从单体程序一步步里拆分出来请参见<a href="https://blog.csdn.net/weixin_38748858/article/details/102634941">“微服务的数据库设计”</a>.</p><h4 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h4><p>微服务之间的调用有两种方式，RPC和事件驱动。事件驱动是更好的方式，因为它是松耦合的。但如果业务逻辑是紧耦合的，RPC方式也是可行的（它的好处是代码更简单），而且你还可以通过选取合适的协议（Protobuf gRPC）来降低这种紧耦合带来的危害。由于事件溯源和事件通知的相似性，很多人把两者弄混了，但它们实际上是完全不同的东西。微服务的数量不宜太多，可以先创建比较大的微服务（更像是服务组合）。如果你还是不能确定是否采用微服务架构，可以先从“内部微服务设计”开始，再逐渐拆分。</p><h4 id="索引："><a href="#索引：" class="headerlink" title="索引："></a>索引：</h4><p>[1] <a href="https://martinfowler.com/articles/201701-event-driven.html">What do you mean by “Event-Driven”</a></p><p>[2] <a href="https://dddcommunity.org/book/evans_2003/">Domain-Driven Design</a></p><p>[3] <a href="https://martinfowler.com/bliki/BoundedContext.html">BoundedContext</a></p><p>[4] <a href="https://www.innoq.com/en/blog/domain-events-versus-event-sourcing/">Domain Events vs. Event Sourcing</a></p><p>[5] <a href="https://stackoverflow.com/a/49868866">Using Kafka as a (CQRS) Eventstore. Good idea</a></p><p>[6] <a href="https://eventstore.org/">Evenstore</a></p><p>[7] <a href="https://martinfowler.com/bliki/MonolithFirst.html">MonolithFirst</a></p><p>[8] <a href="https://blog.csdn.net/weixin_38748858/article/details/102634941">微服务的数据库设计</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/weixin_38748858/article/details/101062272&quot;&gt;https://blog.csdn.net/weixin_38748858/article/details/101062272</summary>
      
    
    
    
    <category term="微服务" scheme="http://zhangyu.info/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
    <category term="微服务" scheme="http://zhangyu.info/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>解决gateway使用nacos重启报503ServiceUnavailable问题</title>
    <link href="http://zhangyu.info/2022/05/01/%E8%A7%A3%E5%86%B3gateway%E4%BD%BF%E7%94%A8nacos%E9%87%8D%E5%90%AF%E6%8A%A5503ServiceUnavailable%E9%97%AE%E9%A2%98/"/>
    <id>http://zhangyu.info/2022/05/01/%E8%A7%A3%E5%86%B3gateway%E4%BD%BF%E7%94%A8nacos%E9%87%8D%E5%90%AF%E6%8A%A5503ServiceUnavailable%E9%97%AE%E9%A2%98/</id>
    <published>2022-04-30T16:00:00.000Z</published>
    <updated>2022-05-01T06:10:29.038Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.jianshu.com/p/70f4c2ce6ac8">https://www.jianshu.com/p/70f4c2ce6ac8</a></p><blockquote><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>项目使用spring cloud gateway作为网关，nacos作为微服务注册中心，项目搭建好后正常访问都没问题，但是有个很烦人的小瑕疵：</p><ul><li>  当某个微服务重启后，通过网关调用这个服务时有时会出现<code>503 Service Unavailable(服务不可用)</code>的错误，但过了一会儿又可以访问了，这个等待时间有时很长有时很短，甚至有时候还不会出现</li><li>  导致每次重启某个项目都要顺便启动gateway项目才能保证立即可以访问，时间长了感觉好累，想彻底研究下为什么，并彻底解决</li></ul><p><em>接下来介绍我在解决整个过程的思路，如果没兴趣，可以直接跳到最后的最终解决方案</em></p><h2 id="gateway感知其它服务上下线"><a href="#gateway感知其它服务上下线" class="headerlink" title="gateway感知其它服务上下线"></a>gateway感知其它服务上下线</h2><p>首先在某个微服务上下线时，gateway的控制台可以立即看到有对应的输出</p><p><img src="https://upload-images.jianshu.io/upload_images/9112801-0168be1734dd7bf4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/793"></p><p>某服务下线gateway输出</p><p><img src="https://upload-images.jianshu.io/upload_images/9112801-6a09eaf1f1b91bee.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/761"></p><p>某服务上线gateway输出</p><p>这说明nacos提供了这种监听功能，在注册中心服务列表发生时可以第一时间通知客户端，而在我们的依赖<code>spring-cloud-starter-alibaba-nacos-discovery</code>中显然已经帮我们实现了这个监听</p><p>所以也就说明gateway是可以立即感知其它服务的上下线事件，但问题是明明感知到某个服务的上线，那为什么会出现<code>503 Service Unavailable</code>的错误，而且上面的输出有时出现了很久，但调用依然是<code>503 Service Unavailable</code>，对应的某服务明明下线，这是应该是<code>503 Service Unavailable</code>状态，可有时确会有一定时间的<code>500</code>错误</p><h2 id="ribbon"><a href="#ribbon" class="headerlink" title="ribbon"></a>ribbon</h2><p>为了调查事情的真相，我打开了gateway的debug日志模式，找到了503的罪魁祸首  </p><p><img src="https://upload-images.jianshu.io/upload_images/9112801-e761406118f10444.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1079"></p><p>503的控制台输出</p><p>在503错误输出前，有一行这样的日志<code>Zone aware logic disabled or there is only one zone</code>，而报这个信息的包就是ribbon-loadbalancer，也就是gateway默认所使用的负载均衡器</p><p>我的gateway配置文件路由方面设置如下</p><pre><code>routes:        - id: auth          uri: lb://demo-auth          predicates:            - Path=/auth/**          filters:            - StripPrefix=1</code></pre><p>其中在uri这一行，使用了lb:// ,代表使用了gateway的ribbon负载均衡功能，官方文档说明如下<br><strong>Note that this example also demonstrates (optional) Spring Cloud Netflix Ribbon load-balancing (defined the lb prefix on the destination URI)</strong></p><p>ribbon再调用时首先会获取所有服务列表(ip和端口信息)，然后根据负载均衡策略调用其中一个服务，选择服务的代码如下</p><pre><code>package com.netflix.loadbalancer;public class ZoneAwareLoadBalancer&lt;T extends Server&gt; extends DynamicServerListLoadBalancer&lt;T&gt; &#123;    // 选择服务的方法    public Server chooseServer(Object key) &#123;            if (!ENABLED.get() || getLoadBalancerStats().getAvailableZones().size() &lt;= 1) &#123;                logger.debug(&quot;Zone aware logic disabled or there is only one zone&quot;);                return super.chooseServer(key);            &#125;    ...     </code></pre><p>这就是上面的<code>Zone aware logic..</code>这行日志的出处，经调试发现在<code>getLoadBalancerStats().getAvailableZones()</code>这一步返回的服务是空列表，说明这里没有存储任何服务信息，所以才导致最终的<code>503 Service Unavailable</code><br>继续跟进去看<code>getAvailableZones</code>的代码，如下</p><pre><code>public class LoadBalancerStats implements IClientConfigAware &#123;    // 一个缓存所有服务的map    volatile Map&lt;String, List&lt;? extends Server&gt;&gt; upServerListZoneMap = new ConcurrentHashMap&lt;String, List&lt;? extends Server&gt;&gt;();    // 获取可用服务keys    public Set&lt;String&gt; getAvailableZones() &#123;        return upServerListZoneMap.keySet();    &#125;</code></pre><p>可以看到ribbon是在LoadBalancerStats中维护了一个map来缓存所有可用服务，而问题的原因也大概明了了：<strong>gateway获取到了服务变更事件，但并没有及时更新ribbon的服务列表缓存</strong></p><h2 id="ribbon的刷新缓存机制"><a href="#ribbon的刷新缓存机制" class="headerlink" title="ribbon的刷新缓存机制"></a>ribbon的刷新缓存机制</h2><p>现在的实际情况是：gateway获取到了服务变更事件，但并没有马上更新ribbon的服务列表缓存，但过一段时间可以访问说明缓存又刷新了，那么接下来就要找到ribbon的缓存怎么刷新的，进而进一步分析为什么没有及时刷新</p><p>在LoadBalancerStats查找到更新缓存的方法是<code>updateZoneServerMapping</code></p><pre><code>public class LoadBalancerStats implements IClientConfigAware &#123;    // 一个缓存所有服务的map    volatile Map&lt;String, List&lt;? extends Server&gt;&gt; upServerListZoneMap = new ConcurrentHashMap&lt;String, List&lt;? extends Server&gt;&gt;();    // 更新缓存    public void updateZoneServerMapping(Map&lt;String, List&lt;Server&gt;&gt; map) &#123;        upServerListZoneMap = new ConcurrentHashMap&lt;String, List&lt;? extends Server&gt;&gt;(map);        // make sure ZoneStats object exist for available zones for monitoring purpose        for (String zone: map.keySet()) &#123;            getZoneStats(zone);        &#125;    &#125;</code></pre><p>那么接下来看看这个方法的调用链，调用链有点长，最终找到了<code>DynamicServerListLoadBalancer</code>下的<code>updateListOfServers</code>方法，首先看<code>DynamicServerListLoadBalancer</code>翻译过来”动态服务列表负载均衡器”，说明它有动态获取服务列表的功能，那我们的bug它肯定难辞其咎，而<code>updateListOfServers</code>就是它刷新缓存的手段，那么就看看这个所谓的”动态服务列表负载均衡器”是如何使用<code>updateListOfServers</code>动态刷新缓存的</p><pre><code>public class DynamicServerListLoadBalancer&lt;T extends Server&gt; extends BaseLoadBalancer &#123;    // 封装成一个回调    protected final ServerListUpdater.UpdateAction updateAction = new ServerListUpdater.UpdateAction() &#123;        @Override        public void doUpdate() &#123;            updateListOfServers();        &#125;    &#125;;    // 初始化    public DynamicServerListLoadBalancer(IClientConfig clientConfig, IRule rule, IPing ping,                                         ServerList&lt;T&gt; serverList, ServerListFilter&lt;T&gt; filter,                                         ServerListUpdater serverListUpdater) &#123;        ...        this.serverListUpdater = serverListUpdater; // serverListUpdate赋值        ...        // 初始化时刷新服务        restOfInit(clientConfig);    &#125;    void restOfInit(IClientConfig clientConfig) &#123;        ...        // 开启动态刷新缓存        enableAndInitLearnNewServersFeature();        // 首先刷新一遍缓存        updateListOfServers();        ...    &#125;    // 开启动态刷新缓存    public void enableAndInitLearnNewServersFeature() &#123;        // 把更新的方法传递给serverListUpdater        serverListUpdater.start(updateAction);    &#125;</code></pre><p>可以看到初始化DynamicServerListLoadBalancer时，首先updateListOfServers获取了一次服务列表并缓存，这只能保证项目启动获取一次服务列表，而真正的动态更新实现是把updateListOfServers方法传递给内部<code>serverListUpdater.start</code>方法，serverListUpdater翻译过来就是“服务列表更新器”，所以再理一下思路：</p><p>DynamicServerListLoadBalancer只所以敢自称“动态服务列表负载均衡器”，是因为它内部有个serverListUpdater(“服务列表更新器”)，也就是<code>serverListUpdater.start</code>才是真正为ribbon提供动态更新服务列表的方法，也就是罪魁祸首</p><p>那么就看看<code>ServerListUpdater</code>到底是怎么实现的动态更新，首先<code>ServerListUpdater</code>是一个接口，它的实现也只有一个PollingServerListUpdater，那么肯定是它了，看一下它的<code>start</code>方法实现</p><pre><code>public class PollingServerListUpdater implements ServerListUpdater &#123;    @Override    public synchronized void start(final UpdateAction updateAction) &#123;        if (isActive.compareAndSet(false, true)) &#123;            // 定义一个runable，运行doUpdate放            final Runnable wrapperRunnable = new Runnable() &#123;                @Override                public void run() &#123;                    ....                    try &#123;                        updateAction.doUpdate(); // 执行更新服务列表方法                        lastUpdated = System.currentTimeMillis();                    &#125; catch (Exception e) &#123;                        logger.warn(&quot;Failed one update cycle&quot;, e);                    &#125;                &#125;            &#125;;            // 定时执行            scheduledFuture = getRefreshExecutor().scheduleWithFixedDelay(                    wrapperRunnable,                    initialDelayMs,                    refreshIntervalMs, // 默认30 * 1000                    TimeUnit.MILLISECONDS            );        &#125; else &#123;            logger.info(&quot;Already active, no-op&quot;);        &#125;    &#125;</code></pre><p>至此真相大白了，原来ribbon默认更新服务列表依靠的是<strong>定时任务</strong>，而且默认30秒一次，<strong>也就是说假如某个服务重启了，gateway的nacos客户端也感知到了，但是ribbon内部极端情况需要30秒才会重新获取服务列表</strong>，这也就解释了为什么会有那么长时间的<code>503 Service Unavailable</code>问题</p><p>而且因为定时任务，所以等待时间是0-30秒不等，有可能你刚重启完就获取了正常调用没问题，也有可能刚重启完时刚获取完一次，结果就得等30秒才能访问到新的节点</p><h2 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h2><p>问题的原因找到了，接下来就是解决了，最简单暴力的方式莫过于修改定时任务的间隔时间，默认30秒，可以改成10秒，5秒，1秒，只要你机器配置够牛逼</p><p>但是有没有更优雅的解决方案，我们的gateway明明已经感知到服务的变化，如果通知ribbon直接更新，问题不就完美解决了吗，这种思路定时任务都可以去掉了，性能还优化了</p><p>具体解决步骤如下</p><ul><li>  写一个新的更新器，替换掉默认的PollingServerListUpdater更新器</li><li>  更新器可以监听nacos的服务更新</li><li>  收到服务更新事件时，调用doUpdate方法更新ribbon缓存</li></ul><p>接下来一步步解决</p><p>首先看上面DynamicServerListLoadBalancer的代码，发现更新器是构造方法传入的，所以要找到构造方法的调用并替换成自己信息的更新器</p><p>在DynamicServerListLoadBalancer构造方法上打了个断点，看看它是如何被初始化的(<strong>并不是gateway启动就会初始化，而是首次调用某个服务，给对应的服务创建一个LoadBalancer，有点懒加载的意思</strong>)  </p><p><img src="https://upload-images.jianshu.io/upload_images/9112801-31bc7100ad4ad37f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1061"></p><p>构造方法断点</p><p><img src="https://upload-images.jianshu.io/upload_images/9112801-44f34f0c171f43c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200"></p><p>debugger</p><p>看一下debugger的函数调用，发现一个<code>doCreateBean&gt;&gt;&gt;createBeanInstance</code>的调用，其中createBeanInstance执行到如下地方  </p><p><img src="https://upload-images.jianshu.io/upload_images/9112801-7f8a73918993940e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/873"></p><p>createBeanInstance</p><p>熟悉spring源码的朋友应该看得出来DynamicServerListLoadBalancer是spring容器负责创建的，而且是FactoryBean模式。</p><p>这个bean的定义在spring-cloud-netflix-ribbon依赖中的RibbonClientConfiguration类</p><pre><code>package org.springframework.cloud.netflix.ribbon;@Configuration(proxyBeanMethods = false)@EnableConfigurationProperties@Import(&#123; HttpClientConfiguration.class, OkHttpRibbonConfiguration.class,        RestClientRibbonConfiguration.class, HttpClientRibbonConfiguration.class &#125;)public class RibbonClientConfiguration &#123;    ...    @Bean    @ConditionalOnMissingBean    public ServerListUpdater ribbonServerListUpdater(IClientConfig config) &#123;        return new PollingServerListUpdater(config);    &#125;    ...&#125;</code></pre><p>也就是通过我们熟知的@Configuration+@Bean模式创建的PollingServerListUpdater更新器，而且加了个注解<code>@ConditionalOnMissingBean</code></p><p>也就是说我们自己实现一个ServerListUpdater更新器，并加入spring容器，就可以代替PollingServerListUpdater成为ribbon的更新器</p><h2 id="最终解决方案"><a href="#最终解决方案" class="headerlink" title="最终解决方案"></a>最终解决方案</h2><p>我们的更新器是要订阅nacos的，收到事件做update处理，为了避免ribbon和nacos耦合抽象一个监听器再用nacos实现</p><h5 id="1-抽象监听器"><a href="#1-抽象监听器" class="headerlink" title="1.抽象监听器"></a>1.抽象监听器</h5><pre><code>/** * @Author pq * @Date 2022/4/26 17:19 * @Description 抽象监听器 */public interface ServerListListener &#123;    /**     * 监听     * @param serviceId 服务名     * @param eventHandler 回调     */    void listen(String serviceId, ServerEventHandler eventHandler);    @FunctionalInterface    interface ServerEventHandler &#123;        void update();    &#125;&#125;</code></pre><h5 id="自定义ServerListUpdater"><a href="#自定义ServerListUpdater" class="headerlink" title="自定义ServerListUpdater"></a>自定义ServerListUpdater</h5><pre><code>public class NotificationServerListUpdater implements ServerListUpdater &#123;    private static final Logger logger = LoggerFactory.getLogger(NotificationServerListUpdater.class);    private final ServerListListener listener;    public NotificationServerListUpdater(ServerListListener listener) &#123;        this.listener = listener;    &#125;    /**     * 开始运行     * @param updateAction     */    @Override    public void start(UpdateAction updateAction) &#123;        // 创建监听        String clientName = getClientName(updateAction);        listener.listen(clientName, ()-&gt; &#123;            logger.info(&quot;&#123;&#125; 服务变化, 主动刷新服务列表缓存&quot;, clientName);            // 回调直接更新            updateAction.doUpdate();        &#125;);    &#125;    /**     * 通过updateAction获取服务名，这种方法比较粗暴     * @param updateAction     * @return     */    private String getClientName(UpdateAction updateAction) &#123;        try &#123;            Class&lt;?&gt; bc = updateAction.getClass();            Field field = bc.getDeclaredField(&quot;this$0&quot;);            field.setAccessible(true);            BaseLoadBalancer baseLoadBalancer = (BaseLoadBalancer) field.get(updateAction);            return baseLoadBalancer.getClientConfig().getClientName();        &#125; catch (Exception e) &#123;            e.printStackTrace();            throw new IllegalStateException(e);        &#125;    &#125;</code></pre><h5 id="实现ServerListListener监控nacos并注入bean容器"><a href="#实现ServerListListener监控nacos并注入bean容器" class="headerlink" title="实现ServerListListener监控nacos并注入bean容器"></a>实现ServerListListener监控nacos并注入bean容器</h5><pre><code>@Slf4j@Componentpublic class NacosServerListListener implements ServerListListener &#123;    @Autowired    private NacosServiceManager nacosServiceManager;    private NamingService namingService;    @Autowired    private NacosDiscoveryProperties properties;    @PostConstruct    public void init() &#123;        namingService =  nacosServiceManager.getNamingService(properties.getNacosProperties());    &#125;    /**     * 创建监听器     */    @Override    public void listen(String serviceId, ServerEventHandler eventHandler) &#123;        try &#123;            namingService.subscribe(serviceId, event -&gt; &#123;                if (event instanceof NamingEvent) &#123;                    NamingEvent namingEvent = (NamingEvent) event;//                    log.info(&quot;服务名：&quot; + namingEvent.getServiceName());//                    log.info(&quot;实例：&quot; + namingEvent.getInstances());                    // 实际更新                    eventHandler.update();                &#125;            &#125;);        &#125; catch (NacosException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;</code></pre><h5 id="把自定义Updater注入bean"><a href="#把自定义Updater注入bean" class="headerlink" title="把自定义Updater注入bean"></a>把自定义Updater注入bean</h5><pre><code>@Configuration@ConditionalOnRibbonNacospublic class RibbonConfig &#123;    @Bean    public ServerListUpdater ribbonServerListUpdater(NacosServerListListener listener) &#123;        return new NotificationServerListUpdater(listener);    &#125;&#125;</code></pre><p>到此，大工告成，效果是gateway访问的某微服务停止后，调用马上503，启动后，马上可以调用</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本来想解决这个问题首先想到的是nacos或ribbon肯定留了扩展，比如说改了配置就可以平滑感知服务下线，但结果看了文档和源码，并没有发现对应的扩展点，所以只能大动干戈来解决问题，其实很多地方都觉得很粗暴，比如获取clientName，但也实在找不到更好的方案，如果谁知道，麻烦评论告诉我一下</p><p>实际上我的项目更新器还保留了定时任务刷新的逻辑，一来刚接触cloud对自己的修改自信不足，二来发现nacos的通知都是udp的通知方式，可能不可靠，不知道是否多余</p><p>nacos的监听主要使用namingService的subscribe方法，里面还有坑，还有一层缓存，以后细讲</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/70f4c2ce6ac8&quot;&gt;https://www.jianshu.com/p/70f4c2ce6ac8&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;h2 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述</summary>
      
    
    
    
    <category term="nacos" scheme="http://zhangyu.info/categories/nacos/"/>
    
    
    <category term="nacos" scheme="http://zhangyu.info/tags/nacos/"/>
    
  </entry>
  
  <entry>
    <title>从监控到可观测性，设计思想、技术选型、职责分工都有哪些变化</title>
    <link href="http://zhangyu.info/2022/05/01/%E4%BB%8E%E7%9B%91%E6%8E%A7%E5%88%B0%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7%EF%BC%8C%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%E3%80%81%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%E3%80%81%E8%81%8C%E8%B4%A3%E5%88%86%E5%B7%A5%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%E5%8F%98%E5%8C%96/"/>
    <id>http://zhangyu.info/2022/05/01/%E4%BB%8E%E7%9B%91%E6%8E%A7%E5%88%B0%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7%EF%BC%8C%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%E3%80%81%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%E3%80%81%E8%81%8C%E8%B4%A3%E5%88%86%E5%B7%A5%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%E5%8F%98%E5%8C%96/</id>
    <published>2022-04-30T16:00:00.000Z</published>
    <updated>2022-05-01T13:57:37.956Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.51cto.com/article/707455.html">https://www.51cto.com/article/707455.html</a></p><p><a href="https://www.51cto.com/article/707455.html">从监控到可观测性，设计思想、技术选型、职责分工都有哪些变化-51CTO.COM</a></p><blockquote><p>随着大量云原生技术的应用，IT系统日益复杂，主动感知、预测故障并迅速定位、排障的难度变得越来越大，传统监控方式已无法跟上需求，由此应运而生的可观测性，被视为未来云环境生产部署不可或缺的技术支撑。</p><p>目前大多数传统企业对可观测性仍处于初步了解阶段，不少互联网公司在可观测性建设上也是起步不久。因此，围绕“从监控到可观测性应如何转变与升级”这一话题，本期dbaplus话题接力专栏，特别采访到知乎全链路可观测系统和接入层网络负责人-熊豹、虎牙直播SRE平台研发团队负责人-匡凌轩、好大夫基础架构部高级工程师-方勇三位老师，希望能通过他们在可观测性领域的研究心得和实践经验，帮助广大技术从业者准确认识可观测性、给企业搭建适配自身发展的可观测体系提供建议和启发。</p><h3 id="Q1监控与可观测性是什么关系？有什么区别？可否从两者的关注点、应用场景、作用、局限性等方面进行解析？"><a href="#Q1监控与可观测性是什么关系？有什么区别？可否从两者的关注点、应用场景、作用、局限性等方面进行解析？" class="headerlink" title="Q1监控与可观测性是什么关系？有什么区别？可否从两者的关注点、应用场景、作用、局限性等方面进行解析？"></a>Q1监控与可观测性是什么关系？有什么区别？可否从两者的关注点、应用场景、作用、局限性等方面进行解析？</h3><h4 id="熊豹"><a href="#熊豹" class="headerlink" title="熊豹"></a>熊豹</h4><h4 id="“正在发生什么-与-为什么会这样”"><a href="#“正在发生什么-与-为什么会这样”" class="headerlink" title="“正在发生什么 与 为什么会这样”"></a>“正在发生什么 与 为什么会这样”</h4><p>监控是常见的运维手段，一般是指以观测系统的外部资源使用情况和接口表现来推测系统运行状态，即感知到“正在发生什么”。</p><p>可观测性是一种属性，是指在可以感知系统当前运行状态的性质，提升系统的可被观测的性质有助于我们了解“正在发生什么”以及“为什么会这样”。</p><p>云原生架构在业内逐步落地，给稳定性建设带来了更多新的挑战：迭代发布更迅速、业务系统更庞大、网络链路更复杂、运行环境更动态。在这样的混沌系统中仅仅只是知道问题发生是不够的，在这样纷繁复杂的环境下赤手空拳的我们很难去进行问题的追踪和溯源。我们要依托分层、多维度的观测数据来构建更立体和智能的诊断系统，以更多样的视角来观察和解读系统。</p><h4 id="匡凌轩"><a href="#匡凌轩" class="headerlink" title="匡凌轩"></a>匡凌轩</h4><h4 id="“可观测性更多是对业务应用系统自身的要求”"><a href="#“可观测性更多是对业务应用系统自身的要求”" class="headerlink" title="“可观测性更多是对业务应用系统自身的要求”"></a>“可观测性更多是对业务应用系统自身的要求”</h4><p>我认为监控是可观测性能力的一部分，初期监控主要是外部对业务应用系统的主动行为，运维是传统监控的使用主体，如：通过业务进程状态、系统资源等监控数据的分析和告警来发现问题。而现在可观测性更多是对业务应用系统自身的要求，如何设计去暴露出更多可被观测的应用运行时的数据，并为这些数据之间建立关联，如：微服务框架在请求处理和RPC调用时提供一些AOP扩展的设计，可以更方便地对请求进行Metric度量和Trace追踪，以及异常情况的上下文关联。</p><h4 id="方勇"><a href="#方勇" class="headerlink" title="方勇"></a>方勇</h4><h4 id="“从局部到全局可用性视角的延伸”"><a href="#“从局部到全局可用性视角的延伸”" class="headerlink" title="“从局部到全局可用性视角的延伸”"></a>“从局部到全局可用性视角的延伸”</h4><p>两者的关系：监控和可观测性都旨在辅助建设高可用的服务，缩短故障处理时长，两者往往是密切协作的，界限相对模糊。</p><p>两者的区别：监控往往关注告警触发的瞬时状态，一般围绕告警事件展开，涉及从告警事件的产生到应急响应等一系列动作。关注的视角一般是局部可用性，关注每个具体的监控项，如CPU负载、剩余内存等。监控是个老生常谈的话题，最常见的场景是系统资源监控、进程或服务状态的粗粒度监控。对定制化的业务指标监控不太友好，另外传统的监控体系对云原生的支持、对微服务体系监控的支持也不太友好。</p><p>可观测性可以看作是监控的一种延续，涉及面较广，包括全链路分析（APM）、业务服务质量（SLA）、业务容量等，聚焦服务的整体可用性。关注的视角一般是全局可用性，会忽略不影响服务质量的一些指标，如CPU负载高，服务整体时延波动不大就会忽略这个CPU负载指标。</p><p>可观测性的应用场景一般与业务能力相绑定，通过可视化聚合展示影响SLA的相关指标（SLI），再配合监控告警，通过可观测性看板下钻分析异常根因。另外可观测性打通Metrics/Traces/Logs后可主动识别出服务的潜在风险，能先于用户发现问题。</p><p>可观测性也有所局限，由于需要收集业务数据，对业务具有一定的侵入性，加上打造可视化平台投入成本较高。另外可观测性整体处于初期阶段，很多工具链还不太完善，价值预期其实是被高估了。</p><p>Q2从监控到可观测性都有哪些变化？对运维、开发、架构师等岗位人员分别提出了怎样的新要求？</p><h4 id="熊豹-1"><a href="#熊豹-1" class="headerlink" title="熊豹"></a>熊豹</h4><h4 id="“要把可观测性理念贯穿到架构和程序设计中”"><a href="#“要把可观测性理念贯穿到架构和程序设计中”" class="headerlink" title="“要把可观测性理念贯穿到架构和程序设计中”"></a>“要把可观测性理念贯穿到架构和程序设计中”</h4><p>目标不一样了，除了要知道“正在发生什么”，还要尝试解释“为什么会这样”。我们需要把可观测性的理念贯穿到架构和程序设计中，而不是到事发或事后再来补救。我们需要有意识地设计一些机制来观察业务指标的关联变化、系统架构的数据漏斗模型、程序内逻辑分支的运行开销、外部资源依赖的健康状态，还要暴露程序内的一些资源并发度、池的填充率和命中率、运行时的状态等情况，当运行错误时也要在错误信息中携带足量的上下文信息。</p><p>运维同学要为可观测场景提供更坚实的工具基础，在上述庞大的数据压力下，保障和解决数据存储和查询的性能、资源开销、集群的拓展性和稳定性等问题。</p><h4 id="匡凌轩-1"><a href="#匡凌轩-1" class="headerlink" title="匡凌轩"></a>匡凌轩</h4><h4 id="“从被动监控向主动发现与定位问题的转变”"><a href="#“从被动监控向主动发现与定位问题的转变”" class="headerlink" title="“从被动监控向主动发现与定位问题的转变”"></a>“从被动监控向主动发现与定位问题的转变”</h4><p>我认为最大的变化是应用系统自身角色的转变，从被动监控转向主动发现与定位问题，在设计应用系统架构之初就需要考虑到系统自身的可观测性建设。运维、开发、架构师都是各环节设计的参与者，在协作方式也有一定的改变：</p><ul><li>  运维：深入熟悉产品业务和应用服务，定义并关联业务指标、应用服务指标、系统资源指标等。</li><li>  开发：在框架层设计和实现对分布式应用服务运行时的Metric、Trace、Log数据采集。</li><li>  架构师：业务应用系统和可观测性系统的整体架构设计，需要关注无侵入式采集上报、多维度量聚合、错误寻根分析、整体海量数据处理和存储等。</li></ul><p>总体来说，需要各角色有更多跨技术领域的知识储备、业务思维和模型抽象能力。</p><h4 id="方勇-1"><a href="#方勇-1" class="headerlink" title="方勇"></a>方勇</h4><h4 id="“职责分工、认知意识、排障效率的转变和升级”"><a href="#“职责分工、认知意识、排障效率的转变和升级”" class="headerlink" title="“职责分工、认知意识、排障效率的转变和升级”"></a>“职责分工、认知意识、排障效率的转变和升级”</h4><p>个人认为主要变化有以下几个方面：</p><ul><li>  职责分工的转变，研发关注服务质量后，部分职责从运维侧开始迁移到研发侧。研发上线后不再当甩手掌柜，开始对自己的服务负责。</li><li>  认知意识的提高，从被动响应告警到主动提升服务质量。</li><li>  排障效率的提升，从原先的黑盒排障模式逐渐朝可视化发展。</li></ul><p>对不同岗位人员也有新的要求：</p><ul><li>  运维，需要摆脱传统监控的意识枷锁，拥抱云原生监控体系，同时和其他岗位人员达成共识，共建高可用服务。</li><li>  开发，接棒部分运维职责，聚焦服务可用性，需要有MDD（Metrics-Driven Developmen）的思想，建设具有高韧性的服务。</li><li>  架构师，在架构设计的过程中需要暴露可观测性的指标，同时需要提升数据分析的能力，建模分析Metrics/Traces/Logs数据，识别服务中潜在的风险。围绕可观测性打造相应的工具链及服务治理平台。</li></ul><h3 id="Q3可观测性的核心方法论-关键技术有哪些？"><a href="#Q3可观测性的核心方法论-关键技术有哪些？" class="headerlink" title="Q3可观测性的核心方法论/关键技术有哪些？"></a>Q3可观测性的核心方法论/关键技术有哪些？</h3><h4 id="熊豹-2"><a href="#熊豹-2" class="headerlink" title="熊豹"></a>熊豹</h4><h4 id="“数据的采集、存储、分析是核心关注点”"><a href="#“数据的采集、存储、分析是核心关注点”" class="headerlink" title="“数据的采集、存储、分析是核心关注点”"></a>“数据的采集、存储、分析是核心关注点”</h4><p>可观测性建设的核心关注点还是在数据的采集、存储、分析环节。</p><p>数据采集的覆盖可以以多种角度来看：可尝试梳理完整的数据链路，来覆盖从终端发起、网关、业务、基础设施中间的每一层组件；可以不同的观测视角进行覆盖，比如Metrics、Traces、Logs、Exception Collection、Profiler、Debuger、Changelog等类别的数据或能力都已建设齐备；可以多种维度来观察系统，比如业务维度、资源瓶颈、关联组件等维度进行覆盖的建设。</p><p>数据存储环节要关注多种类型数据的存储和查询系统选型。最为常见的是Metrics、Traces、Logs相关的存储系统，这三者都有非常广泛的基础软件选型。其中相对棘手的是指标维度爆炸、日志和Trace存储成本及性能相关的问题，一般需要搭配预聚合、前采样和后采样、存储分级等策略来解决。</p><p>数据分析环节要关联不同数据源的元信息，糅合以多维视角来构建查询界面。同时，我们也要关注如何在海量的原始数据中找到一些突出和异常的数据，一般需要建设一些流式检测和聚类分析的能力。</p><h4 id="匡凌轩-2"><a href="#匡凌轩-2" class="headerlink" title="匡凌轩"></a>匡凌轩</h4><h4 id="“采集数据，建立关联，设计模型”"><a href="#“采集数据，建立关联，设计模型”" class="headerlink" title="“采集数据，建立关联，设计模型”"></a>“采集数据，建立关联，设计模型”</h4><p>可观测性的核心思考：需要采集什么数据、如何建立关联、如何设计模型，我们以应用服务场景为例：</p><ul><li>  采集：请求量、耗时、错误和容量等，以及线程池、队列、连接池等资源指标。</li><li>  关联：纵向关联请求上下游链路和调用栈，横向关联请求和处理请求所消耗的应用资源。</li><li>  模型：数据采集和关联、异常定义和分析、全链路错误寻根三方面统一的模型化设计。</li></ul><p>以上可指导我们针对不同的业务应用系统进行合理抽象，建设更标准的可观测性能力。</p><h4 id="方勇-2"><a href="#方勇-2" class="headerlink" title="方勇"></a>方勇</h4><h4 id="“MDD思想主张指标驱动开发”"><a href="#“MDD思想主张指标驱动开发”" class="headerlink" title="“MDD思想主张指标驱动开发”"></a>“MDD思想主张指标驱动开发”</h4><p><strong>常用方法论：</strong></p><p>1、SLI选择：</p><ul><li>  参考Google VALET（Volume、Available、Latency、Error、Ticket）模型。</li><li>  Netflix的USE方法，USE是Utilization（使用率）、Saturation（饱和度）、Error（错误）。</li><li>  Weave Cloud的RED方法，Request-Rate（每秒接收的请求数）/Request-Errors（每秒失败的请求数）/Request-Duration（每个请求所花费的时间，用时间间隔表示）。</li></ul><p>2、MDD（Metrics-Driven Development）思想：MDD主张整个应用开发过程由指标驱动，通过实时指标来驱动快速、精确和细粒度的软件迭代。指标驱动开发的理念，不但可以让程序员实时感知生产状态，及时定位并终结问题，还可以帮助产品经理和运维人员一起关注相关的业务指标。</p><p><strong>关键技术：</strong></p><p>1、数据收集：如果是基于Prometheus生态，有丰富的Exporte可用，还可以自研相应的Exporter。如果基于文件日志收集，可考虑Flume、Fluentd等等。</p><p>2、数据分析：可基于Clickhouse SQL分析提炼日志指标，如果是Prometheus体系，也有丰富的PromQL可用来分析相关指标。针对Traces、Logs分析一般采用自研分析引擎，并与Metrics打通。</p><p>3、数据存储：Prometheus本身就是一款很好的时序数据库，但不支持分布式存储。一般采用远程存储引擎搭配使用，常用Clickhouse、InfluxDB等。Traces和Logs一般可采用Elasticsearch存储。</p><p>4、数据展示：数据最终呈现形式，需要契合可视化设计规划，支持上卷/下钻。大部分需求可采用Grafana呈现，Grafana提供了丰富的插件，支持丰富的数据库类型，也可基于Echarts自研。如果托管公有云，可充分利用公有云自有的体系，不过有些需要单独付费。</p><h3 id="Q4如何将Metrics、Traces、Logs三者打通并发挥最大价值？"><a href="#Q4如何将Metrics、Traces、Logs三者打通并发挥最大价值？" class="headerlink" title="Q4如何将Metrics、Traces、Logs三者打通并发挥最大价值？"></a>Q4如何将Metrics、Traces、Logs三者打通并发挥最大价值？</h3><h4 id="熊豹-3"><a href="#熊豹-3" class="headerlink" title="熊豹"></a>熊豹</h4><h4 id="“基于时间范围内的统计关系或Label和TraceID关联”"><a href="#“基于时间范围内的统计关系或Label和TraceID关联”" class="headerlink" title="“基于时间范围内的统计关系或Label和TraceID关联”"></a>“基于时间范围内的统计关系或Label和TraceID关联”</h4><p>我们已知的有两类方式：</p><p>1、基于时间范围内的统计关系：一般的使用习惯是在Metric异常的时间区间里去找到对应时间区间出现异常行为的Traces和Logs，这种方式会依赖对Traces和Logs的聚类分析能力。</p><p>2、基于Label和TraceID关联：基于OpenTelemetry Collector可观测数据采集的框架，我们可以以插件的形式、以Trace Span元数据Label来生成访问指标，也同时将TraceID携带记录到日志的元信息中，这样就能以同样的TraceID或Label维度进行关联查看了。另外当前Prometheus实现了一个exemplar特性可以将Metric与TraceID关联存储，这个设计也挺有意思的。</p><h4 id="匡凌轩-3"><a href="#匡凌轩-3" class="headerlink" title="匡凌轩"></a>匡凌轩</h4><h4 id="“全链路错误寻根是三者打通的最大价值”"><a href="#“全链路错误寻根是三者打通的最大价值”" class="headerlink" title="“全链路错误寻根是三者打通的最大价值”"></a>“全链路错误寻根是三者打通的最大价值”</h4><p>三者打通最大的价值是能做到全链路错误寻根，即从发现请求Metric指标异常，通过指标关联分析，并逐层下钻到明细Trace追踪和具体Error Log，全流程自动化从宏观到明细的错误发现和根因定位。</p><p>虎牙为三者统一设计了应用监控模型，包括应用服务的透明零成本SDK接入，三者数据自动采集和关联，以及在虎牙大型分布式系统充分实践的全链路错误寻根算法。就整体实践经验来说，最终业务价值在于帮助研发和运维提高了应用服务的排障和治理效率。</p><h4 id="方勇-3"><a href="#方勇-3" class="headerlink" title="方勇"></a>方勇</h4><h4 id="“打通后可立体、全息分析整个服务的可用性”"><a href="#“打通后可立体、全息分析整个服务的可用性”" class="headerlink" title="“打通后可立体、全息分析整个服务的可用性”"></a>“打通后可立体、全息分析整个服务的可用性”</h4><p>从投入成本（CapEx）、运维成本（OpEx）、响应能力（Reaction）、查问题的有效程度（Investigation）几个方面分析。Metrics、Logs、Traces具有以下特征：</p><p><img src="https://s5.51cto.com/oss/202204/26/794bc0a70ed8e615f8524332b2b26c8a70383d.jpg"></p><p>Logs和Traces一般采用trace_id打通，trace_id一般在端入口生成，贯穿整个请求的生命周期，业务记录Logs的时候可记录当前的trace_id，这样Logs和Traces就能打通了。</p><p>与Metrics打通一般是采用标签Tags模式，如某个服务servername产生的metrics可与Traces中的servername关联。</p><p>打通后可以服务名的维度，立体、全息分析整个服务的可用性。</p><h3 id="Q5可观测性工具如何选型？有通用的标准吗？"><a href="#Q5可观测性工具如何选型？有通用的标准吗？" class="headerlink" title="Q5可观测性工具如何选型？有通用的标准吗？"></a>Q5可观测性工具如何选型？有通用的标准吗？</h3><h4 id="熊豹-4"><a href="#熊豹-4" class="headerlink" title="熊豹"></a>熊豹</h4><h4 id="“高可用、可伸缩、降成本、易运维”"><a href="#“高可用、可伸缩、降成本、易运维”" class="headerlink" title="“高可用、可伸缩、降成本、易运维”"></a>“高可用、可伸缩、降成本、易运维”</h4><p>我们关注可观测工具系统的这些特性：</p><ul><li>  高可用：可观测系统作为稳定性的守卫者，本身要求更高的可靠性。</li><li>  可伸缩：我们关注存储写入和查询能力的可拓展性，以支持更大的数据量级。</li><li>  降成本：观测类数据会随着时间的推移逐渐失去价值，历史数据最好能低成本地失效或能对存储介质进行降级。</li><li>  易运维：拥有一定的自动化能力或者本身架构足够简单。</li></ul><h4 id="匡凌轩-4"><a href="#匡凌轩-4" class="headerlink" title="匡凌轩"></a>匡凌轩</h4><h4 id="“是否基于业界标准且方便扩展”"><a href="#“是否基于业界标准且方便扩展”" class="headerlink" title="“是否基于业界标准且方便扩展”"></a>“是否基于业界标准且方便扩展”</h4><p>虎牙主要是基于OpenTracing标准进行的深度自研和扩展，通过业界标准来做会有充分的开源代码和社区支持，可以节省很多基础代码的工作，让我们更关注自身的业务系统特性和模型设计。现在OpenTelemetry对Metrics、Traces、Logs三者提供了统一标准，开源社区热度也比较大，是个值得去研究和实践的方向。</p><p>可观测性工具选型建议可考虑两个方面：</p><ol><li> 是否基于业界标准，有更多社区和厂商支持。</li><li> 是否方便扩展，更容易把共性和个性结合，最终在此基础上建设符合自身业务特性的可观测性系统。</li></ol><h4 id="方勇-4"><a href="#方勇-4" class="headerlink" title="方勇"></a>方勇</h4><h4 id="“根据已有技术栈按需选择，不必盲从主流”"><a href="#“根据已有技术栈按需选择，不必盲从主流”" class="headerlink" title="“根据已有技术栈按需选择，不必盲从主流”"></a>“根据已有技术栈按需选择，不必盲从主流”</h4><p>可观测性分析整个技术栈可参考如下图：</p><p><img src="https://s7.51cto.com/oss/202204/26/79797fd850c3ff8d3dd2788ad4febc3662052a.jpg"></p><p>工具选型：</p><ul><li>  Metrics：常用Zabbix、Nagios、Prometheus，及相关高可用部署方案如Prometheus-operator、Thanos。</li><li>  Logging：ELK Stack、Fluentd、Loki等。</li><li>  Traceing：常用Jaeger、SkyWalking、Pinpoint、Zipkin、Spring Cloud Sleuth等。</li><li>  可视化：Grafana。</li></ul><p>其实技术选型没什么特定的标准，每个企业不同阶段可能有不同的选择，适合自己的才是最好的，这里总结几点心得：</p><ul><li>  控制成本预算，企业一般需要从自身的发展阶段实际情况考虑，不必一上来就整全链路可观测性，也许初期只用传统的Zabbix就满足需求了。理性按需选择，大可不必盲从主流。</li><li>  拥抱开源，初期一般采用开源产品，开箱即用，搭顺风车。另外，选型时还需要考虑周边生态的丰富度。</li><li>  根据团队技术栈选择，中间件、业务服务、云原生、物理机监控等选型都要贴合团队已有的技术栈。</li></ul></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://www.51cto.com/article/707455.html&quot;&gt;https://www.51cto.com/article/707455.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.51cto.com/a</summary>
      
    
    
    
    <category term="监控" scheme="http://zhangyu.info/categories/%E7%9B%91%E6%8E%A7/"/>
    
    
    <category term="监控" scheme="http://zhangyu.info/tags/%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot性能太差,教你几招轻松搞定</title>
    <link href="http://zhangyu.info/2022/04/30/SpringBoot%E6%80%A7%E8%83%BD%E5%A4%AA%E5%B7%AE,%E6%95%99%E4%BD%A0%E5%87%A0%E6%8B%9B%E8%BD%BB%E6%9D%BE%E6%90%9E%E5%AE%9A/"/>
    <id>http://zhangyu.info/2022/04/30/SpringBoot%E6%80%A7%E8%83%BD%E5%A4%AA%E5%B7%AE,%E6%95%99%E4%BD%A0%E5%87%A0%E6%8B%9B%E8%BD%BB%E6%9D%BE%E6%90%9E%E5%AE%9A/</id>
    <published>2022-04-29T16:00:00.000Z</published>
    <updated>2022-04-30T10:42:45.102Z</updated>
    
    <content type="html"><![CDATA[<p>SpringBoot性能太差,教你几招轻松搞定 </p><p>Java派 2022-04-30 09:27</p><p><a href="https://mp.weixin.qq.com/s/lreQia3XL5cl0XKrN47KCA">https://mp.weixin.qq.com/s/lreQia3XL5cl0XKrN47KCA</a></p><p><a href="https://mp.weixin.qq.com/s/lreQia3XL5cl0XKrN47KCA">Spring Boot性能太差，教你几招轻松搞定</a></p><blockquote><p><strong>目录</strong></p><ul><li><p>  异步执行</p></li><li><p>  增加内嵌 Tomcat 的最大连接数</p></li><li><p>  使用 @ComponentScan()</p></li><li><p>  默认 Tomcat 容器改为 Undertow</p></li><li><p>  使用 BufferedWriter 进行缓冲</p></li><li><p>  Deferred 方式实现异步调用</p></li><li><p>  异步调用可以使用 AsyncHandlerInterceptor 进行拦截</p></li></ul><p><strong>异步执行</strong></p><p>实现方式二种：</p><ul><li><p>  使用异步注解 @aysnc、启动类：添加 @EnableAsync 注解</p></li><li><p>  JDK 8 本身有一个非常好用的 Future 类——CompletableFuture</p></li></ul></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">@AllArgsConstructor</span><br><span class="line">public class AskThread implements Runnable&#123;</span><br><span class="line">    private CompletableFuture&lt;Integer&gt; re &#x3D; null;</span><br><span class="line">    public void run() &#123;</span><br><span class="line">        int myRe &#x3D; 0;</span><br><span class="line">        try &#123;</span><br><span class="line">            myRe &#x3D; re.get() * re.get();</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(myRe);</span><br><span class="line">    &#125;</span><br><span class="line">    public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">        final CompletableFuture&lt;Integer&gt; future &#x3D; new CompletableFuture&lt;&gt;();</span><br><span class="line">        new Thread(new AskThread(future)).start();</span><br><span class="line">        &#x2F;&#x2F;模拟长时间的计算过程</span><br><span class="line">        Thread.sleep(1000);</span><br><span class="line">        &#x2F;&#x2F;告知完成结果</span><br><span class="line">        future.complete(60);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>在该示例中，启动一个线程，此时 AskThread 对象还没有拿到它需要的数据，执行到  myRe = re.get() * re.get() 会阻塞。</p><p>我们用休眠 1 秒来模拟一个长时间的计算过程，并将计算结果告诉 future 执行结果，AskThread 线程将会继续执行。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public class Calc &#123;</span><br><span class="line">    public static Integer calc(Integer para) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            &#x2F;&#x2F;模拟一个长时间的执行</span><br><span class="line">            Thread.sleep(1000);</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        return para * para;</span><br><span class="line">    &#125;</span><br><span class="line">    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;</span><br><span class="line">        final CompletableFuture&lt;Void&gt; future &#x3D; CompletableFuture.supplyAsync(() -&gt; calc(50))</span><br><span class="line">                .thenApply((i) -&gt; Integer.toString(i))</span><br><span class="line">                .thenApply((str) -&gt; &quot;\&quot;&quot; + str + &quot;\&quot;&quot;)</span><br><span class="line">                .thenAccept(System.out::println);</span><br><span class="line">        future.get();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>CompletableFuture.supplyAsync 方法构造一个 CompletableFuture 实例，在 supplyAsync() 方法中，它会在一个新线程中，执行传入的参数。</p><p>在这里它会执行 calc() 方法，这个方法可能是比较慢的，但这并不影响 CompletableFuture 实例的构造速度，supplyAsync() 会立即返回。</p><p>而返回的 CompletableFuture 实例就可以作为这次调用的契约，在将来任何场合，用于获得最终的计算结果。</p><p>supplyAsync 用于提供返回值的情况，CompletableFuture 还有一个不需要返回值的异步调用方法 runAsync(Runnable runnable)，一般我们在优化 Controller 时，使用这个方法比较多。</p><p>这两个方法如果在不指定线程池的情况下，都是在 ForkJoinPool.common 线程池中执行，而这个线程池中的所有线程都是 Daemon（守护）线程，所以，当主线程结束时，这些线程无论执行完毕都会退出系统。</p><p>核心代码：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CompletableFuture.runAsync(() -&gt;</span><br><span class="line">   this.afterBetProcessor(betRequest,betDetailResult,appUser,id)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><blockquote><p>异步调用使用 Callable 来实现：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">@RestController  </span><br><span class="line">public class HelloController &#123;</span><br><span class="line">    private static final Logger logger &#x3D; LoggerFactory.getLogger(HelloController.class);</span><br><span class="line">    @Autowired  </span><br><span class="line">    private HelloService hello;</span><br><span class="line">    @GetMapping(&quot;&#x2F;helloworld&quot;)</span><br><span class="line">    public String helloWorldController() &#123;</span><br><span class="line">        return hello.sayHello();</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 异步调用restful</span><br><span class="line">     * 当controller返回值是Callable的时候，springmvc就会启动一个线程将Callable交给TaskExecutor去处理</span><br><span class="line">     * 然后DispatcherServlet还有所有的spring拦截器都退出主线程，然后把response保持打开的状态</span><br><span class="line">     * 当Callable执行结束之后，springmvc就会重新启动分配一个request请求，然后DispatcherServlet就重新</span><br><span class="line">     * 调用和处理Callable异步执行的返回结果， 然后返回视图</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;  </span><br><span class="line">    @GetMapping(&quot;&#x2F;hello&quot;)</span><br><span class="line">    public Callable&lt;String&gt; helloController() &#123;</span><br><span class="line">        logger.info(Thread.currentThread().getName() + &quot; 进入helloController方法&quot;);</span><br><span class="line">        Callable&lt;String&gt; callable &#x3D; new Callable&lt;String&gt;() &#123;</span><br><span class="line">            @Override  </span><br><span class="line">            public String call() throws Exception &#123;</span><br><span class="line">                logger.info(Thread.currentThread().getName() + &quot; 进入call方法&quot;);</span><br><span class="line">                String say &#x3D; hello.sayHello();</span><br><span class="line">                logger.info(Thread.currentThread().getName() + &quot; 从helloService方法返回&quot;);</span><br><span class="line">                return say;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        logger.info(Thread.currentThread().getName() + &quot; 从helloController方法返回&quot;);</span><br><span class="line">        return callable;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>异步调用的方式 WebAsyncTask：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">@RestController  </span><br><span class="line">public class HelloController &#123;</span><br><span class="line">    private static final Logger logger &#x3D; LoggerFactory.getLogger(HelloController.class);</span><br><span class="line">    @Autowired  </span><br><span class="line">    private HelloService hello;</span><br><span class="line">        &#x2F;**</span><br><span class="line">     * 带超时时间的异步请求 通过WebAsyncTask自定义客户端超时间</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;  </span><br><span class="line">    @GetMapping(&quot;&#x2F;world&quot;)</span><br><span class="line">    public WebAsyncTask&lt;String&gt; worldController() &#123;</span><br><span class="line">        logger.info(Thread.currentThread().getName() + &quot; 进入helloController方法&quot;);</span><br><span class="line">        &#x2F;&#x2F; 3s钟没返回，则认为超时</span><br><span class="line">        WebAsyncTask&lt;String&gt; webAsyncTask &#x3D; new WebAsyncTask&lt;&gt;(3000, new Callable&lt;String&gt;() &#123;</span><br><span class="line">            @Override  </span><br><span class="line">            public String call() throws Exception &#123;</span><br><span class="line">                logger.info(Thread.currentThread().getName() + &quot; 进入call方法&quot;);</span><br><span class="line">                String say &#x3D; hello.sayHello();</span><br><span class="line">                logger.info(Thread.currentThread().getName() + &quot; 从helloService方法返回&quot;);</span><br><span class="line">                return say;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        logger.info(Thread.currentThread().getName() + &quot; 从helloController方法返回&quot;);</span><br><span class="line">        webAsyncTask.onCompletion(new Runnable() &#123;</span><br><span class="line">            @Override  </span><br><span class="line">            public void run() &#123;</span><br><span class="line">                logger.info(Thread.currentThread().getName() + &quot; 执行完毕&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        webAsyncTask.onTimeout(new Callable&lt;String&gt;() &#123;</span><br><span class="line"></span><br><span class="line">            @Override  </span><br><span class="line">            public String call() throws Exception &#123;</span><br><span class="line">                logger.info(Thread.currentThread().getName() + &quot; onTimeout&quot;);</span><br><span class="line">                &#x2F;&#x2F; 超时的时候，直接抛异常，让外层统一处理超时异常</span><br><span class="line">                throw new TimeoutException(&quot;调用超时&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        return webAsyncTask;</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 异步调用，异常处理，详细的处理流程见MyExceptionHandler类</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;  </span><br><span class="line">    @GetMapping(&quot;&#x2F;exception&quot;)</span><br><span class="line">    public WebAsyncTask&lt;String&gt; exceptionController() &#123;</span><br><span class="line">        logger.info(Thread.currentThread().getName() + &quot; 进入helloController方法&quot;);</span><br><span class="line">        Callable&lt;String&gt; callable &#x3D; new Callable&lt;String&gt;() &#123;</span><br><span class="line"></span><br><span class="line">            @Override  </span><br><span class="line">            public String call() throws Exception &#123;</span><br><span class="line">                logger.info(Thread.currentThread().getName() + &quot; 进入call方法&quot;);</span><br><span class="line">                throw new TimeoutException(&quot;调用超时!&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        logger.info(Thread.currentThread().getName() + &quot; 从helloController方法返回&quot;);</span><br><span class="line">        return new WebAsyncTask&lt;&gt;(20000, callable);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p><strong>增加内嵌 Tomcat 的最大连接数</strong></p><h6 id=""><a href="#" class="headerlink" title=""></a></h6><h6 id="代码如下："><a href="#代码如下：" class="headerlink" title="代码如下："></a>代码如下：</h6></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">public class TomcatConfig &#123;</span><br><span class="line">    @Bean</span><br><span class="line">    public ConfigurableServletWebServerFactory webServerFactory() &#123;</span><br><span class="line">        TomcatServletWebServerFactory tomcatFactory &#x3D; new TomcatServletWebServerFactory();</span><br><span class="line">        tomcatFactory.addConnectorCustomizers(new MyTomcatConnectorCustomizer());</span><br><span class="line">        tomcatFactory.setPort(8005);</span><br><span class="line">        tomcatFactory.setContextPath(&quot;&#x2F;api-g&quot;);</span><br><span class="line">        return tomcatFactory;</span><br><span class="line">    &#125;</span><br><span class="line">    class MyTomcatConnectorCustomizer implements TomcatConnectorCustomizer &#123;</span><br><span class="line">        public void customize(Connector connector) &#123;</span><br><span class="line">            Http11NioProtocol protocol &#x3D; (Http11NioProtocol) connector.getProtocolHandler();</span><br><span class="line">            &#x2F;&#x2F;设置最大连接数</span><br><span class="line">            protocol.setMaxConnections(20000);</span><br><span class="line">            &#x2F;&#x2F;设置最大线程数</span><br><span class="line">            protocol.setMaxThreads(2000);</span><br><span class="line">            protocol.setConnectionTimeout(30000);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><h6 id="-1"><a href="#-1" class="headerlink" title=""></a></h6><p><strong>使用 @ComponentScan()</strong></p><h6 id="-2"><a href="#-2" class="headerlink" title=""></a></h6><h6 id="使用-ComponentScan-定位扫包比-SpringBootApplication-扫包更快。"><a href="#使用-ComponentScan-定位扫包比-SpringBootApplication-扫包更快。" class="headerlink" title="使用 @ComponentScan() 定位扫包比 @SpringBootApplication 扫包更快。"></a>使用 @ComponentScan() 定位扫包比 @SpringBootApplication 扫包更快。</h6><h6 id="-3"><a href="#-3" class="headerlink" title=""></a></h6><p><strong>默认 Tomcat 容器改为 Undertow</strong></p><h6 id="-4"><a href="#-4" class="headerlink" title=""></a></h6><h6 id="默认-Tomcat-容器改为-Undertow（Jboss-下的服务器，Tomcat-吞吐量-5000，Undertow-吞吐量-8000）"><a href="#默认-Tomcat-容器改为-Undertow（Jboss-下的服务器，Tomcat-吞吐量-5000，Undertow-吞吐量-8000）" class="headerlink" title="默认 Tomcat 容器改为 Undertow（Jboss 下的服务器，Tomcat 吞吐量 5000，Undertow 吞吐量 8000）"></a>默认 Tomcat 容器改为 Undertow（Jboss 下的服务器，Tomcat 吞吐量 5000，Undertow 吞吐量 8000）</h6></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;exclusions&gt;</span><br><span class="line">  &lt;exclusion&gt;</span><br><span class="line">     &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">     &lt;artifactId&gt;spring-boot-starter-tomcat&lt;&#x2F;artifactId&gt;</span><br><span class="line">  &lt;&#x2F;exclusion&gt;</span><br><span class="line">&lt;&#x2F;exclusions&gt;</span><br></pre></td></tr></table></figure><blockquote><p>改为：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;spring-boot-starter-undertow&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure><blockquote><p><strong>使用 BufferedWriter 进行缓冲</strong></p><p>这里不给大家举例，可自行尝试。</p><p><strong>Deferred 方式实现异步调用</strong></p><h6 id="代码如下：-1"><a href="#代码如下：-1" class="headerlink" title="代码如下："></a>代码如下：</h6></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">public class AsyncDeferredController &#123;</span><br><span class="line">    private final Logger logger &#x3D; LoggerFactory.getLogger(this.getClass());</span><br><span class="line">    private final LongTimeTask taskService;</span><br><span class="line">    @Autowired</span><br><span class="line">    public AsyncDeferredController(LongTimeTask taskService) &#123;</span><br><span class="line">        this.taskService &#x3D; taskService;</span><br><span class="line">    &#125;</span><br><span class="line">    @GetMapping(&quot;&#x2F;deferred&quot;)</span><br><span class="line">    public DeferredResult&lt;String&gt; executeSlowTask() &#123;</span><br><span class="line">        logger.info(Thread.currentThread().getName() + &quot;进入executeSlowTask方法&quot;);</span><br><span class="line">        DeferredResult&lt;String&gt; deferredResult &#x3D; new DeferredResult&lt;&gt;();</span><br><span class="line">        &#x2F;&#x2F; 调用长时间执行任务</span><br><span class="line">        taskService.execute(deferredResult);</span><br><span class="line">        &#x2F;&#x2F; 当长时间任务中使用deferred.setResult(&quot;world&quot;);这个方法时，会从长时间任务中返回，继续controller里面的流程</span><br><span class="line">        logger.info(Thread.currentThread().getName() + &quot;从executeSlowTask方法返回&quot;);</span><br><span class="line">        &#x2F;&#x2F; 超时的回调方法</span><br><span class="line">        deferredResult.onTimeout(new Runnable()&#123;</span><br><span class="line">   @Override</span><br><span class="line">   public void run() &#123;</span><br><span class="line">    logger.info(Thread.currentThread().getName() + &quot; onTimeout&quot;);</span><br><span class="line">    &#x2F;&#x2F; 返回超时信息</span><br><span class="line">    deferredResult.setErrorResult(&quot;time out!&quot;);</span><br><span class="line">   &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">        &#x2F;&#x2F; 处理完成的回调方法，无论是超时还是处理成功，都会进入这个回调方法</span><br><span class="line">        deferredResult.onCompletion(new Runnable()&#123;</span><br><span class="line">   @Override</span><br><span class="line">   public void run() &#123;</span><br><span class="line">    logger.info(Thread.currentThread().getName() + &quot; onCompletion&quot;);</span><br><span class="line">   &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">        return deferredResult;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><h6 id="-5"><a href="#-5" class="headerlink" title=""></a></h6><p><strong>异步调用可以使用 AsyncHandlerInterceptor 进行拦截</strong></p><h6 id="-6"><a href="#-6" class="headerlink" title=""></a></h6><h6 id="代码如下：-2"><a href="#代码如下：-2" class="headerlink" title="代码如下："></a>代码如下：</h6></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">@Component</span><br><span class="line">public class MyAsyncHandlerInterceptor implements AsyncHandlerInterceptor &#123;</span><br><span class="line"> private static final Logger logger &#x3D; LoggerFactory.getLogger(MyAsyncHandlerInterceptor.class);</span><br><span class="line"> @Override</span><br><span class="line"> public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)</span><br><span class="line">   throws Exception &#123;</span><br><span class="line">  return true;</span><br><span class="line"> &#125;</span><br><span class="line"> @Override</span><br><span class="line"> public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler,</span><br><span class="line">   ModelAndView modelAndView) throws Exception &#123;</span><br><span class="line">&#x2F;&#x2F; HandlerMethod handlerMethod &#x3D; (HandlerMethod) handler;</span><br><span class="line">  logger.info(Thread.currentThread().getName()+ &quot;服务调用完成，返回结果给客户端&quot;);</span><br><span class="line"> &#125;</span><br><span class="line"> @Override</span><br><span class="line"> public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex)</span><br><span class="line">   throws Exception &#123;</span><br><span class="line">  if(null !&#x3D; ex)&#123;</span><br><span class="line">   System.out.println(&quot;发生异常:&quot;+ex.getMessage());</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> @Override</span><br><span class="line"> public void afterConcurrentHandlingStarted(HttpServletRequest request, HttpServletResponse response, Object handler)</span><br><span class="line">   throws Exception &#123;</span><br><span class="line">  &#x2F;&#x2F; 拦截之后，重新写回数据，将原来的hello world换成如下字符串</span><br><span class="line">  String resp &#x3D; &quot;my name is chhliu!&quot;;</span><br><span class="line">  response.setContentLength(resp.length());</span><br><span class="line">  response.getOutputStream().write(resp.getBytes());</span><br><span class="line">  logger.info(Thread.currentThread().getName() + &quot; 进入afterConcurrentHandlingStarted方法&quot;);</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;SpringBoot性能太差,教你几招轻松搞定 &lt;/p&gt;
&lt;p&gt;Java派 2022-04-30 09:27&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/lreQia3XL5cl0XKrN47KCA&quot;&gt;https://mp.weix</summary>
      
    
    
    
    <category term="SpringBoot" scheme="http://zhangyu.info/categories/SpringBoot/"/>
    
    
    <category term="SpringBoot" scheme="http://zhangyu.info/tags/SpringBoot/"/>
    
  </entry>
  
  <entry>
    <title>API网关的功能用途及实现方式</title>
    <link href="http://zhangyu.info/2022/04/30/API%E7%BD%91%E5%85%B3%E7%9A%84%E5%8A%9F%E8%83%BD%E7%94%A8%E9%80%94%E5%8F%8A%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/"/>
    <id>http://zhangyu.info/2022/04/30/API%E7%BD%91%E5%85%B3%E7%9A%84%E5%8A%9F%E8%83%BD%E7%94%A8%E9%80%94%E5%8F%8A%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/</id>
    <published>2022-04-29T16:00:00.000Z</published>
    <updated>2022-04-30T08:52:54.499Z</updated>
    
    <content type="html"><![CDATA[<p>API网关的功能用途及实现方式 - 东风微鸣技术博客<br><a href="https://ewhisper.cn/posts/52291/">https://ewhisper.cn/posts/52291/</a></p><blockquote><h2 id="1-API-网关诞生背景"><a href="#1-API-网关诞生背景" class="headerlink" title="1. API 网关诞生背景"></a>1. API 网关诞生背景</h2><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>API 经济生态链已经在全球范围覆盖， 绝大多数企业都已经走在数字化转型的道路上，API 成为企业连接业务的核心载体， 并产生巨大的盈利空间。快速增长的 API 规模以及调用量，使得企业 IT 在架构上、模式上面临着更多的挑战。</p><h3 id="API-是什么"><a href="#API-是什么" class="headerlink" title="API 是什么"></a>API 是什么</h3><p>API 网关是一个服务器，是系统的唯一入口。从面向对象设计的角度看，它与外观模式类似。API 网关封装了系统内部架构，为每个客户端提供一个定制的 API。它可能还具有其它职责，如身份验证、监控、负载均衡、缓存、请求分片与管理、静态响应处理。API 网关方式的核心要点是，所有的客户端和消费端都通过统一的网关接入微服务，在网关层处理所有的非业务功能。通常，网关也是提供 REST/HTTP 的访问 API。服务端通过 API-GW 注册和管理服务。</p><h4 id="1-API-开放数量不断增加"><a href="#1-API-开放数量不断增加" class="headerlink" title="1. API 开放数量不断增加"></a>1. API 开放数量不断增加</h4><p>毋庸置疑，随着企业的数据化进展，微服务改造，不同领域的 API 层出不穷，早在 2014 年 ProgrammableWeb 便预测 API 矢量可达到 100,000 到 200,000，并会不断增长。API 开发数量的增加给边缘系统带来机会，也随即演变了 API 网关的出现。大规模的 API 管理系统成为核心的发展趋势。</p><p><a href="https://pic-cdn.ewhisper.cn/img/2021/08/25/56946b95ef344c0b542764b063961940-total-number-of-APis-growth-of-the-API-industry.png" title="The API Economy Disruption and the Business of APIs，Nordic APIs"><img src="https://pic-cdn.ewhisper.cn/img/2021/08/25/56946b95ef344c0b542764b063961940-total-number-of-APis-growth-of-the-API-industry.png" alt="The API Economy Disruption and the Business of APIs，Nordic APIs"></a></p><p><a href="https://pic-cdn.ewhisper.cn/img/2021/08/25/56946b95ef344c0b542764b063961940-total-number-of-APis-growth-of-the-API-industry.png" title="The API Economy Disruption and the Business of APIs，Nordic APIs">The API Economy Disruption and the Business of APIs，Nordic APIs</a></p><h4 id="2-API-服务平台多样化"><a href="#2-API-服务平台多样化" class="headerlink" title="2. API 服务平台多样化"></a>2. API 服务平台多样化</h4><p>最初的 API 主要针对不同单体应用的网络单元之间信息交互，现已演变到服务间快速通讯。随着人工智能 EI，IOT 的不断演进，依赖 API 的平台不断更新，如 Web，Mobile，终端等，未来将会出现更多的服务体系。包括不限于：</p><ul><li>  浏览器</li><li>  IOS</li><li>  Android</li><li>  macOS</li><li>  Windows</li><li>  Linux</li><li>  IOT</li><li>  其他移动端</li><li>  小程序</li><li>  终端设备（如智慧零售、工业的终端等）</li><li>  …</li></ul><p><a href="https://pic-cdn.ewhisper.cn/img/2021/08/25/7a9615fedf5505fd3fc6094d38af448d-20210825104220.png"><img src="https://pic-cdn.ewhisper.cn/img/2021/08/25/7a9615fedf5505fd3fc6094d38af448d-20210825104220.png"></a></p><h4 id="3-逐步替换原有企业的服务模式，API-即商品"><a href="#3-逐步替换原有企业的服务模式，API-即商品" class="headerlink" title="3. 逐步替换原有企业的服务模式，API 即商品"></a>3. 逐步替换原有企业的服务模式，API 即商品</h4><p>卖计算，卖软件，卖能力，最终的企业的销售模式会逐步转变，能力变现，释放数据价值，依托不同的 API 管理平台创造新的盈利。</p><h3 id="API-网关诞生背景"><a href="#API-网关诞生背景" class="headerlink" title="API 网关诞生背景"></a>API 网关诞生背景</h3><p>随着 API 的整体趋势发展，每个时期都面临着不同的挑战，架构也随之变化，具体如下图：</p><ol><li> 1960-1980：阿帕网、ATTP、TCP</li><li> 1980-1990：点对点</li><li> 1990-2000：消息中间件、ESB（企业服务总线，Enterprise service bus），SOA（面向服务的架构）</li><li> 2000 至今：Integration as a service，RESTful services，API 管理，云上编排</li></ol><p><a href="https://pic-cdn.ewhisper.cn/img/2021/08/25/e8fdff5629ec5d463b570ddeb01e8bb5-API-Infographic-Final.webp" title="API economy From systems to business services"><img src="https://pic-cdn.ewhisper.cn/img/2021/08/25/e8fdff5629ec5d463b570ddeb01e8bb5-API-Infographic-Final.webp" alt="API economy From systems to business services"></a></p><p><a href="https://pic-cdn.ewhisper.cn/img/2021/08/25/e8fdff5629ec5d463b570ddeb01e8bb5-API-Infographic-Final.webp" title="API economy From systems to business services">API economy From systems to business services</a></p><p>从最原始的“传输协议通讯” -&gt; “简单的接口集成” -&gt; “消息中间件” -&gt; “标准 REST”， 可以看到 API 的发展更趋向于简洁， 集成，规范化， 这也促使更多的系统边界组件不断涌现，在承载了万亿级的 API 经济的背景下， API 网关应运而生。</p><p>如果没有合适的 API 管理工具， API 经济不可能顺利开展。 同时提出了对于 API 管理系统的生命周期定义： planning（规划）, design（设计）， implementation（实施）， publication（发布），operation（运维）, consumption（消费）, maintenance（维护） and retirement of APIs（下架）</p><p>如果没有合适的 API 管理工具， API 经济不可能顺利开展。 同时提出了对于 API 管理系统的生命周期定义： planning（规划）, design（设计）， implementation（实施）， publication（发布），operation（运维）, consumption（消费）, maintenance（维护） and retirement of APIs（下架）</p><p>– <em>Magic Quadrant for Full Life Cycle API Management，Gartner, 2016-10-27</em></p><h2 id="2-API-网关核心功能"><a href="#2-API-网关核心功能" class="headerlink" title="2. API 网关核心功能"></a>2. API 网关核心功能</h2><ul><li>API 生命周期管理<ul><li>  planning（规划）</li><li>  design（设计）</li><li>  implementation（实施）</li><li>  publication（发布）</li><li>  operation（运维）</li><li>  consumption（消费）</li><li>  maintenance（维护）</li><li>  retirement（下架）</li></ul></li><li>API 网关基础功能<ul><li>  认证</li><li>  鉴权</li><li>  服务发现和集成</li><li>  负载均衡</li><li>  日志</li><li>  链路追踪</li><li>  监控</li><li>  重试</li><li>  限流</li><li>  QoS</li><li>  熔断器</li><li>  映射</li><li>  缓存</li><li>  Header、query 字符串 等 转义</li><li>  API 文档</li><li>  API 测试</li><li>  SDK 生成</li></ul></li><li>  API 多版本、多环境管理</li><li>  插件</li><li>  API 集中式 metrics、logging、tracing 管理</li><li>安全<ul><li>  HTTPS</li><li>  IP 黑白名单</li></ul></li><li>高可用<ul><li>  可热重启</li></ul></li><li>  高性能</li><li>可扩展性<ul><li>  无状态横向扩展</li></ul></li></ul><h2 id="3-API-网关的用途"><a href="#3-API-网关的用途" class="headerlink" title="3. API 网关的用途"></a>3. API 网关的用途</h2><h3 id="OpenAPI"><a href="#OpenAPI" class="headerlink" title="OpenAPI"></a>OpenAPI</h3><p>企业需要将自身数据、能力等作为开发平台向外开放，通常会以 rest 的方式向外提供。最好的例子就是淘宝开放平台、腾讯公司的 QQ 开发平台、微信开放平台。</p><p>Open API 开放平台必然涉及到客户应用的接入、API 权限的管理、调用次数管理等，必然会有一个统一的入口进行管理，这正是 API 网关可以发挥作用的时候。</p><h3 id="微服务网关"><a href="#微服务网关" class="headerlink" title="微服务网关"></a>微服务网关</h3><p>在微服务架构中，有一个组件可以说是必不可少的，那就是微服务网关，微服务网关处理了负载均衡，缓存，路由，访问控制，服务代理，监控，日志等。</p><p>API 网关在微服务架构中正是以微服务网关的身份存在。</p><h3 id="API-中台"><a href="#API-中台" class="headerlink" title="API 中台"></a>API 中台</h3><p>上述的微服务架构对企业来说有可能实施上是困难的，企业有很多遗留系统，要全部抽取为微服务改动太大，对企业来说成本太高。</p><p>但是由于不同系统间存在大量的 API 服务互相调用，因此需要对系统间服务调用进行管理，清晰地看到各系统调用关系，对系统间调用进行监控等。</p><p>API 网关可以解决这些问题，我们可以认为如果没有大规模的实施微服务架构，那么对企业来说微服务网关就是企业的 API 中台。</p><h2 id="4-API-网关的价值"><a href="#4-API-网关的价值" class="headerlink" title="4. API 网关的价值"></a>4. API 网关的价值</h2><p>通过 API 网关，可以封装后端各种服务，以 API 的形式，提供给各方使用。API 网关产品的优势总结如下：</p><ul><li>  API 全生命周期管理：协助开发者轻松完成 API 的创建、维护、发布、监控等整个生命周期的管理。</li><li>  丰富的服务治理能力：支持 API 限流，参数校验，元数据维护，SDK 生成，批量操作等能力，协助开发者高效管理服务。</li><li>  可观察性：通过 API 网关，支持对调用次数，前后端错误次数等丰富监控指标的可视和告警能力；通过全面的监控告警，保证用户服务的可用性。</li><li>  可运营性：支持 企业 OpenAPI 定价，账单等运营功能</li><li>  服务安全：通过接入多种认证方式，确保用户 API 的访问安全性；通过严格的流量控制，避免用户服务的过载。</li><li>  前后端业务解耦</li><li>  多类型后端打通</li></ul><h2 id="5-API-网关的实现方式"><a href="#5-API-网关的实现方式" class="headerlink" title="5. API 网关的实现方式"></a>5. API 网关的实现方式</h2><h3 id="主流-API-网关"><a href="#主流-API-网关" class="headerlink" title="主流 API 网关"></a>主流 API 网关</h3><ul><li>  Istio</li><li>  Linkerd</li><li>  NGINX 及其商业版</li><li>  KONG</li><li>  Traefik</li><li>  APISIX</li><li>  RedHat 3scale</li><li>  Netflix Zuul</li><li>  Spring Cloud Gateway</li><li>  Amazon API Gateway</li><li>  阿里云 API 网关</li><li>  腾讯云 API 网关</li><li>  MuleSoft</li></ul><h3 id="OpenAPI-1"><a href="#OpenAPI-1" class="headerlink" title="OpenAPI"></a>OpenAPI</h3><p>对于定位 OpenAPI 平台的 API 网关，目前只能选择专业的 API 网关作为解决方案。</p><h3 id="微服务网关-1"><a href="#微服务网关-1" class="headerlink" title="微服务网关"></a>微服务网关</h3><p>对于定位为「微服务网关」的 API 网关，业务有多种实现方式：</p><h4 id="Service-Mesh"><a href="#Service-Mesh" class="headerlink" title="Service Mesh"></a>Service Mesh</h4><p>典型的如 Istio，架构如下：</p><p><a href="https://pic-cdn.ewhisper.cn/img/2021/08/25/942a1801e1aa084b7301e0afedcb05d2-service_mesh_5.png"><img src="https://pic-cdn.ewhisper.cn/img/2021/08/25/942a1801e1aa084b7301e0afedcb05d2-service_mesh_5.png"></a><br><a href="https://pic-cdn.ewhisper.cn/img/2021/08/25/7a65f5e28f37fa8cb670d84618bb113d-service_mesh_2.png"><img src="https://pic-cdn.ewhisper.cn/img/2021/08/25/7a65f5e28f37fa8cb670d84618bb113d-service_mesh_2.png"></a></p><h4 id="通用反向代理"><a href="#通用反向代理" class="headerlink" title="通用反向代理"></a>通用反向代理<a href="https://ewhisper.cn/posts/52291/#%E9%80%9A%E7%94%A8%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86"></a></h4><p>基于 NGINX 或 NGINX + LUA + OpenResty 的实现。典型如：</p><ul><li><a href="https://www.nginx.com/">Nginx 及其 商业版</a><ul><li>  NGINX Controller（API 管理、App 交付）</li><li>  NGINX Plus（API Gateway，负载均衡，仪表板）</li><li>  NGINX Ingress Controller</li><li>  NGINX Service Mesh</li></ul></li><li>  <a href="https://github.com/Kong/kong">KONG</a></li><li>  <a href="https://doc.traefik.io/traefik/">Traefik</a></li><li>  <a href="https://www.redhat.com/en/technologies/jboss-middleware/3scale">3scale</a></li></ul><h4 id="API-网关框架"><a href="#API-网关框架" class="headerlink" title="API 网关框架"></a>API 网关框架</h4><ul><li>  <a href="https://github.com/Netflix/zuul">Netflix Zuul</a>，zuul 是 spring cloud 的一个推荐组件</li><li>  <a href="https://spring.io/projects/spring-cloud-gateway">Spring Cloud Gateway</a></li></ul><h4 id="公有云解决方案"><a href="#公有云解决方案" class="headerlink" title="公有云解决方案"></a>公有云解决方案</h4><p>其实公有云的解决方案也是基于以上方案的定制化开发并产品化后发布到公有云上，主流的也是基于：NGINX + LUA + OpenResty 的实现</p><ul><li>  <a href="https://aws.amazon.com/cn/api-gateway/">Amazon API Gateway</a></li><li>  <a href="https://www.aliyun.com/product/apigateway/">阿里云 API 网关</a></li><li>  <a href="https://cloud.tencent.com/product/apigateway">腾讯云 API 网关</a></li></ul><h4 id="其他方案"><a href="#其他方案" class="headerlink" title="其他方案"></a>其他方案</h4><ul><li>  基于 Netty、非阻塞 IO 模型。</li><li>  基于 Node.js 的方案。这种方案是应用了 Node.js 的非阻塞的特性。</li><li>  基于 Java，如 <a href="https://docs.mulesoft.com/general/">MuleSoft</a></li></ul></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;API网关的功能用途及实现方式 - 东风微鸣技术博客&lt;br&gt;&lt;a href=&quot;https://ewhisper.cn/posts/52291/&quot;&gt;https://ewhisper.cn/posts/52291/&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;h2 id=&quot;1-</summary>
      
    
    
    
    <category term="API网关" scheme="http://zhangyu.info/categories/API%E7%BD%91%E5%85%B3/"/>
    
    
    <category term="API网关" scheme="http://zhangyu.info/tags/API%E7%BD%91%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>基于容器的PaaS混合云的几种形式</title>
    <link href="http://zhangyu.info/2022/04/30/%E5%9F%BA%E4%BA%8E%E5%AE%B9%E5%99%A8%E7%9A%84PaaS%E6%B7%B7%E5%90%88%E4%BA%91%E7%9A%84%E5%87%A0%E7%A7%8D%E5%BD%A2%E5%BC%8F/"/>
    <id>http://zhangyu.info/2022/04/30/%E5%9F%BA%E4%BA%8E%E5%AE%B9%E5%99%A8%E7%9A%84PaaS%E6%B7%B7%E5%90%88%E4%BA%91%E7%9A%84%E5%87%A0%E7%A7%8D%E5%BD%A2%E5%BC%8F/</id>
    <published>2022-04-29T16:00:00.000Z</published>
    <updated>2022-04-30T09:25:35.098Z</updated>
    
    <content type="html"><![CDATA[<p> 基于容器的 PaaS 混合云的几种形式 - 东风微鸣技术博客<br><a href="https://ewhisper.cn/posts/57201/">https://ewhisper.cn/posts/57201/</a>) </p><blockquote><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>这是 Gartner 的一个图，提供了全球的基于容器的 PaaS 公有云、混合云服务的梳理展示：<br><a href="https://pic-cdn.ewhisper.cn/img/2021/09/17/a11d88b4ce770c547025af0bee5102bb-v2-c3e894db6f71442f6f959b09f8ed5cc1_b.jpeg"><img src="https://pic-cdn.ewhisper.cn/img/2021/09/17/a11d88b4ce770c547025af0bee5102bb-v2-c3e894db6f71442f6f959b09f8ed5cc1_b.jpeg"></a></p><p>这里提供一个其他的视角：<br>中国市场，基于容器的 PaaS 混合云（公有云 + 私有云）的相关厂商及产品。</p><p>❗️ 注意：</p><p>文章目前还是初版，只是厂商和产品的一个简单罗列，后面会进一步细化。<br>另外由于作者认知所限，无法罗列所有相关厂商和产品。请见谅。</p><h2 id="软件-容器平台"><a href="#软件-容器平台" class="headerlink" title="软件 - 容器平台"></a>软件 - 容器平台</h2><p>指的是通过售卖软件形式提供的容器平台（可能的售卖方式包括: 买断 + 维保；订阅），供应商不提供算力。<br>这里的「容器平台」指的是：基于 Kubernetes 的容器平台，有的容器平台会提供更丰富的功能，如：镜像仓库，监控，日志，Tracing，DevOps，微服务治理，ServiceMesh、Servless 等</p><ol><li> RedHat - OpenShift Container Platform</li><li> Rancher - RKE</li><li> 青云 - Kubesphere</li><li> 时速云 - TCS（TenxCloud Container Service）</li><li> 灵雀云 - ACP（Alauda Container Platform）</li><li> 博云 - BeyondContainer</li><li> DaoCLoud - DaoCloud Enterprise</li><li> 腾讯 - TKE Enterprise（基于灵雀云）</li><li> VMware - VSphere 7+</li></ol><h2 id="软件-多云容器管理平台"><a href="#软件-多云容器管理平台" class="headerlink" title="软件 - 多云容器管理平台"></a>软件 - 多云容器管理平台</h2><p>指的是通过售卖软件形式提供的多云容器管理平台（可能的售卖方式包括: 买断 + 维保；订阅），供应商不提供算力。<br>这里的「多云容器管理平台」指的是：基于 Kubernetes 的容器平台，或基于 Kubernetes 联邦（如华为 MCP），或基于自研多集群能力（如 Rancher），实现对异构、公有云及私有云的 Kubernetes 集群的纳管、甚至安装、运维、统一监控等能力。</p><p>❗️ 注意：</p><p>这类「多云容器管理平台」虽然可以纳管异构 Kubernetes 集群，但是某些高级功能，只有使用供应商推荐的 Kubernetes 产品才能使用。<br>如：Rancher 的安装、监控、日志等高级功能；RedHat 的安装、安全策略、GitOps 等功能</p><h3 id="优劣"><a href="#优劣" class="headerlink" title="优劣"></a>优劣</h3><p>优势：</p><ul><li>  灵活</li><li>  适用于：全内网环境（对于安全级别要求高的如金融行业会非常关注）</li></ul><p>劣势：</p><ul><li>  购买方需要提供硬件</li><li>  需要安装搭建，无法开箱即用</li></ul><h3 id="供应商及产品"><a href="#供应商及产品" class="headerlink" title="供应商及产品"></a>供应商及产品</h3><ol><li> Rancher - Rancher</li><li> 华为 - MCP（多云容器平台）</li><li> DaoCloud - DaoCloud Service Platform</li><li> RedHat - ACM（Advanced Cluster Management for Kubernetes）</li><li> 青云 - Kubesphere（<a href="https://kubesphere.com.cn/docs/multicluster-management/">Kubesphere 3.0 以后支持多集群管理</a>）</li><li> VMware - Tanzu</li></ol><h2 id="托管-公有云托管-K8S-集群"><a href="#托管-公有云托管-K8S-集群" class="headerlink" title="托管 - 公有云托管 K8S 集群"></a>托管 - 公有云托管 K8S 集群</h2><p>指的是公有云提供的 K8S 集群，提供公有云算力，也提供托管 Kubernetes 服务。计费方式为：按量计费或包年包月等。</p><p>✍️ 备注：</p><p>暂不包括公有云实例服务及 Servless 服务。</p><ol><li> Amazon - EKS（Elastic Kubernetes Service）</li><li> 阿里 - ACK（Alibaba Cloud Container Service for Kubernetes）</li><li> 腾讯 - TKE（Tencent Kubernetes Engine）</li><li> 微软 - AKS（Azure Kubernetes Service）</li><li> 华为 - CCE（云容器引擎）</li><li> 青云 - QKE（KubeSphere on QingCloud）</li></ol><h2 id="软件-公有云-K8S-集群产品私有化输出"><a href="#软件-公有云-K8S-集群产品私有化输出" class="headerlink" title="软件 - 公有云 K8S 集群产品私有化输出"></a>软件 - 公有云 K8S 集群产品私有化输出</h2><p>指的是通过售卖软件形式提供的和公有云架构类似的「公有云 K8S 集群产品私有化输出」（可能的售卖方式包括: 买断 + 维保；订阅），供应商不提供算力。</p><ol><li> 华为 - CCE（云容器引擎）</li><li> 阿里 - 阿里飞天专有云敏捷版</li><li> 腾讯 - TCS（Tencent Cloud-Native Suite）</li></ol><h2 id="托管-公有云多云容器管理平台"><a href="#托管-公有云多云容器管理平台" class="headerlink" title="托管 - 公有云多云容器管理平台"></a>托管 - 公有云多云容器管理平台</h2><p>指的是公有云提供的 多云容器管理平台，提供公有云算力，也提供管理 Kubernetes 服务。计费方式为：按量计费或包年包月等。<br>但是有个前提：如果是私有云 Kubernetes 集群或其他公有云提供商的 Kubernetes 集群，必须通过专线或互联网等形式与供应商网络联通。</p><h3 id="优劣-1"><a href="#优劣-1" class="headerlink" title="优劣"></a>优劣</h3><p>优势：</p><ul><li>  标准化产品，灵活性欠缺</li><li>  适用于：互联网环境</li><li>  按需付费</li><li>  开箱即用</li></ul><p>劣势：</p><ul><li>  无法纳管 没有互联网或连接公有云专线的 Kubernetes 集群</li><li>  安全性担忧</li><li>  <strong>对于被纳管集群的要求较多</strong>（如：EKS Anywhere 目前仅支持两种特定 Kubernetes 集群的纳管）</li></ul><h3 id="供应商及产品-1"><a href="#供应商及产品-1" class="headerlink" title="供应商及产品"></a>供应商及产品</h3><ol><li> 华为 - MCP（多云容器平台）</li><li> 腾讯 - <a href="https://mp.weixin.qq.com/s/aERPT13Rs_xgAnrOz2mmvg">TKE Everywhere</a>（❗️ 注意：这个和其他 2 家的 Anywhere 还不太一样，云上云下是 <strong>一个</strong> 集群，云下的 Node 由云上的 Master 纳管。本质上是一个边缘容器管理方案。而且还在内测中。）</li><li> Amazon - <a href="https://aws.amazon.com/cn/eks/eks-anywhere/">EKS Anywhere</a></li><li> 阿里云 - <a href="https://www.aliyun.com/product/kubernetes">AKS Anywhere</a></li></ol><p>🧠 <strong>思考：2 家 xxx Anywhere 具体是啥做法？</strong></p><p>2 家的 Anywhere 做法是极为一致的。本质上就是「公有云私有化，线上线下我全都要」。优势是：（兼听则明啊，经过实战检验才知道效果如何…）</p><ul><li>一致体验<ul><li>  统一集群管理</li><li>  统一资源调度</li><li>  统一数据容灾</li><li>  统一应用交付</li></ul></li><li>  弹性算力</li><li>能力下沉<ul><li>  云原生可观测</li><li>  安全防护能力</li><li>  中间件</li><li>  数据库</li><li>  数据分析</li><li>  AI</li></ul></li><li>  简化容灾</li></ul><p>以阿里云为例：<br>阿里云推出了一云多形态的部署架构，提供中心云、本地云、边缘云、云盒等多种部署形态，ACKAnywhere 的全面升级意味着公共云能力向本地化进一步延伸，客户在自建的数据中心内也能体验到低成本、低延迟、本地化的公共云产品。<br>随着云计算的普及和云原生技术的发展，容器服务已成为各大公司上云用云的必备基础设施。…此次升级的 ACK Anywhere 拥有「一致体验、弹性算力、能力下沉、简化容灾」四大核心能力，使企业在任何业务场景下使用容器服务时，都能实现「统一集群管理、统一资源调度、统一数据容灾和统一应用交付」。<br>得益于阿里云公共云丰富的产品能力，ACK Anywhere 可将成熟的云原生可观测、安全防护能力部署到用户环境，更可以将云端先进的中间件、数据分析和 AI 能力下沉到本地，满足客户对于产品丰富度以及数据管控的需求，加速业务创新。</p><p>业务连续性是现代企业 IT 架构关注的重点，ACK Anywhere 内建的备份中心，实现了备份、容灾、迁移一体化；支持 Kubernetes 集群配置与数据卷的备份恢复。结合阿里云丰富的业务多活容灾经验，帮助企业全面提升系统稳定性和业务连续性。</p><p>❗️ 注意：</p><p>由于上面所说的原因：「对于被纳管集群的要求较多」，所以这类产品往往也会推荐用户安装自己提供的 Kubernetes 产品，如：华为的 CCE，腾讯的 TKE 开源版，或 Amazon EKS Anywhere 的 <a href="https://aws.amazon.com/cn/eks/eks-distro/">EKS Distro</a> 产品，或阿里云的 ACK Distro。</p><h2 id="其他玩家"><a href="#其他玩家" class="headerlink" title="其他玩家"></a>其他玩家</h2><ol><li> 京东云</li><li> UCloud</li><li> 百度云</li><li> 金山云</li></ol></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; 基于容器的 PaaS 混合云的几种形式 - 东风微鸣技术博客&lt;br&gt;&lt;a href=&quot;https://ewhisper.cn/posts/57201/&quot;&gt;https://ewhisper.cn/posts/57201/&lt;/a&gt;) &lt;/p&gt;
&lt;blockquote&gt;
&lt;h2</summary>
      
    
    
    
    <category term="PaaS" scheme="http://zhangyu.info/categories/PaaS/"/>
    
    
    <category term="PaaS" scheme="http://zhangyu.info/tags/PaaS/"/>
    
  </entry>
  
  <entry>
    <title>打破Dockershim移除焦虑,且看Rancher如何应对</title>
    <link href="http://zhangyu.info/2022/04/30/%E6%89%93%E7%A0%B4Dockershim%E7%A7%BB%E9%99%A4%E7%84%A6%E8%99%91,%E4%B8%94%E7%9C%8BRancher%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9/"/>
    <id>http://zhangyu.info/2022/04/30/%E6%89%93%E7%A0%B4Dockershim%E7%A7%BB%E9%99%A4%E7%84%A6%E8%99%91,%E4%B8%94%E7%9C%8BRancher%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9/</id>
    <published>2022-04-29T16:00:00.000Z</published>
    <updated>2022-04-30T14:43:29.818Z</updated>
    
    <content type="html"><![CDATA[<p>打破 Dockershim 移除焦虑，且看 Rancher 如何应对<br><a href="https://mp.weixin.qq.com/s/swhQtu0pb_1AwQtMfTyd9Q">https://mp.weixin.qq.com/s/swhQtu0pb_1AwQtMfTyd9Q</a></p><blockquote><p><strong>前 言</strong></p><p>早在 2020 年 12 月，Kubernetes 就宣布将要弃用 Dockershim（<a href="https://kubernetes.io/blog/2020/12/02/dont-panic-kubernetes-and-docker/%EF%BC%89%E3%80%82%E5%9C%A8">https://kubernetes.io/blog/2020/12/02/dont-panic-kubernetes-and-docker/）。在</a> Kubernetes 中，Dockershim 是一个适配器组件，Dockershim 适配器允许 Kubelet 与 Docker 交互，就好像 Docker 是一个与 CRI 兼容的运行时一样。</p><p>Kubernetes 即将发布的 v1.24 版本最主要的变化就是删除了 Dockershim（<a href="https://github.com/kubernetes/enhancements/issues/2221%EF%BC%89%E3%80%82%E4%B9%9F%E5%B0%B1%E6%98%AF%E8%AF%B4%EF%BC%8CKubernetes">https://github.com/kubernetes/enhancements/issues/2221）。也就是说，Kubernetes</a> v1.24 无法再通过 in-tree 的形式来支持 Docker 作为它的 CRI 运行时。</p><p>随着 Kubernetes 的发展， 虽然 Docker 日渐式微，但还是有大量用户群体离不开 Docker，或者说暂时无法切换到 containerd 或 CRI-O 作为它的 CRI 运行时。 Rancher 为了满足继续使用 Docker 作为 CRI 运行时的需求，通过 RKE 集群支持外部 Dockershim 继续使用 Docker 作为 CRI 运行时。</p><p>虽然 Rancher 最新的 v2.6.4 目前还不支持 Kubernetes v1.24，但早在 Kubernetes v1.21 中就采用了 Mirantis 和 Docker 宣布的上游开源社区外部 Dockershim （该项目称为 cri-dockerd：<a href="https://github.com/kubernetes/enhancements/issues/2221%EF%BC%89%E6%9D%A5%E7%A1%AE%E4%BF%9D">https://github.com/kubernetes/enhancements/issues/2221）来确保</a> RKE 集群可以继续使用 Docker。换句话说，你可以像之前一样继续基于 Docker Engine 构建 Kubernetes，唯一的区别就是 Dockershim 由内置方案变成了外部方案。</p><p>要启用外部 Dockershim，只需要在 RKE 配置中设置以下选项：</p><pre><code>enable_cri_dockerd: true    </code></pre><p>由于外部 Dockershim 的支持是从 RKE 创建的 Kubernetes 1.21 及以上的版本中开始支持，所以我们需要通过 RKE 创建一个 Kubernetes 1.21 及以上的 Kubernetes 版本才能支持这种方案。  </p><p>下面将演示如何在 RKE 创建的 Kubernetes 集群中启用外部 Dockershim。</p><p><strong>通过 RKE CLI 创建集群</strong></p><p>说明：</p><ul><li><p>  RKE 的安装及使用，请参考官方文档（<a href="http://docs.rancher.cn/rke%EF%BC%89%EF%BC%8C">http://docs.rancher.cn/rke），</a> 这里不再详细说明。</p></li><li><p>  本次 demo 使用的 RKE 版本为 `v1.3.9`。</p></li></ul><p><strong>配置RKE cluster.yml 文件</strong></p><p>在 RKE 的集群配置文件 cluster.yml 中通过增加  enable_cri_dockerd: true  选项来启用外部 Dockershim 支持。本例使用最精简文件示例，如需个性化设置，请根据需求调整选项：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">~$ cat cluster.yml</span><br><span class="line">nodes:</span><br><span class="line">  - address: 192.168.205.19</span><br><span class="line">    user: ubuntu</span><br><span class="line">    role:</span><br><span class="line">      - controlplane</span><br><span class="line">      - etcd</span><br><span class="line">      - worker</span><br><span class="line">enable_cri_dockerd: true</span><br></pre></td></tr></table></figure><blockquote><p><strong>通过 RKE 创建 Kubernetes 集群</strong></p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">~$ rke up</span><br><span class="line">INFO[0000] Running RKE version: v1.3.9</span><br><span class="line">INFO[0000] Initiating Kubernetes cluster</span><br><span class="line">INFO[0000] cri-dockerd is enabled for cluster version [v1.22.7-rancher1-2]</span><br><span class="line">INFO[0000] [certificates] GenerateServingCertificate is disabled, checking if there are unused Kubelet certificates</span><br><span class="line">INFO[0000] [certificates] Generating admin certificates and kubeconfig</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">INFO[1130] [ingress] ingress controller nginx deployed successfully</span><br><span class="line">INFO[1130] [addons] Setting up user addons</span><br><span class="line">INFO[1130] [addons] no user addons defined</span><br><span class="line">INFO[1130] Finished building Kubernetes cluster successfully</span><br></pre></td></tr></table></figure><blockquote><p><strong>确认启用 cri-dockerd</strong>  </p><p>集群创建成功后，连接到下游集群的主机查看进程，可以发现增加了一个 cri-dockerd 的进程：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@dev-1:~# ps -ef | grep cri-dockerd</span><br><span class="line">root     26211 25813  3 11:26 ?        00:04:13 &#x2F;opt&#x2F;rke-tools&#x2F;bin&#x2F;cri-dockerd --network-plugin&#x3D;cni --cni-conf-dir&#x3D;&#x2F;etc&#x2F;cni&#x2F;net.d --cni-bin-dir&#x3D;&#x2F;opt&#x2F;cni&#x2F;bin --pod-infra-container-image&#x3D;rancher&#x2F;mirrored-pause:3.6</span><br></pre></td></tr></table></figure><blockquote><p>Cri-dockerd 其实就是从被移除的 Dockershim 中，独立出来的一个项目。为 Docker Engine 提供了一个垫片（shim），可以通过 Kubernetes CRI 控制 Docker。这意味着你可以像以前一样继续基于 Docker Engine 构建 Kubernetes，只需从内置的 Dockershim 切换到外部的 Dockershim 即可。</p><p>接下来，我们再观察 Kubelet 的参数变化：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@dev-1:~# docker inspect kubelet</span><br><span class="line">            &quot;Entrypoint&quot;: [</span><br><span class="line">                ...</span><br><span class="line">                &quot;--container-runtime&#x3D;remote&quot;,</span><br><span class="line">                &quot;--container-runtime-endpoint&#x3D;&#x2F;var&#x2F;run&#x2F;Dockershim.sock&quot;,</span><br><span class="line">                ...</span><br><span class="line">            ],</span><br></pre></td></tr></table></figure><blockquote><p>可以看到，增加 enable_cri_dockerd: true 参数启动的 Kubernetes 集群增加了 --container-runtime=remote 和 --container-runtime-endpoint=/var/run/Dockershim.sock 两个 Kubelet 参数。通过这两个 Kubelet 参数可以设置 Kubernetes 集群利用外部 Dockershim 继续使用 Docker 作为 CRI 运行时。 </p><p><strong>通过 Rancher 创建 RKE 集群</strong></p><p>如果你是 Rancher 的长期用户，你肯定会知道从 Rancher UI 上创建的自定义集群就是通过 RKE 来去实现的。只不过通过 Rancher UI 创建的 RKE 集群可以省去配置 RKE cluster.yml 的烦恼，只需要从 UI 上做一些简单的配置即可。</p><p>本节，将给大家介绍如何通过 Rancher 创建 RKE 集群并启用外部 Dockershim 支持。</p><p><strong>安装 Rancher</strong></p><p>Rancher 的安装及使用，请参考官方文档，这里不再详细说明。因为 RKE 创建的Kubernetes 1.21 及以上的版本中才开始支持外部 Dockershim，并且只有 Rancher v2.6.x 才支持 Kubernetes 1.21 或以上版本。所以，我们本次示例选择 Rancher 2.6.4 作为 demo 环境。</p><p><strong>创建自定义集群</strong></p><p><img src="https://img01.sogoucdn.com/net/a/04/link?appid=100520033&url=https://mmbiz.qpic.cn/sz_mmbiz_png/0peJZSmaUqUcbsgHAnQdTkKXk0ia0N2YXLIvXEYiay5f0XPpZu0HkC4yLr2o5YNNkst1LEFcGVXTTDlPwZxERb6A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p><strong>通过 Edit as YAML 来设置 enable_cri_dockerd 参数值为 true</strong></p><p><img src="https://img01.sogoucdn.com/net/a/04/link?appid=100520033&url=https://mmbiz.qpic.cn/sz_mmbiz_png/0peJZSmaUqUcbsgHAnQdTkKXk0ia0N2YX91OOE4jouqebegsnhCHQfs8NgpzvFkiaUhIkKjEDHLd9adrDggiaerpA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>将 enable_cri_dockerd 的值修改为  true ，保存并创建集群</p><p><img src="https://img01.sogoucdn.com/net/a/04/link?appid=100520033&url=https://mmbiz.qpic.cn/sz_mmbiz_png/0peJZSmaUqUcbsgHAnQdTkKXk0ia0N2YXfrcnGKZCTFOE9nKk3AV0Fib9Fb6Z4clKC3uTibBXyu4JMcqvaWvIszhw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p><strong>确认启用 cri-dockerd</strong></p><p>可以参考上面“通过 RKE CLI 创建集群”章节的步骤去检查下游集群是否成功启用了 cri-docker，为了节省篇幅，这里就不重复说明。</p><p><strong>常见问题</strong></p><p><strong>问：如果要获得 Rancher 对上游 Dockershim 的支持，需要升级 Rancher 吗？</strong></p><p>答：对于 RKE，Dockershim 的上游支持从 Kubernetes 1.21 开始。你需要使用支持 RKE 1.21 的 Rancher 版本。详情请参见我们的支持矩阵。</p><p><strong>问：我目前的 RKE 使用 Kubernetes 1.20。为了避免出现不再支持 Dockershim 的情况，我是否需要尽早将 RKE 升级到 Kubernetes 1.21？</strong></p><p>答：在使用 Kubernetes 1.20 的 RKE 中，Dockershim 版本依然可用，而且在下一个发行版发行之前不会被弃用。有关时间线的更多信息，请参见 [Kubernetes Dockershim 弃用相关的常见问题](<a href="https://kubernetes.io/blog/2020/12/02/Dockershim-faq/#when-will-Dockershim-be-removed)%E3%80%82Kubernetes">https://kubernetes.io/blog/2020/12/02/Dockershim-faq/#when-will-Dockershim-be-removed)。Kubernetes</a> 会发出将会弃用 Dockershim 的警告，而 Rancher 在 RKE 中已经用 Kubernetes 1.21 缓解了这个问题。你可以按照计划正常升级到 1.21。</p><p><strong>问：如果不想再依赖 Dockershim，还有什么选择？</strong></p><p>答：你可以为 Kubernetes 使用不需要 Dockershim 支持的运行时，如 Containerd。RKE2 和 K3s 就是其中的两个选项。</p><p><strong>问：如果目前使用 RKE1，但想切换到 RKE2，可以怎样进行迁移？</strong></p><p>答：你可以构建一个新集群，然后将工作负载迁移到使用 Containerd 的新 RKE2 集群。Rancher 也在探索就地升级路径的可能性。</p><p><strong>问：如果已经通过 RKE 创建了 Kubernetes v1.21 以上的集群，当我切换到外部 Dockershim 时，是否会对集群有影响？</strong></p><p>答：没影响，因为容器运行时没有变化，Dockershim 只是由内置方案变成了外部方案。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;打破 Dockershim 移除焦虑，且看 Rancher 如何应对&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/swhQtu0pb_1AwQtMfTyd9Q&quot;&gt;https://mp.weixin.qq.com/s/swhQtu0pb_1A</summary>
      
    
    
    
    <category term="k8s" scheme="http://zhangyu.info/categories/k8s/"/>
    
    
    <category term="k8s" scheme="http://zhangyu.info/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>API网关为K8s容器应用集群提供强大的接入能力</title>
    <link href="http://zhangyu.info/2022/04/30/API%E7%BD%91%E5%85%B3%E4%B8%BAK8s%E5%AE%B9%E5%99%A8%E5%BA%94%E7%94%A8%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BE%9B%E5%BC%BA%E5%A4%A7%E7%9A%84%E6%8E%A5%E5%85%A5%E8%83%BD%E5%8A%9B/"/>
    <id>http://zhangyu.info/2022/04/30/API%E7%BD%91%E5%85%B3%E4%B8%BAK8s%E5%AE%B9%E5%99%A8%E5%BA%94%E7%94%A8%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BE%9B%E5%BC%BA%E5%A4%A7%E7%9A%84%E6%8E%A5%E5%85%A5%E8%83%BD%E5%8A%9B/</id>
    <published>2022-04-29T16:00:00.000Z</published>
    <updated>2022-04-30T07:58:02.175Z</updated>
    
    <content type="html"><![CDATA[<p>API网关为K8s容器应用集群提供强大的接入能力<br><a href="https://help.aliyun.com/document_detail/71623.html">https://help.aliyun.com/document_detail/71623.html</a></p><blockquote><h2 id="1-Kubernetes-集群介绍"><a href="#1-Kubernetes-集群介绍" class="headerlink" title="1. Kubernetes 集群介绍"></a>1. Kubernetes 集群介绍</h2><p>Kubernetes（k8s）作为自动化容器操作的开源平台已经名声大噪，目前已经成为容器玩家主流选择。Kubernetes在容器技术的基础上，增加调度和节点集群间扩展能力，可以非常轻松地让你快速建立一个企业级容器应用集群，这个集群主要拥有以下能力：</p><ul><li><p>  自动化容器的部署和复制</p></li><li><p>  随时扩展或收缩容器规模</p></li><li><p>  将容器组织成组，并且提供容器间的负载均衡</p></li><li><p>  很容易地升级应用程序容器的新版本</p></li><li><p>  提供容器弹性，如果容器失效就替换它</p></li></ul><p>下面是一个典型的Kubernetes架构图：</p><p><img src="http://help-docs-aliyun.aliyuncs.com/assets/pic/71623/cn_zh/1525425558172/d56441427680948fb56a00af57bda690.png"></p><h2 id="2-API网关作为Kubernetes集群的接入层架构"><a href="#2-API网关作为Kubernetes集群的接入层架构" class="headerlink" title="2. API网关作为Kubernetes集群的接入层架构"></a>2. API网关作为Kubernetes集群的接入层架构</h2><p>我们可以看到Kubernetes集群是有足够理由作为应用服务的首选，但是Kubernetes集群没有足够的接入能力，特别在大型应用中，它是不能够直接对用户提供服务的，否则会有非常大的安全风险。而API网关作为成熟的云产品，已经集成了非常丰富的接入能力，把API网关放在Kubernetes集群前面作为应用集群的接入服务使用，将大大提高Kubernetes集群的服务能力，可以作为标准的大型互联网应用的标准架构。下面是使用阿里云架构图：</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/4354359951/p96242.png"></p><p><strong>是否启用Ingress Control？</strong></p><p>从架构图中我们可以看到，API网关作为Kubernetes集群的桥头堡，负责处理所有客户端的接入及安全工作，API网关和Kubernetes集群中Ingress Control的内网SLB或者服务的内网SLB进行通信。具体什么时候用Ingress Control呢？如果Kubernetes集群内只有一个服务，网关直接和此服务关联的内网SLB进行通信最高效。如果Kubernetes集群内有多个服务，如果使用服务的内网SLB对网关提供服务，将会生成很多SLB，资源管理起来会比较麻烦，此时我们可以使用Ingress Control做Kubernetes中服务发现与七层代理工作，API网关的所有请求发送到Ingress Control关联的内网SLB上，由Ingress Control将请求分发到Kubernetes集群内的容器内，这样我们也只需要一个内网SLB就能将Kubernetes集群内的所有服务暴露出去了。</p><h2 id="3-API网关接入能力"><a href="#3-API网关接入能力" class="headerlink" title="3. API网关接入能力"></a>3. API网关接入能力</h2><p>读者要问了，接入了API网关具体能为整个架构带来哪些好处呢？下面我们列一下这种架构中，API网关具体能给整个应用带来什么价值。</p><p>1.API网关允许客户端和API网关使用多种协议进行通信，其中包括：</p><pre><code>* HTTP  * HTTP2  * WebScoket</code></pre><p>2.API网关使用多种方法保证和客户端之间的通信安全：</p><pre><code>* 允许定义API和APP之间的授权关系，只有授权的APP允许调用；* 全链路通信都使用签名验证机制，包括客户端和API网关之间的通信和API网关和后端服务之间的通信，保证请求在整个链路上不会被篡改；* 支持用户使用自己的SSL证书进行HTTPS通信；* 支持OPENID CONNECT；</code></pre><p>3.API网关具备iOS/Android/Java三种SDK的自动生成能力，并且具备API调用文档自动生成能力；</p><p>4.API网关支持入参混排能力，请求中的参数可以映射到后端请求中的任何位置；</p><p>5.API网关提供参数清洗能力，用户定义API的时候可以指定参数的类型，正则等规则，API网关会帮用户确认传输给后端服务的请求是符合规则的数据；</p><p>6.API网关支持流量控制能力，支持的维度为用户/APP/API；</p><p>7.API网关提供双向通信的能力；</p><p>8.API网关提供基于请求数/错误数/应答超时时间/流量监控报警能力，所有的报警信息会使用短信或者邮件在一分钟内发出；</p><p>9.API网关已经和阿里云的SLS产品打通，用户可以将所有请求日志自动上传到用户自己的SLS中，后继好对访问日志进行统计分析；</p><p>10.API网关支持Mock模式，在联调中这个能力非常方便；</p><p>11.API网关支持用户配置调用方的IP白名单和黑名单； 12.API网关结合阿里云的云市场，为Provider提供向API使用者收费的能力。</p><p>阿里云的API网关是一个上线数年的成熟云产品，在稳定性和性能方面，经过了时间和阿里云的工程师的不断打磨，有高性能需求的用户尽管放马过来。</p><h2 id="4-在阿里云快速配置Kubernetes集群和API网关"><a href="#4-在阿里云快速配置Kubernetes集群和API网关" class="headerlink" title="4. 在阿里云快速配置Kubernetes集群和API网关"></a>4. 在阿里云快速配置Kubernetes集群和API网关</h2><p>阿里云支持快速创建Kubernetes集群，同一个Region内的Kubernetes集群和API网关的集成也非常简单，下面我们来一步一步地在阿里云中配置出本文第二节中架构设计。第二节中的架构设计中，API网关和Kubernetes有两种结合的模式，一种是API网关将请求发送到Ingress Control前的SLB，由Ingress Control将请求路由到Kubernetes对应的节点中，第二种是API网关直接将请求发送到Kubernetes中服务前的SLB，由SLB直接将请求转发到Kubernetes中服务对应的节点中。第一种模式只需要Ingress Control前有一个SLB就可以了，由Ingress Contro做服务发现与路由，第二种模式每个服务前都需要申请一个SLB，适合并发量大的场景。</p><h2 id="4-1-Ingress-Control模式的配置方式"><a href="#4-1-Ingress-Control模式的配置方式" class="headerlink" title="4.1 Ingress Control模式的配置方式"></a>4.1 Ingress Control模式的配置方式</h2><h2 id="4-1-1-创建带有Ingress-Control组件的Kubernetes集群"><a href="#4-1-1-创建带有Ingress-Control组件的Kubernetes集群" class="headerlink" title="4.1.1 创建带有Ingress Control组件的Kubernetes集群"></a>4.1.1 创建带有Ingress Control组件的Kubernetes集群</h2><p>首先我们来通过控制台创建一个具备Ingress Control组件的Kubernetes集群。</p><p>1.进入Kubernetes集群管理控制台界面：<a href="https://cs.console.aliyun.com/#/k8s/cluster/list">https://cs.console.aliyun.com/#/k8s/cluster/list</a></p><p>2.点击左上角“创建Kubernetes集群”按钮，进入</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/4354359951/p96396.png"></p><p>3.在创建Kubernetes集群页面选择不同规格的，具体创建选项和常规创建参数一致，在组件配置子页面，需要注意勾选创建Ingress组件：</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/4354359951/p96275.png"></p><p>4.创建成功后可以在Kubernetes列表页面看到刚才创建的集群。</p><h2 id="4-1-2-在Kubernetes集群内创建一个多容器的服务"><a href="#4-1-2-在Kubernetes集群内创建一个多容器的服务" class="headerlink" title="4.1.2 在Kubernetes集群内创建一个多容器的服务"></a>4.1.2 在Kubernetes集群内创建一个多容器的服务</h2><p>现在集群有了，我们需要在集群内创建一个服务，这个服务由2个容器组成，每个容器都由最新的Tomcat镜像生成。容器的端口是8080，Ingress Control提供服务的端口是80。</p><p>1.进入Kubernetes集群管理控制台界面：<a href="https://cs.console.aliyun.com/#/k8s/cluster/list">https://cs.console.aliyun.com/#/k8s/cluster/list</a></p><p>2.进入Kubernetes集群的控制台页面后，点击左边菜单栏的“应用”菜单下的“无状态”按钮，进入应用列表页面后，点击右上角的“使用模板创建”按钮进入创建页面：</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/4354359951/p96278.png"></p><p>3.进入创建页面后，点击使用文本创建按钮，输入下面的资源编排文本点击上传按钮进行创建：</p><pre><code>apiVersion: apps/v1 kind: Deploymentmetadata:  name: tomcat-demo  labels:    app: tomcatspec:  replicas: 2  selector:    matchLabels:      app: tomcat  template:    metadata:      labels:        app: tomcat    spec:      containers:      - name: tomcat        image: tomcat:latest        ports:        - containerPort: 8080---apiVersion: v1kind: Servicemetadata:  name: tomcat-servicespec:  ports:  - port: 80    protocol: TCP    targetPort: 8080  selector:    app: tomcat  sessionAffinity: None  type: NodePort</code></pre><p>对这段编排模板创建文本做下解释：使用最新的Tomcat镜像创建两个容器的意思，容器的服务端口是8080，并且创建一个命名为tomcat-service的服务，对外服务的端口为80，映射到容器8080的端口；</p><p>好了，目前为止，我们已经创建了一个Kubernetes集群，并且在这个集群下面创建了两个容器，每个容器上面跑着一个最新的Tomcat。这两个容器组成一个无状态应用，并且组成了一个命名为tomcat-service的服务。我们可以进入无状态应用详情页面看到整个应用的运行情况。目前我们的API网关没有办法访问到这个服务，需要我们在Ingress Control上建立一条到这个服务的路由才能把全链路打通</p><h2 id="4-1-3-在Ingress-Control上给服务加上路由"><a href="#4-1-3-在Ingress-Control上给服务加上路由" class="headerlink" title="4.1.3 在Ingress Control上给服务加上路由"></a>4.1.3 在Ingress Control上给服务加上路由</h2><p>现在我们有应用了，还需要在Ingress Control上为这个应用建立一个服务，然后在服务上建立一条路由，这样API网关将请求发送给Ingress Control时，Ingress Control会根据配置的路由信息将请求代理到对应的应用节点上。</p><p>1.在容器服务控制台上点击“路由与负载均衡”菜单下的“服务”按钮，点击右上角的“创建”按钮；</p><p>2.在创建路由页面填写服务对应的域名，所监听的端口等：</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/5354359951/p96324.png"></p><h2 id="4-1-4-在API网关对Ingress-Control的内网SLB授权"><a href="#4-1-4-在API网关对Ingress-Control的内网SLB授权" class="headerlink" title="4.1.4 在API网关对Ingress Control的内网SLB授权"></a>4.1.4 在API网关对Ingress Control的内网SLB授权</h2><p>API网关如果要访问Ingress Control的内网SLB，需要增加VPC网络的授权，首先我们需要准备VPC的标识和内网SLB的实例ID，我们可以在SLB控制台获取。</p><p>1.在Kubernetes管理控制台的“服务于负载均衡”菜单下点击“服务”菜单，进入服务管理页面后，选择命名空间为”所有命名空间”后可以在列表中看到Ingress Control的内网SLB地址：</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/5354359951/p96341.png"></p><p>2.登录SLB控制台（<a href="https://slb.console.aliyun.com/%EF%BC%89%EF%BC%8C%E6%89%BE%E5%88%B0%E5%88%9A%E6%89%8D%E5%88%9B%E5%BB%BAKubernetes%E6%9C%8D%E5%8A%A1%E6%97%B6%E8%87%AA%E5%8A%A8%E5%88%9B%E5%BB%BA%E7%9A%84VPC%EF%BC%8C%E7%82%B9%E5%87%BB%E8%BF%9B%E5%8E%BB%E6%9F%A5%E7%9C%8B%E8%AF%A6%E6%83%85%EF%BC%8C%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E5%9C%A8%E8%BF%99%E4%B8%AA%E9%A1%B5%E9%9D%A2%E7%9C%8B%E5%88%B0VPC%E7%9A%84%E6%A0%87%E8%AF%86%EF%BC%9A">https://slb.console.aliyun.com/），找到刚才创建Kubernetes服务时自动创建的VPC，点击进去查看详情，我们可以在这个页面看到VPC的标识：</a></p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/5354359951/p96332.png"></p><p>好了，目前我们已经获取到了VPC的ID和SLB的实例ID,下面我们来创建API网关的授权：</p><p>3.进入API网关授权页面：<a href="https://apigateway.console.aliyun.com/#/cn-beijing/vpcAccess/list">https://apigateway.console.aliyun.com/#/cn-beijing/vpcAccess/list</a> ，点击右上角的创建授权按钮，弹出创建VPC授权的小页面，将刚才查询到的VPC标识和SLB实例ID填入到对应的内容中：</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/5354359951/p96333.png"></p><p>点击确认按钮后，授权关系就创建好了，需要记住刚才填写的授权名称。</p><h2 id="4-1-5-创建API"><a href="#4-1-5-创建API" class="headerlink" title="4.1.5 创建API"></a>4.1.5 创建API</h2><p>在API网关控制台创建API的时候，后端服务这块，有两点需要注意的：</p><p>1.我们需要填写刚才创建的VPC授权名称；</p><p>2.在创建API页面的常量参数添加一个名字为host，位置header的参数，参数值设置为4.1.3节中设置的路由中填写的域名。</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/5354359951/p96380.png"></p><h2 id="4-1-6-调用测试"><a href="#4-1-6-调用测试" class="headerlink" title="4.1.6 调用测试"></a>4.1.6 调用测试</h2><p>API建立好了以后，我们把API发布到线上就可以使用API网关的测试工具进行测试，看看能否将请求发送到刚才创建的Kubernetes集群中去。 我们进入刚才创建好的API的详情页面，点击左侧菜单中的调试API，进入调试页面。在调试页面填写好相应的参数，点击“发起请求”按钮。</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/5354359951/p96378.png"></p><p>我们可以看到，请求发送到了Kubernetes的集群中的容器中，并且收到了容器中tomcate的404的应答（因为没有配置对应的页面）。</p><h2 id="4-2-Kubernetes服务内网SLB结合模式的配置方式"><a href="#4-2-Kubernetes服务内网SLB结合模式的配置方式" class="headerlink" title="4.2 Kubernetes服务内网SLB结合模式的配置方式"></a>4.2 Kubernetes服务内网SLB结合模式的配置方式</h2><p>通过Kubernetes服务的SLB结合API网关与Kubernetes的模式的配置方式与前一节中通过Ingress Control结合模式的配置方式有两点不同：1.申请Kubernetes中的容器服务时，需要指定生成内网SLB，2.找到这个SLB的VPC ID与SLB ID，使用这两个ID到API网关去进行授权即可。上一节中描述的创建Kubernetes集群的步骤，本节不再冗余描述。本节主要描述创建携带内网SLB的Kubernetes服务，并且找到这个内网SLB的IP地址。在找到SLB的IP地址后，具体授权方法和4.1.4中描述的一致，本节也不再重复描述。</p><h2 id="4-2-1-生成携带内网SLB的Kubernetes服务"><a href="#4-2-1-生成携带内网SLB的Kubernetes服务" class="headerlink" title="4.2.1 生成携带内网SLB的Kubernetes服务"></a>4.2.1 生成携带内网SLB的Kubernetes服务</h2><p>在4.1.1操作之后，我们有了一个Kubernetes集群，现在我们通过资源编排文本在这个集群中创建带有内网SLB的服务。我们注意下，本段资源编排代码和4.1.2中的资源编排代码不同的是，我们把最后一行的Type变成了LoadBalancer，并且指定了这个SLBLoadBalancer为内网：</p><pre><code>apiVersion: apps/v1 kind: Deploymentmetadata:  name: tomcat-demo  labels:    app: tomcatspec:  replicas: 2  selector:    matchLabels:      app: tomcat  template:    metadata:      labels:        app: tomcat    spec:      containers:      - name: tomcat        image: tomcat:latest        ports:        - containerPort: 8080---apiVersion: v1kind: Servicemetadata:  name: tomcat-service  annotations:    service.beta.kubernetes.io/alicloud-loadbalancer-address-type: intranetspec:  ports:  - port: 80    targetPort: 8080    protocol: TCP  selector:    app: tomcat  type: LoadBalancer</code></pre><p>对这段编排模板创建文本做下解释：使用最新的Tomcat镜像创建两个容器的意思，容器的服务端口是8080，并且创建一个命名为tomcat-service的服务，这个服务前有一个内网SLB，对外服务的端口为80，映射到容器8080的端口。</p><h2 id="4-2-2-在Kubernetes控制台找到服务的内网SLB地址"><a href="#4-2-2-在Kubernetes控制台找到服务的内网SLB地址" class="headerlink" title="4.2.2 在Kubernetes控制台找到服务的内网SLB地址"></a>4.2.2 在Kubernetes控制台找到服务的内网SLB地址</h2><p>现在我们成功创建了一个携带内网SLB的服务，我们可以在Kubernetes控制台的“路由与负载均衡”菜单的“服务”子页面找到这个内网SLB的内网IP：</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/5354359951/p96549.png"></p><p>找到内网SLB之后，就可以像4.1.4中一样，去SLB的控制台找到这个SLB的VPC ID和SLB ID，并且使用这个SLB的VPC ID和SLB ID到API网关去授权了。</p><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5 总结"></a>5 总结</h2><p>让我们总结一下本文的内容，在前三节中，我们描述了Kubernetes集群和API网关的各项能力，并且画出了结合他俩作为后端应用服务生产的架构图。我们结合API网关+Kubernetes集群的架构，让系统具备了动态伸缩，动态路由，支持多协议接入，SDK自动生成，双向通信等各项能力，成为可用性更高，更灵活，更可靠的一套架构。</p><h2 id="5-1-配置总结"><a href="#5-1-配置总结" class="headerlink" title="5.1 配置总结"></a>5.1 配置总结</h2><p>在最后一节，我们描述了在阿里云的公有云如何创建一整套API网关加Kubernetes的流程，关键点在于Kubernetes集群通过Ingress Control组件服务发现，在API网关对Ingress Control组件的内网SLB进行授权后，将所有请求发送到SLB上。下面我们再总结一下通过Ingress结合API网关与Kubernetes的步骤：</p><ol><li><p> 创建一个带有Ingress Control组件的Kubernetes的集群；</p></li><li><p> 使用资源编排命令，在Kubernetes集群中创建两个运行这最新版本的Tomcat的容器，并且基于这两个容器创建对应的服务；</p></li><li><p> 在控制台上给Ingress Control加上一条服务路由；</p></li><li><p> 到SLB控制台找到Ingress Control内网SLB的实例ID，在API网关创建一个VPC授权；</p></li><li><p> 在API网关创建API，后端服务使用刚才创建的VPC授权，并且设定一个名为host的参数，参数值使用Ingress Control服务路由设置的域名。API的请求将发送到Kubernetes集群的Ingress Control的SLB上，由Ingress Control将请求路由到容器内部的Tomcat服务上。</p></li></ol><p>在高并发场景或者只有一个服务的场景，我们可以跳过Ingress Control，直接在服务前面架设一个内网SLB，并且将这个内网SLB授权给API网关，供API网关进行访问。</p><h2 id="5-2-Ingress-Control和SLB两种方案对比"><a href="#5-2-Ingress-Control和SLB两种方案对比" class="headerlink" title="5.2 Ingress Control和SLB两种方案对比"></a>5.2 Ingress Control和SLB两种方案对比</h2><p>1. 使用SLB+Ingress Control。Ingress Control可以做Kubernetes集群的服务发现和七层代理工作，如果Kubernetes集群中有多个服务，可以统一使用Ingress Control进行路由，同时只需要一个内网SLB就可以对外暴露多个服务。便于运维管理和Kubernetes集群的服务扩充。推荐使用此种方式。</p><p>2. 直接使用SLB。如果集群中某个服务的业务压力很大，可以考虑为此服务单独建立一个SLB，API网关直接连接此SLB，从而达到更高的通信效率。此种方式的弊端也比较明显，如果Kubernetes集群内有多个服务，需要为每个服务配置一个SLB，因此给运维管理带来较大工作量。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;API网关为K8s容器应用集群提供强大的接入能力&lt;br&gt;&lt;a href=&quot;https://help.aliyun.com/document_detail/71623.html&quot;&gt;https://help.aliyun.com/document_detail/71623.ht</summary>
      
    
    
    
    <category term="API网关" scheme="http://zhangyu.info/categories/API%E7%BD%91%E5%85%B3/"/>
    
    
    <category term="API网关" scheme="http://zhangyu.info/tags/API%E7%BD%91%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>云原生环境下的日志采集、存储、分析实践</title>
    <link href="http://zhangyu.info/2022/04/30/%E4%BA%91%E5%8E%9F%E7%94%9F%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%9A%84%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86-%E5%AD%98%E5%82%A8-%E5%88%86%E6%9E%90%E5%AE%9E%E8%B7%B5/"/>
    <id>http://zhangyu.info/2022/04/30/%E4%BA%91%E5%8E%9F%E7%94%9F%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%9A%84%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86-%E5%AD%98%E5%82%A8-%E5%88%86%E6%9E%90%E5%AE%9E%E8%B7%B5/</id>
    <published>2022-04-29T16:00:00.000Z</published>
    <updated>2022-04-30T09:51:45.713Z</updated>
    
    <content type="html"><![CDATA[<p> 以下文章来源于火山引擎开发者社区<br>作者：刘卯银｜火山引擎日志系统架构师</p><p>云原生环境下的日志采集、存储、分析实践<br><a href="https://mp.weixin.qq.com/s/L2bPGFL2cNamaFrxeyU48Q">https://mp.weixin.qq.com/s/L2bPGFL2cNamaFrxeyU48Q</a></p><blockquote><p>谈到日志系统，首先要从日志说起，日志在 IT 系统里无处不在，也是 IT系统大数据的关键来源。日志的种类和样式非常多，以在线教育系统为例，日志包括客户端日志、服务端日志。服务端日志又包括业务的运行/运维日志以及业务使用的云产品产生的日志。要管理诸多类型的日志，就需要一套统一的日志系统，对日志进行采集、加工、存储、查询、分析、可视化、告警以及消费投递，将日志的生命周期进行闭环。</p><p>Kubernetes 下日志采集的开源自建方案</p><p><strong>开源自建</strong></p><p>火山引擎早期为了快速上线业务，各团队基于开源项目搭建了自己的日志系统，以满足基本的日志查询需求，例如使用典型的开源日志平台 <strong>Filebeat+Logstash+ES+Kibana</strong> 的方案。但是在使用过程中，我们发现了开源日志系统的不足：</p><ul><li><p>  各业务模块自己搭建日志系统，造成重复建设。</p></li><li><p>  以 ES 为中心的日志架构可以利用 ES 查询便利的优势，但是资源开销大、成本高。而且 ES 与 Kibana 在界面上强绑定，不利于功能扩展。</p></li><li><p>  开源方案一般采用单机 yaml 做采集配置，当节点数很多的时候，配置非常繁琐。</p></li><li><p>  开源系统的采集配置难以管理，数据源也比较单一。</p></li></ul><p><img src="https://mmbiz.qpic.cn/mmbiz_png/fgbJnuXT4EqeiaZn0NZBVcfngVp083FmjVjJ2EheTOKXIWcL2QCrDNF5t1ujPv14aWR6ytFwRdS7iaEnkbImdZ2w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p><strong>Kubernetes 下的日志采集</strong></p><p>Kubernetes 下如何采集日志呢？官方推荐了四种日志采集方案：</p><ul><li><p>  DaemonSet：在每台宿主机上搭建一个 DaemonSet 容器来部署 Agent。业务容器将容器标准输出存储到宿主机上的文件，Agent 采集对应宿主机上的文件。</p></li><li><p>  Streaming Sidecar：有一些业务系统的日志不是标准输出，而是文件输出。Streaming Sidecar 的方式可以把这些文件输出通过 Sidecar 容器转换成容器的标准输出，然后采集。</p></li><li><p>  Sidecar Logging Agent：业务 Pod 内单独部署 Agent 的 Sidecar 容器。这种方式的资源隔离性强。</p></li><li><p>  API/SDK：直接在容器内使用 API 或 SDK 接口将日志采集到后端。</p></li></ul><p>以上前三种采集方案都只支持采集容器的标准输出，第四种方案需要改造业务代码，这几种方式对采集容器文件都不友好。但用户对于日志文件有分类的需求，标准输出将所有日志混在一起，不利于用户进行分类。如果用户要把所有日志都转到标准输出上，还需要开发或者配置，难以推广。因此 Kubernetes 官方推荐的方案无法完全满足用户需求，给我们的实际使用带来了很多不便。</p><p><strong>自建日志采集系统的困境与挑战</strong></p><p>云原生场景下<strong>日志种类多、数量多、动态非永久</strong>，开源系统在采集云原生日志时面临诸多困难，主要包括以下问题：</p><p><strong>一、采集难</strong></p><ul><li><p>  <strong>配置复杂</strong>：系统规模越来越大，节点数越来越多，每个节点的配置都不一样，手工配置很容易出错，系统的变更变得非常困难。</p></li><li><p>  <strong>需求不满足</strong>：开源系统无法完全满足实际场景的用户需求，例如不具备多行日志采集、完整正则匹配、过滤、时间解析等功能，容器文件的采集也比较困难。</p></li><li><p>  <strong>运维难度高</strong>：大规模场景下大量 Agent 的升级是个挑战，系统无法实时监控 Agent 的状态，当Agent 状态异常时也没有故障告警。</p></li></ul><p><strong>二、产品化能力不足</strong></p><ul><li><p>  <strong>可用性低</strong>：因为缺少流控，突发的业务容易使后端系统过载，业务之间容易相互影响。</p></li><li><p>  <strong>资源使用效率低</strong>：如果配置的资源是固定的，在突发场景下容易造成性能不足的问题；但如果配置的资源过多，普通场景下资源利用率就会很低；不同的组件配置不均衡还会导致性能瓶颈浪费资源。ES 的原始数据和索引使用相同的资源配置，也会导致高成本。</p></li><li><p>  <strong>功能不足</strong>：比如 ES 的投递和消费能力弱、分析能力固化、没有告警能力、可视化能力有限。</p></li></ul><p>火山引擎统一日志平台 TLS  </p><p>在遇到这些问题以后，我们研发了一套统一的日志管理平台——**火山引擎日志服务（Tinder Log Service，简称为 TLS)**。TLS 的整体架构如下：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/fgbJnuXT4EqeiaZn0NZBVcfngVp083FmjYA33Zyhiav3lzlJhTQemLCOh6K6cfWrQ2xIh0h7ibdBH5JV63wKUOQOw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>面对各种日志源，TLS 通过自研的 LogCollector/SDK/API，可支持专有协议、 OpenTelemetry 和 Kafka 协议上传日志。支持多种类型的终端、多种开发语言以及开源生态标准协议。</p><p>采集到的日志首先会存入<strong>高速缓冲集群</strong>，削峰填谷，随后日志会匀速流入<strong>存储集群</strong>，根据用户配置再流转到<strong>数据加工集群</strong>进行日志加工，或者到<strong>索引集群</strong>建立索引。建立索引后用户可以进行实时查询和分析。TLS 提供标准的 Lucene 查询语法、SQL 92 分析语法、可视化仪表盘以及丰富的监控告警能力。</p><p>当日志存储达到一定周期，不再需要实时分析之后，用户可以把日志投递到成本更低的火山引擎对象存储服务中，或者通过 Kafka 协议投递到其他云产品。如果用户有更高阶的分析需求，TLS 也支持把日志消费到实时计算、流式计算或离线计算进行更深入的分析。</p><p>TLS 的系统设计遵循<strong>高可用、高性能、分层设计</strong>的原则。</p><ul><li><p>  <strong>高可用</strong>：通过存算分离，所有服务都是无状态的，故障快速恢复。</p></li><li><p>  <strong>高性能</strong>：所有集群都可横向扩展，没有热点。</p></li><li><p>  <strong>分层设计</strong>：各模块之间低耦合，模块之间定义标准接口，组件可替换。</p></li></ul><p>以上就是火山引擎自研的日志存储平台 TLS 的系统架构，下面将详细介绍 TLS 相较于开源系统做的优化。</p><p><strong>系统优化</strong></p><p><strong>中心化白屏化的配置管理</strong></p><p>当日志系统中采集 Agent 数量较多时，不再适合在每台机器上手工配置，因此我们开发了中心化、白屏化的配置管理功能，支持动态下发采集配置，并支持查看 Agent 运行状态监控、支持客户端自动升级。</p><p>中心化配置的实现流程如下：</p><ol><li><p> 客户端主动向服务端发起心跳，携带自身版本信息。</p></li><li><p> 服务端收到心跳，检查版本。</p></li><li><p> 服务端判断是否需要下发配置信息给客户端。</p></li><li><p> 客户端收到配置信息，热加载到本地配置，以新的配置进行采集。</p></li></ol><p><img src="https://mmbiz.qpic.cn/mmbiz_png/fgbJnuXT4EqeiaZn0NZBVcfngVp083FmjqSrAjh32gBkHzHr4KHbRSSCDGPZXJbW1SibapEZmrKRVxWkS4TEB45w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>中心化配置管理的优势在于：</p><ul><li><p>  可靠：中心化管理，配置不丢失，白屏化配置不容易出错。</p></li><li><p>  高效：各种环境下所有的配置都是统一处理，无论 LogCollector 部署在移动端、容器还是物理机上，用户都可以在服务端相同的界面上配置，配置以机器组为单位批量下发，快速高效。</p></li><li><p>  轻松运维：用户可以在服务端查看客户端的运行状态，对客户端的异常发出告警。通过中心化配置，TLS 可以向客户端推送最新版本，自动升级。</p></li></ul><p><strong>CRD 云原生配置方式</strong></p><p>中心化、白屏化的配置方式是适合运维人员的配置方式。在开发测试自动化的场景下，最优的方式是 CRD。传统的方式通过 API 接口去做采集配置，用户通常需要写数千行代码来实现。TLS 提供了云原生 CRD 的方式来进行配置，用户只需要在 yaml 文件里配置要采集的容器、容器内的日志路径以及采集规则即可完成采集配置。因为不再需要编写代码，CRD 方式大幅提高了日志接入效率。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/fgbJnuXT4EqeiaZn0NZBVcfngVp083FmjYP0hTUYJJwLgzT60iasNJwsicvYG5Jj6eqXbTcInZ3XFDjGEaUDibZSyw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>CRD 的配置流程如下：</p><ol><li><p> 使用 Kubectl 命令创建 TLS LogConfig CRD；</p></li><li><p> TLS Controller 监听到 CRD 配置更新；</p></li><li><p> TLS Controller 根据 CRD 配置向 TLS Server 发送命令，创建 topic、创建机器组，创建日志采集配置；</p></li><li><p> LogCollector 定期请求 TLS Server，获取新的采集配置并进行热加载；</p></li><li><p> LogCollector 根据采集配置采集各个容器上的标准输出或文本日志；</p></li><li><p> LogCollector 将采集到的日志发送给 TLS Server。</p></li></ol><p><strong>适合大规模、多租户场景的客户端</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/fgbJnuXT4EqeiaZn0NZBVcfngVp083FmjEB0Hw5nv6B6SibRJVfvjQhHrSEkUWKcueLCwZLRvbTiaJMHaDnOB1HOw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>开源日志采集客户端一般只支持一个 Output，多个 Input 采用相同的 Pipeline，相互影响。为了适应大规模、多租户场景，火山引擎自研了日志采集的客户端 LogCollector。LogCollector 对不同的 Input 采用不同的 Pipeline 做资源隔离，减少多租户之间的相互影响。一个 LogCollector 支持多个 Output，可以根据不同的 Output 单独做租户鉴权。同时我们还在 LogCollector 内实现了自适应反压机制，如果服务端忙碌，LogCollector 会自动延迟退避，服务端空闲时再发送，减少算力负担。</p><p><strong>产品优化</strong></p><p><strong>可用性提升</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/fgbJnuXT4EqeiaZn0NZBVcfngVp083Fmjic1FUdj20kJXxkxgzQCQt19sJekvm0ficRQh14rny7h8KQVNYZ4IFLQg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>在可用性方面，TLS 支持多级全局流控，能杜绝因业务突发导致的故障扩散问题。</p><ul><li><p>  在日志采集到高速缓冲集群时，按照用户的 Shard 数控制写入高速缓冲区的流量。</p></li><li><p>  当数据从高速缓冲区流向存储集群时，按存储集群控制单个存储集群的流量。</p></li><li><p>  从存储集群到索引集群，按索引集群控制单个索引集群的写入流控以及查询分析并发数。</p></li></ul><p><strong>效率提升</strong></p><p><strong>索引和原始数据分离</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/fgbJnuXT4EqeiaZn0NZBVcfngVp083FmjZWzzN512awjorhGKgnDNk5YJujrX5DpKfEibfUnOaO0j7NO0PcAVayA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>ES 的索引和数据存在一起，我们在设计过程发现索引和原始数据分离会更优，主要表现在：</p><ul><li><p>  提升数据流动性：存储集群支持批量消费接口，消费数据不经过索引集群。相对于从索引集群先查询后消费的模式，直接从存储集群消费性能更高，有效提升数据流动性。</p></li><li><p>  降低成本：索引和存储可以采用不同成本的存储，整体的存储成本就会降低。用户可以随时按需创建索引，进一步降低索引成本。</p></li><li><p>  提升可用性：索引可以异步创建，流量突发时创建索引慢不会影响存储写入速率。</p></li></ul><p><strong>索引管理和调度</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/fgbJnuXT4EqeiaZn0NZBVcfngVp083FmjomGWwa6uDIge2s5E3JSUYvXtpjyfNFgMgRNNsA3fcGdjC6D1PcCmicA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>索引的流量是不可预测的，因此我们在效率方面的另一个优化是支持索引的管理和调度，实现弹性伸缩，从而提升可用性，解决规模问题。我们的解决方案是在多个索引集群之间做数据流动，基于负载、资源、容量自动迁移索引，支持动态跨集群在线迁移索引，平衡索引集群负载。  </p><p><strong>功能优化</strong></p><ul><li>  <strong>消费投递</strong>：在消费投递方面我们支持了丰富的消费投递接口，包括：</li></ul><ul><li><p>  消费者</p></li><li><p>  消费组</p></li><li><p>  Kafka 协议：通过 Kafka 协议进行标准协议的消费；</p></li><li><p>  S3 协议：支持通过 S3 对象存储的协议把日志投递到对象存储。</p></li></ul><p><img src="https://mmbiz.qpic.cn/mmbiz_png/fgbJnuXT4EqeiaZn0NZBVcfngVp083Fmj0sTazoYHCq7VCMRTENlib89eGtJxdu3bXmBh871Gb0mAGicrxy9iaxTJw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><ul><li><p>  <strong>查询分析</strong>：支持先查询过滤后分析，减少分析数据量提高性能。分析支持标准的 SQL 92，分析结果支持图表可视化。</p></li><li><p>  <strong>日志告警</strong>：通过实时监控日志，基于用户配置的监控规则组合以及告警触发条件，满足条件就可以通过短信、邮件、飞书等方式发送告警给用户或用户组。</p></li><li><p>  <strong>可视化仪表盘</strong>：TLS 提供多种可视化仪表盘，实现实时监测，且仪表盘可以关联告警。</p></li></ul><p>TLS 实践案例</p><p>接下来为大家介绍两个 TLS 的典型案例。</p><p><strong>火山引擎内部业务及运维日志采集</strong></p><p>TLS 目前支撑了火山引擎全国多个 Region 运维日志的采集分析。日志类型包括业务的文件日志、容器标准输出。业务分别部署在内网、外网以及混合云，日志都通过 TLS 平台统一做采集和分析。</p><p>相较于前期各业务模块自己搭建日志系统，采用 TLS 获得了如下收益：</p><ul><li><p>  经济高效：资源利用率由之前的 20% 提升到现在的 **80%**，大幅降低资源成本；</p></li><li><p>  可用性较高：多级流控加缓存，抗突发能力强，即使在索引系统故障的时候也不会影响原始数据的流量；</p></li><li><p>  轻松运维：TLS 的统一运维提升了运维人员的能力，少量运维人员即可完成整个系统的运维。</p></li><li><p>  快速接入：TLS 可以在一小时内完成一个新业务的采集、查询、分析、消费的快速接入。</p></li></ul><p><strong>某教育行业头部客户日志采集</strong></p><p>该客户的系统业务主要采集的日志包括：</p><ul><li><p>  文件日志</p></li><li><p>  App 日志</p></li><li><p>  Kubernetes 集群后端业务的日志</p></li><li><p>  用户行为日志</p></li></ul><p>TLS 把这几个平台的日志统一采集到云端，进行实时查询分析以及进行告警。客户自建有大数据分析平台，TLS 可将日志数据通过消费的方式流转到该平台进行在线、离线等更高阶的大数据分析。对于时间长的历史数据，则投递到对象存储进行归档，从而降低整个系统的成本。</p><p>用户的管理员可在 TLS 上统一查看所有平台的各种日志，整个系统的建设和运维成本也降低了。TLS 使用标准接口，可以兼容云上自建的分析平台，用户在快速上线的同时也能保证系统的高度兼容。</p><p>展望未来</p><p>未来，TLS 平台会不断进行更深层次的优化：</p><ul><li><p>  云产品的一键日志采集</p></li><li><p>  搜索引擎的深度优化</p></li><li><p>  数据清洗和加工的函数式接口</p></li><li><p>  集成更多第三方平台，火山引擎云产品深度融合</p></li></ul><p><strong>Q&amp;A</strong></p><p><strong>Q：中心化配置，各个业务的日志采集配置是 OP 负责还是 RD 负责？</strong><br><strong>A</strong>：日志采集的中心化配置是 Web 方式，配置非常简单，无论是 RD 或是 OP 负责都可以。火山引擎上 Web 配置由 OP 来负责，容器自动化采集是用 CRD 的方式，一般是 RD 负责。</p><p><strong>Q：采集端 Agent 的使用资源可以限制吗？是否会影响业务的资源使用？</strong><br><strong>A</strong>：CPU 占用量、内存占用量这些是可以配置的，不会影响业务的资源使用。</p><p><strong>Q：CRD 和中心化配置不会冲突吗？</strong><br><strong>A</strong>：通常情况下不会冲突。CRD 有特定的命名规则，只要 Web 配置和 CRD 配置的名字不冲突就不会报错。如果名字冲突，配置会失败，改名字后重试即可。</p><p><strong>Q：Node 节点宕机是否会丢日志？</strong><br><strong>A</strong>：不会。LogCollector 有 Checkpoint，Checkpoint 会定期更新。如果节点宕机没有更新 Checkpoint，日志会从上次 Checkpoint 点重新采集，所以是不会丢的。</p><p><strong>Q：日志采集的延迟情况如何？</strong><br><strong>A</strong>：一般在秒级延迟，后端业务忙的时候可能是几秒到十几秒的延迟。</p><p><strong>Q：Kafka 协议是如何暴露的？通过实现 Kafka Server 吗？</strong><br><strong>A</strong>：我们是在服务端实现的 Kafka 协议。用户以 Kafka 的协议方式接入，鉴权也是以 Kafka 的鉴权协议来做的。用户看到的其实就是一个 Kafka。这样可以对用户做到透明。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; 以下文章来源于火山引擎开发者社区&lt;br&gt;作者：刘卯银｜火山引擎日志系统架构师&lt;/p&gt;
&lt;p&gt;云原生环境下的日志采集、存储、分析实践&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/L2bPGFL2cNamaFrxeyU48Q&quot;&gt;https:/</summary>
      
    
    
    
    <category term="日志" scheme="http://zhangyu.info/categories/%E6%97%A5%E5%BF%97/"/>
    
    
    <category term="日志" scheme="http://zhangyu.info/tags/%E6%97%A5%E5%BF%97/"/>
    
  </entry>
  
  <entry>
    <title>公有云降本增效最佳实践</title>
    <link href="http://zhangyu.info/2022/04/30/%E5%85%AC%E6%9C%89%E4%BA%91%E9%99%8D%E6%9C%AC%E5%A2%9E%E6%95%88%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
    <id>http://zhangyu.info/2022/04/30/%E5%85%AC%E6%9C%89%E4%BA%91%E9%99%8D%E6%9C%AC%E5%A2%9E%E6%95%88%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</id>
    <published>2022-04-29T16:00:00.000Z</published>
    <updated>2022-04-30T07:57:55.662Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://ewhisper.cn/posts/59535/">https://ewhisper.cn/posts/59535/</a></p><blockquote><h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><h3 id="整体"><a href="#整体" class="headerlink" title="整体"></a>整体</h3><h4 id="首选公有云服务而非自建"><a href="#首选公有云服务而非自建" class="headerlink" title="首选公有云服务而非自建"></a>首选公有云服务而非自建</h4><p>公有云除了提供 IaaS（计算、存储、网络等）外，也会提供 PaaS（微服务、中间件、数据库、大数据、开发套件等）和 SaaS 服务。</p><p>在公有云提供的服务（如 MySQL 数据库）可以满足需求的前提下，建议首选公有云上的 MySQL 数据库服务，而非自建。</p><p>理由简单说明如下：</p><p>对比项</p><p>成本</p><p>性能</p><p>伸缩性</p><p>维护方</p><p>可靠性</p><p>监控</p><p>易用性</p><p>自建</p><p>高</p><p>低</p><p>弱</p><p>我方</p><p>低</p><p>无</p><p>难</p><p>云上服务</p><p>中</p><p>高</p><p>高</p><p>云提供商</p><p>高</p><p>有</p><p>易用</p><ul><li><strong>成本</strong>：<ul><li>  自建，需要人员维护和优化的成本，需要自行考虑高可靠（可能需要购买多台服务器）和高性能（可能需要购买高性能存储），使得成本偏高。</li><li>  云上服务，通过规模效应、资源池化、参数调优等实现成本相对不高。</li></ul></li><li><strong>性能</strong>：<ul><li>  自建，不一定知道所有的参数优化项，也不一定同价位能买到专用的高性能硬件。</li><li>  云上服务，性能明码标价，按需选择适合自己的性能配置。</li></ul></li><li><strong>伸缩性</strong><ul><li>  自建，伸缩较麻烦，要不手动，要不通过 历经检验的 DevOps 脚本，伸缩性弱。</li><li>  云上服务，很多 PaaS 类服务可以一键升配。</li></ul></li><li><strong>维护方</strong><ul><li>  自建，我方自行兜底</li><li>  云上服务，云提供商提供 SLA 兜底。</li></ul></li><li><strong>可靠性</strong><ul><li>  自建，不一定能实现该组件的集群模式或高可用模式的全部最佳实践。</li><li>  云上服务，会做好网络高可用（甚至是跨 AZ 的高可用）、存储多副本、计算跨物理服务器 / 机架 /AZ 甚至 region、服务监控及自愈、备份等多种措施保障可靠性。</li></ul></li><li><strong>监控</strong>：<ul><li>  自建，要不没监控，要不监控需要从头（采集端）到尾（告警通知）实现一遍</li><li>  云上服务，监控具备，且和公有云监控无缝对接。</li></ul></li><li><strong>易用性</strong>：<ul><li>  自建：一般没有 Web 界面，需要通过线下或流程平台或 CLI 来申请和操作</li><li>  云上服务：有易用的 web 界面，可以在 web 界面上完成大部分功能。</li></ul></li></ul><p>比如云数据库：</p><ul><li>运维架构：<ul><li>  存储的数据规模及后期扩展，采用的高可用架构；</li><li>  异常切换</li></ul></li><li>硬件及基础环境部署<ul><li>  选择什么配置的服务器，服务器型号及对应磁盘阵列；</li><li>  操作系统环境及内核设置；</li></ul></li><li>数据库安装及优化<ul><li>  数据库版本安装部署及配置；</li><li>  数据库配置参数调优；</li></ul></li><li>SQL 语句优化；<ul><li>  慢查询，对 SQL 语句及索引做优化</li></ul></li><li>数据库日常备份及恢复。<ul><li>  备份；</li><li>  热备还是冷备？物理备份还是逻辑备份？</li><li>  备份策略、周期、频率</li></ul></li></ul><p>使用云数据库，这些步骤云数据库都帮你做了。其他 PaaS（中间件、大数据、微服务、DevOps 等）也类似。</p><h4 id="做好安全防护"><a href="#做好安全防护" class="headerlink" title="做好安全防护"></a>做好安全防护</h4><p>公有云最大的风险就是数据泄露。所以一定要做好安全防护。这个安全防护是多方面的。详细见 <a href="https://ewhisper.cn/posts/59535/#%E5%AE%89%E5%85%A8">安全</a> 部分。</p><h4 id="云的优势是「分布式」"><a href="#云的优势是「分布式」" class="headerlink" title="云的优势是「分布式」"></a>云的优势是「分布式」</h4><p>如果对比单台服务器，可能云主机的性能差一些。「分布式」是云计算的最大优势。在实践中，不要只追求单台机器的性能，而是要通过分布式的设计思想来保障业务的高性能。最佳实践推荐，服务器标配 4C8G，低配也可以采用 2C4G 的配置。通过分布式充分压榨了单台服务器的资源，从而最大限度地保障了最终的低成本。<br>所以，在云上，一般情况下应用服务器的选择条件是：更多的低配的云服务胜于更少的高配的云服务器。<br>所以，在云上，对于数据库来说，如果数据量非常大，也推荐使用「分布式数据库」，而非在云上自建 Oracle。</p><h4 id="云的优势是「弹性」"><a href="#云的优势是「弹性」" class="headerlink" title="云的优势是「弹性」"></a>云的优势是「弹性」</h4><p>所以，在云上，不要按照业务峰值购买全量的资源，而是推荐：</p><ul><li>  买满足日常需求的资源</li><li>  高峰时，再提前购买一些弹性的资源，弹性扩容。</li></ul><p>另外，不仅仅是服务器资源，对于网络也适用，如果您的系统经常搞活动，网络负载差距很大，那么推荐：「大带宽按量付费」而不是「固定带宽固定计费」。</p><h4 id="动静分离"><a href="#动静分离" class="headerlink" title="动静分离"></a>动静分离</h4><p>静态：放 CDN + 对象存储上，或者放 NGINX 服务器上也好，不要直接用应用服务器（如 tomcat 或 nodejs）来处理静态资源。（浪费，术业有专攻）<br>动态：典型架构是 LB - NGINX - 应用服务器 - redis - 数据库。</p><h4 id="上云前做好业务量的评估"><a href="#上云前做好业务量的评估" class="headerlink" title="上云前做好业务量的评估"></a>上云前做好业务量的评估</h4><p>上云前做好业务量的评估，为云上的资源规划做好资源预算。<br>可以通过：</p><ul><li>  压测</li><li>  已有监控数据分析</li></ul><p>等方式评估业务量。</p><p>常用的业务量指标如下：</p><p>指标</p><p>计算周期</p><p>指标含义</p><p>PV</p><p>天</p><p>Page View。指 B/S 架构中的 Web 类业务一天内页面的访问次数，每打开或刷新一次页面，算一个 PV。</p><p>UV</p><p>天</p><p>UV 是 Unique Visitor 的简写。指 B/S 架构中 Web 类业务一天内访问站点的用户数（以 cookie 为依据）</p><p>IP</p><p>天</p><p>B/S 架构中 Web 类业务一天内有多少个独立的 IP 浏览了页面，即统计不同的 IP 浏览用户数量。</p><p>用户数</p><p>–</p><p>业务系统的注册用户数</p><p>活跃用户数</p><p>天</p><p>注册用户数中，一天中实际使用了业务系统的用户数量，跟 UV 的概念一样</p><p>在线用户数</p><p>天</p><p>一天的活跃用户数中，用户同时在一定的时间段内在线的数量</p><p>并发用户数</p><p>–</p><p>指在线用户数基础上，某一时刻同时指向服务器发送请求的用户数</p><p>具体的性能监控指标如何和业务指标进行转换就先略过了。</p><h4 id="推荐几个公有云云产品"><a href="#推荐几个公有云云产品" class="headerlink" title="推荐几个公有云云产品"></a>推荐几个公有云云产品</h4><p>这些公有云产品是基本上都会用到的，历经检验，且比较实用的产品。</p><ol><li> 云服务器</li><li> 关系型数据库</li><li> 负载均衡</li><li> 对象存储</li><li> VPC（Virtual Private Cloud）：专有网络</li><li> CDN</li><li> Redis</li><li> 安全类的基本产品（如：安全组、ACL、漏扫、WAF、DDoS 防护等）</li></ol><h3 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h3><h4 id="云服务器配置以中低配为主"><a href="#云服务器配置以中低配为主" class="headerlink" title="云服务器配置以中低配为主"></a>云服务器配置以中低配为主</h4><p>云服务器一般用于承载应用，推荐以更多台数的中低配为主，避免资源的浪费。<br>建议一般配置不要超过：16C32G，主流配置为：</p><ul><li>  4C8G 甚至更低</li><li>  8C16G</li></ul><h4 id="推荐使用容器服务"><a href="#推荐使用容器服务" class="headerlink" title="推荐使用容器服务"></a>推荐使用容器服务</h4><p>容器服务有诸多优势，推荐无状态应用使用容器服务。</p><ul><li>  资源粒度更细，细粒度到: 0.1C, 内存 MB。</li><li>  自动扩缩容更方便</li><li>  扩容后 pod 自动加入负载均衡</li><li>  …</li></ul><h4 id="按需购买"><a href="#按需购买" class="headerlink" title="按需购买"></a>按需购买</h4><p>在云上，不要按照业务峰值购买全量的资源，而是推荐：买满足日常需求的资源</p><h4 id="弹性扩容"><a href="#弹性扩容" class="headerlink" title="弹性扩容"></a>弹性扩容</h4><p>在云上，如果需要搞活动，再通过「容器」或「API + 镜像 + 快照」批量购买、弹性扩容。</p><p>比如在某手机的秒杀活动中，会瞬间开启 200 台机器且持续 2H 来应对，IT 资源花费 600 元人民币：</p><ol><li> 搭建好环境，制作好镜像；</li><li> 活动前通过 API 秒开 200 台服务器来应对活动；</li><li> 活动结束后，通过 API 瞬间释放资源</li></ol><p>这在传统架构中，根本不可想象。比如传统架构，搞「双十一」，都要提前一个月准备 IT 资源。</p><p>另外上面的场景也可以利用 「弹性伸缩服务」或「容器 HPA」来动态调整。</p><h4 id="使用-Ansible-等-DevOps-工具"><a href="#使用-Ansible-等-DevOps-工具" class="headerlink" title="使用 Ansible 等 DevOps 工具"></a>使用 Ansible 等 DevOps 工具</h4><p>既然云的优势是「分布式」，资源多，那么 Ansible 这种批量的 DevOps 工具是必不可少的，可以大幅度提升效率。<br>具体应用，可以通过 Ansible，定制对应的 Playbook，自动化批量安装和运维。</p><h4 id="通过镜像提升云端部署效率"><a href="#通过镜像提升云端部署效率" class="headerlink" title="通过镜像提升云端部署效率"></a>通过镜像提升云端部署效率</h4><p>先开通一台云服务器，并对这台云服务器做运维规范方面的系统调优、安全加固等措施。然后把这台云服务器做成一个基础镜像，批量开通 其他同样环境的服务器，可以大大提升部署效率。</p><h3 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h3><h4 id="域名备案要先行"><a href="#域名备案要先行" class="headerlink" title="域名备案要先行"></a>域名备案要先行</h4><p>上云的最后一步，是要将域名的 IP 解析到 负载均衡 公网 IP 上。但需要提前在共有云上对域名进行备案，如果到最后域名解析到公有云上后才发现域名被拉黑，业务访问被拒绝，这将会变得非常麻烦。因此需要提前通过公有云进行域名备案，或者已经在其他供应商进行备案，那么需要将域名备案转接入公有云。</p><h4 id="推荐必备-CN-域名"><a href="#推荐必备-CN-域名" class="headerlink" title="推荐必备 .CN 域名"></a>推荐必备 .CN 域名</h4><p>近期国际形势愈演愈烈，中美摩擦进一步升级，形势紧张。要做最坏的打算：美国可能会断掉您的 .COM 域名的解析。<br>另外国家最近有指引，不要使用外国管控的根域名作为基础设施的一级域名。<br>.cn 是国家根域，.com.cn、[net.cn]、[org.cn] 等这些都是可以的。</p><h4 id="严禁每台服务器都能访问公网"><a href="#严禁每台服务器都能访问公网" class="headerlink" title="严禁每台服务器都能访问公网"></a>严禁每台服务器都能访问公网</h4><p>出于安全（受攻击面太大）和成本（公网 IP 都是钱）的考虑。<br>而且没必要，如果是业务访问，入向通过负载均衡进来，出向通过 NAT 网关出去。<br>如果是运维，推荐通过 VPN + 跳板机（中小企业）或专线 + 堡垒机（大企业）来实现运维管理。</p><h4 id="如果需要出公网，建议使用-NAT-网关而非在某台机器绑定公网-IP"><a href="#如果需要出公网，建议使用-NAT-网关而非在某台机器绑定公网-IP" class="headerlink" title="如果需要出公网，建议使用 NAT 网关而非在某台机器绑定公网 IP"></a>如果需要出公网，建议使用 NAT 网关而非在某台机器绑定公网 IP</h4><p>原因：可靠性更高，更安全。</p><h4 id="利用低成本高负载的按量带宽"><a href="#利用低成本高负载的按量带宽" class="headerlink" title="利用低成本高负载的按量带宽"></a>利用低成本高负载的按量带宽</h4><p>对于中小规模企业，如果您的系统经常搞活动，网络负载差距很大，那么推荐：「大带宽按量付费」而不是「固定带宽固定计费」，比如：「1Gbps 峰值带宽按量计费」对比「100Mbps 固定带宽」：</p><ul><li>  费用可能更低</li><li>  带宽更大，活动期间可能会超过 100Mbps，那这时候固定带宽就会影响用户体验，而 1Gbps 峰值带宽是完全可以支撑的住的。</li></ul><p>以某客户上云前后为例，在 IDC 机房，200Mbps 的独享电信带宽，一年的成本大概是 1Mbps/100 元 / 月 x 12 个月 x 200 = 24 万。而在云端，采用 1Gbps 峰值的 BGP 多线 SLB 带宽，在带宽质量上面提升了几个量级。另外，带宽费用采用按量付费，大大降低了维护成本。</p><h4 id="推荐使用云上软负载均衡"><a href="#推荐使用云上软负载均衡" class="headerlink" title="推荐使用云上软负载均衡"></a>推荐使用云上软负载均衡</h4><p>推荐使用公有云提供的负载均衡，可以作为反向代理，防止客户端直连云服务器带来的安全和稳定性风险。</p><p>加入 负载均衡 可以保障架构灵活扩展性：加入 负载均衡 后，架构变得更加灵活。典型场景是将所有域名先绑定到 负载均衡 上，然后转到后端 Nginx，通过 Nginx 做虚拟主机等七层更灵活的控制。</p><h4 id="高并发情况下，推荐使用-4-层负载均衡"><a href="#高并发情况下，推荐使用-4-层负载均衡" class="headerlink" title="高并发情况下，推荐使用 4 层负载均衡"></a>高并发情况下，推荐使用 4 层负载均衡</h4><p>采用 4 层 负载均衡 保障性能：在实践中，面对高并发性能的场景时，发现 7 层的负载均衡，相比 4 层的负载均衡，在性能上面有很大差距。7 层负载均衡只能达到万级别并发，而 4 层的负载均衡能达到几十万级，甚至上百万级的并发量。所以在电商等网站应用中，对于 负载均衡，优先选择 TCP 层。四层 LB 能扛得住 10w-50w 的并发。</p><h4 id="DNS-记录调整要注意"><a href="#DNS-记录调整要注意" class="headerlink" title="DNS 记录调整要注意"></a>DNS 记录调整要注意</h4><p>用户的 DNS TTL 我们是无法控制的，如果调整了某域名的 DNS 记录，可能某些用户已生效，某些用户没有生效。<br>针对这种情况，需要在原有 IP 上做 302 重定向跳转，将依旧访问原 IP 的客户引流到新 IP 上，这将大大提高用户的访问体验。</p><h4 id="大型企业-DNS-负载均衡实践"><a href="#大型企业-DNS-负载均衡实践" class="headerlink" title="大型企业 - DNS 负载均衡实践"></a>大型企业 - DNS 负载均衡实践</h4><p>大规模应用。当后端有一两百台云服务器，而一台负载均衡 性能有限时，可以采用多个 负载均衡，前边通过 DNS 负载均衡。典型如：淘宝、阿里云官网。</p><p>DNS 有个最大的问题，就是 本地 DNS 缓存。</p><ol><li> 可以让 DNS TTL 生效快一点；</li><li> DNS 配置的是负载均衡 IP，而不是云服务器的 IP。</li><li> 如果还是有部分用户出问题，指导用户清理 DNS 缓存，或强制绑定本机 host 指向域名解析。</li></ol><p>智能解析 – 跨地域分布式架构中必不可少。根据 ClientIP，选择返回对应地域、运营商的 IP。</p><h5 id="运营商线路解析"><a href="#运营商线路解析" class="headerlink" title="运营商线路解析"></a>运营商线路解析</h5><p>如：DNS 记录：</p><ul><li>  默认线路：电信服务器 IP</li><li>  网通：网通 IP</li><li>  移动：移动 IP</li><li>  教育网：教育网 IP</li><li>  海外：海外 IP</li></ul><p>如果有 BGP 线路，那就更简单了：</p><ul><li>  默认线路：负载均衡的公网 IP</li></ul><h5 id="地域线路解析"><a href="#地域线路解析" class="headerlink" title="地域线路解析"></a>地域线路解析</h5><p>如：用户请求访问域名，DNS 自动判断访问者 IP 是「上海联通」还是「北京联通」，然后智能返回设置的对应的「上海联通」和「北京联通」的服务器 IP 地址完成域名解析。</p><p>海外：可以选择「海外、海外大洲、海外（国家 / 地区）」来细分解析。</p><p>如:</p><ul><li>  海外 - 亚洲地区 - 新加坡线路：指向新加坡服务器的 IP</li><li>  海外 - 北美洲 - 美国线路：指向美国服务器的 IP</li><li>  海外 - 欧洲 - 德国线路：指向德国服务器的 IP</li><li>  默认线路：指向新加坡服务器的 IP</li></ul><h4 id="CDN-就是智能解析的最佳实践"><a href="#CDN-就是智能解析的最佳实践" class="headerlink" title="CDN 就是智能解析的最佳实践"></a>CDN 就是智能解析的最佳实践</h4><h3 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h3><h4 id="云上善用「对象存储服务」"><a href="#云上善用「对象存储服务」" class="headerlink" title="云上善用「对象存储服务」"></a>云上善用「对象存储服务」</h4><p>云上建议尽量不要使用类 NAS 的共享文件存储服务，而应该使用 <strong>对象存储服务</strong> 来替代。<br>在传统环境，NAS 的典型使用场景如下：</p><ul><li><p><strong>负载均衡</strong>：使用 LB + 多台 云服务器（如：Web 服务器）部署的业务。多台 云服务器 需要访问同一个存储空间，以便多台 云服务器 共享数据。</p><ul><li>  <strong>替代方案</strong>：直接使用普通云数据盘，通过 DevOps 等工具实现批量部署及数据一致。</li></ul></li><li><p><strong>代码共享</strong>：多台 云服务器 应用，部署的代码一致。将代码放在同一个存储空间，提供给多台 云服务器 同时访问。代码集中管理。</p><ul><li>  <strong>替代方案</strong>：代码放在代码仓库中集中管理。</li></ul></li><li><p><strong>日志共享</strong>：多台 云服务器 应用，需要将日志写入到同一个存储空间，以便做集中的日志数据处理和分析</p><ul><li>  <strong>替代方案</strong>：日志定期存储到对象存储中，可以根据策略、冷热数据的实际情况选择分别存储到「标准对象存储」、「低频对象存储」和「归档存储」中进一步压缩成本；或直接使用云上的「日志服务」。</li></ul></li><li><p><strong>企业办公文件共享场景</strong>：企业有公共的文件需要共享给多组业务使用，需要集中的共享存储来存放数据。</p><ul><li>  <strong>替代方案</strong>：使用对象存储来替代。</li></ul></li><li><p><strong>容器服务的场景</strong>：部署的容器服务需要共享访问某个文件数据源，特别是在资源编排的容器服务。对应的容器可能会在不同的服务器中进行服务漂移，所以文件共享访问尤为重要。</p><ul><li>  <strong>替代方案</strong>：这种场景确实需要用到云上文件系统服务。</li></ul></li><li><p><strong>备份的场景</strong>：用户希望将数据备份到云上，可以通过挂载文件系统来存储数据备份。</p><ul><li>  <strong>替代方案</strong>：备份到对象存储的「归档存储」中，进一步降低成本。</li></ul></li></ul><h4 id="错误用法：NGINX-做公网转发到对象存储"><a href="#错误用法：NGINX-做公网转发到对象存储" class="headerlink" title="错误用法：NGINX 做公网转发到对象存储"></a>错误用法：NGINX 做公网转发到对象存储</h4><p>在某个客户场景中，静态资源放到 对象存储 中，前端对静态资源的请求通过 Nginx 反向代理转发给 对象存储。但这种做法，在云端架构上是不推荐的，因为它会带来几个问题：</p><ul><li>  访问静态资源的流量走 云服务器 的带宽流量，特别是中大型的 Web 应用中。流量走 云服务器 的带宽，很可能出现性能瓶颈。</li><li>  Nginx 是通过公网将请求反向代理转发给 对象存储 的，所以在网络传输上会影响速度性能。</li><li>  通过 Nginx 反向代理，不仅增加运维成本，还要维护 Nginx 配置文件等。</li></ul><p>所以，添加 Nginx 做反向代理是多此一举。云端不推荐这么做。该客户这么用，主要原因是业务代码侧，静态资源的请求，都是通过目录划分。如果将静态资源单独放在二级域名，跨域等问题代码侧没很好地解决，从而产生这种不伦不类的架构。最终在业务代码侧进行了优化调整，对 对象存储 静态资源的使用规范如下：</p><ul><li>  业务侧使用单独的二级域名来管理静态资源（如：&lt;<a href="http://pic-cdn.ewhisper.cn/">pic-cdn.ewhisper.cn</a>&gt;)，静态资源统一放在 对象存储 中；</li><li>  静态资源的二级域名直接将 CNAME 绑定在 对象存储 的 URL 地址上（访问量很少的情况下），这样就直接跳过「使用 Nginx 做反向代理」这个冗余的步骤了</li><li>如果想要进一步提升 对象存储 中存放的静态资源的访问速度，可以无缝接入 CDN。 CDN 的回源请求，会直接通过内网回源请求 对象存储 中的源数据。相比 Nginx 反向代理走公网请求 对象存储，速度和效率会提升得更高，价格特定情况下也会更划算。<ul><li>  👉 <a href="https://ewhisper.cn/posts/59535/#%E5%85%B8%E5%9E%8B%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%EF%BC%9ACDN-%20%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8">典型使用场景：CDN 对象存储</a></li></ul></li></ul><h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h3><h4 id="数据库推荐云服务-且必须有高可用保障"><a href="#数据库推荐云服务-且必须有高可用保障" class="headerlink" title="数据库推荐云服务 且必须有高可用保障"></a>数据库推荐云服务 且必须有高可用保障</h4><p>数据库不推荐自建，推荐直接使用云提供商的相关数据库服务，且推荐必备高可用保障，如集群模式或多副本，以及数据备份。<br>数据库优先采用云提供商的相关数据库服务 ，低成本高效率：如果在云上购买云服务器自建 MySQL 主从部署并维护的模式，使得后期的维护管理成本很大。即我们要监控及维护主从状态，并且在出现问题时需要及时处理，保障业务对数据库读写的连续性。在采用云提供商的相关数据库服务 后，这些问题都可以自动化解决。即对数据库主从的监控、备份、后期维护、故障切换等，都是全自动。</p><h4 id="对于可靠性要求特别高的-DB，可以选择跨-AZ-高可用的集群方案"><a href="#对于可靠性要求特别高的-DB，可以选择跨-AZ-高可用的集群方案" class="headerlink" title="对于可靠性要求特别高的 DB，可以选择跨 AZ 高可用的集群方案"></a>对于可靠性要求特别高的 DB，可以选择跨 AZ 高可用的集群方案</h4><p>对于可靠性要求特别高的 DB，可以选择跨 AZ 高可用的集群方案。比如：Redis、MongoDB、MySQL 都有类似的跨 AZ 高可用的集群方案提供。</p><h4 id="按需选择合适的数据库"><a href="#按需选择合适的数据库" class="headerlink" title="按需选择合适的数据库"></a>按需选择合适的数据库</h4><p>数据库多种多样，根据自己的实际需求进行选择，以下列出部分：</p><ul><li>关系型数据库<ul><li>  MySQL</li><li>  SQL Server</li><li>  Postgresql</li><li>  MariaDB</li><li>  分布式数据库（如 OceanBase 或 TDSQL 等）</li></ul></li><li>非关系型：内存数据库<ul><li>  Redis</li><li>  Memcache</li></ul></li><li>  文档数据库：MongoDB</li><li>列数据库<ul><li>  HBase 等</li></ul></li><li>时序数据库<ul><li>  InfluxDB</li><li>  TSDB</li></ul></li></ul><h3 id="CDN"><a href="#CDN" class="headerlink" title="CDN"></a>CDN</h3><h4 id="典型使用场景：CDN-对象存储"><a href="#典型使用场景：CDN-对象存储" class="headerlink" title="典型使用场景：CDN + 对象存储"></a>典型使用场景：CDN + 对象存储</h4><ul><li>  <strong>数据分发</strong>：适用于搭建下载行为较多的 APP、音视频平台、网站等，用户可结合 CDN + 对象存储 的能力，将静态内容（包括音视频、图片等文件）托管在对象存储中，并将热点文件提前下发至 CDN 边缘节点，降低下载访问延迟</li><li>  <strong>网站托管</strong>：适用于官方网站等偏静态的站点，将网站的静态资源快速托管存储在对象存储中，同时通过 CDN + 对象存储 分发，通过 CDN 配置的域名作为静态网站访客的访问地址入口，快速建好一个网站</li></ul><h3 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h3><h4 id="必须设置强密码"><a href="#必须设置强密码" class="headerlink" title="必须设置强密码"></a>必须设置强密码</h4><p>典型如：MongoDB、Redis、ES，默认无密码或弱密码，已经发生过多轮、大规模的数据泄露事件，所以针对这些服务，一定要设置强密码。<br>至于云服务器、云账户、关系型数据库等，更是要保障强密码或者更强力的安全措施。</p><h4 id="客户端访问必须-HTTPS"><a href="#客户端访问必须-HTTPS" class="headerlink" title="客户端访问必须 HTTPS"></a>客户端访问必须 HTTPS</h4><p>这个就不多说了。</p><ul><li>  给域名申请证书，放在 Nginx 或 LB 上 管理。</li><li>  业务侧，保留 HTTP 80 端口，做 80 -&gt; 443 的重定向。LB 上 80 和 443 端口监听都要开启。</li></ul><h4 id="一定要配置安全组和-ACL"><a href="#一定要配置安全组和-ACL" class="headerlink" title="一定要配置安全组和 ACL"></a>一定要配置安全组和 ACL</h4><p>最基本的安全防护</p><h4 id="不要-root-直连"><a href="#不要-root-直连" class="headerlink" title="不要 root 直连"></a>不要 root 直连</h4><p>不要 root 直连，用普通用户，登陆过去按需 sudo 切换到 root</p><h4 id="建议暴露公网的-SSH-端口不要用-22"><a href="#建议暴露公网的-SSH-端口不要用-22" class="headerlink" title="建议暴露公网的 SSH 端口不要用 22"></a>建议暴露公网的 SSH 端口不要用 22</h4><p>建议不要用默认的 22 端口，防止被扫描。另外还有建议用证书认证等方式，就不一一赘述了。</p><h4 id="免费安全产品别忘领"><a href="#免费安全产品别忘领" class="headerlink" title="免费安全产品别忘领"></a>免费安全产品别忘领</h4><p>如每开通一台云服务器，都会赠送一些免费额度的「DDoS 防护和主机安全防护」。有基本的防护，会比裸奔安全很多。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://ewhisper.cn/posts/59535/&quot;&gt;https://ewhisper.cn/posts/59535/&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;h2 id=&quot;最佳实践&quot;&gt;&lt;a href=&quot;#最佳实践&quot; class=&quot;hea</summary>
      
    
    
    
    <category term="公有云" scheme="http://zhangyu.info/categories/%E5%85%AC%E6%9C%89%E4%BA%91/"/>
    
    
    <category term="公有云" scheme="http://zhangyu.info/tags/%E5%85%AC%E6%9C%89%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>为什么互联网大厂一边大规模裁员又一边招聘</title>
    <link href="http://zhangyu.info/2022/04/23/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BA%92%E8%81%94%E7%BD%91%E5%A4%A7%E5%8E%82%E4%B8%80%E8%BE%B9%E5%A4%A7%E8%A7%84%E6%A8%A1%E8%A3%81%E5%91%98%E5%8F%88%E4%B8%80%E8%BE%B9%E6%8B%9B%E8%81%98/"/>
    <id>http://zhangyu.info/2022/04/23/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BA%92%E8%81%94%E7%BD%91%E5%A4%A7%E5%8E%82%E4%B8%80%E8%BE%B9%E5%A4%A7%E8%A7%84%E6%A8%A1%E8%A3%81%E5%91%98%E5%8F%88%E4%B8%80%E8%BE%B9%E6%8B%9B%E8%81%98/</id>
    <published>2022-04-22T16:00:00.000Z</published>
    <updated>2022-06-09T04:56:47.045Z</updated>
    
    <content type="html"><![CDATA[<p>作者：东岳老师</p><p><a href="https://www.zhihu.com/people/tian-tian-quan-75-47">https://www.zhihu.com/people/tian-tian-quan-75-47</a></p><blockquote><p>真实在大厂工作过，十几年的互联网老兵告诉你事实。</p><p>大厂里面有很多的业务线，也有很多的部门，每个部门负责的都不一样，阿里不是只做淘宝，腾讯也不是只做微信，一个大厂有数百条业务线，有的赚钱，有的赔钱。但是通常赔钱的最多。</p><p>通常大厂是这样玩的:</p><p>上层领导看中了一个方向，比如说游戏是赚钱的，于是就大量开始招聘游戏岗位。</p><p>公司往这方面投钱，比如说一年投入1000万，然后制定一个目标，实现三年盈利。通过招聘，你顺利进入了他们的游戏业务线，成为大厂员工。</p><p>光环加顶，有些刚进入大厂的员工觉以为祖坟冒青烟了，但也可能冒黑烟。</p><p>因为公司业务线刚开辟，所以就大量招人，高层来赌这个业务三年后一定盈利。把人力，金钱，物力投入进去。至于高层哪来的那么大自信赌成功，说真的，他们也都是懵逼状态。</p><p><strong>高层之间也内卷，总裁副总裁一大批，负责的业务都不同。</strong></p><p>我在某厂做总监时，经常跟一些总裁开会讨论方案，他们真的啥也不懂。因为这群人年龄太大了，很多都是投资人，根本不懂互联网，都是瞎指挥。</p><p>懂互联网的也是极个别人，总裁眼里只有钱。其他都没有。各种不着调的想法每次和他们开完会恨不能摔门而去。</p><p>但你还得执行他们不靠谱的想法，谁让咱们是打工人。就算方案是屎也得给老板做出臭豆腐的口感。实现不了怎么办，假装很努力的加班啊，得让老板看到咱很努力的干啊。</p><p>高层画大饼不要紧，咱也得吃饭啊。</p><p>高层天天开会，传达给中层的就TM一句话，今年我们要实现十个亿的目标!</p><p>卧槽，毛线都没有呢，那怎么办，上有政策下有对策，中层也有办法，你们知道中层每天都在干什么吗，天天写PPT!天天给高层做实现十个亿目标的汇报，一次一次被打回重改，直到改到高层认为PPT可以真的能实现十个亿目标位置。</p><p>PPT是个好东西，不仅能造车，还能造梦!</p><p>很遗憾的是，高层和中层一本正经的搞了PPT很长时间，大家一致认为从PPT上面已经证明能够实现十个亿的目标。</p><p>但多数业务实际根本不可能像预想的那样盈利，PPT终究是PPT，当不能盈利时，这条业务线就会被砍掉，你经常发现大厂裁员是整条业务线从上到下全部被裁掉就是这个问题。</p><p>老板层总是有各种想法，每年都要想我要做什么，总之都是为了赚钱。</p><p>有的老板都是拍脑门，反正人家有钱，玩得起。瞎折腾怕什么，万一折腾成功了呢。就像有个人说的那样，梦想总是有的，万一实现了呢。</p><p>把钱往里面一投资，找一堆写手，做几篇新闻，搞几个概念，开始忽悠了。全都给我上，产品，技术，运营，招起来!上层要干什么事情呢，上层要拿着PPT去资本市场忽悠钱。</p><p>有一次和某个总裁喝酒，无意之间他说了一句话，我们不这样的话，股票就会跌的，我们只有这样做股票才能涨。</p><p>我忽然恍然大悟，其实他们根本不是做互联网的，他们就是一群在股市圈钱的人。是的，只要折腾起来，股民才会不断的被割韭菜。原来赔掉的钱可以通过股市赚回来!资本市场才是真正赚钱的地方。</p><p>互联网从诞生开始，就是靠资本一轮一轮融资的吹起来的，互联网公司本质就是投资公司，而高层就是投资人，靠着一个一个的故事融钱，用钱赚钱，而至于这个业务，他们并不关心能不能做成。他们只关心手里的股票能不能升值。</p><p>但是问题是，你不可能所有开辟的业务线都赔钱吧，股东也不是傻子啊，靠股市画大饼早晚会被做空。所以他们总得有点赚钱的业务啊。</p><p>十条业务线九条可能都赔钱，但有一条业务线赚钱就成功。公司高层都是赌徒心理，因为他们也没办法判断哪个业务能成功。多生几个孩子，总有一个孩子能成器吧。</p><p>不成器的孩子怎么办，放弃吧。然后继续生孩子，继续招人。大厂靠着自己的招牌不用担心招不到人，反正人人都想进大厂。</p><p>就算全都裁掉，照样能够招到。就算赔掉一个亿对大厂来说只不过是交学费而已。毕竟人家赚一个亿也就是小目标。</p><p>那问题在于，为什么他们不用原有的团队做呢，因为原有团队在高层看来就是败军之将，给你三年时间都没搞成你在高层眼里已经没有价值，不裁你才怪呢。老板看你不顺眼，他们眼中只有一个单词：loser!</p><p><strong>这类新闻屡见不鲜:</strong></p><p>字节跳动方面，本地生活和房产业务受到影响。去年10月，字节跳动本地生活被曝出从22个城市撤退，仅保留了北京、上海等几个城市。</p><p>字节跳动HR相关负责人回应媒体称，裁员信息属实，系公司正常业务调整。</p><p>大部分的公司都是公司业务正常调整，简单来说就是，这孩子不成器，赶出家门。</p><p><strong>那你说，我这条业务线搞成了，那总不会被裁吧。</strong></p><p>呵呵，你想的天真了，一条业务线搞成了照样裁掉一半，这叫<strong>组织人员优化</strong>，本身做这条业务线就需要大量人参与进来，就像你建一座桥，建设时候需要几千人，建完了只需要几十人维护就可以了。</p><p>那你说，我只要努力就不会被裁吧，呵呵，裁掉你和你努力不努力无关系，什么末尾淘汰制只不过是裁你的理由，制定一个规则，让员工内卷，因为员工内卷对企业最有好处。</p><p><strong>只有裁员，才能让员工感到危机。</strong></p><p>你虽然花费了大量时间精力，什么996啊，公司是不会看在眼里的，公司只看你成本太高了。</p><p>三十五岁为什么会被裁，你知道，你在一家公司干十年你的薪资得有多高，不给你加薪资你不满意，给你加薪资老板不满意，反正有的是人干活，这么高薪资不需要你了，就裁掉了。</p><p><strong>与你能力无关系。只和你成本有关系。</strong></p><p>在大厂的业务线，中层压力最大，因为裁员先把中层干掉。中层在公司的定位就是背锅的，中层一般都是总监或者级别副总裁级，负责承上启下，只要业务快玩完了，为了给公司交代，稳定军心，高层首先要把中层拿来祭旗了。</p><p>中层天天要逼着底层加班，也并不是真的很忙，因为他要做给高层看，让高层觉得他很努力，一定能成功。但是中层消息也很灵敏，见势不妙，没等裁员就脚底抹油提前跑路了。</p><p>跑之前中层这群老油条们还得给底层没有经验的职场小白PUA，兄弟们，挺住，困难只是暂时的。只要团结一心，一定可以的！</p><p>你会说中层难道不想要补偿吗？呵呵，你太小看中层了，在业务没有倒闭前另谋其主，还TM能吹牛皮一把说这业务做的很成功。</p><p>你看，离开我就倒闭了吧。真要耗到业务干倒闭了拿那个裁员补偿，对他们来说找工作都不好找。中层早就提前谋划好了出路，重要的人该走的都走光了。</p><p>多说句中层的话题，中层之间也经常在一起喝酒，不同的业务线之间也会互相交流经验，我参加过很多聚餐，喝酒前大家牛皮吹一波，我们做的是十个亿的大项目，这算什么，我们做的是一百亿的大项目。</p><p>你们说的都不是什么，我们定下目标一千亿。酒过三巡，真情流露，大家互相安慰，兄弟，早撤吧，我看透了，这活没希望。</p><p>等你有一天做了中层，就知道中层才是互联网公司最苦逼的，上面领导骂你，底下员工骂你，回家老婆骂你，辞职不敢，没有一边讨好。多少底层想要往上爬到中层，等你爬上去，就知道这哪是人生巅峰，是TM火山口!</p><p>上也上不去，下也下不来。每件事处理起来都是贼烫手。做中层久了就知道，有些事不能硬撑，关键时候跑路才是上上策，孙子兵法得作为案头书天天阅读，不然你怎么在这么复杂的环境中生存下去。</p><p>这就是你看到的类似新闻:</p><p><strong>某某大厂某事业部负责人离职，加入某某公司。</strong></p><p>但你看到这种消息后一般还不到裁员时候，因为裁员需要一个过程。</p><p>三个月后，轮到HR上场了，HR会在一夜之间发个通告，因某某原因，公司无法经营，宣布裁员，底层员工被打的措手不及!</p><p>前一天还在加班到凌晨十二点，这时候你忽然看到HR也在加班，你心里想，嗯，公司又开始招人了。</p><p>公司肯定发展越来越好了。其实人家加班是制定裁员名单呢，今天一上班就被告知裁员。没等你反应过来，整个部门都没有了。</p><p>HR才是互联网公司效率最高的职位!昨天，还许诺你加薪，今天你一脸懵逼的发呆，看着同事一个一个打包离开。</p><p>HR就告诉你一句话，今天必须走。按劳动合同，给你n+1补偿。其实发布裁员公告之前，所有准备都已经提前三个月准备好了。连给你n+1的钱都准备好了。</p><p>有的大厂裁员也很有情怀，临走还发给职场小白一个毕业证，<strong>同学!恭喜你在某厂顺利毕业了!</strong></p><p>呵呵，有的应届生刚入职第一天就毕业了，这速度真TM的快啊!给我的50万年薪呢？这么快就没了?咱好歹号称是大厂啊，别这样糊弄人行不？</p><p>这时候你看到的新闻就是:</p><p>某厂内部员工在某APP传闻裁员，整个事业部都被裁撤，未经官方证实。</p><p>于是一轮从招聘到裁员的过程就结束了，宣布一条不靠谱的业务线彻底消失，老板的大饼没有画成。</p><p>从项目立项，到招人，到投资扩建，到疯狂炒概念，再到负责人离职，内部传出裁员，公司证实属实。</p><p>众位朋友，等你经历互联网十年你就知道这种招聘裁员戏天天上演。只是大部分都没有爆出来而已。因为很多业务线都不起眼，还没有人知道就已经消亡了。</p><p>然后公司继续开辟新业务线，继续靠着大厂这个招牌白嫖打工者的青春，反正你不来是有别人来，我反正是给钱的，你不做还有别人做。真招不到人就开始画大饼，给应届生开高薪。</p><p>一毕业就来个年薪五十万，卧槽，我这工作十几年的都没一个应届生薪资高，你招他来做什么？</p><p>后来我明白，很多人都是凑数的。裁员的时候容易点。要招我这种老油条，连签合同我都得看三遍，敢裁我，分分钟给你讲劳动法。别TM忽悠我，罗翔的刑法讲义我天天看。</p><p>应届生就容易多了，签合同都不看一眼，裁你时候给你一个绩效不合格，他们还觉得自己没有尽全力，对不起公司。也不用n+1补偿，因为连n都没有。看起来薪资那么高，其实用工成本真的很廉价。很多都是做给外界看的。</p><p>其实很多人，不过是陪着高层赌未来，高层赌不对没关系，可以继续赌，毕竟人家不会担心自己被裁掉。本身高层眼里也没有员工，只有利益，员工自己堵不对，只能被裁了。</p><p>老板赌上的是钱，员工陪赌的是未来。老板赌输了钱，大不了再赌一把，员工赌没了未来，就真的啥也没有了。有的员工连命都赔赌进去了。</p><p>所谓某些互联网大厂，也不过是披着一层炫酷的外衣，进去也是996的工作。因为你得陪着老板赌这种不靠谱的未来。</p><p>只是，你人生需要做的是淡定！看庭前花开花落，云卷云舒，莫纠结！很多事情，对打工人来说都很无奈，最后苦的还是打工人。</p><p>你方唱罢我登场，今天他被裁，明天你被裁，也只是打工人的命运。与你能力高低真没关系。如果有关系，那你不过是个背锅侠而已。裁你，也只是杀鸡给猴看。</p><p>领导说，我们给社会每年输送一千人才。呵呵，确实是这样，陪你玩几年，你赚的盆满钵满，我们成了人才。两全其美，何乐不为呢。</p><p>我TM混了互联网十五年不是做人才就是走在做人才的路上!</p><p>青春就那么几年，你从小到大都是很优秀，拿着985的学历拼进大厂，恋爱都不敢谈，每天996的为公司奋斗，养着房东，养着这个城市，养着身体几十万亿的细胞。</p><p>不到三十岁的小伙子头发秃顶，肾虚无力，腰间盘突出，赌上了自己一切，用自己拼搏卷走了无数人，梦想有一天出人头地，你做好了最优秀的自己，无一刻休息，只为了明天更好，最后结局被裁了。最后如梦初醒，才知道自己是小丑。</p><p>真实，上面的话都不敢说，我敢说只因为我不在大厂干了，也不想再进去。就算封杀我也无所谓。我坚决反对拿员工前途做赌注的公司!</p><p>我要说这些话，也希望企业裁员慎重考虑!同时也希望企业不要盲目的招聘，因为真的很多同学因为你们的招聘赌上了未来。我不怕得罪那么多的大厂，我只希望彼此都真诚些，大家都是为了更好的未来。</p><p>我没有针对任何大厂，我只说一种现象，希望我写这些不会被封掉。</p><p>人生苦短，善待自己!</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;作者：东岳老师&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/people/tian-tian-quan-75-47&quot;&gt;https://www.zhihu.com/people/tian-tian-quan-75-47&lt;/a&gt;&lt;/p&gt;
&lt;blo</summary>
      
    
    
    
    <category term="我假装讲-你假装看" scheme="http://zhangyu.info/categories/%E6%88%91%E5%81%87%E8%A3%85%E8%AE%B2-%E4%BD%A0%E5%81%87%E8%A3%85%E7%9C%8B/"/>
    
    
    <category term="我假装讲-你假装看" scheme="http://zhangyu.info/tags/%E6%88%91%E5%81%87%E8%A3%85%E8%AE%B2-%E4%BD%A0%E5%81%87%E8%A3%85%E7%9C%8B/"/>
    
  </entry>
  
  <entry>
    <title>Linux的CPU上下文切换深入探讨</title>
    <link href="http://zhangyu.info/2022/04/23/Linux%E7%9A%84CPU%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%E6%B7%B1%E5%85%A5%E6%8E%A2%E8%AE%A8/"/>
    <id>http://zhangyu.info/2022/04/23/Linux%E7%9A%84CPU%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%E6%B7%B1%E5%85%A5%E6%8E%A2%E8%AE%A8/</id>
    <published>2022-04-22T16:00:00.000Z</published>
    <updated>2022-04-23T15:03:30.595Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/3fJvAjgPmi6N8XUQ4QII4w">https://mp.weixin.qq.com/s/3fJvAjgPmi6N8XUQ4QII4w</a></p><blockquote><p><em>链接：<a href="https://medium.com/geekculture/linux-cpu-context-switch-deep-dive-764bfdae4f01">https://medium.com/geekculture/linux-cpu-context-switch-deep-dive-764bfdae4f01</a></em></p></blockquote><blockquote><p>我们都知道 Linux 是一个多任务操作系统，它支持的任务同时运行的数量远远大于 CPU 的数量。当然，这些任务实际上并不是同时运行的（Single CPU），而是因为系统在短时间内将 CPU 轮流分配给任务，造成了多个任务同时运行的假象。</p><h2 id="CPU-上下文（CPU-Context）"><a href="#CPU-上下文（CPU-Context）" class="headerlink" title="CPU 上下文（CPU Context）"></a>CPU 上下文（CPU Context）</h2><p>在每个任务运行之前，CPU 需要知道在哪里加载和启动任务。这意味着系统需要提前帮助设置 CPU <strong>寄存器</strong>和<strong>程序计数器</strong>。</p><p>CPU 寄存器是内置于 CPU 中的小型但速度极快的内存。程序计数器用于存储 CPU 正在执行的或下一条要执行指令的位置。</p><p>它们都是 CPU 在运行任何任务之前必须依赖的依赖环境，因此也被称为 “CPU 上下文”。如下图所示：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/QFzRdz9libEa4QiaK9HAa6licygbok94QEpljrPgEZa2rHcgdQc0BG8icMAkOabSYqPjVaP9ulIZNKZ9RAwm7j26Fg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>知道了 CPU 上下文是什么，我想你理解 <strong>CPU 上下文切换</strong>就很容易了。“CPU上下文切换”指的是先保存上一个任务的 CPU 上下文（CPU寄存器和程序计数器），然后将新任务的上下文加载到这些寄存器和程序计数器中，最后跳转到程序计数器。</p><p>这些保存的上下文存储在系统内核中，并在重新安排任务执行时再次加载。这确保了任务的原始状态不受影响，并且任务似乎在持续运行。</p><h2 id="CPU-上下文切换的类型"><a href="#CPU-上下文切换的类型" class="headerlink" title="CPU 上下文切换的类型"></a>CPU 上下文切换的类型</h2><p>你可能会说 CPU 上下文切换无非就是更新 CPU 寄存器和程序计数器值，而这些寄存器是为了快速运行任务而设计的，那为什么会影响 CPU 性能呢？</p><p>在回答这个问题之前，请问，你有没有想过这些“任务”是什么？你可能会说一个任务就是一个<strong>进程</strong>或者一个<strong>线程</strong>。是的，进程和线程正是最常见的任务，但除此之外，还有其他类型的任务。</p><p>别忘了<strong>硬件中断</strong>也是一个常见的任务，硬件触发信号，会引起中断处理程序的调用。</p><p>因此，CPU 上下文切换至少有三种不同的类型：</p><ul><li><p>  进程上下文切换</p></li><li><p>  线程上下文切换</p></li><li><p>  中断上下文切换</p></li></ul><p>让我们一一来看看。</p><h2 id="进程上下文切换"><a href="#进程上下文切换" class="headerlink" title="进程上下文切换"></a>进程上下文切换</h2><p>Linux 按照特权级别将进程的运行空间划分为内核空间和用户空间，分别对应下图中 <code>Ring 0</code> 和 <code>Ring 3</code> 的 CPU 特权级别的 。</p><ul><li><p>  <strong>内核空间</strong>（<code>Ring 0</code>）拥有最高权限，可以直接访问所有资源</p></li><li><p>  <strong>用户空间</strong>（<code>Ring 3</code>）只能访问受限资源，不能直接访问内存等硬件设备。它必须通过<strong>系统调用</strong>被<strong>陷入（trapped）</strong>内核中才能访问这些特权资源。</p></li></ul><p><img src="https://mmbiz.qpic.cn/mmbiz_png/QFzRdz9libEa4QiaK9HAa6licygbok94QEpMSWZMNUExiaibUIoicUEeT7jdF4d59q7lJQicHQ6Xhe3kbicscVKu3GRBKg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>从另一个角度看，一个进程既可以在用户空间也可以在内核空间运行。当一个进程在<strong>用户空间</strong>运行时，称为该进程的<strong>用户态</strong>，当它落入<strong>内核空间</strong>时，称为该进程的<strong>内核态</strong>。</p><p>从<strong>用户态</strong>到<strong>内核态</strong>的转换需要通过<strong>系统调用</strong>来完成。例如，当我们查看一个文件的内容时，我们需要以下系统调用：</p><ul><li><p>  <code>open()</code>：打开文件</p></li><li><p>  <code>read()</code>：读取文件的内容</p></li><li><p>  <code>write()</code>：将文件的内容写入到输出文件（包括标准输出）</p></li><li><p>  <code>close()</code>：关闭文件</p></li></ul><p>那么在上述系统调用过程中是否会发生 CPU 上下文切换呢？当然是的。</p><p>这需要先保存 CPU 寄存器中原来的用户态指令的位置。接下来，为了执行内核态的代码，需要将 CPU 寄存器更新到内核态指令的新位置。最后是跳转到内核态运行内核任务。</p><p>那么系统调用结束后，CPU 寄存器需要<strong>恢复</strong>原来保存的用户状态，然后切换到用户空间继续运行进程。</p><blockquote><p>因此，在一次系统调用的过程中，实际上有两次 CPU 上下文切换。</p></blockquote><p>但需要指出的是，系统调用进程不会涉及进程切换，也不会涉及虚拟内存等系统资源切换。这与我们通常所说的“进程上下文切换”不同。进程上下文切换是指从一个进程切换到另一个进程，而系统调用期间始终运行同一个进程</p><p>系统调用过程通常被称为<strong>特权模式切换</strong>，而不是<strong>上下文切换</strong>。但实际上，在系统调用过程中，CPU 的上下文切换也是不可避免的。</p><h3 id="进程上下文切换-vs-系统调用"><a href="#进程上下文切换-vs-系统调用" class="headerlink" title="进程上下文切换 vs 系统调用"></a>进程上下文切换 vs 系统调用</h3><p>那么进程上下文切换和系统调用有什么区别呢？首先，进程是由内核管理的，进程切换只能发生在内核态。因此，进程上下文不仅包括<strong>虚拟内存</strong>、<strong>栈</strong>和<strong>全局变量</strong>等用户空间资源，还包括<strong>内核栈</strong>和<strong>寄存器</strong>等内核空间的状态。</p><p>所以<strong>进程上下文切换</strong>比<strong>系统调用</strong>要多出一步：</p><blockquote><p>在保存当前进程的内核状态和 CPU 寄存器之前，需要保存进程的虚拟内存、栈等；并加载下一个进程的内核状态。</p></blockquote><p>根据 Tsuna 的测试报告，每次上下文切换需要几十纳秒至微秒的 CPU 时间。这个时间是相当可观的，尤其是在大量进程上下文切换的情况下，很容易导致 CPU 花费大量时间来保存和恢复寄存器、内核栈、虚拟内存等资源。这正是我们在上一篇文章中谈到的，一个导致平均负载上升的重要因素。</p><p>那么，该进程何时会被调度/切换到在 CPU 上运行？其实有很多场景，下面我为大家总结一下：</p><ul><li><p>  当一个进程的 CPU 时间片用完时，它会被系统<strong>挂起</strong>，并切换到其他等待 CPU 运行的进程。</p></li><li><p>  当系统资源不足（如内存不足）时，直到资源充足之前，进程无法运行。此时进程也会被<strong>挂起</strong>，系统会调度其他进程运行。</p></li><li><p>  当一个进程通过 <code>sleep</code> 函数自动<strong>挂起自己</strong>时，自然会被重新调度。</p></li><li><p>  当优先级较高的进程运行时，为了保证高优先级进程的运行，当前进程会被高优先级进程<strong>挂起运行</strong>。</p></li><li><p>  当发生硬件中断时，CPU 上的进程会被<strong>中断挂起</strong>，转而执行内核中的中断服务程序。</p></li></ul><p>了解这些场景是非常有必要的，因为一旦上下文切换出现性能问题，它们就是幕后杀手。</p><h2 id="线程上下文切换"><a href="#线程上下文切换" class="headerlink" title="线程上下文切换"></a>线程上下文切换</h2><p>线程和进程最大的区别在于，线程是<strong>任务调度</strong>的基本单位，而进程是<strong>资源获取</strong>的基本单位。</p><p>说白了，内核中所谓的任务调度，实际的调度对象是线程；而进程只为线程提供虚拟内存和全局变量等资源。所以，对于线程和进程，我们可以这样理解：</p><ul><li><p>  当一个进程只有一个线程时，可以认为一个进程等于一个线程</p></li><li><p>  当一个进程有多个线程时，这些线程共享相同的资源，例如虚拟内存和全局变量。</p></li><li><p>  此外，线程也有自己的私有数据，比如栈和寄存器，在上下文切换时也需要保存。</p></li></ul><p>这样，线程的上下文切换其实可以分为两种情况：</p><ul><li><p>  首先，前后两个线程属于不同的进程。此时，由于资源不共享，切换过程与进程上下文切换相同。</p></li><li><p>  其次，前后两个线程属于同一个进程。此时，由于虚拟内存是共享的，所以切换时虚拟内存的资源保持不变，只需要切换线程的私有数据、寄存器等未共享的数据。</p></li></ul><p>显然，同一个进程内的线程切换比切换多个进程消耗的资源要少。这也是多线程替代多进程的优势。</p><h2 id="中断上下文切换"><a href="#中断上下文切换" class="headerlink" title="中断上下文切换"></a>中断上下文切换</h2><p>除了前面两种上下文切换之外，还有另外一种场景也输出 CPU 上下文切换的，那就是<strong>中断</strong>。</p><p>为了快速响应事件，硬件中断会中断正常的调度和执行过程，进而调用<strong>中断处理程序</strong>。</p><p>在中断其他进程时，需要保存进程的当前状态，以便中断后进程仍能从原始状态恢复。</p><p>与进程上下文不同，中断上下文切换不涉及进程的用户态。因此，即使中断进程中断了处于用户态的进程，也不需要保存和恢复进程的虚拟内存、全局变量等用户态资源。</p><p>另外，和进程上下文切换一样，中断上下文切换也会消耗 CPU。过多的切换次数会消耗大量的 CPU 资源，甚至严重降低系统的整体性能。因此，当您发现中断过多时，需要注意排查它是否会对您的系统造成严重的性能问题。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>综上所述，无论哪种场景导致上下文切换，你都应该知道：</p><p>CPU 上下文切换是保证 Linux 系统正常运行的核心功能之一，一般不需要我们特别关注。</p><p>但是过多的上下文切换会消耗 CPU 的时间来保存和恢复寄存器、内核栈、虚拟内存等数据，从而缩短进程的实际运行时间，导致系统整体性能显着下降。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/3fJvAjgPmi6N8XUQ4QII4w&quot;&gt;https://mp.weixin.qq.com/s/3fJvAjgPmi6N8XUQ4QII4w&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em</summary>
      
    
    
    
    <category term="linux" scheme="http://zhangyu.info/categories/linux/"/>
    
    
    <category term="linux" scheme="http://zhangyu.info/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>微服务架构及设计模式</title>
    <link href="http://zhangyu.info/2022/04/23/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E5%8F%8A%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    <id>http://zhangyu.info/2022/04/23/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E5%8F%8A%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</id>
    <published>2022-04-22T16:00:00.000Z</published>
    <updated>2022-04-23T14:12:56.733Z</updated>
    
    <content type="html"><![CDATA[<p> <a href="https://colstuwjx.github.io/2020/01/%E7%BF%BB%E8%AF%91-%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E5%8F%8A%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">https://colstuwjx.github.io/2020/01/%E7%BF%BB%E8%AF%91-%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E5%8F%8A%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</a></p><p>原文：<a href="https://medium.com/@madhukaudantha/microservice-architecture-and-design-patterns-for-microservices-e0e5013fd58a">https://medium.com/@madhukaudantha/microservice-architecture-and-design-patterns-for-microservices-e0e5013fd58a</a></p><blockquote><p>本文介绍了主流常见的微服务模式。</p><p>微服务能够对企业产生积极影响。因此，了解如何处理微服务架构（MSA）以及一些微服务设计模式，一个微服务架构的一些通用目标或者设计原则是很有价值的。下面是在微服务架构方案中值得考虑的四个目标[1]。</p><p>1、缩减成本：MSA将会降低设计、实现和维护IT服务的总体成本</p><p>2、加快发布速度：MSA将会加快服务从想法到部署的落地速度</p><p>3、增强弹性：MSA将会提升我们服务网络的弹性</p><p>4、开启可见性：MSA支持为服务和网络提供更好的可见性</p><p>你需要了解建设微服务架构背后的几个设计原则：</p><ul><li>  可扩展性</li><li>  可用性</li><li>  韧性</li><li>  灵活性</li><li>  独立自主性，自治性</li><li>  去中心化治理</li><li>  故障隔离</li><li>  自动装配</li><li>  通过 DevOps 持续交付</li></ul><p>听取上述原则，在你实施的解决方案或系统付诸实践的同时，这也会带来一些挑战和问题。这些问题在许多解决方案中也很常见。使用正确及匹配的设计模式可以克服这些问题。微服务有一些设计模式，这可以大体分为五类。每类都包含许多具体的设计模式。下图展示了这些设计模式。</p><p><img src="https://colstuwjx.github.io/images/2019/Dec/design-patterns.png" alt="Design Patterns for Microservices"></p><p><em>图1 微服务设计模式</em></p><h2 id="分解模式"><a href="#分解模式" class="headerlink" title="分解模式"></a>分解模式</h2><h3 id="按业务功能进行分解"><a href="#按业务功能进行分解" class="headerlink" title="按业务功能进行分解"></a>按业务功能进行分解</h3><p>说白了，微服务就是要应用单一职责原则，把服务改造成松耦合式的。它可以按照业务功能进行分解。定义和业务功能相对应的服务。业务功能是一个来自业务架构建模 [2] 的概念。它是一个企业为了创造价值而要去做的某些事情。一个业务功能往往对应于一个业务对象，比如：</p><ul><li>  订单管理负责订单</li><li>  客户管理则是负责客户</li></ul><h3 id="按问题子域进行分解"><a href="#按问题子域进行分解" class="headerlink" title="按问题子域进行分解"></a>按问题子域进行分解</h3><p>按照业务功能来分解一个应用程序可能会是一个不错的开始，但是你终将会遇到所谓的“神类”，它很难再被分解。这些类将在多个服务之间都是通用的。可以定义一些和领域驱动设计（DDD）里面的子域相对应的服务。DDD 把应用程序的问题空间 —— 也即是业务 —— 称之为域。一个域由多个子域组成。每个子域对应业务的各个不同部分。</p><p>子域可以分为如下几类：</p><ul><li><p>  核心 —— 业务的核心竞争力以及应用程序最有价值的部分</p></li><li><p>  支撑 —— 和业务有关但并不是一个核心竞争力。这些可以在内部实现也可以外包</p></li><li><p>  通用 —— 不特定于业务，而且在理想情况下可以使用现成的软件实现</p></li></ul><p>一个订单管理的子域包括：</p><ul><li><p>  产品目录服务</p></li><li><p>  库存管理服务</p></li><li><p>  订单管理服务</p></li><li><p>  配送管理服务</p></li></ul><h3 id="按事务-两阶段提交（2pc）模式进行分解"><a href="#按事务-两阶段提交（2pc）模式进行分解" class="headerlink" title="按事务/两阶段提交（2pc）模式进行分解"></a>按事务/两阶段提交（2pc）模式进行分解</h3><p>你可以通过事务分解服务。然后，这样一来系统里将会存在多个事务。事务处理协调器[3]是分布式事务处理的重要参与者之一。分布式事务包括两个步骤：</p><ul><li><p>  准备阶段 —— 在这个阶段，事务的所有参与者都准备提交并通知协调员他们已准备好完成事务</p></li><li><p>  提交或回滚阶段 —— 在这个阶段，事务协调器向所有参与者发出提交或回滚命令</p></li></ul><p>2PC 的问题在于，和单个微服务的运行时间相比，它显得相当慢。即便这些微服务跑在相同的网络里，它们之间的事务协调也确实会减慢系统速度，因此这种方法通常不适用于高负载情况。</p><h3 id="绞杀者模式（Strangler-Pattern）"><a href="#绞杀者模式（Strangler-Pattern）" class="headerlink" title="绞杀者模式（Strangler Pattern）"></a>绞杀者模式（Strangler Pattern）</h3><p>上面三种，我们看到的这几个设计模式都是用来分解绿场（Greenfield）的应用程序，但是往往我们所做的工作中有 80％ 是针对灰场（brownfield）应用程序，它们是一些大型的单体应用程序（历史遗留的代码库）。绞杀者模式可以解决这类问题。它会创建两个单独的应用程序，它们并排跑在同一个 URI 空间里。随着时间的流逝，直到最后，新重构的应用程序会“干掉”或替换原有的应用程序，此时就可以关掉那个老的单体应用程序。绞杀应用程序的步骤分别是转换，共存和消除[4]：</p><ul><li><p>  转换（Transform） —— 使用现代方法创建一个并行的全新站点。</p></li><li><p>  共存（Coexist） —— 让现有站点保留一段时间。把针对现有站点的访问重定向到新站点，以便逐步实现所需功能。</p></li><li><p>  消除（Eliminate） —— 从现有站点中删除旧功能。</p></li></ul><h3 id="隔舱模式（Bulkhead-Pattern）"><a href="#隔舱模式（Bulkhead-Pattern）" class="headerlink" title="隔舱模式（Bulkhead Pattern）"></a>隔舱模式（Bulkhead Pattern）</h3><p>让一个应用程序的元素和池子相对隔离，这样一来，其他应用程序将可以继续正常工作。这种模式被称为“隔舱”，因为它类似于船体的分段分区。根据使用者负载和可用性要求，将服务实例分成不同的组。这种设计有助于隔离故障，并允许用户即使在故障期间仍可为某些使用者维持服务。</p><h3 id="边车模式"><a href="#边车模式" class="headerlink" title="边车模式"></a>边车模式</h3><p>该模式将一个应用程序的组件部署到一个单独的处理器容器里以提供隔离和封装。它还允许应用程序由异构的组件和技术组成。这种模式被称为边车模式（Sidecar），因为它类似于连接到摩托车的侧边车。在该模式中，侧边车会附加到父应用程序，并为该应用程序提供功能支持。Sidecar 还与父应用程序共享相同的生命周期，并与父应用程序一起创建和退出。Sidecar 模式有时也称为 sidekick 模式，这是我们在文章中列出的最后一个分解模式。</p><h2 id="集成模式"><a href="#集成模式" class="headerlink" title="集成模式"></a>集成模式</h2><h3 id="API-网关模式"><a href="#API-网关模式" class="headerlink" title="API 网关模式"></a>API 网关模式</h3><p>当一个应用程序被分解成多个较小的微服务时，这里会出现一些需要解决的问题：</p><ul><li><p>  存在不同渠道对多个微服务的多次调用</p></li><li><p>  需要处理不同类型的协议</p></li><li><p>  不同的消费者可能需要不同的响应格式</p></li></ul><p>API 网关有助于解决微服务实现引发的诸多问题，而不仅限于上述提到的这些。</p><ul><li><p>  API 网关是任何微服务调用的单一入口点</p></li><li><p>  它可以用作将请求路由到相关微服务的代理服务</p></li><li><p>  它可以汇总结果并发送回消费者</p></li><li><p>  该解决方案可以为每种特定类型的客户端创建一个细粒度的 API</p></li><li><p>  它还可以转换协议请求并做出响应</p></li><li><p>  它也可以承担微服务的身份验证/授权的责任。</p></li></ul><h3 id="聚合器模式（Aggregator-Pattern）"><a href="#聚合器模式（Aggregator-Pattern）" class="headerlink" title="聚合器模式（Aggregator Pattern）"></a>聚合器模式（Aggregator Pattern）</h3><p>将业务功能分解成几个较小的逻辑代码段后就有必要考虑如何协同每个服务返回的数据。不能把这个职责留给消费者。</p><p>聚合器模式有助于解决这个问题。<strong>它讨论了如何聚合来自不同服务的数据，然后将最终响应发送给消费者。</strong>这里有两种实现方式[6]：</p><p>1、一个组合微服务将调用所有必需的微服务，合并数据，然后在发送回数据之前对其进行转换合成</p><p>2、一个 API 网关还可以将请求划分成多个微服务，然后在将数据发送给使用者之前汇总数据</p><p>如果要应用一些业务逻辑的话，建议选择一个组合式的微服务。除此之外，API 网关作为这个问题的解决方案已经是既定的事实标准。</p><h3 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h3><p>针对 API 网关，我们只是借助它来对外公开我们的微服务。引入 API 网关后，我们得以获得一些像安全性和对 API 进行分类这样的 API 层面功能。在这个例子里，API 网关有三个 API 模块：</p><p>1、移动端 API，它实现了 FTGO 移动客户端的 API 2、浏览器端 API，它实现了在浏览器里运行的 JavaScript 应用程序的 API 3、公共API，它实现了一些第三方开发人员需要的 API</p><h3 id="网关路由模式"><a href="#网关路由模式" class="headerlink" title="网关路由模式"></a>网关路由模式</h3><p>API 网关负责路由请求。一个 API 网关通过将请求路由到相应的服务来实现一些 API 操作。当 API 网关接收到请求时，它会查询一个路由映射，该路由映射指定了将请求路由到哪个服务。一个路由映射可以将一个 HTTP 方法和路径映射到服务的 HTTP URL。这种做法和像 NGINX 这样的 Web 服务器提供的反向代理功能一样。</p><h3 id="链式微服务模式（Chained-Microservice-Pattern）"><a href="#链式微服务模式（Chained-Microservice-Pattern）" class="headerlink" title="链式微服务模式（Chained Microservice Pattern）"></a>链式微服务模式（Chained Microservice Pattern）</h3><p>单个服务或者微服务将会有多级依赖，举个例子：Sale 的微服务依赖 Product 微服务和 Order 微服务。链式微服务设计模式将帮助你提供合并后的请求结果。microservice-1 接收到请求后，该请求随后与 microservice-2 进行通信，还有可能正在和 microservice-3 通信。所有这些服务都是同步调用。</p><h3 id="分支模式"><a href="#分支模式" class="headerlink" title="分支模式"></a>分支模式</h3><p>一个微服务可能需要从包括其他微服务在内的多个来源获取数据。分支微服务模式是聚合器和链式设计模式的混合，并允许来自两个或多个微服务的同时请求/响应处理。调用的微服务可以是一个微服务链。分支模式还可用于根据你的业务需求调用不同的微服务链或单个链。</p><h3 id="客户端UI组合模式"><a href="#客户端UI组合模式" class="headerlink" title="客户端UI组合模式"></a>客户端UI组合模式</h3><p>通过分解业务功能/子域来开发服务时，负责用户体验的服务必须从多个微服务中提取数据。在一个单体世界里，过去只有一个从 UI 到后端服务的调用，它会检索所有数据然后刷新/提交 UI 页面。但是，现在不一样了。对于微服务而言，我们必须把 UI 设计成一个具有屏幕/页面的多个板块/区域的框架。每个板块都将调用一个单独的后端微服务以提取数据。诸如 AngularJS 和 ReactJS 之类的框架可以帮助我们轻松地实现这一点。这些屏幕称为单页应用程序（SPA）。每个团队都开发一个客户端 UI 组件，比如一个 AngularJS 指令，该组件实现其服务的页面/屏幕区域。UI 团队负责通过组合多个特定服务的 UI 组件来实现构建页面/屏幕的页面框架。</p><h2 id="数据库模式"><a href="#数据库模式" class="headerlink" title="数据库模式"></a>数据库模式</h2><p>给微服务定义数据库架构时，我们需要考虑以下几点：</p><p>1、服务必须是松耦合的。这样它们可以独立开发，部署和扩展</p><p>2、业务事务可能会强制跨越多个服务的不变量</p><p>3、一些业务事务需要查询多个服务的数据</p><p>4、为了可扩展性考虑，数据库有时候必须是可复制和共享的</p><p>5、不同服务存在不同的数据存储要求</p><h3 id="每个服务一套数据库"><a href="#每个服务一套数据库" class="headerlink" title="每个服务一套数据库"></a>每个服务一套数据库</h3><p>为了解决上述问题，必须为每个微服务设计一个数据库。它必须仅专用于该服务。应当只能通过微服务的 API 访问它。其他服务无法直接访问它。比如，针对关系型数据库，我们可以采用每个服务使用单独的专用表（private-tables-per-service），每个服务单独的数据库模式（schema-per-service）或每个服务单独的数据库服务器（database-server-per-service）。</p><h3 id="服务之间共享数据库"><a href="#服务之间共享数据库" class="headerlink" title="服务之间共享数据库"></a>服务之间共享数据库</h3><p>我们已经说过，在微服务里，为每个服务分配一套单独的数据库是理想方案。采用共享数据库在微服务里属于反模式。但是，如果应用程序是一个单体应用而且试图拆分成微服务，那么反正规化就不那么容易了。在后面的阶段里，我们可以转到每个服务一套数据库的模式，直到我们完全做到了这一点。服务之间共享数据库并不理想，但是对于上述情况，它是一个切实可行的解决方案。大多数人认为这是微服务的反模式，但是对于灰场应用程序，这是将应用程序分解成更小逻辑部分的一个很好的开始。值得一提的是，这不应当应用于绿场应用程序。</p><h3 id="命令和查询职责分离-CQRS"><a href="#命令和查询职责分离-CQRS" class="headerlink" title="命令和查询职责分离 (CQRS)"></a>命令和查询职责分离 (CQRS)</h3><p>一旦实现了每个服务分配单独一套数据库（database-per-service），自然就会产生查询需求，这需要联合来自多个服务的数据。然而这是不可能的。CQRS 建议将应用程序分成两部分 —— 命令端和查询端。</p><ul><li><p>  命令端处理创建，更新和删除请求</p></li><li><p>  查询端通过使用物化视图来处理查询部分</p></li></ul><p>这通常会搭配事件驱动模式（event sourcing pattern）一起使用，一旦有任何数据更改便会创建对应的事件。通过订阅事件流，我们便可以让物化视图保持更新。</p><h3 id="事件驱动"><a href="#事件驱动" class="headerlink" title="事件驱动"></a>事件驱动</h3><p>绝大多数应用程序需要用到数据，典型的做法就是应用程序要维护当前状态。例如，在传统的创建，读取，更新和删除（CRUD）模型中，典型的数据流程是从存储中读取数据。它也包含了经常使用事务导致锁定数据的限制。</p><p>事件驱动模式[7]定义了一种方法，用于处理由一系列事件驱动的数据操作，每个事件都记录在一个 append-only 的存储中。应用程序代码向事件存储发送一系列事件，这些事件命令式的描述了对数据执行的每个操作，它们会被持久化到事件存储。每个事件代表一组数据更改（例如，AddedItemToOrder）。</p><p>这些事件将保留在充当记录系统的一个事件存储里。事件存储发布的事件的典型用途是在应用程序触发的一些动作更改实体时维护这些实体的物化视图，以及与外部系统集成。例如，一个系统可以维护一个用于填充 UI 部分所有客户订单的物化视图。当应用程序添加新订单，添加或删除订单中的项目以及添加运输信息时，描述这些更改的事件将会得到处理并用于更新物化视图。下图展示了该模式的一个概览。</p><p><img src="https://colstuwjx.github.io/images/2019/Dec/event-sourcing.png" alt="Event Sourcing Pattern"></p><p><em>图2 事件驱动模式[8]</em></p><h2 id="Saga模式"><a href="#Saga模式" class="headerlink" title="Saga模式"></a>Saga模式</h2><p>当每个服务都有它们自己的数据库，并且一个业务事务跨越多个服务时，我们该如何确保各个服务之间的数据一致性呢？ 每个请求都有一个补偿请求，它会在请求失败时执行。这可以通过两种方式实现：</p><ul><li>  编舞（Choreography） —— 在没有中央协调的情况下，每个服务都会生成并侦听另一个服务的事件，并决定是否应该采取措施。编舞是一种指定两个或多个参与方的方案。任何一方都无法控制对方的流程，或者对这些流程有任何可见性，无法协调他们的活动和流程以共享信息和值。当需要跨控制/可见性域进行协调时，请使用编舞的方式。参考一个简单场景，你可以把编舞看作和网络协议类似。它规定了各方之间可接受的请求和响应模式。</li></ul><p><img src="https://colstuwjx.github.io/images/2019/Dec/saga-pattern.png" alt="sage pattern"></p><p><em>图3 Saga模式 —— 编舞</em></p><ul><li>  编排（Orchestration） —— 一个编排器（对象）会负责 saga 的决策和业务逻辑排序。此时你可以控制流程中的所有参与者。当它们全部处于一个控制域时，你可以控制该活动的流程。当然，这通常是你被指派到一个拥有控制权的组织里制定业务流程。</li></ul><p><img src="https://colstuwjx.github.io/images/2019/Dec/saga-pattern-orchestration.png" alt="saga-pattern-orchestration"></p><p><em>图4 Saga模式 —— 编排</em></p><h2 id="可观测性模式"><a href="#可观测性模式" class="headerlink" title="可观测性模式"></a>可观测性模式</h2><h3 id="日志聚合"><a href="#日志聚合" class="headerlink" title="日志聚合"></a>日志聚合</h3><p>考虑一个应用程序包含多个服务的用例。请求通常跨越多个服务实例。每个服务实例均采用标准格式生成日志文件。我们需要一个集中式的日志记录服务，该服务可以汇总每个服务实例的日志。用户可以搜索和分析日志。他们可以配置在某些消息出现在日志中时触发告警。例如，PCF 就有日志聚合器，它在应用侧从 PCF 平台的每个组件（router、controller、diego等）收集日志。AWS Cloud Watch 也是这样做的。</p><h3 id="性能指标"><a href="#性能指标" class="headerlink" title="性能指标"></a>性能指标</h3><p>当服务组合由于引入了微服务架构而增加时，保持对事务的监控就变得尤为关键了，如此一来就可以监控这些模式，而当有问题发生时便会发送告警。</p><p>此外，需要一个度量服务来收集有关单个操作的统计信息。它应当聚合一个应用服务的指标数据，它会用来报告和告警。这里有两种用于汇总指标的模型：</p><ul><li>  推送 —— 服务将指标推送到指标服务，例如 NewRelic，AppDynamics</li><li>  提取 —— 指标服务从服务中提取指标，例如 Prometheus</li></ul><h3 id="分布式链路追踪"><a href="#分布式链路追踪" class="headerlink" title="分布式链路追踪"></a>分布式链路追踪</h3><p>在微服务架构里，请求通常跨越多个服务。每个服务通过跨越多个服务执行一个或多个操作来处理请求。在排障时，有一个 Trace ID 是很有帮助的，我们可以端对端地跟踪一个请求。</p><p>解决方案便是引入一个事务ID。可以采用如下方式：</p><ul><li>  为每个外部请求分配一个唯一的外部请求ID</li><li>  将外部请求ID传递给处理该请求链路的所有服务</li><li>  在所有日志消息中加入该外部请求ID</li></ul><h3 id="健康检查"><a href="#健康检查" class="headerlink" title="健康检查"></a>健康检查</h3><p>实施微服务架构后，服务可能会出现启动了但是无法处理事务的情况。每个服务都需要有一个可用于检查应用程序运行状况的 API 端点，例如 /health。该 API 应该检查主机的状态，与其他服务/基础设施的连接以及任何其他特定的逻辑。</p><h2 id="横切关注点模式（Cross-Cutting-Concern-Patterns）"><a href="#横切关注点模式（Cross-Cutting-Concern-Patterns）" class="headerlink" title="横切关注点模式（Cross-Cutting Concern Patterns）"></a>横切关注点模式（Cross-Cutting Concern Patterns）</h2><h3 id="外部配置"><a href="#外部配置" class="headerlink" title="外部配置"></a>外部配置</h3><p>一个服务通常还会调用其他服务和数据库。对于dev，QA，UAT，Prod等每个环境而言，API 端点的 URL 或某些配置属性可能会有所不同。这些属性中的任何一个更改都可能需要重新构建和重新部署服务。</p><p>为避免代码修改，可以使用配置。把所有配置放到外面，包括端点 URL 和证书。应用程序应该在启动时或运行时加载它们。这些可以在启动时由应用程序访问，也可以在不重新启动服务器的情况下进行刷新。</p><h3 id="服务发现模式"><a href="#服务发现模式" class="headerlink" title="服务发现模式"></a>服务发现模式</h3><p>在微服务出现时，我们需要在调用服务方面解决一些问题。</p><p>借助容器技术，IP地址可以动态地分配给服务实例。每次地址更改时，消费端服务都会中断并且需要手动更改。</p><p>对于消费端服务来说，它们必须记住每个上游服务的 URL ，这就变成紧耦合了。</p><p>为此，需要创建一个服务注册中心，该注册表将保留每个生产者服务的元数据和每个服务的配置。服务实例在启动时应当注册到注册中心，而在关闭时应当注销。服务发现有两种类型：</p><ul><li>  客户端：例如：Netflix Eureka</li><li>  服务端：例如：AWS ALB</li></ul><p><img src="https://colstuwjx.github.io/images/2019/Dec/service-discovery.png" alt="service-discovery"></p><p><em>图5 服务发现[9]</em></p><h3 id="熔断器模式"><a href="#熔断器模式" class="headerlink" title="熔断器模式"></a>熔断器模式</h3><p>一个服务通常会通过调用其他服务来检索数据，而这时候下游服务可能已经挂了。这样的话，有两个问题：首先，请求将继续抵达挂了的服务，耗尽网络资源，并且降低性能。其次，用户体验将是糟糕且不可预测的。</p><p>消费端服务应通过代理来调用远程服务，该代理的表现和一个电流断路器类似。当连续的故障数超过阈值时，断路器将跳闸，并且在超时期间内，所有调用远程服务的尝试都会立即失败。超时到期后，断路器将允许有限数量的测试请求通过。如果这些请求成功，断路器则将恢复正常运行。否则，如果发生故障的话，超时时间则将再次重新开始计算。如果某些操作失败概率很高的话，采取此模式有助于防止应用程序在故障发生后仍然不断尝试调用远程服务或访问共享资源。</p><p><img src="https://colstuwjx.github.io/images/2019/Dec/circuit-breaker.png" alt="circuit-breaker"></p><p><em>图6 熔断器模式[10]</em></p><h3 id="蓝绿部署模式"><a href="#蓝绿部署模式" class="headerlink" title="蓝绿部署模式"></a>蓝绿部署模式</h3><p>使用微服务架构时，一个应用可以被拆分成许多个微服务。如果我们采用停止所有服务然后再部署改进版本的方式的话，宕机时间将是非常可观的，并且会影响业务。同样，回滚也将是一场噩梦。 蓝绿部署模式可以避免这种情况。</p><p>实施蓝绿部署策略可以用来减少或消除宕机。它通过运行两个相同的生产环境，Blue 和Green 来实现这一目标。 假设 Green 是现有的活动实例，Blue 是该应用程序的新版本。在任何时候，只有一个环境处于活动状态，该活动环境为所有生产流量提供服务。所有云平台均提供了用于实施蓝绿部署的选项。</p><p><img src="https://colstuwjx.github.io/images/2019/Dec/blue-green-deployment-pattern.png" alt="blue-green-deployment-pattern"></p><p><em>图7 蓝绿部署模式</em></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>[1] “Microservice Architecture: Aligning Principles, Practices, and Culture” Book by Irakli Nadareishvili, Matt McLarty, and Michael Amundsen</p><p>[2] <a href="https://microservices.io/patterns/decomposition/decompose-by-business-capability.html">https://microservices.io/patterns/decomposition/decompose-by-business-capability.html</a></p><p>[3] <a href="https://www.baeldung.com/transactions-across-microservices">https://www.baeldung.com/transactions-across-microservices</a></p><p>[4] <a href="https://developer.ibm.com/articles/cl-strangler-application-pattern-microservices-apps-trs/">https://developer.ibm.com/articles/cl-strangler-application-pattern-microservices-apps-trs/</a></p><p>[5] <a href="https://docs.microsoft.com/en-us/azure/architecture/patterns/bulkhead">https://docs.microsoft.com/en-us/azure/architecture/patterns/bulkhead</a></p><p>[6] <a href="https://dzone.com/articles/design-patterns-for-microservices">https://dzone.com/articles/design-patterns-for-microservices</a></p><p>[7] <a href="https://docs.microsoft.com/en-us/azure/architecture/patterns/cqrs#event-sourcing-and-cqrs">https://docs.microsoft.com/en-us/azure/architecture/patterns/cqrs#event-sourcing-and-cqrs</a></p><p>[8] <a href="https://docs.microsoft.com/en-us/azure/architecture/patterns/event-sourcing">https://docs.microsoft.com/en-us/azure/architecture/patterns/event-sourcing</a></p><p>[9] <a href="https://www.dineshonjava.com/microservices-with-spring-boot/">https://www.dineshonjava.com/microservices-with-spring-boot/</a></p><p>[10] <a href="https://docs.microsoft.com/en-us/azure/architecture/patterns/circuit-breaker">https://docs.microsoft.com/en-us/azure/architecture/patterns/circuit-breaker</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; &lt;a href=&quot;https://colstuwjx.github.io/2020/01/%E7%BF%BB%E8%AF%91-%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E5%8F%8A%E8%AE%BE%E8%AE%A1</summary>
      
    
    
    
    <category term="架构" scheme="http://zhangyu.info/categories/%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="架构" scheme="http://zhangyu.info/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
</feed>
