<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>张天师</title>
  
  
  <link href="http://zhangyu.info/atom.xml" rel="self"/>
  
  <link href="http://zhangyu.info/"/>
  <updated>2023-04-18T02:42:23.340Z</updated>
  <id>http://zhangyu.info/</id>
  
  <author>
    <name>张天师</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>一键部署工具easy-jenkins</title>
    <link href="http://zhangyu.info/2023/04/18/%E4%B8%80%E9%94%AE%E9%83%A8%E7%BD%B2%E5%B7%A5%E5%85%B7easy-jenkins/"/>
    <id>http://zhangyu.info/2023/04/18/%E4%B8%80%E9%94%AE%E9%83%A8%E7%BD%B2%E5%B7%A5%E5%85%B7easy-jenkins/</id>
    <published>2023-04-17T16:00:00.000Z</published>
    <updated>2023-04-18T02:42:23.340Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://tanyongpeng.blog.csdn.net/article/details/128223343">https://tanyongpeng.blog.csdn.net/article/details/128223343</a></p><p><a href="https://tanyongpeng.blog.csdn.net/article/details/128223343">一键部署工具easy-jenkins，界面友好，操作简单_来自上海的这位朋友的博客-CSDN博客</a></p><blockquote><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><img src="https://img-blog.csdnimg.cn/1c74d60f8cec426cb605e518bf1277d1.png" alt="在这里插入图片描述"></p><p>easy-<a href="https://so.csdn.net/so/search?q=jenkins&spm=1001.2101.3001.7020">jenkins</a>是一款对vue和jar的部署工具，操作简单，实行一键部署，内部结构采用流水线形式架构，每次部署，时时提供部署过程，部署记录，界面友好简洁，使用方便，符合用户常规操作</p><p>easy-jenkins面向分支形式，无需登录，默认分支为jenkins，每个分支可以配置多个数据源，切换不同分支可以管理不同数据源</p><p>easy-jenkins采用本地存储的结构无需配置数据库，简单易上手</p><hr><p><code>提示：以下是本篇文章正文内容，下面案例可供参考</code></p><h1 id="一、项目地址"><a href="#一、项目地址" class="headerlink" title="一、项目地址"></a>一、项目地址</h1><p>开源地址：<a href="https://gitee.com/susantyp/easy-jenkins">https://gitee.com/susantyp/easy-jenkins</a></p><h1 id="二、使用步骤"><a href="#二、使用步骤" class="headerlink" title="二、使用步骤"></a>二、使用步骤</h1><blockquote><p>先把代码拉入你的本地</p></blockquote><h2 id="1-项目结构"><a href="#1-项目结构" class="headerlink" title="1.项目结构"></a>1.项目结构</h2><p><img src="https://img-blog.csdnimg.cn/92f282f2561c4e6f93db1242575220e6.png" alt="在这里插入图片描述"></p><h2 id="2-启动主类-EasyJenkinsApplication"><a href="#2-启动主类-EasyJenkinsApplication" class="headerlink" title="2.启动主类 EasyJenkinsApplication"></a>2.启动主类 EasyJenkinsApplication</h2><p><img src="https://img-blog.csdnimg.cn/b3d3708a1d334a90bc08f760e341d0a2.png" alt="在这里插入图片描述"></p><h2 id="3-安装"><a href="#3-安装" class="headerlink" title="3.安装"></a>3.安装</h2><p>启动后弹出当前窗体 点击下一步</p><p><img src="https://img-blog.csdnimg.cn/706c3440b067464fb62edcd1ea762e3f.png" alt="在这里插入图片描述"></p><p>来到这里后，填写相应的信息<br>安装路径<br>maven路径 打包需要<br>以及项目端口的启动，避免不要和本地端口冲突，我们可以设置 8332 8899 9900 等端口</p><p><img src="https://img-blog.csdnimg.cn/2b5fb05cea9642188fd06e97db49c61b.png" alt="在这里插入图片描述"></p><p>点击安装并启动， 点击确认 等待几秒，项目自动启动</p><p><img src="https://img-blog.csdnimg.cn/186b6e15ef1c4d70b540278724a97bf7.png" alt="在这里插入图片描述"></p><h2 id="4-项目启动图"><a href="#4-项目启动图" class="headerlink" title="4.项目启动图"></a>4.项目启动图</h2><p><img src="https://img-blog.csdnimg.cn/febd91b110fd434e8f55cea9d3c8005d.png" alt="在这里插入图片描述"></p><h1 id="三、功能点介绍"><a href="#三、功能点介绍" class="headerlink" title="三、功能点介绍"></a>三、功能点介绍</h1><ul><li>  部署列表</li><li>  部署记录</li><li>  数据分支</li><li>  基本设置</li></ul><h2 id="1-部署列表"><a href="#1-部署列表" class="headerlink" title="1.部署列表"></a>1.部署列表</h2><p>部署列表主要显示我们的连接信息</p><p><img src="https://img-blog.csdnimg.cn/6af7b39f48364880af6b4465ae474019.png" alt="在这里插入图片描述"></p><h3 id="1-添加连接（部署jar）"><a href="#1-添加连接（部署jar）" class="headerlink" title="1.添加连接（部署jar）"></a>1.添加连接（部署jar）</h3><p>我们点击按钮，添加连接</p><p><img src="https://img-blog.csdnimg.cn/a4da8cd737ae4a65b0178a4005af10ec.png" alt="在这里插入图片描述"></p><h4 id="1-添加本地项目地址"><a href="#1-添加本地项目地址" class="headerlink" title="1.添加本地项目地址"></a>1.添加本地项目地址</h4><p>添加本地项目地址后，它下面的文本款会根据本地项目地址自动生成，如图</p><p><img src="https://img-blog.csdnimg.cn/55b4083131e24f73ab5bb719510c1caf.png" alt="在这里插入图片描述"><br>在这边需要确保，你的本地项目地址是正确的<br>jar名称正确的<br>pom.xml文件是正确的</p><p>我部署项目的端口为8080</p><p>根据你自己的项目设置端口</p><h4 id="2-添加服务器相关信息"><a href="#2-添加服务器相关信息" class="headerlink" title="2.添加服务器相关信息"></a>2.添加服务器相关信息</h4><p>在我们的右边填写我们的服务器信息<br>服务器ip<br>账号<br>密码<br>端口</p><p><img src="https://img-blog.csdnimg.cn/b74dee440b3d42b697df723defbf237f.png" alt="在这里插入图片描述"></p><p>上传的位置 后面不需要带 /</p><p>上传的位置 默认生成一个命令</p><p>如果上传位置是 /home/springboot<br>则生成如下</p><p><img src="https://img-blog.csdnimg.cn/97226334db7442ac88bad38e2047763c.png" alt="在这里插入图片描述"></p><blockquote><p>nohup java -jar /home/springboot/wall.jar &amp; tailf /home/springboot/nohup.out<br>可以修改为你自己需要运行的命令<br>或者直接使用当前命令</p></blockquote><p><img src="https://img-blog.csdnimg.cn/93e18b397d4943ed8aa3ba00d35a9857.png" alt="在这里插入图片描述"></p><h3 id="2-部署jar"><a href="#2-部署jar" class="headerlink" title="2.部署jar"></a>2.部署jar</h3><p>我们点击部署按钮即可</p><p><img src="https://img-blog.csdnimg.cn/adec6772ef0548239e02650e7c1604cb.png" alt="在这里插入图片描述"></p><p>部署过程效果图<br>后台会实时返回部署的消息，返回给前端显示</p><p><img src="https://img-blog.csdnimg.cn/cd71e499072c43dd8837e91bed8a5b1d.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/dbba5f599ffd4dc3b843d3ba58e66205.png" alt="在这里插入图片描述"></p><h3 id="3-部署成功"><a href="#3-部署成功" class="headerlink" title="3.部署成功"></a>3.部署成功</h3><p>部署成功返回：Successfully deployed</p><p><img src="https://img-blog.csdnimg.cn/87238417e0204169a12422e271e7da0c.png" alt="在这里插入图片描述"></p><h3 id="4-删除"><a href="#4-删除" class="headerlink" title="4.删除"></a>4.删除</h3><p>点击table 直接删除</p><h3 id="5-编辑"><a href="#5-编辑" class="headerlink" title="5.编辑"></a>5.编辑</h3><p>编辑小伙伴可以自己玩一下</p><h2 id="2-部署记录"><a href="#2-部署记录" class="headerlink" title="2.部署记录"></a>2.部署记录</h2><p>部署记录主要记录了，最近部署的情况和统计信息</p><p><img src="https://img-blog.csdnimg.cn/bf6e9636be49438096979d760fd6463a.png" alt="在这里插入图片描述"></p><h2 id="3-数据分支"><a href="#3-数据分支" class="headerlink" title="3.数据分支"></a>3.数据分支</h2><p>easy-jenkins 是面向分支的<br>不同分支存储不同的连接，默认分支为jenkins</p><p><img src="https://img-blog.csdnimg.cn/60bc2e8cf4ab428e8c279f104b613aca.png" alt="在这里插入图片描述"></p><h3 id="1-创建分支"><a href="#1-创建分支" class="headerlink" title="1.创建分支"></a>1.创建分支</h3><p>创建一个root的分支<br><img src="https://img-blog.csdnimg.cn/c3f60ec7fb384ca7a2c69bb56c2d8da9.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/71c601545eb34f29914247cbd68ea3a1.png" alt="在这里插入图片描述"></p><h3 id="2-切换分支"><a href="#2-切换分支" class="headerlink" title="2.切换分支"></a>2.切换分支</h3><p><img src="https://img-blog.csdnimg.cn/0459d2a62f89425ab9974b3bf7d311f5.png" alt="在这里插入图片描述"><br>切换完成后，可以查看当前分支的状态<br><img src="https://img-blog.csdnimg.cn/941f325447b64186b2b2129ca315ee40.png" alt="在这里插入图片描述"><br>当前我们就是root分支的环境下</p><p>我们点击部署记录<br><img src="https://img-blog.csdnimg.cn/6a23dd1296d84c0ebb58700d4eccdd79.png" alt="在这里插入图片描述"><br>部署记录此时为空的，刚刚创建分支下面是没有连接数据的，需要重新添加连接</p><p>我们切换为jenkins分支后，前面我们在jenkins添加了一条连接数据，下面就显示数据了，同时上面会标注当前的环境为jenkins</p><p><img src="https://img-blog.csdnimg.cn/9e4f64381efe4f7dacdb07ad5ab16db5.png" alt="在这里插入图片描述"></p><blockquote><p>注意了，正在使用的分支是不可以删除，</p></blockquote><h2 id="4-基本设置"><a href="#4-基本设置" class="headerlink" title="4.基本设置"></a>4.基本设置</h2><p>安装路径<br>maven路径<br>项目端口号<br>当前这三个值，是我们最初刚刚开始安装的时候的需要录入的值，我们可以点击编辑操作<br><img src="https://img-blog.csdnimg.cn/5d8ee9db75bf41fc92b91c8043d40a3e.png" alt="在这里插入图片描述"></p><h2 id="5-启动"><a href="#5-启动" class="headerlink" title="5.启动"></a>5.启动</h2><p>第一次启动会启动安装向导程序<br>第二次启动直接启动浏览器，则不再启动安装向导程序</p><h2 id="6-如何部署vue"><a href="#6-如何部署vue" class="headerlink" title="6.如何部署vue"></a>6.如何部署vue</h2><p>dist 是vue项目默认build的位置<br>同样 后面 不需要 ‘/’</p><p><img src="https://img-blog.csdnimg.cn/45fe4f680416480280c248747480473b.png" alt="在这里插入图片描述"></p><h3 id="1-需要注意"><a href="#1-需要注意" class="headerlink" title="1.需要注意"></a>1.需要注意</h3><p>上传位置名字保持跟本地相同的名字，如图：</p><p><img src="https://img-blog.csdnimg.cn/3c0229457f2140888f5507f8ea9a9cf8.png" alt="在这里插入图片描述"><br>然后填写你相应的服务器信息即可</p><h2 id="7-exe启动项目"><a href="#7-exe启动项目" class="headerlink" title="7.exe启动项目"></a>7.exe启动项目</h2><p>在我们exe文件夹下面，有一个easy-jenkins.exe文件<br>可以将他拷贝到桌面，直接点击它运行即可，不需要每次启动springboot程序</p><p><img src="https://img-blog.csdnimg.cn/928a89b3979043ac93894dfcd5424b58.png" alt="在这里插入图片描述"></p><hr><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>此部署工具主要针对于个人本地的部署<br>针对于小型项目的部署，轻量级的，一键部署，操作简单</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://tanyongpeng.blog.csdn.net/article/details/128223343&quot;&gt;https://tanyongpeng.blog.csdn.net/article/details/128223343&lt;/a&gt;&lt;/p&gt;</summary>
      
    
    
    
    <category term="jenkins" scheme="http://zhangyu.info/categories/jenkins/"/>
    
    
    <category term="jenkins" scheme="http://zhangyu.info/tags/jenkins/"/>
    
  </entry>
  
  <entry>
    <title>SSD固态硬盘的结构和原理导论</title>
    <link href="http://zhangyu.info/2023/04/18/SSD%E5%9B%BA%E6%80%81%E7%A1%AC%E7%9B%98%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8E%9F%E7%90%86%E5%AF%BC%E8%AE%BA/"/>
    <id>http://zhangyu.info/2023/04/18/SSD%E5%9B%BA%E6%80%81%E7%A1%AC%E7%9B%98%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8E%9F%E7%90%86%E5%AF%BC%E8%AE%BA/</id>
    <published>2023-04-17T16:00:00.000Z</published>
    <updated>2023-04-18T03:57:22.109Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/vagrant0407/article/details/128986172">https://blog.csdn.net/vagrant0407/article/details/128986172</a></p><p>内容摘要</p><p>1 什么是SSD</p><p>2 SSD的存储介质分类</p><p>3 SSD的结构</p><p>3.1 主控制器</p><p>3.2 存储单元</p><p>3.3 闪存的分类</p><p>4 Host访问SSD的原理</p><p>5 SSD相关概念和技术</p><p>5.1 多Plane操作</p><p>5.2 多Die交错操作</p><p>5.3 FTL</p><p>5.4 磨损平衡(Wear leveling)</p><p>5.5 垃圾回收(Garbagecollection)</p><p>5.6 Trim</p><p>5.7 预留空间(Over-provisioning)</p><p>5.8 写入放大(Write amplification)</p><p>5.9 ECC</p><hr><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>机械硬盘的存储系统由于内部结构,其IO访问性能无法进一步提高,CPU与存储器之间的性能差距逐渐扩大。以Nand Flash为存储介质的固态硬盘技术的发展，性能瓶颈得到缓解。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/efb2ddbf770746c3abdd5338a35a9d3d.jpeg"></p><h1 id="1-什么是SSD"><a href="#1-什么是SSD" class="headerlink" title="1 什么是SSD"></a>1 什么是SSD</h1><p>固态硬盘（Solid State Drives），用固态电子存储芯片阵列而制成的硬盘，由控制单元和存储单元（FLASH芯片、DRAM芯片）组成。固态硬盘被广泛使用于军事方面、车载系统方面、工程控制技术方面、视频监控存储、网络监控存储、网络终端保存、电力系统方面、医疗信息存储方面、航空技术方面、导航设备存储等重要领域。</p><h1 id="2-SSD的存储介质分类"><a href="#2-SSD的存储介质分类" class="headerlink" title="2 SSD的存储介质分类"></a>2 SSD的存储介质分类</h1><p>固态硬盘(SSD)的存储介质分为两种，一种是采用闪存（FLASH芯片）作为存储介质，另外一种是采用DRAM作为存储介质。</p><p>基于闪存类：基于闪存的固态硬盘（IDEFLASH DISK、Serial ATA Flash Disk），采用FLASH芯片作为存储介质，这也是通常所说的SSD。它的外观可以被制作成多种模样，例如：笔记本硬盘、微硬盘、存储卡、U盘等样式。这种SSD固态硬盘最大的优点就是可以移动，而且数据保护不受电源控制，能适应于各种环境，适合于个人用户使用。</p><p>基于DRAM类：基于DRAM的固态硬盘，采用DRAM作为存储介质，应用范围较窄。它仿效传统硬盘的设计，可被绝大部分操作系统的文件系统工具进行卷设置和管理，并提供工业标准的PCI和FC接口用于连接主机或者服务器。应用方式可分为SSD硬盘和SSD硬盘阵列两种。它是一种高性能的存储器，而且使用寿命很长，美中不足的是需要独立电源来保护数据安全。DRAM固态硬盘属于比较非主流的设备。</p><p>基于3D XPoint类：在闪存与<a href="https://www.elecfans.com/tags/dram/">DRAM</a>之间开创新市场的新一代内存技术， 3D XPoint是一种新的非易失性存储技术，也就是能像NAND闪存那样断电保持数据，但同时又有着极高的速度和性能，能够达到DRAM内存级别，因此它既能做成硬盘，也能做成内存，而且单位容量成本介于二者之间，堪称梦幻黑科技。3D XPoint的首款产品将是“Optane”傲腾品牌的固态硬盘。只有少数高端系列有， 而且已经放弃了3D XPoint技术，可惜了这么强大的技术，性能秒杀各种NAND SSD，最终输给了市场， 昙花一现。</p><h1 id="3-SSD的结构"><a href="#3-SSD的结构" class="headerlink" title="3 SSD的结构"></a>3 SSD的结构</h1><p>SSD主要由主控制器芯片，闪存芯片，缓存芯片（可选），以及跟HOST接口（诸如SATA，SAS, PCIe等）组成。SSD作为数据存储设备， 其实是一种典型的（System on Chip） 单机系统， 有主控CPU、 RAM、 操作加速器、 总线、 数据编码译码等模块（见图2-1） ， 操作对象为协议、 数据命令、 介质， 操作目的是写入和读取用户数据。[7]</p><p><img src="https://img-blog.csdnimg.cn/img_convert/3d645758dce4464bbe135ed0cbce12a6.png"></p><p>图片来源 [11]</p><h2 id="3-1-主控制器"><a href="#3-1-主控制器" class="headerlink" title="3.1 主控制器"></a>3.1 主控制器</h2><p>SSD控制器是固态硬盘的主要控制芯片, 负责指挥、运算和协调SSD设备, FTL (Flash Translation Layer) 算法的运行[8]。目前主流的SSD主控架构如下图：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/73c288d5d6ad4b73ac7238d86b21e855.png"></p><p>主要有三大部分组成：与Host对接的界面(Host interface, ) 称为前端, 闪存转换层FTL，称为中端以及闪存对接界面(Flash interface)，称为后端。</p><p>每个 SSD 都有一个控制器(controller)将存储单元连接到电脑，主控器可以通过若干个通道（channel）并行操作多块FLASH颗粒，类似RAID0，大大提高底层的带宽。控制器是一个执行固件(firmware)代码的嵌入式处理器。主要功能如下：</p><p>Read</p><p>Write</p><p>Trim</p><p>错误检查和纠正(ECC)</p><p>Address Translation——映射管理</p><p>Garbage Collection——垃圾回收</p><p>Wear Leveling——磨损平衡</p><p>Power off Recovery —— 掉电恢复</p><p>Error Handler——坏块管理</p><p>SLC Cache</p><p>Read Disturb &amp; Data Retention</p><p>Over Privision——预留空间</p><p>Latecncy 平滑管理</p><p>WAF写入放大</p><p>缓存控制</p><p>加密</p><p>压缩</p><p>重复数据去冗</p><p>HMB（host memory buffer） 管理</p><p>固件升级</p><p>Self Test</p><h2 id="3-2-存储单元"><a href="#3-2-存储单元" class="headerlink" title="3.2 存储单元"></a>3.2 存储单元</h2><p>尽管有某些厂商推出了基于更高速的 DRAM 内存的产品，但 NAND 闪存依然最常见，占据着绝对主导地位。一般采用 TLC(multi-level cell) 甚至 QLC(Triple Level Cell) 闪存，其特点是容量大、速度慢、可靠性低、存取次数低、价格也低。高端产品一般采用 SLC(single-level cell) 闪存，其特点是技术成熟、容量小、速度快、可靠性高、存取次数高、价格也高。但是事实上，取决于不同产品的内部架构设计，速度和可靠性的差别也可以通过各种技术加以弥补甚至反转。</p><p>闪存内部结构</p><p><img src="https://img-blog.csdnimg.cn/img_convert/6c8f4d98ad014fc38678fa120a352bf5.png"></p><p>一个Die又可以分为多个Plane,而每个Plane又包含多个多个Block,每个Block又分为多个Page。以Samsung 4GB Flash为例，共享8位I/0数据总线和一些控制信号线。每个Die由4个Plane组成，每个Plane包含2048个Block，每个Block又包含64个4KB大小的Page。我们顺序写入4个逻辑页，分别写到不同的plane上，这样写的目的是增加底层的并行性，提升写入性能。</p><p>参考：[<a href="https://blog.csdn.net/qq_40838478/article/details/121114961">121114961</a>]</p><h2 id="3-3-闪存的分类"><a href="#3-3-闪存的分类" class="headerlink" title="3.3 闪存的分类"></a>3.3 闪存的分类</h2><p>NAND FLASH 从 SLC -&gt; MLC -&gt; TLC -&gt; QLC，每个单元存储的比特数增加，这样晶圆的存储密度会成倍提高，但对应的整卡可写入/擦除次数(P/E Cycle) 也降低（意味着寿命也越短），读写性能会越差。最重要的单位GB的成本会更低，芯片的成本是和面积直接相关的。面积越小，一个晶圆切出的Die(片)数目就更多，单Die的成本就降下来了。[12]</p><p>各大原厂孜孜不倦地提高每个单元的比特数，目的就是为了减少成本，成本才是王道！</p><p><img src="https://img-blog.csdnimg.cn/img_convert/149265d1ca124478a13b89583dcb51a0.webp?x-oss-process=image/format,png"></p><h1 id="4-Host访问SSD的原理"><a href="#4-Host访问SSD的原理" class="headerlink" title="4 Host访问SSD的原理"></a>4 Host访问SSD的原理</h1><p>固态硬盘的存储器件采用的是闪存，具有以下几个特点：</p><p>(1)读写基本单位是以页（Page）为单位，擦除是以块（Block）为单位。</p><p>(2)每个物理块，必须先擦除，才能够写入数据。</p><p>基于这些问题，在固态硬盘中引入了闪存转换层映射表。</p><p>Host是通过LBA（Logical BlockAddress，逻辑地址块）访问SSD的，每个LBA代表着一个Sector（一般为512B大小），文件系统一般以4KB为单位访问SSD，我们把Host访问SSD的基本单元叫用户页（Host Page）。而在SSD内部，SSD主控与Flash之间是Flash Page为基本单元访问Flash的，我们称Flash Page为物理页（Physical Page）。Host每写入一个Host Page, SSD主控会找一个Physical Page把Host数据写入，SSD内部同时记录了这样一条映射（Map）。有了这样一个映射关系后，下次Host需要读某个Host Page 时，SSD就知道从Flash的哪个位置把数据读取上来。</p><p>SSD内部维护了一张映射表（Map Table），Host每写入一个Host Page，就会产生一个新的映射关系，这个映射关系会加入（第一次写）或者更改（覆盖写）Map Table；当读取某个Host Page时， SSD首先查找Map Table中该Host Page对应的Physical Page，然后再访问Flash读取相应的Host数据。</p><p>大多数SSD，我们可以看到上面都有板载DRAM，其主要作用就是用来存储这张映射表。也有例外，比如基于Sandforce主控的SSD，它并不支持板载DRAM，那么它的映射表存在哪里呢？SSD工作时，它的绝大部分映射是存储在FLASH里面，还有一部分存储在片上RAM上。当Host需要读取一笔数据时，对有板载DRAM的SSD来说，只要查找DRAM当中的映射表，获取到物理地址后访问Flash从而得到Host数据.这期间只需要访问一次FlashH；而对Sandforce的SSD来说，它首先看看该Host Page对应的映射关系是否在RAM内，如果在，那好办，直接根据映射关系读取FLASH；如果该映射关系不在RAM内，那么它首先需要把映射关系从FLASH里面读取出来，然后再根据这个映射关系读取Host数据，这就意味着相比有DRAM的SSD，它需要读取两次FLASH才能把HOST数据读取出来，底层有效带宽减半。对HOST随机读来说，由于片上RAM有限，映射关系Cache命中(映射关系在片上RAM)的概率很小，所以对它来说，基本每次读都需要访问两次FLASH，所以我们可以看到基于Sandforce主控的SSD随机读取性能是不太理想的。</p><h1 id="5-SSD相关概念和技术"><a href="#5-SSD相关概念和技术" class="headerlink" title="5 SSD相关概念和技术"></a>5 SSD相关概念和技术</h1><h2 id="5-1-多Plane操作"><a href="#5-1-多Plane操作" class="headerlink" title="5.1 多Plane操作"></a>5.1 多Plane操作</h2><p>多 Plane NAND 是一种能够有效提升性能的设计。例如，一个晶片内部分成了4个 Plane，想象我们在操作时，也可以进行多Plane并行操作来提升性能，</p><p>不同的Die 是独立工作的，可以并行操作。</p><p>多个SSD Channel 可以并行操作。</p><h2 id="5-2-多Die交错操作"><a href="#5-2-多Die交错操作" class="headerlink" title="5.2 多Die交错操作"></a>5.2 多Die交错操作</h2><p>交错操作可以成倍提升NAND的传输率，因为NAND颗粒封装时候可能有多Die、多Plane(每个plane都有4KB寄存器)，不同Die操作时候可以交叉操作(第一个plane接到指令后，在操作的同时第二个指令已经发送给了第二个Die，以此类推)，达到接近双倍甚至4倍的传输能力(看闪存颗粒支持度)。</p><h2 id="5-3-FTL"><a href="#5-3-FTL" class="headerlink" title="5.3 FTL"></a>5.3 FTL</h2><p>操作系统通常将硬盘理解为一连串 512B 大小的扇区[注意：操作系统对磁盘进行一次读或写的最小单位并不是扇区，而是文件系统的块，一般为 512B/1KB/4KB 之一(也可能更大)，其具体大小在格式化时设定]，但是闪存的读写单位是 4KB 或 8KB 大小的页，而且闪存的擦除(又叫编程)操作是按照 128 或 256 页大小的块来操作的。更要命的是写入数据前必须要先擦除整个块，而不能直接覆盖。这完全不符合现有的、针对传统硬盘设计的文件系统的操作方式，很明显，我们需要更高级、专门针对 SSD 设计的文件系统来适应这种操作方式。但遗憾的是，目前还没有这样的文件系统。为了兼容现有的文件系统，就出现了 FTL(闪存转换层)，它位于文件系统和物理介质之间，把闪存的操作习惯虚拟成以传统硬盘的 512B 扇区进行操作。这样，操作系统就可以按照传统的扇区方式操作，而不用担心之前说的擦除/读/写问题。一切逻辑到物理的转换，全部由 FTL 层包了。</p><p>FTL 算法，本质上就是一种逻辑到物理的映射，因此，当文件系统发送指令说要写入或者更新一个特定的逻辑扇区时，FTL 实际上写入了另一个空闲物理页，并更新映射表，再把这个页上包含的旧数据标记为无效(更新后的数据已经写入新地址了，旧地址的数据自然就无效了)。</p><h2 id="5-4-磨损平衡-Wear-leveling"><a href="#5-4-磨损平衡-Wear-leveling" class="headerlink" title="5.4 磨损平衡(Wear leveling)"></a>5.4 磨损平衡(Wear leveling)</h2><p>简单说来，磨损平衡是确保闪存的每个块被写入的次数相等的一种机制。</p><p>如果系统中的所有块都定期更新，这就没有问题，因为当页面被标记为无效然后被回收时，磨损均衡几乎会自然发生。通常情况下，在 NAND 块里的数据更新频度是不同的。具体来说：如果我们有一些冷块，即数据永远不会改变的位置，那么我们必须采取措施手动重新定位该数据，否则这些块将永远不会磨损……磨损均衡需要将数据搬移到新的块，这意味着我们也在增加写入工作量，这最终意味着增加磨损。</p><p>因此，简而言之，我们对均匀磨损均衡的要求越高，我们造成的磨损就越多。但不够积极可能会导致热点和冷点，因为磨损变得更加不均匀。一如既往，这是一个找到正确平衡的问题。或者，如果您愿意，找到写入平衡。</p><p>磨损平衡算法分静态和动态。动态磨损算法是基本的磨损算法：只有用户在使用中更新的文件占用的物理页地址被磨损平衡了。而静态磨损算法是更高级的磨损算法：在动态磨损算法的基础上，增加了对于那些不常更新的文件占用的物理地址进行磨损平衡，这才算是真正的全盘磨损平衡。简单点说来，动态算法就是每次都挑最年轻的 NAND 块来用，老的 NAND 块尽量不用。静态算法就是把长期没有修改的老数据从一个年轻 NAND 块里面搬出来，重新找个最老的 NAND 块放着，这样年轻的 NAND 块就能再度进入经常使用区。</p><p>尽管磨损均衡的目的是避免数据重复在某个空间写入，以保证各个存储区域内磨损程度基本一致，从而达到延长固态硬盘的目的。但是，它对固态硬盘的性能有不利影响，并且会增加磨损。</p><h2 id="5-5-垃圾回收-Garbagecollection"><a href="#5-5-垃圾回收-Garbagecollection" class="headerlink" title="5.5 垃圾回收(Garbagecollection)"></a>5.5 垃圾回收(Garbagecollection)</h2><p>当整个SSD写满后，从用户角度来看，如果想写入新的数据，则必须删除一些数据，然后腾出空间再写。用户在删除和写入数据的过程中，会导致一些Block里面的数据变无效或者变老。Block中的数据变老或者无效，是指没有任何映射关系指向它们，用户不会访问到这些FLASH空间，它们被新的映射关系所取代。比如有一个Host Page A，开始它存储在FLASH空间的X,映射关系为A-&gt;X。后来，HOST重写了该Host Page，由于FLASH不能覆盖写，SSD内部必须寻找一个没有写过的位置写入新的数据，假设为Y，这个时候新的映射关系建立：A-&gt;Y，之前的映射关系解除，位置X上的数据变老失效，我们把这些数据叫垃圾数据。随着HOST的持续写入，FLASH存储空间慢慢变小，直到耗尽。如果不及时清除这些垃圾数据，HOST就无法写入。SSD内部都有垃圾回收机制，它的基本原理是把几个Block中的有效数据（非垃圾数据）集中搬到一个新的Block上面去，然后再把这几个Block擦除掉，这样就产生新的可用Block了.</p><p>另一方面，由前面的磨损平衡机制知道，磨损平衡的执行需要有“空白块”来写入更新后的数据。当可以直接写入数据的“备用空白块”数量低于一个阀值后，SSD主控制器就会把那些包含无效数据的块里的所有有效数据合并起来写到新的“空白块”中，然后擦除这个块以增加“备用空白块”的数量。</p><p>有三种垃圾回收策略：</p><p>闲置垃圾回收：很明显在进行垃圾回收时候会消耗大量的主控处理能力和带宽造成处理用户请求的性能下降，SSD 主控制器可以设置在系统闲置时候做“预先”垃圾回收(提前做垃圾回收操作)，保证一定数量的”备用空白块”，让 SSD 在运行时候能够保持较高的性能。闲置垃圾回收的缺点是会增加额外的”写入放大”，因为你刚刚垃圾回收的”有效数据”，也许马上就会被更新后的数据替代而变成”无效数据”，这样就造成之前的垃圾回收做无用功了。</p><p>被动垃圾回收：每个 SSD 都支持的技术，但是对主控制器的性能提出了很高的要求，适合在服务器里用到，SandForce 的主控就属这类。在垃圾回收操作消耗带宽和处理能力的同时处理用户操作数据，如果没有足够强劲的主控制器性能则会造成明显的速度下降。这就是为啥很多 SSD 在全盘写满一次后会出现性能下降的道理，因为要想继续写入数据就必须要边垃圾回收边做写入。</p><p>手动垃圾回收：用户自己手动选择合适的时机运行垃圾回收软件，执行垃圾回收操作。</p><p>可以想象，如果系统经常进行垃圾回收处理，频繁的将一些区块进行擦除操作，那么 SSD 的寿命反而也会进一步下降。由此把握这个垃圾回收的频繁程度，同时确保 SSD 中的闪存芯片拥有更高的使用寿命，这确实需要找到一个完美的平衡点。所以，SSD 必须要支持 Trim 技术，不然 GC 就显不出他的优势了。</p><h2 id="5-6-Trim"><a href="#5-6-Trim" class="headerlink" title="5.6 Trim"></a>5.6 Trim</h2><p>Trim 是一个 ATA 指令，当操作系统删除文件或格式化的时候，由操作系统同时把这个文件地址发送给 SSD 的主控制器，让主控制器知道这个地址的数据无效了。当你删除一个文件的时候，文件系统其实并不会真正去删除它，而只是把这个文件地址标记为“已删除”，可以被再次使用，这意味着这个文件占的地址已经是“无效”的了。这就会带来一个问题，硬盘并不知道操作系统把这个地址标记为“已删除”了，机械盘的话无所谓，因为可以直接在这个地址上重新覆盖写入，但是到了 SSD 上问题就来了。NAND 需要先擦除才能再次写入数据，要得到空闲的 NAND 空间，SSD 必须复制所有的有效页到新的空闲块里，并擦除旧块(垃圾回收)。如果没有 Trim 指令，意味着 SSD 主控制器不知道这个页是“无效”的，除非再次被操作系统要求覆盖上去。</p><p>Trim 只是条指令，让操作系统告诉 SSD 主控制器这个页已经“无效”了。Trim 会减少写入放大，因为主控制器不需要复制“无效”的页(没 Trim 就是“有效”的)到空白块里，这同时代表复制的“有效”页变少了，垃圾回收的效率和 SSD 性能也提升了。Trim 能大量减少伪有效页的数量，它能大大提升垃圾回收的效率。目前，支持 Trim 需要三个要素，</p><p>(1)系统：操作系统必须会发送 Trim 指令，Win7, Win2008R2 , Linux-2.6.33 以上。</p><p>(2)固件： SSD 的厂商在固件里要放有 Trim 算法，也就是 SSD 的主控制器必须认识 Trim 指令。</p><p>(3)驱动： 控制器驱动必须要支持 Trim 指令的传输，也就是能够将 Trim 指令传输到 SSD 控制器。MS 的驱动，Intel 的 AHCI 驱动目前支持。别的要看之后的更新了。</p><p>目前，RAID 阵列里的盘明确不支持 TRIM，不过 RAID 阵列支持 GC。</p><h2 id="5-7-预留空间-Over-provisioning"><a href="#5-7-预留空间-Over-provisioning" class="headerlink" title="5.7 预留空间(Over-provisioning)"></a>5.7 预留空间(Over-provisioning)</h2><p>预留空间是指用户不可操作的容量，为实际物理闪存容量减去用户可用容量。这块区域一般被用来做优化，包括磨损均衡，GC和坏块映射。</p><p>第一层为固定的7.37%，这个数字是如何得出的哪？我们知道机械硬盘和 SSD 的厂商容量是这样算的，1GB 是1,000,000,000字节(10的9 次方)，但是闪存的实际容量是每 GB=1,073,741,824，(2的30次方) ，两者相差7.37%。所以说假设1块 128GB 的 SSD，用户得到的容量是 128,000,000,000 字节，多出来的那个 7.37% 就被主控固件用做OP了。</p><p>第二层来自制造商的设置，通常为 0%，7%，28% 等，打个比方，对于 128G 颗粒的 SandForce 主控 SSD，市场上会有 120G 和 100G 两种型号卖，这个取决于厂商的固件设置，这个容量不包括之前的第一层 7.37% 。</p><p>第三层是用户在日常使用中可以分配的预留空间，用户可以在分区的时候，不分到完全的 SSD 容量来达到这个目的。不过需要注意的是，需要先做安全擦除(Secure Erase)，以保证此空间确实没有被使用过。</p><p>预留空间的具体作用：</p><p>(1)垃圾回收：就是要把数据搬来搬去，那就需要始终有空的地方来放搬的数据。空的越多，搬的越快，多多益善，有些SSD为了更快，还会再拿走一些用户的容量。</p><p>(2)映射表等内部数据保存：SSD里面有一个巨大的映射表，把用户地址转成物理Flash颗粒地址，需要保存，以防掉电丢失。这个大概是千分之三的容量。</p><p>(3)坏块替换：写得多了，坏块会逐渐增加，需要用好的顶替。随着Flash的制程从32nm不断变小，变到现在的14nm，Flash质量越来越差，坏块越来越多，这部分可能会到3%甚至更多。</p><h2 id="5-8-写入放大-Write-amplification"><a href="#5-8-写入放大-Write-amplification" class="headerlink" title="5.8 写入放大(Write amplification)"></a>5.8 写入放大(Write amplification)</h2><p>因为闪存必须先擦除(也叫编程)才能写入，在执行这些操作的时候，移动或覆盖用户数据和元数据(metadata)不止一次。这些额外的操作，不但增加了写入数据量，减少了SSD的使用寿命，而且还吃光了闪存的带宽，间接地影响了随机写入性能。这种效应就叫写入放大(Write amplification)。一个主控的好坏主要体现在写入放大上。</p><p>比如我要写入一个 4KB 的数据，最坏的情况是，一个块里已经没有干净空间了，但是有无效数据可以擦除，所以主控就把所有的数据读到缓存，擦除块，从缓存里更新整个块的数据，再把新数据写回去。这个操作带来的写入放大就是：我实际写4K的数据，造成了整个块(1024KB)的写入操作，那就是256倍放大。同时带来了原本只需要简单的写4KB的操作变成闪存读取(1024KB)，缓存改(4KB)，闪存擦(1024KB)，闪存写(1024KB)，造成了延迟大大增加，速度急剧下降也就是自然的事了。所以，写入放大是影响 SSD 随机写入性能和寿命的关键因素。</p><p>用100%随机4KB来写入 SSD，对于目前的大多数 SSD 主控而言，在最糟糕的情况下，写入放大的实际值可能会达到或超过20倍。当然，用户也可以设置一定的预留空间来减少写入放大，假设你有个 128G 的 SSD，你只分了 64G 的区使用，那么最坏情况下的写入放大就能减少约3倍。</p><p>许多因素影响 SSD 的写入放大。下面列出了主要因素，以及它们如何影响写入放大。</p><p>(1)垃圾回收虽然增加了写入放大(被动垃圾回收不影响，闲置垃圾回收影响)，但是速度有提升。</p><p>(2)预留空间可以减少写入放大，预留空间越大，写入放大越低。</p><p>(3)开启 TRIM 指令后可以减少写入放大</p><p>(4)用户使用中没有用到的空间越大，写入放大越低(需要有 Trim 支持)。</p><p>(5)持续写入可以减少写入放大。理论上来说，持续写入的写入放大为1，但是某些因素还是会影响这个数值。</p><p>(6)随机写入将会大大提升写入放大，因为会写入很多非连续的 LBA。</p><p>(7)磨损平衡机制直接提高了写入放大</p><h2 id="5-9-ECC"><a href="#5-9-ECC" class="headerlink" title="5.9 ECC"></a>5.9 ECC</h2><p>ECC的全称是Error Checking and Correction，是一种用于Nand的差错检测和修正算法。由于NAND Flash的工艺不能保证NAND在其生命周期中保持性能的可靠，因此，在NAND的生产中及使用过程中会产生坏块。为了检测数据的可靠性，在应用NAND Flash的系统中一般都会采用一定的坏区管理机制，而管理坏区的前提是能比较可靠的进行坏区检测。如果操作时序和电路稳定性不存在问题的话，NAND Flash出错的时候一般不会造成整个Block或是Page不能读取或是全部出错，而是整个Page中只有一个或几个bit出错，这时候ECC就能发挥作用了。不同颗粒有不同的基本ECC要求，不同主控制器支持的ECC能力也不同，理论上说主控越强ECC能力越强。</p><p>参考：</p><p>[1] SSD(固态硬盘)简介 <a href="http://www.jinbuguo.com/storage/ssd_intro.html">http://www.jinbuguo.com/storage/ssd_intro.html</a></p><p>[2] SSD背后的秘密：SSD基本工作原理 <a href="http://www.ssdfans.com/?p=131">http://www.ssdfans.com/?p=131</a></p><p>[3] 固态硬盘(SSD)原理及相关介绍 <a href="https://blog.csdn.net/cighao/article/details/48135137">https://blog.csdn.net/cighao/article/details/48135137</a></p><p>[4] [SSD固态硬盘技术 15] FTL映射表的神秘面纱 <a href="https://blog.csdn.net/vagrant0407/article/details/128983639">https://blog.csdn.net/vagrant0407/article/details/128983639</a></p><p>[5] [SSD固态硬盘技术 9] FTL详解 <a href="https://blog.csdn.net/vagrant0407/article/details/128978780">https://blog.csdn.net/vagrant0407/article/details/128978780</a></p><p>[6] 王发宽.基于NADA闪存的混合固态硬盘设计研究[D].杭州:杭州电子科技大学,2017.</p><p>[7] SSD Fans.深入浅出SSD[M].机械工业出版社,2018.</p><p>[8] 李想.基于软件架构的固态硬盘FTL设计[D].武汉:华中科技大学,2015.</p><p>[9] 赵鹏,白石.基于随机游走的大容量固态硬盘磨损均衡算法[J].计算机学报,2012,35(5):972-978.</p><p>[10] 周懿,戴紫彬,面向Nand Flash自适应纠错码方案研究与设计[J].计算机工程与设计,2017,38(6):1681-1685.</p><p>[11] 固态硬盘存储技术的分析<a href="https://blog.csdn.net/weixin/_46637351/article/details/126013567">https://blog.csdn.net/weixin\_46637351/article/details/126013567</a></p><p>[12] NOR Flash 和 NAND Flash 闪存详解<a href="https://blog.csdn.net/vagrant0407/article/details/127813278">https://blog.csdn.net/vagrant0407/article/details/127813278</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/vagrant0407/article/details/128986172&quot;&gt;https://blog.csdn.net/vagrant0407/article/details/128986172&lt;/a&gt;&lt;/p&gt;</summary>
      
    
    
    
    <category term="SSD" scheme="http://zhangyu.info/categories/SSD/"/>
    
    
    <category term="SSD" scheme="http://zhangyu.info/tags/SSD/"/>
    
  </entry>
  
  <entry>
    <title>用eBPF+XDP来替代LVS-1</title>
    <link href="http://zhangyu.info/2023/04/16/%E7%94%A8eBPF+XDP%E6%9D%A5%E6%9B%BF%E4%BB%A3LVS-1/"/>
    <id>http://zhangyu.info/2023/04/16/%E7%94%A8eBPF+XDP%E6%9D%A5%E6%9B%BF%E4%BB%A3LVS-1/</id>
    <published>2023-04-15T16:00:00.000Z</published>
    <updated>2023-04-16T10:04:12.305Z</updated>
    
    <content type="html"><![CDATA[<p> 以下文章来源于九零后程序员 ，作者mageekchiu </p><p><a href="http://news.sohu.com/a/664404869_121124374">用eBPF/XDP来替代LVS_rs-_ip_部署</a></p><blockquote><p>前文见#lvs合集分析了 LVS 作为负载均衡的原理。随着 eBPF 的发展，我们已经可以将 eBPF/XDP 程序直接部署在普通服务器上来实现负载均衡，从而节省掉用于专门部署 LVS 的机器。</p><p>本文不打算直接到这一步，而是首先看看如何用 eBPF/XDP 按照常规模式来替代 LVS，也就是说我们还是将负载均衡程序（software load balance 简称 SLB）部署在专用机器上，只不过不用 LVS，而是用 eBPF/XDP 来实现。</p><p>实验步骤 创建网络环境 # 不同发行版命令不一样</p><p>systemctl start docker</p><p>docker network create south –subnet 172.19.0.0/16 –gateway 172.19.0.1</p><p># check</p><p>docker network inspect south</p><p># or</p><p>ip link</p><p># 先用 ifconfig 获得刚创建的 network 应的 bridge</p><p># 后续则可以在宿主机上抓取这个 network 的所有 IP 包</p><p>tcpdump -i br-3512959a6150 ip</p><p># 也可以获得某个容器的 veth ,抓取这个容器进出的所有包</p><p>tcpdump -i vethf01d241 ip</p><p># 当然，如果是 offload 的模式，则调试确实不易，需要嗅探本地网络的数据包并抓取了</p><p># 在容器网络里，我们尚有宿主机这个上帝视角，在裸机网络里，则可能得去捯饬路由器了</p><p><img src="https://p3.itc.cn/q_70/images03/20230408/5d4a517204d445f3a8ca8faf9e76b16d.png"></p><p>创建两个RS echo “rs-1” &gt; rs1.html</p><p>echo “rs-2” &gt; rs2.html</p><p>docker run -itd –name rs1 –hostname rs1 –privileged=true –net south -p 8888:80 –ip 172.19.0.2 –mac-address=”02:42:ac:13:00:02” -v “$(pwd)”/rs1.html:/usr/share/nginx/html/index.html:ro nginx:stable</p><p>docker run -itd –name rs2 –hostname rs2 –privileged=true –net south -p 9999:80 –ip 172.19.0.3 –mac-address=”02:42:ac:13:00:03” -v “$(pwd)”/rs2.html:/usr/share/nginx/html/index.html:ro nginx:stable</p><p># check on host</p><p>curl 127.0.0.1:8888</p><p>curl 127.0.0.1:9999</p><p>另：</p><p>即使是 nginx 对于我们调试负载均衡也不是足够简单，调试阶段可以用 nc 来进行调试</p><p>dnf install nc or apt install netcat</p><p>server side nc -l -vv -p 5000</p><p>client side nc 172.19.0.2 5000</p><p>实现SLB</p><p>为了不影响 RS，本文采用 NAT 模式的进一步：Full-NAT 模式实现 SLB。这种模式有缺陷：rs 不能获得真实的 client ip，但是对部署环境要求相对较少（网络相通，无需设置默认网关）。</p><p>实现分析</p><p>源码都在 <a href="https://github.com/MageekChiu/xdp4slb%E3%80%82%E6%AC%A2%E8%BF%8E%E5%A4%A7%E5%AE%B6%E6%8F%90%E5%87%BA%E7%BC%BA%E9%99%B7%E5%92%8C%E5%BB%BA%E8%AE%AE%EF%BC%81">https://github.com/MageekChiu/xdp4slb。欢迎大家提出缺陷和建议！</a></p><p>核心框架如下:</p><p>if(dest_ip = vip &amp;&amp; dest_ port= vport){</p><p>ingress，包来源于 client，要转发给 rs</p><p>挑选本地一个可用的 port1-ip1 作为新包的 src</p><p>使用负载均衡算法挑选一个 rs，并将其 port2-ip2 作为新包的 dst</p><p>相应的修改 src mac 和 dst mac</p><p>此外保存 client 的 port3-ip3 和 port1-ip1 的双向映射关系</p><p>便于后续 ingress 和 egress 使用</p><p>} else{</p><p>egress，包来源于 rs， 要转发给 client</p><p>根据包的 dst 找到 port1-ip1</p><p>根据 ingress 里面的映射找到对应的 client 的 port3-ip3 作为新包的 dst</p><p>使用 vip 和 v port作为新包的 src</p><p>相应的修改 src mac 和 dst mac</p><p>}</p><p>重新计算校验和</p><p>使用 XDP_TX将包从本网卡重新扔回去</p><p>这里面还有些校验细节就不讲了，大家可以直接看代码</p><p>本地测试</p><p>开发完成后，可以先在本地进行编译和load，以提前暴露问题，没问题后，在将目标文件放到容器里进行测试</p><p># CORE, if you want to include vmlinux.h</p><p>bpftool btf dump file /sys/kernel /btf/vmlinux format c &gt; vmlinux.h</p><p># local compile and test</p><p>rm -f /sys/fs /bpf/slb \</p><p>&amp;&amp; rm -f slb.bpf.o \</p><p>&amp;&amp; clang -target bpf -g -O2 -c slb.bpf.c -o slb.bpf.o \</p><p>&amp;&amp; bpftool prog load slb.bpf.o /sys/fs /bpf/slb \</p><p>&amp;&amp; ll /sys/fs /bpf/slb \</p><p># for testing, you can cp newly compiled object to container</p><p>docker cp slb.bpf.o slb: /tmp/部署和配置SLB</p><p>Dockerfile 如下</p><p>FROMdebian:bullseye</p><p># modify source to get faster installation</p><p>RUNsed -i ‘s/deb.debian.org/mirrors.aliyun.com/g’/etc/apt/sources.list \</p><p>&amp;&amp; apt- getupdate -y &amp;&amp; apt- getupgrade -y \</p><p>&amp;&amp; apt install -y procps bpftool iproute2 net-tools telnet kmod curl tcpdump</p><p>WORKDIR /tmp/</p><p>COPY slb.bpf.o /tmp/</p><p>构建镜像并运行</p><p>docker build -t mageek/slb :0.1.</p><p>docker run -itd --nameslb --hostnameslb --privileged=true--netsouth --ip172.19.0.5 --mac-address=”02:42:ac:13:00:05”mageek/slb :0.1</p><p>进入容器加载 xdp 目标文件</p><p>docker exec -it slb bash</p><p># 在SLB中启用VIP</p><p># reuse mac addr from slb ip</p><p># ifconfig eth0:0 172.19.0.10/32 up</p><p># add new mac for vip</p><p>ifconfig eth0: 0172.19. 0.10/ 32hw ether 02: 42:ac: 13: 00: 10up</p><p># to delete</p><p># ifconfig eth0:0 down</p><p>bpftool net detach xdpgeneric dev eth0</p><p>rm /sys/fs /bpf/slb</p><p>bpftool prog load slb.bpf.o /sys/fs /bpf/slb</p><p># ls -l /sys/fs/bpf</p><p>bpftool prog list</p><p># bpftool prog show name xdp_lb –pretty</p><p># bpftool net attach xdpgeneric name xdp_lb dev eth0</p><p># or</p><p>bpftool net attach xdpgeneric id 211dev eth0</p><p># check with</p><p>ip link</p><p>cat /sys/kernel /debug/tracing/trace_pipe</p><p># better use code bellow</p><p>bpftool prog tracelog</p><p># won’t get any result, cause the packets haven’t got there</p><p>tcpdump host 172.19. 0.10</p><p>注意，虽然官方文档上说，attach xdp 会自己选择合适的模式，但是我们在虚拟网卡下面，只能选择 attach xdpgeneric，前者不会生效，估计是个bug。</p><p>测试</p><p>新起一个client容器</p><p>docker run-itd –name client --hostname client --privileged= true--net south -p 10000:80 –ip 172.19.0.9 --mac-address= “02:42:ac:13:00:09”nginx:stable</p><p>进入 client</p><p>dockerexec -it client bash</p><p># visit rs first</p><p>curl172.19.0.2:80</p><p>curl172.19.0.3:80</p><p># visit slb</p><p>curl172.19.0.10:80</p><p>rs- 1</p><p>curl172.19.0.10:80</p><p>rs- 2</p><p>curl172.19.0.10:80</p><p>rs- 1</p><p>curl172.19.0.10:80</p><p>rs- 2</p><p>可见确实实现了 round_robin 算法。</p><p>限制</p><p>TCP的负载均衡是比较复杂的，还有各种条件需要考虑，比如：多实例 SLB 之间的状态同步、conntrack 条目的回收、端口自动管理、arp动态处理等等。完整的实现是非常复杂和体系化的，本文作为一个简单的实现，目的是体验ebpf/xdp，生产级别的实现请自行完成（工作量较大）或参考社区已有版本（虽然不多）。</p><p>参考</p><ul><li><p>  <a href="https://github.com/torvalds/linux/blob/master/net/netfilter/nf/_nat/_core.c#L504">https://github.com/torvalds/linux/blob/master/net/netfilter/nf\_nat\_core.c#L504</a></p></li><li><p>  <a href="https://github.com/lizrice/lb-from-scratch/blob/main/README.MD">https://github.com/lizrice/lb-from-scratch/blob/main/README.MD</a></p></li><li><p>  <a href="https://github.com/xdp-project/xdp-tutorial">https://github.com/xdp-project/xdp-tutorial</a></p></li><li><p>  <a href="https://github.com/iovisor/bcc/issues/2463">https://github.com/iovisor/bcc/issues/2463</a></p></li><li><p>  <a href="https://github.com/facebookincubator/katran/blob/master/katran/lib/bpf/balancer/_helpers.h">https://github.com/facebookincubator/katran/blob/master/katran/lib/bpf/balancer\_helpers.h</a></p></li><li><p>  <a href="https://man.archlinux.org/man/bpftool-net.8.en">https://man.archlinux.org/man/bpftool-net.8.en</a></p></li><li><p>  <a href="https://www.kernel.org/doc/html/latest/core-api/printk-formats.html#ipv4-addresses">https://www.kernel.org/doc/html/latest/core-api/printk-formats.html#ipv4-addresses</a></p></li></ul><p>下文预告</p><p>本文采用了 bpftool 来手动加载 eBPF 程序，并且 VIP 和 RIP 都是 hard code。后面可以使用 libbpf 来支持 eBPF 的程序化加载和 VIP 配置。</p><p>另，本文体验了 xdp 如何替换 LVS 实现负载均衡功能，但是并没有充分体现 xdp 的优势，下回将分析 xdp 的真正优势场景：直接部署在普通服务器上，去掉专用的 LVS 服务</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; 以下文章来源于九零后程序员 ，作者mageekchiu &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://news.sohu.com/a/664404869_121124374&quot;&gt;用eBPF/XDP来替代LVS_rs-_ip_部署&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
</summary>
      
    
    
    
    <category term="eBPF+XDP" scheme="http://zhangyu.info/categories/eBPF-XDP/"/>
    
    
    <category term="eBPF+XDP" scheme="http://zhangyu.info/tags/eBPF-XDP/"/>
    
  </entry>
  
  <entry>
    <title>用eBPF+XDP来替代LVS-2</title>
    <link href="http://zhangyu.info/2023/04/16/%E7%94%A8eBPF+XDP%E6%9D%A5%E6%9B%BF%E4%BB%A3LVS-2/"/>
    <id>http://zhangyu.info/2023/04/16/%E7%94%A8eBPF+XDP%E6%9D%A5%E6%9B%BF%E4%BB%A3LVS-2/</id>
    <published>2023-04-15T16:00:00.000Z</published>
    <updated>2023-04-16T10:00:58.420Z</updated>
    
    <content type="html"><![CDATA[<p> 以下文章来源于九零后程序员 ，作者mageekchiu </p><blockquote><p>随着 eBPF 的发展，我们已经可以将 eBPF/XDP 程序直接部署在普通服务器上来实现负载均衡，从而节省掉用于专门部署 LVS 的机器。</p><p><a href="https://link.juejin.cn/?target=https://mp.weixin.qq.com/s/XjDXyNPjEzMy5jfwfO2AnA" title="https://mp.weixin.qq.com/s/XjDXyNPjEzMy5jfwfO2AnA">前文</a> 分享了如何使用 xdp/ebpf 替换 lvs 来实现 slb，采用的是 slb 独立机器部署模式，并且采用 bpftool 和硬编码配置的形式来进行加载 xdp 程序，这是 <a href="https://link.juejin.cn/?target=https://github.com/MageekChiu/xdp4slb/tree/dev-0.1" title="https://github.com/MageekChiu/xdp4slb/tree/dev-0.1">版本 0.1</a>。</p><p><a href="https://link.juejin.cn/?target=https://github.com/MageekChiu/xdp4slb/tree/dev-0.2" title="https://github.com/MageekChiu/xdp4slb/tree/dev-0.2">版本 0.2</a> 在 0.1 基础上，修改为基于 <a href="https://link.juejin.cn/?target=https://nakryiko.com/posts/bcc-to-libbpf-howto-guide/%23bpf-skeleton-and-bpf-app-lifecycle" title="https://nakryiko.com/posts/bcc-to-libbpf-howto-guide/#bpf-skeleton-and-bpf-app-lifecycle">bpf skeleton</a> 的程序化加载模式，要想简单地体验下这种工作流而不改动 版本0.1 中整体部署模式的，可以去看看 <a href="https://link.juejin.cn/?target=https://github.com/MageekChiu/xdp4slb/tree/dev-0.2" title="https://github.com/MageekChiu/xdp4slb/tree/dev-0.2">github.com/MageekChiu/…</a>。</p><p><a href="https://link.juejin.cn/?target=https://github.com/MageekChiu/xdp4slb/tree/dev-0.3" title="https://github.com/MageekChiu/xdp4slb/tree/dev-0.3">版本 0.3</a> 在 0.2 基础上，支持以配置文件和命令行参数的形式动态加载 slb 配置</p><p>本文属于 <a href="https://link.juejin.cn/?target=https://github.com/MageekChiu/xdp4slb/blob/dev-0.4/README-0.4.md" title="https://github.com/MageekChiu/xdp4slb/blob/dev-0.4/README-0.4.md">版本 0.4</a>，支持 slb 和 application 混布的模式，去除了专用的 slb 机器。<br>混布模式使得普通机器也能直接做负载均衡，同时不影响应用（off load 模式下可以体现），有成本效益；另外，在路由到本地的场景下，减少了路由跳数，整体性能更好。</p><h2 id="创建网络环境"><a href="#创建网络环境" class="headerlink" title="创建网络环境"></a>创建网络环境</h2><pre><code># 不同发行版命令不一样systemctl start dockerdocker network create south --subnet 172.19.0.0/16 --gateway 172.19.0.1# checkdocker network inspect south# orip link# 先用 ifconfig 获得刚创建的 network 应的 bridge# 后续则可以在宿主机上抓取这个 network 的所有 IP 包tcpdump -i br-3512959a6150 ip# 也可以获得某个容器的 veth ,抓取这个容器进出的所有包tcpdump -i vethf01d241  ip复制代码</code></pre><h1 id="原理解析"><a href="#原理解析" class="headerlink" title="原理解析"></a>原理解析</h1><h2 id="SLB-集群路由"><a href="#SLB-集群路由" class="headerlink" title="SLB 集群路由"></a>SLB 集群路由</h2><p>slb 为了高可用，一般都会集群化部署，那么请求怎么路由到每一台 slb 上呢？一般由（动态）路由协议（ospf bgp）实现 ecmp，使得各个 slb 实例从 router/switch 那里均匀地获得流量。<br>由于配置动态路由协议非常繁杂，不在本文考虑范围之内，这里采用一个简单的脚本来模拟 ecmp。</p><pre><code>#!/bin/bashdst=&quot;172.19.0.10&quot;rs1=&quot;172.19.0.2&quot;rs2=&quot;172.19.0.3&quot;ip route del $dst/32ip route add $dst/32 nexthop via $rs1 dev eth0 weight 1while true; do    nexthop=$(ip route show $dst/32 | awk &#39;&#123;print $3&#125;&#39;)    # nexthop=$(ip route show &quot;$dst&quot; | grep -oP &quot;nexthop \K\S+&quot;)    echo &quot;to $&#123;dst&#125; via $&#123;nexthop&#125; now!&quot;    sleep 3    # the requirements for blank is crazy!    if [ &quot;$nexthop&quot; = &quot;$rs1&quot; ]; then        new_nexthop=&quot;$rs2&quot;    else        new_nexthop=&quot;$rs1&quot;    fi    ip route del $dst/32    ip route add $dst/32 nexthop via $new_nexthop dev eth0 weight 1done复制代码</code></pre><p>其实就是将到达 vip 的下一跳在几个 host（混布有 slb 和 app 的机器，以下简称 mix） 之间反复修改即可。</p><h2 id="NAT模式"><a href="#NAT模式" class="headerlink" title="NAT模式"></a>NAT模式</h2><p>版本 0.1~0.3 都采用了 full nat 模式，在当前混布的模式下不再合适，可能会导致数据包无穷循环。因为不对数据包做一些标记的话，xdp 程序无法区分是来自 client 的数据包还是来自另一个 slb 的包。我们采用 DR 模式，除了能避免循环问题以外，性能也更好，因为</p><ol><li> 回包少了一跳</li><li> 包的修改少了，也不用重新计算 ip、tcp 校验和等</li></ol><p>架构图如下，这里做了简化，client 和 mix 之间实际上是有 router/switch 的，但是我们采用上面的模拟脚本把 router/switch 路由功能也直接放 client 里面了。</p><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1747db8b0dbc441685c941ca95aac2e1~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.image"></p><p>深蓝色表示请求，浅蓝色表示响应。<br>vip 采用了 ecmp，一次请求只会路由到一个 mix 上，mis 上的 slb 可能会把这个转发到本地 app（本文以 Nginx 为例） 或其它 mix，但是响应一定是从 mix 直接回去的，而不会再次经过其它 mix。</p><h2 id="负载均衡算法"><a href="#负载均衡算法" class="headerlink" title="负载均衡算法"></a>负载均衡算法</h2><p>目前支持以下几种算法</p><ul><li>  random</li><li>  round_roubin</li><li>  hash</li></ul><p>本文不在 slb 集群中同步会话状态，所以只能选择 hash 算法，也就是不论请求路由到哪个 slb ，都会被转发到同一个 backend app。</p><h2 id="SLB-路由伪代码"><a href="#SLB-路由伪代码" class="headerlink" title="SLB 路由伪代码"></a>SLB 路由伪代码</h2><pre><code>if (dest_ip = local_ip)&#123;    // 直接交给本机协议栈    return&#125;if (dest_ip = vip &amp;&amp; dest_port = vport)&#123;    使用负载均衡算法挑选一个 rs    若RS就是本机，则 直接交给本机协议栈 并 return    否则，将rs 的 mac 作为新包的 dst        此外保存 client 和 rs 的双向映射关系    便于后续 路由直接 使用    将本机 mac 作为新包的 src    将新包扔出去重新路由&#125;else&#123;    报错，丢包&#125;复制代码</code></pre><h1 id="配置SLB和应用"><a href="#配置SLB和应用" class="headerlink" title="配置SLB和应用"></a>配置SLB和应用</h1><p>Mix 的 Dockerfile 如下</p><pre><code>FROM debian:bookwormRUN apt-get update -y &amp;&amp; apt-get upgrade -y \    &amp;&amp; apt install -y nginx procps bpftool iproute2 net-tools telnet kmod curl tcpdumpWORKDIR /tmp/COPY src/slb /tmp/COPY slb.conf /tmp/复制代码</code></pre><p>这里修改镜像是因为我的宿主机 fedora:37 的 libc 版本是 2.36，而 debian:bullseye 对应的版本是 2.31 ，不能直接运行宿主机编译的可执行文件。</p><p>构建镜像并运行 app (这里是 nginx)</p><pre><code>docker build -t mageek/mix:0.1 .# in case you want to run a brand new containerdocker rm mix1 mix2 -fdocker run -itd --name mix1 --hostname mix1 --privileged=true \    --net south -p 8888:80 --ip 172.19.0.2 --mac-address=&quot;02:42:ac:13:00:02&quot; \    -v &quot;$(pwd)&quot;/rs1.html:/var/www/html/index.html:ro mageek/mix:0.1 nginx -g &quot;daemon off;&quot;docker run -itd --name mix2 --hostname mix2 --privileged=true \    --net south -p 9999:80 --ip 172.19.0.3 --mac-address=&quot;02:42:ac:13:00:03&quot; \    -v &quot;$(pwd)&quot;/rs2.html:/var/www/html/index.html:ro mageek/mix:0.1 nginx -g &quot;daemon off;&quot;# check on hostdocker pscurl 127.0.0.1:8888curl 127.0.0.1:9999复制代码</code></pre><p>分别进入容器，配置 VIP，由于我们已经有模拟的路由协议了，所以在 mix 中配置好 vip 以后，要关闭 arp，避免影响 client 的包的路由</p><pre><code>docker exec -it mix1 bashdocker exec -it mix2 bashifconfig lo:0 172.19.0.10/32 upecho &quot;1&quot;&gt;/proc/sys/net/ipv4/conf/all/arp_ignoreecho &quot;1&quot;&gt;/proc/sys/net/ipv4/conf/lo/arp_ignoreecho &quot;2&quot;&gt;/proc/sys/net/ipv4/conf/all/arp_announceecho &quot;2&quot;&gt;/proc/sys/net/ipv4/conf/lo/arp_announce复制代码</code></pre><p>然后运行 slb</p><pre><code># 启动 slb 并指定网卡和配置文件./slb -i eth0 -c ./slb.conf# in another terminal bpftool prog list# bpftool prog show name xdp_lb  --pretty# check global variables# bpftool map list# bpftool map dump name slb_bpf.rodata# check attaching with ip link复制代码</code></pre><p>日志直接在宿主机（整机一份）上看即可，不要开好几个终端（会导致日志不完整）</p><p><code>bpftool prog tracelog</code></p><p>此外，测试阶段可以直接在宿主机编译完成可执行文件后，拷贝到容器里(当然，前提是你已经创建好了这些容器和相关的网络)</p><pre><code>docker start mix1 mix2 clientdocker cp src/slb mix1:/tmp/ &amp;&amp; \docker cp slb.conf mix1:/tmp/ &amp;&amp; \docker cp src/slb mix2:/tmp/ &amp;&amp; \docker cp slb.conf mix2:/tmp/ &amp;&amp; \docker cp routing.sh client:/tmp/ 复制代码</code></pre><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>新起一个client容器</p><pre><code>docker run -itd --name client --hostname client --privileged=true \    --net south -p 10000:80 --ip 172.19.0.9 --mac-address=&quot;02:42:ac:13:00:09&quot; \    -v &quot;$(pwd)&quot;/routing.sh:/tmp/routing.sh mageek/mix:0.1 nginx -g &quot;daemon off;&quot;复制代码</code></pre><p>进入 client 配置并运行以下路由脚本脚本</p><pre><code>docker exec -it client bashsh routing.sh复制代码</code></pre><p>另开一个 client terminal 进行请求测试</p><pre><code>docker exec -it client bash# visit rs firstcurl 172.19.0.2:80curl 172.19.0.3:80# visit slb curl 172.19.0.10:80rs-1curl 172.19.0.10:80rs-2复制代码</code></pre><p>我们可以在 client 里面压测一把，但是要注意压测时不要运行 routing.sh ，因为并发场景下存在 <strong>“老路由刚被删，新路由尚未建立的中间态”</strong> 的问题，导致请求失败。</p><pre><code>apt-get install apache2-utils# 并发 50，总请求数 5000ab -c 50 -n 5000 http://172.19.0.10:80/复制代码</code></pre><p>压测结果如下，可见都成功了</p><pre><code>erver Software:        nginx/1.22.1Server Hostname:        172.19.0.10Server Port:            80Document Path:          /Document Length:        5 bytesConcurrency Level:      50Time taken for tests:   3.141 secondsComplete requests:      5000Failed requests:        0Total transferred:      1170000 bytesHTML transferred:       25000 bytesRequests per second:    1591.81 [#/sec] (mean)Time per request:       31.411 [ms] (mean)Time per request:       0.628 [ms] (mean, across all concurrent requests)Transfer rate:          363.75 [Kbytes/sec] receivedConnection Times (ms)              min  mean[+/-sd] median   maxConnect:        0   15   3.9     15      31Processing:     5   16   4.7     16      48Waiting:        0   11   4.4     10      34Total:         17   31   3.6     30      60Percentage of the requests served within a certain time (ms)  50%     30  66%     32  75%     32  80%     33  90%     35  95%     37  98%     40  99%     47 100%     60 (longest request)复制代码</code></pre><p>还可以增大并发数测试，并发最大理论值是我们存储 conntrack 条目的 back_map 数量最大值。超过这个并发数，会导致重新路由映射，可能导致 tcp reset。</p><h1 id="下文预告"><a href="#下文预告" class="headerlink" title="下文预告"></a>下文预告</h1><p>要想打造一个完整的 slb，还有许多工作要做，比如利用内核能力进行 mac 自动寻址、许多边界检查等。这都是后面要做的工作，欢迎大家一起参与 <a href="https://link.juejin.cn/?target=https://github.com/MageekChiu/xdp4slb/" title="https://github.com/MageekChiu/xdp4slb/">github.com/MageekChiu/…</a>。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; 以下文章来源于九零后程序员 ，作者mageekchiu &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;随着 eBPF 的发展，我们已经可以将 eBPF/XDP 程序直接部署在普通服务器上来实现负载均衡，从而节省掉用于专门部署 LVS 的机器。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;</summary>
      
    
    
    
    <category term="eBPF+XDP" scheme="http://zhangyu.info/categories/eBPF-XDP/"/>
    
    
    <category term="eBPF+XDP" scheme="http://zhangyu.info/tags/eBPF-XDP/"/>
    
  </entry>
  
  <entry>
    <title>Linux中CPU利用率是如何算出来的</title>
    <link href="http://zhangyu.info/2023/03/08/Linux%E4%B8%ADCPU%E5%88%A9%E7%94%A8%E7%8E%87%E6%98%AF%E5%A6%82%E4%BD%95%E7%AE%97%E5%87%BA%E6%9D%A5%E7%9A%84/"/>
    <id>http://zhangyu.info/2023/03/08/Linux%E4%B8%ADCPU%E5%88%A9%E7%94%A8%E7%8E%87%E6%98%AF%E5%A6%82%E4%BD%95%E7%AE%97%E5%87%BA%E6%9D%A5%E7%9A%84/</id>
    <published>2023-03-07T16:00:00.000Z</published>
    <updated>2023-03-08T04:36:54.791Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/40KWGKNBoa35s533YGWYIQ">https://mp.weixin.qq.com/s/40KWGKNBoa35s533YGWYIQ</a></p><p>Linux 中 CPU 利用率是如何算出来的<br>原创 张彦飞allen 开发内功修炼 2023-02-22</p><blockquote><p>在线上服务器观察线上服务运行状态的时候，绝大多数人都是喜欢先用 top 命令看看当前系统的整体 cpu 利用率。例如，随手拿来的一台机器，top 命令显示的利用率信息如下</p><p><img src="https://pic1.zhimg.com/v2-02de6736b8d9bbc34d93ec2b6d0b22a4_b.png"></p><p><img src="https://pic1.zhimg.com/v2-02de6736b8d9bbc34d93ec2b6d0b22a4_r.jpg"></p><p>这个输出结果说简单也简单，说复杂也不是那么容易就能全部搞明白的。例如：</p><p>问题 1：top 输出的利用率信息是如何计算出来的，它精确吗？<br>问题 2：ni 这一列是 nice，它输出的是 cpu 在处理啥时的开销？<br>问题 3：wa 代表的是 io wait，那么这段时间中 cpu 到底是忙碌还是空闲？</p><p>今天我们对 cpu 利用率统计进行深入的学习。通过今天的学习，你不但能了解 cpu 利用率统计实现细节，还能 nice、io wait 等指标有更深入的理解。</p><p>区别于以往的文章，今天我们不直接进入 Linux 实现，而是先从自己的思考开始！</p><h2 id="一、先思考一下"><a href="#一、先思考一下" class="headerlink" title="一、先思考一下"></a><strong>一、先思考一下</strong></h2><p>抛开 Linux 的实现先不谈，如果有如下需求，有一个四核服务器，上面跑了四个进程。</p><p><img src="https://pic2.zhimg.com/v2-b13f7213a807217826ac9b407cf793a5_b.jpg"></p><p><img src="https://pic2.zhimg.com/v2-b13f7213a807217826ac9b407cf793a5_r.jpg"></p><p>让你来设计计算整个系统 cpu 利用率的这个需求，支持像 top 命令这样的输出，满足以下要求：</p><ul><li>  cpu 使用率要尽可能地准确</li><li>  要能地体现秒级瞬时 cpu 状态</li></ul><p>可以先停下来阅读思考几分钟。</p><p><img src="https://pic1.zhimg.com/v2-8b44ef5e7066c9255773b63299bf4838_b.jpg"></p><p><img src="https://pic1.zhimg.com/v2-8b44ef5e7066c9255773b63299bf4838_r.jpg"></p><p>好，思考结束。经过思考你会发现，这个看起来很简单的需求，实际还是有点小复杂的。</p><p>其中一个思路是把所有进程的执行时间都加起来，然后再除以系统执行总时间*4。</p><p><img src="https://pic1.zhimg.com/v2-6bcc54f8a10115e04166eff64a5da1d0_b.jpg"></p><p><img src="https://pic1.zhimg.com/v2-6bcc54f8a10115e04166eff64a5da1d0_r.jpg"></p><p>这个思路是没问题的，用这种方法统计很长一段时间内的 cpu 利用率是可以的，统计也足够的准确。</p><p>但只要用过 top 你就知道 top 输出的 cpu 利用率并不是长时间不变的，而是默认 3 秒为单位会动态更新一下（这个时间间隔可以使用 -d 设置）。我们的这个方案体现总利用率可以，体现这种瞬时的状态就难办了。你可能会想到那我也 3 秒算一次不就行了？但这个 3 秒的时间从哪个点开始呢。粒度很不好控制。</p><p>上一个思路问题核心就是如何解决瞬时问题。提到瞬时状态，你可能就又来思路了。那我就用瞬时采样去看，看看当前有几个核在忙。四个核中如果有两个核在忙，那利用率就是 50%。</p><p>这个思路思考的方向也是正确的，但是问题有两个：</p><ul><li>  你算出的数字都是 25% 的整数倍</li><li>  这个瞬时值会导致 cpu 使用率显示的剧烈震荡。</li></ul><p>比如下图：</p><p><img src="https://pic1.zhimg.com/v2-a575e13ff2437b0fb3147b884ca1b740_b.jpg"></p><p><img src="https://pic1.zhimg.com/v2-a575e13ff2437b0fb3147b884ca1b740_r.jpg"></p><p>在 t1 的瞬时状态看来，系统的 cpu 利用率毫无疑问就是 100%，但在 t2 时间看来，使用率又变成 0% 了。思路方向是对的，但显然这种粗暴的计算无法像 top 命令一样优雅地工作。</p><p>我们再改进一下它，把上面两个思路结合起来，可能就能解决我们的问题了。在采样上，我们把周期定的细一些，但在计算上我们把周期定的粗一些。</p><p>我们引入采用周期的概念，定时比如每 1 毫秒采样一次。如果采样的瞬时，cpu 在运行，就将这 1 ms 记录为使用。这时会得出一个瞬时的 cpu 使用率，把它都存起来。</p><p><img src="https://pic4.zhimg.com/v2-7629838dec9eb6dfb77751259ccb05af_b.jpg"></p><p><img src="https://pic4.zhimg.com/v2-7629838dec9eb6dfb77751259ccb05af_r.jpg"></p><p>在统计 3 秒内的 cpu 使用率的时候，比如上图中的 t1 和 t2 这段时间范围。那就把这段时间内的所有瞬时值全加一下，取个平均值。这样就能解决上面的问题了，统计相对准确，避免了瞬时值剧烈震荡且粒度过粗（只能以 25 %为单位变化）的问题了。</p><p>可能有同学会问了，假如 cpu 在两次采样中间发生变化了呢，如下图这种情况。</p><p><img src="https://pic1.zhimg.com/v2-d40df24f387387e77d645a4624def564_b.jpg"></p><p><img src="https://pic1.zhimg.com/v2-d40df24f387387e77d645a4624def564_r.jpg"></p><p>在当前采样点到来的时候，进程 A 其实刚执行完，有一点点时间没有既没被上一个采样点统计到，本次也统计不到。对于进程 B，其实只开始了一小段时间，把 1 ms 全记上似乎有点多记了。</p><p>确实会存在这个问题，但因为我们的采样是 1 ms 一次，而我们实际查看使用的时候最少也有是秒级别地用，会包括有成千上万个采样点的信息，所以这种误差并不会影响我们对全局的把握。</p><p>事实上，Linux 也就是这样来统计系统 cpu 利用率的。虽然可能会有误差，但作为一项统计数据使用已经是足够了的。在实现上，Linux 是将所有的瞬时值都累加到某一个数据上的，而不是真的存了很多份的瞬时数据。</p><p>接下来就让我们进入 Linux 来查看它对系统 cpu 利用率统计的具体实现。</p><h2 id="二、top-命令使用数据在哪儿"><a href="#二、top-命令使用数据在哪儿" class="headerlink" title="二、top 命令使用数据在哪儿"></a><strong>二、top 命令使用数据在哪儿</strong></h2><p>上一节我们说的 Linux 在实现上是将瞬时值都累加到某一个数据上的，这个值是内核通过 /proc/stat 伪文件来对用户态暴露。Linux 在计算系统 cpu 利用率的时候用的就是它。</p><p>整体上看，top 命令工作的内部细节如下图所示。</p><p><img src="https://pic4.zhimg.com/v2-c7a59f749efe2f28b96dea41b04cdac3_b.jpg"></p><p><img src="https://pic4.zhimg.com/v2-c7a59f749efe2f28b96dea41b04cdac3_r.jpg"></p><ul><li>  top 命令访问 /proc/stat 获取各项 cpu 利用率使用值</li><li>  内核调用 stat_open 函数来处理对 /proc/stat 的访问</li><li>  内核访问的数据来源于 kernel_cpustat 数组，并汇总</li><li>  打印输出给用户态</li></ul><p>接下来我们把每一步都展开来详细看看。</p><p>通过使用 strace 跟踪 top 命令的各种系统调用，可以看的到它对该文件的调用。</p><pre><code># strace top...openat(AT_FDCWD, &quot;/proc/stat&quot;, O_RDONLY) = 4openat(AT_FDCWD, &quot;/proc/2351514/stat&quot;, O_RDONLY) = 8openat(AT_FDCWD, &quot;/proc/2393539/stat&quot;, O_RDONLY) = 8...</code></pre><blockquote><p>除了 /proc/stat 外，还有各个进程细分的 /proc/{pid}/stat，是用来计算各个进程的 cpu 利用率时使用的。</p></blockquote><p>内核为各个伪文件都定义了处理函数，/proc/stat 文件的处理方法是 proc_stat_operations。</p><pre><code>//file:fs/proc/stat.cstatic int __init proc_stat_init(void)&#123; proc_create(&quot;stat&quot;, 0, NULL, &amp;proc_stat_operations); return 0;&#125;static const struct file_operations proc_stat_operations = &#123; .open  = stat_open, ...&#125;;</code></pre><p>proc_stat_operations 中包含了该文件时对应的操作方法。当打开 /proc/stat 文件的时候，stat_open 就会被调用到。stat_open 依次调用 single_open_size，show_stat 来输出数据内容。我们来看看它的代码：</p><pre><code>//file:fs/proc/stat.cstatic int show_stat(struct seq_file *p, void *v)&#123; u64 user, nice, system, idle, iowait, irq, softirq, steal; for_each_possible_cpu(i) &#123;  struct kernel_cpustat *kcs = &amp;kcpustat_cpu(i);  user += kcs-&gt;cpustat[CPUTIME_USER];  nice += kcs-&gt;cpustat[CPUTIME_NICE];  system += kcs-&gt;cpustat[CPUTIME_SYSTEM];  idle += get_idle_time(kcs, i);  iowait += get_iowait_time(kcs, i);  irq += kcs-&gt;cpustat[CPUTIME_IRQ];  softirq += kcs-&gt;cpustat[CPUTIME_SOFTIRQ];  ... &#125; //转换成节拍数并打印出来 seq_put_decimal_ull(p, &quot;cpu  &quot;, nsec_to_clock_t(user)); seq_put_decimal_ull(p, &quot; &quot;, nsec_to_clock_t(nice)); seq_put_decimal_ull(p, &quot; &quot;, nsec_to_clock_t(system)); seq_put_decimal_ull(p, &quot; &quot;, nsec_to_clock_t(idle)); seq_put_decimal_ull(p, &quot; &quot;, nsec_to_clock_t(iowait)); seq_put_decimal_ull(p, &quot; &quot;, nsec_to_clock_t(irq)); seq_put_decimal_ull(p, &quot; &quot;, nsec_to_clock_t(softirq)); ...&#125;</code></pre><p>在上面的代码中，for_each_possible_cpu 是在遍历存储着 cpu 使用率数据的 kcpustat_cpu 变量。该变量是一个 percpu 变量，它为每一个逻辑核都准备了一个数组元素。里面存储着当前核所对应各种事件，包括 user、nice、system、idel、iowait、irq、softirq 等。</p><p>在这个循环中，将每一个核的每种使用率都加起来。最后通过 seq_put_decimal_ull 将这些数据输出出来。</p><p><img src="https://pic1.zhimg.com/v2-832a8469182b55b7c97d9e76f60de7cc_b.jpg"></p><p><img src="https://pic1.zhimg.com/v2-832a8469182b55b7c97d9e76f60de7cc_r.jpg"></p><p>注意，在内核中实际每个时间记录的是纳秒数，但是在输出的时候统一都转化成了节拍单位。至于节拍单位多长，下一节我们介绍。总之， /proc/stat 的输出是从 kernel_cpustat 这个 percpu 变量中读取出来的。</p><p>我们接着再看看这个变量中的数据是何时加进来的。</p><h2 id="三、统计数据怎么来的"><a href="#三、统计数据怎么来的" class="headerlink" title="三、统计数据怎么来的"></a><strong>三、统计数据怎么来的</strong></h2><p>前面我们提到内核是以采样的方式来统计 cpu 使用率的。这个采样周期依赖的是 Linux 时间子系统中的定时器。</p><p>Linux 内核每隔固定周期会发出 timer interrupt (IRQ 0)，这有点像乐谱中的节拍的概念。每隔一段时间，就打出一个拍子，Linux 就响应之并处理一些事情。</p><p><img src="https://pic2.zhimg.com/v2-dc678ad0a78577fb8690b277bfaf18d5_b.jpg"></p><p><img src="https://pic2.zhimg.com/v2-dc678ad0a78577fb8690b277bfaf18d5_r.jpg"></p><p>一个节拍的长度是多长时间，是通过 CONFIG_HZ 来定义的。它定义的方式是每一秒有几次 timer interrupts。不同的系统中这个节拍的大小可能不同，通常在 1 ms 到 10 ms 之间。可以在自己的 Linux config 文件中找到它的配置。</p><pre><code># grep ^CONFIG_HZ /boot/config-5.4.56.bsk.10-amd64CONFIG_HZ=1000</code></pre><p>从上述结果中可以看出，我的机器的每秒要打出 1000 次节拍。也就是每 1 ms 一次。</p><p>每次当时间中断到来的时候，都会调用 update_process_times 来更新系统时间。更新后的时间都存储在我们前面提到的 percpu 变量 kcpustat_cpu 中。</p><p><img src="https://pic2.zhimg.com/v2-5cd853bc434f3df18ac95f42a1f3c7e5_b.jpg"></p><p><img src="https://pic2.zhimg.com/v2-5cd853bc434f3df18ac95f42a1f3c7e5_r.jpg"></p><p>我们来详细看下汇总过程 update_process_times 的源码，它位于 kernel/time/timer.c 文件中。</p><pre><code>//file:kernel/time/timer.cvoid update_process_times(int user_tick)&#123; struct task_struct *p = current; //进行时间累积处理 account_process_tick(p, user_tick); ...&#125;</code></pre><p>这个函数的参数 user_tick 值得是采样的瞬间是处于内核态还是用户态。接下来调用 account_process_tick。</p><pre><code>//file:kernel/sched/cputime.cvoid account_process_tick(struct task_struct *p, int user_tick)&#123; cputime = TICK_NSEC; ... if (user_tick)  //3.1 统计用户态时间  account_user_time(p, cputime); else if ((p != rq-&gt;idle) || (irq_count() != HARDIRQ_OFFSET))  //3.2 统计内核态时间  account_system_time(p, HARDIRQ_OFFSET, cputime); else  //3.3 统计空闲时间  account_idle_time(cputime);&#125;</code></pre><p>在这个函数中，首先设置 <code>cputime = TICK_NSEC</code>, 一个 TICK_NSEC 的定义是一个节拍所占的纳秒数。接下来根据判断结果分别执行 account_user_time、account_system_time 和 account_idle_time 来统计用户态、内核态和空闲时间。</p><h3 id="3-1-用户态时间统计"><a href="#3-1-用户态时间统计" class="headerlink" title="3.1 用户态时间统计"></a><strong>3.1 用户态时间统计</strong></h3><pre><code>//file:kernel/sched/cputime.cvoid account_user_time(struct task_struct *p, u64 cputime)&#123; //分两种种情况统计用户态 CPU 的使用情况 int index; index = (task_nice(p) &gt; 0) ? CPUTIME_NICE : CPUTIME_USER; //将时间累积到 /proc/stat 中 task_group_account_field(p, index, cputime); ......&#125;</code></pre><p>account_user_time 函数主要分两种情况统计：</p><ul><li>  如果进程的 nice 值大于 0，那么将会增加到 CPU 统计结构的 nice 字段中。</li><li>  如果进程的 nice 值小于等于 0，那么增加到 CPU 统计结构的 user 字段中。</li></ul><p>看到这里，开篇的问题 2 就有答案了，其实用户态的时间不只是 user 字段，nice 也是。之所以要把 nice 分出来，是为了让 Linux 用户更一目了然地看到调过 nice 的进程所占的 cpu 周期有多少。</p><p>我们平时如果想要观察系统的用户态消耗的时间的话，应该是将 top 中输出的 user 和 nice 加起来一并考虑，而不是只看 user！</p><p>接着调用 task_group_account_field 来把时间加到前面我们用到的 kernel_cpustat 内核变量中。</p><pre><code>//file:kernel/sched/cputime.cstatic inline void task_group_account_field(struct task_struct *p, int index,      u64 tmp)&#123; __this_cpu_add(kernel_cpustat.cpustat[index], tmp); ...&#125;</code></pre><h3 id="3-2-内核态时间统计"><a href="#3-2-内核态时间统计" class="headerlink" title="3.2 内核态时间统计"></a><strong>3.2 内核态时间统计</strong></h3><p>我们再来看内核态时间是如何统计的，找到 account_system_time 的代码。</p><pre><code>//file:kernel/sched/cputime.cvoid account_system_time(struct task_struct *p, int hardirq_offset, u64 cputime)&#123; if (hardirq_count() - hardirq_offset)  index = CPUTIME_IRQ; else if (in_serving_softirq())  index = CPUTIME_SOFTIRQ; else  index = CPUTIME_SYSTEM; account_system_index_time(p, cputime, index);&#125;</code></pre><p>内核态的时间主要分 3 种情况进行统计。</p><ul><li>  如果当前处于硬中断执行上下文, 那么统计到 irq 字段中</li><li>  如果当前处于软中断执行上下文, 那么统计到 softirq 字段中</li><li>  否则统计到 system 字段中</li></ul><p>判断好要加到哪个统计项中后，依次调用 account_system_index_time、task_group_account_field 来将这段时间加到内核变量 kernel_cpustat 中</p><pre><code>//file:kernel/sched/cputime.cstatic inline void task_group_account_field(struct task_struct *p, int index,      u64 tmp)&#123;  __this_cpu_add(kernel_cpustat.cpustat[index], tmp);&#125;</code></pre><h3 id="3-3-空闲时间的累积"><a href="#3-3-空闲时间的累积" class="headerlink" title="3.3 空闲时间的累积"></a><strong>3.3 空闲时间的累积</strong></h3><p>没错，在内核变量 kernel_cpustat 中不仅仅是统计了各种用户态、内核态的使用统计，空闲也一并统计起来了。</p><p>如果在采样的瞬间，cpu 既不在内核态也不在用户态的话，就将当前节拍的时间都累加到 idle 中。</p><pre><code>//file:kernel/sched/cputime.cvoid account_idle_time(u64 cputime)&#123; u64 *cpustat = kcpustat_this_cpu-&gt;cpustat; struct rq *rq = this_rq(); if (atomic_read(&amp;rq-&gt;nr_iowait) &gt; 0)  cpustat[CPUTIME_IOWAIT] += cputime; else  cpustat[CPUTIME_IDLE] += cputime;&#125;</code></pre><p>在 cpu 空闲的情况下，进一步判断当前是不是在等待 IO（例如磁盘 IO），如果是的话这段空闲时间会加到 iowait 中，否则就加到 idle 中。从这里，我们可以看到 iowait 其实是 cpu 的空闲时间，只不过是在等待 IO 完成而已。</p><p>看到这里，开篇问题 3 也有非常明确的答案了，io wait 其实是 cpu 在空闲状态的一项统计，只不过这种状态和 idle 的区别是 cpu 是因为等待 io 而空闲。</p><h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a><strong>四、总结</strong></h2><p>本文深入分析了 Linux 统计系统 CPU 利用率的内部原理。全文的内容可以用如下一张图来汇总：</p><p><img src="https://pic3.zhimg.com/v2-d97225b8d4a45dbdefee63904ff44656_b.jpg"></p><p><img src="https://pic3.zhimg.com/v2-d97225b8d4a45dbdefee63904ff44656_r.jpg"></p><p>Linux 中的定时器会以某个固定节拍，比如 1 ms 一次采样各个 cpu 核的使用情况，然后将当前节拍的所有时间都累加到 user/nice/system/irq/softirq/io_wait/idle 中的某一项上。</p><p>top 命令是读取的 /proc/stat 中输出的 cpu 各项利用率数据，而这个数据在内核中的是根据 kernel_cpustat 来汇总并输出的。</p><p>回到开篇问题 1，top 输出的利用率信息是如何计算出来的，它精确吗？</p><p>/proc/stat 文件输出的是某个时间点的各个指标所占用的节拍数。如果想像 top 那样输出一个百分比，计算过程是分两个时间点 t1, t2 分别获取一下 stat 文件中的相关输出，然后经过个简单的算术运算便可以算出当前的 cpu 利用率。</p><p>我也提供了一个简单的 shell 代码，你可以把它下载下来，用它来实际查看一下你服务器的 cpu 利用率，我放到我的 github 上了。</p><p>Github 地址：<a href="https://link.zhihu.com/?target=https://github.com/yanfeizhang/coder-kung-fu/blob/main/tests/cpu/test06/cpu_stat.sh">https://github.com/yanfeizhang/coder-kung-fu/blob/main/tests/cpu/test06/cpu_stat.sh</a></p><p>再说是否精确。这个统计方法是采样的，只要是采样，肯定就不是百分之百精确。但由于我们查看 cpu 使用率的时候往往都是计算 1 秒甚至更长一段时间的使用情况，这其中会包含很多采样点，所以查看整体情况是问题不大的。</p><p>另外从本文，我们也学到了 top 中输出的 cpu 时间项目其实大致可以分为三类：</p><p><strong>第一类：</strong>用户态消耗时间，包括 user 和 nice。如果想看用户态的消耗，要将 user 和 nice 加起来看才对。<br><strong>第二类：</strong>内核态消耗时间，包括 irq、softirq 和 system。<br><strong>第三类：</strong>空闲时间，包括 io_wait 和 idle。其中 io_wait 也是 cpu 的空闲状态，只不过是在等 io 完成而已。如果只是想看 cpu 到底有多闲，应该把 io_wait 和 idle 加起来才对。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/40KWGKNBoa35s533YGWYIQ&quot;&gt;https://mp.weixin.qq.com/s/40KWGKNBoa35s533YGWYIQ&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Linux 中 CPU 利用率是</summary>
      
    
    
    
    <category term="linux" scheme="http://zhangyu.info/categories/linux/"/>
    
    
    <category term="linux" scheme="http://zhangyu.info/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>多少道防线才能挡住顶尖黑客？</title>
    <link href="http://zhangyu.info/2023/01/03/%E5%A4%9A%E5%B0%91%E9%81%93%E9%98%B2%E7%BA%BF%E6%89%8D%E8%83%BD%E6%8C%A1%E4%BD%8F%E9%A1%B6%E5%B0%96%E9%BB%91%E5%AE%A2/"/>
    <id>http://zhangyu.info/2023/01/03/%E5%A4%9A%E5%B0%91%E9%81%93%E9%98%B2%E7%BA%BF%E6%89%8D%E8%83%BD%E6%8C%A1%E4%BD%8F%E9%A1%B6%E5%B0%96%E9%BB%91%E5%AE%A2/</id>
    <published>2023-01-02T16:00:00.000Z</published>
    <updated>2023-01-03T13:50:25.250Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/vigor2323/article/details/126552784">https://blog.csdn.net/vigor2323/article/details/126552784</a></p><p><a href="https://blog.csdn.net/vigor2323/article/details/126552784">多少道防线才能挡住顶尖黑客？_vigor2323的博客-CSDN博客</a></p><blockquote><p>本文别名：网络安全纵深防御五道防线</p><p>先看一下这张图，这是欧洲中世纪非常典型的棱堡。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/ef4a9a3b6da7b822e40018db4f48b0db.jpeg" alt="ef4a9a3b6da7b822e40018db4f48b0db.jpeg">棱堡</p><p>在十字军东征期间，代表基督教世界的医院骑士团占领了意大利罗德岛，在岛上修建了这样的棱堡，用7000多人抵御奥斯曼帝国，而对方，派出400艘战舰和10万人的军队发起攻击。</p><p>城堡分外城和内城，城墙设计成凹陷形状，外面还挖了壕沟，这样，不管是敌军从哪个方向进攻，守方都可以在两个面上对来犯者进行打击。</p><p>奥斯曼帝国使用火炮、挖地道、正面攻坚等方式下，两个月后，终于攻破了外墙。骑士团依靠内墙，又抵御了3个月，最后，双方由于精疲力尽，缺乏补给，谁也再耗不起，最终通过和谈方式才结束了战争。骑士团携带财产完美退出。</p><p>显然，_纵深防御思维作为人类战争中最朴素的思维，在网络安全领域一样适用。_但专门研究网络安全纵深防御的文章非常少见，人们通常觉得说说就可以了。</p><p>对于一个企业或单位，要构筑多少道防线，以及怎样的防线，才能抵挡中国顶尖级别的黑客团队？</p><p>我认为至少要五道。</p><h2 id="第一道：边界防御"><a href="#第一道：边界防御" class="headerlink" title="第一道：边界防御"></a>第一道：边界防御</h2><p><em>边界防御是最基础、最常用，也是最管用的。</em></p><p><em>一个单位，即便人力和资源再有限，也会在边界上投入的。</em></p><p>这其中，_防火墙是最基础的_。注意一点，对于比较大的单位，建议仅使用防火墙的网络封禁能力，不要使用其他那些花里胡哨的功能，这主要是从性能角度考虑，让防火墙做单一的事，其他功能让其他设备做。</p><p>防火墙封禁应尽可能做到自动化、简单化、减少误操作，使得操作员简单填入IP就可以封禁，而不需要登录防火墙操作。具体参见<a href="https://blog.csdn.net/vigor2323/article/details/126552784">《如何封禁大量恶意IP》</a>。</p><p>第二类产品是_IDS/IPS_，这个比较古老，而且多年来一直以海量报警而闻名，所以形象比较差，一般而言不是监控防御的主力选手。</p><p>_WAF_是一道防线的重要组成部分，可以抵御常见的WEB攻击，这类产品已经比较成熟，通过返回HTTP错误的形式拦截攻击。由于其自动化拦截能力，<a href="https://so.csdn.net/so/search?q=WAF&spm=1001.2101.3001.7020">WAF</a>是一道防线必不可少的。</p><p>_K01_这类产品，结合情报信息，可以实时阻断进犯IP，而且不用串接，也是很有力的工具。它通过发送TCP reset包分别到访问端和服务端，有很好的拦截效果。</p><p>还有一类工具叫_“动态安全”_，这类产品，可以自动识别访问者是自然人还是黑客工具。如果发现是后者，则自动阻断（返回HTTP错误），这让惯用工具的黑客非常头疼。</p><blockquote><p>它的基本原理是：设备以中间人形式串接在服务端和访问端之间，当服务端返回响应页面时，设备在返回页面中插入js，要求访问端（浏览器或黑客工具）执行js并计算出token放入cookie返回，设备收到token后进行判断，判断对方是否为黑客工具并采取相应动作。</p><p>这类产品还可以对页面中的指定内容（比如页面中的url或是表单内容）做加密。虽然从理论上讲，这种加密难不倒一个意志坚定的<a href="https://so.csdn.net/so/search?q=%E5%AF%86%E7%A0%81%E5%AD%A6&spm=1001.2101.3001.7020">密码学</a>爱好者（因为客户端和服务端之间并没有实现一个完美的密钥建立机制），但对付那些熟练的渗透工具使用者已经足够。</p></blockquote><p>部署时，对于HTTPS应用，这类产品应放在SSL网关之后，如果并没有SSL网关，要把服务端的证书和私钥导入产品，总之，产品要能看得见明文。</p><p>一道防线主要部署在企业边界和DMZ区。一般来说，会有这样的复杂性：入站的流量经过一层层的安全设备，在逻辑上呈现出糖葫芦状，在部署和维护时，需要清晰梳理关系和路由，比较麻烦。</p><p>使用_流量编排设备_，可以通过SDN技术将流量进行灵活、简单地配置，原先串接的安全设备放入安全资源池中，流量经过谁，不经过谁，先过谁，后过谁，经过一台，还是多台，都可以通过Web界面做比较容易的编排，这就轻松多了。</p><p>_流量编排使得安全结构和网络拓扑解耦，在部署和维护上会带来很多便利。_这篇文章<a href="https://blog.csdn.net/vigor2323/article/details/126552784">《网络智能流量编排探索》</a>很好，感兴趣可以看看。</p><h2 id="第二道：监测响应"><a href="#第二道：监测响应" class="headerlink" title="第二道：监测响应"></a>第二道：监测响应</h2><p>第二道防线的名字不太好取，我反复思考以后，将其命名为监测响应。</p><p><em>二道防线中的重点不是拦截，而是能准确发现正在发生的攻击，不管是从外部还是内部发起的。</em></p><p>像_NTA、NDR_，都属于这类工具，为确保安全，一个单位应至少部署两到三家这样的产品，互相弥补对方的不足：即便一家发现不了，另一家也可能发现。当然，最好的情况下，这类产品可以和防火墙联动。</p><p>很多产品仅分析访问单向来包，并不做双向的分析。_WEBIDS_做得比较好，它能够对http请求和响应进行综合分析，服务端是否已经被控，很有价值。</p><p>_蜜罐/蜜网_主要用来引诱攻击者，内网的蜜罐如果被触发，不是误触就是攻击者已经进来。通常应在各个网络区域都开启蜜罐，只要是不用的IP都放入蜜罐。可以购买专门的产品，也可以利用负载均衡的功能来设置。</p><p>_抗APT工具_这里不多说了，它的侧重点和优势在于发现木马。</p><p>在检测木马（包括隐蔽信道）方面，还有一种比较新的产品是_加密流量检测_。现在，几乎所有木马都采用了加密方式，没有私钥是无法解开分析的，这类产品可以通过特征匹配、行为识别和机器学习的方法，在不解密的情况下，分析一个加密流量是不是木马流量。</p><p>总之，这道防线的产品很多，而且往往会用到很多先进技术，但能力和易用性参差不齐，能否买到好的产品，既考验判断力，也考验运气，如果条件允许，多部署一些总是对的。</p><p>从基础设施上讲，单位最好能建设一个_流量汇聚平台_，该平台可以采集各个网络区域的流量，然后汇聚和处理，最终输出到需要流量的设备，这样，各类安全设备不用到处接流量，集中部署并享用流量输出就可以了。这篇文章<a href="https://blog.csdn.net/vigor2323/article/details/126552784">《数据中心流量如何整合应用》</a>就是讲这个的，有兴趣可以一看。</p><h2 id="第三道：访问控制"><a href="#第三道：访问控制" class="headerlink" title="第三道：访问控制"></a>第三道：访问控制</h2><p><em>基本上，内网里面的一切访问控制措施都可以认为是第三道防线。</em></p><p>这道防线体现一个单位的安全基本功，也体现一个单位的信息科技实力。</p><p>访问控制其实就是给攻击者处处设卡，让攻击者寸步难行。</p><p>_从网络访问的角度看_，网络分区，系统间的隔离，终端间的隔离，以及网络准入、DNS安全等，都是非常有效的防护手段。</p><p>_从资源访问的角度看_，使用虚拟桌面、堡垒机、特权管理这些工具，使得服务器、网络设备、数据库不能被随便访问，结合口令管理、认证管理（包括双因素）、审计管理（录屏取证）等，不仅防外部攻击，也防内部人员攻击。</p><p>_从应用访问的角度看_，通过开发安全、认证授权、加密通信、加密存储、漏洞管理等这些工作，来保障应用系统的安全性。这方面内容很多，这里不细说了。</p><p>值得一提的是，<em>看似不起眼的口令管理，应该格外重视_，很多所谓著名黑客的著名攻击，并没有什么技术含量，仅仅是口令的窃取和尝试成功而已。一个单位的口令管理应尽可能自动和严格，强制口令复杂度、强制定期修改，对于重要系统强制双因素认证（短信或动态口令）。_这些看上去不难，但能做好的很少，只有很懂安全的单位才能做好这件事。</em></p><p>_从安全的本质讲，第三道防线是最重要的。_一道和二道防线在很大程度上都是在帮助三道，如果一个应用系统自身不安全，前两道防线能挡一挡，但终究是挡不住的。</p><p>如果应用系统很安全，即便没有前两道防线，攻击者也无计可施。</p><p>看过我写的<a href="https://blog.csdn.net/vigor2323/article/details/126552784">《区块链安全和传统安全的区别》</a>都知道，安全说到底，是程序的问题。</p><p>开发安全能力，是真正的实力。</p><h2 id="第四道：端点安全"><a href="#第四道：端点安全" class="headerlink" title="第四道：端点安全"></a>第四道：端点安全</h2><p><em>端点通常是攻击者最想拿到的据点，拿下一个机器就代表着一种胜利。</em></p><p>这道防线建立在服务器或用户终端上，从技术上讲，这已经是最后的防线了。</p><p>这道防线最基本的一个功能是_防病毒_，这里不多说了，主要说说_EDR_（端点检测和响应）。</p><p>_EDR_的重要功能是异常发现，主要是通过对主机的网络、进程、文件等资源的监控。比如通过_网络监测_，可以发现正在开展的网络攻击、网络扫描以及可疑的外联；通过_进程监测_，可以发现一些异常的进程创建和执行；通过_文件监测_，可以发现一些恶意文件的读写。</p><p>EDR可以对这些网络异常、进程异常、文件异常进行阻拦和处置，这在一定程度上可以防范0day攻击。</p><p>此外，通过监测日志，EDR可以发现正在开展的暴力破解；通过离线破译，可以发现常见应用的弱口令；其他如资产管理、漏洞管理等能力也很实用。</p><p>总体而言，这类产品是非常有力和有效的。</p><h2 id="第五道：人的防线"><a href="#第五道：人的防线" class="headerlink" title="第五道：人的防线"></a>第五道：人的防线</h2><p>上述这些工具，都需要人的使用和维护。<em>人就是第五道防线。</em></p><p>所以你看在搞安全演习时，满满一屋子都是人（至少30、40人起）。</p><p>组织层面不多说了，大多数单位在组织层面做得都还不错，因为组织技术是通用的，一般而言，就是领导重视、层层压实、某处牵头、全局动员、资产梳理、表格完善、制定方案、安排任务、汇报进度、协调资源、各司其职、检查确认、问题发现、举一反三，落实整改，层层请示、高层决策。这和做其他工作没有什么不同，属于管理层面的技术。</p><p>但有一点，传统管理往往不太能注意到，并因此中招，这就是老生常谈的安全意识问题。</p><p>纵观网络安全攻击史，社工一直是攻击者最重要的手段。（没有之一）</p><p><em>一个攻击者想入侵一个单位，100%会采用社工方法，所以一定要在所有员工的意识层面建立起强大的防御能力。</em></p><p>一封带有木马的钓鱼邮件，如果躲过了第一层的封禁，逃过了第二层的检测，一般就会逃过第三层和第四层，那么这封邮件就展现在员工面前了，这时就靠员工的安全意识防线了。</p><p>增强员工意识的方法就是反复讲，反复说，反复培训，反复测试，看看员工是不是真的掌握了，要通过最真实的案例强化员工意识。</p><p>这个工作看上去没有什么技术含量，但如果水平不足，往往无法做好这个工作。</p><p><em>反社工需要和社工一样的能力：洞悉人性。</em></p><h2 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h2><p>第一道防线守住大门，及时阻拦可能的攻击。</p><p>第二道防线严加监测，一旦发现有异常，立刻处置。</p><p>第三道防线坚壁清野，让攻击者即便进来也寸步难行，无门可入，或者是处处踩雷。</p><p>第四道防线坚守据点，在终端层面第一时间发现异常，然后采取行动。</p><p>第五道防线全民皆兵，各司其职，协作有力；人人不中招，不上当。</p><h2 id="纵深防御的应用"><a href="#纵深防御的应用" class="headerlink" title="纵深防御的应用"></a>纵深防御的应用</h2><p>这些年比较火的零信任架构，其实也是纵深防御思维的应用。</p><p>下图是某个零信任方案的架构图：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/7e2267cc7c73c164f095791c40be3a62.jpeg" alt="7e2267cc7c73c164f095791c40be3a62.jpeg">某厂商零信任安全架构</p><p>图中，单包认证（SPA）就是一道防线，</p><p>SDP控制器和SDP可信网关是二道防线，对用户的行为和终端的安全情况进行分析，并据此动态调整用户可访问的资源和权限。</p><p>再往右，就进入企业的内部，这里是三道防线，发挥作用的是企业的身份认证和权限管理（IAM），以及企业内部各种访问控制。</p><p>客户端上的防病毒软件，终端安全软件，是第四道防线，主机上的EDR也属于这道防线。</p><p>最后，第五道防线在人脑之中。</p><p>文｜卫剑钒</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/vigor2323/article/details/126552784&quot;&gt;https://blog.csdn.net/vigor2323/article/details/126552784&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;</summary>
      
    
    
    
    <category term="安全" scheme="http://zhangyu.info/categories/%E5%AE%89%E5%85%A8/"/>
    
    
    <category term="安全" scheme="http://zhangyu.info/tags/%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>云原生到底是个啥</title>
    <link href="http://zhangyu.info/2023/01/03/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%88%B0%E5%BA%95%E6%98%AF%E4%B8%AA%E5%95%A5/"/>
    <id>http://zhangyu.info/2023/01/03/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%88%B0%E5%BA%95%E6%98%AF%E4%B8%AA%E5%95%A5/</id>
    <published>2023-01-02T16:00:00.000Z</published>
    <updated>2023-01-03T13:45:35.405Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/vigor2323/article/details/128397832">吊炸天的云原生，到底是个啥_vigor2323的博客-CSDN博客</a></p><blockquote><p><a href="https://so.csdn.net/so/search?q=%E4%BA%91%E5%8E%9F%E7%94%9F&spm=1001.2101.3001.7020">云原生</a>技术里有很多技术、概念和术语，不了解的人，往往弄不清楚而一头雾水，这些概念都是啥，之间是什么关系？</p><p>本文要说的就是这些。</p><p>本文更多是科普和扫盲，无意面面俱到，也无意深入细节。 本文适合一定IT基础的人阅读，完全的小白和门外汉，可能是看不懂的。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/d5325dae8b39ec9bb02151a6a6fefc34.png" alt="d5325dae8b39ec9bb02151a6a6fefc34.png">完全看不懂的云原生</p><h2 id="云计算？云原生？"><a href="#云计算？云原生？" class="headerlink" title="云计算？云原生？"></a>云计算？云原生？</h2><p><code>云原生</code>就是“云+原生”（cloud + native）。一般而言，“<code>云</code>”更关注<a href="https://so.csdn.net/so/search?q=IaaS&spm=1001.2101.3001.7020">IaaS</a>，也就是基础设施层面（如计算、存储、网络）；“<code>原生</code>”更关注PaaS层面（如容器、微服务）。<strong>之所以叫“原生”，是因为它一生下来是给云用的，可谓是生在云里，长在云里。</strong></p><p>一位学者可能会说：“云计算是一种灵活提供基础IT资源的架构，云原生是一种在云计算上创建和运行应用程序的方法。”这话没有什么错，但也没有什么用，因为太抽象了。</p><p>在词汇使用上，据我观察，“云计算”和“云原生”基本上已经混为一谈了，我从来没有见过一个人说“云原生”的时候，另一个人站出来说“不对，这个是云计算”，反之亦然。</p><p>唯一的区别是：<strong>人们以前爱说“云计算”，现在爱说“云原生”。</strong></p><p>毕竟，新词总是高大上一点嘛。</p><p>所以，这块不要太纠结。</p><h2 id="云原生带来什么好处"><a href="#云原生带来什么好处" class="headerlink" title="云原生带来什么好处"></a>云原生带来什么好处</h2><p>其实这等同一个问题：为什么要上云。</p><p>好处有很多，<code>我本人</code>觉得最重要的有3点：</p><p><strong>7个字：隔离、弹性、自动化。</strong></p><p>1、**<code>隔离</code><strong>：在传统架构中，一个<a href="https://so.csdn.net/so/search?q=%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE&spm=1001.2101.3001.7020">网络配置</a>错误可能导致整个DC故障，一个模块出问题可能会导致整个应用系统故障。而且往往很难定位和隔离。云原生通过VPC、容器、微服务这些能力，把网络、操作系统、应用系统以<code>虚拟</code>或拆分的方式隔离开来，做到互不影响。</strong>一个部分的运行、变更或故障，不会影响其他部分，这就安全多了。**</p><p>2、**<code>弹性</code><strong>：应用系统在服务能力紧张时，需要扩容，比如增加机器的内存和CPU，或是部署新的实例并做负载均衡，在传统环境下，这需要一定的工作量，尤其是需要运维人员的安装和配置。</strong>云原生在一开始设计时，就考虑了如何更方便、更快捷、更安全地扩容**，比如虚机、容器的快速生成，自动地扩容和负载均衡。这样，以前是几个小时的事，现在稍稍动动手指就可以了，几分钟或者更少的时间搞定。</p><p>3、**<code>自动化</code><strong>：不管是部署还是变更、维护，如果一项工作涉及多个步骤，需要多项配置，甚至需要多个团队配合，那就会很繁琐，很复杂，对使用者的要求就会很高，出错的概率就会变大。</strong>如果只需一条指令、一个按键就能完成相关工作，那就是高度的自动化。**云原生的很多设计，就是以尽可能少的指令，完成尽可能复杂的操作。</p><p>自动化通过什么方式呈现给用户？一是<code>图形化界面</code>，让各类用户（平台租户、运营人员、运维人员、开发人员）都可以简单上手操作，比如租户（就是客户）点点鼠标就能申请一台虚机或是一台网关；二是<code>命令行界面</code>，让喜欢命令行的人可以直接或者写脚本调用；三是<code>API</code>，让程序员可以写程序任意编排操作。这样，各种不同技能基础的人，都能够尽自己能力实现尽可能的自动化。</p><p><strong>云原生的本质，就是IT全过程的软件化，也即“软件定义everything”在IT行业得以实现，而且是规模化和自动化的实现。</strong>原先冗长、复杂、颇费时费力的技术工作和体力活，现在可以轻轻松松搞定。</p><p>说这么多，现在略略见识一下：</p><pre><code>kubectl create deployment nginx --image=nginx --replicas=2kubectl set image deployment/nginx nginx=nginx:latest</code></pre><p>以上是两条kubernetes命令，其中，第一条命令部署两个nginx容器，第二条命令则让它们更新成一个最新的镜像版本。</p><p>看，这多么简单。</p><h2 id="云原生的基础知识"><a href="#云原生的基础知识" class="headerlink" title="云原生的基础知识"></a>云原生的基础知识</h2><p>考虑扫盲性质，现在说一点最基础的东西。</p><p>1、<code>虚机</code>：虚机是在物理服务器之上虚拟出来的具有完整功能的计算机。人们可以通过云平台创建虚机并安装操作系统，对其扩容，并在不停机的情况下将其迁移到另一台物理机上。</p><p>2、<code>裸金属</code>：裸金属即云纳管的物理机。裸金属不参与虚拟化，不提供虚机，但一样可以被云管理，可以被云自动化地分配、回收和管理。</p><p>3、<code>存储</code>：云可以提供块存储（如IPSAN）、文件存储（如NAS）、对象存储（OBS）。并且都提供界面、命令行和API给用户，让用户可以非常便利的使用和管理存储。通过对存储的资源池化和虚拟化，抹平了不同设备的差异，用户不再需要学习具体的存储设备知识、指令和配置方法。 </p><blockquote><p>比如在openstack中，用如下命令创建一个叫my_volume的卷，大小为10G，然后通过命令将这个创建好的卷连接到虚拟服务器my_server上。</p></blockquote><pre><code>openstack volume create --size 10 my_volumeopenstack server add volume myserver my_volume</code></pre><blockquote><p>看，这多么简单！作为一个完全不懂存储的人，我也可以轻而易举做到。</p></blockquote><p><strong>可以说，云的用户，就是在抽象层或者说逻辑层工作，底层细节完全可以不了解。</strong></p><p>4、<code>网络</code>：云提供虚拟的网络，用户并不用实际购买和独占网络设备，就可以在云里构建出一个个互相隔离的虚拟网络分区，组织他的多台虚机。这通过创建虚拟私有网络（VPC）、虚拟子网、虚拟路由器、虚拟NAT网关等来实现。用户不再需要和底层的网络设备打交道，用户只需要在云平台里“创建”和“配置”即可。</p><p>5、<code>容器</code>：容器可视为轻量级的虚拟机，它把应用“集装箱”化，应用程序和自己需要的<code>依赖</code>（Depends）打包在一起，自成一体。容器可以在各种操作系统中部署，不受具体宿主机影响。比起虚机，它更轻量，更方便、可以秒级启动。</p><p>以上这些是最基本的概念，相对靠基础设施一些，再往上走，就会遇到更“云原生”一些的概念：<code>微服务</code>、<code>服务网格</code>、<code>函数计算</code>、<code>DevOps</code>等，这些更靠近开发一些。</p><p>下面，我们继续，部分概念会再次说起。</p><h2 id="云原生中最重要的概念"><a href="#云原生中最重要的概念" class="headerlink" title="云原生中最重要的概念"></a>云原生中最重要的概念</h2><p>搞明白下面这些概念及其关系，你就心里有底了。</p><h3 id="1、虚机"><a href="#1、虚机" class="headerlink" title="1、虚机"></a>1、虚机</h3><p>虚机（<code>VM</code>，Virtual Machine，或称虚拟机 ）是在一台物理机（又称<code>宿主机</code>）上虚拟出来的计算机，目的是提高计算机硬件资源的利用率。这通过物理机上安装VMM（Virtual Machine Manager，虚拟机管理器）来实现。VMM给虚机分配调度相应的资源（内存、CPU、网络、磁盘等），加载虚机的操作系统，并调度给虚机最终所需的物理资源。大体而言，一台物理机可以虚拟出10台虚拟机。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/3c8763c879df3001805cf53ae7d944e6.png" alt="3c8763c879df3001805cf53ae7d944e6.png">虚机、VMM、物理机关系示意图</p><p>和容器相比，虚机还是有些笨重的，由于<code>虚机镜像</code>包含了整个操作系统，所以通常有几个GB大小。虚机启动时间通常是1分钟或几分钟。</p><blockquote><p><code>虚机镜像</code>是包含一台计算机的操作系统、安装的软件、数据和配置等信息的文件。镜像文件通常被用来作为虚拟机的模板，以便在需要时快速地创建多台相同内容的虚拟机。</p></blockquote><p>正是因为虚机还不够敏捷便利，速度也不够快，所以才产生了容器技术。</p><h3 id="2、容器"><a href="#2、容器" class="headerlink" title="2、容器"></a>2、容器</h3><p>在一个操作系统中，通过进程隔离、内存隔离、文件隔离、用户隔离、网络隔离等技术，形成一个个互相隔离的运行空间，每个空间里运行着应用程序和其所依赖的程序及库，这就是容器。</p><p>这样，<strong>多个容器共享同一个操作系统，但又互相隔离。</strong>容器通常不大，可以秒级启动，非常迅捷。</p><p><strong>容器实现了完全的可移植性</strong>，在支持容器的任何操作系统或环境上都可以兼容运行。因为容器里的软件和所需要的库依赖是封装好的，和所在宿主机的库是互相隔离的，不需要像以前那样，要在宿主机上做各种安装和适配。</p><p>在Linux操作系统中，早有通过命名空间（namespace）和控制组（control group）实现应用程序隔离的方法，使得一个或多个进程的CPU，内存，磁盘I / O和网络使用可以隔离开来互不影响，此即Linux容器（LXC）技术。但对用户而言，LXC并不易用。<strong>Docker把这些较为复杂的容器功能封装起来，形成对用户友好的操作命令或图形界面，才使得容器流行起来。</strong></p><h3 id="3、容器编排"><a href="#3、容器编排" class="headerlink" title="3、容器编排"></a>3、容器编排</h3><p>在大型系统中，需要大量的容器同时运行，直接管理一个个容器有点麻烦，如果能以更优雅更自动化的方法就更好了，这就出现了<code>容器编排</code>工具，有好几种容器编排工具，但是毫无疑问，Kubernetes（简称k8s）这些年最流行的容器编排工具。</p><blockquote><p>所谓<code>编排</code>（orchestration），就是统揽全局式的规划、组织、部署、管理等，把众多复杂的元素管理地井然有序，达到管理者所指定和预期的目标。</p></blockquote><p>k8s提供了许多强大的功能，例如部署容器、自动扩容、负载均衡、应用更新、故障恢复和容器监控等。<strong>总之，它能让用户更轻松、更便利地部署、调度和监控容器。</strong>用户可以通过描述性的文件，描述k8s应部署容器的规格、个数和关系，指定服务端口，将多个容器组织成一个应用，并能根据容器的负载情况自动地扩展容器的数量。</p><p>比如下面两句话，就能将nginx容器扩容到5个。</p><pre><code>kubectl scale deployment web-server --replicas=5kubectl rollout restart deployment/web-server</code></pre><h3 id="4、VPC"><a href="#4、VPC" class="headerlink" title="4、VPC"></a>4、VPC</h3><p>VPC（Virtual Private Cloud，虚拟私有云）是在云中构建出来的一个独立的、隔离的虚拟网络环境，一朵云中，可以有多个VPC。</p><p>虽然名字里带个“云”字，但人们更喜欢称之为“虚拟私有网”，因为它更多的特性是网，然后才是其上的虚机、容器等。</p><p>用户可以在VPC中自主规划 IP 地址，创建子网，并使用虚拟交换机vSwitch、虚拟路由器vRouter、虚拟负载均衡vLB等网络组件，还能通过网络ACL、安全组、虚拟防火墙vFW等方式，实现网络内虚机的隔离保护。</p><p>比起虚机和容器，虚拟网络会更让人难以理解一些，如果想快速扫盲，见我下一篇文章《让人懵懂的云网络，里面原来是这些》。</p><h3 id="5、微服务（Microservices）"><a href="#5、微服务（Microservices）" class="headerlink" title="5、微服务（Microservices）"></a>5、微服务（Microservices）</h3><p>微服务是一种架构，<strong>在这种架构中，把原先应用系统中的各个功能模块独立出来，形成一个个服务，跑在不同的虚机或容器中，然后用标准化的方法互相调用。</strong>这些服务原先是耦合在一台机器里的，现在都独立出来了，人们也就能独立地开发、部署和管理它们了。</p><p>微服务架构的目标是让每个服务都尽可能简单、单一，每个服务只执行特定的业务逻辑，并且具备良好的横向扩展能力。各服务之间通过简单、轻量的通信协议（如REST、gRPC等）进行通信。</p><p>微服务的好处是，<code>一、便于隔离</code>，一个服务坏了也不会影响其他服务，不像以前都在一个机器里，一坏就感染一片；<code>二、便于扩容</code>，一个服务如果形成性能瓶颈，就对那个服务扩容，多弄几个容器运行它。不像以前那样，要对整个应用系统扩容。<code>三、便于维护</code>，每个服务都可以独立地开发、部署、运维，一个服务只由一个小团队专门负责。在另一个层面上讲，小团队的管理，也显然要比大团队容易。</p><p>在微服务架构中，常遇到两个概念：<code>API网关</code>和<code>服务网格</code>。</p><p><code>API网关</code>提供集中式的服务请求处理，集成了反向代理、负载均衡、SSL卸载、身份认证、限流熔断、超时重试、流量监控、日志统计等功能，适合处理来自外部的流量（南北向）。在客户端和后台服务之间可以存在一个或多个功能不同的API网关。最受欢迎的网关代理是Nginx、HAProxy和Envoy。</p><p>对于系统内部复杂的服务间调用（东西向），为了避免瓶颈，还是以分布式的方法通信比较好，这就是近年来比较火的<code>服务网格</code>。</p><h3 id="6、服务网格（Service-Mesh）"><a href="#6、服务网格（Service-Mesh）" class="headerlink" title="6、服务网格（Service Mesh）"></a>6、服务网格（Service Mesh）</h3><p>由于服务总是要处理请求，遇到网络不好的时候，就需要重连或做超时处理，这样，每个服务都需要实现请求重试、超时处理、断路器等机制。如果每个服务都写这样的机制，就有点不经济。如果服务还是用不同语言实现的，这些部分也得用不同语言实现，就很不经济了。</p><p><code>服务网格</code>的想法是将这种通用的功能从每个服务中抽出来，最早的做法是给服务提供SDK(便于服务集成通用功能)，后来逐渐演变为由独立的代理来完成通用功能：在每个服务旁边运行一个代理（<code>sidecar</code>），sidecar作为一个单独的容器与应用容器放在k8s的同一个<code>Pod</code>中（Pod是k8s调度的最小单元，里面可以有1个或多个容器）运行，它们共享相同的网络。sidecar处理流入或流出的请求和响应流量，实现路由、安全和监控等功能。</p><p>比如：Istio服务网格在服务的每个应用容器旁运行Envoy代理作为sidecar，所有sidecar都受微服务控制平面管理。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/67069c9d624772b236c2b06923197268.png" alt="67069c9d624772b236c2b06923197268.png">由Sidecar组成的服务网格</p><p>注：Sidecar是一种形象的比喻，原意是摩托车旁的边车。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/9b2cbb5857daaa4765acc772e0cb4122.jpeg" alt="9b2cbb5857daaa4765acc772e0cb4122.jpeg">真正的sidecar</p><p>这种分离让开发人员能够很集中精力在业务上，而真正不再考虑非业务功能，所有服务所共需的通用能力，都放在sidecar里来做。</p><p>就好像开车的就专心开车，通信和作战交给边车上的队友。</p><h3 id="7、无服务器（serverless）"><a href="#7、无服务器（serverless）" class="headerlink" title="7、无服务器（serverless）"></a>7、无服务器（serverless）</h3><p>“<code>无服务器</code>”并非真的没有服务器，而是说用户（比如开发人员）完全不用关心服务器的事，不用申请服务器、存储和网络。用户只关心自己的程序，所有和资源相关的琐事都由云提供商处理。<strong>代码执行时，云提供商会启动资源，代码执行结束时，释放资源。用户只为使用时间付费，而不为闲置容量付费。</strong></p><p>这提法更像是一个理念，更像是一个产品营销话术，而不像一项新技术，因为“无服务器”的背后无非还是虚机、容器、微服务这些，只是用户可以不管这些，这些都由云服务商提供，用户把精力放在自己的程序上就好。</p><p><code>函数即服务</code>（Function as a Service，<code>FaaS</code>）是最常被提起的无服务器架构，虽然它只是serverless的一种。使用<code>FaaS</code>，用户将函数放到云上（将代码作为zip文件或容器镜像上传），在需要的时候，通过HTTP调用即可，用户只需为函数的执行时间付费，函数所在容器，以及所需的RunTime，都由云服务商调度和管理。常见的FaaS产品AWS Lambada、Azure Functions和谷歌的Cloud Functions。</p><p>显然，这种一会运行一会关闭的函数，只适合那种一过性的运算，那种很简单的、无状态的运算，比如简单计算、更新记录、发送消息、写入数据这种。</p><p>除了FaaS，还有别的serverless，比如serverless DB，它不需要用户手动维护和配置服务器资源，而是自动扩展和伸缩。</p><p><strong>总之，只要是用户原先要考虑服务器而现在不用考虑服务器的服务，都是Serverless。</strong></p><h3 id="8、基础设施即代码（IaC）"><a href="#8、基础设施即代码（IaC）" class="headerlink" title="8、基础设施即代码（IaC）"></a>8、基础设施即代码（IaC）</h3><p>程序员大多是不太爱碰硬件的，他们喜欢沉溺在软件的思维里。当他们不得不接触和管理硬件的时候（比如被轮岗或是种种原因），他们就决心用软件的方式来管理这些硬件。</p><p><code>基础设施即代码</code>（Infrastructure as Code，IaC）用编程语言描述他们要运维和管理的基础设施（服务器、网络设备、存储设备等硬件），这样，部署和管理笨重的硬件设备，无非也就是在电脑面前敲几句代码而已，不再需要像以前那样吭哧吭哧地猛干了。</p><p>这是硬件维护人员多年以来梦寐以求的自动化。现在，人们只是写一个脚本，用脚本去部署服务器，并配置各种网络、存储、负载均衡器等任何基础设施服务。然后，只是执行这个脚本，就可以在完全不同的AZ（AZ即可用区，后面会介绍）中部署一套高度一致的基础设施。以前，这样的任务需要数人、数周才能完成。现在，几个小时就可以完成。</p><p>基础设施即代码，换句话说，即，<code>软件定义基础设施</code>。</p><h3 id="9、DevOps"><a href="#9、DevOps" class="headerlink" title="9、DevOps"></a>9、DevOps</h3><p>DevOps（它是“Development”和“Operations”的缩写），就是从开发到运维，整个过程自动化。自动化地编译、测试、构建容器、上传容器、部署、发布、监控、告警等，如果发现了Bug或问题，团队能够迅速迭代这一过程，修改代码，然后又是自动化的编译、测试、部署、发布等，<strong>一天可以来上这么10次！</strong></p><blockquote><p>在2009年O’Reilly Velocity大会上两个Flickr员工做了题为《10+ Deploys Per Day: Dev and Ops Cooperation at Flickr》的演讲1，引起了轰动，随后得以蓬勃发展。</p></blockquote><p>当然，这需要多种工具和多个脚本的有机衔接。</p><p><strong>以前，这一过程冗长，开发团队和运维团队的配合并不容易。</strong>因为他们有着不同的部门和领导，有着不同的文化，他们的目标和利益并不一致。从开发到上线，这个过程中，有着各种流程和审批，1天能有10次发布？开玩笑，10天能有1次就不错了。现在可好，全都自动化了，一个小团队，从开发到发布，全都干了，还很快，运维人员几乎都不用动手，或者几乎都不需要出现。</p><p>本质上，DevOps是搞开发的人终于帮助搞运维的人，把运维那摊子事给自动化了（搞运维的人，通常不太擅长写代码）。我想，这肯定是哪个公司，非要逼得开发人员去搞运维，所以他们没办法，只能自己拿起看家本事造福自己了。开发那一段的自动化，早在近二十年前，他们搞<code>敏捷开发</code>的时候就搞差不多了，他们早早就搞了<code>CI</code>（持续集成），然后又搞了<code>CD</code>（持续部署），这十年，他们通过前面说的容器、微服务、k8s等技术，再加上一些新方法、新工具，把运维这一段也搞定了，他们终于打通了任督二脉。</p><p>崇拜DevOps的人会说远远不止这些，是的，他们往DevOps里装了种种思想、理念和方法论，以至于人们似乎已经忘了它本来想致力于什么。我以前写过一篇文章讲如何从高层把握DevOps2的实质，有兴趣可以看看。</p><p>下面这张图有助于你从全貌上概览一下，这只是一种框架，引自3，篇幅有限，此处不细解释。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/6735196a649e27addd015f3b455fe434.png" alt="6735196a649e27addd015f3b455fe434.png">一种DevOps工作模型</p><blockquote><p><code>滚动发布</code>是一种发布软件更新的方法。软件新版本先在小范围内发布，没有什么问题的话，再慢慢扩展到更大的范围。这样，一开始如果有问题，受影响的也只是少数用户。类似概念和叫法有<code>灰度发布</code>、<code>金丝雀发布</code>。以前矿工下矿前，为防范探洞里有有毒气体，会先放一只金丝雀进去，看金丝雀能否活下来，金丝雀发布得名于此。</p></blockquote><h2 id="更深一步：云计算背后的东西"><a href="#更深一步：云计算背后的东西" class="headerlink" title="更深一步：云计算背后的东西"></a>更深一步：云计算背后的东西</h2><p>下面的内容有点偏底层技术了。</p><p>如果你不想了解更多，跳过这章就好。</p><h3 id="1、云平台和云管平台"><a href="#1、云平台和云管平台" class="headerlink" title="1、云平台和云管平台"></a>1、云平台和云管平台</h3><p>当“云管平台”（Cloud Management Platform）这个说法在n年前第一次介绍给我时，我当时还真有点懵。</p><p>我心想，云平台（Cloud Platform）不就是Openstack这些东西吗，怎么又冒出来一个“云管”平台？</p><p>后来才弄明白，原来还是有点不同的。</p><p><code>云平台</code>更多是指云计算平台，偏技术层面，提供计算、存储、数据库、网络、安全等基础设施服务，供客户在云上部署和运行应用程序。比如OpenStack提供IaaS，Docker和Kubernetes提供PaaS等，这些都属于云平台。</p><p><code>云管平台</code>从名称上就能看出来，侧重于管理，侧重于多云、混合云、异构云场景下的统一管理。它给用户提供统一的运营控制台和运维控制台。所谓运营控制台，就是为用户提供登录、资源开通、使用、配置等功能，并且达到“<code>自服务</code>”的水平；所谓运维控制台，就是让运维人员可以对物理资源状况进行监控和管理。</p><blockquote><p>所谓“<code>自服务</code>”，是指客户可以通过平台界面或API，自行创建和管理虚拟机、存储空间、网络资源和其他云服务，而无需其他专业人员参与，自己点点鼠标，想要的东西就出现了，就能用了。</p></blockquote><p>两者之间有一个明显的不同是：<strong>云管平台可以管理多云以及一朵云中的多个Region，而云平台通常只能管理本Region内的资源。</strong></p><p>在我看来，云平台更偏技术一些，更靠近基础设施一些，云管平台则在云平台的基础上又做了一次封装，以更简便易用的方式将云服务提供给用户。</p><p>不过，正如“云计算”和“云原生”这两个词已经被人们混用，“云平台”和“云管平台”往往也被混用起来了，你听他说“云平台”，其实他很大概率是在说“云管平台”。</p><h3 id="2、地域（Region）"><a href="#2、地域（Region）" class="headerlink" title="2、地域（Region）"></a>2、地域（Region）</h3><p><code>Region</code>即一朵云内某个物理区域中基础设施服务的集合。不同Region之间的物理资源（计算、存储、网络）是完全隔离不共享的。</p><p><strong>一朵云里可以有多个Region，每个Region可位于不同的城市的DC（数据中心）中，也可以位于同一个城市的不同DC中。</strong>不同DC能否放在一个Region中，关键看时延，如果时延超过 2ms，就应该在不同的Region中，因为同一Region内对时延有较高要求。</p><p>不同Region之间的时延也应该在100ms之内4，因为云管平台对Region的命令下发和信息上报时延也有要求。</p><p>不同Region之间的通信使用“<code>云连接</code>”，通过“<code>专线网关</code>”实现，这个网关可以是软件的，也可以是硬件交换机（又称专线交换机），这块见我下篇关于云网络的文章。</p><p>每个Region中包含数个独立的，物理分隔开的<code>AZ</code>，每个AZ可以有独立的供电，制冷。</p><h3 id="3、可用区（AZ）"><a href="#3、可用区（AZ）" class="headerlink" title="3、可用区（AZ）"></a>3、可用区（AZ）</h3><p><strong><code>可用区</code>（Available Zone，AZ）可以简单理解（虽然并非总是如此）为机房及其内的计算、存储和网络资源。</strong>一个Region内有多个机房，每个机房就是一个AZ。不同AZ使用不同的电力和制冷，使用独立的计算、存储和网络资源（但网络是互通的）。这样，即便一个AZ不可用了，另一个还是可用的。AZ内通信时延要小于0.25ms。</p><p><code>AZ</code>中的A就是可用（Available）的意思，一般而言，不同AZ使用独立的电力、制冷、机房模块等基础环境。应用系统如果要实现高可用，应该同时部署多份在不同的可用区内，这样，一个AZ坏了，还有另一个AZ可以提供服务。</p><p>裸金属和不同CPU架构的物理机，通常部署在不同的AZ；同一个AZ内，又可以根据不同性能属性划分不同的主机组（host aggregate），便于管理员进一步按组分发虚机5。不同主机组提供不同的主机资源，但存储和网络资源是共享的。</p><p>VPC的子网是可以跨AZ的。比如在同一个子网中，VM1在AZ1，VM2在AZ2，他们可以同时承担Web服务器功能，这样，即便整个AZ1不可用了，VM2仍然能够提供服务。</p><h3 id="4、SDN"><a href="#4、SDN" class="headerlink" title="4、SDN"></a>4、SDN</h3><p>传统的网络设备是分布式和去中心化的，每台设备可以通过自主学习和人工配置，知道如何转发数据包，而不需要一个集中式的控制设备。SDN则像各个网络设备的软件大脑，让各网络设备不再用自主学习和人工配置，而是由大脑下达命令，告诉各设备应该怎么转发数据包。</p><p><strong><code>SDN</code>（Software Defined Network）就是<code>软件定义网络</code>，那个大脑被称为SDN控制器。</strong></p><p>SDN为什么要把原先的分布式运行改为集中控制呢？因为如果每个网络设备都要人工配置和管理，就会太麻烦，容易出错，不易于统一集中管控。如果能力足够，那就不如一起管了算了。</p><p>在虚拟网络里，像虚拟交换机、虚拟路由器、虚拟网关等等，这些虚拟网络设备，都受SDN统一管理。</p><h3 id="5、网络资源池"><a href="#5、网络资源池" class="headerlink" title="5、网络资源池"></a>5、网络资源池</h3><p>网络资源池由一组网络硬件设备（如交换机、路由器等）构成，为上层的虚拟网络、虚机、存储等提供底层的通信功能。</p><p><strong>说起来有点复杂，大体而言，应用系统在虚拟网络（<code>Overlay</code>）上跑，虚拟网络基于隧道技术在物理网络（<code>Underlay</code>）上跑。</strong></p><p>从技术上讲，Overlay的二层数据包封装在Underlay的三层报文中传输，到达目的地之后再解封装得到Overlay的二层报文。实际上，这是一种“L2 over L3”的隧道封装技术，目前主流的隧道封装协议为VxLAN。</p><p>如果Overlay的网络数据封装和路由都是软件实现的，那就是<code>软件SDN</code>（又称<code>主机Overlay</code>），如果是硬件网络设备做的，那就是<code>硬件SDN</code>（又称<code>网络Overlay</code>）。</p><p>一个Region需要一套网络资源池，提供该Region内共用（多AZ、多VPC共用）的底层数据包转发，该资源池是由跨机房模块（也即跨AZ）的多组Leaf+Spine模块组成，跨机房模块的网络交换通过一组Core节点(Super Spine)交换机实现。</p><p>在主机Overlay这种主流场景下，网络资源池中的网络设备并不关心上层是哪个VM要和哪个VM通信，它们只是忠实地转发数据包而已，它们不会去关心隧道里的虚拟网络通信。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/39142020e8f12fe9bc92104f9351e2f3.png" alt="39142020e8f12fe9bc92104f9351e2f3.png">通过隧道，在物理网络上构建虚拟网络</p><p>上图使用两台Super Spine，四台Spine，八台Leaf，并通过在不同机房部署，提供了一套网络资源池，供多个AZ共同使用。这样，虽然VPC子网和虚机可能在不同AZ和机房内，但通过VxLAN隧道，它们之间的通信就像在一个交换机下面的二层通信。</p><h2 id="那么，云原生是什么"><a href="#那么，云原生是什么" class="headerlink" title="那么，云原生是什么"></a>那么，云原生是什么</h2><p>看到现在，你大概知道云原生是什么了吧。</p><p><strong>整个IT被云化了，不管是搞开发的，还是搞运维的，都在使用云，依靠云，发展云。</strong></p><p>IT的一切，都尽可能用软件定义，都尽可能虚拟化，一切都是为了简单、自动、弹性、安全。</p><p>所有使用云的人，都只是点点鼠标，就可以完成以前很复杂的事。</p><p>IT在给其他行业搞数字化转型的同时，给自己搞了个数字化转型。</p><p>本质上，IT人终于把自己给解放了。</p><p>他们感叹说，**<code>云</code><strong>里</strong><code>原</code><strong>来才是我们</strong><code>生</code>**活应有的样子。</p><p>文｜卫剑钒</p><p>参考链接：</p><ol><li><p> 10+ Deploys Per Day: Dev and Ops Cooperation at Flickr(<a href="https://www.bilibili.com/video/av929343748/">https://www.bilibili.com/video/av929343748/</a>) </p></li><li><p> <a href="https://blog.csdn.net/vigor2323/article/details/128397832">如何从高层把握住DevOps的实质</a> </p></li><li><p> 云原生：运用容器、函数计算和数据构建下一代应用(<a href="https://e.jd.com/30613841.html">https://e.jd.com/30613841.html</a>) </p></li><li><p> 云Stack中Global、Region、AZ、资源池以及主机组 (<a href="https://bbs.huaweicloud.com/blogs/231197">https://bbs.huaweicloud.com/blogs/231197</a>) </p></li><li><p> openstack中region、az、host aggregate、cell 概念 (<a href="http://t.zoukankan.com/xingyun-p-4703325.html">http://t.zoukankan.com/xingyun-p-4703325.html</a>)</p></li></ol></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/vigor2323/article/details/128397832&quot;&gt;吊炸天的云原生，到底是个啥_vigor2323的博客-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;ht</summary>
      
    
    
    
    <category term="架构" scheme="http://zhangyu.info/categories/%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="架构" scheme="http://zhangyu.info/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>谁再问我Kafka-我把这43张图甩给他</title>
    <link href="http://zhangyu.info/2023/01/03/%E8%B0%81%E5%86%8D%E9%97%AE%E6%88%91Kafka-%E6%88%91%E6%8A%8A%E8%BF%9943%E5%BC%A0%E5%9B%BE%E7%94%A9%E7%BB%99%E4%BB%96/"/>
    <id>http://zhangyu.info/2023/01/03/%E8%B0%81%E5%86%8D%E9%97%AE%E6%88%91Kafka-%E6%88%91%E6%8A%8A%E8%BF%9943%E5%BC%A0%E5%9B%BE%E7%94%A9%E7%BB%99%E4%BB%96/</id>
    <published>2023-01-02T16:00:00.000Z</published>
    <updated>2023-04-18T02:51:16.641Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/mxt51220/article/details/128338358">https://blog.csdn.net/mxt51220/article/details/128338358</a></p><blockquote><p>从Kafka诞生的早期，我就对Kafka投入了很多的关注，虽然不敢说精通Kafka, 但也算是非常熟悉了。</p><p>平时在工作之中，几乎天天都在跟这玩意儿打交道，在面试的时候，也会经常聊一些Kafka相关的内容。</p><p>Kafka 是一个优秀的分布式消息中间件，许多系统中都会使用到 Kafka 来做消息通信。对分布式消息系统的了解和使用几乎成为一个开发人员必备的技能。</p><p>我写过很多Kafka的内容，也在不断优化迭代，今天来分享一篇硬核的文章。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/2accda1bd8fd53611f479ca5d538fc1c.png"></p><p>[思维导图] </p><h2 id="讲一讲分布式消息中间件"><a href="#讲一讲分布式消息中间件" class="headerlink" title="讲一讲分布式消息中间件"></a>讲一讲分布式消息中间件</h2><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><ul><li><p>  什么是分布式消息中间件？</p></li><li><p>  消息中间件的作用是什么？</p></li><li><p>  消息中间件的使用场景是什么？</p></li><li><p>  消息中间件选型？</p></li></ul><p><img src="https://img-blog.csdnimg.cn/img_convert/6f25a79580f6d6fba047f1a0789df3c5.png"></p><p> 消息队列</p><p>分布式消息是一种通信机制，和 RPC、HTTP、RMI 等不一样，消息中间件采用分布式中间代理的方式进行通信。如图所示，采用了消息中间件之后，上游业务系统发送消息，先存储在消息中间件，然后由消息中间件将消息分发到对应的业务模块应用（分布式生产者 - 消费者模式）。这种异步的方式，减少了服务之间的耦合程度。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/4c4304fecb05136c1c455570c6e6936b.png"></p><p> 架构</p><p><strong>定义消息中间件：</strong></p><ul><li><p>  利用高效可靠的消息传递机制进行平台无关的数据交流</p></li><li><p>  基于数据通信，来进行分布式系统的集成</p></li><li><p>  通过提供消息传递和消息排队模型，可以在分布式环境下扩展进程间的通信</p></li></ul><p>在系统架构中引用额外的组件，必然提高系统的架构复杂度和运维的难度，那么<strong>在系统中使用分布式消息中间件有什么优势呢？消息中间件在系统中起的作用又是什么呢？</strong></p><ul><li><p>  解耦</p></li><li><p>  冗余（存储）</p></li><li><p>  扩展性</p></li><li><p>  削峰</p></li><li><p>  可恢复性</p></li><li><p>  顺序保证</p></li><li><p>  缓冲</p></li><li><p>  异步通信</p></li></ul><p><strong>下面是常见的几种分布式消息系统的对比：</strong></p><p><img src="https://img-blog.csdnimg.cn/img_convert/bf09ad30eea76b1dde251878eab5f9df.jpeg"></p><p>选择</p><h3 id="答案关键字"><a href="#答案关键字" class="headerlink" title="答案关键字"></a>答案关键字</h3><ul><li><p>  什么是分布式消息中间件？通信，队列，分布式，生产消费者模式。</p></li><li><p>  消息中间件的作用是什么？解耦、峰值处理、异步通信、缓冲。</p></li><li><p>  消息中间件的使用场景是什么？异步通信，消息存储处理。</p></li><li><p>  消息中间件选型？语言，协议、HA、数据可靠性、性能、事务、生态、简易、推拉模式。</p></li></ul><h2 id="Kafka-基本概念和架构"><a href="#Kafka-基本概念和架构" class="headerlink" title="Kafka 基本概念和架构"></a>Kafka 基本概念和架构</h2><h3 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h3><ul><li><p>  简单讲下 Kafka 的架构？</p></li><li><p>  Kafka 是推模式还是拉模式，推拉的区别是什么？</p></li><li><p>  Kafka 如何广播消息？</p></li><li><p>  Kafka 的消息是否是有序的？</p></li><li><p>  Kafka 是否支持读写分离？</p></li><li><p>  Kafka 如何保证数据高可用？</p></li><li><p>  Kafka 中 zookeeper 的作用？</p></li><li><p>  是否支持事务？</p></li><li><p>  分区数是否可以减少？</p></li></ul><p><strong>Kafka 架构中的一般概念：</strong></p><p><img src="https://img-blog.csdnimg.cn/img_convert/76873cfb6e12565cbcf14fc4cab5145a.png"></p><p> 架构</p><ul><li><p>  Producer：生产者，也就是发送消息的一方。生产者负责创建消息，然后将其发送到 Kafka。</p></li><li><p>  Consumer：消费者，也就是接受消息的一方。消费者连接到 Kafka 上并接收消息，进而进行相应的业务逻辑处理。</p></li><li><p>  Consumer Group：一个消费者组可以包含一个或多个消费者。使用多分区 + 多消费者方式可以极大提高数据下游的处理速度，同一消费组中的消费者不会重复消费消息，同样的，不同消费组中的消费者消息消息时互不影响。Kafka 就是通过消费组的方式来实现消息 P2P 模式和广播模式。</p></li><li><p>  Broker：服务代理节点。Broker 是 Kafka 的服务节点，即 Kafka 的服务器。</p></li><li><p>  Topic：Kafka 中的消息以 Topic 为单位进行划分，生产者将消息发送到特定的 Topic，而消费者负责订阅 Topic 的消息并进行消费。</p></li><li><p>  Partition：Topic 是一个逻辑的概念，它可以细分为多个分区，每个分区只属于单个主题。同一个主题下不同分区包含的消息是不同的，分区在存储层面可以看作一个可追加的日志（Log）文件，消息在被追加到分区日志文件的时候都会分配一个特定的偏移量（offset）。</p></li><li><p>  Offset：offset 是消息在分区中的唯一标识，Kafka 通过它来保证消息在分区内的顺序性，不过 offset 并不跨越分区，也就是说，Kafka 保证的是分区有序性而不是主题有序性。</p></li><li><p>  Replication：副本，是 Kafka 保证数据高可用的方式，Kafka 同一 Partition 的数据可以在多 Broker 上存在多个副本，通常只有主副本对外提供读写服务，当主副本所在 broker 崩溃或发生网络一场，Kafka 会在 Controller 的管理下会重新选择新的 Leader 副本对外提供读写服务。</p></li><li><p>  Record：实际写入 Kafka 中并可以被读取的消息记录。每个 record 包含了 key、value 和 timestamp。</p></li></ul><p><strong>Kafka Topic Partitions Layout</strong><img src="https://img-blog.csdnimg.cn/img_convert/e5d78cc24540edca67c184740622d1b1.jpeg" alt="e5d78cc24540edca67c184740622d1b1.jpeg"></p><p>主题</p><p>Kafka 将 Topic 进行分区，分区可以并发读写。</p><p><strong>Kafka Consumer Offset</strong><img src="https://img-blog.csdnimg.cn/img_convert/5b53a5751eb845f1167d111d0c3b259c.png" alt="5b53a5751eb845f1167d111d0c3b259c.png"></p><p>consumer offset</p><h3 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h3><p><img src="https://img-blog.csdnimg.cn/img_convert/305b13f9493689531f0cef9d9f84fed6.png"></p><p>zookeeper</p><ul><li><p>  Broker 注册：Broker 是分布式部署并且之间相互独立，Zookeeper 用来管理注册到集群的所有 Broker 节点。</p></li><li><p>  Topic 注册：在 Kafka 中，同一个 Topic 的消息会被分成多个分区并将其分布在多个 Broker 上，这些分区信息及与 Broker 的对应关系也都是由 Zookeeper 在维护</p></li><li><p>  生产者负载均衡：由于同一个 Topic 消息会被分区并将其分布在多个 Broker 上，因此，生产者需要将消息合理地发送到这些分布式的 Broker 上。</p></li><li><p>  消费者负载均衡：与生产者类似，Kafka 中的消费者同样需要进行负载均衡来实现多个消费者合理地从对应的 Broker 服务器上接收消息，每个消费者分组包含若干消费者，每条消息都只会发送给分组中的一个消费者，不同的消费者分组消费自己特定的 Topic 下面的消息，互不干扰。</p></li></ul><h3 id="答案关键字-1"><a href="#答案关键字-1" class="headerlink" title="答案关键字"></a>答案关键字</h3><ul><li><p>简单讲下 Kafka 的架构？</p><blockquote><p>Producer、Consumer、Consumer Group、Topic、Partition</p></blockquote></li><li><p>Kafka 是推模式还是拉模式，推拉的区别是什么？</p><blockquote><p>Kafka Producer 向 Broker 发送消息使用 Push 模式，Consumer 消费采用的 Pull 模式。拉取模式，让 consumer 自己管理 offset，可以提供读取性能</p></blockquote></li><li><p>Kafka 如何广播消息？</p><blockquote><p>Consumer group</p></blockquote></li><li><p>Kafka 的消息是否是有序的？</p><blockquote><p>Topic 级别无序，Partition 有序</p></blockquote></li><li><p>Kafka 是否支持读写分离？</p><blockquote><p>不支持，只有 Leader 对外提供读写服务</p></blockquote></li><li><p>Kafka 如何保证数据高可用？</p><blockquote><p>副本，ack，HW</p></blockquote></li><li><p>Kafka 中 zookeeper 的作用？</p><blockquote><p>集群管理，元数据管理</p></blockquote></li><li><p>是否支持事务？</p><blockquote><p>0.11 后支持事务，可以实现”exactly once“</p></blockquote></li><li><p>分区数是否可以减少？</p><blockquote><p>不可以，会丢失数据</p></blockquote></li></ul><h2 id="Kafka-使用"><a href="#Kafka-使用" class="headerlink" title="Kafka 使用"></a>Kafka 使用</h2><h3 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h3><ul><li><p>  Kafka 有哪些命令行工具？你用过哪些？</p></li><li><p>  Kafka Producer 的执行过程？</p></li><li><p>  Kafka Producer 有哪些常见配置？</p></li><li><p>  如何让 Kafka 的消息有序？</p></li><li><p>  Producer 如何保证数据发送不丢失？</p></li><li><p>  如何提升 Producer 的性能？</p></li><li><p>  如果同一 group 下 consumer 的数量大于 part 的数量，kafka 如何处理？</p></li><li><p>  Kafka Consumer 是否是线程安全的？</p></li><li><p>  讲一下你使用 Kafka Consumer 消费消息时的线程模型，为何如此设计？</p></li><li><p>  Kafka Consumer 的常见配置？</p></li><li><p>  Consumer 什么时候会被踢出集群？</p></li><li><p>  当有 Consumer 加入或退出时，Kafka 会作何反应？</p></li><li><p>  什么是 Rebalance，何时会发生 Rebalance？</p></li></ul><h3 id="命令行工具"><a href="#命令行工具" class="headerlink" title="命令行工具"></a>命令行工具</h3><p>Kafka 的命令行工具在 Kafka 包的<code>/bin</code>目录下，主要包括服务和集群管理脚本，配置脚本，信息查看脚本，Topic 脚本，客户端脚本等。</p><ul><li><p>  kafka-configs.sh：配置管理脚本</p></li><li><p>  kafka-console-consumer.sh：kafka 消费者控制台</p></li><li><p>  kafka-console-producer.sh：kafka 生产者控制台</p></li><li><p>  kafka-consumer-groups.sh：kafka 消费者组相关信息</p></li><li><p>  kafka-delete-records.sh：删除低水位的日志文件</p></li><li><p>  kafka-log-dirs.sh：kafka 消息日志目录信息</p></li><li><p>  kafka-mirror-maker.sh：不同数据中心 kafka 集群复制工具</p></li><li><p>  kafka-preferred-replica-election.sh：触发 preferred replica 选举</p></li><li><p>  kafka-producer-perf-test.sh：kafka 生产者性能测试脚本</p></li><li><p>  kafka-reassign-partitions.sh：分区重分配脚本</p></li><li><p>  kafka-replica-verification.sh：复制进度验证脚本</p></li><li><p>  kafka-server-start.sh：启动 kafka 服务</p></li><li><p>  kafka-server-stop.sh：停止 kafka 服务</p></li><li><p>  kafka-topics.sh：topic 管理脚本</p></li><li><p>  kafka-verifiable-consumer.sh：可检验的 kafka 消费者</p></li><li><p>  kafka-verifiable-producer.sh：可检验的 kafka 生产者</p></li><li><p>  zookeeper-server-start.sh：启动 zk 服务</p></li><li><p>  zookeeper-server-stop.sh：停止 zk 服务</p></li><li><p>  zookeeper-shell.sh：zk 客户端</p></li></ul><p>我们通常可以使用<code>kafka-console-consumer.sh</code>和<code>kafka-console-producer.sh</code>脚本来测试 Kafka 生产和消费，<code>kafka-consumer-groups.sh</code>可以查看和管理集群中的 Topic，<code>kafka-topics.sh</code>通常用于查看 Kafka 的消费组情况。</p><h3 id="Kafka-Producer"><a href="#Kafka-Producer" class="headerlink" title="Kafka Producer"></a>Kafka Producer</h3><p>Kafka producer 的正常生产逻辑包含以下几个步骤：</p><ol><li><p> 配置生产者客户端参数常见生产者实例。</p></li><li><p> 构建待发送的消息。</p></li><li><p> 发送消息。</p></li><li><p> 关闭生产者实例。</p></li></ol><p>Producer 发送消息的过程如下图所示，需要经过<code>拦截器</code>，<code>序列化器</code>和<code>分区器</code>，最终由<code>累加器</code>批量发送至 Broker。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/44b01d79940b297ff8f6fbb824b289f6.png"></p><p> producer</p><p>Kafka Producer 需要以下必要参数：</p><ul><li><p>  bootstrap.server：指定 Kafka 的 Broker 的地址</p></li><li><p>  key.serializer：key 序列化器</p></li><li><p>  value.serializer：value 序列化器</p></li></ul><p>常见参数：</p><ul><li><p>batch.num.messages</p><blockquote><p>默认值：200，每次批量消息的数量，只对 asyc 起作用。</p></blockquote></li><li><p>request.required.acks</p><blockquote><p>默认值：0，0 表示 producer 毋须等待 leader 的确认，1 代表需要 leader 确认写入它的本地 log 并立即确认，-1 代表所有的备份都完成后确认。只对 async 模式起作用，这个参数的调整是数据不丢失和发送效率的 tradeoff，如果对数据丢失不敏感而在乎效率的场景可以考虑设置为 0，这样可以大大提高 producer 发送数据的效率。</p></blockquote></li><li><p>request.timeout.ms</p><blockquote><p>默认值：10000，确认超时时间。</p></blockquote></li><li><p>partitioner.class</p><blockquote><p>默认值：kafka.producer.DefaultPartitioner，必须实现 kafka.producer.Partitioner，根据 Key 提供一个分区策略。<em>有时候我们需要相同类型的消息必须顺序处理，这样我们就必须自定义分配策略，从而将相同类型的数据分配到同一个分区中。</em></p></blockquote></li><li><p>producer.type</p><blockquote><p>默认值：sync，指定消息发送是同步还是异步。异步 asyc 成批发送用 kafka.producer.AyncProducer， 同步 sync 用 kafka.producer.SyncProducer。同步和异步发送也会影响消息生产的效率。</p></blockquote></li><li><p>compression.topic</p><blockquote><p>默认值：none，消息压缩，默认不压缩。其余压缩方式还有，”gzip”、”snappy”和”lz4”。对消息的压缩可以极大地减少网络传输量、降低网络 IO，从而提高整体性能。</p></blockquote></li><li><p>compressed.topics</p><blockquote><p>默认值：null，在设置了压缩的情况下，可以指定特定的 topic 压缩，未指定则全部压缩。</p></blockquote></li><li><p>message.send.max.retries</p><blockquote><p>默认值：3，消息发送最大尝试次数。</p></blockquote></li><li><p>retry.backoff.ms</p><blockquote><p>默认值：300，每次尝试增加的额外的间隔时间。</p></blockquote></li><li><p>topic.metadata.refresh.interval.ms</p><blockquote><p>默认值：600000，定期的获取元数据的时间。当分区丢失，leader 不可用时 producer 也会主动获取元数据，如果为 0，则每次发送完消息就获取元数据，不推荐。如果为负值，则只有在失败的情况下获取元数据。</p></blockquote></li><li><p>queue.buffering.max.ms</p><blockquote><p>默认值：5000，在 producer queue 的缓存的数据最大时间，仅仅 for asyc。</p></blockquote></li><li><p>queue.buffering.max.message</p><blockquote><p>默认值：10000，producer 缓存的消息的最大数量，仅仅 for asyc。</p></blockquote></li><li><p>queue.enqueue.timeout.ms</p><blockquote><p>默认值：-1，0 当 queue 满时丢掉，负值是 queue 满时 block, 正值是 queue 满时 block 相应的时间，仅仅 for asyc。</p></blockquote></li></ul><h3 id="Kafka-Consumer"><a href="#Kafka-Consumer" class="headerlink" title="Kafka Consumer"></a>Kafka Consumer</h3><p>Kafka 有消费组的概念，每个消费者只能消费所分配到的分区的消息，每一个分区只能被一个消费组中的一个消费者所消费，所以同一个消费组中消费者的数量如果超过了分区的数量，将会出现有些消费者分配不到消费的分区。消费组与消费者关系如下图所示：</p><p>consumer group</p><p>Kafka Consumer Client 消费消息通常包含以下步骤：</p><ol><li><p> 配置客户端，创建消费者</p></li><li><p> 订阅主题</p></li><li><p> 拉去消息并消费</p></li><li><p> 提交消费位移</p></li><li><p> 关闭消费者实例</p></li></ol><p><img src="https://img-blog.csdnimg.cn/img_convert/facc5036b40e2d3e55fe8eadf2b8658f.png"></p><p> 过程</p><p>因为 Kafka 的 Consumer 客户端是线程不安全的，为了保证线程安全，并提升消费性能，可以在 Consumer 端采用类似 Reactor 的线程模型来消费数据。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/6ebd82d958f6faf081bffab04d1d72bf.png"></p><p> 消费模型</p><p>Kafka consumer 参数</p><ul><li><p>  bootstrap.servers：连接 broker 地址，<code>host：port</code> 格式。</p></li><li><p>  group.id：消费者隶属的消费组。</p></li><li><p>  key.deserializer：与生产者的<code>key.serializer</code>对应，key 的反序列化方式。</p></li><li><p>  value.deserializer：与生产者的<code>value.serializer</code>对应，value 的反序列化方式。</p></li><li><p>  session.timeout.ms：coordinator 检测失败的时间。默认 10s 该参数是 Consumer Group 主动检测 （组内成员 comsummer) 崩溃的时间间隔，类似于心跳过期时间。</p></li><li><p>  auto.offset.reset：该属性指定了消费者在读取一个没有偏移量后者偏移量无效（消费者长时间失效当前的偏移量已经过时并且被删除了）的分区的情况下，应该作何处理，默认值是 latest，也就是从最新记录读取数据（消费者启动之后生成的记录），另一个值是 earliest，意思是在偏移量无效的情况下，消费者从起始位置开始读取数据。</p></li><li><p>  enable.auto.commit：否自动提交位移，如果为<code>false</code>，则需要在程序中手动提交位移。对于精确到一次的语义，最好手动提交位移</p></li><li><p>  fetch.max.bytes：单次拉取数据的最大字节数量</p></li><li><p>  max.poll.records：单次 poll 调用返回的最大消息数，如果处理逻辑很轻量，可以适当提高该值。但是<code>max.poll.records</code>条数据需要在在 session.timeout.ms 这个时间内处理完 。默认值为 500</p></li><li><p>  request.timeout.ms：一次请求响应的最长等待时间。如果在超时时间内未得到响应，kafka 要么重发这条消息，要么超过重试次数的情况下直接置为失败。</p></li></ul><p>Kafka Rebalance</p><p>rebalance 本质上是一种协议，规定了一个 consumer group 下的所有 consumer 如何达成一致来分配订阅 topic 的每个分区。比如某个 group 下有 20 个 consumer，它订阅了一个具有 100 个分区的 topic。正常情况下，Kafka 平均会为每个 consumer 分配 5 个分区。这个分配的过程就叫 rebalance。</p><p><strong>什么时候 rebalance？</strong></p><p>这也是经常被提及的一个问题。rebalance 的触发条件有三种：</p><ul><li><p>  组成员发生变更（新 consumer 加入组、已有 consumer 主动离开组或已有 consumer 崩溃了——这两者的区别后面会谈到）</p></li><li><p>  订阅主题数发生变更</p></li><li><p>  订阅主题的分区数发生变更</p></li></ul><p><strong>如何进行组内分区分配？</strong></p><p>Kafka 默认提供了两种分配策略：Range 和 Round-Robin。当然 Kafka 采用了可插拔式的分配策略，你可以创建自己的分配器以实现不同的分配策略。</p><h3 id="答案关键字-2"><a href="#答案关键字-2" class="headerlink" title="答案关键字"></a>答案关键字</h3><ul><li><p>  Kafka 有哪些命令行工具？你用过哪些？<code>/bin</code>目录，管理 kafka 集群、管理 topic、生产和消费 kafka</p></li><li><p>  Kafka Producer 的执行过程？拦截器，序列化器，分区器和累加器</p></li><li><p>  Kafka Producer 有哪些常见配置？broker 配置，ack 配置，网络和发送参数，压缩参数，ack 参数</p></li><li><p>  如何让 Kafka 的消息有序？Kafka 在 Topic 级别本身是无序的，只有 partition 上才有序，所以为了保证处理顺序，可以自定义分区器，将需顺序处理的数据发送到同一个 partition</p></li><li><p>  Producer 如何保证数据发送不丢失？ack 机制，重试机制</p></li><li><p>  如何提升 Producer 的性能？批量，异步，压缩</p></li><li><p>  如果同一 group 下 consumer 的数量大于 part 的数量，kafka 如何处理？多余的 Part 将处于无用状态，不消费数据</p></li><li><p>  Kafka Consumer 是否是线程安全的？不安全，单线程消费，多线程处理</p></li><li><p>  讲一下你使用 Kafka Consumer 消费消息时的线程模型，为何如此设计？拉取和处理分离</p></li><li><p>  Kafka Consumer 的常见配置？broker, 网络和拉取参数，心跳参数</p></li><li><p>  Consumer 什么时候会被踢出集群？奔溃，网络异常，处理时间过长提交位移超时</p></li><li><p>  当有 Consumer 加入或退出时，Kafka 会作何反应？进行 Rebalance</p></li><li><p>  什么是 Rebalance，何时会发生 Rebalance？topic 变化，consumer 变化</p></li></ul><h2 id="高可用和性能"><a href="#高可用和性能" class="headerlink" title="高可用和性能"></a>高可用和性能</h2><h3 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h3><ul><li><p>  Kafka 如何保证高可用？</p></li><li><p>  Kafka 的交付语义？</p></li><li><p>  Replic 的作用？</p></li><li><p>  什么事 AR，ISR？</p></li><li><p>  Leader 和 Flower 是什么？</p></li><li><p>  Kafka 中的 HW、LEO、LSO、LW 等分别代表什么？</p></li><li><p>  Kafka 为保证优越的性能做了哪些处理？</p></li></ul><h3 id="分区与副本"><a href="#分区与副本" class="headerlink" title="分区与副本"></a>分区与副本</h3><p>分区副本</p><p>在分布式数据系统中，通常使用分区来提高系统的处理能力，通过副本来保证数据的高可用性。多分区意味着并发处理的能力，这多个副本中，只有一个是 leader，而其他的都是 follower 副本。仅有 leader 副本可以对外提供服务。多个 follower 副本通常存放在和 leader 副本不同的 broker 中。通过这样的机制实现了高可用，当某台机器挂掉后，其他 follower 副本也能迅速”转正“，开始对外提供服务。</p><p><strong>为什么 follower 副本不提供读服务？</strong></p><p>这个问题本质上是对性能和一致性的取舍。试想一下，如果 follower 副本也对外提供服务那会怎么样呢？首先，性能是肯定会有所提升的。但同时，会出现一系列问题。类似数据库事务中的幻读，脏读。比如你现在写入一条数据到 kafka 主题 a，消费者 b 从主题 a 消费数据，却发现消费不到，因为消费者 b 去读取的那个分区副本中，最新消息还没写入。而这个时候，另一个消费者 c 却可以消费到最新那条数据，因为它消费了 leader 副本。Kafka 通过 WH 和 Offset 的管理来决定 Consumer 可以消费哪些数据，已经当前写入的数据。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/27fd0100cf5600b7c7277724ccadc814.png"></p><p>watermark</p><p><strong>只有 Leader 可以对外提供读服务，那如何选举 Leader</strong></p><p>kafka 会将与 leader 副本保持同步的副本放到 ISR 副本集合中。当然，leader 副本是一直存在于 ISR 副本集合中的，在某些特殊情况下，ISR 副本中甚至只有 leader 一个副本。当 leader 挂掉时，kakfa 通过 zookeeper 感知到这一情况，在 ISR 副本中选取新的副本成为 leader，对外提供服务。但这样还有一个问题，前面提到过，有可能 ISR 副本集合中，只有 leader，当 leader 副本挂掉后，ISR 集合就为空，这时候怎么办呢？这时候如果设置 unclean.leader.election.enable 参数为 true，那么 kafka 会在非同步，也就是不在 ISR 副本集合中的副本中，选取出副本成为 leader。</p><p><strong>副本的存在就会出现副本同步问题</strong></p><p>Kafka 在所有分配的副本 (AR) 中维护一个可用的副本列表 (ISR)，Producer 向 Broker 发送消息时会根据<code>ack</code>配置来确定需要等待几个副本已经同步了消息才相应成功，Broker 内部会<code>ReplicaManager</code>服务来管理 flower 与 leader 之间的数据同步。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/4ea4ba7cd942c12cc985ad0126d5b5a5.png"></p><p>sync</p><h3 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h3><ul><li><p>  partition 并发</p></li><li><p>  顺序读写磁盘</p></li><li><p>  page cache：按页读写</p></li><li><p>  预读：Kafka 会将将要消费的消息提前读入内存</p></li><li><p>  高性能序列化（二进制）</p></li><li><p>  内存映射</p></li><li><p>  无锁 offset 管理：提高并发能力</p></li><li><p>  Java NIO 模型</p></li><li><p>  批量：批量读写</p></li><li><p>  压缩：消息压缩，存储压缩，减小网络和 IO 开销</p></li></ul><p>Partition 并发</p><p>一方面，由于不同 Partition 可位于不同机器，因此可以充分利用集群优势，实现机器间的并行处理。另一方面，由于 Partition 在物理上对应一个文件夹，即使多个 Partition 位于同一个节点，也可通过配置让同一节点上的不同 Partition 置于不同的 disk drive 上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。</p><p>顺序读写</p><p>Kafka 每一个 partition 目录下的文件被平均切割成大小相等（默认一个文件是 500 兆，可以手动去设置）的数据文件， 每一个数据文件都被称为一个段（segment file）, 每个 segment 都采用 append 的方式追加数据。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/fe05fa7570e2bbb65e0b0d7646e05338.png" alt="fe05fa7570e2bbb65e0b0d7646e05338.png"></p><p>追加数据</p><h3 id="答案关键字-3"><a href="#答案关键字-3" class="headerlink" title="答案关键字"></a>答案关键字</h3><ul><li><p>Kafka 如何保证高可用？</p><blockquote><p>通过副本来保证数据的高可用，producer ack、重试、自动 Leader 选举，Consumer 自平衡</p></blockquote></li><li><p>Kafka 的交付语义？</p><blockquote><p>交付语义一般有<code>at least once</code>、<code>at most once</code>和<code>exactly once</code>。kafka 通过 ack 的配置来实现前两种。</p></blockquote></li><li><p>Replic 的作用？</p><blockquote><p>实现数据的高可用</p></blockquote></li><li><p>什么是 AR，ISR？</p><blockquote><p>AR：Assigned Replicas。AR 是主题被创建后，分区创建时被分配的副本集合，副本个 数由副本因子决定。ISR：In-Sync Replicas。Kafka 中特别重要的概念，指代的是 AR 中那些与 Leader 保 持同步的副本集合。在 AR 中的副本可能不在 ISR 中，但 Leader 副本天然就包含在 ISR 中。关于 ISR，还有一个常见的面试题目是如何判断副本是否应该属于 ISR。目前的判断 依据是：Follower 副本的 LEO 落后 Leader LEO 的时间，是否超过了 Broker 端参数 replica.lag.time.max.ms 值。如果超过了，副本就会被从 ISR 中移除。</p></blockquote></li><li><p>  Leader 和 Flower 是什么？</p></li><li><p>Kafka 中的 HW 代表什么？</p><blockquote><p>高水位值 (High watermark)。这是控制消费者可读取消息范围的重要字段。一 个普通消费者只能“看到”Leader 副本上介于 Log Start Offset 和 HW（不含）之间的 所有消息。水位以上的消息是对消费者不可见的。</p></blockquote></li><li><p>Kafka 为保证优越的性能做了哪些处理？</p><blockquote><p>partition 并发、顺序读写磁盘、page cache 压缩、高性能序列化（二进制）、内存映射 无锁 offset 管理、Java NIO 模型</p></blockquote></li></ul><p>建议读者同学结合 Kafka 的配置去了解 Kafka 的实现原理，Kafka 有大量的配置，这也是 Kafka 高度扩展的一个表现，很多同学对 Kafka 的配置也不敢轻易改动。所以理解这些配置背后的实现原理，可以让我们在实践中懂得如何使用和优化 Kafka。既可面试造火箭，也可以实战造火箭。</p><p>Kafka 配置说明链接：<a href="https://kafka.apache.org/documentation">https://kafka.apache.org/documentation</a></p><p><img src="https://img-blog.csdnimg.cn/img_convert/0b7c7fa6c9cf01cf01d6e912fc8315c0.png" alt="0b7c7fa6c9cf01cf01d6e912fc8315c0.png"></p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>Architecture</p><p>理解 Kafka 架构，就是理解 Kafka 的各种组件的概念，以及这些组件的关系。先简单看一下各组件及其简单说明。</p><p>不要去尝试记忆他们</p><p>Producer： 生产者，发送消息的一方。生产者负责创建消息，然后将其发送到 Kafka。</p><p>Consumer： 消费者，接受消息的一方。消费者连接到 Kafka 上并接收消息，进而进行相应的业务逻辑处理。</p><p>Consumer Group： 一个消费者组可以包含一个或多个消费者。使用多分区 + 多消费者方式可以极大提高数据下游的处理速度，同一消费组中的消费者不会重复消费消息，同样的，不同消费组中的消费者消息消息时互不影响。Kafka 就是通过消费组的方式来实现消息 P2P 模式和广播模式。</p><p>Broker： 服务代理节点。Broker 是 Kafka 的服务节点，即 Kafka 的服务器。</p><p>Topic： Kafka 中的消息以 Topic 为单位进行划分，生产者将消息发送到特定的 Topic，而消费者负责订阅 Topic 的消息并进行消费。</p><p>Partition： Topic 是一个逻辑的概念，它可以细分为多个分区，每个分区只属于单个主题。同一个主题下不同分区包含的消息是不同的，分区在存储层面可以看作一个可追加的日志（Log）文件，消息在被追加到分区日志文件的时候都会分配一个特定的偏移量（offset）。</p><p>Offset： offset 是消息在分区中的唯一标识，Kafka 通过它来保证消息在分区内的顺序性，不过 offset 并不跨越分区，也就是说，Kafka 保证的是分区有序性而不是主题有序性。</p><p>Replication： 副本，是 Kafka 保证数据高可用的方式，Kafka 同一 Partition 的数据可以在多 Broker 上存在多个副本，通常只有主副本对外提供读写服务，当主副本所在 broker 崩溃或发生网络异常，Kafka 会在 Controller 的管理下会重新选择新的 Leader 副本对外提供读写服务。</p><p>Record： 实际写入 Kafka 中并可以被读取的消息记录。每个 record 包含了 key、value 和 timestamp。</p><p>我们理解了也就自然记住了</p><p>我们应该通过理解的方式去记忆它们。</p><p>生产者-消费者</p><p><code>生产者</code>-<code>消费者</code>是一种设计模式，<code>生产者</code>和<code>消费者</code>之间通过添加一个<code>中间组件</code>来达到解耦。<code>生产者</code>向<code>中间组件</code>生成数据，<code>消费者</code>消费数据。</p><p>就像读书时65 哥给小芳写情书，这里写情书就是<code>生产者</code>，情书就是<code>消息</code>，小芳就是<code>消费者</code>。但有时候小芳不在，或者比较忙，65 哥也比较害羞，不敢直接将情书塞小芳手里，于是将情书塞在小芳抽屉中。所以抽屉就是这个<code>中间组件</code>。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/8f3c785291d5113aa418661688fb353f.png" alt="8f3c785291d5113aa418661688fb353f.png"></p><p>在程序中我们通常使用<code>Queue</code>来作为这个<code>中间组件</code>。可以使用多线程向队列中写入数据，另外的消费者线程依次读取队列中的数据进行消费。模型如下图所示：</p><p><code>生产者</code>-<code>消费者</code>模式通过添加一个中间层，不仅可以解耦生产者和消费者，使其易于扩展，还可以异步化调用、缓冲消息等。</p><p>分布式队列</p><p>后来 65 哥和小芳异地了，65 哥在<code>卷都</code>奋斗，小芳在<code>魔都</code>逛街。于是只能通过<code>邮局</code>寄暧昧信了。这样 65 哥、邮局和小芳就成了<code>分布式</code>的了。65 哥将信件发给邮局，小芳从邮局拿到 65 哥写的信，再回去慢慢看。</p><p>Kafka 的消息<code>生产者</code>就是<code>Producer</code>，上游消费者进程添加 Kafka Client 创建 Kafka Producer，向 Broker 发送消息，Broker 是集群部署在远程服务器上的 Kafka Server 进程，下游消费者进程引入 Kafka Consumer API 持续消费队列中消息。</p><p>因为 Kafka Consumer 使用 Poll 的模式，需要 Consumer 主动拉去消息。所有小芳只能定期去邮局拿信件了(呃，果然主动权都在小芳手上啊)。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/18212ac9da003d26ba93a345c75858f4.png" alt="18212ac9da003d26ba93a345c75858f4.png"></p><p>主题</p><p>邮局不能只为 65 哥服务，虽然 65 哥一天写好几封信。但也无法挽回邮局的损失。所以邮局是可以供任何人寄信。只需要寄信人写好地址(主题)，邮局建有两地的通道就可以发收信件了。</p><p>Kafka 的 Topic 才相当于一个队列，Broker 是所有队列部署的机器。可以按业务创建不同的 Topic，Producer 向所属业务的 Topic 发送消息，相应的 Consumer 可以消费并处理消息。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/a0e2c59f45370e28cc01f7a17a369e05.png"></p><p>分区</p><p>由于 65 哥写的信太多，一个邮局已经无法满足 65 哥的需求，邮政公司只能多建几个邮局了，65 哥将信件按私密度分类(分区策略)，从不同的邮局寄送。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/865c34534aa862eadaa17bd8b9f8028d.png"></p><p>同一个 Topic 可以创建多个分区。理论上分区越多并发度越高，Kafka 会根据分区策略将分区尽可能均衡的分布在不同的 Broker 节点上，以避免消息倾斜，不同的 Broker 负载差异太大。分区也不是越多越好哦，毕竟太多邮政公司也管理不过来。</p><p>副本</p><p>为防止由于邮局的问题，比如交通断啦，邮车没油啦。导致 65 哥的暧昧信无法寄到小芳手上，使得 65 哥晚上远程跪键盘。邮局决定将 65 哥的信件复制几份发到多个正常的邮局，这样只要有一个邮局还在，小芳就可以收到 65 哥的信了。</p><p>Kafka 采用分区副本的方式来保证数据的高可用，每个分区都将建立指定数量的副本数，kakfa 保证同一分区副本尽量分布在不同的 Broker 节点上，以防止 Broker 宕机导致所有副本不可用。Kafka 会为分区的多个副本选举一个作为主副本(Leader)，主副本对外提供读写服务，从副本(Follower)实时同步 Leader 的数据。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/eeb8632036f3e52ef3249c75ac6a4a69.png"></p><p>多消费者</p><p>哎，65 哥的信件满天飞，小芳天天跑邮局，还要一一拆开看，65 哥写的信又臭又长，让小芳忙得满身大汉大汗。于是小芳啪的一下，很快啊，变出多个分身去不同的邮局取信，这样小芳终于可以挤出额外的时间逛街了。</p><p>广播消息</p><p>邮局最近提供了定制明信片业务，每个人都可以设计明信片，同一个身份只能领取一种明信片。65 哥设计了一堆，广播给所有漂亮的小妹妹都可以来领取，美女啪变出的分身也可以来领取，但是同一个身份的多个分身只能取一种明信片。</p><p>Kafka 通过 Consumer Group 来实现广播模式消息订阅，即不同 group 下的 consumer 可以重复消费消息，相互不影响，同一个 group 下的 consumer 构成一个整体。</p><p>最后我们完成了 Kafka 的整体架构，如下：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/4e5ba5ba733614a0d6e8bf10629f6ab8.png"></p><h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><p>Zookeeper 是一个成熟的分布式协调服务，它可以为分布式服务提供分布式配置服、同步服务和命名注册等能力.。对于任何分布式系统，都需要一种协调任务的方法。Kafka 是使用 ZooKeeper 而构建的分布式系统。但是也有一些其他技术（例如 Elasticsearch 和 MongoDB）具有其自己的内置任务协调机制。</p><p>Kafka 将 Broker、Topic 和 Partition 的元数据信息存储在 Zookeeper 上。通过在 Zookeeper 上建立相应的数据节点，并监听节点的变化，Kafka 使用 Zookeeper 完成以下功能：</p><ul><li><p>  Kafka Controller 的 Leader 选举</p></li><li><p>  Kafka 集群成员管理</p></li><li><p>  Topic 配置管理</p></li><li><p>  分区副本管理</p></li></ul><p>我们看一看 Zookeeper 下 Kafka 创建的节点，即可一目了然的看出这些相关的功能。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/1b38cac9933bbaca280253f7a1c3caa2.png"></p><h2 id="Controller"><a href="#Controller" class="headerlink" title="Controller"></a>Controller</h2><p>Controller 是从 Broker 中选举出来的，负责分区 Leader 和 Follower 的管理。当某个分区的 leader 副本发生故障时，由 Controller 负责为该分区选举新的 leader 副本。当检测到某个分区的 ISR(In-Sync Replica)集合发生变化时，由控制器负责通知所有 broker 更新其元数据信息。当使用<code>kafka-topics.sh</code>脚本为某个 topic 增加分区数量时，同样还是由控制器负责分区的重新分配。</p><p>Kafka 中 Contorller 的选举的工作依赖于 Zookeeper，成功竞选为控制器的 broker 会在 Zookeeper 中创建<code>/controller</code>这个临时（EPHEMERAL）节点。</p><h3 id="选举过程"><a href="#选举过程" class="headerlink" title="选举过程"></a>选举过程</h3><p><img src="https://img-blog.csdnimg.cn/img_convert/086b01429b3cd2f41e4028864de25207.png"></p><p>Broker 启动的时候尝试去读取<code>/controller</code>节点的<code>brokerid</code>的值，如果<code>brokerid</code>的值不等于-1，则表明已经有其他的 Broker 成功成为 Controller 节点，当前 Broker 主动放弃竞选；如果不存在<code>/controller</code>节点，或者 brokerid 数值异常，当前 Broker 尝试去创建<code>/controller</code>这个节点。</p><p>此时也有可能其他 broker 同时去尝试创建这个节点，只有创建成功的那个 broker 才会成为控制器，而创建失败的 broker 则表示竞选失败。每个 broker 都会在内存中保存当前控制器的 brokerid 值，这个值可以标识为 activeControllerId。</p><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p><img src="https://img-blog.csdnimg.cn/img_convert/ebd99e8ff6ba5c2f23f58ccf7a3318d9.png"></p><p>Controller 读取 Zookeeper 中的节点数据，初始化上下文(Controller Context)，并管理节点变化，变更上下文，同时也需要将这些变更信息同步到其他普通的 broker 节点中。Controller 通过定时任务，或者监听器模式获取 zookeeper 信息，事件监听会更新更新上下文信息。</p><p>如图所示，Controller 内部也采用生产者-消费者实现模式，Controller 将 zookeeper 的变动通过事件的方式发送给事件队列，队列就是一个<code>LinkedBlockingQueue</code>，事件消费者线程组通过消费消费事件，将相应的事件同步到各 Broker 节点。这种队列 FIFO 的模式保证了消息的有序性。</p><h3 id="职责"><a href="#职责" class="headerlink" title="职责"></a>职责</h3><p>Controller 被选举出来，作为整个 Broker 集群的管理者，管理所有的集群信息和元数据信息。它的职责包括下面几部分：</p><ol><li><p> 处理 Broker 节点的上线和下线，包括自然下线、宕机和网络不可达导致的集群变动，Controller 需要及时更新集群元数据，并将集群变化通知到所有的 Broker 集群节点；</p></li><li><p> 创建 Topic 或者 Topic 扩容分区，Controller 需要负责分区副本的分配工作，并主导 Topic 分区副本的 Leader 选举。</p></li><li><p> 管理集群中所有的副本和分区的状态机，监听状态机变化事件，并作出相应的处理。Kafka 分区和副本数据采用状态机的方式管理，分区和副本的变化都在状态机内会引起状态机状态的变更，从而触发相应的变化事件。</p></li></ol><blockquote><p>“</p><p>状态机啊，听起来好复杂。</p><p>”</p></blockquote><p>Controller 管理着集群中所有副本和分区的状态机。大家不要被<code>状态机</code>这个词唬住了。理解状态机很简单。先理解模型，即这是什么关于什么模型，然后就是模型的状态有哪些，模型状态之间如何转换，转换时发送相应的变化事件。</p><p>Kafka 的分区和副本状态机很简单。我们先理解，这分别是管理 Kafka Topic 的分区和副本的。它们的状态也很简单，就是 CRUD，具体说来如下：</p><p>分区状态机</p><p>PartitionStateChange，管理 Topic 的分区，它有以下 4 种状态：</p><ol><li><p> NonExistentPartition：该状态表示分区没有被创建过或创建后被删除了。</p></li><li><p> NewPartition：分区刚创建后，处于这个状态。此状态下分区已经分配了副本，但是还没有选举 leader，也没有 ISR 列表。</p></li><li><p> OnlinePartition：一旦这个分区的 leader 被选举出来，将处于这个状态。</p></li><li><p> OfflinePartition：当分区的 leader 宕机，转移到这个状态。</p></li></ol><p>我们用一张图来直观的看看这些状态是如何变化的，以及在状态发生变化时 Controller 都有哪些操作：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/efb89664c9eb727227383342fc3a89b8.png"></p><p>副本状态机</p><p>ReplicaStateChange，副本状态，管理分区副本信息，它也有 4 种状态：</p><ol><li><p> NewReplica: 创建 topic 和分区分配后创建 replicas，此时，replica 只能获取到成为 follower 状态变化请求。</p></li><li><p> OnlineReplica: 当 replica 成为 parition 的 assingned replicas 时，其状态变为 OnlineReplica, 即一个有效的 OnlineReplica。</p></li><li><p> OfflineReplica: 当一个 replica 下线，进入此状态，这一般发生在 broker 宕机的情况下；</p></li><li><p> NonExistentReplica: Replica 成功删除后，replica 进入 NonExistentReplica 状态。</p></li></ol><p>副本状态间的变化如下图所示，Controller 在状态变化时会做出相应的操作：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/04848f58ce2ce9a6879319a790c07c5c.png"></p><h2 id="Network"><a href="#Network" class="headerlink" title="Network"></a>Network</h2><p>Kafka 的网络通信模型是基于 NIO 的 Reactor 多线程模型来设计的。其中包含了一个<code>Acceptor</code>线程，用于处理新的连接，<code>Acceptor</code> 有 N 个 <code>Processor</code> 线程 select 和 read socket 请求，N 个 <code>Handler</code> 线程处理请求并相应，即处理业务逻辑。下面就是 KafkaServer 的模型图：</p><h2 id="-1"><a href="#-1" class="headerlink" title=""></a></h2><p>Kafka 性能全景</p><p>从高度抽象的角度来看，性能问题逃不出下面三个方面：</p><ul><li><p>  网络</p></li><li><p>  磁盘</p></li><li><p>  复杂度</p></li></ul><p>对于 Kafka 这种网络分布式队列来说，网络和磁盘更是优化的重中之重。针对于上面提出的抽象问题，解决方案高度抽象出来也很简单：</p><ul><li><p>  并发</p></li><li><p>  压缩</p></li><li><p>  批量</p></li><li><p>  缓存</p></li><li><p>  算法</p></li></ul><p>知道了问题和思路，我们再来看看，在 Kafka 中，有哪些角色，而这些角色就是可以优化的点：</p><ul><li><p>  Producer</p></li><li><p>  Broker</p></li><li><p>  Consumer</p></li></ul><p>是的，所有的问题，思路，优化点都已经列出来了，我们可以尽可能的细化，三个方向都可以细化，如此，所有的实现便一目了然，即使不看 Kafka 的实现，我们自己也可以想到一二点可以优化的地方。</p><p>这就是思考方式。<code>提出问题</code> &gt; <code>列出问题点</code> &gt; <code>列出优化方法</code> &gt; <code>列出具体可切入的点</code> &gt; <code>tradeoff和细化实现</code>。</p><p>现在，你也可以尝试自己想一想优化的点和方法，不用尽善尽美，不用管好不好实现，想一点是一点。</p><blockquote><p>“</p><p>不行啊，我很笨，也很懒，你还是直接和我说吧，我白嫖比较行。</p><p>”</p></blockquote><h2 id="顺序写"><a href="#顺序写" class="headerlink" title="顺序写"></a>顺序写</h2><blockquote><p>“</p><p>人家 Redis 是基于纯内存的系统，你 kafka 还要读写磁盘，能比？</p><p>”</p></blockquote><p><code>为什么说写磁盘慢？</code></p><p>我们不能只知道结论，而不知其所以然。要回答这个问题，就得回到在校时我们学的操作系统课程了。来，翻到讲磁盘的章节，让我们回顾一下磁盘的运行原理。</p><blockquote><p>“</p><p>鬼还留着哦，课程还没上到一半书就没了。要不是考试俺眼神好，估计现在还没毕业。</p><p>”</p></blockquote><p>看经典大图：</p><p>完成一次磁盘 IO，需要经过<code>寻道</code>、<code>旋转</code>和<code>数据传输</code>三个步骤。</p><p>影响磁盘 IO 性能的因素也就发生在上面三个步骤上，因此主要花费的时间就是：</p><ol><li><p> 寻道时间：Tseek 是指将读写磁头移动至正确的磁道上所需要的时间。寻道时间越短，I/O 操作越快，目前磁盘的平均寻道时间一般在 3-15ms。</p></li><li><p> 旋转延迟：Trotation 是指盘片旋转将请求数据所在的扇区移动到读写磁盘下方所需要的时间。旋转延迟取决于磁盘转速，通常用磁盘旋转一周所需时间的 1/2 表示。比如：7200rpm 的磁盘平均旋转延迟大约为 60*1000/7200/2 = 4.17ms，而转速为 15000rpm 的磁盘其平均旋转延迟为 2ms。</p></li><li><p> 数据传输时间：Ttransfer 是指完成传输所请求的数据所需要的时间，它取决于数据传输率，其值等于数据大小除以数据传输率。目前 IDE/ATA 能达到 133MB/s，SATA II 可达到 300MB/s 的接口数据传输率，数据传输时间通常远小于前两部分消耗时间。简单计算时可忽略。</p></li></ol><p>因此，如果在写磁盘的时候省去<code>寻道</code>、<code>旋转</code>可以极大地提高磁盘读写的性能。</p><p>Kafka 采用<code>顺序写</code>文件的方式来提高磁盘写入性能。<code>顺序写</code>文件，基本减少了磁盘<code>寻道</code>和<code>旋转</code>的次数。磁头再也不用在磁道上乱舞了，而是一路向前飞速前行。</p><p>Kafka 中每个分区是一个有序的，不可变的消息序列，新的消息不断追加到 Partition 的末尾，在 Kafka 中 Partition 只是一个逻辑概念，Kafka 将 Partition 划分为多个 Segment，每个 Segment 对应一个物理文件，Kafka 对 segment 文件追加写，这就是顺序写文件。</p><blockquote><p>“</p><p>为什么 Kafka 可以使用追加写的方式呢？</p><p>”</p></blockquote><p>这和 Kafka 的性质有关，我们来看看 Kafka 和 Redis，说白了，Kafka 就是一个<code>Queue</code>，而 Redis 就是一个<code>HashMap</code>。<code>Queue</code>和<code>Map</code>的区别是什么？</p><p><code>Queue</code> 是 FIFO 的，数据是有序的；<code>HashMap</code>数据是无序的，是随机读写的。Kafka 的不可变性，有序性使得 Kafka 可以使用追加写的方式写文件。</p><p>其实很多符合以上特性的数据系统，都可以采用追加写的方式来优化磁盘性能。典型的有<code>Redis</code>的 AOF 文件，各种数据库的<code>WAL(Write ahead log)</code>机制等等。</p><blockquote><p>“</p><p>所以清楚明白自身业务的特点，就可以针对性地做出优化。</p><p>”</p></blockquote><h2 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h2><blockquote><p>“</p><p>哈哈，这个我面试被问到过。可惜答得一般般，唉。</p><p>”</p></blockquote><p><code>什么是零拷贝？</code></p><p>我们从 Kafka 的场景来看，Kafka Consumer 消费存储在 Broker 磁盘的数据，从读取 Broker 磁盘到网络传输给 Consumer，期间涉及哪些系统交互。Kafka Consumer 从 Broker 消费数据，Broker 读取 Log，就使用了 sendfile。如果使用传统的 IO 模型，伪代码逻辑就如下所示：</p><pre><code>readFile(buffer)send(buffer)</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/3e427dce7762de7a8d635469d8d64cc8.jpeg"></p><p>如图，如果采用传统的 IO 流程，先读取网络 IO，再写入磁盘 IO，实际需要将数据 Copy 四次。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/2639df5adf0d57cf6b11755268bc70d7.jpeg"></p><ol><li><p> 第一次：读取磁盘文件到操作系统内核缓冲区；</p></li><li><p> 第二次：将内核缓冲区的数据，copy 到应用程序的 buffer；</p></li><li><p> 第三步：将应用程序 buffer 中的数据，copy 到 socket 网络发送缓冲区；</p></li><li><p> 第四次：将 socket buffer 的数据，copy 到网卡，由网卡进行网络传输。</p></li></ol><blockquote><p>“</p><p>啊，操作系统这么傻吗？copy 来 copy 去的。</p><p>”</p></blockquote><p>并不是操作系统傻，操作系统的设计就是每个应用程序都有自己的用户内存，用户内存和内核内存隔离，这是为了程序和系统安全考虑，否则的话每个应用程序内存满天飞，随意读写那还得了。</p><p>不过，还有<code>零拷贝</code>技术，英文——<code>Zero-Copy</code>。<code>零拷贝</code>就是尽量去减少上面数据的拷贝次数，从而减少拷贝的 CPU 开销，减少用户态内核态的上下文切换次数，从而优化数据传输的性能。</p><p>常见的零拷贝思路主要有三种：</p><ul><li><p>  直接 I/O：数据直接跨过内核，在用户地址空间与 I/O 设备之间传递，内核只是进行必要的虚拟存储配置等辅助工作；</p></li><li><p>  避免内核和用户空间之间的数据拷贝：当应用程序不需要对数据进行访问时，则可以避免将数据从内核空间拷贝到用户空间；</p></li><li><p>  写时复制：数据不需要提前拷贝，而是当需要修改的时候再进行部分拷贝。</p></li></ul><p>Kafka 使用到了 <code>mmap</code> 和 <code>sendfile</code> 的方式来实现<code>零拷贝</code>。分别对应 Java 的 <code>MappedByteBuffer</code> 和 <code>FileChannel.transferTo</code>。</p><p>使用 Java NIO 实现<code>零拷贝</code>，如下：</p><pre><code>FileChannel.transferTo()</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/682335fa8351381b644e1dce2d87ad38.jpeg"></p><p>在此模型下，上下文切换的数量减少到一个。具体而言，<code>transferTo()</code>方法指示块设备通过 DMA 引擎将数据读取到读取缓冲区中。然后，将该缓冲区复制到另一个内核缓冲区以暂存到套接字。最后，套接字缓冲区通过 DMA 复制到 NIC 缓冲区。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/26778b15105de9141ef22941c6244231.jpeg"></p><p>我们将副本数从四减少到三，并且这些副本中只有一个涉及 CPU。我们还将上下文切换的数量从四个减少到了两个。这是一个很大的改进，但是还没有查询零副本。当运行 Linux 内核 2.4 及更高版本以及支持收集操作的网络接口卡时，后者可以作为进一步的优化来实现。如下所示。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/f9f17c0ca6314126547da4e1766a89b2.jpeg"></p><p>根据前面的示例，调用<code>transferTo()</code>方法会使设备通过 DMA 引擎将数据读取到内核读取缓冲区中。但是，使用<code>gather</code>操作时，读取缓冲区和套接字缓冲区之间没有复制。取而代之的是，给 NIC 一个指向读取缓冲区的指针以及偏移量和长度，该偏移量和长度由 DMA 清除。CPU 绝对不参与复制缓冲区。</p><p>关于<code>零拷贝</code>详情，可以详读这篇文章零拷贝 (Zero-copy) 浅析及其应用。</p><h2 id="PageCache"><a href="#PageCache" class="headerlink" title="PageCache"></a>PageCache</h2><p><img src="https://img-blog.csdnimg.cn/img_convert/07d08398c4d0b6857e7746db12b14f57.png"></p><p>producer 生产消息到 Broker 时，Broker 会使用 pwrite() 系统调用【对应到 Java NIO 的 FileChannel.write() API】按偏移量写入数据，此时数据都会先写入<code>page cache</code>。consumer 消费消息时，Broker 使用 sendfile() 系统调用【对应 FileChannel.transferTo() API】，零拷贝地将数据从 page cache 传输到 broker 的 Socket buffer，再通过网络传输。</p><p>leader 与 follower 之间的同步，与上面 consumer 消费数据的过程是同理的。</p><p><code>page cache</code>中的数据会随着内核中 flusher 线程的调度以及对 sync()/fsync() 的调用写回到磁盘，就算进程崩溃，也不用担心数据丢失。另外，如果 consumer 要消费的消息不在<code>page cache</code>里，才会去磁盘读取，并且会顺便预读出一些相邻的块放入 page cache，以方便下一次读取。</p><p>因此如果 Kafka producer 的生产速率与 consumer 的消费速率相差不大，那么就能几乎只靠对 broker page cache 的读写完成整个生产 - 消费过程，磁盘访问非常少。</p><h2 id="网络模型"><a href="#网络模型" class="headerlink" title="网络模型"></a>网络模型</h2><blockquote><p>“</p><p>网络嘛，作为 Java 程序员，自然是 Netty</p><p>”</p></blockquote><p>是的，Netty 是 JVM 领域一个优秀的网络框架，提供了高性能的网络服务。大多数 Java 程序员提到网络框架，首先想到的就是 Netty。Dubbo、Avro-RPC 等等优秀的框架都使用 Netty 作为底层的网络通信框架。</p><p>Kafka 自己实现了网络模型做 RPC。底层基于 Java NIO，采用和 Netty 一样的 Reactor 线程模型。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/e118fe5aee13748f6c6348c891dea544.png"></p><p>Reacotr 模型主要分为三个角色</p><ul><li><p>  Reactor：把 IO 事件分配给对应的 handler 处理</p></li><li><p>  Acceptor：处理客户端连接事件</p></li><li><p>  Handler：处理非阻塞的任务</p></li></ul><p>在传统阻塞 IO 模型中，每个连接都需要独立线程处理，当并发数大时，创建线程数多，占用资源；采用阻塞 IO 模型，连接建立后，若当前线程没有数据可读，线程会阻塞在读操作上，造成资源浪费</p><p>针对传统阻塞 IO 模型的两个问题，Reactor 模型基于池化思想，避免为每个连接创建线程，连接完成后将业务处理交给线程池处理；基于 IO 复用模型，多个连接共用同一个阻塞对象，不用等待所有的连接。遍历到有新数据可以处理时，操作系统会通知程序，线程跳出阻塞状态，进行业务逻辑处理</p><p>Kafka 即基于 Reactor 模型实现了多路复用和处理线程池。其设计如下：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/6ceb0060b48dfbf5fd613aa46117e593.png"></p><p>其中包含了一个<code>Acceptor</code>线程，用于处理新的连接，<code>Acceptor</code> 有 N 个 <code>Processor</code> 线程 select 和 read socket 请求，N 个 <code>Handler</code> 线程处理请求并相应，即处理业务逻辑。</p><p>I/O 多路复用可以通过把多个 I/O 的阻塞复用到同一个 select 的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求。它的最大优势是系统开销小，并且不需要创建新的进程或者线程，降低了系统的资源开销。</p><p>总结： Kafka Broker 的 <code>KafkaServer</code> 设计是一个优秀的网络架构，有想了解 Java 网络编程，或需要使用到这方面技术的同学不妨去读一读源码。</p><h2 id="批量与压缩"><a href="#批量与压缩" class="headerlink" title="批量与压缩"></a>批量与压缩</h2><p>Kafka Producer 向 Broker 发送消息不是一条消息一条消息的发送。使用过 Kafka 的同学应该知道，Producer 有两个重要的参数：<code>batch.size</code>和<code>linger.ms</code>。这两个参数就和 Producer 的批量发送有关。</p><p>Kafka Producer 的执行流程如下图所示</p><p><img src="https://img-blog.csdnimg.cn/img_convert/dd7f9af0d288150d202f8e83cd934258.png"></p><p>发送消息依次经过以下处理器：</p><ul><li><p>  Serialize：键和值都根据传递的序列化器进行序列化。优秀的序列化方式可以提高网络传输的效率。</p></li><li><p>  Partition：决定将消息写入主题的哪个分区，默认情况下遵循 murmur2 算法。自定义分区程序也可以传递给生产者，以控制应将消息写入哪个分区。</p></li><li><p>  Compress：默认情况下，在 Kafka 生产者中不启用压缩.Compression 不仅可以更快地从生产者传输到代理，还可以在复制过程中进行更快的传输。压缩有助于提高吞吐量，降低延迟并提高磁盘利用率。</p></li><li><p>  Accumulate：<code>Accumulate</code>顾名思义，就是一个消息累计器。其内部为每个 Partition 维护一个<code>Deque</code>双端队列，队列保存将要发送的批次数据，<code>Accumulate</code>将数据累计到一定数量，或者在一定过期时间内，便将数据以批次的方式发送出去。记录被累积在主题每个分区的缓冲区中。根据生产者批次大小属性将记录分组。主题中的每个分区都有一个单独的累加器 / 缓冲区。</p></li><li><p>  Group Send：记录累积器中分区的批次按将它们发送到的代理分组。批处理中的记录基于 batch.size 和 linger.ms 属性发送到代理。记录由生产者根据两个条件发送。当达到定义的批次大小或达到定义的延迟时间时。</p></li></ul><p>Kafka 支持多种压缩算法：lz4、snappy、gzip。Kafka 2.1.0 正式支持 ZStandard —— ZStandard 是 Facebook 开源的压缩算法，旨在提供超高的压缩比 (compression ratio)，具体细节参见 zstd。</p><p>Producer、Broker 和 Consumer 使用相同的压缩算法，在 producer 向 Broker 写入数据，Consumer 向 Broker 读取数据时甚至可以不用解压缩，最终在 Consumer Poll 到消息时才解压，这样节省了大量的网络和磁盘开销。</p><h2 id="分区并发"><a href="#分区并发" class="headerlink" title="分区并发"></a>分区并发</h2><p>Kafka 的 Topic 可以分成多个 Partition，每个 Paritition 类似于一个队列，保证数据有序。同一个 Group 下的不同 Consumer 并发消费 Paritition，分区实际上是调优 Kafka 并行度的最小单元，因此，可以说，每增加一个 Paritition 就增加了一个消费并发。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/b8f64c1b4de8cd8608962b8be424dbb1.png"></p><p>Kafka 具有优秀的分区分配算法——StickyAssignor，可以保证分区的分配尽量地均衡，且每一次重分配的结果尽量与上一次分配结果保持一致。这样，整个集群的分区尽量地均衡，各个 Broker 和 Consumer 的处理不至于出现太大的倾斜。</p><blockquote><p>“</p><p>那是不是分区数越多越好呢？</p><p>”</p></blockquote><p>当然不是。</p><p>越多的分区需要打开更多的文件句柄</p><p>在 kafka 的 broker 中，每个分区都会对照着文件系统的一个目录。在 kafka 的数据日志文件目录中，每个日志数据段都会分配两个文件，一个索引文件和一个数据文件。因此，随着 partition 的增多，需要的文件句柄数急剧增加，必要时需要调整操作系统允许打开的文件句柄数。</p><p>客户端 / 服务器端需要使用的内存就越多</p><p>客户端 producer 有个参数 batch.size，默认是 16KB。它会为每个分区缓存消息，一旦满了就打包将消息批量发出。看上去这是个能够提升性能的设计。不过很显然，因为这个参数是分区级别的，如果分区数越多，这部分缓存所需的内存占用也会更多。</p><p>降低高可用性</p><p>分区越多，每个 Broker 上分配的分区也就越多，当一个发生 Broker 宕机，那么恢复时间将很长。</p><h2 id="文件结构"><a href="#文件结构" class="headerlink" title="文件结构"></a>文件结构</h2><p>Kafka 消息是以 Topic 为单位进行归类，各个 Topic 之间是彼此独立的，互不影响。每个 Topic 又可以分为一个或多个分区。每个分区各自存在一个记录消息数据的日志文件。</p><p>Kafka 每个分区日志在物理上实际按大小被分成多个 Segment。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/86ec1397c9fc3d2d1e954c979dc8d756.png"></p><ul><li><p>  segment file 组成：由 2 大部分组成，分别为 index file 和 data file，此 2 个文件一一对应，成对出现，后缀”.index”和“.log”分别表示为 segment 索引文件、数据文件。</p></li><li><p>  segment 文件命名规则：partion 全局的第一个 segment 从 0 开始，后续每个 segment 文件名为上一个 segment 文件最后一条消息的 offset 值。数值最大为 64 位 long 大小，19 位数字字符长度，没有数字用 0 填充。</p></li></ul><p>index 采用稀疏索引，这样每个 index 文件大小有限，Kafka 采用<code>mmap</code>的方式，直接将 index 文件映射到内存，这样对 index 的操作就不需要操作磁盘 IO。<code>mmap</code>的 Java 实现对应 <code>MappedByteBuffer</code> 。</p><blockquote><p>“</p><p>mmap 是一种内存映射文件的方法。即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存。</p><p>而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用 read,write 等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。</p><p>”</p></blockquote><p>Kafka 充分利用二分法来查找对应 offset 的消息位置：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/69fcc376dd37c0d63474330345360fe9.png"></p><ol><li><p> 按照二分法找到小于 offset 的 segment 的.log 和.index</p></li><li><p> 用目标 offset 减去文件名中的 offset 得到消息在这个 segment 中的偏移量。</p></li><li><p> 再次用二分法在 index 文件中找到对应的索引。</p></li><li><p> 到 log 文件中，顺序查找，直到找到 offset 对应的消息。</p></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Kafka 是一个优秀的开源项目。其在性能上面的优化做的淋漓尽致，是很值得我们深入学习的一个项目。无论是思想还是实现，我们都应该认真的去看一看，想一想。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/mxt51220/article/details/128338358&quot;&gt;https://blog.csdn.net/mxt51220/article/details/128338358&lt;/a&gt;&lt;/p&gt;
&lt;bloc</summary>
      
    
    
    
    <category term="Kafka" scheme="http://zhangyu.info/categories/Kafka/"/>
    
    
    <category term="Kafka" scheme="http://zhangyu.info/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>redis的20种常见使用场景</title>
    <link href="http://zhangyu.info/2022/12/05/redis%E7%9A%8420%E7%A7%8D%E5%B8%B8%E8%A7%81%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/"/>
    <id>http://zhangyu.info/2022/12/05/redis%E7%9A%8420%E7%A7%8D%E5%B8%B8%E8%A7%81%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/</id>
    <published>2022-12-04T16:00:00.000Z</published>
    <updated>2022-12-05T14:17:46.579Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/qkuejUUQ-mco-ZX2impZXw">https://mp.weixin.qq.com/s/qkuejUUQ-mco-ZX2impZXw</a><br><a href="https://blog.csdn.net/lupengfei1009/article/details/126266870">https://blog.csdn.net/lupengfei1009/article/details/126266870</a></p><blockquote><h3 id="文章目录"><a href="#文章目录" class="headerlink" title="文章目录"></a>文章目录</h3><ul><li><ul><li><p><a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#_19">缓存</a></p><ul><li><p>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#_46">抽奖</a></p></li><li><ul><li><a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#Rediscli__58">Redis-cli 操作</a><ul><li>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#SpringBoot__76">SpringBoot 实现</a></li></ul></li></ul></li><li><ul><li><a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#Rediscli_API_143">Redis-cli API操作</a><ul><li>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#SpringBoot__165">SpringBoot 操作</a></li></ul></li></ul></li><li><p>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#_236">排行榜</a></p></li><li><ul><li><a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#Rediscli_254">Redis-cli操作</a><ul><li>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#SpringBoot_298">SpringBoot操作</a></li></ul></li></ul></li><li><p>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#PVincr_365">PV统计（incr自增计数）</a></p></li><li><ul><li>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#Rediscli__373">Redis-cli 操作</a></li></ul></li><li><p>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#UVHeyperLogLog_384">UV统计（HeyperLogLog）</a></p></li><li><ul><li><a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#Rediscli__402">Redis-cli 操作</a><ul><li>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#SpringBootHeyperLogLog_421">SpringBoot操作HeyperLogLog</a></li></ul></li></ul></li><li><p>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#BloomFiler_494">去重（BloomFiler）</a></p></li><li><ul><li><a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#BloomFiler__517">BloomFiler 安装</a><ul><li>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#Rediscli_532">Redis-cli操作</a></li><li>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#SpringBoot_547">SpringBoot整合</a></li></ul></li></ul></li><li><p>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#BitMap_716">用户签到（BitMap）</a></p></li><li><ul><li><a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#Rediscli__746">Redis-cli 操作：</a><ul><li>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#_784">是否签到、连续签到判断</a></li><li>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#SpringBoot_847">SpringBoot实现签到</a></li><li><ul><li><a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#_851">按月签到</a><ul><li>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#_1171">指定时间签到</a></li></ul></li></ul></li></ul></li></ul></li><li><p>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#GEO_1464">GEO搜附近</a></p></li><li><ul><li><a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#GEO_API_Rediscli__1472">GEO API 及Redis-cli 操作：</a><ul><li>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#SpringBoot__1579">SpringBoot 操作</a></li></ul></li></ul></li><li><p>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#_1728">简单限流</a></p></li><li><ul><li><a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#Rediscli_1737">Redis-cli操作</a><ul><li>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#SpringBoot_1752">SpringBoot示例：</a></li></ul></li></ul></li><li><p>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#ID_1833">全局ID</a></p></li><li><ul><li>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#Rediscli__1841">Redis-cli 客户端测试</a></li></ul></li><li><p>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#_1856">简单分布式锁</a></p></li><li><p>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#_1900">认识的人/好友推荐</a></p></li><li><ul><li>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#Rediscli__1917">Redis-cli 客户端测试</a></li></ul></li><li><p>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#_1944">发布/订阅</a></p></li><li><ul><li>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#Rediscli_1953">Redis-cli操作</a></li></ul></li><li><p>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#_1963">消息队列</a></p></li><li><p>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#session_2073">数据共享（session共享）</a></p></li><li><p>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#_2181">商品筛选</a></p></li><li><ul><li>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#Rediscli__2194">Redis-cli 客户端测试</a></li></ul></li><li><p>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#_2245">购物车</a></p></li><li><ul><li>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#Rediscli__2264">Redis-cli 客户端测试</a></li></ul></li><li><p>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#key_2297">定时取消订单（key过期监听）</a></p></li><li><p>  <a href="https://blog.csdn.net/lupengfei1009/article/details/126266870#_2411">物流信息（时间线）</a></p></li></ul></li></ul></li></ul><p>大家好，我是一航</p><p>后端程序员，不管是出去面试，还是当面试官，Redis几乎是100%会问到的技术点；究其原因，主要是因为他实在过于强大、使用率太高了；导致项目中几乎无处不在。</p><p>那Redis部分，不出意外，第一个问题就是：<strong>你做的项目，用Redis干了些啥</strong>？大部分人的回答都会是：<strong>缓存</strong>；当问到是否还有其他场景中使用时，部分用的少的朋友就会微微摇头；</p><p>其实也没错，Redis绝不部分使用场景就是用来做缓存；但是，由于Redis 支持比较丰富的数据结构，因此他能实现的功能并不仅限于缓存，而是可以运用到各种业务场景中，开发出既简洁、又高效的系统;</p><p>下面整理了20种 Redis 的妙用场景，每个方案都用一个实际的业务需求并结合数据结构的API来讲解，希望大家能够理解其底层的实现方式，学会举一反三，并运用到项目的方方面面：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/2ca50242c26e57209b971a016682275e.png"></p><blockquote><p>本文稍微有点点长，如果时间不够，建议看一下目录，收藏起来，用的时候再翻出来看看。</p></blockquote><p>测试源码：<a href="https://github.com/vehang/ehang-spring-boot/tree/main/spring-boot-011-redis">https://github.com/vehang/ehang-spring-boot/tree/main/spring-boot-011-redis</a></p><h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><p>本文假定你已经了解过Redis，并知晓Redis最基础的一些使用，如果你对Redis的基础API还不了解，可以先看一下菜鸟教程：<a href="https://www.runoob.com/redis%EF%BC%8C%E9%82%A3%E4%B9%88%E7%BC%93%E5%AD%98%E9%83%A8%E5%88%86%E5%8F%8A%E5%9F%BA%E7%A1%80API%E7%9A%84%E6%BC%94%E7%A4%BA%EF%BC%8C%E5%B0%B1%E4%B8%8D%E8%BF%87%E5%A4%9A%E6%9D%A5%E8%AE%B2%E8%A7%A3%E4%BA%86%EF%BC%9B">https://www.runoob.com/redis，那么缓存部分及基础API的演示，就不过多来讲解了；</a></p><p>但是，基本的数据结构，在这里再列举一下，方便后续方案的理解：</p><p>结构类型</p><p>结构存储的值</p><p>结构的读写能力</p><p><strong>String字符串</strong></p><p>可以是字符串、整数或浮点数</p><p>对整个字符串或字符串的一部分进行操作；对整数或浮点数进行自增或自减操作；</p><p><strong>List列表</strong></p><p>一个链表，链表上的每个节点都包含一个字符串</p><p>对链表的两端进行push和pop操作，读取单个或多个元素；根据值查找或删除元素；</p><p><strong>Set集合</strong></p><p>包含字符串的无序集合</p><p>字符串的集合，包含基础的方法有：看是否存在、添加、获取、删除；还包含计算交集、并集、差集等</p><p><strong>Hash散列</strong></p><p>包含键值对的无序散列表</p><p>包含方法有：添加、获取、删除单个元素</p><p><strong>Zset有序集合</strong></p><p>和散列一样，用于存储键值对</p><p>字符串成员与浮点数分数之间的有序映射；元素的排列顺序由分数的大小决定；包含方法有：添加、获取、删除单个元素以及根据分值范围或成员来获取元素</p><ul><li><p>依赖</p><p>  以下所有通过SpringBoot测试的用例，都需要引入 Redis 的依赖</p><pre><code>  &lt;dependency&gt;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;  &lt;/dependency&gt;</code></pre></li></ul><h2 id="抽奖"><a href="#抽奖" class="headerlink" title="抽奖"></a>抽奖</h2><p>曾几何时，抽奖是互联网APP热衷的一种推广、拉新的方式，节假日没有好的策划，那就抽个奖吧！一堆用户参与进来，然后随机抽取几个幸运用户给予实物/虚拟的奖品；此时，开发人员就需要写上一个抽奖的算法，来实现幸运用户的抽取；其实我们完全可以利用Redis的集合（Set），就能轻松实现抽奖的功能；</p><p>功能实现需要的API</p><ul><li>  <strong>SADD</strong> key member1 [member2]：添加一个或者多个参与用户；</li><li>  <strong>SRANDMEMBER</strong> KEY [count]：随机返回一个或者多个用户；</li><li>  <strong>SPOP</strong> key：随机返回一个或者多个用户，并删除返回的用户；</li></ul><p>SRANDMEMBER 和 SPOP 主要用于两种不同的抽奖模式，SRANDMEMBER 适用于一个用户可中奖多次的场景（就是中奖之后，不从用户池中移除，继续参与其他奖项的抽取）；而 SPOP 就适用于仅能中一次的场景（一旦中奖，就将用户从用户池中移除，后续的抽奖，就不可能再抽到该用户）； 通常 SPOP 会用的会比较多。</p><h3 id="Redis-cli-操作"><a href="#Redis-cli-操作" class="headerlink" title="Redis-cli 操作"></a>Redis-cli 操作</h3><pre><code>127.0.0.1:6379&gt; SADD raffle user1(integer) 1127.0.0.1:6379&gt; SADD raffle user2 user3 user4 user5 user6 user7 user8 user9 user10(integer) 9127.0.0.1:6379&gt; SRANDMEMBER raffle 21) &quot;user5&quot;2) &quot;user2&quot;127.0.0.1:6379&gt; SPOP raffle 21) &quot;user3&quot;2) &quot;user4&quot;127.0.0.1:6379&gt; SPOP raffle 21) &quot;user10&quot;2) &quot;user9&quot;</code></pre><h3 id="SpringBoot-实现"><a href="#SpringBoot-实现" class="headerlink" title="SpringBoot 实现"></a>SpringBoot 实现</h3><pre><code>import lombok.extern.slf4j.Slf4j;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.redis.core.RedisTemplate;import java.util.List;/** * @author 一行Java * @title: RaffleMain * @projectName ehang-spring-boot * @description: TODO * @date 2022/7/18 15:17 */@Slf4j@SpringBootTestpublic class RaffleMain &#123;    private final String KEY_RAFFLE_PROFIX = &quot;raffle:&quot;;    @Autowired    RedisTemplate redisTemplate;    @Test    void test() &#123;        Integer raffleId = 1;        join(raffleId, 1000, 1001, 2233, 7890, 44556, 74512);        List lucky = lucky(raffleId, 2);        log.info(&quot;活动：&#123;&#125; 的幸运中奖用户是：&#123;&#125;&quot;, raffleId, lucky);    &#125;    public void join(Integer raffleId, Integer... userIds) &#123;        String key = KEY_RAFFLE_PROFIX + raffleId;        redisTemplate.opsForSet().add(key, userIds);    &#125;    public List lucky(Integer raffleId, long num) &#123;        String key = KEY_RAFFLE_PROFIX + raffleId;        // 随机抽取 抽完之后将用户移除奖池        List list = redisTemplate.opsForSet().pop(key, num);        // 随机抽取 抽完之后用户保留在池子里        //List list = redisTemplate.opsForSet().randomMembers(key, num);        return list;    &#125;&#125;</code></pre><h2 id="Set实现点赞-收藏功能"><a href="#Set实现点赞-收藏功能" class="headerlink" title="Set实现点赞/收藏功能"></a>Set实现点赞/收藏功能</h2><p>有互动属性APP一般都会有点赞/收藏/喜欢等功能，来提升用户之间的互动。</p><p><strong>传统的实现</strong>：用户点赞之后，在数据库中记录一条数据，同时一般都会在主题库中记录一个点赞/收藏汇总数，来方便显示；</p><p><strong>Redis方案</strong>：基于Redis的集合（Set），记录每个帖子/文章对应的收藏、点赞的用户数据，同时set还提供了检查集合中是否存在指定用户，用户快速判断用户是否已经点赞过</p><p>功能实现需要的API</p><ul><li>  <strong>SADD</strong> key member1 [member2]：添加一个或者多个成员（点赞）</li><li>  <strong>SCARD</strong> key：获取所有成员的数量（点赞数量）</li><li>  <strong>SISMEMBER</strong> key member：判断成员是否存在（是否点赞）</li><li>  <strong>SREM</strong> key member1 [member2] ：移除一个或者多个成员（点赞数量）</li></ul><h3 id="Redis-cli-API操作"><a href="#Redis-cli-API操作" class="headerlink" title="Redis-cli API操作"></a>Redis-cli API操作</h3><pre><code>127.0.0.1:6379&gt; sadd like:article:1 user1(integer) 1127.0.0.1:6379&gt; sadd like:article:1 user2(integer) 1# 获取成员数量（点赞数量）127.0.0.1:6379&gt; SCARD like:article:1(integer) 2# 判断成员是否存在（是否点在）127.0.0.1:6379&gt; SISMEMBER like:article:1 user1(integer) 1127.0.0.1:6379&gt; SISMEMBER like:article:1 user3(integer) 0# 移除一个或者多个成员（取消点赞）127.0.0.1:6379&gt; SREM like:article:1 user1(integer) 1127.0.0.1:6379&gt; SCARD like:article:1(integer) 1</code></pre><h3 id="SpringBoot-操作"><a href="#SpringBoot-操作" class="headerlink" title="SpringBoot 操作"></a>SpringBoot 操作</h3><pre><code>import lombok.extern.slf4j.Slf4j;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.redis.core.RedisTemplate;/** * @author 一行Java * @title: LikeMain * @projectName ehang-spring-boot * @description: TODO * @date 2022/7/18 15:38 */@Slf4j@SpringBootTestpublic class LikeMain &#123;    private final String KEY_LIKE_ARTICLE_PROFIX = &quot;like:article:&quot;;    @Autowired    RedisTemplate redisTemplate;    @Test    void test() &#123;        long articleId = 100;        Long likeNum = like(articleId, 1001, 1002, 2001, 3005, 4003);        unLike(articleId, 2001);        likeNum = likeNum(articleId);        boolean b2001 = isLike(articleId, 2001);        boolean b3005 = isLike(articleId, 3005);        log.info(&quot;文章：&#123;&#125; 点赞数量：&#123;&#125; 用户2001的点赞状态：&#123;&#125; 用户3005的点赞状态：&#123;&#125;&quot;, articleId, likeNum, b2001, b3005);    &#125;    /**     * 点赞     *     * @param articleId 文章ID     * @return 点赞数量     */    public Long like(Long articleId, Integer... userIds) &#123;        String key = KEY_LIKE_ARTICLE_PROFIX + articleId;        Long add = redisTemplate.opsForSet().add(key, userIds);        return add;    &#125;    public Long unLike(Long articleId, Integer... userIds) &#123;        String key = KEY_LIKE_ARTICLE_PROFIX + articleId;        Long remove = redisTemplate.opsForSet().remove(key, userIds);        return remove;    &#125;    public Long likeNum(Long articleId) &#123;        String key = KEY_LIKE_ARTICLE_PROFIX + articleId;        Long size = redisTemplate.opsForSet().size(key);        return size;    &#125;    public Boolean isLike(Long articleId, Integer userId) &#123;        String key = KEY_LIKE_ARTICLE_PROFIX + articleId;        return redisTemplate.opsForSet().isMember(key, userId);    &#125;&#125;</code></pre><h2 id="排行榜"><a href="#排行榜" class="headerlink" title="排行榜"></a>排行榜</h2><p>排名、排行榜、热搜榜是很多APP、游戏都有的功能，常用于用户活动推广、竞技排名、热门信息展示等功能；</p><p><img src="https://img-blog.csdnimg.cn/img_convert/161c0b70efd7ac9c13519941aa0b0076.png"></p><p>比如上面的热搜榜，热度数据来源于全网用户的贡献，但用户只关心热度最高的前50条。</p><p><strong>常规的做法</strong>：就是将用户的名次、分数等用于排名的数据更新到数据库，然后查询的时候通过Order by + limit 取出前50名显示，如果是参与用户不多，更新不频繁的数据，采用数据库的方式也没有啥问题，但是一旦出现爆炸性热点资讯（比如：大陆收复湾湾，xxx某些绿了等等），短时间会出现爆炸式的流量，瞬间的压力可能让数据库扛不住；</p><p><strong>Redis方案</strong>：将热点资讯全页缓存，采用Redis的<strong>有序队列</strong>（Sorted Set）来缓存热度（SCORES），即可瞬间缓解数据库的压力，同时轻松筛选出热度最高的50条；</p><p>功能实现需要的命令</p><ul><li>  <strong>ZADD</strong> key score1 member1 [score2 member2]：添加并设置SCORES，支持一次性添加多个；</li><li>  <strong>ZREVRANGE</strong> key start stop [WITHSCORES] ：根据SCORES降序排列；</li><li>  <strong>ZRANGE</strong> key start stop [WITHSCORES] ：根据SCORES降序排列；</li></ul><h3 id="Redis-cli操作"><a href="#Redis-cli操作" class="headerlink" title="Redis-cli操作"></a>Redis-cli操作</h3><pre><code># 单个插入127.0.0.1:6379&gt; ZADD ranking 1 user1  (integer) 1# 批量插入127.0.0.1:6379&gt; ZADD ranking 10 user2 50 user3 3 user4 25 user5(integer) 4# 降序排列 不带SCORES127.0.0.1:6379&gt; ZREVRANGE ranking 0 -1 1) &quot;user3&quot;2) &quot;user5&quot;3) &quot;user2&quot;4) &quot;user4&quot;5) &quot;user1&quot;# 降序排列 带SCORES127.0.0.1:6379&gt; ZREVRANGE ranking 0 -1 WITHSCORES 1) &quot;user3&quot; 2) &quot;50&quot; 3) &quot;user5&quot; 4) &quot;25&quot; 5) &quot;user2&quot; 6) &quot;10&quot; 7) &quot;user4&quot; 8) &quot;3&quot; 9) &quot;user1&quot;10) &quot;1&quot;# 升序127.0.0.1:6379&gt; ZRANGE ranking 0 -1 WITHSCORES 1) &quot;user1&quot; 2) &quot;1&quot; 3) &quot;user4&quot; 4) &quot;3&quot; 5) &quot;user2&quot; 6) &quot;10&quot; 7) &quot;user5&quot; 8) &quot;25&quot; 9) &quot;user3&quot;10) &quot;50&quot;</code></pre><h3 id="SpringBoot操作"><a href="#SpringBoot操作" class="headerlink" title="SpringBoot操作"></a>SpringBoot操作</h3><pre><code>import lombok.extern.slf4j.Slf4j;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.redis.core.DefaultTypedTuple;import org.springframework.data.redis.core.RedisTemplate;import java.util.Set;/** * @author 一行Java * @title: RankingTest * @projectName ehang-spring-boot * @description: TODO * @date 2022/7/18 15:54 */@SpringBootTest@Slf4jpublic class RankingTest &#123;    private final String KEY_RANKING = &quot;ranking&quot;;    @Autowired    RedisTemplate redisTemplate;    @Test    void test() &#123;        add(1001, (double) 60);        add(1002, (double) 80);        add(1003, (double) 100);        add(1004, (double) 90);        add(1005, (double) 70);        // 取所有        Set&lt;DefaultTypedTuple&gt; range = range(0, -1);        log.info(&quot;所有用户排序：&#123;&#125;&quot;, range);        // 前三名        range = range(0, 2);        log.info(&quot;前三名排序：&#123;&#125;&quot;, range);    &#125;    public Boolean add(Integer userId, Double score) &#123;        Boolean add = redisTemplate.opsForZSet().add(KEY_RANKING, userId, score);        return add;    &#125;    public Set&lt;DefaultTypedTuple&gt; range(long min, long max) &#123;        // 降序        Set&lt;DefaultTypedTuple&gt; set = redisTemplate.opsForZSet().reverseRangeWithScores(KEY_RANKING, min, max);        // 升序        //Set&lt;DefaultTypedTuple&gt; set = redisTemplate.opsForZSet().rangeWithScores(KEY_RANKING, min, max);        return set;    &#125;&#125;</code></pre><p>输出</p><pre><code>所有用户排序：[DefaultTypedTuple [score=100.0, value=1003], DefaultTypedTuple [score=90.0, value=1004], DefaultTypedTuple [score=80.0, value=1002], DefaultTypedTuple [score=70.0, value=1005], DefaultTypedTuple [score=60.0, value=1001]]前三名排序：[DefaultTypedTuple [score=100.0, value=1003], DefaultTypedTuple [score=90.0, value=1004], DefaultTypedTuple [score=80.0, value=1002]]</code></pre><h2 id="PV统计（incr自增计数）"><a href="#PV统计（incr自增计数）" class="headerlink" title="PV统计（incr自增计数）"></a>PV统计（incr自增计数）</h2><p>Page View（PV）指的是页面浏览量，是用来衡量流量的一个重要标准，也是数据分析很重要的一个依据；通常统计规则是页面被展示一次，就加一</p><p>功能所需命令</p><ul><li>  <strong>INCR</strong>：将 key 中储存的数字值增一</li></ul><h3 id="Redis-cli-操作-1"><a href="#Redis-cli-操作-1" class="headerlink" title="Redis-cli 操作"></a>Redis-cli 操作</h3><pre><code>127.0.0.1:6379&gt; INCR pv:article:1(integer) 1127.0.0.1:6379&gt; INCR pv:article:1(integer) 2</code></pre><h2 id="UV统计（HeyperLogLog）"><a href="#UV统计（HeyperLogLog）" class="headerlink" title="UV统计（HeyperLogLog）"></a>UV统计（HeyperLogLog）</h2><p>前面，介绍了通过（INCR）方式来实现页面的PV；除了PV之外，UV（独立访客）也是一个很重要的统计数据；</p><p>但是如果要想通过计数（INCR）的方式来实现UV计数，就非常的麻烦，增加之前，需要判断这个用户是否访问过；那判断依据就需要额外的方式再进行记录。</p><p>你可能会说，不是还有Set嘛！一个页面弄个集合，来一个用户塞（SADD）一个用户进去，要统计UV的时候，再通过SCARD汇总一下数量，就能轻松搞定了；此方案确实能实现UV的统计效果，但是忽略了成本；如果是普通页面，几百、几千的访问，可能造成的影响微乎其微，如果一旦遇到爆款页面，动辄上千万、上亿用户访问时，就一个页面UV将会带来非常大的内存开销，对于如此珍贵的内存来说，这显然是不划算的。</p><p>此时，HeyperLogLog数据结构，就能完美的解决这一问题，它提供了一种<strong>不精准的去重计数</strong>方案，注意！这里强调一下，是不精准的，会存在误差，不过误差也不会很大，**标准的误差率是0.81%**，这个误差率对于统计UV计数，是能够容忍的；所以，不要将这个数据结构拿去做精准的去重计数。</p><p>另外，HeyperLogLog 是会<strong>占用12KB的存储空间</strong>，虽然说，Redis 对 HeyperLogLog 进行了优化，在存储数据比较少的时候，采用了稀疏矩阵存储，只有在数据量变大，稀疏矩阵空间占用超过阈值时，才会转为空间为12KB的稠密矩阵；相比于成千、上亿的数据量，这小小的12KB，简直是太划算了；但是还是建议，不要将其用于数据量少，且频繁创建 HeyperLogLog 的场景，避免使用不当，造成资源消耗没减反增的不良效果。</p><p>功能所需命令：</p><ul><li>  <strong>PFADD</strong> key element [element …]：增加计数（统计UV）</li><li>  <strong>PFCOUNT</strong> key [key …]：获取计数（货物UV）</li><li>  <strong>PFMERGE</strong> destkey sourcekey [sourcekey …]：将多个 HyperLogLog 合并为一个 HyperLogLog（多个合起来统计）</li></ul><h3 id="Redis-cli-操作-2"><a href="#Redis-cli-操作-2" class="headerlink" title="Redis-cli 操作"></a>Redis-cli 操作</h3><pre><code># 添加三个用户的访问127.0.0.1:6379&gt; PFADD uv:page:1 user1 user2 user3(integer) 1# 获取UV数量127.0.0.1:6379&gt; PFCOUNT uv:page:1(integer) 3# 再添加三个用户的访问  user3是重复用户127.0.0.1:6379&gt; PFADD uv:page:1 user3 user4 user5(integer) 1# 获取UV数量 user3是重复用户 所以这里返回的是5127.0.0.1:6379&gt; PFCOUNT uv:page:1(integer) 5</code></pre><h3 id="SpringBoot操作HeyperLogLog"><a href="#SpringBoot操作HeyperLogLog" class="headerlink" title="SpringBoot操作HeyperLogLog"></a>SpringBoot操作HeyperLogLog</h3><p>模拟测试10000个用户访问id为2的页面</p><pre><code>import lombok.extern.slf4j.Slf4j;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.redis.core.RedisTemplate;/** * @author 一行Java * @title: HeyperLogLog 统计UV * @projectName ehang-spring-boot * @description: TODO * @date 2022/7/19 16:13 */@SpringBootTest@Slf4jpublic class UVTest &#123;    private final String KEY_UV_PAGE_PROFIX = &quot;uv:page:&quot;;    @Autowired    RedisTemplate redisTemplate;    @Test    public void uvTest() &#123;        Integer pageId = 2;        for (int i = 0; i &lt; 10000; i++) &#123;            uv(pageId, i);        &#125;        for (int i = 0; i &lt; 10000; i++) &#123;            uv(pageId, i);        &#125;        Long uv = getUv(pageId);        log.info(&quot;pageId:&#123;&#125; uv:&#123;&#125;&quot;, pageId, uv);    &#125;    /**     * 用户访问页面     * @param pageId     * @param userId     * @return     */    private Long uv(Integer pageId, Integer userId) &#123;        String key = KEY_UV_PAGE_PROFIX + pageId;        return redisTemplate.opsForHyperLogLog().add(key, userId);    &#125;    /**     * 统计页面的UV     * @param pageId     * @return     */    private Long getUv(Integer pageId) &#123;        String key = KEY_UV_PAGE_PROFIX + pageId;        return redisTemplate.opsForHyperLogLog().size(key);    &#125;&#125;</code></pre><p>日志输出</p><pre><code>pageId:2 uv:10023</code></pre><p>由于存在误差，这里访问的实际访问的数量是1万，统计出来的多了23个，在标准的误差（0.81%）范围内，加上UV数据不是必须要求准确，因此这个误差是可以接受的。</p><h2 id="去重（BloomFiler）"><a href="#去重（BloomFiler）" class="headerlink" title="去重（BloomFiler）"></a>去重（BloomFiler）</h2><p>通过上面HeyperLogLog的学习，我们掌握了一种<strong>不精准的去重计数</strong>方案，但是有没有发现，他没办法获取某个用户是否访问过；理想中，我们是希望有一个<code>PFEXISTS</code>的命令，来判断某个key是否存在，然而HeyperLogLog并没有；要想实现这一需求，就得 BloomFiler 上场了。</p><ul><li><p>什么是Bloom Filter？</p><p>  Bloom Filter是由Bloom在1970年提出的一种多哈希函数映射的快速查找算法。<br>  通常应用在一些需要快速判断某个元素是否属于集合，但是<strong>并不严格要求100%正确的场合</strong>。<br>  基于一种概率数据结构来实现，是一个有趣且强大的算法。</p></li></ul><p><strong>举个例子</strong>：假如你写了一个爬虫，用于爬取网络中的所有页面，当你拿到一个新的页面时，如何判断这个页面是否爬取过？</p><p><strong>普通做法</strong>：每爬取一个页面，往数据库插入一行数据，记录一下URL，每次拿到一个新的页面，就去数据库里面查询一下，存在就说明爬取过；</p><p><strong>普通做法的缺点</strong>：少量数据，用传统方案没啥问题，如果是海量数据，每次爬取前的检索，将会越来越慢；如果你的爬虫只关心内容，对来源数据不太关心的话，这部分数据的存储，也将消耗你很大的物理资源；</p><p>此时通过 BloomFiler 就能以很小的内存空间作为代价，即可轻松判断某个值是否存在。</p><p>同样，BloomFiler 也不那么精准，在默认参数情况下，是存在1%左右的误差；但是 BloomFiler 是允许通过error_rate（误差率）以及initial_size（预计大小）来设置他的误差比例</p><ul><li>  <strong>error_rate</strong>：误差率，越低，需要的空间就越大；</li><li>  <strong>initial_size</strong>：预计放入值的数量，当实际放入的数量大于设置的值时，误差率就会逐渐升高；所以为了避免误差率，可以提前做好估值，避免再次大的误差；</li></ul><h3 id="BloomFiler-安装"><a href="#BloomFiler-安装" class="headerlink" title="BloomFiler 安装"></a>BloomFiler 安装</h3><p>为了方便测试，这里使用 Docker 快速安装</p><pre><code>docker run -d -p 6379:6379 redislabs/rebloom</code></pre><p>功能所需的命令</p><ul><li>  <strong>bf.add</strong> 添加单个元素</li><li>  <strong>bf.madd</strong> 批量田间</li><li>  <strong>bf.exists</strong> 检测元素是否存在</li><li>  <strong>bf.mexists</strong> 批量检测</li></ul><h3 id="Redis-cli操作-1"><a href="#Redis-cli操作-1" class="headerlink" title="Redis-cli操作"></a>Redis-cli操作</h3><pre><code>127.0.0.1:6379&gt; bf.add web:crawler baidu(integer) 1127.0.0.1:6379&gt; bf.madd web:crawler tencent bing1) (integer) 12) (integer) 1127.0.0.1:6379&gt; bf.exists web:crawler baidu(integer) 1127.0.0.1:6379&gt; bf.mexists web:crawler baidu 1631) (integer) 12) (integer) 0</code></pre><h3 id="SpringBoot整合"><a href="#SpringBoot整合" class="headerlink" title="SpringBoot整合"></a>SpringBoot整合</h3><ul><li><p>工具类 RedisBloom</p><pre><code>  import org.springframework.beans.factory.annotation.Autowired;  import org.springframework.data.redis.core.StringRedisTemplate;  import org.springframework.data.redis.core.script.DefaultRedisScript;  import org.springframework.data.redis.core.script.RedisScript;  import org.springframework.stereotype.Component;  import java.util.Arrays;  import java.util.List;  /**   * redis布隆过滤器   *   * @author 一行Java   * @title: RedisBloom   * @projectName ehang-spring-boot   * @description: TODO   * @date 2022/7/19 17:03   */  @Component  public class RedisBloom &#123;      private static RedisScript&lt;Boolean&gt; bfreserveScript = new DefaultRedisScript&lt;&gt;(&quot;return redis.call(&#39;bf.reserve&#39;, KEYS[1], ARGV[1], ARGV[2])&quot;, Boolean.class);      private static RedisScript&lt;Boolean&gt; bfaddScript = new DefaultRedisScript&lt;&gt;(&quot;return redis.call(&#39;bf.add&#39;, KEYS[1], ARGV[1])&quot;, Boolean.class);      private static RedisScript&lt;Boolean&gt; bfexistsScript = new DefaultRedisScript&lt;&gt;(&quot;return redis.call(&#39;bf.exists&#39;, KEYS[1], ARGV[1])&quot;, Boolean.class);      private static String bfmaddScript = &quot;return redis.call(&#39;bf.madd&#39;, KEYS[1], %s)&quot;;      private static String bfmexistsScript = &quot;return redis.call(&#39;bf.mexists&#39;, KEYS[1], %s)&quot;;      @Autowired      private StringRedisTemplate redisTemplate;      /**       * 设置错误率和大小（需要在添加元素前调用，若已存在元素，则会报错）       * 错误率越低，需要的空间越大       *       * @param key       * @param errorRate   错误率，默认0.01       * @param initialSize 默认100，预计放入的元素数量，当实际数量超出这个数值时，误判率会上升，尽量估计一个准确数值再加上一定的冗余空间       * @return       */      public Boolean bfreserve(String key, double errorRate, int initialSize) &#123;          return redisTemplate.execute(bfreserveScript, Arrays.asList(key), String.valueOf(errorRate), String.valueOf(initialSize));      &#125;      /**       * 添加元素       *       * @param key       * @param value       * @return true表示添加成功，false表示添加失败（存在时会返回false）       */      public Boolean bfadd(String key, String value) &#123;          return redisTemplate.execute(bfaddScript, Arrays.asList(key), value);      &#125;      /**       * 查看元素是否存在（判断为存在时有可能是误判，不存在是一定不存在）       *       * @param key       * @param value       * @return true表示存在，false表示不存在       */      public Boolean bfexists(String key, String value) &#123;          return redisTemplate.execute(bfexistsScript, Arrays.asList(key), value);      &#125;      /**       * 批量添加元素       *       * @param key       * @param values       * @return 按序 1表示添加成功，0表示添加失败       */      public List&lt;Integer&gt; bfmadd(String key, String... values) &#123;          return (List&lt;Integer&gt;) redisTemplate.execute(this.generateScript(bfmaddScript, values), Arrays.asList(key), values);      &#125;      /**       * 批量检查元素是否存在（判断为存在时有可能是误判，不存在是一定不存在）       *       * @param key       * @param values       * @return 按序 1表示存在，0表示不存在       */      public List&lt;Integer&gt; bfmexists(String key, String... values) &#123;          return (List&lt;Integer&gt;) redisTemplate.execute(this.generateScript(bfmexistsScript, values), Arrays.asList(key), values);      &#125;      private RedisScript&lt;List&gt; generateScript(String script, String[] values) &#123;          StringBuilder sb = new StringBuilder();          for (int i = 1; i &lt;= values.length; i++) &#123;              if (i != 1) &#123;                  sb.append(&quot;,&quot;);              &#125;              sb.append(&quot;ARGV[&quot;).append(i).append(&quot;]&quot;);          &#125;          return new DefaultRedisScript&lt;&gt;(String.format(script, sb.toString()), List.class);      &#125;  &#125;</code></pre></li></ul><ul><li><p>测试</p><pre><code>  import lombok.extern.slf4j.Slf4j;  import org.junit.jupiter.api.Test;  import org.springframework.beans.factory.annotation.Autowired;  import org.springframework.boot.test.context.SpringBootTest;  import org.springframework.data.redis.core.RedisTemplate;  import java.util.List;  /**   * @author 一行Java   * @title: BFTest   * @projectName ehang-spring-boot   * @description: TODO   * @date 2022/7/19 17:04   */  @SpringBootTest  @Slf4j  public class BFTest &#123;      private final String KEY_WEB_CRAWLER = &quot;web:crawler1&quot;;      @Autowired      RedisBloom bloom;      @Autowired      RedisTemplate redisTemplate;</code></pre></li></ul><pre><code>        @Test        public void test() &#123;            Boolean hasKey = redisTemplate.hasKey(KEY_WEB_CRAWLER);            log.info(&quot;bloom hasKey:&#123;&#125;&quot;, hasKey);            if (!hasKey) &#123;                // 不存在的时候  再去初始化                Boolean bfreserve = bloom.bfreserve(KEY_WEB_CRAWLER, 0.0001, 10000);                log.info(&quot;bloom bfreserve:&#123;&#125;&quot;, bfreserve);            &#125;            List&lt;Integer&gt; madd = bloom.bfmadd(KEY_WEB_CRAWLER, &quot;baidu&quot;, &quot;google&quot;);            log.info(&quot;bloom bfmadd:&#123;&#125;&quot;, madd);            Boolean baidu = bloom.bfexists(KEY_WEB_CRAWLER, &quot;baidu&quot;);            log.info(&quot;bloom bfexists baidu:&#123;&#125;&quot;, baidu);            Boolean bing = bloom.bfexists(KEY_WEB_CRAWLER, &quot;bing&quot;);            log.info(&quot;bloom bfexists bing:&#123;&#125;&quot;, bing);        &#125;    &#125;日志输出    com.ehang.redis.bloom_filter.BFTest      : bloom hasKey:false    com.ehang.redis.bloom_filter.BFTest      : bloom bfreserve:true    com.ehang.redis.bloom_filter.BFTest      : bloom bfmadd:[1, 1]    com.ehang.redis.bloom_filter.BFTest      : bloom bfexists baidu:true    com.ehang.redis.bloom_filter.BFTest      : bloom bfexists bing:false</code></pre><h2 id="用户签到（BitMap）"><a href="#用户签到（BitMap）" class="headerlink" title="用户签到（BitMap）"></a>用户签到（BitMap）</h2><p>很多APP为了拉动用户活跃度，往往都会做一些活动，比如连续签到领积分/礼包等等</p><p><img src="https://img-blog.csdnimg.cn/img_convert/569538054edab81cad99406f34cad33f.png"></p><p><strong>传统做法</strong>：用户每次签到时，往是数据库插入一条签到数据，展示的时候，把本月（或者指定周期）的签到数据获取出来，用于判断用户是否签到、以及连续签到情况；此方式，简单，理解容易；</p><p><strong>Redis做法</strong>：由于签到数据的关注点就2个：是否签到（0/1）、连续性，因此就完全可以利用BitMap（位图）来实现；</p><p><img src="https://img-blog.csdnimg.cn/img_convert/dfc6921d1f159dd343f617905b66f031.png" alt="一个月的签到情况，4个字节就记录了（图源：网络）"></p><p>如上图所示，将一个月的31天，用31个位（4个字节）来表示，偏移量（offset）代表当前是第几天，0/1表示当前是否签到，连续签到只需从右往左校验连续为1的位数；</p><p>由于String类型的最大上限是512M，转换为bit则是2^32个bit位。</p><p>所需命令：</p><ul><li><p>  <strong>SETBIT</strong> key offset value：向指定位置offset存入一个0或1</p></li><li><p>  <strong>GETBIT</strong> key offset：获取指定位置offset的bit值</p></li><li><p>  <strong>BITCOUNT</strong> key [start] [end]：统计BitMap中值为1的bit位的数量</p></li><li><p><strong>BITFIELD</strong>: 操作（查询，修改，自增）BitMap中bit 数组中的指定位置offset的值</p><p>  这里最不容易理解的就是：BITFIELD，详情可参考：<a href="https://deepinout.com/redis-cmd/redis-bitmap-cmd/redis-cmd-bitfield.html">https://deepinout.com/redis-cmd/redis-bitmap-cmd/redis-cmd-bitfield.html</a> 而且这部分还必须理解了，否则，该需求的核心部分就没办法理解了；</p></li></ul><p>需求：假如当前为8月4号，检测本月的签到情况，用户分别于1、3、4号签到过</p><h3 id="Redis-cli-操作："><a href="#Redis-cli-操作：" class="headerlink" title="Redis-cli 操作："></a>Redis-cli 操作：</h3><pre><code># 8月1号的签到127.0.0.1:6379&gt; SETBIT RangeId:Sign:1:8899 0 1(integer) 1# 8月3号的签到127.0.0.1:6379&gt; SETBIT RangeId:Sign:1:8899 2 1(integer) 1# 8月4号的签到127.0.0.1:6379&gt; SETBIT RangeId:Sign:1:8899 3 1(integer) 1# 查询各天的签到情况# 查询1号127.0.0.1:6379&gt; GETBIT RangeId:Sign:1:8899 0(integer) 1# 查询2号127.0.0.1:6379&gt; GETBIT RangeId:Sign:1:8899 1(integer) 0# 查询3号127.0.0.1:6379&gt; GETBIT RangeId:Sign:1:8899 2(integer) 1# 查询4号127.0.0.1:6379&gt; GETBIT RangeId:Sign:1:8899 3(integer) 1# 查询指定区间的签到情况127.0.0.1:6379&gt; BITFIELD RangeId:Sign:1:8899 get u4 01) (integer) 11</code></pre><blockquote><p>1-4号的签到情况为：1011（二进制） ==&gt; 11（十进制）</p></blockquote><h3 id="是否签到、连续签到判断"><a href="#是否签到、连续签到判断" class="headerlink" title="是否签到、连续签到判断"></a>是否签到、连续签到判断</h3><p>签到功能中，最不好理解的就是是否签到、连续签到的判断，在下面SpringBoot代码中，就是通过这样的：<code>signFlag &gt;&gt; 1 &lt;&lt; 1 != signFlag</code>来判断的，稍微有一点不好理解，在这里提前讲述一下；</p><p>上面测试了1-4号的签到情况，通过<code>BITFIELD</code>获取出来signFlag = 11（十进制） = 1011（二进制）；</p><p>连续签到的判断依据就是：<strong>从右往左计算连续为1的BIT个数</strong>，二进制 1011 表示连续签到的天数就是2天，2天的计算过程如下：</p><ul><li><p>  第一步，获取signFlag</p></li><li><p>  第二步，循环天数，以上测试用例是4天的签到情况，for循环也就是4次</p></li><li><p>第三步，从右往左循环判断</p><p>  <strong>连续签到</strong>：遇到第一个false的时候，终止并得到连续天数</p><p>  <strong>签到详情</strong>：循环所有天数，true就表示当前签到了，false表示当天未签到；</p><p>  第一次循环</p><pre><code>  signFlag = 1011  signFlag &gt;&gt; 1   结果： 101  signFlag &lt;&lt; 1   结果：1010  1010 != signFlag（1011） 结果：true  //4号已签到，说明连续签到1天  signFlag &gt;&gt;= 1  结果： 101   // 此时signFlag = 101</code></pre></li></ul><pre><code>第二次循环    signFlag = 101  // 前一次循环计算的结果    signFlag &gt;&gt; 1   结果： 10    signFlag &lt;&lt; 1   结果：100    100 != signFlag（101） 结果：true  //3号已签到，说明连续签到2天    signFlag &gt;&gt;= 1  结果： 10   // 此时signFlag = 10第三次循环    signFlag = 10  // 前一次循环计算的结果    signFlag &gt;&gt; 1   结果： 1    signFlag &lt;&lt; 1   结果：10    10 != signFlag（10） 结果：false  //2号未签到，说明连续签到从这里就断了     signFlag &gt;&gt;= 1  结果： 1   // 此时signFlag = 1到这一步，遇到第一个false，说明连续签到中断；第四次循环：    signFlag = 1  // 前一次循环计算的结果    signFlag &gt;&gt; 1   结果： 0    signFlag &lt;&lt; 1   结果： 0    0 != signFlag（1） 结果：true  //1号已签到到此，根据`BITFIELD`获取出来11（十进制），就能得到1、3、4号已签到，2号未签到；连续签到2天；</code></pre><p>理解上面的逻辑之后，再来看下面的SpringBoot代码，就会容易很多了；</p><h3 id="SpringBoot实现签到"><a href="#SpringBoot实现签到" class="headerlink" title="SpringBoot实现签到"></a>SpringBoot实现签到</h3><p>签到的方式一般就两种，按月（周）/ 自定义周期，下面将两种方式的签到全部列举出来，以供大家参考：</p><h4 id="按月签到"><a href="#按月签到" class="headerlink" title="按月签到"></a>按月签到</h4><p>签到工具类：</p><pre><code>import lombok.extern.slf4j.Slf4j;import org.joda.time.DateTime;import org.joda.time.format.DateTimeFormat;import org.joda.time.format.DateTimeFormatter;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.connection.BitFieldSubCommands;import org.springframework.data.redis.core.RedisCallback;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.stereotype.Service;import org.springframework.util.CollectionUtils;import java.util.HashMap;import java.util.List;import java.util.Map;/** * @author 一行Java * @title: 按月签到 * @projectName ehang-spring-boot * @description: TODO * @date 2022/7/18 18:28 */@Slf4j@Servicepublic class SignByMonthServiceImpl &#123;    @Autowired    StringRedisTemplate stringRedisTemplate;    private int dayOfMonth() &#123;        DateTime dateTime = new DateTime();        return dateTime.dayOfMonth().get();    &#125;    /**     * 按照月份和用户ID生成用户签到标识 UserId:Sign:560:2021-08     *     * @param userId 用户id     * @return     */    private String signKeyWitMouth(String userId) &#123;        DateTime dateTime = new DateTime();        DateTimeFormatter fmt = DateTimeFormat.forPattern(&quot;yyyy-MM&quot;);        StringBuilder builder = new StringBuilder(&quot;UserId:Sign:&quot;);        builder.append(userId).append(&quot;:&quot;)                .append(dateTime.toString(fmt));        return builder.toString();    &#125;    /**     * 设置标记位     * 标记是否签到     *     * @param key     * @param offset     * @param tag     * @return     */    public Boolean sign(String key, long offset, boolean tag) &#123;        return this.stringRedisTemplate.opsForValue().setBit(key, offset, tag);    &#125;    /**     * 统计计数     *     * @param key 用户标识     * @return     */    public long bitCount(String key) &#123;        return stringRedisTemplate.execute((RedisCallback&lt;Long&gt;) redisConnection -&gt; redisConnection.bitCount(key.getBytes()));    &#125;    /**     * 获取多字节位域     */    public List&lt;Long&gt; bitfield(String buildSignKey, int limit, long offset) &#123;        return this.stringRedisTemplate                .opsForValue()                .bitField(buildSignKey, BitFieldSubCommands.create().get(BitFieldSubCommands.BitFieldType.unsigned(limit)).valueAt(offset));    &#125;    /**     * 判断是否被标记     *     * @param key     * @param offest     * @return     */    public Boolean container(String key, long offest) &#123;        return this.stringRedisTemplate.opsForValue().getBit(key, offest);    &#125;    /**     * 用户今天是否签到     *     * @param userId     * @return     */    public int checkSign(String userId) &#123;        DateTime dateTime = new DateTime();        String signKey = this.signKeyWitMouth(userId);        int offset = dateTime.getDayOfMonth() - 1;        int value = this.container(signKey, offset) ? 1 : 0;        return value;    &#125;    /**     * 查询用户当月签到日历     *     * @param userId     * @return     */    public Map&lt;String, Boolean&gt; querySignedInMonth(String userId) &#123;        DateTime dateTime = new DateTime();        int lengthOfMonth = dateTime.dayOfMonth().getMaximumValue();        Map&lt;String, Boolean&gt; signedInMap = new HashMap&lt;&gt;(dateTime.getDayOfMonth());        String signKey = this.signKeyWitMouth(userId);        List&lt;Long&gt; bitfield = this.bitfield(signKey, lengthOfMonth, 0);        if (!CollectionUtils.isEmpty(bitfield)) &#123;            long signFlag = bitfield.get(0) == null ? 0 : bitfield.get(0);            DateTimeFormatter fmt = DateTimeFormat.forPattern(&quot;yyyy-MM-dd&quot;);            for (int i = lengthOfMonth; i &gt; 0; i--) &#123;                DateTime dateTime1 = dateTime.withDayOfMonth(i);                signedInMap.put(dateTime1.toString(fmt), signFlag &gt;&gt; 1 &lt;&lt; 1 != signFlag);                signFlag &gt;&gt;= 1;            &#125;        &#125;        return signedInMap;    &#125;    /**     * 用户签到     *     * @param userId     * @return     */    public boolean signWithUserId(String userId) &#123;        int dayOfMonth = this.dayOfMonth();        String signKey = this.signKeyWitMouth(userId);        long offset = (long) dayOfMonth - 1;        boolean re = false;        if (Boolean.TRUE.equals(this.sign(signKey, offset, Boolean.TRUE))) &#123;            re = true;        &#125;        // 查询用户连续签到次数,最大连续次数为7天        long continuousSignCount = this.queryContinuousSignCount(userId, 7);        return re;    &#125;    /**     * 统计当前月份一共签到天数     *     * @param userId     */    public long countSignedInDayOfMonth(String userId) &#123;        String signKey = this.signKeyWitMouth(userId);        return this.bitCount(signKey);    &#125;    /**     * 查询用户当月连续签到次数     *     * @param userId     * @return     */    public long queryContinuousSignCountOfMonth(String userId) &#123;        int signCount = 0;        String signKey = this.signKeyWitMouth(userId);        int dayOfMonth = this.dayOfMonth();        List&lt;Long&gt; bitfield = this.bitfield(signKey, dayOfMonth, 0);        if (!CollectionUtils.isEmpty(bitfield)) &#123;            long signFlag = bitfield.get(0) == null ? 0 : bitfield.get(0);            DateTime dateTime = new DateTime();            // 连续不为0即为连续签到次数，当天未签到情况下            for (int i = 0; i &lt; dateTime.getDayOfMonth(); i++) &#123;                if (signFlag &gt;&gt; 1 &lt;&lt; 1 == signFlag) &#123;                    if (i &gt; 0) break;                &#125; else &#123;                    signCount += 1;                &#125;                signFlag &gt;&gt;= 1;            &#125;        &#125;        return signCount;    &#125;    /**     * 以7天一个周期连续签到次数     *     * @param period 周期     * @return     */    public long queryContinuousSignCount(String userId, Integer period) &#123;        //查询目前连续签到次数        long count = this.queryContinuousSignCountOfMonth(userId);        //按最大连续签到取余        if (period != null &amp;&amp; period &lt; count) &#123;            long num = count % period;            if (num == 0) &#123;                count = period;            &#125; else &#123;                count = num;            &#125;        &#125;        return count;    &#125;&#125;</code></pre><p>测试类：</p><pre><code>import lombok.extern.slf4j.Slf4j;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.redis.core.StringRedisTemplate;import java.util.Map;/** * @author 一行Java * @title: SignTest2 * @projectName ehang-spring-boot * @description: TODO * @date 2022/7/19 12:06 */@SpringBootTest@Slf4jpublic class SignTest2 &#123;    @Autowired    private SignByMonthServiceImpl signByMonthService;    @Autowired    private StringRedisTemplate redisTemplate;    /**     * 测试用户按月签到     */    @Test    public void querySignDay() &#123;        //模拟用户签到        //for(int i=5;i&lt;19;i++)&#123;        redisTemplate.opsForValue().setBit(&quot;UserId:Sign:560:2022-08&quot;, 0, true);        //&#125;        System.out.println(&quot;560用户今日是否已签到:&quot; + this.signByMonthService.checkSign(&quot;560&quot;));        Map&lt;String, Boolean&gt; stringBooleanMap = this.signByMonthService.querySignedInMonth(&quot;560&quot;);        System.out.println(&quot;本月签到情况:&quot;);        for (Map.Entry&lt;String, Boolean&gt; entry : stringBooleanMap.entrySet()) &#123;            System.out.println(entry.getKey() + &quot;: &quot; + (entry.getValue() ? &quot;√&quot; : &quot;-&quot;));        &#125;        long countSignedInDayOfMonth = this.signByMonthService.countSignedInDayOfMonth(&quot;560&quot;);        System.out.println(&quot;本月一共签到:&quot; + countSignedInDayOfMonth + &quot;天&quot;);        System.out.println(&quot;目前连续签到:&quot; + this.signByMonthService.queryContinuousSignCount(&quot;560&quot;, 7) + &quot;天&quot;);    &#125;&#125;</code></pre><p>执行日志：</p><pre><code>c.e.r.bitmap_sign_by_month.SignTest2     : 560用户今日是否已签到:0c.e.r.bitmap_sign_by_month.SignTest2     : 本月签到情况:c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-12: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-11: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-10: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-31: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-30: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-19: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-18: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-17: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-16: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-15: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-14: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-13: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-23: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-01: √c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-22: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-21: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-20: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-09: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-08: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-29: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-07: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-28: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-06: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-27: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-05: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-26: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-04: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-25: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-03: √c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-24: -c.e.r.bitmap_sign_by_month.SignTest2     : 2022-08-02: -c.e.r.bitmap_sign_by_month.SignTest2     : 本月一共签到:2天c.e.r.bitmap_sign_by_month.SignTest2     : 目前连续签到:1天</code></pre><h4 id="指定时间签到"><a href="#指定时间签到" class="headerlink" title="指定时间签到"></a>指定时间签到</h4><p>签到工具类：</p><pre><code>package com.ehang.redis.bitmap_sign_by_range;import lombok.extern.slf4j.Slf4j;import org.joda.time.DateTime;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.connection.BitFieldSubCommands;import org.springframework.data.redis.core.RedisCallback;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.stereotype.Service;import org.springframework.util.CollectionUtils;import java.time.LocalDateTime;import java.time.format.DateTimeFormatter;import java.util.HashMap;import java.util.List;import java.util.Map;/** * @author 一行Java * @title: SignByRangeServiceImpl * @projectName ehang-spring-boot * @description: TODO * @date 2022/7/19 12:27 */@Slf4j@Servicepublic class SignByRangeServiceImpl &#123;    @Autowired    StringRedisTemplate stringRedisTemplate;    /**     * 根据区间的id 以及用户id 拼接key     *     * @param rangeId 区间ID 一般是指定活动的ID等     * @param userId  用户的ID     * @return     */    private String signKey(Integer rangeId, Integer userId) &#123;        StringBuilder builder = new StringBuilder(&quot;RangeId:Sign:&quot;);        builder.append(rangeId).append(&quot;:&quot;)                .append(userId);        return builder.toString();    &#125;    /**     * 获取当前时间与起始时间的间隔天数     *     * @param start 起始时间     * @return     */    private int intervalTime(LocalDateTime start) &#123;        return (int) (LocalDateTime.now().toLocalDate().toEpochDay() - start.toLocalDate().toEpochDay());    &#125;    /**     * 设置标记位     * 标记是否签到     *     * @param key    签到的key     * @param offset 偏移量 一般是指当前时间离起始时间（活动开始）的天数     * @param tag    是否签到  true:签到  false:未签到     * @return     */    private Boolean setBit(String key, long offset, boolean tag) &#123;        return this.stringRedisTemplate.opsForValue().setBit(key, offset, tag);    &#125;    /**     * 统计计数     *     * @param key 统计的key     * @return     */    private long bitCount(String key) &#123;        return stringRedisTemplate.execute((RedisCallback&lt;Long&gt;) redisConnection -&gt; redisConnection.bitCount(key.getBytes()));    &#125;    /**     * 获取多字节位域     *     * @param key    缓存的key     * @param limit  获取多少     * @param offset 偏移量是多少     * @return     */    private List&lt;Long&gt; bitfield(String key, int limit, long offset) &#123;        return this.stringRedisTemplate                .opsForValue()                .bitField(key, BitFieldSubCommands.create().get(BitFieldSubCommands.BitFieldType.unsigned(limit)).valueAt(offset));    &#125;    /**     * 判断是否签到     *     * @param key    缓存的key     * @param offest 偏移量 指当前时间距离起始时间的天数     * @return     */    private Boolean container(String key, long offest) &#123;        return this.stringRedisTemplate.opsForValue().getBit(key, offest);    &#125;    /**     * 根据起始时间进行签到     *     * @param rangeId     * @param userId     * @param start     * @return     */    public Boolean sign(Integer rangeId, Integer userId, LocalDateTime start) &#123;        int offset = intervalTime(start);        String key = signKey(rangeId, userId);        return setBit(key, offset, true);    &#125;    /**     * 根据偏移量签到     *     * @param rangeId     * @param userId     * @param offset     * @return     */    public Boolean sign(Integer rangeId, Integer userId, long offset) &#123;        String key = signKey(rangeId, userId);        return setBit(key, offset, true);    &#125;    /**     * 用户今天是否签到     *     * @param userId     * @return     */    public Boolean checkSign(Integer rangeId, Integer userId, LocalDateTime start) &#123;        long offset = intervalTime(start);        String key = this.signKey(rangeId, userId);        return this.container(key, offset);    &#125;    /**     * 统计当前月份一共签到天数     *     * @param userId     */    public long countSigned(Integer rangeId, Integer userId) &#123;        String signKey = this.signKey(rangeId, userId);        return this.bitCount(signKey);    &#125;    public Map&lt;String, Boolean&gt; querySigned(Integer rangeId, Integer userId, LocalDateTime start) &#123;        int days = intervalTime(start);        Map&lt;String, Boolean&gt; signedInMap = new HashMap&lt;&gt;(days);        String signKey = this.signKey(rangeId, userId);        List&lt;Long&gt; bitfield = this.bitfield(signKey, days + 1, 0);        if (!CollectionUtils.isEmpty(bitfield)) &#123;            long signFlag = bitfield.get(0) == null ? 0 : bitfield.get(0);            DateTimeFormatter fmt = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;);            for (int i = days; i &gt;= 0; i--) &#123;                LocalDateTime localDateTime = start.plusDays(i);                signedInMap.put(localDateTime.format(fmt), signFlag &gt;&gt; 1 &lt;&lt; 1 != signFlag);                signFlag &gt;&gt;= 1;            &#125;        &#125;        return signedInMap;    &#125;    /**     * 查询用户当月连续签到次数     *     * @param userId     * @return     */    public long queryContinuousSignCount(Integer rangeId, Integer userId, LocalDateTime start) &#123;        int signCount = 0;        String signKey = this.signKey(rangeId, userId);        int days = this.intervalTime(start);        List&lt;Long&gt; bitfield = this.bitfield(signKey, days + 1, 0);        if (!CollectionUtils.isEmpty(bitfield)) &#123;            long signFlag = bitfield.get(0) == null ? 0 : bitfield.get(0);            DateTime dateTime = new DateTime();            // 连续不为0即为连续签到次数，当天未签到情况下            for (int i = 0; i &lt; dateTime.getDayOfMonth(); i++) &#123;                if (signFlag &gt;&gt; 1 &lt;&lt; 1 == signFlag) &#123;                    if (i &gt; 0) break;                &#125; else &#123;                    signCount += 1;                &#125;                signFlag &gt;&gt;= 1;            &#125;        &#125;        return signCount;    &#125;&#125;</code></pre><p>测试工具类：</p><pre><code>package com.ehang.redis.bitmap_sign_by_range;import lombok.extern.slf4j.Slf4j;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import java.time.LocalDateTime;import java.time.format.DateTimeFormatter;import java.util.Map;/** * @author 一行Java * @title: SignTest * @projectName ehang-spring-boot * @description: TODO * @date 2022/7/18 16:11 */@SpringBootTest@Slf4jpublic class SignTest &#123;    @Autowired    SignByRangeServiceImpl signByRangeService;    @Test    void test() &#123;        DateTimeFormatter isoDateTime = DateTimeFormatter.ISO_DATE_TIME;        // 活动开始时间        LocalDateTime start = LocalDateTime.of(2022, 8, 1, 1, 0, 0);        Integer rangeId = 1;        Integer userId = 8899;        log.info(&quot;签到开始时间: &#123;&#125;&quot;, start.format(isoDateTime));        log.info(&quot;活动ID: &#123;&#125; 用户ID: &#123;&#125;&quot;, rangeId, userId);        // 手动指定偏移量签到        signByRangeService.sign(rangeId, userId, 0);        // 判断是否签到        Boolean signed = signByRangeService.checkSign(rangeId, userId, start);        log.info(&quot;今日是否签到: &#123;&#125;&quot;, signed ? &quot;√&quot; : &quot;-&quot;);        // 签到        Boolean sign = signByRangeService.sign(rangeId, userId, start);        log.info(&quot;签到操作之前的签到状态：&#123;&#125; （-：表示今日第一次签到，√：表示今天已经签到过了）&quot;, sign ? &quot;√&quot; : &quot;-&quot;);        // 签到总数        long countSigned = signByRangeService.countSigned(rangeId, userId);        log.info(&quot;总共签到: &#123;&#125; 天&quot;, countSigned);        // 连续签到的次数        long continuousSignCount = signByRangeService.queryContinuousSignCount(rangeId, userId, start);        log.info(&quot;连续签到: &#123;&#125; 天&quot;, continuousSignCount);        // 签到的详情        Map&lt;String, Boolean&gt; stringBooleanMap = signByRangeService.querySigned(rangeId, userId, start);        for (Map.Entry&lt;String, Boolean&gt; entry : stringBooleanMap.entrySet()) &#123;            log.info(&quot;签到详情&gt; &#123;&#125; : &#123;&#125;&quot;, entry.getKey(), (entry.getValue() ? &quot;√&quot; : &quot;-&quot;));        &#125;    &#125;&#125;</code></pre><p>输出日志：</p><pre><code>签到开始时间: 2022-08-01T01:00:00活动ID: 1 用户ID: 8899今日是否签到: √签到操作之前的签到状态：√ （-：表示今日第一次签到，√：表示今天已经签到过了）总共签到: 3 天连续签到: 2 天签到详情&gt; 2022-08-01 : √签到详情&gt; 2022-08-04 : √签到详情&gt; 2022-08-03 : √签到详情&gt; 2022-08-02 : -</code></pre><h2 id="GEO搜附近"><a href="#GEO搜附近" class="headerlink" title="GEO搜附近"></a>GEO搜附近</h2><p>很多生活类的APP都具备一个搜索附近的功能，比如美团搜索附近的商家；</p><p><img src="https://img-blog.csdnimg.cn/img_convert/3431c43e788c0f6b0399a52892ab49ae.png" alt="网图"></p><p>如果自己想要根据经纬度来实现一个搜索附近的功能，是非常麻烦的；但是Redis 在3.2的版本新增了Redis GEO，用于存储地址位置信息，并对支持范围搜索；基于GEO就能轻松且快速的开发一个搜索附近的功能；</p><h3 id="GEO-API-及Redis-cli-操作："><a href="#GEO-API-及Redis-cli-操作：" class="headerlink" title="GEO API 及Redis-cli 操作："></a>GEO API 及Redis-cli 操作：</h3><ul><li><p><strong>geoadd</strong>：新增位置坐标。</p><pre><code>  127.0.0.1:6379&gt; GEOADD drinks 116.62445 39.86206 starbucks 117.3514785 38.7501247 yidiandian 116.538542 39.75412 xicha  (integer) 3</code></pre></li></ul><ul><li><p><strong>geopos</strong>：获取位置坐标。</p><pre><code>  127.0.0.1:6379&gt; GEOPOS drinks starbucks  1) 1) &quot;116.62445157766342163&quot;     2) &quot;39.86206038535793539&quot;  127.0.0.1:6379&gt; GEOPOS drinks starbucks yidiandian mxbc  1) 1) &quot;116.62445157766342163&quot;     2) &quot;39.86206038535793539&quot;  2) 1) &quot;117.35148042440414429&quot;     2) &quot;38.75012383773680114&quot;  3) (nil)</code></pre></li></ul><ul><li><p><strong>geodist</strong>：计算两个位置之间的距离。</p><p>  单位参数：</p><ul><li><p>  m ：米，默认单位。</p></li><li><p>  km ：千米。</p></li><li><p>  mi ：英里。</p></li><li><p>ft ：英尺。</p><p>  127.0.0.1:6379&gt; GEODIST drinks starbucks yidiandian<br>  “138602.4133”<br>  127.0.0.1:6379&gt; GEODIST drinks starbucks xicha<br>  “14072.1255”<br>  127.0.0.1:6379&gt; GEODIST drinks starbucks xicha m<br>  “14072.1255”<br>  127.0.0.1:6379&gt; GEODIST drinks starbucks xicha km<br>  “14.0721”</p></li></ul></li></ul><ul><li><p><strong>georadius</strong>：根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。</p><p>  参数说明</p><ul><li><p>  m ：米，默认单位。</p></li><li><p>  km ：千米。</p></li><li><p>  mi ：英里。</p></li><li><p>  ft ：英尺。</p></li><li><p>  WITHDIST: 在返回位置元素的同时， 将位置元素与中心之间的距离也一并返回。</p></li><li><p>  WITHCOORD: 将位置元素的经度和纬度也一并返回。</p></li><li><p>  WITHHASH: 以 52 位有符号整数的形式， 返回位置元素经过原始 geohash 编码的有序集合分值。 这个选项主要用于底层应用或者调试， 实际中的作用并不大。</p></li><li><p>  COUNT 限定返回的记录数。</p></li><li><p>  ASC: 查找结果根据距离从近到远排序。</p></li><li><p>DESC: 查找结果根据从远到近排序。</p><p>  127.0.0.1:6379&gt; GEORADIUS drinks 116 39 100 km WITHDIST</p><ol><li><ol><li>“xicha”</li><li>“95.8085”</li></ol></li></ol><p>  127.0.0.1:6379&gt; GEORADIUS drinks 116 39 100 km WITHDIST WITHCOORD</p><ol><li><ol><li>“xicha”</li><li>“95.8085”</li><li><ol><li>“116.53854042291641235”</li><li>“39.75411928478748536”</li></ol></li></ol></li></ol><p>  127.0.0.1:6379&gt; GEORADIUS drinks 116 39 100 km WITHDIST WITHCOORD WITHHASH</p><ol><li><ol><li>“xicha”</li><li>“95.8085”</li><li>(integer) 4069151800882301</li><li><ol><li>“116.53854042291641235”</li><li>“39.75411928478748536”</li></ol></li></ol></li></ol><p>  127.0.0.1:6379&gt; GEORADIUS drinks 116 39 120 km WITHDIST WITHCOORD  COUNT 1</p><ol><li><ol><li>“xicha”</li><li>“95.8085”</li><li><ol><li>“116.53854042291641235”</li><li>“39.75411928478748536”</li></ol></li></ol></li></ol><p>  127.0.0.1:6379&gt; GEORADIUS drinks 116 39 120 km WITHDIST WITHCOORD  COUNT 1 ASC</p><ol><li><ol><li>“xicha”</li><li>“95.8085”</li><li><ol><li>“116.53854042291641235”</li><li>“39.75411928478748536”</li></ol></li></ol></li></ol><p>  127.0.0.1:6379&gt; GEORADIUS drinks 116 39 120 km WITHDIST WITHCOORD  COUNT 1 DESC</p><ol><li><ol><li>“starbucks”</li><li>“109.8703”</li><li><ol><li>“116.62445157766342163”</li><li>“39.86206038535793539”</li></ol></li></ol></li></ol></li></ul></li></ul><ul><li><p><strong>georadiusbymember</strong>：根据储存在位置集合里面的某个地点获取指定范围内的地理位置集合。</p><p>  功能和上面的georadius类似，只是georadius是以经纬度坐标为中心，这个是以某个地点为中心；</p></li><li><p><strong>geohash</strong>：返回一个或多个位置对象的 geohash 值。</p><pre><code>  127.0.0.1:6379&gt; GEOHASH drinks starbucks xicha  1) &quot;wx4fvbem6d0&quot;  2) &quot;wx4f5vhb8b0&quot;</code></pre></li></ul><h3 id="SpringBoot-操作-1"><a href="#SpringBoot-操作-1" class="headerlink" title="SpringBoot 操作"></a>SpringBoot 操作</h3><p>通过SpringBoot操作GEO的示例如下</p><pre><code>import lombok.extern.slf4j.Slf4j;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.geo.*;import org.springframework.data.redis.connection.RedisGeoCommands;import org.springframework.data.redis.core.RedisTemplate;import java.util.List;/** * @author 一行Java * @title: GEOTest * @projectName ehang-spring-boot * @description: TODO * @date 2022/7/28 17:29 */@SpringBootTest@Slf4jpublic class GEOTest &#123;    private final String KEY = &quot;geo:drinks&quot;;    @Autowired    RedisTemplate redisTemplate;    @Test    public void test() &#123;        add(&quot;starbucks&quot;, new Point(116.62445, 39.86206));        add(&quot;yidiandian&quot;, new Point(117.3514785, 38.7501247));        add(&quot;xicha&quot;, new Point(116.538542, 39.75412));        get(&quot;starbucks&quot;, &quot;yidiandian&quot;, &quot;xicha&quot;);        GeoResults nearByXY = getNearByXY(new Point(116, 39), new Distance(120, Metrics.KILOMETERS));        List&lt;GeoResult&gt; content = nearByXY.getContent();        for (GeoResult geoResult : content) &#123;            log.info(&quot;&#123;&#125;&quot;, geoResult.getContent());        &#125;        GeoResults nearByPlace = getNearByPlace(&quot;starbucks&quot;, new Distance(120, Metrics.KILOMETERS));        content = nearByPlace.getContent();        for (GeoResult geoResult : content) &#123;            log.info(&quot;&#123;&#125;&quot;, geoResult.getContent());        &#125;        getGeoHash(&quot;starbucks&quot;, &quot;yidiandian&quot;, &quot;xicha&quot;);        del(&quot;yidiandian&quot;, &quot;xicha&quot;);    &#125;    private void add(String name, Point point) &#123;        Long add = redisTemplate.opsForGeo().add(KEY, point, name);        log.info(&quot;成功添加名称：&#123;&#125; 的坐标信息信息：&#123;&#125;&quot;, name, point);    &#125;    private void get(String... names) &#123;        List&lt;Point&gt; position = redisTemplate.opsForGeo().position(KEY, names);        log.info(&quot;获取名称为：&#123;&#125; 的坐标信息：&#123;&#125;&quot;, names, position);    &#125;    private void del(String... names) &#123;        Long remove = redisTemplate.opsForGeo().remove(KEY, names);        log.info(&quot;删除名称为：&#123;&#125; 的坐标信息数量：&#123;&#125;&quot;, names, remove);    &#125;    /**     * 根据坐标 获取指定范围的位置     *     * @param point     * @param distance     * @return     */    private GeoResults getNearByXY(Point point, Distance distance) &#123;        Circle circle = new Circle(point, distance);        RedisGeoCommands.GeoRadiusCommandArgs args = RedisGeoCommands.GeoRadiusCommandArgs.                newGeoRadiusArgs().                includeDistance(). // 包含距离                includeCoordinates(). // 包含坐标                sortAscending(). // 排序 还可选sortDescending()                limit(5); // 获取前多少个        GeoResults geoResults = redisTemplate.opsForGeo().radius(KEY, circle, args);        log.info(&quot;根据坐标获取：&#123;&#125; &#123;&#125; 范围的数据：&#123;&#125;&quot;, point, distance, geoResults);        return geoResults;    &#125;    /**     * 根据一个位置，获取指定范围内的其他位置     *     * @param name     * @param distance     * @return     */    private GeoResults getNearByPlace(String name, Distance distance) &#123;        RedisGeoCommands.GeoRadiusCommandArgs args = RedisGeoCommands.GeoRadiusCommandArgs.                newGeoRadiusArgs().                includeDistance(). // 包含距离                includeCoordinates(). // 包含坐标                sortAscending(). // 排序 还可选sortDescending()                limit(5); // 获取前多少个        GeoResults geoResults = redisTemplate.opsForGeo()                .radius(KEY, name, distance, args);        log.info(&quot;根据位置：&#123;&#125; 获取： &#123;&#125; 范围的数据：&#123;&#125;&quot;, name, distance, geoResults);        return geoResults;    &#125;    /**     * 获取GEO HASH     *     * @param names     * @return     */    private List&lt;String&gt; getGeoHash(String... names) &#123;        List&lt;String&gt; hash = redisTemplate.opsForGeo().hash(KEY, names);        log.info(&quot;names：&#123;&#125; 对应的hash：&#123;&#125;&quot;, names, hash);        return hash;    &#125;&#125;</code></pre><p>执行日志：</p><pre><code>成功添加名称：starbucks 的坐标信息信息：Point [x=116.624450, y=39.862060]成功添加名称：yidiandian 的坐标信息信息：Point [x=117.351479, y=38.750125]成功添加名称：xicha 的坐标信息信息：Point [x=116.538542, y=39.754120]获取名称为：[starbucks, yidiandian, xicha] 的坐标信息：[Point [x=116.624452, y=39.862060], Point [x=117.351480, y=38.750124], Point [x=116.538540, y=39.754119]]根据坐标获取：Point [x=116.000000, y=39.000000] 120.0 KILOMETERS 范围的数据：GeoResults: [averageDistance: 102.8394 KILOMETERS, results: GeoResult [content: RedisGeoCommands.GeoLocation(name=xicha, point=Point [x=116.538540, y=39.754119]), distance: 95.8085 KILOMETERS, ],GeoResult [content: RedisGeoCommands.GeoLocation(name=starbucks, point=Point [x=116.624452, y=39.862060]), distance: 109.8703 KILOMETERS, ]]RedisGeoCommands.GeoLocation(name=xicha, point=Point [x=116.538540, y=39.754119])RedisGeoCommands.GeoLocation(name=starbucks, point=Point [x=116.624452, y=39.862060])根据位置：starbucks 获取： 120.0 KILOMETERS 范围的数据：GeoResults: [averageDistance: 7.03605 KILOMETERS, results: GeoResult [content: RedisGeoCommands.GeoLocation(name=starbucks, point=Point [x=116.624452, y=39.862060]), distance: 0.0 KILOMETERS, ],GeoResult [content: RedisGeoCommands.GeoLocation(name=xicha, point=Point [x=116.538540, y=39.754119]), distance: 14.0721 KILOMETERS, ]]RedisGeoCommands.GeoLocation(name=starbucks, point=Point [x=116.624452, y=39.862060])RedisGeoCommands.GeoLocation(name=xicha, point=Point [x=116.538540, y=39.754119])names：[starbucks, yidiandian, xicha] 对应的hash：[wx4fvbem6d0, wwgkqqhxzd0, wx4f5vhb8b0]删除名称为：[yidiandian, xicha] 的坐标信息数量：2</code></pre><h2 id="简单限流"><a href="#简单限流" class="headerlink" title="简单限流"></a>简单限流</h2><p>为了保证项目的安全稳定运行，防止被恶意的用户或者异常的流量打垮整个系统，一般都会加上限流，比如常见的<code>sential</code>、<code>hystrix</code>，都是实现限流控制；如果项目用到了Redis，也可以利用Redis，来实现一个简单的限流功能；</p><p>功能所需命令</p><ul><li>  <strong>INCR</strong>：将 key 中储存的数字值增一</li><li>  <strong>Expire</strong>：设置key的有效期</li></ul><h3 id="Redis-cli操作-2"><a href="#Redis-cli操作-2" class="headerlink" title="Redis-cli操作"></a>Redis-cli操作</h3><pre><code>127.0.0.1:6379&gt; INCR r:f:user1(integer) 1# 第一次 设置一个过期时间127.0.0.1:6379&gt; EXPIRE r:f:user1 5(integer) 1127.0.0.1:6379&gt; INCR r:f:user1(integer) 2# 等待5s 再次增加 发现已经重置了127.0.0.1:6379&gt; INCR r:f:user1(integer) 1</code></pre><h3 id="SpringBoot示例："><a href="#SpringBoot示例：" class="headerlink" title="SpringBoot示例："></a>SpringBoot示例：</h3><pre><code>import lombok.extern.slf4j.Slf4j;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.redis.core.RedisTemplate;import java.util.concurrent.TimeUnit;/** * @author 一行Java * @title: 基于Redis的简单限流 * @projectName ehang-spring-boot * @description: TODO * @date 2022/8/2 9:43 */@SpringBootTest@Slf4jpublic class FreqTest &#123;    // 单位时间（秒）    private static final Integer TIME = 5;    // 允许访问上限次数    private static final Integer MAX = 100;    @Autowired    RedisTemplate redisTemplate;    @Test    public void test() throws Exception &#123;        String userName = &quot;user1&quot;;        int tag = 1;        boolean frequency = frequency(userName);        log.info(&quot;第&#123;&#125;次是否放行：&#123;&#125;&quot;, tag, frequency);        for (int i = 0; i &lt; 100; i++) &#123;            tag += 1;            frequency(userName);        &#125;        frequency = frequency(userName);        log.info(&quot;第&#123;&#125;次是否放行：&#123;&#125;&quot;, tag, frequency);        Thread.sleep(5000);        frequency = frequency(userName);        log.info(&quot;模拟等待5s后，第&#123;&#125;次是否放行：&#123;&#125;&quot;, tag, frequency);    &#125;    /**     * 校验访问频率     *     * @param uniqueId 用于限流的唯一ID 可以是用户ID、或者客户端IP等     * @return true：放行  false：拦截     */    private boolean frequency(String uniqueId) &#123;        String key = &quot;r:q:&quot; + uniqueId;        Long increment = redisTemplate.opsForValue().increment(key);        if (increment == 1) &#123;            redisTemplate.expire(key, TIME, TimeUnit.SECONDS);        &#125;        if (increment &lt;= MAX) &#123;            return true;        &#125;        return false;    &#125;&#125;</code></pre><p>运行日志：</p><pre><code>user1 第1次请求是否放行：trueuser1 第101次请求是否放行：false模拟等待5s后，user1 第101次请求是否放行：true</code></pre><h2 id="全局ID"><a href="#全局ID" class="headerlink" title="全局ID"></a>全局ID</h2><p>在分布式系统中，很多场景下需要全局的唯一ID，由于Redis是独立于业务服务的其他应用，就可以利用<code>Incr</code>的原子性操作来生成全局的唯一递增ID</p><p>功能所需命令</p><ul><li>  <strong>INCR</strong>：将 key 中储存的数字值增一</li></ul><h3 id="Redis-cli-客户端测试"><a href="#Redis-cli-客户端测试" class="headerlink" title="Redis-cli 客户端测试"></a>Redis-cli 客户端测试</h3><pre><code>127.0.0.1:6379&gt; incr g:uid(integer) 1127.0.0.1:6379&gt; incr g:uid(integer) 2127.0.0.1:6379&gt; incr g:uid(integer) 3</code></pre><h2 id="简单分布式锁"><a href="#简单分布式锁" class="headerlink" title="简单分布式锁"></a>简单分布式锁</h2><p>在分布式系统中，很多操作是需要用到分布式锁，防止并发操作带来一些问题；因为redis是独立于分布式系统外的其他服务，因此就可以利用redis，来实现一个简单的<strong>不完美</strong>分布式锁；</p><p>功能所需命令</p><ul><li><p><strong>SETNX</strong> key不存在，设置；key存在，不设置</p><pre><code>  # 加锁  127.0.0.1:6379&gt; SETNX try_lock 1  (integer) 1  # 释放锁  127.0.0.1:6379&gt; del try_lock  (integer) 1</code></pre></li></ul><pre><code>![](https://img-blog.csdnimg.cn/img_convert/014e5bf95c1355c5e09088347222338b.png)</code></pre><ul><li><p>set key value [ex seconds] [nx | xx]</p><p>  上面的方式，虽然能够加锁，但是不难发现，很容易出现死锁的情况；比如，a用户在加锁之后，突然系统挂了，此时a就永远不会释放他持有的锁了，从而导致死锁；为此，我们可以利用redis的过期时间来防止死锁问题</p><pre><code>  set try_lock 1 ex 5 nx</code></pre></li></ul><pre><code>![](https://img-blog.csdnimg.cn/img_convert/763268e3dc3e2b7224e829dce8556ca4.png)</code></pre><p><strong>不完美的锁</strong></p><p>上面的方案，虽然解决了死锁的问题，但是又带来了一个新的问题，执行时间如果长于自动释放的时间（比如自动释放是5秒，但是业务执行耗时了8秒），那么在第5秒的时候，锁就自动释放了，此时其他的线程就能正常拿到锁，简单流程如下：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/a45c37778871ceec7517cba5afd11bca.png"></p><p>此时相同颜色部分的时间区间是由多线程同时在执行。而且此问题在此方案下并<strong>没有完美的解决方案，只能做到尽可能的避免</strong>：</p><ul><li>  方式一，_value设置为随机数（如：1234），在程序释放锁的时候，检测一下是不是自己加的锁_；比如，A线程在第8s释放的锁就是线程B加的，此时在释放的时候，就可以检验一下value是不是自己当初设置的值（1234），是的就释放，不是的就不管了；</li><li>  方式二，_只在时间消耗比较小的业务上选用此方案_，尽可能的避免执行时间超过锁的自动释放时间</li></ul><h2 id="认识的人-好友推荐"><a href="#认识的人-好友推荐" class="headerlink" title="认识的人/好友推荐"></a>认识的人/好友推荐</h2><p>在支付宝、抖音、QQ等应用中，都会看到好友推荐；</p><p><img src="https://img-blog.csdnimg.cn/img_convert/9fc6a60c0dadfb4a3f4bdbc11e6f1687.png"></p><p>好友推荐往往都是基于你的好友关系网来推荐，将你可能认识的人推荐给你，让你去添加好友，如果随意在系统找个人推荐给你，那你认识的可能性是非常小的，此时就失去了推荐的目的；</p><p>比如，A和B是好友，B和C是好友，此时A和C认识的概率是比较大的，就可以在A和C之间的好友推荐；</p><p>基于这个逻辑，就可以利用 Redis 的 Set 集合，缓存各个用户的好友列表，然后以差集的方式，来实现好友推荐；</p><p>功能所需的命令</p><ul><li>  <strong>SADD</strong> key member [member …]：集合中添加元素，缓存好友列表</li><li>  <strong>SDIFF</strong> key [key …]：取两个集合间的差集，找出可以推荐的用户</li></ul><h3 id="Redis-cli-客户端测试-1"><a href="#Redis-cli-客户端测试-1" class="headerlink" title="Redis-cli 客户端测试"></a>Redis-cli 客户端测试</h3><pre><code># 记录 用户1 的好友列表127.0.0.1:6379&gt; SADD fl:user1 user2 user3(integer) 2# 记录 用户2 的好友列表127.0.0.1:6379&gt; SADD fl:user2 user1 user4(integer) 2# 用户1 可能认识的人 ，把自己（user1）去掉，user4是可能认识的人127.0.0.1:6379&gt; SDIFF fl:user2 fl:user11) &quot;user1&quot;2) &quot;user4&quot;# 用户2 可能认识的人 ，把自己（user2）去掉，user3是可能认识的人127.0.0.1:6379&gt; SDIFF fl:user1 fl:user21) &quot;user3&quot;2) &quot;user2&quot;</code></pre><p>不过这只是推荐机制中的一种因素，可以借助其他条件，来增强推荐的准确度；</p><h2 id="发布-订阅"><a href="#发布-订阅" class="headerlink" title="发布/订阅"></a>发布/订阅</h2><p>发布/订阅是比较常用的一种模式；在分布式系统中，如果需要实时感知到一些变化，比如：某些配置发生变化需要实时同步，就可以用到发布，订阅功能</p><p>常用API</p><ul><li>  <strong>PUBLISH</strong> channel message：将消息推送到指定的频道</li><li>  <strong>SUBSCRIBE</strong> channel [channel …]：订阅给定的一个或多个频道的信息</li></ul><h3 id="Redis-cli操作-3"><a href="#Redis-cli操作-3" class="headerlink" title="Redis-cli操作"></a>Redis-cli操作</h3><p><img src="https://img-blog.csdnimg.cn/img_convert/227b7269acb0c52d3043ceb9103764cb.gif"></p><p>如上图所示，左侧多个客户端订阅了频道，当右侧客户端往频道发送消息的时候，左侧客户端都能收到对应的消息。</p><h2 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h2><p>说到消息队列，常用的就是Kafka、RabbitMQ等等，其实 Redis 利用 List 也能实现一个消息队列；</p><p>功能所需的指令</p><ul><li>  <strong>RPUSH</strong> key value1 [value2]：在列表中添加一个或多个值；</li><li>  <strong>BLPOP</strong> key1 [key2] timeout：移出并获取列表的第一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止；</li><li>  <strong>BRPOP</strong> key1 [key2] timeout：移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。</li></ul><p>依赖调整：</p><p>Spring Boot 从 2.0版本开始，将默认的Redis客户端Jedis替换为Lettuce，在测试这块阻塞的时候，会出现一个超时的异常<code>io.lettuce.core.RedisCommandTimeoutException: Command timed out after 1 minute(s)</code>；没有找到一个好的解决方式，所以这里将 Lettuce 换回成 Jedis ，就没有问题了，pom.xml 的配置如下：</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;    &lt;exclusions&gt;        &lt;exclusion&gt;            &lt;groupId&gt;redis.clients&lt;/groupId&gt;            &lt;artifactId&gt;jedis&lt;/artifactId&gt;        &lt;/exclusion&gt;        &lt;exclusion&gt;            &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt;            &lt;groupId&gt;io.lettuce&lt;/groupId&gt;        &lt;/exclusion&gt;    &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!-- jedis客户端 --&gt;&lt;dependency&gt;    &lt;groupId&gt;redis.clients&lt;/groupId&gt;    &lt;artifactId&gt;jedis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- spring2.X集成redis所需common-pool2，使用jedis必须依赖它--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;    &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>测试代码：</p><pre><code>import lombok.extern.slf4j.Slf4j;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.redis.core.StringRedisTemplate;import java.util.concurrent.TimeUnit;/** * @author 一行Java * @title: QueueTest * @projectName ehang-spring-boot * @description: TODO * @date 2022/8/5 14:27 */@SpringBootTest@Slf4jpublic class QueueTest &#123;    private static final String REDIS_LP_QUEUE = &quot;redis:lp:queue&quot;;    private static final String REDIS_RP_QUEUE = &quot;redis:rp:queue&quot;;    @Autowired    StringRedisTemplate stringRedisTemplate;    /**     * 先进后出队列     */    @Test    public void rightMonitor() &#123;        while (true) &#123;            Object o = stringRedisTemplate.opsForList().rightPop(REDIS_LP_QUEUE, 0, TimeUnit.SECONDS);            log.info(&quot;先进后出队列 接收到数据：&#123;&#125;&quot;, o);        &#125;    &#125;    /**     * 先进先出队列     */    @Test    public void leftMonitor() &#123;        while (true) &#123;            Object o = stringRedisTemplate.opsForList().leftPop(REDIS_RP_QUEUE, 0, TimeUnit.SECONDS);            log.info(&quot;先进先出队列 接收到数据：&#123;&#125;&quot;, o);        &#125;    &#125;&#125;</code></pre><ul><li><p>先进先出测试效果</p><p>  <img src="https://img-blog.csdnimg.cn/img_convert/4f6600f6343e16fde052097d5aa28d18.gif"></p></li><li><p>先进后出测试效果</p><p>  <img src="https://img-blog.csdnimg.cn/img_convert/8207be288a3657c262a658548d51a645.gif"></p></li></ul><p>不过，对消息的可靠性要求比较高的场景，建议还是使用专业的消息队列框架，当值被弹出之后，List 中就已经不存在对应的值了，假如此时程序崩溃，就会出现消息的丢失，无法保证可靠性；虽然说也有策略能够保证消息的可靠性，比如，在弹出的同时，将其保存到另外一个队列（BRPOPLPUSH），成功之后，再从另外的队列中移除，当消息处理失败或者异常，再重新进入队列执行，只是这样做就得不偿失了。</p><h2 id="数据共享（session共享）"><a href="#数据共享（session共享）" class="headerlink" title="数据共享（session共享）"></a>数据共享（session共享）</h2><p>既然Redis能持久化数据，就可以用它来实现模块间的数据共享；SpringBoot Session 利用的这个机制来实现 Session 共享；</p><ul><li><p>依赖</p><pre><code>  &lt;dependency&gt;      &lt;groupId&gt;org.springframework.session&lt;/groupId&gt;      &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt;  &lt;/dependency&gt;</code></pre></li></ul><ul><li><p>开启session共享</p><pre><code>  @Configuration  @EnableRedisHttpSession  public class RedisSessionConfig &#123;  &#125;</code></pre></li></ul><ul><li><p>测试代码</p><pre><code>  package com.ehang.redis.controller;  import org.springframework.web.bind.annotation.GetMapping;  import org.springframework.web.bind.annotation.RequestMapping;  import org.springframework.web.bind.annotation.RestController;  import javax.servlet.http.HttpServletRequest;  import java.util.Enumeration;  import java.util.HashMap;  import java.util.Map;  /**   * @author session 共享   * @title: RedisSessionController   * @projectName ehang-spring-boot   * @description: TODO   * @date 2022/8/5 15:58   */  @RestController  @RequestMapping(&quot;session&quot;)  public class RedisSessionController &#123;      /**       * 设置session的值       * @param request       * @return       */      @GetMapping(&quot;set&quot;)      public Map set(HttpServletRequest request) &#123;          String id = request.getSession().getId();          Map&lt;String, String&gt; vas = new HashMap&lt;&gt;();          String key = &quot;key&quot;;          String value = &quot;value&quot;;          vas.put(&quot;id&quot;, id);          vas.put(key, value);          // 自定义session的值          request.getSession().setAttribute(key, value);          return vas;      &#125;      /**       * 获取session的值       * @param request       * @return       */      @GetMapping(&quot;get&quot;)      public Map get(HttpServletRequest request) &#123;          Map&lt;String, Object&gt; vas = new HashMap&lt;&gt;();          // 遍历所有的session值          Enumeration&lt;String&gt; attributeNames = request.getSession().getAttributeNames();          while (attributeNames.hasMoreElements()) &#123;              String k = attributeNames.nextElement();              Object va = request.getSession().getAttribute(k);              vas.put(k, va);          &#125;          vas.put(&quot;id&quot;, request.getSession().getId());          return vas;      &#125;  &#125;</code></pre></li></ul><ul><li><p>测试</p><p>  开启两个服务，分别接听8080和8081，8080调用赋值接口，8081调用获取接口，如下图，可以看到，两个服务共享了一份Session数据；</p><p>  <img src="https://img-blog.csdnimg.cn/img_convert/61a8e6f3a3e50052232d45903052e836.png"></p></li><li><p>Redis中保存的数据</p><pre><code>  127.0.0.1:6379&gt; keys spring:*  1) &quot;spring:session:sessions:expires:6f1d7d53-fe01-4e80-9e6a-5ff54fffa92a&quot;  2) &quot;spring:session:expirations:1659688680000&quot;  3) &quot;spring:session:sessions:6f1d7d53-fe01-4e80-9e6a-5ff54fffa92a&quot;</code></pre></li></ul><h2 id="商品筛选"><a href="#商品筛选" class="headerlink" title="商品筛选"></a>商品筛选</h2><p>商城类的应用，都会有类似于下图的一个商品筛选的功能，来帮用户快速搜索理想的商品；</p><p><img src="https://img-blog.csdnimg.cn/img_convert/89d0277e8d2321070b6f7135f77b109d.png"></p><p>假如现在iphone 100 、华为mate 5000 已发布，在各大商城上线；下面就通过 Redis 的 set 来实现上述的商品筛选功能；</p><p>功能所需命令</p><ul><li>  <strong>SADD</strong> key member [member …]：添加一个或多个元素</li><li>  <strong>SINTER</strong> key [key …]：返回给定所有集合的交集</li></ul><h3 id="Redis-cli-客户端测试-2"><a href="#Redis-cli-客户端测试-2" class="headerlink" title="Redis-cli 客户端测试"></a>Redis-cli 客户端测试</h3><pre><code># 将iphone100 添加到品牌为苹果的集合127.0.0.1:6379&gt; sadd brand:apple iphone100(integer) 1# 将meta5000 添加到品牌为苹果的集合127.0.0.1:6379&gt; sadd brand:huawei meta5000(integer) 1# 将 meta5000 iphone100 添加到支持5T内存的集合127.0.0.1:6379&gt; sadd ram:5t iphone100 meta5000(integer) 2# 将 meta5000 添加到支持10T内存的集合127.0.0.1:6379&gt; sadd ram:10t meta5000(integer) 1# 将 iphone100 添加到操作系统是iOS的集合127.0.0.1:6379&gt; sadd os:ios iphone100(integer) 1# 将 meta5000 添加到操作系统是Android的集合127.0.0.1:6379&gt; sadd os:android meta5000(integer) 1# 将 iphone100 meta5000 添加到屏幕为6.0-6.29的集合中127.0.0.1:6379&gt; sadd screensize:6.0-6.29 iphone100 meta5000(integer) 2# 筛选内存5T、屏幕在6.0-6.29的机型127.0.0.1:6379&gt; sinter ram:5t screensize:6.0-6.291) &quot;meta5000&quot;2) &quot;iphone100&quot;# 筛选内存10T、屏幕在6.0-6.29的机型127.0.0.1:6379&gt; sinter ram:10t screensize:6.0-6.291) &quot;meta5000&quot;# 筛选内存5T、系统为iOS的机型127.0.0.1:6379&gt; sinter ram:5t screensize:6.0-6.29 os:ios1) &quot;iphone100&quot;# 筛选内存5T、屏幕在6.0-6.29、品牌是华为的机型127.0.0.1:6379&gt; sinter ram:5t screensize:6.0-6.29 brand:huawei1) &quot;meta5000&quot;</code></pre><h2 id="购物车"><a href="#购物车" class="headerlink" title="购物车"></a>购物车</h2><p><strong>商品缓存</strong></p><p>电商项目中，商品消息，都会做缓存处理，特别是热门商品，访问用户比较多，由于商品的结果比较复杂，店铺信息，产品信息，标题、描述、详情图，封面图；为了方便管理和操作，一般都会采用 Hash 的方式来存储（key为商品ID，field用来保存各项参数，value保存对于的值）</p><p><strong>购物车</strong></p><p>当商品信息做了缓存，购物车需要做的，就是通过Hash记录商品ID，以及需要购买的数量（其中key为用户信息，field为商品ID，value用来记录购买的数量） ；</p><p>功能所需命令</p><ul><li>  <strong>HSET</strong> key field value : 将哈希表 key 中的字段 field 的值设为 value ;</li><li>  <strong>HMSET</strong> key field1 value1 [field2 value2 ] ：同时将多个 field-value (域-值)对设置到哈希表 key 中。</li><li>  <strong>HGET</strong> key field：获取存储在哈希表中指定字段的值。</li><li>  <strong>HGETALL</strong> key ：获取在哈希表中指定 key 的所有字段和值</li><li>  <strong>HINCRBY</strong> key field increment ：为哈希表 key 中的指定字段的整数值加上增量 increment 。</li><li>  <strong>HLEN</strong> key：获取哈希表中字段的数量</li></ul><h3 id="Redis-cli-客户端测试-3"><a href="#Redis-cli-客户端测试-3" class="headerlink" title="Redis-cli 客户端测试"></a>Redis-cli 客户端测试</h3><pre><code># 购物车添加单个商品127.0.0.1:6379&gt; HSET sc:u1 c001 1(integer) 1# 购物车添加多个商品127.0.0.1:6379&gt; HMSET sc:u1 c002 1 coo3 2OK# 添加商品购买数量127.0.0.1:6379&gt; HINCRBY sc:u1 c002 1(integer) 2# 减少商品的购买数量127.0.0.1:6379&gt; HINCRBY sc:u1 c003 -1(integer) 1# 获取单个的购买数量127.0.0.1:6379&gt; HGET sc:u1 c002&quot;2&quot;# 获取购物车的商品数量127.0.0.1:6379&gt; HLEN sc:u1(integer) 3# 购物车详情127.0.0.1:6379&gt; HGETALL sc:u11) &quot;c001&quot;2) &quot;1&quot;3) &quot;c002&quot;4) &quot;2&quot;5) &quot;coo3&quot;6) &quot;2&quot;</code></pre><h2 id="定时取消订单（key过期监听）"><a href="#定时取消订单（key过期监听）" class="headerlink" title="定时取消订单（key过期监听）"></a>定时取消订单（key过期监听）</h2><p>电商类的业务，一般都会有订单30分钟不支付，自动取消的功能，此时就需要用到定时任务框架，Quartz、xxl-job、elastic-job 是比较常用的 Java 定时任务；我们也可以通过 Redis 的定时过期、以及过期key的监听，来实现订单的取消功能；</p><ul><li><p>Redis key 过期提醒配置</p><p>  修改 redis 相关事件配置。找到 redis 配置文件 redis.conf，查看 notify-keyspace-events 配置项，如果没有，添加 notify-keyspace-events Ex，如果有值，则追加 Ex，相关参数说明如下：</p><ul><li><p>  <code>K</code>：keyspace 事件，事件以 keyspace@ 为前缀进行发布</p></li><li><p>  <code>E</code>：keyevent 事件，事件以 keyevent@ 为前缀进行发布</p></li><li><p>  <code>g</code>：一般性的，非特定类型的命令，比如del，expire，rename等</p></li><li><p>  <code>$</code>：字符串特定命令</p></li><li><p>  <code>l</code>：列表特定命令</p></li><li><p>  <code>s</code>：集合特定命令</p></li><li><p>  <code>h</code>：哈希特定命令</p></li><li><p>  <code>z</code>：有序集合特定命令</p></li><li><p>  <code>x</code>：过期事件，当某个键过期并删除时会产生该事件</p></li><li><p>  <code>e</code>：驱逐事件，当某个键因 maxmemore 策略而被删除时，产生该事件</p></li><li><p>  <code>A</code>：g$lshzxe的别名，因此”AKE”意味着所有事件</p></li></ul></li><li><p>添加RedisKeyExpirationListener的监听</p><pre><code>  import org.springframework.context.annotation.Bean;  import org.springframework.context.annotation.Configuration;  import org.springframework.data.redis.connection.RedisConnectionFactory;  import org.springframework.data.redis.listener.RedisMessageListenerContainer;  @Configuration  public class RedisListenerConfig &#123;      @Bean      RedisMessageListenerContainer container(RedisConnectionFactory connectionFactory) &#123;          RedisMessageListenerContainer container = new RedisMessageListenerContainer();          container.setConnectionFactory(connectionFactory);          return container;      &#125;  &#125;</code></pre></li></ul><pre><code>`KeyExpirationEventMessageListener` 接口监听所有 db 的过期事件 `keyevent@*:expired&quot;`    package com.ehang.redis.config;    import lombok.extern.slf4j.Slf4j;    import org.springframework.data.redis.connection.Message;    import org.springframework.data.redis.listener.KeyExpirationEventMessageListener;    import org.springframework.data.redis.listener.RedisMessageListenerContainer;    import org.springframework.stereotype.Component;    /**     * 监听所有db的过期事件__keyevent@*__:expired&quot;     *     * @author 一行Java     * @title: RedisKeyExpirationListener     * @projectName ehang-spring-boot     * @description: TODO     * @date 2022/8/5 16:36     */    @Component    @Slf4j    public class RedisKeyExpirationListener extends KeyExpirationEventMessageListener &#123;        public RedisKeyExpirationListener(RedisMessageListenerContainer listenerContainer) &#123;            super(listenerContainer);        &#125;        /**         * 针对 redis 数据失效事件，进行数据处理         *         * @param message         * @param pattern         */        @Override        public void onMessage(Message message, byte[] pattern) &#123;            // 获取到失效的 key，进行取消订单业务处理            // 由于这里是监听了所有的key，如果只处理特定数据的话，需要做特殊处理            String expiredKey = message.toString();            log.info(&quot;过期的Key：&#123;&#125;&quot;, expiredKey);        &#125;    &#125;</code></pre><ul><li><p>测试</p><p>  为了快速验证效果，这里 将过期时间调整为2秒；</p><p>  注意，由于过期之后，Redis中的Key已经不存在了，因此，<strong>一定要将订单号作为key</strong>，不能作为值保存，否则监听到过期Key之后，将拿不到过期的订单号；</p><p>  <img src="https://img-blog.csdnimg.cn/img_convert/5e13c6a9c6c611a57435abc7543aee48.gif"></p></li><li><p>不推荐使用</p><p>  基于这一套机制，确实能够实现订单的超时取消，但是还是不太建议使用，这里仅作为一个思路；原因主要有以下几个：</p><ol><li> redis 的过期删除策略是采用定时离线扫描，或者访问时懒性检测删除，并没有办法保证时效性，有可能key已经到期了，但Redis并没有扫描到，导致通知的延迟；</li><li> 消息发送即忘（fire and forget），并不会保证消息的可达性，如果此时服务不在线或者异常，通知就再也收不到了；</li></ol></li></ul><h2 id="物流信息（时间线）"><a href="#物流信息（时间线）" class="headerlink" title="物流信息（时间线）"></a>物流信息（时间线）</h2><p>寄快递、网购的时候，查询物流信息，都会给我们展示xxx时候，快递到达什么地方了，这就是一个典型的时间线列表；</p><p><img src="https://img-blog.csdnimg.cn/img_convert/eedf461b45361641b2716233077da67c.png"></p><p>数据库的做法，就是每次变更就插入一条带时间的信息记录，然后根据时间和ID（ID是必须的，如果出现两个相同的时间，单纯时间排序，会造成顺序不对），来排序生成时间线；</p><p>我们也可以通过 Redis 的 List 来实现时间线功能，由于 List 采用的是双向链表，因此升序，降序的时间线都能正常满足；</p><ul><li>  <strong>RPUSH</strong> key value1 [value2]：在列表中添加一个或多个值，（升序时间线）</li><li>  <strong>LPUSH</strong> key value1 [value2]：将一个或多个值插入到列表头部（降序时间线）</li><li>  <strong>LRANGE</strong> key start stop：获取列表指定范围内的元素</li></ul><p>Redis-cli 客户端测试</p><ul><li><p>升序</p><pre><code>  127.0.0.1:6379&gt; RPUSH time:line:asc 20220805170000  (integer) 1  127.0.0.1:6379&gt; RPUSH time:line:asc 20220805170001  (integer) 2  127.0.0.1:6379&gt; RPUSH time:line:asc 20220805170002  (integer) 3  127.0.0.1:6379&gt; LRANGE time:line:asc 0 -1  1) &quot;20220805170000&quot;  2) &quot;20220805170001&quot;  3) &quot;20220805170002&quot;</code></pre></li></ul><ul><li><p>降序</p><pre><code>  127.0.0.1:6379&gt; LPUSH time:line:desc 20220805170000  (integer) 1  127.0.0.1:6379&gt; LPUSH time:line:desc 20220805170001  (integer) 2  127.0.0.1:6379&gt; LPUSH time:line:desc 20220805170002  (integer) 3  127.0.0.1:6379&gt; LRANGE time:line:desc 0 -1  1) &quot;20220805170002&quot;  2) &quot;20220805170001&quot;  3) &quot;20220805170000&quot;</code></pre></li></ul><p>好了，关于Redis 的妙用，就介绍到这里；有了这些个场景的运用，下次再有面试官问你，Redis除了缓存还做过什么，相信聊上个1小时，应该不成问题了。</p><blockquote><p>测试源码：<a href="https://github.com/vehang/ehang-spring-boot/tree/main/spring-boot-011-redis">https://github.com/vehang/ehang-spring-boot/tree/main/spring-boot-011-redis</a></p><p>大部分用例都在test目录下</p></blockquote></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/qkuejUUQ-mco-ZX2impZXw&quot;&gt;https://mp.weixin.qq.com/s/qkuejUUQ-mco-ZX2impZXw&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://blo</summary>
      
    
    
    
    <category term="redis" scheme="http://zhangyu.info/categories/redis/"/>
    
    
    <category term="redis" scheme="http://zhangyu.info/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>OKR之剑·理念篇03-OKR理念认同</title>
    <link href="http://zhangyu.info/2022/11/30/OKR%E4%B9%8B%E5%89%91%C2%B7%E7%90%86%E5%BF%B5%E7%AF%8703-OKR%E7%90%86%E5%BF%B5%E8%AE%A4%E5%90%8C/"/>
    <id>http://zhangyu.info/2022/11/30/OKR%E4%B9%8B%E5%89%91%C2%B7%E7%90%86%E5%BF%B5%E7%AF%8703-OKR%E7%90%86%E5%BF%B5%E8%AE%A4%E5%90%8C/</id>
    <published>2022-11-29T16:00:00.000Z</published>
    <updated>2022-11-30T05:34:35.319Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文是《OKR 之剑》系列之理念第3篇。本文就我们对于OKR理念的理解和分析，和市面上一些变味的OKR实操，和大家探讨一下OKR理念，并初步介绍一下我们通过氛围来宣扬OKR理念的主要思路。</p><h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>众所周知，OKR引入中国多年，很多创业成长期的互联网公司都在纷纷实施OKR，似乎都认为实施了OKR之后就能和Google一样成为互联网巨头。然而，实际结果并不尽如人意（参考佐佳咨询针对OKR的调查报告）。那么，为什么这么多的公司在实践OKR时，会觉得诸多不顺呢？</p><p>我们认为根本原因就是在于大家对OKR的理解或执行出现了偏差。在前文之中，我们也详细地描述了什么样的企业适合使用OKR，然而，如果大家在思维上没有转变，理念上没有真正认同，OKR执行就容易走偏，最终效果可能不尽如人意。</p><p>基于此，我们在本文针对这种偏差做了一些案例分析和理解；并且阐明了我们对于OKR的理念和预期；最后，我们也针对性地介绍了OKR氛围营造的核心思路，帮助大家在OKR上阵之前，思想上达成一致，理念上认同支持，最终在行动上“不遗余力”。</p><h2 id="二、理解偏差"><a href="#二、理解偏差" class="headerlink" title="二、理解偏差"></a>二、理解偏差</h2><p>“万事开头难”，理解上的偏差对整个团队OKR的推进影响深远。多做正确的事情，并把事情做正确，我们的企业才能走得更远。本节重点介绍一下OKR执行不顺的常见案例，并分析了一些可能的原因，帮助大家少走弯路。最后，我们重点论述了一下KPI式OKR的踩坑分析。</p><h3 id="2-1-OKR不顺的案例"><a href="#2-1-OKR不顺的案例" class="headerlink" title="2.1 OKR不顺的案例"></a>2.1 OKR不顺的案例</h3><p> <strong>1）案例一，</strong>OKR负责人管理能力一般，既没有令人信服的业绩，又没有让人心服的能力，更谈不上领导魅力。抛开KPI，他们压根就管不住底下的员工。基于此，他们在任何涉及管理的工作中，都只能附身KPI，“大权在握，俯视众生”，只有带上KPI“拿捏”住绩效，他们才能“无所畏惧，勇往直前”，这样的负责人自然会把OKR执行带偏。</p><p><strong>2）案例二，</strong>某团队安排那种只会在办公室里作报告的人成为其OKR负责人。这些人可能就读了几天OKR，对技术理解非常片面，更谈不上深刻，毫无前瞻性，只会用一些看起来高大上的名词扯虎皮、作报告。基于其形式主义的作风，和自己浅显的理解开始实施其变味的OKR，最终结果自然“惨淡收场”。除了被其鼓吹了一波自己成功施行OKR之外，大家都身心俱疲。殊不知，这样施行OKR，只不过是另一种形式的“借OKR概念割韭菜”“蹭热度”罢了。</p><p> <strong>3）案例三，</strong>OKR负责人认为其所属业务确定性工作较多，或者其专门成立团队用于不确定性工作的探索。在负责人心中，“业务组”是确定性的工作，不确定性的工作让“预研组”“创新组”去负责就好。至此，基于其认知，业务组的OKR就会被KPI化，OKR执行上形成了显著的偏差。</p><p> <strong>4）案例四，</strong>OKR负责人理解OKR的理念，但是在执行的时候，未做合适的解读和过渡，施行的时候习惯性的强压任务。下面的人未能很好的理解OKR，只认为身上多了一个挑战型任务。不挑战不行，挑战失败会挨板子，苦不堪言，也只能默默忍受。最后大家身心俱疲，有人认为“卷不过”跑路，有人“佛系面对”选择躺平，最终OKR无疾而终。</p><p><strong>5）案例五，</strong>OKR负责人引入了一套OKR管理工具，让大家填，看OKR完成度打分打绩效。如此，OKR跟绩效进行了强绑定，虽然披着OKR的外衣，但是本质还是KPI。</p><h3 id="2-2-OKR不顺可能的原因"><a href="#2-2-OKR不顺可能的原因" class="headerlink" title="2.2 OKR不顺可能的原因"></a>2.2 OKR不顺可能的原因</h3><h4 id="2-2-1-KPI管理深入人心，甩不开的KPI惯性包袱"><a href="#2-2-1-KPI管理深入人心，甩不开的KPI惯性包袱" class="headerlink" title="2.2.1 KPI管理深入人心，甩不开的KPI惯性包袱"></a>2.2.1 KPI管理深入人心，甩不开的KPI惯性包袱</h4><p>KPI的设计通常是自上而下，本质上是对战略的层层分解，其分解的逻辑底子是自上而下。虽然也有聚焦的作用，也会自下而上对齐一下，但是KPI中要求性质的内容占比远大于OKR。</p><p>很多人推行OKR之前就是以KPI管理为主的风格，KPI思维贯彻始终，一切以KPI说话的理念贯穿其思维，这种强KPI的惯性力会导致其OKR推行困难丛丛。这种情况下，之前推行KPI越顺利，其惯性力也就越大，特别是其引以为傲的KPI管理比较成功之后，理念转变极其困难，遇到那种与时俱进、乐于听取别人意见的负责人还好，否则，整个团队的OKR执行都容易走偏。</p><h4 id="2-2-2-实操偏少，过于形式主义"><a href="#2-2-2-实操偏少，过于形式主义" class="headerlink" title="2.2.2 实操偏少，过于形式主义"></a>2.2.2 实操偏少，过于形式主义</h4><p> 很多企业引入OKR概念的人，对业务接触偏少，其主导OKR变更的时候，对于工具性质的形式化内容更看重。条条框框无限制的加在参与者身上，并没有切身帮助大家解决OKR推行过程中遇到的真实问题。为了吹嘘自己的产出，东拼西凑一堆“虚头巴脑”的东西忽悠老板，结果自然是“怨声载道”。具体的形式主义的特征和规避方法在下一篇文章中有详细的论述。</p><h4 id="2-2-3-引入OKR就够了，剩下的全交给团队自驱"><a href="#2-2-3-引入OKR就够了，剩下的全交给团队自驱" class="headerlink" title="2.2.3 引入OKR就够了，剩下的全交给团队自驱"></a>2.2.3 引入OKR就够了，剩下的全交给团队自驱</h4><p>也许你有已经完全理解了OKR的理念，但是团队成员不一定都达到同样的认知高度。缺少必要的理念引领，大家对OKR理念的理解并没有完全达成一致，特别是在OKR氛围小飞轮（下文会详细介绍）完成打造之前，自驱能量严重不足，自然难以带领整个团队OKR完整运转起来。</p><p>另外，OKR模式运转也需要解决团队遇到的各项问题，如果业务上大家尚且自顾不暇，OKR的执行必然会事倍功半。</p><h3 id="2-3-避开KPI式的OKR"><a href="#2-3-避开KPI式的OKR" class="headerlink" title="2.3 避开KPI式的OKR"></a>2.3 避开KPI式的OKR</h3><blockquote><p><em>网上看到一则案例：</em> </p><p><em>有人提问：员工不愿意用OKR怎么办？        下</em></p><p><em>面的回答是：如果“做不好OKR就辞退”，“BOSS安排的事要大力支持”这样的回答。</em></p></blockquote><p>作为OKR负责人，有时候难以避免<strong>被任务式的下压</strong>，接受压力后，再以任务<strong>下压的方式来推行OKR</strong>，第一步就把OKR做成了KPI。</p><p>如果真的是这种下压的方式来推行OKR，如案例所述，开场就做成了绝对的老板导向。负责人开场就以KPI的方式来推行OKR，自己都没有真正理解OKR。也就是常说的“以OKR之名行KPI之实”，这种情况下，强制执行OKR，只会越走越偏，官僚主义盛行，OKR最终只会变成”骆驼身上的稻草”。</p><p><strong>怎么过渡才能少踩坑？</strong></p><p>有些团队刚从外部引入OKR的时候，执行往往会走偏，执行成KPI。除了最开始的动员大会有一些介绍之外，很少有人去了解OKR的核心是什么，大家都是按格式化的模板填内容，照本宣科，以新增了一项KPI任务的心态去做这件事。</p><p>然而，如果项目任务比较重，OKR定什么是个难题。为了好好表现以提高绩效，大家制定OKR会尽力求多、求全。于是，在项目工作之外，大家身上都平添了不少负担。</p><p>到了季度总结的时候，问题也随之而来。虽然OKR模板填的满满当当，但是干的事却跟OKR内容关系不大，部分非业务OKR进度长期处于停滞状态，典型的高开低走。大家只是简单的多了个任务，多了些会议而已，没有实质性的产出价值。</p><p>而我们团队，区别于这种KPI式的OKR执行，有了巨大的转变。</p><p><strong>1）OKR减负</strong>，每个人的OKR自己跟踪，不用自己凑数字，更不用帮别人凑数字，OKR任务少了很多；</p><p><strong>2）管理层也有OKR</strong>，他们每次都会分享自己的OKR内容，分享自己的认知内容，毫无保留，帮助大家集体提升OKR管理理念和认知，起到很好的氛围引领作用；一般而言，管理层作为引入者才是第一批OKR教练。</p><p><strong>3）管理层切实帮助我们解决问题</strong>，提供优渥的OKR土壤。</p><p>并且，随着OKR施行，团队氛围越来越热烈，逐步安排了经验丰富的OKR教练。OKR教练们和管理层不停地学习和思考，从上到下贯彻OKR的核心理念，有效帮助大家解决执行OKR遇到的各类问题，如：伙力平台解决人力问题、过程管理解决激励问题和导向问题。大家的OKR也越来越聚焦、越来越有挑战性。（备注：伙力平台和过程管理在后续文章中会详细描述）。</p><p>至此，从早期的微创新开始，我们也衍生出了一大批极具价值且挑战性十足的OKR，大家挑战的目标也越来越大、越来越难，需要的时间周期也在逐步变长。针对此现象，我们OKR教练和管理层也跟随节奏，把握平衡，聚焦目标，适度审视，并给予足够的支持和认可。</p><h2 id="三、理念引导"><a href="#三、理念引导" class="headerlink" title="三、理念引导"></a>三、理念引导</h2><p>本节，我们探讨一下我们对于OKR理念的分析、理解和预期；并对OKR施行成功做了一番特征论述，带大家在OKR理念上达成一致。</p><h3 id="3-1-我们对OKR的五维分析"><a href="#3-1-我们对OKR的五维分析" class="headerlink" title="3.1 我们对OKR的五维分析"></a>3.1 我们对OKR的五维分析</h3><p>有人说，OKR只是个工具；也有人说，OKR是一种新的管理法；还有人说，OKR是一种思想（思想一般是包含理念的）；此外，更有人直接表明，OKR就是“关注过程的KPI”。那么，我们是怎么理解OKR的呢？</p><p><img src="https://segmentfault.com/img/remote/1460000042635613"></p><p>（图3-1）</p><p>我们从五个维度分析了一下，供大家参考。</p><p><strong>道：通过OKR理念，集中力量办大事，符合自然规律</strong></p><p>OKR的理念给予大家更大的自由度，除了自上而下的目标之外，可以加入更多自下而上甚至横向的目标，多向沟通对齐，并且经由团队成员拍砖，取得团队更广泛的支持，号召更多成员参与，集中力量办大事，符合多业务方向竞争获胜的基本条件。</p><p> <strong>法：打造OKR氛围小飞轮，注入能量，打造自驱自组织型团队</strong></p><p>OKR执行的核心的战略是要以OKR理念为引导，打造氛围小飞轮，持续注入开放、共享、自驱、自组织的氛围能量。让大家的理念步调一致，循环渐进，为公司的发展建设挑战更多“不可能”、“不确定”。大家理念一致，都从“心”开始，用“心”突破，放弃躺平，才能让团队更加强大，才能真正释放团队的潜力。</p><p><strong>术：OKR教练、正向引导、解决问题、容忍“不确定性”探索</strong></p><p>OKR教练可以起到理念引领的作用，而正向引导才能打出“金钱奖励”之外的精神激励。通过解决问题，容忍一定的“不确定”探索，让团队无后顾之忧，大家才能真正发挥主观能动性，探索更多，挑战更多。</p><p><strong>器：OKR工具帮助大家聚焦目标和挑战更高目标</strong></p><p>作为一个目标管理与沟通的利器，其工具属性也是非常明显的。</p><p><strong>势：VUCA时代，远离物质匮乏，有些员工更追求自我，有些更愿意躺平；信息爆炸中如何持续做出正确的决策，需要团队的力量。</strong></p><p>① 时代的转变引领管理理念的变更。新时代的管理，工作复杂度稳步飙升，计量计件的管理只是在开历史倒车，因为我们不是流水线工人。</p><p>比如：网传的项目管理团队搞的计算程序员提交代码行数工具，以此来评估其工作饱和度，并且用此来衡量其绩效，确实有些不合适。当大家干的都是类似的技术工作，有人勤奋有人高效，如何让产出更高的人获得更多的挑战和机会，OKR是很好的选择。</p><p>② 新时代的员工成长过程信息爆炸，不好“被忽悠”，他们更加追求尊重、自我实现，更愿意接收挑战、收获成果，OKR这种多维互动更符合他们的理念。</p><p>③信息爆炸的时代，不能与时俱进的跟进各方向的态势就难以在竞争中持续获胜。这种情况下，只依赖领导层的力量是远远不够的，只有把团队的力量整合在一起，才能让企业无惧任何挑战。</p><p>比如：有些企业是在实业风口靠产品质量起家的，其重点可能一直关注在质量上。并且，随着新时代的营销和品牌打造愈发重要，领导层也尝试突破关注这类内容。然而，领导层的思维和精力都是有限的，很多新兴的方向更是难以探索，比如电商、直播带货、海外、数字化等，企业总会比人慢半拍，自然难以在竞争中获得优势。</p><p>OKR是要求设定有挑战的目标，即使每天加班加点，所有目标最终实现的概率也只有不到70%，一般以此证明目标设定的可挑战性。所以，这不是一个工具就能搞定的，工具只是告诉大家，按照工具的方法和步骤去执行，OKR有工具方面的属性，但是不应仅当它是个工具。更多的希望大家能看到OKR理念中发挥集体智慧、构建自驱团队、推进团队挑战自我、坚持做正确的事情，激发个人潜力、团队潜力的底层思想。</p><p>在我们实践过程中，会发现大量的参与者，随着OKR教练的逐步引领，管理理念的日益灌输，团队氛围的渐染熏陶，以及切实感受到的鼓励支持，会逐渐融入团队，成为氛围组的一员。这样的氛围对于积极参与者提供更多的自由发挥的机会，让他们成长更快，走的更远。也许业务性质上存在是否容易产出结果的问题，但是只要积极努力，不轻言放弃，不容易产出的业务有可能做出更高的上限。</p><p>毕竟，在OKR的理念聚焦下，有了更大的自由度，行为上没了枷锁，思想上没有包袱，结果才会无限可能！</p><h3 id="3-2-我们的理念"><a href="#3-2-我们的理念" class="headerlink" title="3.2 我们的理念"></a>3.2 我们的理念</h3><p>OKR之于管理者，是一种管理理念，也是一种宣导管理理念的工具；之于参与者，是一种聚焦目标，主动思考的协同方式；之于团队，是一种开放氛围、自驱成长的催化剂。</p><p>如果你希望你的团队达成更多的的创新目标，那么作为管理者，<strong>就要搭建好“鼓励创新”这个聚焦目标的舞台</strong>。</p><p>作为舞台的搭建者，可以考虑外围，观众，表演者三类角色进行分别处理。一方面，管理者要吸引更多的观众参与进来，让表演氛围更浓；另一方面，管理者对表演者给予更大的自由度，提供崇尚自由度的OKR理念，鼓励更多观众成为表演者，甚至让表演者持续创造出更好的作品。最后，通过不停地正向引导，节目就会越来越丰富多彩，氛围就带动起来了。</p><p>同样的，在OKR理念中，作为管理层，也可以在这个搭台子的过程中持续灌输自己的管理理念，想要倡导的理念。比如：你想要鼓励创新的理念，那么OKR阶段结束时可以针对创新类产出给予更多鼓励和支持，其它操作（如：不必要的考试内卷）注意多加审视；那么，参与者就可以通过对倡导目标进行聚焦和发散，主动思考突破点，实现个人和团队突破。这样，想要表演的人都有机会表演呈现价值，不想要表演的人也能做好观众，学人之长，为后续逐步转化成表演者做好准备；而整个团队就在这种开放的氛围下，自驱成长，由点化面，带动团队的每个成员高速成长。</p><h3 id="3-3-我们的预期"><a href="#3-3-我们的预期" class="headerlink" title="3.3 我们的预期"></a>3.3 我们的预期</h3><p>作为管理者要对OKR解决的问题要有一个合理预期，OKR不是万能的，不能期望它解决有关目标、绩效、产出等所有问题。</p><p><strong>那么，我们推行OKR有什么用呢？</strong></p><h4 id="3-3-1-聚焦目标与重点"><a href="#3-3-1-聚焦目标与重点" class="headerlink" title="3.3.1 聚焦目标与重点"></a>3.3.1 聚焦目标与重点</h4><p>OKR的全称是目标与关键结果，如果把OKR当做一个工具来用，其最浅显的作用就是帮助员工聚焦目标。</p><h4 id="3-3-2-管理理念传达迅速，让管理更扁平"><a href="#3-3-2-管理理念传达迅速，让管理更扁平" class="headerlink" title="3.3.2 管理理念传达迅速，让管理更扁平"></a>3.3.2 管理理念传达迅速，让管理更扁平</h4><p>在我们的理念中，于管理者而言，OKR本身是一种管理理念。通过这种理念，可以一统自上而下和自下而上的目标，让管理效率大大提升。管理一直以来都是是各个公司永恒的话题。如何管理才能让决策层的理念最快速地传达到各层？如何才能避免任用“帕金森定律”？</p><p>实行OKR理念之后，我们的管理就显得更扁平了。一方面，上层管理通过OKR倡导可以更快地贯彻大团队的各项理念，作战统一更协调，更高效，上下同欲；另一方面，中下层管理可以抽出更多精力，聚焦于更重要的事情，不用花费大量时间揣摩、转义、开会传达上层思想了。具体为什么更扁平在实战篇中有详细论述。</p><h4 id="3-3-3-增强未知探索能力"><a href="#3-3-3-增强未知探索能力" class="headerlink" title="3.3.3 增强未知探索能力"></a>3.3.3 增强未知探索能力</h4><p>OKR对Google和字节跳动最重要的作用就是创新方面的引领，这恰恰说明了其在探索未知能力方向的神奇魔力。从逻辑上来讲，OKR理念贯彻之后，大家的自由度得到了一定范围的扩大，不再是冷冰冰的指标，并且做出成绩会得到成就，自然而然大家的主观能动性就得到了极大的提升。如此环境，对未知的探索就会得到加强。</p><h4 id="3-3-4-团队效率更高，减少内卷"><a href="#3-3-4-团队效率更高，减少内卷" class="headerlink" title="3.3.4 团队效率更高，减少内卷"></a>3.3.4 团队效率更高，减少内卷</h4><p> 一方面，基于透明、公开的环境，同步其他人确定的方向和目标，相互之间重复概率会大大降低。而闭门造车必然会导致许多的重复建设，从而产生不必要的内耗。</p><p> 另一方面，众所周知，<strong>避免内卷的唯一方法就是外拓</strong>。如果大家都只盯着队伍盘子里的“三瓜两枣”，没有对公司或者大团队做出任何有效的产出，只会做向上汇报，并且相互竞争比谁的PPT做的好，谁更会讲故事，整个团队就会陷入无休止的内卷当中。今天你把BUG数降到零，明天他又做了一个烂尾工具强制消费团队的精力，后天又有几十人做了个平台，但年化收益仅仅只有十几万。公开的环境和导向，大家可以尽情拍砖，可以大幅度减少这些蹩脚项目诞生的可能性，减少不必要的内卷。</p><h4 id="3-3-5-提升员工敬业度和专业度"><a href="#3-3-5-提升员工敬业度和专业度" class="headerlink" title="3.3.5 提升员工敬业度和专业度"></a>3.3.5 提升员工敬业度和专业度</h4><p>OKR更加包容，参与者在选择目标上存在更大的自主权，最终目标很可能是自上而下和自下而上的融合。如此，参与个体就有机会做真正对工作有意义的事情，或者发起更具深度的未知探索，持续参与此类事项的打磨，可以让参与者的敬业度和专业性得到显著的提升。</p><h3 id="3-4-怎样才算成功推行OKR"><a href="#3-4-怎样才算成功推行OKR" class="headerlink" title="3.4 怎样才算成功推行OKR"></a>3.4 怎样才算成功推行OKR</h3><p>OKR的核心是一种理念，让大家共同参与。可以是自下而上，也可以是自上而下。特别是作为研发团队，能起到信息公示、氛围营造、目标共识、愿景指引、聚焦重点、集体决策，就已经成功了。</p><p>针对不同角色，我们定义了“三步识别法”，帮助大家对照OKR推行情况：</p><h4 id="3-4-1-上下左右同欲，信息传递速度快、失真少；"><a href="#3-4-1-上下左右同欲，信息传递速度快、失真少；" class="headerlink" title="3.4.1 上下左右同欲，信息传递速度快、失真少；"></a>3.4.1 上下左右同欲，信息传递速度快、失真少；</h4><p>这其实是一种非常扁平化的管理思路，可以大幅度减少管理资源的浪费。管理层想要传导的理念，根本不需要管理层过来给大家动员演讲 或者 逐层传递，通过OKR，或者管理事例公示的日常行为方式，即可快速触达团队每一位成员，上下同欲，信息传导更快，聚焦重点效率更高。</p><h4 id="3-4-2-全员九成参与，主观能动，四面开花；"><a href="#3-4-2-全员九成参与，主观能动，四面开花；" class="headerlink" title="3.4.2 全员九成参与，主观能动，四面开花；"></a>3.4.2 全员九成参与，主观能动，四面开花；</h4><p>其实我们很早就已经达到了全员参与的状态，之所以定个九成参与，主要是给各个业务留点余地，毕竟每个团队性质可能存在差异。主观能动性则说明全员都在自驱自组织地尝试做一些突破，纷纷加入“表演者”的团队，“节目”多了，就会出现四面开花的情况。</p><h4 id="3-4-3-团队自驱自组织，自驱认领，自驱进化。"><a href="#3-4-3-团队自驱自组织，自驱认领，自驱进化。" class="headerlink" title="3.4.3 团队自驱自组织，自驱认领，自驱进化。"></a>3.4.3 团队自驱自组织，自驱认领，自驱进化。</h4><p>没有加入我们团队，其实很难理解，我们团队为何各项都如此的优秀？系统稳定性、线上质量、迭代效率、专利、分享、技术投稿、评审、技术创新、团建活动等等，每次都是遥遥领先。</p><p>直到加入我们团队之后，才切切实实地感受到团队管理层能量的强大。管理层根本没有做过任何动员会，大家都自驱自组织地找“贡献点”，各自从自己的角度挖掘“亮点”，仿佛一个大染缸，进来的人一个个都被染成了“自驱型”的课代表。有小伙伴也在加入之后，结合业务实际深入思考，随后在降本方向取得重大突破，为公司网络费用降低取得了显著效果。</p><p>俗话说的好，“花若盛开，蝴蝶自来”，只有培养好肥沃的OKR土壤，才能让百花盛开，而这肥沃的OKR土壤可以通过OKR理念搭配出来。</p><h2 id="四、氛围营造"><a href="#四、氛围营造" class="headerlink" title="四、氛围营造"></a>四、氛围营造</h2><p>传播理念的最佳渠道就是氛围。现在，大家理解了OKR理念，要想真正把这一脉理念传播好，就必须着手营造好的OKR氛围。本节，我们主要介绍了下我们心中的OKR氛围和营造方法论，并针对变味的OKR做了一番探讨。更多详细的OKR氛围实操案例请看后续篇章：《OKR致胜法宝：氛围&amp;业绩双轮驱动》。</p><h3 id="4-1-什么是好的OKR氛围"><a href="#4-1-什么是好的OKR氛围" class="headerlink" title="4.1 什么是好的OKR氛围"></a>4.1 什么是好的OKR氛围</h3><p>我们认为最好的氛围就是大家全员参与，<strong>植入兴趣，投入热情，加入灵感，成于习惯，终于成就</strong>，把每个人枯燥无味的工作变得充满“意义”。</p><p>大家都在什么氛围下做事效率更高？归因一下，我们觉得有几个方面是要着重考虑的：</p><p><strong>1）植入兴趣</strong></p><p>众所周知，兴趣是一个人最好的入门老师，没兴趣的事情，至少前期做起来没那么幸福。但是如果你做的事情有一定的自由度，可以往自己感兴趣的方向偏移一些，肯定比规定的死任务、固化方向让你执行效率更高。而且有兴趣的事情，热情度也会更高，投入的时间精力也会让这件事更容易达成。</p><p><strong>2）投入热情</strong></p><p> 一直做自己感兴趣的事情十分美好，但是大家毕竟还是处于工作状态，这么美好的事情可能不多见。但是，相对兴趣却是比较容易达成的。比如，不喜欢写PPT，相对更喜欢写代码，那就可以选择写代码相关的OKR。有了兴趣，对于自己研究的项目，是否能够投入足够的热情，决定了这件事的成功率上限。</p><p><strong>3）加入灵感</strong>       </p><p>如果是自己想要做的事情，通过自己灵感发散出来的，自己必须第一个说服自己。由于是自己对自己的强说服，对应事项的执行力和驱动力肯定远远大于别人的安排。</p><p><strong>4）成于习惯</strong>       </p><p>习惯其实跟氛围相关性很大，当整个团队氛围因子里都有某种思维时，这种思维就成为了大家的习惯。一方面，习惯和氛围会影响团队更多成员，另一方面，更多成员影响团队的习惯和氛围。如此循环，自然而然，在工作甚至日常生活中，大家都会习惯性的思考，习惯性的发现，习惯性的优秀。当然，有些坏习惯，比如推崇全员躺平的，需要考虑加强审视，尽早剔除。</p><p><strong>5）终于成就</strong>       </p><p>成就感是持续成功的永动机，是大家最好的激励老师。也许OKR前期是鼓励式的，但是只有鼓励式没有真成就这种状态就不可能持久。只有氛围成长，大家都理解了OKR的意义，才能让大家真正去挖掘成就自我、成就团队的高阶奥义。只有持续进步，才能持续的产生自我突破，团队突破，最终通过持续不断的成就和荣耀造就团队的一项又一项成功。</p><p><strong>小结：</strong>良好的OKR环境，帮助大家在枯燥的工作之余，找到适合突破自我的事情来做，岂不美哉！</p><h3 id="4-2-OKR氛围与传统KPI氛围的差异"><a href="#4-2-OKR氛围与传统KPI氛围的差异" class="headerlink" title="4.2 OKR氛围与传统KPI氛围的差异"></a>4.2 OKR氛围与传统KPI氛围的差异</h3><p>相对于传统KPI&amp;薪酬导向的企业管理氛围，OKR氛围对“团队自由度”要求更高，但是这个自由度也并不是意味着大家可以为所欲为。只是在大方向提供更为公开、透明的交流环境，给予大家一定自由度的思维扩散，让大家能发挥更多的主观能动性，自驱、自组织。而KPI式的氛围更适用于强结果导向的业务。</p><p>如果在需要创新和开拓的企业中继续采用KPI式的管理方式，图4-1 可能就是KPI氛围和OKR氛围的员工心理差异：</p><p><img src="https://segmentfault.com/img/remote/1460000042635614"></p><p>（图4-1）</p><p>例如：对于产研团队来说，如果大家都是KPI式的心理，可能明知设计存在问题，但是不一定会去点破，不想付出额外的精力去处理这类与自己绩效无关的问题。这类问题一旦集中爆发，对产品也许是致命的。而OKR氛围下，大家都希望获得更多的支持力量，遇到问题时，更愿意去挑战和协助解决。如此，当他们主导新方向突破时，振臂一呼，更容易获得更多的拥护者，集中力量办大事，更容易成功，成就他人从而成就自己。</p><h3 id="4-3-如何营造OKR工作氛围"><a href="#4-3-如何营造OKR工作氛围" class="headerlink" title="4.3 如何营造OKR工作氛围"></a>4.3 如何营造OKR工作氛围</h3><p>很多时候，OKR在组织中推行难，特别是前期刚开始的时候，究其原因，在于缺少了OKR践行的文化和氛围。刚推行OKR的时候，大家通过对目标的聚焦、对齐，达成共识，对目标的价值挖掘比较大的时候，雄心勃勃，信心暴涨。但是在真正执行过程中，大家发现OKR对个人而言是反人性的。所以践行OKR的时候，人们常常想要实现远大的目标，又难以持续走出自己的舒适区，持续付出。最后，这些OKR往往完成度偏低，大家的积极性受挫，OKR推行愈发举步维艰。</p><p>所以，我们从营造氛围出发，解决这种OKR推行问题。这里假设OKR执行过程是一个小飞轮，前期要让他运转起来，需要引导氛围，后期他转动起来之后，更要维护好氛围，为之提供源源不断的动力，OKR才能越走越远。</p><p>以OKR这个民主开放的方式，营造氛围，我们从四个维度入手：</p><h4 id="4-3-1-OKR教练制度-种子引领"><a href="#4-3-1-OKR教练制度-种子引领" class="headerlink" title="4.3.1 OKR教练制度-种子引领"></a>4.3.1 OKR教练制度-种子引领</h4><p>当你经营社区的时候，为了能带动社区的活跃氛围，你需要培养一些意见领袖，带动大家积极的讨论，OKR同样如此。</p><p>我们把这部分人称之为“OKR教练”，也可以是“OKR专家”，他们是OKR牵引行动的关键角色，OKR的理念需要他们持续引导，OKR进度追踪落地主要靠他们。让他们更好地理解原汁原味的OKR的思想，大家的执行才不会走偏。并且，他们也需要身体力行、持续学习、活跃气氛、纠偏扶正，最终引导大家对OKR的认知走向正规。</p><p>因此，管理者一定要选好OKR教练。选对教练，OKR理解正确，理念相通，推行OKR就已经成功了一半。</p><p>当然，不同的团队选定OKR教练的方式存在差异：</p><p>1）有的团队是<strong>轮流式</strong>的，这个季度是你们三人一组，下个季度是他们三人一组；</p><p>2）有的团队是<strong>自愿报名</strong>的，想当OKR教练的，自愿报名，经过管理层审核，就可以成为OKR教练；</p><p>3）有的团队是<strong>管理层指定</strong>的，对一些活跃分子，做事方式符合OKR文化的，自驱自组织能力本身就偏强的人，优先指定其为OKR教练。</p><p>至此，我们OKR教练的选取策略是：<strong>优先自愿、管理层指定补位、团队整体一致后采用轮流式</strong>。</p><p>第一阶段其实是最艰难的，大家对OKR也在探索中，自愿成为OKR教练的人数可能偏少，可以指定补位；当进入第二阶段之后，大家对OKR已经有较为统一的认知了，自愿报名的人数一般有些富余了，这时候就需要管理层筛选一下教练了；而进入第三阶段之后，大家对OKR已经有一定高度的认知了，团队自驱自组织已经成为习惯，轮流式也未尝不可。</p><h4 id="4-3-2-OKR目标导向-循序渐进"><a href="#4-3-2-OKR目标导向-循序渐进" class="headerlink" title="4.3.2 OKR目标导向-循序渐进"></a>4.3.2 OKR目标导向-循序渐进</h4><p>很多时候大家一看可以搞事，上来就挑战难度最大的，对其中的困难和曲折错误的预估，最后平时固化的迭代任务也不少（721的分配机制），能挤出的时间就更少。OKR做着做着就做成了空气，时间成了最大的阻力。</p><p><strong>举个例子：</strong></p><blockquote><p><em>最开始立OKR的时候想把日志告警做的更好，所以立OKR想要做一个日志告警平台，把各个项目做日志做归集，一起汇总告警，输出问题数排名，引起组内各个模块对线上问题的关注。</em></p><p><em>但是这个平台需要的开发人力不少，而且打通日志平台等需要别人的排期，对各个项目的了解和问题收集也需要不少时间，不确定性非常强。抛开业务任务，剩余时间，不足于完成这些工作，加上平时对于OKR执行的惰性和拖延，最后进度可想而知。</em></p><p><em>于是，第二个季度，我们只是把自己项目的日志做个归集，由近及远，由小到大，推广到更多业务，OKR执行起来，挑战小一些，能够得着，更容易获得持续的激励 和持续的动力，结果努力付出一些代价，我们顺利完成了此项OKR的落地。</em></p></blockquote><p>制定OKR是希望挑战更高目标，但是也要选择自己努力努力就能够得着的事情。正所谓“贪多嚼不烂”，制定的目标太大，时间精力预估不足，可行性不高，最后往往不了了之。这种事情如果持续进行，会严重打击大家对OKR施行的信心。</p><p> 我们OKR教练会帮助学员举例剖析目标的可行性，对于一些中长期目标或者挑战型目标，建议“分而治之”，帮助学员做好分析和过渡，循序渐进，保障其对OKR的长期信心。</p><h4 id="4-3-3-OKR过程跟踪-及时激励"><a href="#4-3-3-OKR过程跟踪-及时激励" class="headerlink" title="4.3.3 OKR过程跟踪-及时激励"></a>4.3.3 OKR过程跟踪-及时激励</h4><p><strong>生活中有哪些场景人们的效率最高？</strong></p><p>引用常见的例子，打麻将肯定算一个，一轮又一轮大家乐此不疲，是什么支持他们通宵达旦呢？</p><p>因为及时的激励，每次一轮打完，就能知道有没有赢钱，你会非常期待这种赢钱的感觉，而工作中我们也希望如此。当你去激励一个人的时候，他能兴奋半天，这半天的工作效率就能提高至少50%，特别是在攻坚的时候，如果一周激励十次，可能大部分难题都能给你拿下。</p><p><strong>我们主要的OKR激励方式有哪些？</strong></p><p>①零食畅吃，讨论会形成一种宽松、愉快的交流方式；</p><p>②正向反馈，通过正向提问，认可大家的阶段性成果并鼓励继续努力，及时激励；</p><p>③解决困难，讨论和发散问题难点，通过团队的群体力量和管理层的有力支撑解决阻塞性问题；</p><p>④参与激励，对乐于分享的同学给予OKR持续奋斗奖励（不分享也没关系）。</p><h4 id="4-3-4-OKR结果复盘-正向牵引"><a href="#4-3-4-OKR结果复盘-正向牵引" class="headerlink" title="4.3.4 OKR结果复盘-正向牵引"></a>4.3.4 OKR结果复盘-正向牵引</h4><p>在复盘OKR的时候，为了支持大家发散思维，我们提倡鼓励多一些，遇到批评和持续负反馈的时候，OKR教练们要把控好节奏，及时叫停。避免复盘会演变成批斗会，降低了大家持续投入的热情。除此之外，我们OKR教练团队也积极制定一些有意思的激励措施，引导大家更努力参与进来。这些奖励的评审，都是在公开透明的评审原则下评定出来的。</p><p>复盘会，我们会评审以下奖项进行团队<strong>正面激励</strong>：</p><p>①OKR之星 – 结果优秀</p><p>②OKR积极贡献奖 – 过程努力</p><p>③OKR积极分享奖 – 氛围积极</p><p>④月度提名激励名额 - 重大突破直接激励</p><p>当然，这些奖励奖金其实很少，每个OKR团队大概一个OKR团队奖励100至200元，主要并不是物质上的奖励，更多的是一种精神层面的激励。复盘反馈结果可以持续补充到飞轮中，形成一种积极向上的氛围引领。作为被激励者，不仅能感受到团队对自己的思考和实践的认可，更能得到整个大团队的支持，吸引更多优秀的资源加入自己的OKR建设中，把这件事做的更大，发挥出无与伦比的团队力量。</p><h3 id="4-4-氛围讨论点-变味的OKR"><a href="#4-4-氛围讨论点-变味的OKR" class="headerlink" title="4.4 氛围讨论点-变味的OKR"></a>4.4 氛围讨论点-变味的OKR</h3><p>很多人一看到开放、透明的交流环境，就想到开放式的讨论，或者工作坊式的共创。</p><p>市场上有一些咨询公司或培训机构，负责人<strong>没有真正的大团队管理经验</strong>，没有真正实践过一个完整的OKR周期， 没有真正理解过OKR精髓，却提出许多<strong>花式嫁接的OKR理论</strong>。凑一本书，两个人搭档弄个小作坊，靠着一些<strong>看似很有实操性</strong>的模式化的方法和工具，从操盘着千亿量级生意的公司那，收取高额的培训费帮做管理培训，忽悠没有经验的老板，其实就是“新瓶装旧酒”、“穿新鞋走老路”。</p><p>他们把公司的中高层管理者聚在一起，天马行空发散讨论三天三夜，最后在所有人都身心俱疲时，睡眼惺忪地拍拍屁股，愉快地决定一些，看起来似是而非的共创结果。</p><p><strong>这样的OKR执行方式真的能打造OKR氛围？</strong>着实有些危险。</p><p><img src="https://segmentfault.com/img/remote/1460000042635615"></p><p>（图4-2）</p><p>如图4-2， 主要体现在以下几点：</p><p><strong>1）发散不聚焦</strong>       </p><p>主管缺位，只有自下而上，没有自上而下。这样的OKR就是一些散兵游勇在作战，管理者想要什么是不清楚的。管理者思想上懒惰，自然难以成事。不管OKR还是KPI都是以聚焦为核心的，天马行空的发散，也只有那些忽悠老板的人才能提出这种“不切实际”、“似是而非”的“所谓实操”。</p><p><strong>2）官僚主义驱动，大家被动参与</strong>       </p><p>大家被聚集在一起，非自驱行为，大家更多的是KPI式地附和，最终的结果能有多尊重现实？最典型的心里话：老板似乎挺喜欢这个idea，那就都投这个吧，已经三天三夜了，早点结束吧。</p><p><strong>3）过于抠细节</strong>       </p><p>一方面，OKR相对于KPI的挑战性质更强，过于抠细节只会让人望而却步；另一方面，既然是管理者的OKR，战略高度是要高于底层员工的。如果发散的每个idea的底层实现都推敲一遍，那还有谁能挑战那些传说中的不可能呢？切掉了对未知全方位的探索，OKR就被切掉了翅膀，不变味才怪。</p><p>当然，我们对于原汁原味的OKR， 如 <strong>姚琼老师、明道团队、黄勇等OKR大师的理念，是非常认同和推崇的</strong>。</p><p>在这一块有何高见，<strong>真诚欢迎您在评论区与我们互动</strong>。</p><h2 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h2><p>在一个组织中，如果管理只认KPI，会失去很多机会。特别是在VUCA时代的职场里，一方面，95后和00后已成为主力军，远离物质匮乏，他们更加追求尊重、自我实现和自我超越，OKR这种上下左右地多维互动才更符合他们的理念；另一方面，信息时代，信息爆炸，正确决策的能力决定了企业的竞争力，这里仅靠少量管理层是远远不够的。因此，越来越多的互联网企业，甚至经过数字化转型的传统企业，都纷纷引入OKR改变现状。</p><p>然而，“带着KPI去执行OKR”，“以OKR之名行KPI之实”，“把OKR当做新的KPI工具”都不是原汁原味的OKR理念。这样的偏离OKR原始理念的执行方式，不仅不会对团队的氛围营造有任何益处，反而会给团队增加新的负担，让大家在“OKR式KPI的小道”上越走越远，最终只会悻悻而归。</p><p>要知道，很多企业在竞争中失利的根本原因或许并不是他们缺乏创新，而是他们对外部变化的关注缺失。如：柯达对于胶卷的执念、诺基亚对于功能机和质量的执着，他们的专利数量就证明了他们从未放弃过探索。而且，柯达早在1976年就发明了数字相机技术，在1991年就有了130万像素的数码相机，为何最后却被数码相机技术所淘汰？我想，如果他们也推行了OKR，激发了组织内所有成员的力量，敏锐的发掘到了数码相机的发展机遇，我们今天看到的将会是不一样的柯达吧！</p><p>通过本文，想必大家对于我们的OKR理念和氛围营造思路都有大致的了解。简而言之，营造氛围是传播理念的最佳渠道，毕竟“搭好台子，才能唱好戏”；共同的理念是团队自驱自组织的指南针，毕竟，在这个信息泛滥的时代，只有发挥出团队每个人的力量，集中力量办大事，才能守正出奇，持续为团队创造惊喜。</p><p>下一章，我们将会分析一下OKR执行之前的工具选择和落地形式，带大家用最小的负担引入OKR，轻松上阵！</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;本文是《OKR 之剑》系列之理念第3篇。本文就我们对于OKR理念的理解和分析，和市面上一些变味的OKR实操，和大家探讨一下OKR理念，并初步介绍一下我们通过氛围来宣扬OKR理念的主要思路。&lt;/p&gt;
&lt;h2 id=&quot;一、前言&quot;&gt;&lt;a href=&quot;#一</summary>
      
    
    
    
    <category term="OKR" scheme="http://zhangyu.info/categories/OKR/"/>
    
    
    <category term="OKR" scheme="http://zhangyu.info/tags/OKR/"/>
    
  </entry>
  
  <entry>
    <title>Linux性能优化</title>
    <link href="http://zhangyu.info/2022/11/30/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    <id>http://zhangyu.info/2022/11/30/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</id>
    <published>2022-11-29T16:00:00.000Z</published>
    <updated>2022-12-05T14:15:56.251Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/">https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</a></p><blockquote><h2 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h2><h3 id="性能指标"><a href="#性能指标" class="headerlink" title="性能指标"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87"></a>性能指标</h3><p>高并发和响应快对应着性能优化的两个核心指标：<strong>吞吐</strong>和<strong>延时</strong></p><p><img src="https://xiaozhazi.github.io/2020/05/31/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%80%E5%91%A8--CPU%E6%80%A7%E8%83%BD%E7%AF%87%28%E4%B8%8A%29/week1_1.png" alt="https://xiaozhazi.github.io/2020/05/31/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%80%E5%91%A8--CPU%E6%80%A7%E8%83%BD%E7%AF%87(%E4%B8%8A)/week1_1.png" title="https://xiaozhazi.github.io/2020/05/31/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%80%E5%91%A8--CPU%E6%80%A7%E8%83%BD%E7%AF%87(%E4%B8%8A)/week1_1.png"></p><ul><li>  <strong>应用负载</strong>角度：直接影响了产品终端的用户体验</li><li>  <strong>系统资源</strong>角度：资源使用率、饱和度等</li></ul><p><strong>性能问题的本质</strong>就是系统资源已经到达瓶颈，但请求的处理还不够快，无法支撑更多的请求。 性能分析实际上就是找出应用或系统的瓶颈，设法去避免或缓解它们。</p><ul><li>  选择指标评估应用程序和系统性能</li><li>  为应用程序和系统设置性能目标</li><li>  进行性能基准测试</li><li>  性能分析定位瓶颈</li><li>  性能监控和告警</li></ul><p>对于不同的性能问题要选取不同的性能分析工具。 下面是常用的Linux Performance Tools以及对应分析的性能问题类型。</p><p><img src="https://xiaozhazi.github.io/2020/05/31/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%80%E5%91%A8--CPU%E6%80%A7%E8%83%BD%E7%AF%87%28%E4%B8%8A%29/LinuxPerformanceTool.png" alt="https://xiaozhazi.github.io/2020/05/31/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%80%E5%91%A8--CPU%E6%80%A7%E8%83%BD%E7%AF%87(%E4%B8%8A)/LinuxPerformanceTool.png" title="https://xiaozhazi.github.io/2020/05/31/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%80%E5%91%A8--CPU%E6%80%A7%E8%83%BD%E7%AF%87(%E4%B8%8A)/LinuxPerformanceTool.png"></p><h3 id="到底应该怎么理解“平均负载”"><a href="#到底应该怎么理解“平均负载”" class="headerlink" title="到底应该怎么理解“平均负载”"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E5%88%B0%E5%BA%95%E5%BA%94%E8%AF%A5%E6%80%8E%E4%B9%88%E7%90%86%E8%A7%A3%E5%B9%B3%E5%9D%87%E8%B4%9F%E8%BD%BD"></a>到底应该怎么理解“平均负载”</h3><p>**平均负载：**单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数。它和我们传统意义上理解的CPU使用率并没有直接关系。</p><p>其中不可中断进程是正处于内核态关键流程中的进程（如常见的等待设备的I/O响应）。<strong>不可中断状态实际上是系统对进程和硬件设备的一种保护机制。</strong></p><h3 id="平均负载多少时合理"><a href="#平均负载多少时合理" class="headerlink" title="平均负载多少时合理"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E5%B9%B3%E5%9D%87%E8%B4%9F%E8%BD%BD%E5%A4%9A%E5%B0%91%E6%97%B6%E5%90%88%E7%90%86"></a>平均负载多少时合理</h3><p>实际生产环境中将系统的平均负载监控起来，根据历史数据判断负载的变化趋势。当负载存在明显升高趋势时，及时进行分析和调查。 当然也可以当设置阈值（如当平均负载高于CPU数量的70%时）</p><p>现实工作中我们会经常混淆平均负载和CPU使用率的概念，其实两者并不完全对等：</p><ul><li>  CPU密集型进程，大量CPU使用会导致平均负载升高，此时两者一致</li><li>  I/O密集型进程，等待I/O也会导致平均负载升高，此时CPU使用率并不一定高</li><li>  大量等待CPU的进程调度会导致平均负载升高，此时CPU使用率也会比较高</li></ul><p><strong>平均负载高时可能是CPU密集型进程导致，也可能是I/O繁忙导致。具体分析时可以结合mpstat/pidstat工具辅助分析负载来源</strong></p><h2 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#cpu"></a>CPU</h2><h3 id="CPU上下文切换-上"><a href="#CPU上下文切换-上" class="headerlink" title="CPU上下文切换(上)"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#cpu%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%E4%B8%8A"></a>CPU上下文切换(上)</h3><p><strong>CPU上下文切换</strong>，就是把前一个任务的CPU上下文（CPU寄存器和PC）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的位置，运行新任务。其中，保存下来的上下文会存储在系统内核中，待任务重新调度执行时再加载，保证原来的任务状态不受影响。</p><p>按照任务类型，CPU上下文切换分为：</p><ul><li>  进程上下文切换</li><li>  线程上下文切换</li><li>  中断上下文切换</li></ul><h4 id="进程上下文切换"><a href="#进程上下文切换" class="headerlink" title="进程上下文切换"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E8%BF%9B%E7%A8%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2"></a>进程上下文切换</h4><p>Linux进程按照等级权限将进程的运行空间分为内核空间和用户空间。从用户态向内核态转变时需要通过系统调用来完成。</p><p>一次系统调用过程其实进行了两次CPU上下文切换：</p><ul><li>  CPU寄存器中用户态的指令位置先保存起来，CPU寄存器更新为内核态指令的位置，跳转到内核态运行内核任务；</li><li>  系统调用结束后，CPU寄存器恢复原来保存的用户态数据，再切换到用户空间继续运行。</li></ul><p>系统调用过程中并不会涉及虚拟内存等进程用户态资源，也不会切换进程。和传统意义上的进程上下文切换不同。因此<strong>系统调用通常称为特权模式切换</strong>。</p><p>进程是由内核管理和调度的，进程上下文切换只能发生在内核态。 因此相比系统调用来说，在保存当前进程的内核状态和CPU寄存器之前，需要先把该进程的虚拟内存，栈保存下来。再加载新进程的内核态后，还要刷新进程的虚拟内存和用户栈。</p><p>进程只有在调度到CPU上运行时才需要切换上下文，有以下几种场景： CPU时间片轮流分配，系统资源不足导致进程挂起，进程通过sleep函数主动挂起，高优先级进程抢占时间片，硬件中断时CPU上的进程被挂起转而执行内核中的中断服务。</p><h4 id="线程上下文切换"><a href="#线程上下文切换" class="headerlink" title="线程上下文切换"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E7%BA%BF%E7%A8%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2"></a>线程上下文切换</h4><p>线程上下文切换分为两种：</p><ul><li>  前后线程同属于一个进程，切换时虚拟内存资源不变，只需要切换线程的私有数据，寄存器等；</li><li>  前后线程属于不同进程，与进程上下文切换相同。</li></ul><p>同进程的线程切换消耗资源较少，这也是多线程的优势。</p><h4 id="中断上下文切换"><a href="#中断上下文切换" class="headerlink" title="中断上下文切换"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E4%B8%AD%E6%96%AD%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2"></a>中断上下文切换</h4><p>中断上下文切换并不涉及到进程的用户态，因此中断上下文只包括内核态中断服务程序执行所必须的状态（CPU寄存器，内核堆栈，硬件中断参数等）。</p><p><strong>中断处理优先级比进程高，所以中断上下文切换和进程上下文切换不会同时发生</strong></p><h3 id="CPU上下文切换-下"><a href="#CPU上下文切换-下" class="headerlink" title="CPU上下文切换(下)"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#cpu%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%E4%B8%8B"></a>CPU上下文切换(下)</h3><p>通过vmstat可以查看系统总体的上下文切换情况</p></blockquote><blockquote><pre><code>vmstat 5         #每隔5s输出一组数据procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st 1  0      0 103388 145412 511056    0    0    18    60    1    1  2  1 96  0  0 0  0      0 103388 145412 511076    0    0     0     2  450 1176  1  1 99  0  0 0  0      0 103388 145412 511076    0    0     0     8  429 1135  1  1 98  0  0 0  0      0 103388 145412 511076    0    0     0     0  431 1132  1  1 98  0  0 0  0      0 103388 145412 511076    0    0     0    10  467 1195  1  1 98  0  0 1  0      0 103388 145412 511076    0    0     0     2  426 1139  1  0 99  0  0 4  0      0  95184 145412 511108    0    0     0    74  500 1228  4  1 94  0  0 0  0      0 103512 145416 511076    0    0     0   455  723 1573 12  3 83  2  0</code></pre><ul><li>  cs （context switch） 每秒上下文切换次数</li><li>  in （interrupt） 每秒中断次数</li><li>  r （runnning or runnable）就绪队列的长度，正在运行和等待CPU的进程数</li><li>  b （Blocked） 处于不可中断睡眠状态的进程数</li></ul><p>要查看每个进程的详细情况，需要使用pidstat来查看每个进程上下文切换情况</p><pre><code>pidstat -w 514时51分16秒   UID       PID   cswch/s nvcswch/s  Command14时51分21秒     0         1      0.80      0.00  systemd14时51分21秒     0         6      1.40      0.00  ksoftirqd/014时51分21秒     0         9     32.67      0.00  rcu_sched14时51分21秒     0        11      0.40      0.00  watchdog/014时51分21秒     0        32      0.20      0.00  khugepaged14时51分21秒     0       271      0.20      0.00  jbd2/vda1-814时51分21秒     0      1332      0.20      0.00  argusagent14时51分21秒     0      5265     10.02      0.00  AliSecGuard14时51分21秒     0      7439      7.82      0.00  kworker/0:214时51分21秒     0      7906      0.20      0.00  pidstat14时51分21秒     0      8346      0.20      0.00  sshd14时51分21秒     0     20654      9.82      0.00  AliYunDun14时51分21秒     0     25766      0.20      0.00  kworker/u2:114时51分21秒     0     28603      1.00      0.00  python3</code></pre><ul><li>  cswch 每秒自愿上下文切换次数 （进程无法获取所需资源导致的上下文切换）</li><li>  nvcswch 每秒非自愿上下文切换次数 （时间片轮流等系统强制调度）</li></ul><pre><code>vmstat 1 1    #首先获取空闲系统的上下文切换次数sysbench --threads=10 --max-time=300 threads run #模拟多线程切换问题vmstat 1 1    #新终端观察上下文切换情况此时发现cs数据明显升高，同时观察其他指标：r列： 远超系统CPU个数，说明存在大量CPU竞争us和sy列： sy列占比80%，说明CPU主要被内核占用in列： 中断次数明显上升，说明中断处理也是潜在问题</code></pre><p>说明运行/等待CPU的进程过多，导致大量的上下文切换，上下文切换导致系统的CPU占用率高</p><pre><code>pidstat -w -u 1  #查看到底哪个进程导致的问题</code></pre><p>从结果中看出是sysbench导致CPU使用率过高，但是pidstat输出的上下文次数加起来也并不多。分析sysbench模拟的是线程的切换，因此需要在pidstat后加-t参数查看线程指标。</p><p>另外对于中断次数过多，我们可以通过/proc/interrupts文件读取</p><pre><code>1watch -d cat /proc/interrupts</code></pre><p>发现次数变化速度最快的是重调度中断（RES），该中断用来唤醒空闲状态的CPU来调度新的任务运行。分析还是因为过多任务的调度问题，和上下文切换分析一致。</p><h3 id="某个应用的CPU使用率达到100-，怎么办？"><a href="#某个应用的CPU使用率达到100-，怎么办？" class="headerlink" title="某个应用的CPU使用率达到100%，怎么办？"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E6%9F%90%E4%B8%AA%E5%BA%94%E7%94%A8%E7%9A%84cpu%E4%BD%BF%E7%94%A8%E7%8E%87%E8%BE%BE%E5%88%B0100%E6%80%8E%E4%B9%88%E5%8A%9E"></a>某个应用的CPU使用率达到100%，怎么办？</h3><p>Linux作为多任务操作系统，将CPU时间划分为很短的时间片，通过调度器轮流分配给各个任务使用。为了维护CPU时间，Linux通过事先定义的节拍率，触发时间中断，并使用全局变了jiffies记录开机以来的节拍数。时间中断发生一次该值+1.</p><p><strong>CPU使用率</strong>，除了空闲时间以外的其他时间占总CPU时间的百分比。可以通过/proc/stat中的数据来计算出CPU使用率。因为/proc/stat时开机以来的节拍数累加值，计算出来的是开机以来的平均CPU使用率，一般意义不大。可以间隔取一段时间的两次值作差来计算该段时间内的平均CPU使用率。 <strong>性能分析工具给出的都是间隔一段时间的平均CPU使用率，要注意间隔时间的设置。</strong></p><p>CPU使用率可以通过top 或 ps来查看。分析进程的CPU问题可以通过perf，它以性能事件采样为基础，不仅可以分析系统的各种事件和内核性能，还可以用来分析指定应用程序的性能问题。</p><p>perf top / perf record / perf report （-g 开启调用关系的采样）</p><pre><code>sudo docker run --name nginx -p 10000:80 -itd feisky/nginxsudo docker run --name phpfpm -itd --network container:nginx feisky/php-fpmab -c 10 -n 100 http://XXX.XXX.XXX.XXX:10000/ #测试Nginx服务性能</code></pre><p>发现此时每秒可承受请求给长少，此时将测试的请求数从100增加到10000。 在另外一个终端运行top查看每个CPU的使用率。发现系统中几个php-fpm进程导致CPU使用率骤升。</p><p>接着用perf来分析具体是php-fpm中哪个函数导致该问题。</p><pre><code>1perf top -g -p XXXX #对某一个php-fpm进程进行分析</code></pre><p>发现其中sqrt和add_function占用CPU过多， 此时查看源码找到原来是sqrt中在发布前没有删除测试代码段，存在一个百万次的循环导致。 将该无用代码删除后发现nginx负载能力明显提升</p><h3 id="系统的CPU使用率很高，为什么找不到高CPU的应用？"><a href="#系统的CPU使用率很高，为什么找不到高CPU的应用？" class="headerlink" title="系统的CPU使用率很高，为什么找不到高CPU的应用？"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E7%B3%BB%E7%BB%9F%E7%9A%84cpu%E4%BD%BF%E7%94%A8%E7%8E%87%E5%BE%88%E9%AB%98%E4%B8%BA%E4%BB%80%E4%B9%88%E6%89%BE%E4%B8%8D%E5%88%B0%E9%AB%98cpu%E7%9A%84%E5%BA%94%E7%94%A8"></a>系统的CPU使用率很高，为什么找不到高CPU的应用？</h3><pre><code>sudo docker run --name nginx -p 10000:80 -itd feisky/nginx:spsudo docker run --name phpfpm -itd --network container:nginx feisky/php-fpm:spab -c 100 -n 1000 http://XXX.XXX.XXX.XXX:10000/ #并发100个请求测试</code></pre><p>实验结果中每秒请求数依旧不高，我们将并发请求数降为5后，nginx负载能力依旧很低。</p><p>此时用top和pidstat发现系统CPU使用率过高，但是并没有发现CPU使用率高的进程。</p><p>出现这种情况一般时我们分析时遗漏的什么信息，重新运行top命令并观察一会。发现就绪队列中处于Running状态的进行过多，超过了我们的并发请求次数5. 再仔细查看进程运行数据，发现nginx和php-fpm都处于sleep状态，真正处于运行的却是几个stress进程。</p><p>下一步就利用pidstat分析这几个stress进程，发现没有任何输出。用ps aux交叉验证发现依旧不存在该进程。说明不是工具的问题。再top查看发现stress进程的进程号变化了，此时有可能时以下两种原因导致：</p><ul><li>  进程不停的崩溃重启（如段错误/配置错误等），此时进程退出后可能又被监控系统重启；</li><li>  短时进程导致，即其他应用内部通过exec调用的外面命令，这些命令一般只运行很短时间就结束，很难用top这种间隔较长的工具来发现</li></ul><p>可以通过pstree来查找 stress的父进程，找出调用关系。</p><pre><code>pstree | grep stress</code></pre><p>发现是php-fpm调用的该子进程，此时去查看源码可以看出每个请求都会调用一个stress命令来模拟I/O压力。 之前top显示的结果是CPU使用率升高，是否真的是由该stress命令导致的，还需要继续分析。 代码中给每个请求加了verbose=1的参数后可以查看stress命令的输出，在中断测试该命令结果显示stress命令运行时存在因权限问题导致的文件创建失败的bug。</p><p>此时依旧只是猜测，下一步继续通过perf工具来分析。性能报告显示确实时stress占用了大量的CPU，通过修复权限问题来优化解决即可.</p><h3 id="系统中出现大量不可中断进程和僵尸进程怎么办？"><a href="#系统中出现大量不可中断进程和僵尸进程怎么办？" class="headerlink" title="系统中出现大量不可中断进程和僵尸进程怎么办？"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%87%BA%E7%8E%B0%E5%A4%A7%E9%87%8F%E4%B8%8D%E5%8F%AF%E4%B8%AD%E6%96%AD%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E6%80%8E%E4%B9%88%E5%8A%9E"></a>系统中出现大量不可中断进程和僵尸进程怎么办？</h3><h4 id="进程状态"><a href="#进程状态" class="headerlink" title="进程状态"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81"></a>进程状态</h4><ul><li>  R Running/Runnable，表示进程在CPU的就绪队列中，正在运行或者等待运行；</li><li>  D Disk Sleep，不可中断状态睡眠，一般表示进程正在跟硬件交互，并且交互过程中不允许被其他进程中断；</li><li>  Z Zombie，僵尸进程，表示进程实际上已经结束，但是父进程还没有回收它的资源；</li><li>  S Interruptible Sleep，可中断睡眠状态，表示进程因为等待某个事件而被系统挂起，当等待事件发生则会被唤醒并进入R状态；</li><li>  I Idle，空闲状态，用在不可中断睡眠的内核线程上。 该状态不会导致平均负载升高；</li><li>  T Stop/Traced，表示进程处于暂停或跟踪状态（SIGSTOP/SIGCONT， GDB调试）；</li><li>  X Dead，进程已经消亡，不会在top/ps中看到。</li></ul><p>对于不可中断状态，一般都是在很短时间内结束，可忽略。但是如果系统或硬件发生故障，进程可能会保持不可中断状态很久，甚至系统中出现大量不可中断状态，此时需注意是否出现了I/O性能问题。</p><p>僵尸进程一般多进程应用容易遇到，父进程来不及处理子进程状态时子进程就提前退出，此时子进程就变成了僵尸进程。大量的僵尸进程会用尽PID进程号，导致新进程无法建立。</p><h4 id="磁盘O-DIRECT问题"><a href="#磁盘O-DIRECT问题" class="headerlink" title="磁盘O_DIRECT问题"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E7%A3%81%E7%9B%98o_direct%E9%97%AE%E9%A2%98"></a>磁盘O_DIRECT问题</h4><pre><code>sudo docker run --privileged --name=app -itd feisky/app:iowaitps aux | grep &#39;/app&#39;</code></pre><p>可以看到此时有多个app进程运行，状态分别时Ss+和D+。其中后面s表示进程是一个会话的领导进程，+号表示前台进程组。</p><p>其中<strong>进程组</strong>表示一组相互关联的进程，子进程是父进程所在组的组员。 <strong>会话</strong>指共享同一个控制终端的一个或多个进程组。</p><p>用top查看系统资源发现：1）平均负载在逐渐增加，且1分钟内平均负载达到了CPU个数，说明系统可能已经有了性能瓶颈；2）僵尸进程比较多且在不停增加；3）us和sys CPU使用率都不高，iowait却比较高；4）每个进程CPU使用率也不高，但有两个进程处于D状态，可能在等待IO。</p><p>分析目前数据可知：iowait过高导致系统平均负载升高，僵尸进程不断增长说明有程序没能正确清理子进程资源。</p><p>用dstat来分析，因为它可以同时查看CPU和I/O两种资源的使用情况，便于对比分析。</p><pre><code>1dstat 1 10    #间隔1秒输出10组数据</code></pre><p>可以看到当wai（iowait）升高时磁盘请求read都会很大，说明iowait的升高和磁盘的读请求有关。接下来分析到底时哪个进程在读磁盘。</p><p>之前top查看的处于D状态的进程号，用pidstat -d -p XXX 展示进程的I/O统计数据。发现处于D状态的进程都没有任何读写操作。 在用pidstat -d 查看所有进程的I/O统计数据，看到app进程在进行磁盘读操作，每秒读取32MB的数据。进程访问磁盘必须使用系统调用处于内核态，接下来重点就是找到app进程的系统调用。</p><pre><code>1sudo strace -p XXX #对app进程调用进行跟踪</code></pre><p>报错没有权限，因为已经时root权限了。所以遇到这种情况，首先要检查进程状态是否正常。 ps命令查找该进程已经处于Z状态，即僵尸进程。</p><p>这种情况下top pidstat之类的工具无法给出更多的信息，此时像第5篇一样，用perf record -d和perf report进行分析，查看app进程调用栈。</p><p>看到app确实在通过系统调用sys_read()读取数据，并且从new_sync_read和blkdev_direct_IO看出进程时进行直接读操作，请求直接从磁盘读，没有通过缓存导致iowait升高。</p><p>通过层层分析后，root cause是app内部进行了磁盘的直接I/O。然后定位到具体代码位置进行优化即可。</p><h4 id="僵尸进程"><a href="#僵尸进程" class="headerlink" title="僵尸进程"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B"></a>僵尸进程</h4><p>上述优化后iowait显著下降，但是僵尸进程数量仍旧在增加。首先要定位僵尸进程的父进程，通过pstree -aps XXX，打印出该僵尸进程的调用树，发现父进程就是app进程。</p><p>查看app代码，看看子进程结束的处理是否正确（是否调用wait()/waitpid(),有没有注册SIGCHILD信号的处理函数等）。</p><p><strong>碰到iowait升高时，先用dstat pidstat等工具确认是否存在磁盘I/O问题，再找是哪些进程导致I/O，不能用strace直接分析进程调用时可以通过perf工具分析。</strong></p><p><strong>对于僵尸问题，用pstree找到父进程，然后看源码检查子进程结束的处理逻辑即可。</strong></p><h3 id="CPU性能指标"><a href="#CPU性能指标" class="headerlink" title="CPU性能指标"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#cpu%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87"></a>CPU性能指标</h3><ul><li><p>CPU使用率</p><ul><li>  用户CPU使用率, 包括用户态(user)和低优先级用户态(nice). 该指标过高说明应用程序比较繁忙.</li><li>  系统CPU使用率, CPU在内核态运行的时间百分比(不含中断). 该指标高说明内核比较繁忙.</li><li>  等待I/O的CPU使用率, iowait, 该指标高说明系统与硬件设备I/O交互时间比较长.</li><li>  软/硬中断CPU使用率, 该指标高说明系统中发生大量中断.</li><li>  steal CPU / guest CPU, 表示虚拟机占用的CPU百分比.</li></ul></li><li><p>平均负载</p><p>  理想情况下平均负载等于逻辑CPU个数,表示每个CPU都被充分利用. 若大于则说明系统负载较重.</p></li><li><p>进程上下文切换</p><p>  包括无法获取资源的自愿切换和系统强制调度时的非自愿切换. 上下文切换本身是保证Linux正常运行的一项核心功能. 过多的切换则会将原本运行进程的CPU时间消耗在寄存器,内核占及虚拟内存等数据保存和恢复上</p></li><li><p>CPU缓存命中率</p><p>  CPU缓存的复用情况,命中率越高性能越好. 其中L1/L2常用在单核,L3则用在多核中</p></li></ul><h3 id="性能工具"><a href="#性能工具" class="headerlink" title="性能工具"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E6%80%A7%E8%83%BD%E5%B7%A5%E5%85%B7"></a>性能工具</h3><ul><li>平均负载案例<ul><li>  先用uptime查看系统平均负载</li><li>  判断负载在升高后再用mpstat和pidstat分别查看每个CPU和每个进程CPU使用情况.找出导致平均负载较高的进程.</li></ul></li><li>上下文切换案例<ul><li>  先用vmstat查看系统上下文切换和中断次数</li><li>  再用pidstat观察进程的自愿和非自愿上下文切换情况</li><li>  最后通过pidstat观察线程的上下文切换情况</li></ul></li><li>进程CPU使用率高案例<ul><li>  先用top查看系统和进程的CPU使用情况,定位到进程</li><li>  再用perf top观察进程调用链,定位到具体函数</li></ul></li><li>系统CPU使用率高案例<ul><li>  先用top查看系统和进程的CPU使用情况,top/pidstat都无法找到CPU使用率高的进程</li><li>  重新审视top输出</li><li>  从CPU使用率不高,但是处于Running状态的进程入手</li><li>  perf record/report发现短时进程导致 (execsnoop工具)</li></ul></li><li>不可中断和僵尸进程案例<ul><li>  先用top观察iowait升高,发现大量不可中断和僵尸进程</li><li>  strace无法跟踪进程系统调用</li><li>  perf分析调用链发现根源来自磁盘直接I/O</li></ul></li><li>软中断案例<ul><li>  top观察系统软中断CPU使用率高</li><li>  查看/proc/softirqs找到变化速率较快的几种软中断</li><li>  sar命令发现是网络小包问题</li><li>  tcpdump找出网络帧的类型和来源, 确定SYN FLOOD攻击导致</li></ul></li></ul><p>根据不同的性能指标来找合适的工具:</p><p><img src="https://xiaozhazi.github.io/2020/06/03/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E5%91%A8--CPU%E6%80%A7%E8%83%BD%E7%AF%87%28%E4%B8%8B%29/performance_tool.png" alt="https://xiaozhazi.github.io/2020/06/03/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E5%91%A8--CPU%E6%80%A7%E8%83%BD%E7%AF%87(%E4%B8%8B)/performance_tool.png" title="https://xiaozhazi.github.io/2020/06/03/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E5%91%A8--CPU%E6%80%A7%E8%83%BD%E7%AF%87(%E4%B8%8B)/performance_tool.png"></p><p>在生产环境中往往开发者没有权限安装新的工具包,只能最大化利用好系统中已经安装好的工具. 因此要了解一些主流工具能够提供哪些指标分析.</p><p><img src="https://xiaozhazi.github.io/2020/06/03/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E5%91%A8--CPU%E6%80%A7%E8%83%BD%E7%AF%87%28%E4%B8%8B%29/performance_tool_1.png" alt="https://xiaozhazi.github.io/2020/06/03/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E5%91%A8--CPU%E6%80%A7%E8%83%BD%E7%AF%87(%E4%B8%8B)/performance_tool_1.png" title="https://xiaozhazi.github.io/2020/06/03/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E5%91%A8--CPU%E6%80%A7%E8%83%BD%E7%AF%87(%E4%B8%8B)/performance_tool_1.png"></p><p>先运行几个支持指标较多的工具, 如top/vmstat/pidstat,根据它们的输出可以得出是哪种类型的性能问题. 定位到进程后再用strace/perf分析调用情况进一步分析. 如果是软中断导致用/proc/softirqs</p><p><img src="https://xiaozhazi.github.io/2020/06/03/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E5%91%A8--CPU%E6%80%A7%E8%83%BD%E7%AF%87%28%E4%B8%8B%29/normal_tool.png" alt="https://xiaozhazi.github.io/2020/06/03/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E5%91%A8--CPU%E6%80%A7%E8%83%BD%E7%AF%87(%E4%B8%8B)/normal_tool.png" title="https://xiaozhazi.github.io/2020/06/03/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%BA%8C%E5%91%A8--CPU%E6%80%A7%E8%83%BD%E7%AF%87(%E4%B8%8B)/normal_tool.png"></p><h3 id="CPU优化"><a href="#CPU优化" class="headerlink" title="CPU优化"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#cpu%E4%BC%98%E5%8C%96"></a>CPU优化</h3><ul><li><p>应用程序优化</p><ul><li>  编译器优化: 编译阶段开启优化选项, 如gcc -O2</li><li>  算法优化</li><li>  异步处理: 避免程序因为等待某个资源而一直阻塞,提升程序的并发处理能力. (将轮询替换为事件通知)</li><li>  多线程代替多进程: 减少上下文切换成本</li><li>  善用缓存: 加快程序处理速度</li></ul></li><li><p>系统优化</p><ul><li>  CPU绑定: 将进程绑定要1个/多个CPU上,提高CPU缓存命中率,减少CPU调度带来的上下文切换</li><li>  CPU独占: CPU亲和性机制来分配进程</li><li>  优先级调整:使用nice适当降低非核心应用的优先级</li><li>  为进程设置资源显示: cgroups设置使用上限,防止由某个应用自身问题耗尽系统资源</li><li>  NUMA优化: CPU尽可能访问本地内存</li><li>  中断负载均衡: irpbalance,将中断处理过程自动负载均衡到各个CPU上</li></ul></li><li><p>TPS、QPS、系统吞吐量的区别和理解</p><ul><li><p>  QPS (Queries Per Second)每秒查询率,一台服务器每秒能够响应的查询次数.</p></li><li><p>TPS (Transactions Per Second)每秒事务数,软件测试的结果.</p><ul><li><p>  用户请求服务器</p></li><li><p>  服务器内部处理</p></li><li><p>服务器返回给客户</p><p>  QPS类似TPS,但是对于一个页面的访问形成一个TPS,但是一次页面请求可能包含多次对服务器的请求,可能计入多次QPS</p></li></ul></li><li><p>系统吞吐量, 包括几个重要参数:</p><ul><li><p>  QPS(TPS)</p></li><li><p>  并发数</p></li><li><p>响应时间</p><p>  QPS(TPS)=并发数/平均相应时间</p></li></ul></li></ul></li></ul><h2 id="内存"><a href="#内存" class="headerlink" title="内存"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E5%86%85%E5%AD%98"></a>内存</h2><h3 id="Linux内存是怎么工作的"><a href="#Linux内存是怎么工作的" class="headerlink" title="Linux内存是怎么工作的"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#linux%E5%86%85%E5%AD%98%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84"></a>Linux内存是怎么工作的</h3><h4 id="内存映射"><a href="#内存映射" class="headerlink" title="内存映射"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84"></a>内存映射</h4><p>大多数计算机用的主存都是动态随机访问内存(DRAM)，只有内核才可以直接访问物理内存。Linux内核给每个进程提供了一个独立的虚拟地址空间，并且这个地址空间是连续的。这样进程就可以很方便的访问内存(虚拟内存)。</p><p>虚拟地址空间的内部分为内核空间和用户空间两部分，不同字长的处理器地址空间的范围不同。32位系统内核空间占用1G，用户空间占3G。 64位系统内核空间和用户空间都是128T，分别占内存空间的最高和最低处，中间部分为未定义。</p><p>并不是所有的虚拟内存都会分配物理内存，只有实际使用的才会。分配后的物理内存通过内存映射管理。为了完成内存映射，内核为每个进程都维护了一个页表，记录虚拟地址和物理地址的映射关系。页表实际存储在CPU的内存管理单元MMU中，处理器可以直接通过硬件找出要访问的内存。</p><p>当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入内核空间分配物理内存，更新进程页表，再返回用户空间恢复进程的运行。</p><p>MMU以页为单位管理内存，页大小4KB。为了解决页表项过多问题Linux提供了<strong>多级页表</strong>和<strong>HugePage</strong>的机制。</p><h4 id="虚拟内存空间分布"><a href="#虚拟内存空间分布" class="headerlink" title="虚拟内存空间分布"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E7%A9%BA%E9%97%B4%E5%88%86%E5%B8%83"></a>虚拟内存空间分布</h4><p>用户空间内存从低到高是五种不同的内存段：</p><ul><li>  <strong>只读段</strong> 代码和常量等</li><li>  <strong>数据段</strong> 全局变量等</li><li>  <strong>堆</strong> 动态分配的内存，从低地址开始向上增长</li><li>  <strong>文件映射</strong> 动态库、共享内存等，从高地址开始向下增长</li><li>  <strong>栈</strong> 包括局部变量和函数调用的上下文等，栈的大小是固定的。一般8MB</li></ul><h4 id="内存分配与回收"><a href="#内存分配与回收" class="headerlink" title="内存分配与回收"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E4%B8%8E%E5%9B%9E%E6%94%B6"></a>内存分配与回收</h4><h5 id="分配"><a href="#分配" class="headerlink" title="分配"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E5%88%86%E9%85%8D"></a>分配</h5><p>malloc对应到系统调用上有两种实现方式：</p><ul><li>  <strong>brk()</strong> 针对小块内存(&lt;128K)，通过移动堆顶位置来分配。内存释放后不立即归还内存，而是被缓存起来。</li><li>  **mmap()**针对大块内存(&gt;128K)，直接用内存映射来分配，即在文件映射段找一块空闲内存分配。</li></ul><p>前者的缓存可以减少缺页异常的发生，提高内存访问效率。但是由于内存没有归还系统，在内存工作繁忙时，频繁的内存分配/释放会造成内存碎片。</p><p>后者在释放时直接归还系统，所以每次mmap都会发生缺页异常。在内存工作繁忙时，频繁内存分配会导致大量缺页异常，使内核管理负担增加。</p><p>上述两种调用并没有真正分配内存，这些内存只有在首次访问时，才通过缺页异常进入内核中，由内核来分配</p><h5 id="回收"><a href="#回收" class="headerlink" title="回收"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E5%9B%9E%E6%94%B6"></a>回收</h5><p>内存紧张时，系统通过以下方式来回收内存：</p><ul><li><p>  回收缓存： LRU算法回收最近最少使用的内存页面；</p></li><li><p>  回收不常访问内存： 把不常用的内存通过交换分区写入磁盘</p></li><li><p>  杀死进程： OOM内核保护机制 （进程消耗内存越大oom_score越大，占用CPU越多oom_score越小，可以通过/proc手动调整oom_adj）</p></li></ul><pre><code>    echo -16 &gt; /proc/$(pidof XXX)/oom_adj</code></pre><h4 id="如何查看内存使用情况"><a href="#如何查看内存使用情况" class="headerlink" title="如何查看内存使用情况"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5"></a>如何查看内存使用情况</h4><p>free来查看整个系统的内存使用情况</p><p>top/ps来查看某个进程的内存使用情况</p><ul><li>  <strong>VIRT</strong> 进程的虚拟内存大小</li><li>  <strong>RES</strong> 常驻内存的大小，即进程实际使用的物理内存大小，不包括swap和共享内存</li><li>  <strong>SHR</strong> 共享内存大小，与其他进程共享的内存，加载的动态链接库以及程序代码段</li><li>  <strong>%MEM</strong> 进程使用物理内存占系统总内存的百分比</li></ul><h3 id="怎样理解内存中的Buffer和Cache？"><a href="#怎样理解内存中的Buffer和Cache？" class="headerlink" title="怎样理解内存中的Buffer和Cache？"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E6%80%8E%E6%A0%B7%E7%90%86%E8%A7%A3%E5%86%85%E5%AD%98%E4%B8%AD%E7%9A%84buffer%E5%92%8Ccache"></a>怎样理解内存中的Buffer和Cache？</h3><p><strong>buffer是对磁盘数据的缓存，cache是对文件数据的缓存，它们既会用在读请求也会用在写请求中</strong></p><h3 id="如何利用系统缓存优化程序的运行效率"><a href="#如何利用系统缓存优化程序的运行效率" class="headerlink" title="如何利用系统缓存优化程序的运行效率"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96%E7%A8%8B%E5%BA%8F%E7%9A%84%E8%BF%90%E8%A1%8C%E6%95%88%E7%8E%87"></a>如何利用系统缓存优化程序的运行效率</h3><h4 id="缓存命中率"><a href="#缓存命中率" class="headerlink" title="缓存命中率"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E7%BC%93%E5%AD%98%E5%91%BD%E4%B8%AD%E7%8E%87"></a>缓存命中率</h4><p><strong>缓存命中率</strong>是指直接通过缓存获取数据的请求次数，占所有请求次数的百分比。<strong>命中率越高说明缓存带来的收益越高，应用程序的性能也就越好。</strong></p><p>安装bcc包后可以通过cachestat和cachetop来监测缓存的读写命中情况。</p><p>安装pcstat后可以查看文件在内存中的缓存大小以及缓存比例</p><pre><code>#首先安装Goexport GOPATH=~/goexport PATH=~/go/bin:$PATHgo get golang.org/x/sys/unixgo ge github.com/tobert/pcstat/pcstat</code></pre><h4 id="dd缓存加速"><a href="#dd缓存加速" class="headerlink" title="dd缓存加速"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#dd%E7%BC%93%E5%AD%98%E5%8A%A0%E9%80%9F"></a>dd缓存加速</h4></blockquote><blockquote><pre><code>dd if=/dev/sda1 of=file bs=1M count=512 #生产一个512MB的临时文件echo 3 &gt; /proc/sys/vm/drop_caches #清理缓存pcstat file #确定刚才生成文件不在系统缓存中，此时cached和percent都是0cachetop 5dd if=file of=/dev/null bs=1M #测试文件读取速度#此时文件读取性能为30+MB/s，查看cachetop结果发现并不是所有的读都落在磁盘上，读缓存命中率只有50%。dd if=file of=/dev/null bs=1M #重复上述读文件测试#此时文件读取性能为4+GB/s，读缓存命中率为100%pcstat file #查看文件file的缓存情况，100%全部缓存</code></pre><h4 id="O-DIRECT选项绕过系统缓存"><a href="#O-DIRECT选项绕过系统缓存" class="headerlink" title="O_DIRECT选项绕过系统缓存"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#o_direct%E9%80%89%E9%A1%B9%E7%BB%95%E8%BF%87%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98"></a>O_DIRECT选项绕过系统缓存</h4><pre><code>cachetop 5sudo docker run --privileged --name=app -itd feisky/app:io-directsudo docker logs app #确认案例启动成功#实验结果表明每读32MB数据都要花0.9s，且cachetop输出中显示1024次缓存全部命中</code></pre><p>但是凭感觉可知如果缓存命中读速度不应如此慢，读次数时1024，页大小为4K，五秒的时间内读取了1024*4KB数据，即每秒0.8MB，和结果中32MB相差较大。说明该案例没有充分利用缓存，怀疑系统调用设置了直接I/O标志绕过系统缓存。因此接下来观察系统调用.</p><pre><code>strace -p $(pgrep app)#strace 结果可以看到openat打开磁盘分区/dev/sdb1，传入参数为O_RDONLY|O_DIRECT</code></pre><p>这就解释了为什么读32MB数据那么慢，直接从磁盘读写肯定远远慢于缓存。找出问题后我们再看案例的源代码发现flags中指定了直接IO标志。删除该选项后重跑，验证性能变化。</p><h3 id="内存泄漏，如何定位和处理？"><a href="#内存泄漏，如何定位和处理？" class="headerlink" title="内存泄漏，如何定位和处理？"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E5%A6%82%E4%BD%95%E5%AE%9A%E4%BD%8D%E5%92%8C%E5%A4%84%E7%90%86"></a>内存泄漏，如何定位和处理？</h3><p>对应用程序来说，动态内存的分配和回收是核心又复杂的一个逻辑功能模块。管理内存的过程中会发生各种各样的“事故”：</p><ul><li>  没正确回收分配的内存，导致了泄漏</li><li>  访问的是已分配内存边界外的地址，导致程序异常退出</li></ul><h4 id="内存的分配与回收"><a href="#内存的分配与回收" class="headerlink" title="内存的分配与回收"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E5%86%85%E5%AD%98%E7%9A%84%E5%88%86%E9%85%8D%E4%B8%8E%E5%9B%9E%E6%94%B6"></a>内存的分配与回收</h4><p>虚拟内存分布从低到高分别是<strong>只读段，数据段，堆，内存映射段，栈</strong>五部分。其中会导致内存泄漏的是：</p><ul><li>  堆： 由应用程序自己来分配和管理，除非程序退出这些堆内存不会被系统自动释放。</li><li>  内存映射段：包括动态链接库和共享内存，其中共享内存由程序自动分配和管理</li></ul><p><strong>内存泄漏的危害比较大，这些忘记释放的内存，不仅应用程序自己不能访问，系统也不能把它们再次分配给其他应用。</strong> 内存泄漏不断累积甚至会耗尽系统内存.</p><h4 id="如何检测内存泄漏"><a href="#如何检测内存泄漏" class="headerlink" title="如何检测内存泄漏"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E5%A6%82%E4%BD%95%E6%A3%80%E6%B5%8B%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F"></a>如何检测内存泄漏</h4><p>预先安装systat，docker，bcc</p><pre><code>123sudo docker run --name=app -itd feisky/app:mem-leaksudo docker logs appvmstat 3</code></pre><p>可以看到free在不断下降，buffer和cache基本保持不变。说明系统的内存一致在升高。但并不能说明存在内存泄漏。此时可以通过memleak工具来跟踪系统或进程的内存分配/释放请求</p><pre><code>1/usr/share/bcc/tools/memleak -a -p $(pidof app)</code></pre><p>从memleak输出可以看到，应用在不停地分配内存，并且这些分配的地址并没有被回收。通过调用栈看到是fibonacci函数分配的内存没有释放。定位到源码后查看源码来修复增加内存释放函数即可.</p><h3 id="为什么系统的Swap变高"><a href="#为什么系统的Swap变高" class="headerlink" title="为什么系统的Swap变高"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E4%B8%BA%E4%BB%80%E4%B9%88%E7%B3%BB%E7%BB%9F%E7%9A%84swap%E5%8F%98%E9%AB%98"></a>为什么系统的Swap变高</h3><p>系统内存资源紧张时通过内存回收和OOM杀死进程来解决。其中可回收内存包括：</p><ul><li>缓存/缓冲区，属于可回收资源，在文件管理中通常叫做文件页<ul><li>被应用程序修改过暂时没写入磁盘的数据(脏页)，要先写入磁盘然后才能内存释放<ul><li>  在应用程序中通过fsync将脏页同步到磁盘</li><li>  交给系统，内核线程pdflush负责这些脏页的刷新</li></ul></li></ul></li><li>  内存映射获取的文件映射页，也可以被释放掉，下次访问时从文件重新读取</li></ul><p>对于程序自动分配的堆内存，也就是我们在内存管理中的匿名页，虽然这些内存不能直接释放，但是Linux提供了Swap机制将不常访问的内存写入到磁盘来释放内存，再次访问时从磁盘读取到内存即可。</p><h4 id="Swap原理"><a href="#Swap原理" class="headerlink" title="Swap原理"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#swap%E5%8E%9F%E7%90%86"></a>Swap原理</h4><p>Swap本质就是把一块磁盘空间或者一个本地文件当作内存来使用，包括换入和换出两个过程：</p><ul><li>  换出： 将进程暂时不用的内存数据存储到磁盘中，并释放这些内存</li><li>  换入： 进程再次访问内存时，将它们从磁盘读到内存中</li></ul><p>Linux如何衡量内存资源是否紧张？</p><ul><li><p>  <strong>直接内存回收</strong> 新的大块内存分配请求，但剩余内存不足。此时系统会回收一部分内存；</p></li><li><p><strong>kswapd0</strong> 内核线程定期回收内存。为了衡量内存使用情况，定义了pages_min,pages_low,pages_high三个阈值，并根据其来进行内存的回收操作。</p><ul><li><p>  剩余内存 &lt; pages_min，进程可用内存耗尽了，只有内核才可以分配内存</p></li><li><p>  pages_min &lt; 剩余内存 &lt; pages_low,内存压力较大，kswapd0执行内存回收，直到剩余内存 &gt; pages_high</p></li><li><p>  pages_low &lt; 剩余内存 &lt; pages_high，内存有一定压力，但可以满足新内存请求</p></li><li><p>剩余内存 &gt; pages_high，说明剩余内存较多，无内存压力</p><p>  pages_low = pages_min <em>5 / 4 pages_high = pages_min</em> 3 / 2</p></li></ul></li></ul><h4 id="NUMA-与-SWAP"><a href="#NUMA-与-SWAP" class="headerlink" title="NUMA 与 SWAP"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#numa-%E4%B8%8E-swap"></a>NUMA 与 SWAP</h4><p>很多情况下系统剩余内存较多，但SWAP依旧升高，这是由于处理器的NUMA架构。</p><p>在NUMA架构下多个处理器划分到不同的Node，每个Node都拥有自己的本地内存空间。在分析内存的使用时应该针对每个Node单独分析</p><pre><code>1numactl --hardware #查看处理器在Node的分布情况，以及每个Node的内存使用情况</code></pre><p>内存三个阈值可以通过/proc/zoneinfo来查看，该文件中还包括活跃和非活跃的匿名页/文件页数。</p><p>当某个Node内存不足时，系统可以从其他Node寻找空闲资源，也可以从本地内存中回收内存。 通过/proc/sys/vm/zone_raclaim_mode来调整。</p><ul><li>  0表示既可以从其他Node寻找空闲资源，也可以从本地回收内存</li><li>  1，2，4表示只回收本地内存，2表示可以会回脏数据回收内存，4表示可以用Swap方式回收内存。</li></ul><h4 id="swappiness"><a href="#swappiness" class="headerlink" title="swappiness"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#swappiness"></a>swappiness</h4><p>在实际回收过程中Linux根据/proc/sys/vm/swapiness选项来调整使用Swap的积极程度，从0-100，数值越大越积极使用Swap，即更倾向于回收匿名页；数值越小越消极使用Swap，即更倾向于回收文件页。</p><p><strong>注意：这只是调整Swap积极程度的权重，即使设置为0，当剩余内存+文件页小于页高阈值时，还是会发生Swap。</strong></p><h4 id="Swap升高时如何定位分析"><a href="#Swap升高时如何定位分析" class="headerlink" title="Swap升高时如何定位分析"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#swap%E5%8D%87%E9%AB%98%E6%97%B6%E5%A6%82%E4%BD%95%E5%AE%9A%E4%BD%8D%E5%88%86%E6%9E%90"></a>Swap升高时如何定位分析</h4><pre><code>free #首先通过free查看swap使用情况，若swap=0表示未配置Swap#先创建并开启swapfallocate -l 8G /mnt/swapfilechmod 600 /mnt/swapfilemkswap /mnt/swapfileswapon /mnt/swapfilefree #再次执行free确保Swap配置成功dd if=/dev/sda1 of=/dev/null bs=1G count=2048 #模拟大文件读取sar -r -S 1  #查看内存各个指标变化 -r内存 -S swap#根据结果可以看出，%memused在不断增长，剩余内存kbmemfress不断减少，缓冲区kbbuffers不断增大，由此可知剩余内存不断分配给了缓冲区#一段时间之后，剩余内存很小，而缓冲区占用了大部分内存。此时Swap使用之间增大，缓冲区和剩余内存只在小范围波动停下sar命令cachetop5 #观察缓存#可以看到dd进程读写只有50%的命中率，未命中数为4w+页，说明正式dd进程导致缓冲区使用升高watch -d grep -A 15 ‘Normal’ /proc/zoneinfo #观察内存指标变化#发现升级内存在一个小范围不停的波动，低于页低阈值时会突然增大到一个大于页高阈值的值</code></pre><p>说明剩余内存和缓冲区的波动变化正是由于内存回收和缓存再次分配的循环往复。有时候Swap用的多，有时候缓冲区波动更多。此时查看swappiness值为60，是一个相对中和的配置，系统会根据实际运行情况来选去合适的回收类型.</p><h3 id="如何“快准狠”找到系统内存存在的问题"><a href="#如何“快准狠”找到系统内存存在的问题" class="headerlink" title="如何“快准狠”找到系统内存存在的问题"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E5%A6%82%E4%BD%95%E5%BF%AB%E5%87%86%E7%8B%A0%E6%89%BE%E5%88%B0%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98"></a>如何“快准狠”找到系统内存存在的问题</h3><h4 id="内存性能指标"><a href="#内存性能指标" class="headerlink" title="内存性能指标"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E5%86%85%E5%AD%98%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87"></a>内存性能指标</h4><p><strong>系统内存指标</strong></p><ul><li>  已用内存/剩余内存</li><li>  共享内存 （tmpfs实现）</li><li>  可用内存： 包括剩余内存和可回收内存</li><li>  缓存：磁盘读取文件的页缓存，slab分配器中的可回收部分</li><li>  缓冲区： 原始磁盘块的临时存储，缓存将要写入磁盘的数据</li></ul><p><strong>进程内存指标</strong></p><ul><li>  虚拟内存： 5大部分</li><li>  常驻内存： 进程实际使用的物理内存，不包括Swap和共享内存</li><li>  共享内存： 与其他进程共享的内存，以及动态链接库和程序的代码段</li><li>  Swap内存： 通过Swap换出到磁盘的内存</li></ul><p><strong>缺页异常</strong></p><ul><li>  可以直接从物理内存中分配，次缺页异常</li><li>  需要磁盘IO介入(如Swap)，主缺页异常。 此时内存访问会慢很多</li></ul><h4 id="内存性能工具"><a href="#内存性能工具" class="headerlink" title="内存性能工具"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E5%86%85%E5%AD%98%E6%80%A7%E8%83%BD%E5%B7%A5%E5%85%B7"></a>内存性能工具</h4><p>根据不同的性能指标来找合适的工具:</p><p><img src="https://xiaozhazi.github.io/2020/06/14/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%89%E5%91%A8--%E5%86%85%E5%AD%98%E6%80%A7%E8%83%BD%E7%AF%87/metric_tool.png" alt="https://xiaozhazi.github.io/2020/06/14/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%89%E5%91%A8--%E5%86%85%E5%AD%98%E6%80%A7%E8%83%BD%E7%AF%87/metric_tool.png" title="https://xiaozhazi.github.io/2020/06/14/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%89%E5%91%A8--%E5%86%85%E5%AD%98%E6%80%A7%E8%83%BD%E7%AF%87/metric_tool.png"></p><p>内存分析工具包含的性能指标:</p><p><img src="https://xiaozhazi.github.io/2020/06/14/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%89%E5%91%A8--%E5%86%85%E5%AD%98%E6%80%A7%E8%83%BD%E7%AF%87/tool_metric.png" alt="https://xiaozhazi.github.io/2020/06/14/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%89%E5%91%A8--%E5%86%85%E5%AD%98%E6%80%A7%E8%83%BD%E7%AF%87/tool_metric.png" title="https://xiaozhazi.github.io/2020/06/14/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%89%E5%91%A8--%E5%86%85%E5%AD%98%E6%80%A7%E8%83%BD%E7%AF%87/tool_metric.png"></p><h4 id="如何迅速分析内存的性能瓶颈"><a href="#如何迅速分析内存的性能瓶颈" class="headerlink" title="如何迅速分析内存的性能瓶颈"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#%E5%A6%82%E4%BD%95%E8%BF%85%E9%80%9F%E5%88%86%E6%9E%90%E5%86%85%E5%AD%98%E7%9A%84%E6%80%A7%E8%83%BD%E7%93%B6%E9%A2%88"></a>如何迅速分析内存的性能瓶颈</h4><p>通常先运行几个覆盖面比较大的性能工具，如free，top，vmstat，pidstat等</p><ul><li>  先用free和top查看系统整体内存使用情况</li><li>  再用vmstat和pidstat，查看一段时间的趋势，从而判断内存问题的类型</li><li>  最后进行详细分析，比如内存分配分析，缓存/缓冲区分析，具体进程的内存使用分析等</li></ul><p>常见的优化思路：</p><ul><li>  最好禁止Swap，若必须开启则尽量降低swappiness的值</li><li>  减少内存的动态分配，如可以用内存池，HugePage等</li><li>  尽量使用缓存和缓冲区来访问数据。如用堆栈明确声明内存空间来存储需要缓存的数据，或者用Redis外部缓存组件来优化数据的访问</li><li>  cgroups等方式来限制进程的内存使用情况，确保系统内存不被异常进程耗尽</li><li>  /proc/pid/oom_adj调整核心应用的oom_score，保证即使内存紧张核心应用也不会被OOM杀死</li></ul><h5 id="vmstat使用详解"><a href="#vmstat使用详解" class="headerlink" title="vmstat使用详解"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#vmstat%E4%BD%BF%E7%94%A8%E8%AF%A6%E8%A7%A3"></a>vmstat使用详解</h5><p>vmstat命令是最常见的Linux/Unix监控工具，可以展现给定时间间隔的服务器的状态值,包括服务器的CPU使用率，内存使用，虚拟内存交换情况,IO读写情况。可以看到整个机器的CPU,内存,IO的使用情况，而不是单单看到各个进程的CPU使用率和内存使用率(使用场景不一样)。</p><pre><code>vmstat 2procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st 1  0      0 1379064 282244 11537528    0    0     3   104    0    0  3  0 97  0  0 0  0      0 1372716 282244 11537544    0    0     0    24 4893 8947  1  0 98  0  0 0  0      0 1373404 282248 11537544    0    0     0    96 5105 9278  2  0 98  0  0 0  0      0 1374168 282248 11537556    0    0     0     0 5001 9208  1  0 99  0  0 0  0      0 1376948 282248 11537564    0    0     0    80 5176 9388  2  0 98  0  0 0  0      0 1379356 282256 11537580    0    0     0   202 5474 9519  2  0 98  0  0 1  0      0 1368376 282256 11543696    0    0     0     0 5894 8940 12  0 88  0  0 1  0      0 1371936 282256 11539240    0    0     0 10554 6176 9481 14  1 85  1  0 1  0      0 1366184 282260 11542292    0    0     0  7456 6102 9983  7  1 91  0  0 1  0      0 1353040 282260 11556176    0    0     0 16924 7233 9578 18  1 80  1  0 0  0      0 1359432 282260 11549124    0    0     0 12576 5495 9271  7  0 92  1  0 0  0      0 1361744 282264 11549132    0    0     0    58 8606 15079  4  2 95  0  0 1  0      0 1367120 282264 11549140    0    0     0     2 5716 9205  8  0 92  0  0 0  0      0 1346580 282264 11562644    0    0     0    70 6416 9944 12  0 88  0  0 0  0      0 1359164 282264 11550108    0    0     0  2922 4941 8969  3  0 97  0  0 1  0      0 1353992 282264 11557044    0    0     0     0 6023 8917 15  0 84  0  0# 结果说明- r 表示运行队列(就是说多少个进程真的分配到CPU)，我测试的服务器目前CPU比较空闲，没什么程序在跑，当这个值超过了CPU数目，就会出现CPU瓶颈了。这个也和top的负载有关系，一般负载超过了3就比较高，超过了5就高，超过了10就不正常了，服务器的状态很危险。top的负载类似每秒的运行队列。如果运行队列过大，表示你的CPU很繁忙，一般会造成CPU使用率很高。- b 表示阻塞的进程,这个不多说，进程阻塞，大家懂的。- swpd 虚拟内存已使用的大小，如果大于0，表示你的机器物理内存不足了，如果不是程序内存泄露的原因，那么你该升级内存了或者把耗内存的任务迁移到其他机器。- free   空闲的物理内存的大小，我的机器内存总共8G，剩余3415M。- buff   Linux/Unix系统是用来存储，目录里面有什么内容，权限等的缓存，我本机大概占用300多M- cache cache直接用来记忆我们打开的文件,给文件做缓冲，我本机大概占用300多M(这里是Linux/Unix的聪明之处，把空闲的物理内存的一部分拿来做文件和目录的缓存，是为了提高 程序执行的性能，当程序使用内存时，buffer/cached会很快地被使用。)- si  每秒从磁盘读入虚拟内存的大小，如果这个值大于0，表示物理内存不够用或者内存泄露了，要查找耗内存进程解决掉。我的机器内存充裕，一切正常。- so  每秒虚拟内存写入磁盘的大小，如果这个值大于0，同上。- bi  块设备每秒接收的块数量，这里的块设备是指系统上所有的磁盘和其他块设备，默认块大小是1024byte，我本机上没什么IO操作，所以一直是0，但是我曾在处理拷贝大量数据(2-3T)的机器上看过可以达到140000/s，磁盘写入速度差不多140M每秒- bo 块设备每秒发送的块数量，例如我们读取文件，bo就要大于0。bi和bo一般都要接近0，不然就是IO过于频繁，需要调整。- in 每秒CPU的中断次数，包括时间中断- cs 每秒上下文切换次数，例如我们调用系统函数，就要进行上下文切换，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的数目,例如在apache和nginx这种web服务器中，我们一般做性能测试时会进行几千并发甚至几万并发的测试，选择web服务器的进程可以由进程或者线程的峰值一直下调，压测，直到cs到一个比较小的值，这个进程和线程数就是比较合适的值了。系统调用也是，每次调用系统函数，我们的代码就会进入内核空间，导致上下文切换，这个是很耗资源，也要尽量避免频繁调用系统函数。上下文切换次数过多表示你的CPU大部分浪费在上下文切换，导致CPU干正经事的时间少了，CPU没有充分利用，是不可取的。- us 用户CPU时间，我曾经在一个做加密解密很频繁的服务器上，可以看到us接近100,r运行队列达到80(机器在做压力测试，性能表现不佳)。- sy 系统CPU时间，如果太高，表示系统调用时间长，例如是IO操作频繁。- id 空闲CPU时间，一般来说，id + us + sy = 100,一般我认为id是空闲CPU使用率，us是用户CPU使用率，sy是系统CPU使用率。- wt 等待IO CPU时间</code></pre><h5 id="pidstat-使用详解"><a href="#pidstat-使用详解" class="headerlink" title="pidstat 使用详解"></a><a href="https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/#pidstat-%E4%BD%BF%E7%94%A8%E8%AF%A6%E8%A7%A3"></a>pidstat 使用详解</h5><p>pidstat主要用于监控全部或指定进程占用系统资源的情况,如CPU,内存、设备IO、任务切换、线程等。</p><p>使用方法：</p><ul><li>  pidstat –d interval times 统计各个进程的IO使用情况</li><li>  pidstat –u interval times 统计各个进程的CPU统计信息</li><li>  pidstat –r interval times 统计各个进程的内存使用信息</li><li>  pidstat -w interval times 统计各个进程的上下文切换</li><li>  p PID 指定PID</li></ul><p>1、统计IO使用情况</p><pre><code>pidstat -d 1 1003:02:02 PM   UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s  Command03:02:03 PM     0       816      0.00    918.81      0.00  jbd2/vda1-803:02:03 PM     0      1007      0.00      3.96      0.00  AliYunDun03:02:03 PM   997      7326      0.00   1904.95    918.81  java03:02:03 PM   997      8539      0.00      3.96      0.00  java03:02:03 PM     0     16066      0.00     35.64      0.00  cmagent03:02:03 PM   UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s  Command03:02:04 PM     0       816      0.00   1924.00      0.00  jbd2/vda1-803:02:04 PM   997      7326      0.00  11156.00   1888.00  java03:02:04 PM   997      8539      0.00      4.00      0.00  java</code></pre><ul><li>  UID</li><li>  PID</li><li>  kB_rd/s: 每秒进程从磁盘读取的数据量 KB 单位 read from disk each second KB</li><li>  kB_wr/s: 每秒进程向磁盘写的数据量 KB 单位 write to disk each second KB</li><li>  kB_ccwr/s: 每秒进程向磁盘写入，但是被取消的数据量，This may occur when the task truncates some dirty pagecache.</li><li>  iodelay: Block I/O delay, measured in clock ticks</li><li>  Command: 进程名 task name</li></ul><p>2、统计CPU使用情况</p><pre><code># 统计CPUpidstat -u 1 1003:03:33 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command03:03:34 PM     0      2321    3.96    0.00    0.00    3.96     0  ansible03:03:34 PM     0      7110    0.00    0.99    0.00    0.99     4  pidstat03:03:34 PM   997      8539    0.99    0.00    0.00    0.99     5  java03:03:34 PM   984     15517    0.99    0.00    0.00    0.99     5  java03:03:34 PM     0     24406    0.99    0.00    0.00    0.99     5  java03:03:34 PM     0     32158    3.96    0.00    0.00    3.96     2  ansible</code></pre><ul><li>  UID</li><li>  PID</li><li>  %usr: 进程在用户空间占用 cpu 的百分比</li><li>  %system: 进程在内核空间占用 CPU 百分比</li><li>  %guest: 进程在虚拟机占用 CPU 百分比</li><li>  %wait: 进程等待运行的百分比</li><li>  %CPU: 进程占用 CPU 百分比</li><li>  CPU: 处理进程的 CPU 编号</li><li>  Command: 进程名</li></ul><p>3、统计内存使用情况</p><pre><code># 统计内存pidstat -r 1 10Average:      UID       PID  minflt/s  majflt/s     VSZ    RSS   %MEM  CommandAverage:        0         1      0.20      0.00  191256   3064   0.01  systemdAverage:        0      1007      1.30      0.00  143256  22720   0.07  AliYunDunAverage:        0      6642      0.10      0.00 6301904 107680   0.33  javaAverage:      997      7326     10.89      0.00 13468904 8395848  26.04  javaAverage:        0      7795    348.15      0.00  108376   1233   0.00  pidstatAverage:      997      8539      0.50      0.00 8242256 2062228   6.40  javaAverage:      987      9518      0.20      0.00 6300944 1242924   3.85  javaAverage:        0     10280      3.70      0.00  807372   8344   0.03  aliyun-serviceAverage:      984     15517      0.40      0.00 6386464 1464572   4.54  javaAverage:        0     16066    236.46      0.00 2678332  71020   0.22  cmagentAverage:      995     20955      0.30      0.00 6312520 1408040   4.37  javaAverage:      995     20956      0.20      0.00 6093764 1505028   4.67  javaAverage:        0     23936      0.10      0.00 5302416 110804   0.34  javaAverage:        0     24406      0.70      0.00 10211672 2361304   7.32  javaAverage:        0     26870      1.40      0.00 1470212  36084   0.11  promtail</code></pre><ul><li>  UID</li><li>  PID</li><li>  Minflt/s : 每秒次缺页错误次数 （minor page faults），虚拟内存地址映射成物理内存地址产生的 page fault 次数</li><li>  Majflt/s : 每秒主缺页错误次数 (major page faults), 虚拟内存地址映射成物理内存地址时，相应 page 在 swap 中</li><li>  VSZ virtual memory usage : 该进程使用的虚拟内存 KB 单位</li><li>  RSS : 该进程使用的物理内存 KB 单位</li><li>  %MEM : 内存使用率</li><li>  Command : 该进程的命令 task name</li></ul><p>4、查看具体进程使用情况</p><pre><code>pidstat -T ALL -r -p 20955 1 1003:12:16 PM   UID       PID  minflt/s  majflt/s     VSZ    RSS   %MEM  Command03:12:17 PM   995     20955      0.00      0.00 6312520 1408040   4.37  java03:12:16 PM   UID       PID minflt-nr majflt-nr  Command03:12:17 PM   995     20955         0         0  java</code></pre></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/&quot;&gt;https://www.ctq6.cn/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/&lt;/</summary>
      
    
    
    
    <category term="linux" scheme="http://zhangyu.info/categories/linux/"/>
    
    
    <category term="linux" scheme="http://zhangyu.info/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>网卡限速工具之WonderShaper</title>
    <link href="http://zhangyu.info/2022/11/17/%E7%BD%91%E5%8D%A1%E9%99%90%E9%80%9F%E5%B7%A5%E5%85%B7%E4%B9%8BWonderShaper/"/>
    <id>http://zhangyu.info/2022/11/17/%E7%BD%91%E5%8D%A1%E9%99%90%E9%80%9F%E5%B7%A5%E5%85%B7%E4%B9%8BWonderShaper/</id>
    <published>2022-11-16T16:00:00.000Z</published>
    <updated>2022-11-17T14:51:18.905Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.cnblogs.com/greatsql/p/16641935.html">https://www.cnblogs.com/greatsql/p/16641935.html</a></p><p><a href="https://www.cnblogs.com/greatsql/p/16641935.html">网卡限速工具之WonderShaper - GreatSQL - 博客园</a></p><blockquote><ul><li>  什么是WonderShaper</li><li>  如何安装WonderShaper</li><li>  WonderShaper使用帮助</li><li>WonderShaper使用示例<ul><li>  查看网卡状态</li><li>  限制网卡速度（单位Kbps）</li><li>  取消限速</li></ul></li><li>  WonderShaper在测试中的应用</li><li>  网速单位转换</li><li>  总结</li></ul><h2 id="1-什么是WonderShaper"><a href="#1-什么是WonderShaper" class="headerlink" title="1.什么是WonderShaper"></a>1.什么是WonderShaper</h2><p>WonderShaper是用来对特定网卡进行快速限速的工具，它实际是对linux的tc命令进行封装后的shell脚本，所以使用成本比tc更低，更容易上手，以下配合测速工具speedtest一起使用</p><h2 id="2-如何安装WonderShaper"><a href="#2-如何安装WonderShaper" class="headerlink" title="2.如何安装WonderShaper"></a>2.如何安装WonderShaper</h2><pre><code>#直接拉取WonderShaper，开箱即用git clone https://github.com/magnific0/wondershaper.gitroot@****-5491:/home/soft/wondershaper# ./wondershaper -vVersion 1.4.1root@****-5491:/home/soft/wondershaper# #网速测试工具speedtest安装(Ubuntu)apt install speedtest-cli--yum install speedtest-cli (centos) </code></pre><h2 id="3-WonderShaper使用帮助"><a href="#3-WonderShaper使用帮助" class="headerlink" title="3.WonderShaper使用帮助"></a>3.WonderShaper使用帮助</h2><pre><code>root@****-5491:/home/soft/wondershaper# ./wondershaper -hUSAGE: ./wondershaper [-hcs] [-a &lt;adapter&gt;] [-d &lt;rate&gt;] [-u &lt;rate&gt;]Limit the bandwidth of an adapterOPTIONS:   -h           Show this message 【帮助信息】   -a &lt;adapter&gt; Set the adapter  【指定网卡接口】   -d &lt;rate&gt;    Set maximum download rate (in Kbps) and/or 【限制下载速度(Kbps)】   -u &lt;rate&gt;    Set maximum upload rate (in Kbps)   【限制上传速度(Kbps)】   -p           Use presets in &quot;/etc/systemd/wondershaper.conf&quot;   -f &lt;file&gt;    Use alternative preset file   -c           Clear the limits from adapter 【清除指定网卡规则，用于取消限速】   -s           Show the current status of adapter 【显示当前网卡的状态】   -v           Show the current version  【显示当前版本】   Configure HIPRIODST in &quot;/etc/systemd/wondershaper.conf&quot; for hosts   requiring high priority i.e. in case ssh uses dport 443.MODES:   wondershaper -a &lt;adapter&gt; -d &lt;rate&gt; -u &lt;rate&gt;   wondershaper -c -a &lt;adapter&gt;   wondershaper -s -a &lt;adapter&gt;EXAMPLES: 【使用示例】   wondershaper -a eth0 -d 1024 -u 512  【设置网卡eth0的上行速度为512kbps，下行速度为1024kbps】   wondershaper -a eth0 -u 512 【只设置上行速度为512kbps】   wondershaper -c -a eth0 【清除网卡eth0的规则】   wondershaper -p -f foo.conf 【设置指定的配置文件】root@****-5491:/home/soft/wondershaper#</code></pre><h2 id="4-WonderShaper使用示例"><a href="#4-WonderShaper使用示例" class="headerlink" title="4.WonderShaper使用示例"></a>4.WonderShaper使用示例</h2><h3 id="4-1查看网卡状态"><a href="#4-1查看网卡状态" class="headerlink" title="4.1查看网卡状态"></a>4.1查看网卡状态</h3><pre><code>root@****-5491:/home/soft/wondershaper# ifconfig eno1eno1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 192.168.5.103  netmask 255.255.255.0  broadcast 192.168.5.255        inet6 fe80::2c93:21f9:1931:304  prefixlen 64  scopeid 0x20&lt;link&gt;        ether c8:f7:50:7e:50:48  txqueuelen 1000  (Ethernet)        RX packets 7748809  bytes 1034513376 (1.0 GB)        RX errors 0  dropped 439  overruns 0  frame 0        TX packets 15528838  bytes 4784318169 (4.7 GB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0        device interrupt 16  memory 0x91500000-91520000 root@****-5491:/home/soft/wondershaper# ./wondershaper -s -a eno1qdisc fq_codel 0: root refcnt 2 limit 10240p flows 1024 quantum 1514 target 5.0ms interval 100.0ms memory_limit 32Mb ecn  Sent 4528052159 bytes 14890189 pkt (dropped 0, overlimits 0 requeues 4224)  backlog 0b 0p requeues 4224  maxpacket 66616 drop_overlimit 0 new_flow_count 35953 ecn_mark 0  new_flows_len 0 old_flows_len 0--测试网速root@****-5491:/home/soft/wondershaper# speedtestRetrieving speedtest.net configuration...Testing from China Telecom (120.36.98.11)...Retrieving speedtest.net server list...Selecting best server based on ping...Hosted by Fuzhou China Mobile,Fujian (Fuzhou) [589.19 km]: 14.449 msTesting download speed................................................................................-- 下载网速是171.43 Mbit/s，Download: 171.43 Mbit/sTesting upload speed......................................................................................................-- 上传网速是4.15 Mbit/sUpload: 4.15 Mbit/s</code></pre><h3 id="4-2限制网卡速度（单位Kbps）"><a href="#4-2限制网卡速度（单位Kbps）" class="headerlink" title="4.2限制网卡速度（单位Kbps）"></a>4.2限制网卡速度（单位Kbps）</h3><pre><code>-- 下行2048kbps=2 Mbit/s,上行 1024kbps=1 Mbit/sroot@****-5491:/home/soft/wondershaper# ./wondershaper -a eno1 -d 2048 -u 1024--测试网速root@****-5491:/home/soft/wondershaper# speedtestRetrieving speedtest.net configuration...Testing from China Telecom (120.36.98.11)...Retrieving speedtest.net server list...Selecting best server based on ping...Hosted by Far EasTone Telecom (Miaoli City) [722.10 km]: 174.383 msTesting download speed................................................................................-- 下行速度Download: 1.80 Mbit/sTesting upload speed......................................................................................................--上行速度Upload: 1.28 Mbit/sroot@****-5491:/home/soft/wondershaper# </code></pre><h3 id="4-3取消限速"><a href="#4-3取消限速" class="headerlink" title="4.3取消限速"></a>4.3取消限速</h3><pre><code>--取消限速root@****-5491:/home/soft/wondershaper# ./wondershaper -c -a eno1-- 查看网卡状态root@****-5491:/home/soft/wondershaper# ./wondershaper -s -a eno1qdisc fq_codel 0: root refcnt 2 limit 10240p flows 1024 quantum 1514 target 5.0ms interval 100.0ms memory_limit 32Mb ecn  Sent 123022 bytes 471 pkt (dropped 0, overlimits 0 requeues 0)  backlog 0b 0p requeues 0  maxpacket 0 drop_overlimit 0 new_flow_count 0 ecn_mark 0  new_flows_len 0 old_flows_len 0-- 测试网速root@****-5491:/home/soft/wondershaper# speedtestRetrieving speedtest.net configuration...Testing from China Telecom (120.36.98.11)...Retrieving speedtest.net server list...Selecting best server based on ping...Hosted by Far EasTone Telecom (Miaoli City) [722.10 km]: 173.886 msTesting download speed................................................................................Download: 11.29 Mbit/sTesting upload speed......................................................................................................Upload: 2.93 Mbit/sroot@****-5491:/home/soft/wondershaper#</code></pre><h2 id="5-WonderShaper在测试中的应用"><a href="#5-WonderShaper在测试中的应用" class="headerlink" title="5.WonderShaper在测试中的应用"></a>5.WonderShaper在测试中的应用</h2><ul><li><p>  测试项目：某内部数据库迁移工具</p></li><li><p>  测试目的：数据迁移中，对目标端进行限速，当取消限速后，传输速度可以恢复</p></li><li><p>测试步骤：起迁移进程，在目标端服务器上用WonderShaper工具进行限速：</p><pre><code>  -- 只限制下行速度  [#22#root@**** ~/wondershaper 14:49:32]22  ./wondershaper -a enp0s3  -d 100</code></pre></li></ul><ul><li><p>测试结果：</p><p>  限速后，写目标库单位写入行数和单位写入字节数都急剧下降，如下图：</p></li></ul><p><img src="https://img2022.cnblogs.com/other/2630741/202208/2630741-20220831094736279-1706023113.png"></p><pre><code>取消限速，恢复网络后，传输速率慢慢恢复：</code></pre><p><img src="https://img2022.cnblogs.com/other/2630741/202208/2630741-20220831094736640-1476630909.png"></p><p><img src="https://img2022.cnblogs.com/other/2630741/202208/2630741-20220831094736914-1168193485.png"></p><h2 id="6-网速单位转换"><a href="#6-网速单位转换" class="headerlink" title="6.网速单位转换"></a>6.网速单位转换</h2><pre><code>1KB/s = 8kbps = 8kb/s比如一般100M的宽带，实际是100Mbps=(100/8) MB/s=12.5 MB/s</code></pre><h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7.总结"></a>7.总结</h2><p>使用WonderShaper对网卡进行限速，在测试时可以针对性的指定网卡，指定上传速度或者指定下载速度，在测试中上传和下载速度是互不影响的，可以只限制一方；且WonderShaper工具操作简单好入手，是个不错的工具。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/greatsql/p/16641935.html&quot;&gt;https://www.cnblogs.com/greatsql/p/16641935.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://w</summary>
      
    
    
    
    <category term="linux" scheme="http://zhangyu.info/categories/linux/"/>
    
    
    <category term="linux" scheme="http://zhangyu.info/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>OKR之剑·理念篇02-OKR布道之旅</title>
    <link href="http://zhangyu.info/2022/11/17/OKR%E4%B9%8B%E5%89%91.%E7%90%86%E5%BF%B5%E7%AF%8702-OKR%E5%B8%83%E9%81%93%E4%B9%8B%E6%97%85/"/>
    <id>http://zhangyu.info/2022/11/17/OKR%E4%B9%8B%E5%89%91.%E7%90%86%E5%BF%B5%E7%AF%8702-OKR%E5%B8%83%E9%81%93%E4%B9%8B%E6%97%85/</id>
    <published>2022-11-16T16:00:00.000Z</published>
    <updated>2022-11-17T15:00:04.490Z</updated>
    
    <content type="html"><![CDATA[<p>OKR之剑（理念篇）02—— OKR布道之旅 - 掘金</p><p><a href="https://juejin.cn/post/7145641312216154119">https://juejin.cn/post/7145641312216154119</a></p><blockquote><blockquote><p>作者：vivo互联网平台产品研发团队</p></blockquote><h1 id="1、我们是如何引入的"><a href="#1、我们是如何引入的" class="headerlink" title="1、我们是如何引入的"></a>1、我们是如何引入的</h1><h2 id="1-1、企业文化匹配"><a href="#1-1、企业文化匹配" class="headerlink" title="1.1、企业文化匹配"></a>1.1、企业文化匹配</h2><p>大概是在2013年底，一些创业者在硅谷深受OKR洗礼，并在自己的公司内小范围运用，以此OKR开始传入中国。而vivo初尝OKR则是在2019年，当时的互联网管理团队注意到OKR在Google和 MicroSoft等大型公司的成功实践，于是让部门内的管理层开展OKR的学习工作。</p><p>我们自此开始了，以在平台产品研发团队内大范围落地为目标的OKR调研工作，方式大致就是找资料、找案例，再做归纳总结。通读一遍当时市面上比较经典的OKR书籍，包括《这就是OKR》、《OKR工作法》、《OKR：源于英特尔和谷歌的目标管理利器》以及《OKR使用手册》；然后又联系有Google、MicroSoft、字节跳动工作背景的员工做了访谈。</p><p>结合国内运用OKR的一些企业的具体实践，我们总结出来适用OKR的企业，需要具备的5条<strong>基本特征</strong>：</p><p><strong>1.推崇内在驱动</strong></p><blockquote><p>OKR信奉内部动机的力量，鼓励员工自主制定挑战性目标，锻炼自己的能力。在胜任岗位与能力提升的过程中收获快乐，在相互赞赏与拥抱成功中得到满足。因此顺利推行OKR需要企业为员工营造开放性、创造性的氛围，保持员工勇于挑战的进取心，而不会因为没有达成OKR目标变得沮丧消沉。</p></blockquote><p><strong>2.组织结构扁平</strong></p><blockquote><p>OKR需要经常关注目标执行情况，当遇到问题时需要及时应对调整，快速获得上级资源支持，团队内外信息互通。这就要求简化管理层次，缩短决策路径。</p></blockquote><p><strong>3.信息透明公开</strong></p><blockquote><p>OKR提倡公开透明，鼓励积极反馈。参考张一鸣在字节跳动推行的”Context，not Control”，想要OKR能够成功高效地运转，离不开透明公开的Context上下文贯穿整个体系。</p></blockquote><p><strong>4.平等沟通氛围</strong></p><blockquote><p>制定OKR需要团队成员坦诚交流，充分了解彼此的看法，最终依据企业的战略目标达成共识，因此打造极致的沟通环境，就需要能够真正做到平等公开，打破组织成员中“层级分明”的沟通障碍。</p></blockquote><p><strong>5.利益风险共享</strong></p><blockquote><p>OKR能够促进组织和个人螺旋上升的关键，在于内在驱动，而能够让员工长期稳定的发光发热，靠”情怀和信仰”是不够的，还需要一套行之有效的人才管理机制，比如股权和上升通道，满足员工求名求利求本事的实际需求，实现精神和物质的双重驱动。</p></blockquote><p>我们把公司核心价值观“<strong>本分 用户导向 设计驱动 学习 团队</strong>”与之对照，发现契合度非常高：</p><blockquote><p><strong>本分</strong>，永远保持平常心，求责于己，坚守诚信、结果导向和主人翁精神；设计驱动，是创新解决用户潜在需求、推动社会进步的系统思维方式和价值观；学习，永远保持进取心，不满足现状。创造性的设计和主动意识，以及自我提升打破个体和群体局限，这一点和OKR的内驱力异曲同工。</p><p><strong>用户导向</strong>，一切工作须以用户的真实需求为原点而展开。而当用户需求发生变化时，我们需要及时判断并做好应对，这就要求我们扁平化的结构，减少信息传递误差，提高协作和管理效率。这又和企业文化，团队这一条相互呼应，坚持以广泛和而深入的团队协作，来应对市场需求的不确定性和复杂性。</p></blockquote><p>如果一直无法见到成效和回报，而没有其他推动力的情况下，势必会导致沮丧和畏难。如企业文化中的使命所述，通过服务好用户、员工、伙伴、股东这四个利益相关方，让四个利益相关方持续Happy。这里其实也就描述了外推力（利益共同体），与OKR利益风险共享不谋而合。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/63ba8ed7f9ed4e438ebcab83d1b40238~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p>企业文化论证完，我们再看团队管理方式。长久以来，平台产品研发领导团队始终保持较强战斗力，应对不确定性，以更Open的心态打造学习型高绩效团队。以这种理念贯穿管理行为，不断优化沉淀管理经验，总结方法论。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/490ab0bcf7a0429ca493b5e831ea3832~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p>迭代至今已逐渐形成以“开放+协同”作为方向路标，以“信任+凝聚”作为动力源泉，把“传承+发展”作为通往未来的武器和盾牌的独特管理风格。而团队中持续践行的管理方法，就是强调人性，弱化KPI和绩效结果，强化目标牵引和结果导向。这一点与OKR提倡的鼓励员工勇于挑战自我，与绩效解耦的理念一致。</p><p>作者有话说：</p><blockquote><p>“这里我们是以vivo公司的企业文化来进行论述，但其实类比到其他企业，也同样适用。在中国这片神奇土地上成长起来的人和企业，都必然会深受“<strong>儒皮道骨法治</strong>”思想的熏陶和影响，其核心价值观和文化底蕴都很相似。如果说KPI属于法家治理，那OKR更接近于道家管理。一个成熟的企业，需要在不同的阶段，不同的领域中，在道和法之间倾斜平衡，找到一个更适合自己当下实情的管理模式。</p><p>人法地，地法天，天法道，道法自然。过往我们倾向于KPI模式，在国力孱弱，需要勤劳奋斗翻身做主时，是适用的，虽然压抑了道性人性，但保证了基本效率，不会走偏。而如今局势已经截然不同，也是时候拥抱更加契合国人思想根源的，更加多元化的管理模式了。”</p></blockquote><h2 id="1-2、判断引入影响"><a href="#1-2、判断引入影响" class="headerlink" title="1.2、判断引入影响"></a>1.2、判断引入影响</h2><p>分析论证到这一步，公司企业文化、管理方式和OKR都没有发现冲突点，这样我们的调研就已经完成了一半。另外一半是，引入是否能够解决旧的问题，是否又会带来新的问题？我们根据在书本中学习到的OKR相关特性，结合OKR在字节、微软等公司的实践，汇总后得到以下可能的影响：</p><p><strong>1.群体目标一致（正向）</strong></p><blockquote><p>企业文化的深度践行，为员工打造出一个平等、透明、积极、自驱的氛围和环境，但从公司战略到平台产品研发团队战略，到项目规划，到个人目标，每个层级的分解和理解，都会因为角色、重心不同发生偏差。特别是出现偏差后，如果没有及时有效的沟通手段同步，那么很可能会在年底复盘时，才发现大团队在不重要的方向浪费了精力。OKR作为一种“目标沟通工具”，能够保证大方向的一致，细节处不断修正，最终达成团队目标趋同。</p></blockquote><p><strong>2.激发组织活力（正向）</strong></p><blockquote><p>当下企业内部门细分，职能也越来越多，每个团队只为自己的团队目标负责，就导致最终协作困难，没有阶段性胜利来鼓舞，员工只会越来越沉默。而OKR鼓励员工打破个体局限，不畏惧失败和困难，是基于氛围营造、绩效不与KR直接关联、教练式管理、 以及长期利益风险共享等手段。在这种环境下，员工都是向相同的目标努力，为他人的进步而欣喜，互相之间更加信任，协作更加顺畅。</p></blockquote><p><strong>3.绩效管理挑战（负向）</strong></p><blockquote><p>OKR的推行，从制定OKR、周报、庆功会、复盘这一整套循环，需要占用团队成员的大量时间精力。而且由于OKR与绩效评估脱钩，这就导致管理者无法从OKR的执行情况直接得到员工绩效，那么势必要带来额外的绩效考评流程和考核方式。这对很多在KPI模式下“躺赢”的管理者来说，是一个新的挑战。</p></blockquote><p><strong>4.短期效果不显（负向）</strong></p><blockquote><p>引入OKR，并不代表企业面临的环境、拥有的资源发生变化，只不过能够让企业更快的应对变化。而OKR的执行效果又和决策层的心态、参与者的认知、思维方式行为方式密切相关。从一个传统的目标管理工具切换到OKR，带来的是理念的巨大变化，而改变一个习惯很难，改变思维方式更难，只有长期实践运用OKR，保持团队氛围透明公开平等，才能让OKR的价值体现不断变大。</p></blockquote><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2eaf9102ee7a457da19a1bce22d96557~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p>（图片来源：<a href="https://link.juejin.cn/?target=https://pixabay.com/zh/photos/libra-weigh-balance-weigh-out-2759820/" title="https://pixabay.com/zh/photos/libra-weigh-balance-weigh-out-2759820/">pixabay</a>）</p><p>上述罗列的负向影响，我们认为，是可以通过其他手段来解决的。首先是弱化360环评、自评，强化管理者中间过程记录，来减轻员工的接受障碍。其次是面向管理者，做好知识培训，提供相关的辅助管理工具，提高管理者的能力和效率。至于短期效果不明显的问题，我们会对管理者和领导层做好预期管理，留下足够的操作空间和时间。</p><p>结合当前我司管理模式，和当下互联网形式急剧变化产生的冲突，我们分析判断，引入OKR替代原有KPI的管理模式后带来正向结果&gt;负向结果。因此引入OKR，是可行且合适的。</p><h1 id="2、团队的引入和实践"><a href="#2、团队的引入和实践" class="headerlink" title="2、团队的引入和实践"></a>2、团队的引入和实践</h1><h2 id="2-1、团队现状分析"><a href="#2-1、团队现状分析" class="headerlink" title="2.1、团队现状分析"></a>2.1、团队现状分析</h2><p>前序调研结论出来后，我们在团队负责人的带领下快速决定，主动出击，拥抱OKR，并且为实际落地OKR这一管理工具，进行了大量的准备工作。</p><p>我们将从书籍学习到的相关知识，包括核心原理、运转模式整理到PPT上，并开始在各职能团队间宣传。我们设想过很多人可能会针对OKR提出疑问，并且也做足了功课，自认为能够给予完美的解答，然后就能有条不紊的推行下去。然而现实却给我们浇了一盆冷水：</p><p><strong>书中学到的，终究只是抽象的结论，实操却是实实在在的难题。</strong></p><p>在宣传会议上，有管理者很认同OKR的管理理念，认为可以一试；也有管理者质疑OKR，在他们理解中现有的管理模式运行的很健康，并没有发现有什么问题；甚至于有人认为OKR只是一个舶来品，到我们团队内运行很大可能会水土不服。</p><p>我们没有想到同属一个平台产品研发团队，不同角色对于OKR的理解差异居然如此之大。在这种情况下，我们只好暂停推行计划，转而冷静思考分析，到底应该怎么去落地它。我们重新观察平台产品研发团队内现有的团队，了解他们内部运作和管理的方式，经过汇总我们发现：</p><ol><li><p> **管理方式差异较大：**不同的职能线，不同的业务线管理方法千差万别，部分团队的管理风格已经偏向于OKR，弱化了KPI；绝大部分团队重度依赖KPI。</p></li><li><p> **管理能力参差不齐：**平台产品研发团队管理层，有公司内部培养的，也有一些具有其他公司的工作经验，还有个别管理者具有创业经验，不同的履历导致他们对于管理的理解都不尽相同。</p></li><li><p> **团队人员组成不同：**有一些团队，成立了很久，团队成员也都深受企业文化熏陶；也有个别团队的员工，几乎都是最近从其他公司跳槽过来的，对于公司和平台产品研发团队的信任认可程度并不高。</p></li></ol><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e0c78e30212c436b900adad28fb34517~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p>（图片来源：<a href="https://pixabay.com/zh/photos/teamwork-team-board-chalk-hatching-2499638" title="https://pixabay.com/zh/photos/teamwork-team-board-chalk-hatching-2499638">pixabay</a>）</p><p>结合平台产品研发团队的这几大现状，以及当下各团队，都已经沉淀出了一套自洽的，能够良好运转的管理理念的实际情况。我们决定在引入OKR的过程中，抛弃大刀阔斧的变革，转而用相对柔性的、平缓的方式逐步推行。我们先选择在意向较强的团队中，进行OKR试点。给予他们支持和鼓励，包括培训支持、领导支持，排除使用的心理负担。深度参与，了解他们在落地中遇到的各种困难和疑惑，及时跟进解决。在“试点-复盘-改善-试点”的循环中，不断丰富完善属于我们的推广方式以及实操姿势。</p><p>在这样的推广方式下，我们不再以扩大推广范围和速度作为目标，而是希望能够兼顾不同团队的特点，不同角色的管理风格，避免出现截趾适履的错误认知，能够更加的本地化，从而形成基于公司和团队特色风格的OKR。</p><h2 id="2-2、推进问题收集"><a href="#2-2、推进问题收集" class="headerlink" title="2.2、推进问题收集"></a>2.2、推进问题收集</h2><p>伴随着OKR落地计划的开展，我们也从试点团队陆续收到了不少的反馈和质疑，我们对问题进行了总结和归纳，这里列几个比较典型的提问给大家参考下：</p><p><strong>1.能否用目标完成度决定绩效</strong></p><blockquote><p>与产研团队有所不同的是，部分职能团队原有绩效管理是强依赖于KPI模式。在制定目标和过程跟踪，管理者和员工都做的非常细致。从上层视角鸟瞰团队目标完成情况、员工进度非常直观，而且基于完成结果给予绩效评价也非常便捷。他们内部执行OKR一段时间下来，发现还是回到了KPI的老路，根据KR达成情况来评估员工绩效。但这一方式在各个权威书籍都不建议进行关联，而且也违背了鼓励员工大胆突破的初衷，这种情况该怎么解？</p><p>针对这种情况，我们的建议是，管理理念上还是要尽量契合OKR的本意，用目标牵引的方式来激发员工，淡化考核。实操上弱关联绩效，用类KPI的方式保证下限，进行人员管理和绩效评估，也未尝不可。关于这块的详细解读，我们后续章节会有交代，此处不做赘述。</p></blockquote><p><strong>2.OKR能否应用于劳务派遣员工</strong></p><blockquote><p>公司部分增量业务、创新型业务在快速扩张时期，为了降低用人成本和项目风险，会通过第三方劳务公司雇佣大量员工，公司不直接和员工签订劳务合同，一般称为“外聘”。这类员工的薪酬、晋升的激励政策和司内自有员工不同，公司不会有太强的培养预期，无法通过前文中描述的“利益风险共享”策略持续激发员工进取心。</p><p>提出此问题的团队，之前都是利用KPI，由自有员工下达任务目标，根据达成结果来评估员工绩效。此时施行OKR，如果一味通过成长、前景、发展来给员工打鸡血，最终又无法兑付，反而会导致员工消极怠工，心生嫌隙。因此，我们建议OKR的执行层级，可以落到能够建立长期稳定信任和利益关系的层级即可，更基层可以沿用原有模式。这里的实际执行方式就是，利用OKR管理自有员工，自有员工评估外聘员工绩效时，仍然依托于KPI。</p></blockquote><p><strong>3.OKR项目与职能方向权重衡量</strong></p><blockquote><p>部分研发团队反馈，在制定OKR时，发现O都是项目方向的，个人发展和技能提升等方向无法在OKR中得到体现，这样就很容易让员工在执行过程中感觉分裂：职能线重视的事情，在项目线看来可能并不重要，如果不在个人OKR中进行追踪跟进，那么势必导致员工和团队成长滞后。但实际上技能提升、影响力提升对组织与个人的长远发展非常重要，企业文化也是要员工坚持学习进取。</p><p>我们参考了8/2黄金法则，建议员工制定个人OKR时，80%精力投入到项目和业务方向，20%精力投入到创新、探索、学习方向，来契合职能线的发展规划与预期。这样既能够保留OKR目标牵引，利用群体力量完成挑战，又能够保证个人和组织的持续发展。</p></blockquote><p>从上面列举的三个问题，仅仅只是在实际落地时，发现的相对典型的一小部分问题。更多的实际案例，在后续文章中会有介绍。我们发现这些问题，给予相关的知识、可参考的案例，跟踪团队去尝试解决验证，直到OKR的使用趋于稳定。最终有的团队选择使用承诺型OKR，有的团队使用了挑战性OKR，还有一些团队分层使用OKR和KPI的模式，百花齐放各有千秋。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/db4ff3bb9a8748a6b4adde5cf3f219f7~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p>也有一些团队在尝试一段不短的时间，虽然我们不断调整，但仍然会持续出现水土不服的情况。我们总结后发现，OKR对于落地的团队是有一定要求的，匹配度不高的团队使用OKR，是无法真正将OKR的作用发挥出来的。经过一段时间的试点运行，收集各个团队的反馈结果，我们整理出来适合OKR的团队，需要具备的三个<strong>要素</strong>：</p><blockquote><ol><li><p> **团队特色：**自我驱动、敏捷团队、基于兴趣</p></li><li><p> **业务方向：**面对高创新、高不确定性业务和工作</p></li><li><p> **管理方式：**相互信任、敢于授权、教练型领导力</p></li></ol></blockquote><p>在试点运行后，部分不适合的团队切换回KPI管理模式，这些团队的员工反而变得很轻松，而另外一些团队，在具有团队特色OKR的管理模式帮助下，业绩实现突飞猛进式的提升。当然，也有一些难题，我们现在仍然在尝试解决，去找其他有实操经验的团队进行交流探讨，去迭代优化应对方式，保持着最初的热情。如果你也有很多困惑找不到答案，或者有相关经验可以分享，欢迎加入社群，让我们一起学习成长！</p><h1 id="3、引入OKR具体步骤"><a href="#3、引入OKR具体步骤" class="headerlink" title="3、引入OKR具体步骤"></a>3、引入OKR具体步骤</h1><blockquote><p>变革：改变事物的本质——《汉语大词典》。</p></blockquote><p>这一章的标题，我们团队内部讨论了许久。为什么最后我们不用“变革”这么个非常吸引眼球的词呢？这就得说回我们公司的文化理念。公司坚持“做正确的事，并把事情做正确”，而外在环境却是在不断变化的，我们需要不停的学习进步，来适应变化，做当下以及未来对的事情。由此我们认为，任何一家公司都不需要颠覆式、推倒式的“变革”，而是基于当下自有的逻辑和理论、不断完善和优化，提高应对变化的能力。具备迎接所谓的“V（易变） U（不确定）C（复杂）A（模糊）”的复杂环境的考验和冲击，而不会因为在错误的时间使用错误的方法，导致被时代抛弃。</p><p>我们认为，OKR并不仅仅是一个目标管理方法，更是一套理念。就像达摩祖师传之言“佛教吾本来兹土，传法救迷情，一花开五叶，结果自然成”，我们希望能够通过本系列文章 ，让更多的人去理解和践行它，并能从中收益。如果此刻遍览形形色色OKR书籍的你，能够在本文中有所得，并运用之于企业内部，通过推广OKR解决现存的一些问题，让管理者如获至宝，让员工如释重负，那么也就如达摩传佛法一样，是值得回味和自豪的成就了。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9f520d1c42f64e009315dda771e6ea66~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p>（图片来源：<a href="https://pixabay.com/zh/illustrations/jesus-gospel-sermon-on-the-mount-7220256/" title="https://pixabay.com/zh/illustrations/jesus-gospel-sermon-on-the-mount-7220256/">pixabay</a>）</p><p>下面我们就开始正式进入OKR的布道之旅，按照操作顺序，甄别选型—&gt;获取授权—&gt;认知对齐—&gt;环境准备，先从甄别选型讲起。</p><h2 id="3-1、你的团队适合OKR吗？"><a href="#3-1、你的团队适合OKR吗？" class="headerlink" title="3.1、你的团队适合OKR吗？"></a>3.1、你的团队适合OKR吗？</h2><p>公司内的管理者大多都肩负着团队季度或者年度的目标，数据、营收、利润、管理等等。引入一种新的团队目标管理方法，一旦遭遇失败，那么带来的打击和影响是管理者无法承受的。如果你的团队中没有对OKR理解比较深或实际参与使用过OKR的成员，那么在刚开始做选择的时候，肯定会有这样的疑问，我们这样的团队适不适合开展OKR？所以我们希望在采用OKR之前，首先确保你的团队或者企业属于以下几个类型：</p><p><strong>1.产品更新迅速的IT/互联网团队</strong></p><blockquote><p>对比传统企业，互联网行业更容易诞生新兴的事物和现象级的产品，产品的更迭迅速也是非常普遍的现象，这对于一个专业从事互联网的团队是一个非常大的挑战，团队不仅需要有较强的执行力，同时也需要不断突破自身的局限，产品、运营团队需要对市场环境拥有较高的敏感度，技术上需要勇于创新，抓住风口。这和OKR鼓励打破局限，突破自我不谋而合，因此这类团队非常适合引入OKR目标管理模式。</p></blockquote><p><strong>2.面对非确定性工作，注重自驱的团队</strong></p><blockquote><p>OKR在员工生产力的刺激作用，主要产生于非确定性工作。如果员工日常工作内容，是类似于计件/计时类的，要求遵守流程，相对比较死板时，OKR并不能对员工效率和生产力有提升。这种情况下，使用传统的KPI绩效管理方式，则更加合适。而如果团队需要处理的工作内容，更多的是非制式的、偏设计的、需要发挥主人翁意识和创新意识才能创造更大价值的，则比较贴合OKR适用场景。</p></blockquote><p><strong>3.承载传统企业数字化转型的团队</strong></p><blockquote><p>准备转型的团队需要思考过去的模式能否适应转型发展的需要，兵法有云：“上下同欲者胜”，转型中的团队需要上下齐心，需要目标更透明、更清晰，团队成员对目标有非常高的认同，这种情况下OKR是个非常好的目标牵引工具。OKR在这类团队中发挥的作用是很大的，首先能够有效避免转型过程中决策的模糊、队员没有方向感这类情况的发生，同时能够规范团队成员的工作内容，及时矫正偏离核心目标的行为。</p></blockquote><p><strong>4.准备大干一场的创业团队</strong></p><blockquote><p>相比于成熟的企业，创业团队面临生存的风险很高，“摸索”和“走弯路”是常态，“如何确认走在正确的路上”以及“如何及时修正方向”对创业团队来说是道难题。OKR对于目标和结果的紧密结合对于初创团队是个福音，它能确保目标能够走在正确的路上。同时，初创团队内部扁平化的管理结构相对简单，层级不多，OKR的目标和绩效管理方式能够非常好的贯彻和传达。</p></blockquote><p>在后续的文章中，我们会将企业文化要求、团队要求、员工能力以及氛围、业务等多重因素考量，融合到一份评分卡中。根据评分卡，你和你的团队可以快速验证当前团队是否能够无缝切换OKR，也可以发现哪里需要补足，此处不再列举说明。</p><h2 id="3-2、教你一招说服老板用OKR！"><a href="#3-2、教你一招说服老板用OKR！" class="headerlink" title="3.2、教你一招说服老板用OKR！"></a>3.2、教你一招说服老板用OKR！</h2><p>领导与变革领域教父人物，John P. Kotter 在《领导变革》说过：“变革只有在卓越的领导而不只是优秀的管理的推动下，才能有效实施”。这本书被《时代》杂志评为最权威的管理书籍之一，几乎是C字头的管理层必读书籍，当下华为也正是用的这套理论。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dff8451de9374e95aa32882f3c11d1f5~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p>仔细研读这本书，我们将变革理解为“落后变化太多导致需要整体革新，向死而生”。虽然很多时候企业并不会让自己落入到这样的境地，但书中说明的推动变革的思考和理念还是值得借鉴的，其核心思想用白话来讲就是：</p><blockquote><p>“<strong>领导是盘古，管理是斧，想要开天，缺一不可</strong>”。</p></blockquote><p>类比到OKR的推行，我们观察到失败案例中有70%以上都存在相同的问题，那就是顶层管理者参与度太低。有一些企业在引入OKR过程中可能只是口头上一句“你去用看看，用一段时间来汇报”，或者可能非常重视中基层和员工的参与，要求他们掌握OKR操作流程，理解其中的原理，但高层自身却并不参与OKR的实际执行过程。这样运转中就会逐渐凸显一些问题，包括企业战略目标拆解偏差总是修正不及时，部门与部门之间目标不对齐，导致基层之间协作变得非常困难。同时，中高层对于OKR的效果也会存疑，毕竟顶层目标不对齐不透明，OKR的执行就流于形式，最终被无奈放弃。</p><p>再看字节跳动的张一鸣，从一开始就不遗余力在企业内推行“Context, Not Control（情景管理，而不是控制管理 ）”。为了充分发挥集体智慧的力量，打造理想中的分布式决策中心，他每季度都会提前预留两天时间，用于构思自己的OKR，制定结束后即在飞书上发布，员工们都可以直接面向他的OKR来规划自己的OKR。同时，为了纠正“Context”在不同层级的理解偏差，字节定期举行Boss面对面会议，让员工和公司高层直面沟通对齐。 多种举措之下，让字节的开放文化深刻影响了员工的日常做事方式和思考方式，人与人之间更加信任，协作更加顺畅，优秀的人才也就能最大程度上发挥了自身价值。</p><p>所以<strong>获取领导的授权和支持，是引入OKR的必要条件</strong>。</p><p>一般来讲，获取授权会遇到两种情况：你就是老板，或者你的老板深入学习过OKR，理解其中的原理，且非常支持你；你的老板听说过这个目标管理工具，对于是否推广没有想法，对于运用后的成效也比较存疑，你需要说服老板。如果你是第一种情况，那么恭喜你，最大的困难已经解决，可以跳过这一小节了。如果你是第二种情况，我们就要做好充分的准备迎接来自领导的挑战了。</p><p><strong>首先，你要尽量收集和OKR相关的素材，包括但不限于：</strong></p><p>有哪些成功应用的知名企业及何时应用的：海外的有1999谷歌、2011YouTube、2014Uber、Facebook、Twitter、LinkedIn等，国内有2019vivo、2012字节、2014知乎、2015华为、2018美的，2018阿里，2019百度、小米、腾讯等。可以看到传统型企业、互联网企业都涵盖其中，涉及的行业更是千差万别，每个企业都是根据自身特性来调整OKR的使用姿势，因地制宜。</p><p>有哪些更加鲜活的，运用OKR后获得巨大提升的例子：陈鹏鹏卤鹅饭店（2016-2018实现深圳门店1-10）、北京好韵味餐饮（2019引入实现转亏为盈，并在广州、深圳、南京等城市扩展很多分店），还有更多的实际案例此处不再列举。</p><p><strong>其次，你需要整理推行OKR能够给你们企业带来什么，你可以按图索骥，看是否当前企业中有以下问题：</strong></p><ol><li><p> 目标不一致，追溯到上层只能不了了之</p></li><li><p> 跨团队协作难度大，资源难以调动</p></li><li><p> 外部环境变化快，战略调整组织应对总是不及时</p></li><li><p> 信息不透明，层层传达逐渐失真，只能靠猜</p></li><li><p> 唯上昧下，PPT文化盛行，管理层与基层对立</p></li><li><p> 员工没有激情，混吃等死，大锅饭躺平心态</p></li></ol><p>如果有这些情况那么你就可以针对性的向你的老板推介OKR了，基于OKR自身的特性，可以让这些问题逐步瓦解，让企业发展的更快，员工更有干劲。</p><p><strong>最后，设计一个推进OKR落地的计划，其中包括：</strong></p><ol><li> 圈定试点范围，这个范围内的团队，员工要有进取心、管理者有领导力、团队氛围积极向上，越契合OKR团队要求的越好；</li><li> 组建推广小队，小队成员需要有一定影响力，比如职能线高管、部门经理、还有你的老板，不仅仅是需要小队成员的认可支持，还需要他们深度参与，为了推广OKR这个目标也可以拟定一个目标，内部各个角色进行认领分解；</li><li> 安排推介会议，包括面向圈定范围全体的宣讲动员、中高管理层答疑、小团队内部推广，针对不同人群的侧重要有所差异；</li><li> 定期复盘总结，试点范围内要不断收集过程中的正向反向的声音，调整OKR的使用姿势，达成推广小目标要给予鼓励，让团队保持信心，让老板保持信心；</li><li> 扩大推广范围，试点范围OKR执行过一段不断的周期后，当团队稳定下来，并产生好的收益时，可以重新走一遍1-5的步骤循环，直到全公司都开始运用OKR</li></ol><p>当你准备好以上内容时，就可以向老板介绍OKR这一企业发展利器了。实在不行，拉你老板进群，我们会用实战经验来帮你说服老板。</p><h2 id="3-3、知行合一：OKR推行秘诀"><a href="#3-3、知行合一：OKR推行秘诀" class="headerlink" title="3.3、知行合一：OKR推行秘诀"></a>3.3、知行合一：OKR推行秘诀</h2><blockquote><p><strong>“道理我都懂，仍然过不好这一生”—— 这背后的真相就是知行不合一。</strong></p></blockquote><p>OKR的顺利执行，并不是简单的自上而下的安排，也不是自下而上的汇报，而是需要组织所有成员对OKR达成了基本一致的认知，并且认同OKR所倡导的管理理念，管理者切实认同OKR的执行对于团队战斗力的巨大推动力，而作为个体也能认识到践行OKR对自己成长和绩效的促进作用。只有这样才能避免机械式、任务式地执行，违背引入OKR的初衷。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7e3c3cb26e5748afb3a943418d47ff40~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p>（图片来源：<a href="https://link.juejin.cn/?target=https://pixabay.com/zh/photos/head-brain-thoughts-human-body-1965675" title="https://pixabay.com/zh/photos/head-brain-thoughts-human-body-1965675">pixabay</a>）</p><p>我们公司内部推行OKR时，很多管理者都会问：“OKR和其他绩效工具，比如KPI的差异是什么？有什么优势？能解决什么问题？”。有这样的疑问其实很正常，因为对组织做任何改变，都需要非常大的成本，而且管理方式的容错成本更是无法承受。</p><p>而在布道者或者顶层管理成员来看，更可怕的是中层基层管理者不提出质疑，认为OKR简单明了不需要集中学习，不需要格外注意就可以直接试运行。也许有个别的人之前使用过，或者很容易就能理解这套目标管理工具的底层逻辑，能够保证在个体使用时很快上手，但我们推行的目标群体里的绝大多数人都是初次接触OKR，并不知道该如何使用它。</p><p>因此面对这些问题，我们可以通过对员工进行一些基本原理的分享交流，组织推广活动，例如知识分享会、PPT或者视频、组建交流群等方式，广而告之，让大家能够初次接触OKR，在心中有一个大概的轮廓，这是做信息输入。让大家知道这是一个什么样的东西，它和KPI的区别是什么，它能给大家带来什么。这有助于拉齐员工的普遍认知，让大家对OKR的理解能够达成初步共识。</p><p>同时我们建议面向不同的角色，推介时需要带有一定的偏向性，站在不同角色的视角来反向思考，怎么去进行推广，制定不同的策略。</p><h3 id="3-3-1-面向管理者"><a href="#3-3-1-面向管理者" class="headerlink" title="3.3.1 面向管理者"></a>3.3.1 面向管理者</h3><p>OKR能够发挥团队力量，叔本华说：“单个的人是软弱无力的，就像漂流的鲁滨孙一样，只有同别人在一起，他才能完成许多事业。”打造一个高绩效团队，不是管理者一个人的事情，而是需要群力。所以我们需要向管理者阐明OKR在沟通协助、组织氛围、跨组织合作等方面的天然优势，以及OKR为何能够帮助管理者打造“高绩效团队”。</p><p>当然，作为OKR引入者，也不能报喜不报忧。管理者初次运用起OKR来进行团队管理，一定会遇到以前没有遇到的问题，如果没有提前做好心理预期和解决措施，难免对OKR有所失望。这里管理者面对的挑战主要是两个，一个是管理思想，一个是管理行为。对于习惯于使用KPI进行目标管理和绩效管理的管理者，只是行为的模仿是很容易的，但涉及到思维的转变却是非常困难，这需要深入学习和实践，并且在OKR运转过程中不断复盘总结，不断调整优化，来强化理念认同度，转化思维惯性。</p><p><strong>那么思想上有哪些需要改变认知和强化理解的呢？</strong></p><p><strong>1.高绩效团队不是管出来的</strong></p><blockquote><p>放弃对员工的控制，而要转变为激励员工不断向上成长的“教练型导师”。传统的管理方式，管理者给予任务，或者员工做出任务承诺，然后根据任务完成情况给予评价，这种模式下管理者和员工一起划出了一条绩效的下限和上限，员工当然会尽量避免绩效低于下限，但同时没有特别的助力，员工并不会打破约定的绩效天花板。而OKR能够更多的体现出员工对于目标实现的参与，对管理的参与，对高级需求的追求。所以想要让员工发挥能动性，更大程度上，需要管理者放弃控制式的管理方式，转变思维，拥抱变化。</p></blockquote><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b14c3f421aeb4cb49fbb56878b80cd57~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p><strong>2.考核不是目的，而是筛选培养人才</strong></p><blockquote><p>管理者为员工评估绩效时，不可以直接将OKR与绩效挂钩。因此管理者在评估员工绩效的过程，也是管理者评估员工的“人才画像”的过程，通过参考员工KR的完成情况，还需要查看员工周报、月报中的说明，观察其为达成KR付出的努力，以及个人的成长。</p><p>“他是不是一个有强烈成功欲的人？”</p><p>“他是不是很善于学习成长？”</p><p>“他是不是敢于担当，愿意承担责任？ ”</p><p>在制定OKR目标和实施OKR考评、以及最后的OKR复盘的过程中，管理者能够很容易地发现那些乐于设置挑战性目标并努力达成的员工，以及有热情但需要持续激励的员工，针对不同特质的人才进行培养，最终组建出一个有梯度的不断成长的团队。</p><p>当然，不用KR的完成情况作为考核依据并不代表不考核，我们最终目的是为了减少内耗，提高人效，提高绩效上限。实际去衡量员工的绩效时，需要更全面的评估，OKR的执行情况可以间接参考。</p></blockquote><p><strong>3.透明公开平等是高绩效团队的培养基</strong></p><blockquote><p>我们再次强调这一点，是因为这是最容易看懂，但却最难做到的。人们总是习惯于依附强者而践踏弱者，这种强弱关系，几乎贯穿每个人的一生。在家庭中的父母与小孩，在学生时代的学生和老师，在职场中的领导和员工中，这种情况普遍存在。那么在这种天然的关系中，想要营造出公开平等，像朋友一样相处，需要的是管理者先改变自己的思维惯性。</p><p>如果员工反馈OKR执行中遇到的问题，不是给予鼓励和提供资源，而是以上位者的姿态命令和责备，那必然所有人都会谨小慎微，少做少错，不做不错，很多优秀的创意就会被扼杀，组织就会出现停滞不前甚至倒退。只有在公开、透明和 共创中，每一位员工才能更清楚的知道组织正朝着哪个方向去，自己可以贡献些什么，如何在进程中实现自我超越。</p></blockquote><p><strong>在OKR实操过程中，有哪些关键行为需要格外注意的呢？</strong></p><p><strong>1.获取团队成员的支持有些小窍门</strong></p><blockquote><p>管理者在团队内部试用OKR时，尽量多介绍对其个人绩效、成长的推动效应。从一些名人名事、有趣的知识入手，这样很容易吸引员工的注意力，让他们感兴趣。比如脱口秀演员呼兰调侃OKR的段子，比如3.3.2面向参与者中推广的理论依据和个体成功的案例等等。</p><p>另外，在内部推广的过程中，讲明白一些总结出来的特征，能够让他们快速了解到，使用OKR自己能够得到什么，需要承担和改变什么，这对于降低员工戒备心、让OKR推行的顺畅非常关键。</p></blockquote><p><strong>2.培养OKR种子选手很关键</strong></p><blockquote><p>OKR自身没有办法去约束团队内员工的行为，它更多的是一个目标牵引和沟通工具，所以顺利推行，并实现预期中的推动力，就需要每一层级每一个成员的参与。所以作为管理者，在给下一层级管理者推广OKR时，也需要做3.3.1节中面向管理者的信息输入，保证每个层级的理解都是一致的。</p><p>同时管理者还需要在团队中培养种子选手，对他们进行理念的影响和灌输，让他们理解推行OKR的益处，拥护推行OKR这一举措。理想中的种子选手一般是团队中思维活跃、思路清晰、外向能够带动氛围的，具有领袖气质的人。让他们成为OKR教练，或者团队中OKR推行的骨干成员。他们的深入参与能够有效带动团队内其他成员，这样建设积极健康向上的氛围，和透明平等公开的团队文化，就变得更加容易。在榜样效应下，打消群众的抗拒和防备心理，就能更大程度上保证整体方向正确性。</p><p>当流程成熟之后，可以适当去中心化，每个人都能形成一个服务节点，让整个OKR织入的过程能够免于形式化、运动式、交作业式的错误调性。</p></blockquote><p><strong>3.氛围营造不是说说而已</strong></p><blockquote><p>作为管理者，需要将透明公开平等的沟通氛围营造作为长期投入的工作，需要持续践行，以身作则。管理者是一个团队的风向标，他们的行为方式会直接影响员工的做事方式。在我们团队中，从团队负责人，到一级大组，到二级小组，每层的领导会有在工作日最后一天，给下级发周报。我们也提倡跨层级沟通，包括部长一对一、OfficeHour一对一等等形式，将透明公开落在实处。</p><p>在带领成员完成一轮OKR的执行，管理者需要进行复盘和总结，目的是提高OKR的执行效果，如何更好的激发大家的热情，让大家明白团队或者领导对于OKR执行的“上下限”在哪里，让员工明白自己可以“开放”到什么程度。这就是信任和试探的过程，涉及到人性的一般来讲都是缓慢难以见效的，需要贯之以恒，让成员明白领导说的和做的也是一致的。</p></blockquote><p>实际执行时，还是以团队特性不同来进行调整，就像上文罗列的有大量劳务派遣员工的团队，持续贯彻OKR的精神让整个团队保持热情同样是非常好的，但可能就不用特别关注KR的执行情况，直接关注KPI完成结果就可以了。所以，作为布道者，我们要做的是给予足够的支持和帮助，给予足够的空间和时间，像栽种树苗一样，施肥和修剪，等待它自由成长。</p><h3 id="3-3-2-面向参与者"><a href="#3-3-2-面向参与者" class="headerlink" title="3.3.2 面向参与者"></a>3.3.2 面向参与者</h3><p>2015微软因为员工大量流失，做过了一次全员调研，他们发现最让员工无法忍受的不是薪资，也不是缺少晋升通道，而是绩效考核机制。通过KPI给员工贴标签分等级，这其实是一种心理奴役，完全不能给予员工正向激励。</p><p>再看当下，00后已经在“整顿”职场。他们是在信息爆炸环境中成长起来的一代，也是在物资丰富吃穿不愁的一代，相比于80或者90后，他们已经不是单纯地在“搞钱”，而是更加关注职业发展、工作体验和个人价值。所以面向参与者，我们要站在他们的视角来看，00后群体需求层次已经上升到高于归属，尊重，触及审美甚至自我实现。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/da7c2474206743a7a0778ecec7026061~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp"></p><p>所以使用绩效薪酬来绑架员工职业生涯，很明显已经不可取。那么为了给公司更好更快的发展，为了组织更好的协同，为了员工实现个人价值和超越自我，从这个角度布道者向员工们推介OKR就显得非常有理论依据了。</p><p>有了理论的支持，我们再找一些实际的案例：苏珊·沃西，谷歌公司NO.16员工，她被《时代》杂志评为互联网行业最有影响力的女性企业家，谷歌当年刚诞生时的第一个办公室就是苏珊的车库。她曾用OKR帮助即将消失的 YouTube 完成了十倍速的增长。从2011年起，她更是每年都会入选《福布斯》的“年度100位最具影响力女性”，在她的成功背后，OKR 贡献了不可忽视的作用。这样的案例比比皆是，特别是在应用了OKR企业里，伴随着企业快速成长，也孵化出很多行业巨擘，包括谷歌、Facebook、字节跳动等等。</p><p>管理者、布道者在面向更大范围推广OKR的时候，除了上述理论和案例，也有一些推广的要点，在试运行阶段着重说明，员工的参与度和积极性会有一个较大的改善：</p><p><strong>1.你可以说：告诉我组织需要什么就行了！</strong></p><blockquote><p>OKR区别于其他目标管理工具和绩效管理工具，在于我们关注的是“去哪里”。从制定到执行的每个流程，都能够保证透明公开，每个人可见，让所有人的工作都更优参与感，提升了主人翁意识。为了达成战略目标，每个人都可以自发制定个人的目标，并为之付出努力和创意。</p><p>因为不强依赖于中间层级的传达解读，以及其个人的任务分解分派，下属层级都不再会有被“PUA”的负面情绪。组织内部工作思维的转变，由原来的被动接受任务变为现在的主动发起挑战，由原来死板执行命令的人变为一个有思想有追求的人，会让员工更加信赖企业。</p><p>原来，螺丝钉也可以有自己的想法，打工人也可以自己书写诗和远方。</p></blockquote><p><strong>2.你可以说：我可以！我能够做得更好！</strong></p><blockquote><p>OKR鼓励员工不断挑战自我，从自我提升和收获成功中得到乐趣和满足。由于不与绩效直接挂钩，所以他们就可以放下心理负担，不断突破，向更高的目标，更好的自己进发。</p><p>当员工掌握OKR的思维方式和底层逻辑后，就可以通过OKR来帮助自己聚焦于目标，基于其周期性复盘与修正的机制，让自己的进步和成长持续累积，以此向下一个目标不断迈进，最终实现个人价值的螺旋上升。</p></blockquote><p><strong>3.你可以说：拒绝内卷，从我做起！</strong></p><blockquote><p>传统绩效管理工具之下，干得好=升职加薪。所以想想当你拿到S级评价时，隔壁的兄弟：“哇塞，恭喜恭喜，实至名归啊！”，可能实际上他想的是“凭啥？明明我做的也很好！”。这是因为资源是有限的，当个人目标直接与薪酬挂钩后，一定会带来竞争&gt;合作，组织之间协同也会有利益纠纷导致内耗，效率都变得更低。</p><p>而现在我们推崇的是个人目标不再与绩效挂钩，每个人的工作都是为了公司项目的推进，竞争关系没有那么明显，大家都是一起努力的合作者。人与人之间的相处模式更融洽，协作关系会更强。当一个人取得阶段性的成功后，就能得到全员的发自内心的赞赏和鼓励。</p></blockquote><p>试问，这样的环境氛围，谁能不喜欢呢？</p><p>一般来讲，为大团队安排一次知识分享会，旨在从概念、理念上分析OKR，为所有人解读引入的动机；为管理者安排一次推广宣讲动员，旨在让管理者认同OKR对于管理工作的助益；管理者再面向团队成员进行一次内部集中学习，旨在让团队成员理解OKR对于个人绩效、目标达成的正向作用。有这三层解读，大团队就能够达成基本的认知对齐，然后就可以为OKR试运行做一些环境准备了。</p><h2 id="3-4、撸起袖子准备开干"><a href="#3-4、撸起袖子准备开干" class="headerlink" title="3.4、撸起袖子准备开干"></a>3.4、撸起袖子准备开干</h2><p>在获得老板授权、完成认知对齐后，你和你的小伙伴可能已经摩拳擦掌，准备轰轰烈烈的搞起来了。但冷静下来到这个节骨眼上，突然会有种无处下手的感觉：</p><blockquote><p><strong>怎么搞？</strong></p></blockquote><p>我们非常理解此时你的心态，因为和当初我们部门引入OKR的历程如出一辙：总经理认可支持推广，并在部门范围进行了宣导，团队负责人大力推动OKR落地，到达组这一层级就很挠头，因为没有谁能给出一套直接搬来就用的法门，结果就造就不同团队百花齐放，各有各样的做法，各有各的理解。</p><p>但总结下来，能让我们探索出因地制宜的OKR执行方式，最重要的就是：</p><blockquote><p><strong>思想上保持统一，行动上不设限制</strong></p></blockquote><ol><li><p> 不要将OKR当做解决所有问题的银弹，而只是尽力发挥其目标聚焦、信息透明、氛围营造的力量</p></li><li><p> 工具不设限，是用Excel，还是用在线文档，用OKR工具，甚至纸笔都可以</p></li><li><p> 最好有一个OKR教练，是管理者承接，还是额外找一个成员负责都可以，是几个团队共用还是团队内专属都可以</p></li><li><p> OKR每个周期多久合适？并没有明确的优劣定论，但建议不要少于2个月，不要多于6个月</p></li></ol><p>这里只是做一点简单的说明，在我们后续章节《OKR之剑（理念篇）-OKR理念认同》《OKR之剑（引入篇）-让OKR轻松上阵》中有更加详细的介绍。总而言之，放下负担，向上进发吧！</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;OKR之剑（理念篇）02—— OKR布道之旅 - 掘金&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://juejin.cn/post/7145641312216154119&quot;&gt;https://juejin.cn/post/7145641312216154119&lt;/a&gt;&lt;/p</summary>
      
    
    
    
    <category term="OKR" scheme="http://zhangyu.info/categories/OKR/"/>
    
    
    <category term="OKR" scheme="http://zhangyu.info/tags/OKR/"/>
    
  </entry>
  
  <entry>
    <title>搞懂MySQL是怎么加行级锁的</title>
    <link href="http://zhangyu.info/2022/11/17/%E6%90%9E%E6%87%82MySQL%E6%98%AF%E6%80%8E%E4%B9%88%E5%8A%A0%E8%A1%8C%E7%BA%A7%E9%94%81%E7%9A%84/"/>
    <id>http://zhangyu.info/2022/11/17/%E6%90%9E%E6%87%82MySQL%E6%98%AF%E6%80%8E%E4%B9%88%E5%8A%A0%E8%A1%8C%E7%BA%A7%E9%94%81%E7%9A%84/</id>
    <published>2022-11-16T16:00:00.000Z</published>
    <updated>2022-11-17T14:55:27.636Z</updated>
    
    <content type="html"><![CDATA[<p>保姆级教程！2 万字 + 30 张图搞懂 MySQL 是怎么加行级锁的？</p><p><a href="https://www.51cto.com/article/740013.html">https://www.51cto.com/article/740013.html</a></p><blockquote><h3 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h3><p>是不是很多人都对 MySQL 加行级锁的规则搞的迷迷糊糊，对记录一会加的是 next-key 锁，一会加是间隙锁，一会又是记录锁。</p><p>坦白说，确实还挺复杂的，但是好在我找点了点规律，也知道如何如何用命令分析加了什么类型的行级锁。</p><p>为了说清楚这三件事情：</p><p>1、MySQL 是怎么加行级锁的？有什么规则？</p><p>2、为什么 MySQL 要这么加行级锁？</p><p>3、如何用命令分析加了什么行级锁？</p><p>所以我重写了这篇文章。</p><p>目录结构如下：</p><p><img src="https://s3.51cto.com/oss/202211/17/22ba35f3845896364f69688c50b3e0595bef63.png" alt="图片" title="图片"></p><h3 id="什么-SQL-语句会加行级锁？"><a href="#什么-SQL-语句会加行级锁？" class="headerlink" title="什么 SQL 语句会加行级锁？"></a>什么 SQL 语句会加行级锁？</h3><p>InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁，所以后面的内容都是基于 InnoDB 引擎 的。</p><p>所以，在说 MySQL 是怎么加行级锁的时候，其实是在说 InnoDB 引擎是怎么加行级锁的。</p><p>普通的 select 语句是不会对记录加锁的，因为它属于快照读，是通过  MVCC（多版本并发控制）实现的。</p><p>如果要在查询时对记录加行级锁，可以使用下面这两个方式，这两种查询会加锁的语句称为锁定读。</p><pre><code>//对读取的记录加共享锁(S型锁)select ... lock in share mode;//对读取的记录加独占锁(X型锁)select ... for update;</code></pre><p>上面这两条语句必须在一个事务中，因为当事务提交了，锁就会被释放，所以在使用这两条语句的时候，要加上 begin 或者 start transaction 开启事务的语句。</p><p>**除了上面这两条锁定读语句会加行级锁之外，update 和 delete 操作都会加行级锁，且锁的类型都是独占锁(X型锁)**。</p><pre><code>//对操作的记录加独占锁(X型锁)updaet table .... where id = 1;//对操作的记录加独占锁(X型锁)delete from table where id = 1;</code></pre><p>共享锁（S锁）满足读读共享，读写互斥。独占锁（X锁）满足写写互斥、读写互斥。</p><p><img src="https://s4.51cto.com/oss/202211/17/497a3dc33343645a708825e3e6abd4cac48ff5.png" alt="图片" title="图片"></p><h3 id="行级锁有哪些种类？"><a href="#行级锁有哪些种类？" class="headerlink" title="行级锁有哪些种类？"></a>行级锁有哪些种类？</h3><p>不同隔离级别下，行级锁的种类是不同的。</p><p>在读已提交隔离级别下，行级锁的种类只有记录锁，也就是仅仅把一条记录锁上。</p><p>在可重复读隔离级别下，行级锁的种类除了有记录锁，还有间隙锁（目的是为了避免幻读），所以行级锁的种类主要有三类：</p><ul><li>  Record Lock，记录锁，也就是仅仅把一条记录锁上；</li><li>  Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；</li><li>  Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。</li></ul><p>接下来，分别介绍这三种行级锁。</p><h4 id="Record-Lock"><a href="#Record-Lock" class="headerlink" title="Record Lock"></a>Record Lock</h4><p>Record Lock 称为记录锁，锁住的是一条记录。而且记录锁是有 S 锁和 X 锁之分的：</p><ul><li>  当一个事务对一条记录加了 S 型记录锁后，其他事务也可以继续对该记录加 S 型记录锁（S 型与 S 锁兼容），但是不可以对该记录加 X 型记录锁（S 型与 X 锁不兼容）;</li><li>  当一个事务对一条记录加了 X 型记录锁后，其他事务既不可以对该记录加 S 型记录锁（S 型与 X 锁不兼容），也不可以对该记录加 X 型记录锁（X 型与 X 锁不兼容）。</li></ul><p>举个例子，当一个事务执行了下面这条语句：</p><pre><code>mysql &gt; begin;mysql &gt; select * from t_test where id = 1 for update;</code></pre><p>事务会对表中主键 id = 1 的这条记录加上 X 型的记录锁，如果这时候其他事务对这条记录进行删除或者更新操作，那么这些操作都会被阻塞。注意，其他事务插入一条 id = 1 的新记录并不会被阻塞，而是会报主键冲突的错误，这是因为主键有唯一性的约束。</p><p><img src="https://s2.51cto.com/oss/202211/17/67eff2c26578e6a34e83345845ca6c35594f0c.png" alt="图片" title="图片"></p><p>当事务执行 commit 后，事务过程中生成的锁都会被释放。</p><h4 id="Gap-Lock"><a href="#Gap-Lock" class="headerlink" title="Gap Lock"></a>Gap Lock</h4><p>Gap Lock 称为间隙锁，只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下幻读的现象。</p><p>假设，表中有一个范围 id 为（3，5）间隙锁，那么其他事务就无法插入 id = 4 这条记录了，这样就有效的防止幻读现象的发生。</p><p><img src="https://s8.51cto.com/oss/202211/17/350d0ad07ddb5b5f5b821628f2f62b7bc75ac9.png" alt="图片" title="图片"></p><p>间隙锁虽然存在 X 型间隙锁和 S 型间隙锁，但是并没有什么区别，间隙锁之间是兼容的，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出的。</p><h4 id="Next-Key-Lock"><a href="#Next-Key-Lock" class="headerlink" title="Next-Key Lock"></a>Next-Key Lock</h4><p>Next-Key Lock 称为临键锁，是 Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。</p><p>假设，表中有一个范围 id 为（3，5] 的 next-key lock，那么其他事务即不能插入 id = 4 记录，也不能修改和删除 id = 5 这条记录。</p><p><img src="https://s5.51cto.com/oss/202211/17/a4db4650124dd8d27f7625f154acf4b3a49d95.png" alt="图片" title="图片"></p><p>所以，next-key lock 即能保护该记录，又能阻止其他事务将新记录插入到被保护记录前面的间隙中。</p><p>next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的。</p><p>比如，一个事务持有了范围为 (1, 10] 的 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，就会被阻塞。</p><p>虽然相同范围的间隙锁是多个事务相互兼容的，但对于记录锁，我们是要考虑 X 型与 S 型关系，X 型的记录锁与 X 型的记录锁是冲突的。</p><h3 id="MySQL-是怎么加行级锁的？"><a href="#MySQL-是怎么加行级锁的？" class="headerlink" title="MySQL 是怎么加行级锁的？"></a>MySQL 是怎么加行级锁的？</h3><p>行级锁加锁规则比较复杂，不同的场景，加锁的形式是不同的。</p><p>加锁的对象是索引，加锁的基本单位是 next-key lock，它是由记录锁和间隙锁组合而成的，next-key lock 是前开后闭区间，而间隙锁是前开后开区间。</p><p>但是，next-key lock 在一些场景下会退化成记录锁或间隙锁。</p><p>那到底是什么场景呢？总结一句，在能使用记录锁或者间隙锁就能避免幻读现象的场景下， next-key lock  就会退化成退化成记录锁或间隙锁。</p><p>这次会以下面这个表结构来进行实验说明：</p><pre><code>CREATE TABLE `user` (  `id` bigint NOT NULL AUTO_INCREMENT,  `name` varchar(30) COLLATE utf8mb4_unicode_ci NOT NULL,  `age` int NOT NULL,  PRIMARY KEY (`id`),  KEY `index_age` (`age`) USING BTREE) ENGINE=InnoDB  DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;</code></pre><p>其中，id 是主键索引（唯一索引），age 是普通索引（非唯一索引），name 是普通的列。</p><p>表中的有这些行记录：</p><p><img src="https://s8.51cto.com/oss/202211/17/b8c11cf0949bda4061f031cd804b9fc1024723.png" alt="图片" title="图片"></p><p>这次实验环境的 MySQL 版本是 8.0.26，隔离级别是「可重复读」。</p><p>不同版本的加锁规则可能是不同的，但是大体上是相同的。</p><h4 id="唯一索引等值查询"><a href="#唯一索引等值查询" class="headerlink" title="唯一索引等值查询"></a>唯一索引等值查询</h4><p>当我们用唯一索引进行等值查询的时候，查询的记录存不存在，加锁的规则也会不同：</p><p>当查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的 next-key lock 会退化成「记录锁」。</p><p>当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的 next-key lock 会退化成「间隙锁」。</p><p>接下里用两个案例来说明。</p><p><strong>1、记录存在的情况</strong></p><p>假设事务 A 执行了这条等值查询语句，查询的记录是「存在」于表中的。</p><pre><code>mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user where id = 1 for update;+----+--------+-----+| id | name   | age |+----+--------+-----+|  1 | 路飞   |  19 |+----+--------+-----+1 row in set (0.02 sec)</code></pre><p>那么，事务 A 会为 id 为 1 的这条记录就会加上 X 型的记录锁。</p><p><img src="https://s8.51cto.com/oss/202211/17/335b7ad611ad93cfd1263812e5655f9006df4a.png" alt="图片" title="图片"></p><p>接下来，如果有其他事务，对 id 为 1 的记录进行更新或者删除操作的话，这些操作都会被阻塞，因为更新或者删除操作也会对记录加 X 型的记录锁，而 X 锁和 X 锁之间是互斥关系。</p><p>比如，下面这个例子：</p><p><img src="https://s2.51cto.com/oss/202211/17/93f69fb720cfdab30882855af09c5c29d995fd.png" alt="图片" title="图片"></p><p>因为事务 A 对 id = 1的记录加了 X 型的记录锁，所以事务 B 在修改 id=1 的记录时会被阻塞，事务 C 在删除 id=1 的记录时也会被阻塞。</p><p>有什么命令可以分析加了什么锁？</p><p><img src="https://s3.51cto.com/oss/202211/17/f104a2c17dda54ed0cc106adff7fe2cae5c59b.png" alt="图片" title="图片"></p><p>我们可以通过 select * from performance_schema.data_locks\G; 这条语句，查看事务执行 SQL 过程中加了什么锁。</p><p>我们以前面的事务 A 作为例子，分析下下它加了什么锁。</p><p>从上图可以看到，共加了两个锁，分别是：</p><ul><li>  表锁：X 类型的意向锁；</li><li>  行锁：X 类型的记录锁；</li></ul><p>这里我们重点关注行级锁，图中 LOCK_TYPE 中的 RECORD 表示行级锁，而不是记录锁的意思。</p><p>通过 LOCK_MODE 可以确认是 next-key 锁，还是间隙锁，还是记录锁：</p><ul><li>  如果 LOCK_MODE 为X，说明是 next-key 锁；</li><li>  如果 LOCK_MODE 为X, REC_NOT_GAP，说明是记录锁；</li><li>  如果 LOCK_MODE 为X, GAP，说明是间隙锁；</li></ul><p>因此，此时事务 A 在 id = 1 记录的主键索引上加的是记录锁，锁住的范围是 id 为 1 的这条记录。这样其他事务就无法对 id 为 1 的这条记录进行更新和删除操作了。</p><p>从这里我们也可以得知，加锁的对象是针对索引，因为这里查询语句扫描的 B+ 树是聚簇索引树，即主键索引树，所以是对主键索引加锁。将对应记录的主键索引加 记录锁后，就意味着其他事务无法对该记录进行更新和删除操作了。</p><p>为什么唯一索引等值查询并且查询记录存在的场景下，该记录的索引中的 next-key lock 会退化成记录锁？</p><p>原因就是在唯一索引等值查询并且查询记录存在的场景下，仅靠记录锁也能避免幻读的问题。</p><p>幻读的定义就是，当一个事务前后两次查询的结果集，不相同时，就认为发生幻读。所以，要避免幻读就是避免结果集某一条记录被其他事务删除，或者有其他事务插入了一条新记录，这样前后两次查询的结果集就不会出现不相同的情况。</p><ul><li>  由于主键具有唯一性，所以其他事务插入 id = 1 的时候，会因为主键冲突，导致无法插入 id = 1 的新记录。这样事务 A 在多次查询  id = 1 的记录的时候，不会出现前后两次查询的结果集不同，也就避免了幻读的问题。</li><li>  由于对 id = 1 加了记录锁，其他事务无法删除该记录，这样事务 A 在多次查询  id = 1 的记录的时候，不会出现前后两次查询的结果集不同，也就避免了幻读的问题。</li></ul><p><strong>2、记录不存在的情况</strong></p><p>假设事务 A 执行了这条等值查询语句，查询的记录是「不存在」于表中的。</p><pre><code>mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user where id = 2 for update;Empty set (0.03 sec)</code></pre><p>接下来，通过 select * from performance_schema.data_locks\G; 这条语句，查看事务执行 SQL 过程中加了什么锁。</p><p>从上图可以看到，共加了两个锁，分别是：</p><ul><li>  表锁：X 类型的意向锁；</li><li>  行锁：X 类型的间隙锁；</li></ul><p>因此，此时事务 A 在 id = 5 记录的主键索引上加的是间隙锁，锁住的范围是 (1, 5)。</p><p><img src="https://s8.51cto.com/oss/202211/17/c4b97ce51a7ae98d3d2902f3d8f0cda6666113.png" alt="图片" title="图片"></p><p>接下来，如果有其他事务插入 id 值为 2、3、4 这一些记录的话，这些插入语句都会发生阻塞。</p><p>注意，如果其他事务插入的 id = 1 或者 id = 5 的记录话，并不会发生阻塞，而是报主键冲突的错误，因为表中已经存在 id = 1 和 id = 5 的记录了。</p><p>比如，下面这个例子：</p><p><img src="https://s5.51cto.com/oss/202211/17/c217c4b120edd923a1a5875c998a1acf8942c5.png" alt="图片" title="图片"></p><p>因为事务 A 在 id = 5 记录的主键索引上加了范围为 (1, 5) 的 X 型间隙锁，所以事务 B 在插入一条 id 为 3 的记录时会被阻塞住，即无法插入 id = 3 的记录。</p><ul><li>  间隙锁的范围(1, 5) ，是怎么确定的？</li></ul><p>根据我的经验，如果 LOCK_MODE 是 next-key 锁或者间隙锁，那么 LOCK_DATA 就表示锁的范围「右边界」，此次的事务 A 的 LOCK_DATA 是 5。</p><p>然后锁范围的「左边界」是表中 id 为 5 的上一条记录的 id 值，即 1。</p><p>因此，间隙锁的范围(1, 5)。</p><ul><li>  为什么唯一索引等值查询并且查询记录「不存在」的场景下，在索引树找到第一条大于该查询记录的记录后，要将该记录的索引中的 next-key lock 会退化成「间隙锁」？</li></ul><p>原因就是在唯一索引等值查询并且查询记录不存在的场景下，仅靠间隙锁就能避免幻读的问题。</p><ul><li>  为什么 id = 5 记录上的主键索引的锁不可以是 next-key lock？如果是 next-key lock，就意味着其他事务无法删除 id = 5 这条记录，但是这次的案例是查询 id = 2 的记录，只要保证前后两次查询 id = 2 的结果集相同，就能避免幻读的问题了，所以即使 id =5 被删除，也不会有什么影响，那就没必须加 next-key lock，因此只需要在 id = 5 加间隙锁，避免其他事务插入 id = 2 的新记录就行了。</li><li>  为什么不可以针对不存在的记录加记录锁？锁是加在索引上的，而这个场景下查询的记录是不存在的，自然就没办法锁住这条不存在的记录。</li></ul><p><strong>唯一索引范围查询</strong></p><p>范围查询和等值查询的加锁规则是不同的。</p><p>当唯一索引进行范围查询时，会对每一个扫描到的索引加 next-key 锁，然后如果遇到下面这些情况，会退化成记录锁或者间隙锁：</p><ul><li>  情况一：针对「大于等于」的范围查询，因为存在等值查询的条件，那么如果等值查询的记录是存在于表中，那么该记录的索引中的 next-key 锁会退化成记录锁。</li><li>  情况二：针对「小于或者小于等于」的范围查询，要看条件值的记录是否存在于表中：</li></ul><p>当条件值的记录不在表中，那么不管是「小于」还是「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁。</p><p>当条件值的记录在表中，如果是「小于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁；如果「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引 next-key 锁不会退化成间隙锁。其他扫描到的记录，都是在这些记录的索引上加 next-key 锁。</p><p>接下来，通过几个实验，才验证我上面说的结论。</p><h4 id="1、针对「大于或者大于等于」的范围查询"><a href="#1、针对「大于或者大于等于」的范围查询" class="headerlink" title="1、针对「大于或者大于等于」的范围查询"></a>1、针对「大于或者大于等于」的范围查询</h4><ul><li>  实验一：针对「大于」的范围查询的情况。</li></ul><p>假设事务 A 执行了这条范围查询语句：</p><pre><code>mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user where id &gt; 15 for update;+----+-----------+-----+| id | name      | age |+----+-----------+-----+| 20 | 香克斯    |  39 |+----+-----------+-----+1 row in set (0.01 sec)</code></pre><p>事务 A 加锁变化过程如下：</p><ul><li>  最开始要找的第一行是 id = 20，由于查询该记录不是一个等值查询（不是大于等于条件查询），所以对该主键索引加的是范围为  (15, 20] 的 next-key 锁；</li><li>  由于是范围查找，就会继续往后找存在的记录，虽然我们看见表中最后一条记录是 id = 20 的记录，但是实际在 Innodb 存储引擎中，会用一个特殊的记录来标识最后一条记录，该特殊的记录的名字叫 supremum pseudo-record ，所以扫描第二行的时候，也就扫描到了这个特殊记录的时候，会对该主键索引加的是范围为  (20, +∞] 的 next-key 锁。</li><li>  停止扫描。</li></ul><p>可以得知，事务 A 在主键索引上加了两个 X 型 的 next-key 锁：</p><p><img src="https://s6.51cto.com/oss/202211/17/d3dd90488fa33b184d0224cdc4e0617f675df2.png" alt="图片" title="图片"></p><ul><li>  在 id = 20 这条记录的主键索引上，加了范围为 (15, 20] 的 next-key 锁，意味着其他事务即无法更新或者删除 id = 20 的记录，同时无法插入 id 值为 16、17、18、19 的这一些新记录。</li><li>  在特殊记录（ supremum pseudo-record）的主键索引上，加了范围为 (20, +∞] 的 next-key 锁，意味着其他事务无法插入 id 值大于 20 的这一些新记录。</li></ul><p>我们也可以通过 select * from performance_schema.data_locks\G; 这条语句来看看事务 A 加了什么锁。</p><p>输出结果如下，我这里只截取了行级锁的内容。</p><p><img src="https://s2.51cto.com/oss/202211/17/14c4ad39784c460a1d4786e7526e54eb1650c0.png" alt="图片" title="图片"></p><p>从上图中的分析中，也可以得到事务 A 在主键索引上加了两个 X 型 的next-key 锁：</p><p>在 id = 20 这条记录的主键索引上，加了范围为 (15, 20] 的 next-key 锁，意味着其他事务即无法更新或者删除 id = 20 的记录，同时无法插入 id 值为 16、17、18、19 的这一些新记录。</p><p>在特殊记录（ supremum pseudo-record）的主键索引上，加了范围为 (20, +∞] 的 next-key 锁，意味着其他事务无法插入 id 值大于 20 的这一些新记录。</p><ul><li>  实验二：针对「大于等于」的范围查询的情况。</li></ul><p>假设事务 A 执行了这条范围查询语句：</p><pre><code>mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user where id &gt;= 15 for update;+----+-----------+-----+| id | name      | age |+----+-----------+-----+| 15 | 乌索普    |  20 || 20 | 香克斯    |  39 |+----+-----------+-----+2 rows in set (0.00 sec)</code></pre><p>事务 A 加锁变化过程如下：</p><ul><li>  最开始要找的第一行是 id = 15，由于查询该记录是一个等值查询（等于 15），所以该主键索引的 next-key 锁会退化成记录锁，也就是仅锁住 id = 15 这一行记录。</li><li>  由于是范围查找，就会继续往后找存在的记录，扫描到的第二行是 id = 20，于是对该主键索引加的是范围为  (15, 20] 的 next-key 锁；</li><li>  接着扫描到第三行的时候，扫描到了特殊记录（ supremum pseudo-record），于是对该主键索引加的是范围为  (20, +∞] 的 next-key 锁。</li><li>  停止扫描。</li></ul><p>可以得知，事务 A 在主键索引上加了三个 X 型 的锁，分别是：</p><p><img src="https://s8.51cto.com/oss/202211/17/57176529152103ed5b4067775f2af7089d1f1a.png" alt="图片" title="图片"></p><ul><li>  在 id = 15 这条记录的主键索引上，加了记录锁，范围是 id = 15 这一行记录；意味着其他事务无法更新或者删除 id = 15 的这一条记录；</li><li>  在 id = 20 这条记录的主键索引上，加了 next-key 锁，范围是  (15, 20] 。意味着其他事务即无法更新或者删除 id = 20 的记录，同时无法插入 id 值为 16、17、18、19 的这一些新记录。</li><li>  在特殊记录（ supremum pseudo-record）的主键索引上，加了 next-key 锁，范围是  (20, +∞] 。意味着其他事务无法插入 id 值大于 20 的这一些新记录。</li></ul><p>我们也可以通过 select * from performance_schema.data_locks\G; 这条语句来看看事务 A 加了什么锁。</p><p>输出结果如下，我这里只截取了行级锁的内容。</p><p><img src="https://s8.51cto.com/oss/202211/17/78a4d3304504d635a224667c2cf4c56fb252e7.png" alt="图片" title="图片"></p><p>通过前面这个实验，我们证明了：</p><p>针对「大于等于」条件的唯一索引范围查询的情况下， 如果条件值的记录存在于表中，那么由于查询该条件值的记录是包含一个等值查询的操作，所以该记录的索引中的 next-key 锁会退化成记录锁。</p><p><strong>2、针对「小于或者小于等于」的范围查询</strong></p><p>实验一：针对「小于」的范围查询时，查询条件值的记录「不存在」表中的情况。</p><p>假设事务 A 执行了这条范围查询语句，注意查询条件值的记录（id 为 6）并不存在于表中。</p><pre><code>mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user where id &lt; 6 for update;+----+--------+-----+| id | name   | age |+----+--------+-----+|  1 | 路飞   |  19 ||  5 | 索隆   |  21 |+----+--------+-----+3 rows in set (0.00 sec)</code></pre><p>事务 A 加锁变化过程如下：</p><ul><li>  最开始要找的第一行是 id = 1，于是对该主键索引加的是范围为  (-∞, 1] 的 next-key 锁；</li><li>  由于是范围查找，就会继续往后找存在的记录，扫描到的第二行是 id = 5，所以对该主键索引加的是范围为  (1, 5] 的 next-key 锁；</li><li>  由于扫描到的第二行记录（id = 5），满足 id &lt; 6 条件，而且也没有达到终止扫描的条件，接着会继续扫描。</li><li>  扫描到的第三行是 id = 10，该记录不满足 id &lt; 6 条件的记录，所以 id = 10 这一行记录的锁会退化成间隙锁，于是对该主键索引加的是范围为  (5, 10) 的间隙锁。</li></ul><p>由于扫描到的第三行记录（id = 10），不满足 id &lt; 6 条件，达到了终止扫描的条件，于是停止扫描。</p><p>从上面的分析中，可以得知事务 A 在主键索引上加了三个 X 型的锁：</p><p><img src="https://s7.51cto.com/oss/202211/17/93b2613114d0c8f1ea12735833e9395efd1e5b.png" alt="图片" title="图片"></p><ul><li>  在 id = 1 这条记录的主键索引上，加了范围为  (-∞, 1] 的 next-key 锁，意味着其他事务即无法更新或者删除 id = 1 的这一条记录，同时也无法插入 id 小于 1 的这一些新记录。</li><li>  在 id = 5 这条记录的主键索引上，加了范围为  (1, 5] 的 next-key 锁，意味着其他事务即无法更新或者删除 id = 5 的这一条记录，同时也无法插入 id 值为 2、3、4 的这一些新记录。</li><li>  在 id = 10 这条记录的主键索引上，加了范围为 (5, 10) 的间隙锁，意味着其他事务无法插入 id 值为 6、7、8、9 的这一些新记录。</li></ul><p>我们也可以通过 select * from performance_schema.data_locks\G; 这条语句来看看事务 A 加了什么锁。</p><p>输出结果如下，我这里只截取了行级锁的内容。</p><p><img src="https://s4.51cto.com/oss/202211/17/e4655f1291d7b84d43d644a5b49ae8a65b2d14.png" alt="图片" title="图片"></p><p>从上图中的分析中，也可以得知事务 A 在主键索引加的三个锁，就是我们前面分析出那三个锁。</p><p>虽然这次范围查询的条件是「小于」，但是查询条件值的记录不存在于表中（ id 为 6 的记录不在表中），所以如果事务 A 的范围查询的条件改成 &lt;= 6 的话，加的锁还是和范围查询条件为 &lt; 6 是一样的。大家自己也验证下这个结论。</p><p>因此，针对「小于或者小于等于」的唯一索引范围查询，如果条件值的记录不在表中，那么不管是「小于」还是「小于等于」的范围查询，扫描到终止范围查询的记录时，该记录中索引的 next-key 锁会退化成间隙锁，其他扫描的记录，则是在这些记录的索引上加 next-key 锁。</p><ul><li>  实验二：针对「小于等于」的范围查询时，查询条件值的记录「存在」表中的情况。</li></ul><p>假设事务 A 执行了这条范围查询语句，注意查询条件值的记录（id 为 5）存在于表中。</p><pre><code>mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user where id &lt;= 5 for update;+----+--------+-----+| id | name   | age |+----+--------+-----+|  1 | 路飞   |  19 ||  5 | 索隆   |  21 |+----+--------+-----+2 rows in set (0.00 sec)</code></pre><p>事务 A 加锁变化过程如下：</p><ul><li>  最开始要找的第一行是 id = 1，于是对该记录加的是范围为  (-∞, 1] 的 next-key 锁；</li><li>  由于是范围查找，就会继续往后找存在的记录，扫描到的第二行是 id = 5，于是对该记录加的是范围为  (1, 5] 的 next-key 锁。</li><li>  由于主键索引具有唯一性，不会存在两个 id = 5 的记录，所以不会再继续扫描，于是停止扫描。</li></ul><p>从上面的分析中，可以得到事务 A 在主键索引上加了 2 个 X 型的锁：</p><p><img src="https://s2.51cto.com/oss/202211/17/f4e08bd9250f337a4eb212ab839ce2206c56ee.png" alt="图片" title="图片"></p><ul><li>  在 id = 1 这条记录的主键索引上，加了范围为  (-∞, 1] 的 next-key 锁。意味着其他事务即无法更新或者删除 id = 1 的这一条记录，同时也无法插入 id 小于 1 的这一些新记录。</li><li>  在 id = 5 这条记录的主键索引上，加了范围为  (1, 5] 的 next-key 锁。意味着其他事务即无法更新或者删除 id = 5 的这一条记录，同时也无法插入 id 值为 2、3、4 的这一些新记录。</li></ul><p>我们也可以通过 select * from performance_schema.data_locks\G; 这条语句来看看事务 A 加了什么锁。</p><p>输出结果如下，我这里只截取了行级锁的内容。</p><p><img src="https://s2.51cto.com/oss/202211/17/2605f4e85a7b1acf1f4827b2373544622c3fd9.png" alt="图片" title="图片"></p><p>从上图中的分析中，可以得到事务 A 在主键索引上加了两个 X 型 next-key 锁，分别是：</p><p>在 id = 1 这条记录的主键索引上，加了范围为  (-∞, 1] 的 next-key 锁；</p><p>在 id = 5 这条记录的主键索引上，加了范围为(1, 5 ] 的 next-key 锁。</p><ul><li>  实验三：再来看针对「小于」的范围查询时，查询条件值的记录「存在」表中的情况。</li></ul><p>如果事务 A 的查询语句是小于的范围查询，且查询条件值的记录（id 为 5）存在于表中。</p><pre><code>select * from user where id &lt; 5 for update;</code></pre><p>事务 A 加锁变化过程如下：</p><ul><li>  最开始要找的第一行是 id = 1，于是对该记录加的是范围为  (-∞, 1] 的 next-key 锁；</li><li>  由于是范围查找，就会继续往后找存在的记录，扫描到的第二行是 id = 5，该记录是第一条不满足 id &lt; 5 条件的记录，于是**该记录的锁会退化为间隙锁，锁范围是 (1,5)**。</li><li>  由于找到了第一条不满足 id &lt; 5 条件的记录，于是停止扫描。</li></ul><p>可以得知，此时事务 A 在主键索引上加了两种 X 型锁：</p><p><img src="https://s2.51cto.com/oss/202211/17/65e3022974ae9b602d3500e834f408f5e85668.png" alt="图片" title="图片"></p><ul><li>  在 id = 1 这条记录的主键索引上，加了范围为  (-∞, 1] 的 next-key 锁，意味着其他事务即无法更新或者删除 id = 1 的这一条记录，同时也无法插入 id 小于 1 的这一些新记录。</li><li>  在 id = 5 这条记录的主键索引上，加了范围为 (1,5) 的间隙锁，意味着其他事务无法插入 id 值为 2、3、4 的这一些新记录。</li></ul><p>我们也可以通过 select * from performance_schema.data_locks\G; 这条语句来看看事务 A 加了什么锁。</p><p>输出结果如下，我这里只截取了行级锁的内容。</p><p><img src="https://s4.51cto.com/oss/202211/17/572d3c51267ab0fdb086525e735d7db0bcc80b.png" alt="图片" title="图片"></p><p>从上图中的分析中，可以得到事务 A 在主键索引上加了 X 型的范围为  (-∞, 1] 的 next-key 锁，和 X 型的范围为 (1, 5) 的间隙锁。</p><p>因此，通过前面这三个实验，可以得知。</p><p>在针对「小于或者小于等于」的唯一索引（主键索引）范围查询时，存在这两种情况会将索引的 next-key 锁会退化成间隙锁的：</p><ul><li>  当条件值的记录「不在」表中时，那么不管是「小于」还是「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的主键索引中的 next-key 锁会退化成间隙锁，其他扫描到的记录，都是在这些记录的主键索引上加 next-key 锁。</li><li>  当条件值的记录「在」表中时：</li></ul><p>如果是「小于」条件的范围查询，扫描到终止范围查询的记录时，该记录的主键索引中的 next-key 锁会退化成间隙锁，其他扫描到的记录，都是在这些记录的主键索引上，加 next-key 锁。</p><p>如果是「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的主键索引中的 next-key 锁「不会」退化成间隙锁，其他扫描到的记录，都是在这些记录的主键索引上加 next-key 锁。</p><p><strong>非唯一索引等值查询</strong></p><p>当我们用非唯一索引进行等值查询的时候，因为存在两个索引，一个是主键索引，一个是非唯一索引（二级索引），所以在加锁时，同时会对这两个索引都加锁，但是对主键索引加锁的时候，只有满足查询条件的记录才会对它们的主键索引加锁。</p><p>针对非唯一索引等值查询时，查询的记录存不存在，加锁的规则也会不同：</p><ul><li>  当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的  next-key 锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁。</li><li>  当查询的记录「不存在」时，扫描到第一条不符合条件的二级索引记录，该二级索引的  next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁。</li></ul><p>接下里用两个实验来说明。</p><p><strong>1、记录不存在的情况</strong></p><p>实验一：针对非唯一索引等值查询时，查询的值不存在的情况。</p><p>先来说说非唯一索引等值查询时，查询的记录不存在的情况，因为这个比较简单。</p><p>假设事务 A 对非唯一索引（age）进行了等值查询，且表中不存在 age = 25 的记录。</p><pre><code>mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user where age = 25 for update;Empty set (0.00 sec)</code></pre><p>事务 A 加锁变化过程如下：</p><ul><li>  定位到第一条不符合查询条件的二级索引记录，即扫描到 age = 39，于是**该二级索引的  next-key 锁会退化成间隙锁，范围是 (22, 39)**。</li><li>  停止查询</li></ul><p>事务 A 在 age = 39 记录的二级索引上，加了 X 型的间隙锁，范围是  (22, 39)。意味着其他事务无法插入 age 值为 23、24、25、26、….、38 这些新记录。不过对于插入 age = 22 和 age = 39 记录的语句，在一些情况是可以成功插入的，而一些情况则无法成功插入，具体哪些情况，会在后面说。</p><p>我们也可以通过 select * from performance_schema.data_locks\G; 这条语句来看看事务 A 加了什么锁。</p><p>输出结果如下，我这里只截取了行级锁的内容。</p><p><img src="https://s3.51cto.com/oss/202211/17/2261b163874ebefc947749258155d65bff7b5f.png" alt="图片" title="图片"></p><p>从上图的分析，可以看到，事务 A 在 age = 39 记录的二级索引上（INDEX_NAME: index_age  ），加了范围为 (22, 39) 的 X 型间隙锁。</p><p>此时，如果有其他事务插入了 age 值为 23、24、25、26、….、38 这些新记录，那么这些插入语句都会发生阻塞。不过对于插入 age = 39 记录的语句，在一些情况是可以成功插入的，而一些情况则无法成功插入，具体哪些情况，接下来我们就说！</p><ul><li>  当有一个事务持有二级索引的间隙锁 (22, 39) 时，什么情况下，可以让其他事务的插入 age = 22 或者 age = 39 记录的语句成功？又是什么情况下，插入  age = 22 或者 age = 39 记录时的语句会被阻塞？</li></ul><p>我们先要清楚，什么情况下插入语句会发生阻塞。</p><p>插入语句在插入一条记录之前，需要先定位到该记录在 B+树 的位置，如果插入的位置的下一条记录的索引上有间隙锁，才会发生阻塞。</p><p>在分析二级索引的间隙锁是否可以成功插入记录时，我们要先要知道二级索引树是如何存放记录的？</p><p>二级索引树是按照二级索引值（age列）按顺序存放的，在相同的二级索引值情况下， 再按主键 id 的顺序存放。知道了这个前提，我们才能知道执行插入语句的时候，插入的位置的下一条记录是谁。</p><p>基于前面的实验，事务 A 是在 age = 39 记录的二级索引上，加了 X 型的间隙锁，范围是  (22, 39)。</p><p>插入 age = 22 记录的成功和失败的情况分别如下：</p><ul><li>  当其他事务插入一条 age = 22，id = 3 的记录的时候，在二级索引树上定位到插入的位置，而该位置的下一条是 id = 10、age = 22 的记录，该记录的二级索引上没有间隙锁，所以这条插入语句可以执行成功。</li><li>  当其他事务插入一条 age = 22，id = 12 的记录的时候，在二级索引树上定位到插入的位置，而该位置的下一条是 id = 20、age = 39 的记录，正好该记录的二级索引上有间隙锁，所以这条插入语句会被阻塞，无法插入成功。</li></ul><p>插入 age = 39 记录的成功和失败的情况分别如下：</p><ul><li>  当其他事务插入一条 age = 39，id = 3 的记录的时候，在二级索引树上定位到插入的位置，而该位置的下一条是 id = 20、age = 39 的记录，正好该记录的二级索引上有间隙锁，所以这条插入语句会被阻塞，无法插入成功。</li><li>  当其他事务插入一条 age = 39，id = 21 的记录的时候，在二级索引树上定位到插入的位置，而该位置的下一条记录不存在，也就没有间隙锁了，所以这条插入语句可以插入成功。</li></ul><p>所以，当有一个事务持有二级索引的间隙锁 (22, 39) 时，插入 age = 22 或者 age = 39 记录的语句是否可以执行成功，关键还要考虑插入记录的主键值，因为「二级索引值（age列）+主键值（id列）」才可以确定插入的位置，确定了插入位置后，就要看插入的位置的下一条记录是否有间隙锁，如果有间隙锁，就会发生阻塞，如果没有间隙锁，则可以插入成功。</p><p>知道了这个结论之后，我们再回过头看，非唯一索引等值查询时，查询的记录不存在时，执行select * from performance_schema.data_locks\G; 输出的结果。</p><p><img src="https://s9.51cto.com/oss/202211/17/49adbd824827c45e66f2863ef45d2027e7aa53.png" alt="图片" title="图片"></p><p>在前面分析输出结果的时候，我说的结论是：「事务 A 在 age = 39 记录的二级索引上（INDEX_NAME: index_age  ），加了范围为 (22, 39) 的 X 型间隙锁」。这个结论其实还不够准确，因为只考虑了 LOCK_DATA 第一个数值（39），没有考虑 LOCK_DATA 第二个数值（20）。</p><p>那 LOCK_DATA：39，20 是什么意思？</p><ul><li>  LOCK_DATA 第一个数值，也就是 39， 它代表的是 age 值。从前面我们也知道了，LOCK_DATA 第一个数值是 next-key 锁和间隙锁锁住的范围的右边界值。</li><li>  LOCK_DATA 第二个数值，也就是 20， 它代表的是 id 值。</li></ul><p>之所以 LOCK_DATA 要多显示一个数值（ID值），是因为针对「当某个事务持有非唯一索引的 (22, 39) 间隙锁的时候，其他事务是否可以插入 age = 39 新记录」的问题，还需要考虑插入记录的 id 值。而 LOCK_DATA 的第二个数值，就是说明在插入 age = 39 新记录时，哪些范围的 id 值是不可以插入的。</p><p>因此， LOCK_DATA：39，20 + LOCK_MODE : X, GAP 的意思是，事务 A 在 age = 39 记录的二级索引上（INDEX_NAME: index_age ），加了 age 值范围为 (22, 39) 的 X 型间隙锁，**同时针对其他事务插入 age 值为 39 的新记录时，不允许插入的新记录的 id 值小于 20 **。如果插入的新记录的 id 值大于 20，则可以插入成功。</p><p>但是我们无法从select * from performance_schema.data_locks\G; 输出的结果分析出「在插入 age =22 新记录时，哪些范围的 id 值是可以插入成功的」，这时候就得自己画出二级索引的 B+ 树的结构，然后确定插入位置后，看下该位置的下一条记录是否存在间隙锁，如果存在间隙锁，则无法插入成功，如果不存在间隙锁，则可以插入成功。</p><p><strong>2、记录存在的情况</strong></p><p>实验二：针对非唯一索引等值查询时，查询的值存在的情况。</p><p>假设事务 A 对非唯一索引（age）进行了等值查询，且表中存在 age = 22 的记录。</p><pre><code>mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user where age = 22 for update;+----+--------+-----+| id | name   | age |+----+--------+-----+| 10 | 山治   |  22 |+----+--------+-----+1 row in set (0.00 sec)</code></pre><p>事务 A 加锁变化过程如下：</p><ul><li>  由于不是唯一索引，所以肯定存在值相同的记录，于是非唯一索引等值查询的过程是一个扫描的过程，最开始要找的第一行是 age = 22，于是对该二级索引记录加上范围为 (21, 22] 的 next-key 锁。同时，因为 age = 22 符合查询条件，于是对 age = 22 的记录的主键索引加上记录锁，即对 id = 10 这一行加记录锁。</li><li>  接着继续扫描，扫描到的第二行是 age = 39，该记录是第一个不符合条件的二级索引记录，所以该二级索引的  next-key 锁会退化成间隙锁，范围是 (22, 39)。</li><li>  停止查询。</li></ul><p>可以看到，事务 A 对主键索引和二级索引都加了 X 型的锁：</p><p><img src="https://s4.51cto.com/oss/202211/17/a868f7775281584c26c092f6c22f69d28a5365.png" alt="图片" title="图片"></p><ul><li>  主键索引：</li></ul><p>在 id = 10 这条记录的主键索引上，加了记录锁，意味着其他事务无法更新或者删除 id = 10 的这一行记录。</p><ul><li>  二级索引（非唯一索引）：</li></ul><p>在 age = 22 这条记录的二级索引上，加了范围为 (21, 22] 的 next-key 锁，意味着其他事务无法更新或者删除 age = 22 的这一些新记录，不过对于插入 age = 20 和 age = 21 新记录的语句，在一些情况是可以成功插入的，而一些情况则无法成功插入，具体哪些情况，会在后面说。</p><p>在 age = 39 这条记录的二级索引上，加了范围 (22, 39) 的间隙锁。意味着其他事务无法插入 age 值为 23、24、….. 、38 的这一些新记录。不过对于插入 age = 22 和 age = 39 记录的语句，在一些情况是可以成功插入的，而一些情况则无法成功插入，具体哪些情况，会在后面说。</p><p>我们也可以通过 select * from performance_schema.data_locks\G; 这条语句来看看事务 A 加了什么锁。</p><p>输出结果如下，我这里只截取了行级锁的内容。</p><p><img src="https://s8.51cto.com/oss/202211/17/311cd2d870406820cba657eb3fe70597ca6959.png" alt="图片" title="图片"></p><p>从上图的分析，可以看到，事务 A 对二级索引（INDEX_NAME: index_age ）加了两个 X 型锁，分别是：</p><ul><li>  在 age = 22 这条记录的二级索引上，加了范围为 (21, 22] 的 next-key 锁，意味着其他事务无法更新或者删除 age = 22 的这一些新记录，针对是否可以插入 age = 21 和 age = 22 的新记录，分析如下：</li></ul><p>是否可以插入 age = 21 的新记录，还要看插入的新记录的 id 值，如果插入 age = 21 新记录的 id 值小于 5，那么就可以插入成功，因为此时插入的位置的下一条记录是 id = 5，age = 21 的记录，该记录的二级索引上没有间隙锁。如果插入 age = 21 新记录的 id 值大于 5，那么就无法插入成功，因为此时插入的位置的下一条记录是 id = 20，age = 39 的记录，该记录的二级索引上有间隙锁。</p><p>是否可以插入 age = 22 的新记录，还要看插入的新记录的 id 值，从LOCK_DATA : 22, 10 可以得知，其他事务插入 age 值为 22 的新记录时，如果插入的新记录的 id 值小于 10，那么插入语句会发生阻塞；如果插入的新记录的 id 大于 10，还要看该新记录插入的位置的下一条记录是否有间隙锁，如果没有间隙锁则可以插入成功，如果有间隙锁，则无法插入成功。</p><ul><li>  在 age = 39 这条记录的二级索引上，加了范围 (22, 39) 的间隙锁。意味着其他事务无法插入 age 值为 23、24、….. 、38 的这一些新记录，针对是否可以插入 age = 22 和 age = 39 的新记录，分析如下：</li></ul><p>是否可以插入 age = 22 的新记录，还要看插入的新记录的 id 值，如果插入 age = 22 新记录的 id 值小于 10，那么插入语句会被阻塞，无法插入，因为此时插入的位置的下一条记录是 id = 10，age = 22 的记录，该记录的二级索引上有间隙锁（ age = 22 这条记录的二级索引上有 next-key 锁）。如果插入 age = 21 新记录的 id 值大于 10，也无法插入，因为此时插入的位置的下一条记录是 id = 20，age = 39 的记录，该记录的二级索引上有间隙锁。</p><p>是否可以插入 age = 39 的新记录，还要看插入的新记录的 id 值，从 LOCK_DATA : 39, 20 可以得知，其他事务插入 age 值为 39 的新记录时，如果插入的新记录的 id 值小于 20，那么插入语句会发生阻塞，如果插入的新记录的 id 大于 20，则可以插入成功。</p><p>同时，事务 A  还对主键索引（INDEX_NAME: PRIMARY ）加了X 型的记录锁：</p><ul><li>  在 id = 10 这条记录的主键索引上，加了记录锁，意味着其他事务无法更新或者删除 id = 10 的这一行记录。</li></ul><p>为什么这个实验案例中，需要在二级索引索引上加范围 (22, 39) 的间隙锁？</p><p>要找到这个问题的答案，我们要明白 MySQL 在可重复读的隔离级别场景下，为什么要引入间隙锁？其实是为了避免幻读现象的发生。</p><p>如果这个实验案例中：</p><pre><code>select * from user where age = 22 for update;</code></pre><p>如果事务 A 不在二级索引索引上加范围 (22, 39) 的间隙锁，只在二级索引索引上加范围为 (21, 22] 的 next-key 锁的话，那么就会有幻读的问题。</p><p>前面我也说过，在非唯一索引上加了范围为 (21, 22] 的 next-key 锁，是无法完全锁住 age  = 22 新记录的插入，因为对于是否可以插入 age = 22 的新记录，还要看插入的新记录的 id 值，从 LOCK_DATA : 22, 10 可以得知，其他事务插入 age 值为 22 的新记录时，如果插入的新记录的 id 值小于 10，那么插入语句会发生阻塞，如果插入的新记录的 id 值大于 10，则可以插入成功。</p><p>也就是说，只在二级索引索引（非唯一索引）上加范围为 (21, 22] 的 next-key 锁，其他事务是有可能插入 age 值为 22 的新记录的（比如插入一个 age = 22，id = 12 的新记录），那么如果事务 A 再一次查询 age = 22 的记录的时候，前后两次查询 age = 22 的结果集就不一样了，这时就发生了幻读的现象。</p><p>那么当在 age = 39 这条记录的二级索引索引上加了范围为 (22, 39) 的间隙锁后，其他事务是无法插入一个 age = 22，id = 12 的新记录，因为当其他事务插入一条 age = 22，id = 12 的新记录的时候，在二级索引树上定位到插入的位置，而该位置的下一条是 id = 20、age = 39 的记录，正好该记录的二级索引上有间隙锁，所以这条插入语句会被阻塞，无法插入成功，这样就避免幻读现象的发生。</p><p>所以，为了避免幻读现象的发生，就需要在二级索引索引上加范围 (22, 39) 的间隙锁。</p><p><strong>非唯一索引范围查询</strong></p><p>非唯一索引和主键索引的范围查询的加锁也有所不同，不同之处在于非唯一索引范围查询，索引的 next-key lock 不会有退化为间隙锁和记录锁的情况，也就是非唯一索引进行范围查询时，对二级索引记录加锁都是加 next-key 锁。</p><p>就带大家简单分析一下，事务 A 的这条范围查询语句：</p><pre><code>mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user where age &gt;= 22  for update;+----+-----------+-----+| id | name      | age |+----+-----------+-----+| 10 | 山治      |  22 || 20 | 香克斯    |  39 |+----+-----------+-----+2 rows in set (0.01 sec)</code></pre><p>事务 A 的加锁变化：</p><ul><li>  最开始要找的第一行是 age = 22，虽然范围查询语句包含等值查询，但是这里不是唯一索引范围查询，所以是不会发生退化锁的现象，因此对该二级索引记录加 next-key 锁，范围是 (21, 22]。同时，对 age = 22 这条记录的主键索引加记录锁，即对 id = 10 这一行记录的主键索引加记录锁。</li><li>  由于是范围查询，接着继续扫描已经存在的二级索引记录。扫面的第二行是 age = 39 的二级索引记录，于是对该二级索引记录加 next-key 锁，范围是 (22, 39]，同时，对 age = 39 这条记录的主键索引加记录锁，即对 id = 20 这一行记录的主键索引加记录锁。</li><li>  虽然我们看见表中最后一条二级索引记录是 age = 39 的记录，但是实际在 Innodb 存储引擎中，会用一个特殊的记录来标识最后一条记录，该特殊的记录的名字叫 supremum pseudo-record ，所以扫描第二行的时候，也就扫描到了这个特殊记录的时候，会对该二级索引记录加的是范围为  (39, +∞] 的 next-key 锁。</li></ul><p>停止查询</p><p>可以看到，事务 A 对主键索引和二级索引都加了 X 型的锁：</p><p><img src="https://s7.51cto.com/oss/202211/17/d6ae507946974e2de34900959434cb668a11e2.png" alt="图片" title="图片"></p><ul><li>  主键索引（id 列）：</li></ul><p>在 id = 10 这条记录的主键索引上，加了记录锁，意味着其他事务无法更新或者删除 id = 10 的这一行记录。</p><p>在 id = 20 这条记录的主键索引上，加了记录锁，意味着其他事务无法更新或者删除 id = 20 的这一行记录。</p><ul><li>  二级索引（age 列）：</li></ul><p>在 age = 22 这条记录的二级索引上，加了范围为 (21, 22] 的 next-key 锁，意味着其他事务无法更新或者删除 age = 22 的这一些新记录，不过对于是否可以插入 age = 21 和 age = 22 的新记录，还需要看新记录的 id 值，有些情况是可以成功插入的，而一些情况则无法插入，具体哪些情况，我们前面也讲了。</p><p>在 age = 39 这条记录的二级索引上，加了范围为 (22, 39] 的 next-key 锁，意味着其他事务无法更新或者删除 age = 39 的这一些记录，也无法插入 age 值为 23、24、25、…、38 的这一些新记录。不过对于是否可以插入 age = 22 和 age = 39 的新记录，还需要看新记录的 id 值，有些情况是可以成功插入的，而一些情况则无法插入，具体哪些情况，我们前面也讲了。</p><ul><li>  在特殊的记录（supremum pseudo-record）的二级索引上，加了范围为 (39, +∞] 的 next-key 锁，意味着其他事务无法插入 age 值大于 39 的这些新记录。</li></ul><p>在 age &gt;= 22  的范围查询中，明明查询 age = 22 的记录存在并且属于等值查询，为什么不会像唯一索引那样，将 age = 22 记录的二级索引上的 next-key 锁退化为记录锁？</p><p>因为 age 字段是非唯一索引，不具有唯一性，所以如果只加记录锁（记录锁无法防止插入，只能防止删除或者修改），就会导致其他事务插入一条 age = 22 的记录，这样前后两次查询的结果集就不相同了，出现了幻读现象。</p><p><strong>没有加索引的查询</strong></p><p>前面的案例，我们的查询语句都有使用索引查询，也就是查询记录的时候，是通过索引扫描的方式查询的，然后对扫描出来的记录进行加锁。</p><p>如果锁定读查询语句，没有使用索引列作为查询条件，或者查询语句没有走索引查询，导致扫描是全表扫描。那么，每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表，这时如果其他事务对该表进行增、删、改操作的时候，都会被阻塞。</p><p>不只是锁定读查询语句不加索引才会导致这种情况，update 和 delete 语句如果查询条件不加索引，那么由于扫描的方式是全表扫描，于是就会对每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表。</p><p>因此，在线上在执行 update、delete、select … for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了，这是挺严重的问题。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这次我以 MySQL 8.0.26 版本，在可重复读隔离级别之下，做了几个实验，让大家了解了唯一索引和非唯一索引的行级锁的加锁规则。</p><p>我这里总结下，  MySQL 行级锁的加锁规则。</p><p>唯一索引等值查询：</p><ul><li>  当查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的 next-key lock 会退化成「记录锁」。</li><li>  当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的 next-key lock 会退化成「间隙锁」。</li></ul><p>非唯一索引等值查询：</p><ul><li>  当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁。</li><li>  当查询的记录「不存在」时，扫描到第一条不符合条件的二级索引记录，该二级索引的  next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁。</li></ul><p>非唯一索引和主键索引的范围查询的加锁规则不同之处在于：</p><ul><li>  唯一索引在满足一些条件的时候，索引的 next-key lock 退化为间隙锁或者记录锁。</li><li>  非唯一索引范围查询，索引的 next-key lock 不会退化为间隙锁和记录锁。</li></ul><p>其实理解 MySQL 为什么要这样加锁，主要要以避免幻读角度去分析，这样就很容易理解这些加锁的规则了。</p><p>还有一件很重要的事情，在线上在执行 update、delete、select … for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了，这是挺严重的问题。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;保姆级教程！2 万字 + 30 张图搞懂 MySQL 是怎么加行级锁的？&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.51cto.com/article/740013.html&quot;&gt;https://www.51cto.com/article/740013.html</summary>
      
    
    
    
    <category term="mysql" scheme="http://zhangyu.info/categories/mysql/"/>
    
    
    <category term="mysql" scheme="http://zhangyu.info/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>OKR之剑·理念篇01-OKR带给我们的改变我们的改变</title>
    <link href="http://zhangyu.info/2022/11/02/OKR%E4%B9%8B%E5%89%91%C2%B7%E7%90%86%E5%BF%B5%E7%AF%8701-OKR%E5%B8%A6%E7%BB%99%E6%88%91%E4%BB%AC%E7%9A%84%E6%94%B9%E5%8F%98%E6%88%91%E4%BB%AC%E7%9A%84%E6%94%B9%E5%8F%98/"/>
    <id>http://zhangyu.info/2022/11/02/OKR%E4%B9%8B%E5%89%91%C2%B7%E7%90%86%E5%BF%B5%E7%AF%8701-OKR%E5%B8%A6%E7%BB%99%E6%88%91%E4%BB%AC%E7%9A%84%E6%94%B9%E5%8F%98%E6%88%91%E4%BB%AC%E7%9A%84%E6%94%B9%E5%8F%98/</id>
    <published>2022-11-01T16:00:00.000Z</published>
    <updated>2022-11-17T14:59:35.032Z</updated>
    
    <content type="html"><![CDATA[<p>平台产品研发团队 vivo互联网技术 2022-11-02</p><p><a href="https://mp.weixin.qq.com/s/NLxg-4JUx-F-0NwPfO1qIw">https://mp.weixin.qq.com/s/NLxg-4JUx-F-0NwPfO1qIw</a></p><p>[OKR之剑（理念篇）01—— OKR带给我们的改变_<a href="https://blog.csdn.net/m0_56069948/article/details/126869001">虚幻私塾】的博客-CSDN博客_okr总是变化</a></p><blockquote><blockquote><p>作者：vivo互联网平台产品研发团队</p></blockquote><h1 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h1><p>OKR即目标与关键成果法，起源于英特尔，在谷歌发扬光大。近几年在国内比较火，很多企业都相继引入了OKR的管理方式，小到2-3人的小微初创公司，大到十几万名员工的大型企业，都因此而受益。vivo互联网团队经过三年的积极实践，证实这一目标管理工具对于业务和人员发展有非常强大的推动作用。</p><p>“众多企业争相追捧的OKR，到底是何方神圣？我可以用么？”</p><p>从各个渠道了解到OKR对企业有正向作用的你，一定也有这样的疑问。那么此小节，我们先简单解答下这个问题，同时也论述下本系列文章的核心理念，让你充满信心的深入学习OKR以及本系列文章的实践经验。</p><p>通俗来讲，OKR就是一套科学的目标管理工具和方法，它的特点在于重视员工内在动机，激发员工内在潜能，提升员工工作热情。与其他目标管理方法不同的是，OKR弱化了目标管理和绩效考核的关系，通过鼓励员工主动制定更有挑战性的目标，鼓励目标的开放透明，团队精诚合作对齐一致，最终达成大团队的目标。</p><p>本系列文章是基于我们团队中的具体OKR实践，讲述我们如何理解和运用OKR，以及在OKR运用过程中如何践行“团队管理”这一学问，并且在文章中分享我们的团队管理的心得和理念。我们认为OKR与管理的有机结合，归根结底还是对管理的理解要一致，正如德鲁克之言：“<strong>企业需要的管理原则，就是让个人充分发挥特长，凝聚共同的愿景和一致的努力方向，建立团队合作，调和个人目标和共同福祉</strong>”，这其中又包含了两个要点：</p><p><strong>1.目标一致，是战略目标达成的关键</strong></p><p>在信息不透明的情况下，员工和企业计划和战略没有对齐，团队之间规划和方向没有对齐，相互之间目标不一致，怎么可能协作顺畅？特别是当员工只专注个人成就，团队只在乎局部胜利，而非企业整体目标，这对于企业发展来说是非常致命的。</p><p><strong>2.管理之责，在于充分发挥员工才能</strong></p><p>经营企业其实就是经营人，团队管理也是一样。人尽其才，才尽其用，是企业管理的目标之一。OKR让员工自己制定挑战性任务，并在目标达成的推进过程中突破自我局限，收获成长和成就感。在目标制定阶段，员工可以切实的感受到是在掌控工作，而不是被支配。在目标执行过程中，员工可以获得实实在在的能力提升、成就感和相应的影响力，进而有更强的动力去挑战下一阶段的目标，以此进入良性循环。最终OKR高效激发了员工潜能，并逐步释放整个团队的潜力。</p><p>在本系列文章中，我们采用场景化方式进行讲述，让你能够在碎片化的时间里了解我们的执行细节，并从中有所收获，解除OKR实践和团队管理上的困惑。</p><h1 id="二、我们为何引入OKR？"><a href="#二、我们为何引入OKR？" class="headerlink" title="二、我们为何引入OKR？"></a>二、我们为何引入OKR？</h1><p>通过前面介绍，相信你对OKR已经有了一个初步的印象。本小节主要介绍我们是怎样的一个团队，并让大家更加清楚我们是在什么样的背景下开始接触并践行OKR的。</p><p>我们团队于2015年成立，最初只有几个人，主要负责业务方向是垂直电商。最开始的电商研发小队，接到这个时间紧任务重的从0到1的建设任务，也是鸭梨山大。好在团队梯队比较健全，有深耕互联网多年的老司机，有初出茅庐的应届大学生，在互帮互学的氛围引领下，逢山开路遇水架桥，逐渐在一片混沌的情况下开辟了新气象。最终我们把国内电商这块硬骨头啃了下来，收获了业务团队的信任和兄弟团队的称赞。</p><p>在这种团队风貌的影响下，越来越多的业务交接过来，小队也逐渐变成了小组，变成了大组，直至成长为如今的平台产品研发中心，负责整个vivo互联网平台类方向的研发工作。在这风云变幻的8年里，我们见证了互联网的飞速发展，也经历了组织架构调整，业务调整，团队合并，我们改变了很多，但始终保持着那份初心。</p><p>一路走来我们收获了非常多的荣誉，同时也遇到了相当多的困难，特别是在团队规模持续扩大的情况下，我们的团队管理面临着巨大的挑战：</p><p><strong>1.团队目标对不齐，项目协作总困难</strong></p><p>这是在当时非常常见的问题，多发生在上下游有依赖的项目中。比如某一个项目，同时有多个团队在支撑，而这些团队都有各自的产品规划和目标。这就导致在项目版本中，经常出现A团队觉得有个需求非常重要紧急，需要B团队配合，却发现B团队因为要执行自己的计划而出现资源冲突。</p><p><strong>2.角色视角有偏差，Roadmap拍脑袋</strong></p><p>即使在同一个项目团队，也会存在因为角色的不同而在一些事情上出现分歧，一个产品从研发的视角来看要让其稳定高性能的运行，此时他就会想着做对外接口的性能优化；从产品经理的视角来看就想让产品具备更完备的功能，不停的增加新功能。</p><p>因为资源的有限，是先进行接口性能优化还是开发产品新功能呢？两拨人争执不下，每个人都说自己的优先级高，这个时候我们怎么做决策呢？</p><p><strong>3.版本人力空转，资源协调不及时</strong></p><p>我们的团队负责的项目很多，大的项目十几人参与，小的项目一个人负责几个，出现“旱的旱死，涝的涝死”的情况再正常不过了，有些项目这段时间特别的忙，版本的排期都是根据最终交付时间进行倒排，而此时此刻另外一些项目却只有零星的小需求，不慌不忙。</p><p><strong>4.学习进取成空谈，完成任务是唯一</strong></p><p>为了打造一支学习型的团队，公司专门建设了一个线上学习平台，上面有各种类别的学习视频，并且规定每个员工每年必须参与学习多长时间，即使这样效果也不甚理想，每年到年底的时候很多人都需要进行冲刺，毕竟学习是痛苦的，让大家快乐的学习貌似变成了一件不可能的事情。</p><p><strong>5.绩效考核遭质疑，什么样才算是优秀？</strong></p><p>一个高绩效员工所产出的创新效果数倍于一个能力中等的人，同时优秀人才创造的出色成果还能感染激励更多的出色人才，可见优秀的人是多么的重要。</p><p>那么如何识别优秀的人才呢？以前我们用环评+自评+KPI三套组合拳的方式来评定优秀，导致员工比较质疑这个结果的公平性，因为环评+自评本身非常主观，并且KPI又不够透明，管理者总是需要直面这样的挑战：为什么这个人表现平平，绩效比我好？</p><p>上面列举了我们团队之前趟过的一些坑，其实说到底还是怎么管理团队的问题，包括如何调动员工积极性，如何发挥每个人的主观能动性，这也是我们一直在思考的方向。在16年，我们就已经逐渐意识到，原有的类KPI的绩效考核方法对于研发岗位变得不适用了。随后我们去寻找新的管理办法，调研了主流的管理方式，发现它们都与vivo互联网的文化和团队实际情况无法完美契合。</p><p>向外求无果的情况下，我们开始摸索新的管理理念来打造高绩效团队，同时积极寻找更加优秀的管理工具，期望能够将沉淀下来的经验更好地落地和推广。19年的夏天，部门开始学习、引入OKR管理工具。在学习OKR了相关理论书籍后，我们惊奇的发现原来一直苦苦找寻的，能解决我们痛点的工具，就这样出现了我们的面前，直叹相见恨晚。</p><h1 id="三、OKR带给我们的改变"><a href="#三、OKR带给我们的改变" class="headerlink" title="三、OKR带给我们的改变"></a>三、OKR带给我们的改变</h1><p>我们团队的愿景：持续成长为行业一流的技术团队，并打造出了一支自组织、高绩效的标杆团队。目前由三大互联网服务端研发团队组成，人员规模在两百人左右，业务整体可以划分三个方向（三驾马车）：平台产品，营销产品，创新产品。三大业务方向相辅相成，都有着各自的责任和使命。</p><p><strong>平台产品</strong>主要包括业务平台与效率中台两大模块，完善沉淀，稳定支撑业务发展的项目。</p><p><strong>营销产品</strong>主要包括线上营销与线下营销两个模块，主要是能力组合复用，助力营销变革。</p><p><strong>创新产品</strong>主要包括管理创新与技术创新两个模块，创新产品主要是源于业务，发掘新的可能。</p><p>无论团队人员规模还是业务复杂度，都不难看出，对于团队成员以及业务的管理面临着不小的挑战。从19年正式引入OKR起，为了应对不断变化的业务，以及不断调整的组织结构，在团队和业务发展中，我们不断实践和优化符合我们团队特色的管理方式，集百家之长，成一家之言，逐渐沉淀出一套逻辑清晰的管理理念。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/b761540df78dc20204c2d1eb91cfc975.png"></p><p>引入OKR三年多来，让我们一直坚持的“面向未来的组织”的管理理念遍地开花，给我们团队带来了方方面面的改变。团队的凝聚力、氛围以及生产力得到了极大提升，以下是我们认为比较重要的改变。</p><h2 id="3-1专注团队最重要目标"><a href="#3-1专注团队最重要目标" class="headerlink" title="3.1专注团队最重要目标"></a>3.1专注团队最重要目标</h2><blockquote><p>人生之要事在于确立伟大的目标与实现这目标的决心。——歌德</p></blockquote><p>首先，我们需要制定出好的目标，需要足够“伟大”，同时又要让所有人都能够有参与感。在引入OKR后，我们的目标是通过自上而下+自下而上双向产生。在公司确定年度规划和战略目标后，我们会根据自身业务和团队的特点，制定具有挑战性的目标以支撑战略的落地；接着团队成员主动去思考，制定出衡量实现此目标的关键结果，以此解决目标的制定与目标的执行割裂的问题，让团队成员都有参与感，自主感。</p><p>其次我们会为每条关键结果指定负责人，通常是由提出人负责，当然也可以协商由其他人负责。在负责人owner制度下，可以更好的发挥主观能动性，从心理学角度激发完成承诺的欲望。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/f4297458cc2da95c41e87590b4bd35f8.png"></p><p>最后使用在线的OKR管理工具来保证目标的透明性和公开性，通过每周OKR tips来提醒员工持续专注于自己的OKR目标，通过两周一次的OKR庆功会来持续激励和反馈困难。多措并举之下，团队成员自始至终都专注于最重要的目标。</p><h2 id="3-2聚焦价值挑战不可能"><a href="#3-2聚焦价值挑战不可能" class="headerlink" title="3.2聚焦价值挑战不可能"></a>3.2聚焦价值挑战不可能</h2><p>有的人可能会讲定目标那还不简单，但是我们认为，目标不能太多，需要集中优势兵力解决核心问题，让组织保持专注。资源是有限的，为了保证组织的专注，目标的制定必须要聚焦价值。这样事情就变得简单多了，当我们进行两个人目标PK的时候，就比较张三的目标与李四的目标的价值，每个人对自己提出的目标进行价值论证，同时论证的过程也逼迫着我们深入思考，思考我们的目标对用户的价值，对产品的价值，对组织的价值，然后大家一起评估，最终确定我们这个季度的目标。</p><p>这个时候有人就会反驳说，难道没有引入OKR，你们就不思考价值？目标的制定肯定会思考，参考上一节，没有引入OKR的时候，目标是少数人在制定，大部分是自己说服自己，而引入OKR之后，目标是大家一起制定的，那么这个时候就需要每个人都要对目标进行思考。如果你想要自己的目标脱颖而出，那你就要把你的目标的商业价值说的非常清楚，比如为产品提高百分之多少的日活，带来多少收入，节省多少开支。</p><p>目标制定聚焦于价值，也逐步改变了我们绩效评估的方式。以往我们绩效评估，看的是员工在一个绩效周期业务版本、上司任务的产出，员工被动接受任务；随着我们对目标价值的追求，绩效评估也变得更为简单，考察员工在绩效周期内带来的价值即可，员工主动挖掘任务，解决团队最核心的问题。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/440938b36da10fcb10e1d2f3a15638e6.png"></p><h2 id="3-3团队高效协作"><a href="#3-3团队高效协作" class="headerlink" title="3.3团队高效协作"></a>3.3团队高效协作</h2><p>季度初设定了有挑战的目标，那么如何在季度末保证目标的关键结果达成呢？制定目标容易，难的是目标的达成。从一个创意到可运行的产品或服务、再到让客户认可价值，然后客户开始使用，到最终愿意为之付费，整个过程的每个环节难度都在增大，每个环节都需要我们组建合适的团队来完成。</p><p>从前文中关于我们中心的介绍可看出，团队负责的业务形态不同，每个业务的优先级、重要性也不同，每个项目运行的周期都呈现出忙闲交替的现象，作为管理者通过什么手段来合理的调度人力资源？一个KR负责人评估当前KR完成需要的人力不足时该怎么办？一个团队战斗力爆表的成员，完成了自己负责的KR外还想做更多的事情怎么办？</p><p>针对上面的现象，我们建设了伙力平台：一个用于管理人力池、招募人才和认领任务的系统。我们期望能够通过这个平台解决上面的问题时，而此时面临的最大的问题，就是如何保证员工认领任务的积极性。对于普通员工来说，需要走出舒适圈，面对不了解的需求，不熟悉的伙伴，本身就是一件非常具有挑战的事情，如果没有一个好的团队氛围，必然会导致意愿下降，没有人参与，没有人发布，恶性循环，最终流于形式。</p><p>得益于OKR的目标公开透明，和层层分解的思路，员工对组织目标有更加清晰的认知，对于共同目标的达成有更强的意愿。只有大团队的胜利，才能证明小团队的努力是有价值的，才能证明个人的努力是成功的。在这样共赢的氛围下，强化了人与人的信任和协作，弱化了内耗和竞争，伙力平台的能力得到了最大程度的发挥。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/583f1b325028a4b43288273a91491b5a.png"></p><p>从伙力平台上线到现在一年多的时间里，一共发布了35个任务，共有72个同事申请，实现了408个人日的火力输出，不仅帮助我们协调了项目间的人力，更促进了团队共同成长，让优秀的人脱颖而出。不断的成功和胜利，让员工更加相信组织，相信队友，带来良性循环，实现了我们集中力量办大事的愿景。</p><h2 id="3-4浓厚的学习氛围"><a href="#3-4浓厚的学习氛围" class="headerlink" title="3.4浓厚的学习氛围"></a>3.4浓厚的学习氛围</h2><p>为了践行我们的核心价值观（学习是我们公司的核心价值观之一），为了更好的解决业务发展中的技术难题，同时也为了员工的自我成长，我们很有必要去营造一个浓厚的学习氛围。</p><p>作为一个管理者，建设一个学习型的团队是其工作内容的一部分，针对研发团队如何建设呢？通常的做法是：指定一个负责人，让其组织团队的成员轮流在固定的时间固定的场所给大家分享他的知识和经验，比如读书笔记，设计的方案，线上遇到的问题……。既然有现成的模型可以照搬，那对于我们这样执行力强的团队来说，说干就干，于是我们制定了一个规则：每周四晚上七点半大家轮流进行分享。一周一次，轮流分享，团队的人也比较多，一年下来一个人也分享不了几次，从明面上看，这个任务完成的难度不是很大，负责人也是拍着那坚实的胸脯信心满满。</p><p>半年后的一天负责人突然说：不行了，分享搞不下去了，首先是没有子弹了（没有可以分享的内容了），库存已搬空；其实是参与学习的人也没激情了，很多时候参加的人数都少于5个人，既没有想分享的人，也没有想学习的人。问了下不参加的理由，有要紧急发版的，有要配合测试的，都有各自的说法。</p><p>如何解决没有子弹的问题？我们决定换一种分享模式试试，于是我们又组织了读书会，大家一段时间内一起阅读同一本书，一个月分享一次读书心得，分享的形式就是口述，这非常轻量化了，我们想这样大家应该能坚持下去吧。事实证明我们还是太天真，这次比上次的分享会坚持的时间还要短，就搞了几期然后就悄无声息的结束了。</p><p>在我们遇到OKR之后，形势反转了，我们把“营造快乐进取的学习型团队氛围”作为一个目标来跟踪，每个季度制定不同的KR来支撑O的达成。在这种方式下，我们将原来的指派式转变为主动报名，同时OKR的目标牵引又能够让负责人专注于目标的执行和达成，学习的氛围发生了180°的大逆转，教与学变成了水到渠成的事情，很多新的思路和创意也在碰撞中产生。快闪分享、技术沙龙、源码领读、算法专题、读书会、好文分享等是中心内技术学习的专题活动，形式多样丰富，为中心内成员搭建学习交流平台。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/555f9be2e785a058dac1316474a51e57.png"></p><p>（读书会分享：《价值》读书心得）</p><h2 id="3-5持续的内部创新"><a href="#3-5持续的内部创新" class="headerlink" title="3.5持续的内部创新"></a>3.5持续的内部创新</h2><p>当今世界，新技术、新产品、新服务、新模式层出不穷，传统商业模式面临颠覆性的挑战，创新是企业的灵魂，创新是企业发展的不竭动力，对于手机行业公司来说，创新将显得更为重要。对我们团队而言创新主要体现在新能力和新项目的孵化。</p><p>我们首先是通过OKR的目标牵引和激励策略，来培育创新土壤，鼓励创新。众所周知，一个创意从诞生到落地，最大到难关是开始行动，99%的创意在行动之前就被自我扼杀了。所以我们需要建立鼓励创新、包容失败的氛围，降低员工踏出第一步的难度。</p><p>其次是聚焦创新目标，跟踪创新过程。通过持续的激励，让员工能够有足够的动力去长期投入创新目标的完成；通过阶段性的对齐，让团队能够了解目前的进展和瓶颈，利用群体智慧来共同解决困难。以此来呵护创新萌芽的成长壮大。</p><p>最后是关注创新结果，保持正向激励。因为创新这一目标，本身就是极具挑战和不确定性的，因此总结和复盘时，我们并不追求此OKR的完成度，而是以目标是否有价值、是否具备挑战性、员工是否付出足够的努力为衡量标准，即使最终这个KR没有完成，也并不影响到员工的绩效考核。在这样的理念下，保证了创新氛围的可信和持续，让创新变成一件水到渠成的事情。</p><p>三年来，在围绕着创新制定目标的牵引下，中心已经成功孵化出了6个组件和12个服务，在公司内部累计已经超过千余个系统使用，并且我们也在开源上面做探索，让这些组件和服务能为更多的人服务。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/360f8628e9997941686bbc0e7a82cb17.png"></p><p>通过OKR实践，我们扭转了曾经“畏惧犯错，不敢失败，不敢试错”的氛围，打造“乐于创新，敢于突破，勇于挑战”的文化。</p><h2 id="3-6-员工生产力提升"><a href="#3-6-员工生产力提升" class="headerlink" title="3.6 员工生产力提升"></a>3.6 员工生产力提升</h2><p>员工生产力的提升可以说是执行OKR科学管理的必然结果。OKR执行的一个特点：自下而上，即自主，是内在动机的一个基本心理需求。OKR理念强调在目标设定时，要有相当一部分目标是员工自己提出来的，而不是上级指派的。只有这样，员工才会感知到目标是自己的目标，不是他人强加给自己的目标，从而显著增强对目标的承诺感，最终带来员工生产力的提升。</p><p>海外商城的建设就是一个很好的案例。最初海外只有印度市场提出建设官方商城的需求，我们只需将内销商城系统复制一套，并部署到印度当地即可，这种方法简单高效，但是我们并未止步于此，当时我们预见到，海外其它市场需求也必将接踵而至，为了能够快速应对未来全球化业务的发展，我们做了充分的竞品分析、技术调研、架构设计、脑暴碰撞，经过一段时间的摸索和打磨，我们打造出了一套通用的全球化解决方案，包括多语言文案系统、多时区通用组件、多国家隔离框架、多机房域名部署方案等等，一套系统可满足多地区多品牌的需求，极大地提升了人效，在业务需求真正到来之时，可最快7天部署一套新商城。这些能力较好的支撑了商城当前业务的发展需要，同时赋能其它外销业务解决相关难题，多语言平台还一举获得公司级设计驱动奖。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/babd2223d926143ebfe0957ed6910080.png"></p><p>海外能力的建设，从设想到确立目标到落地，是员工自发自主自下而上去完成的，科技时代需要技术创新力，知识工作者需要突破既有经验和惯性束缚，OKR科学的管理机制给与了员工更大的发挥空间，生产力提升水到渠成。</p><h1 id="四、小结"><a href="#四、小结" class="headerlink" title="四、小结"></a>四、小结</h1><p>本章给大家讲述了我们在引入OKR之后发生的六点明显变化，这些变化既是因也是果，它们互相形成了一个良性循环的飞轮，朝着我们的愿景：“持续成长为行业一流的技术团队，并打造出了一支自组织、高绩效的标杆团队”不断前进。</p><p>如果你也想让你的团队有所改变，想更深入的了解OKR是怎么样一步一步的改变我们的，想进一步了解我们执行OKR的核心理念，想了解我们团队有哪些管理理念，那么这就是一本专门为你所写的系列文章。希望我们的团队一路走过来的经验，能为你打开一扇窗，让你有所启发，对你的团队管理有所帮助。</p><p>后续我们将会就以下话题和大家一起分享：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/594fd81198ad489a6443a714d1213152.png"></p><p>OKR给我们带来了很多改变，你们团队有引入OKR吗？为什么要引入OKR？它又给你们带来哪些改变呢？</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;平台产品研发团队 vivo互联网技术 2022-11-02&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/NLxg-4JUx-F-0NwPfO1qIw&quot;&gt;https://mp.weixin.qq.com/s/NLxg-4JUx-F-0</summary>
      
    
    
    
    <category term="OKR" scheme="http://zhangyu.info/categories/OKR/"/>
    
    
    <category term="OKR" scheme="http://zhangyu.info/tags/OKR/"/>
    
  </entry>
  
  <entry>
    <title>redis的大Key对持久化有什么影响</title>
    <link href="http://zhangyu.info/2022/10/26/redis%E7%9A%84%E5%A4%A7Key%E5%AF%B9%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%89%E4%BB%80%E4%B9%88%E5%BD%B1%E5%93%8D/"/>
    <id>http://zhangyu.info/2022/10/26/redis%E7%9A%84%E5%A4%A7Key%E5%AF%B9%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%89%E4%BB%80%E4%B9%88%E5%BD%B1%E5%93%8D/</id>
    <published>2022-10-25T16:00:00.000Z</published>
    <updated>2022-10-26T14:59:49.350Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/qq_34827674/article/details/126829220">https://blog.csdn.net/qq_34827674/article/details/126829220</a></p><p><a href="https://blog.csdn.net/qq_34827674/article/details/126829220">Redis 的大 Key 对持久化有什么影响？_小林coding的博客-CSDN博客_大key对redis的影响</a></p><blockquote><p>Redis 的持久化方式有两种：AOF 日志和 RDB <a href="https://so.csdn.net/so/search?q=%E5%BF%AB%E7%85%A7&spm=1001.2101.3001.7020">快照</a>。</p><p>所以接下来，针对这两种持久化方式具体分析分析。</p><h2 id="大-Key-对-AOF-日志的影响"><a href="#大-Key-对-AOF-日志的影响" class="headerlink" title="大 Key 对 AOF 日志的影响"></a>大 Key 对 AOF 日志的影响</h2><blockquote><p>先说说 AOF 日志三种写回磁盘的策略</p></blockquote><p>Redis 提供了 3 种 AOF 日志写回硬盘的策略，分别是：</p><ul><li>  Always，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；</li><li>  Everysec，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；</li><li>  No，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。</li></ul><p>这三种策略只是在控制 fsync() 函数的调用时机。</p><p>当应用程序向文件写入数据时，内核通常先将数据复制到内核缓冲区中，然后排入队列，然后由内核决定何时写入硬盘。</p><p><img src="https://img-blog.csdnimg.cn/def7d5328829470c9f3cfd15bbcc6814.png"></p><p>如果想要应用程序向文件写入数据后，能立马将数据同步到硬盘，就可以调用 fsync() 函数，这样内核就会将内核缓冲区的数据直接写入到硬盘，等到硬盘写操作完成后，该函数才会返回。</p><ul><li>  Always 策略就是每次写入 AOF 文件数据后，就执行 fsync() 函数；</li><li>  Everysec 策略就会创建一个异步任务来执行 fsync() 函数；</li><li>  No 策略就是永不执行 fsync() 函数;</li></ul><blockquote><p>分别说说这三种策略，在持久化大 Key 的时候，会影响什么？</p></blockquote><p>在使用 Always 策略的时候，主线程在执行完命令后，会把数据写入到 AOF 日志文件，然后会调用 fsync() 函数，将内核缓冲区的数据直接写入到硬盘，等到硬盘写操作完成后，该函数才会返回。</p><p><strong>当使用 Always 策略的时候，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的</strong>。</p><p>当使用 Everysec 策略的时候，由于是异步执行 fsync() 函数，所以大 Key 持久化的过程（数据同步磁盘）不会影响主线程。</p><p>当使用 No 策略的时候，由于永不执行 fsync() 函数，所以大 Key 持久化的过程不会影响主线程。</p><h2 id="大-Key-对-AOF-重写和-RDB-的影响"><a href="#大-Key-对-AOF-重写和-RDB-的影响" class="headerlink" title="大 Key 对 AOF 重写和 RDB 的影响"></a>大 Key 对 AOF 重写和 RDB 的影响</h2><p>当 AOF 日志写入了很多的大 Key，AOF 日志文件的大小会很大，那么很快就会触发 <strong>AOF 重写机制</strong>。</p><p>AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 <code>fork()</code> 函数创建一个子进程来处理任务。</p><p>在创建子进程的过程中，操作系统会把父进程的「<a href="https://so.csdn.net/so/search?q=%E9%A1%B5%E8%A1%A8&spm=1001.2101.3001.7020">页表</a>」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。</p><p><img src="https://img-blog.csdnimg.cn/06657cb93ffa4a24b8fc5b3069cb29bf.png"><br>这样一来，子进程就共享了父进程的物理内存数据了，这样能够节约物理内存资源，页表对应的页表项的属性会标记该物理内存的权限为<strong>只读</strong>。</p><p>随着 Redis 存在越来越多的大 Key，那么 Redis 就会占用很多内存，对应的页表就会越大。</p><p>在通过 <code>fork()</code> 函数创建子进程的时候，虽然不会复制父进程的物理内存，但是<strong>内核会把父进程的页表复制一份给子进程，如果页表很大，那么这个复制过程是会很耗时的，那么在执行 fork 函数的时候就会发生阻塞现象</strong>。</p><p>而且，fork 函数是由 Redis 主线程调用的，如果 fork 函数发生阻塞，那么意味着就会阻塞 Redis 主线程。由于 Redis 执行命令是在主线程处理的，所以当 Redis 主线程发生阻塞，就无法处理后续客户端发来的命令。</p><p>我们可以执行 <code>info</code> 命令获取到 latest_fork_usec 指标，表示 Redis 最近一次 fork 操作耗时。</p><pre><code># 最近一次 fork 操作耗时latest_fork_usec:315</code></pre><p>如果 fork 耗时很大，比如超过1秒，则需要做出优化调整：</p><ul><li>  单个实例的内存占用控制在 10 GB 以下，这样 fork 函数就能很快返回。</li><li>  如果 Redis 只是当作纯缓存使用，不关心 Redis 数据安全性问题，可以考虑关闭 AOF 和 AOF 重写，这样就不会调用 fork 函数了。</li><li>  在主从架构中，要适当调大 repl-backlog-size，避免因为 repl_backlog_buffer 不够大，导致主节点频繁地使用全量同步的方式，全量同步的时候，是会创建 RDB 文件的，也就是会调用 fork 函数。</li></ul><blockquote><p>那什么时候会发生物理内存的复制呢？</p></blockquote><p>当父进程或者子进程在向共享内存发起写操作时，CPU 就会触发<strong>缺页中断</strong>，这个缺页中断是由于违反权限导致的，然后操作系统会在「缺页异常处理函数」里进行物理内存的复制，并重新设置其内存映射关系，将父子进程的内存读写权限设置为可读写，最后才会对内存进行写操作，这个过程被称为「**写时复制(Copy On Write)**」。</p><p><img src="https://img-blog.csdnimg.cn/451024fe10374431aff6f93a8fed4638.png"></p><p>写时复制顾名思义，在发生写操作的时候，操作系统才会去复制物理内存，这样是为了防止 fork 创建子进程时，由于物理内存数据的复制时间过长而导致父进程长时间阻塞的问题。</p><p>如果创建完子进程后，<strong>父进程对共享内存中的大 Key 进行了修改，那么内核就会发生写时复制，会把物理内存复制一份，由于大 Key 占用的物理内存是比较大的，那么在复制物理内存这一过程中，也是比较耗时的，于是父进程（主线程）就会发生阻塞</strong>。</p><p>所以，有两个阶段会导致阻塞父进程：</p><ul><li>  创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；</li><li>  创建完子进程后，如果子进程或者父进程修改了共享数据，就会发生写时复制，这期间会拷贝物理内存，如果内存越大，自然阻塞的时间也越长；</li></ul><p>这里额外提一下， 如果 <strong>Linux 开启了内存大页，会影响 Redis 的性能的</strong>。</p><p>Linux 内核从 2.6.38 开始支持内存大页机制，该机制支持 2MB 大小的内存页分配，而常规的内存页分配是按 4KB 的粒度来执行的。</p><p>如果采用了内存大页，那么即使客户端请求只修改 100B 的数据，在发生写时复制后，Redis 也需要拷贝 2MB 的大页。相反，如果是常规内存页机制，只用拷贝 4KB。</p><p>两者相比，你可以看到，每次写命令引起的<strong>复制内存页单位放大了 512 倍，会拖慢写操作的执行时间，最终导致 Redis 性能变慢</strong>。</p><p>那该怎么办呢？很简单，关闭内存大页（默认是关闭的）。</p><p>禁用方法如下：</p><pre><code>echo never &gt;  /sys/kernel/mm/transparent_hugepage/enabled</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>当 AOF 写回策略配置了 Always 策略，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的。</p><p>AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 <code>fork()</code> 函数创建一个子进程来处理任务。会有两个阶段会导致阻塞父进程（主线程）：</p><ul><li>  创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；</li><li>  创建完子进程后，如果父进程修改了共享数据中的大 Key，就会发生写时复制，这期间会拷贝物理内存，由于大 Key 占用的物理内存会很大，那么在复制物理内存这一过程，就会比较耗时，所以有可能会阻塞父进程。</li></ul><p>大 key 除了会影响持久化之外，还会有以下的影响。</p><ul><li><p>  客户端超时阻塞。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</p></li><li><p>  引发网络阻塞。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</p></li><li><p>  阻塞工作线程。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</p></li><li><p>  内存分布不均。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。</p></li></ul><p>如何避免大 Key 呢？</p><p>最好在设计阶段，就把大 key 拆分成一个一个小 key。或者，定时检查 Redis 是否存在大 key ，如果该大 key 是可以删除的，不要使用 DEL 命令删除，因为该命令删除过程会阻塞主线程，而是用 unlink 命令（Redis 4.0+）删除大 key，因为该命令的删除过程是异步的，不会阻塞主线程。</p><p>完！</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/qq_34827674/article/details/126829220&quot;&gt;https://blog.csdn.net/qq_34827674/article/details/126829220&lt;/a&gt;&lt;/p&gt;</summary>
      
    
    
    
    <category term="redis" scheme="http://zhangyu.info/categories/redis/"/>
    
    
    <category term="redis" scheme="http://zhangyu.info/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis的常见使用场景</title>
    <link href="http://zhangyu.info/2022/10/26/redis%E7%9A%84%E5%B8%B8%E8%A7%81%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/"/>
    <id>http://zhangyu.info/2022/10/26/redis%E7%9A%84%E5%B8%B8%E8%A7%81%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/</id>
    <published>2022-10-25T16:00:00.000Z</published>
    <updated>2022-10-26T15:19:01.932Z</updated>
    
    <content type="html"><![CDATA[<p> <a href="https://blog.csdn.net/Number_oneEngineer/article/details/123229706">https://blog.csdn.net/Number_oneEngineer/article/details/123229706</a><br><a href="https://blog.csdn.net/agonie201218/article/details/123640871">https://blog.csdn.net/agonie201218/article/details/123640871</a></p><blockquote><h2 id="1-缓存"><a href="#1-缓存" class="headerlink" title="1. 缓存"></a>1. 缓存</h2><p>作为<code>Key-Value</code>形态的内存数据库，Redis 最先会被想到的应用场景便是作为数据缓存。而使用 Redis 缓存数据非常简单，只需要通过<code>string</code>类型将序列化后的对象存起来即可，不过也有一些需要注意的地方：</p><ul><li><p>  必须保证不同对象的 key 不会重复，并且使 key 尽量短，一般使用类名（表名）加主键拼接而成。</p></li><li><p>  选择一个优秀的序列化方式也很重要，目的是提高序列化的效率和减少内存占用。</p></li><li><p>缓存内容与数据库的一致性，这里一般有两种做法：</p><ol><li> 只在数据库查询后将对象放入缓存，如果对象发生了修改或删除操作，直接清除对应缓存（或设为过期）。</li><li> 在数据库新增和查询后将对象放入缓存，修改后更新缓存，删除后清除对应缓存（或设为过期）。</li></ol></li></ul><p>String类型</p><p>例如：热点数据缓存（例如报表、明星出轨），对象缓存、全页缓存、可以提升热点数据的访问数据。</p><h2 id="2-数据共享分布式"><a href="#2-数据共享分布式" class="headerlink" title="2. 数据共享分布式"></a>2. 数据共享分布式</h2><p>String 类型，因为 Redis 是分布式的独立服务，可以在多个应用之间共享</p><p>例如：分布式Session</p><pre><code>&lt;dependency&gt;  &lt;groupId&gt;org.springframework.session&lt;/groupId&gt;  &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; &lt;/dependency&gt;</code></pre><h2 id="3、分布式锁"><a href="#3、分布式锁" class="headerlink" title="3、分布式锁"></a>3、分布式锁</h2><p>如今都是分布式的环境下java自带的单体锁已经不适用的。在 Redis 2.6.12 版本开始，<code>string</code>的<code>set</code>命令增加了一些参数：</p><ul><li><p>  <code>EX</code>：设置键的过期时间（单位为秒）</p></li><li><p>  <code>PX</code>：设置键的过期时间（单位为毫秒）</p></li><li><p>  <code>NX</code> ：只在键不存在时，才对键进行设置操作。 <code>SET key value NX</code> 效果等同于 <code>SETNX key value</code> 。</p></li><li><p>  <code>XX</code> ：只在键已经存在时，才对键进行设置操作。</p></li></ul><p>由于这个操作是原子性的，可以简单地以此实现一个分布式的锁，例如：</p><pre><code>　　set lock_key locked NX EX 1 </code></pre><p>如果这个操作返回<code>false</code>，说明 key 的添加不成功，也就是当前有人在占用这把锁。而如果返回<code>true</code>，则说明得了锁，便可以继续进行操作，并且在操作后通过<code>del</code>命令释放掉锁。并且即使程序因为某些原因并没有释放锁，由于设置了过期时间，该锁也会在 1 秒后自动释放，不会影响到其他程序的运行。<br>　　<br>推荐使用 redisson 第三方库实现分布式锁。<br>参考 <a href="https://blog.csdn.net/agonie201218/article/details/122084140">java分布式锁终极解决方案之 redisson</a><br>String 类型setnx方法，只有不存在时才能添加成功，返回true</p><pre><code>public static boolean getLock(String key) &#123;    Long flag = jedis.setnx(key, &quot;1&quot;);    if (flag == 1) &#123;        jedis.expire(key, 10);    &#125;    return flag == 1;&#125;public static void releaseLock(String key) &#123;    jedis.del(key);&#125;</code></pre><h2 id="4、全局ID"><a href="#4、全局ID" class="headerlink" title="4、全局ID"></a>4、全局ID</h2><p>int类型，incrby，利用原子性</p><p><code>incrby userid 1000</code></p><p>分库分表的场景，一次性拿一段</p><h2 id="5、计数器"><a href="#5、计数器" class="headerlink" title="5、计数器"></a>5、计数器</h2><p>int类型，incr方法</p><p>例如：文章的阅读量、微博点赞数、允许一定的延迟，先写入Redis再定时同步到数据库</p><p>计数功能应该是最适合 Redis 的使用场景之一了，因为它高频率读写的特征可以完全发挥 Redis 作为内存数据库的高效。在 Redis 的<a href="https://so.csdn.net/so/search?q=%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84&spm=1001.2101.3001.7020">数据结构</a>中，<code>string</code>、<code>hash</code>和<code>sorted set</code>都提供了<code>incr</code>方法用于原子性的自增操作，下面举例说明一下它们各自的使用场景：</p><ul><li>  如果应用需要显示每天的注册用户数，便可以使用<code>string</code>作为计数器，设定一个名为<code>REGISTERED_COUNT_TODAY</code>的 key，并在初始化时给它设置一个到凌晨 0 点的过期时间，每当用户注册成功后便使用<code>incr</code>命令使该 key 增长 1，同时当每天凌晨 0 点后，这个计数器都会因为 key 过期使值清零。</li><li>  每条微博都有点赞数、评论数、转发数和浏览数四条属性，这时用<code>hash</code>进行计数会更好，将该计数器的 key 设为<code>weibo:weibo_id</code>，<code>hash</code>的 field 为<code>like_number</code>、<code>comment_number</code>、<code>forward_number</code>和<code>view_number</code>，在对应操作后通过<code>hincrby</code>使<code>hash 中</code>的 field 自增。</li><li>  如果应用有一个发帖排行榜的功能，便选择<code>sorted set</code>吧，将集合的 key 设为<code>POST_RANK</code>。当用户发帖后，使用<code>zincrby</code>将该用户 id 的 score 增长 1。<code>sorted set</code>会重新进行排序，用户所在排行榜的位置也就会得到实时的更新。</li></ul><h2 id="6、限流"><a href="#6、限流" class="headerlink" title="6、限流"></a>6、限流</h2><p>int类型，incr方法</p><p>以访问者的ip和其他信息作为key，访问一次增加一次计数，超过次数则返回false</p><h2 id="7、位统计"><a href="#7、位统计" class="headerlink" title="7、位统计"></a>7、位统计</h2><p>String类型的bitcount（1.6.6的bitmap数据结构介绍）</p><p>字符是以8位二进制存储的</p><pre><code>set k1 asetbit k1 6 1setbit k1 7 0get k1 /* 6 7 代表的a的二进制位的修改a 对应的ASCII码是97，转换为二进制数据是01100001b 对应的ASCII码是98，转换为二进制数据是01100010因为bit非常节省空间（1 MB=8388608 bit），可以用来做大数据量的统计。*/</code></pre><p>例如：在线用户统计，留存用户统计</p><pre><code>setbit onlineusers 01 setbit onlineusers 11 setbit onlineusers 20</code></pre><p>支持按位与、按位或等等操作</p><pre><code>BITOPANDdestkeykey[key...] ，对一个或多个 key 求逻辑并，并将结果保存到 destkey 。       BITOPORdestkeykey[key...] ，对一个或多个 key 求逻辑或，并将结果保存到 destkey 。 BITOPXORdestkeykey[key...] ，对一个或多个 key 求逻辑异或，并将结果保存到 destkey 。 BITOPNOTdestkeykey ，对给定 key 求逻辑非，并将结果保存到 destkey 。</code></pre><p>计算出7天都在线的用户</p><pre><code>BITOP &quot;AND&quot; &quot;7_days_both_online_users&quot; &quot;day_1_online_users&quot; &quot;day_2_online_users&quot; ...  &quot;day_7_online_users&quot;</code></pre><p>参考 <a href="https://blog.csdn.net/agonie201218/article/details/107161106">使用Redis的bitmaps统计用户留存率、活跃用户</a></p><p><a href="https://blog.csdn.net/agonie201218/article/details/108988577">用户日活月活怎么统计 - Redis HyperLogLog 详解</a></p><h2 id="8-时间轴（Timeline）"><a href="#8-时间轴（Timeline）" class="headerlink" title="8. 时间轴（Timeline）"></a>8. 时间轴（Timeline）</h2><p> <code>list</code>作为双向链表，不光可以作为队列使用。如果将它用作栈便可以成为一个公用的时间轴。当用户发完微博后，都通过<code>lpush</code>将它存放在一个 key 为<code>LATEST_WEIBO</code>的<code>list</code>中，之后便可以通过<code>lrange</code>取出当前最新的微博。</p><h2 id="9-消息队列"><a href="#9-消息队列" class="headerlink" title="9. 消息队列"></a>9. 消息队列</h2><p>Redis 中<code>list</code>的数据结构实现是双向链表，所以可以非常便捷的应用于消息队列（生产者 / 消费者模型）。消息的生产者只需要通过<code>lpush</code>将消息放入 list，消费者便可以通过<code>rpop</code>取出该消息，并且可以保证消息的有序性。如果需要实现带有优先级的消息队列也可以选择<code>sorted set</code>。而<code>pub/sub</code>功能也可以用作发布者 / 订阅者模型的消息。无论使用何种方式，由于 Redis 拥有持久化功能，也不需要担心由于服务器故障导致消息丢失的情况。</p><p>List提供了两个阻塞的弹出操作：blpop/brpop，可以设置超时时间</p><ul><li>  blpop：blpop key1 timeout 移除并获取列表的第一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。</li><li>  brpop：brpop key1 timeout 移除并获取列表的最后一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。</li></ul><p>上面的操作。其实就是java的阻塞队列。学习的东西越多。学习成本越低</p><ul><li>  队列：先进先除：rpush blpop，左头右尾，右边进入队列，左边出队列</li><li>  栈：先进后出：rpush brpop</li></ul><h3 id="10、抽奖"><a href="#10、抽奖" class="headerlink" title="10、抽奖"></a>10、抽奖</h3><p>利用set结构的无序性,通过 Spop（ Redis Spop 命令用于移除<a href="https://so.csdn.net/so/search?q=%E9%9B%86%E5%90%88&spm=1001.2101.3001.7020">集合</a>中的指定 key 的一个或多个随机元素，移除后会返回移除的元素。 ） 随机获得值</p><pre><code>redis&gt; SADD myset &quot;one&quot;(integer) 1redis&gt; SADD myset &quot;two&quot;(integer) 1redis&gt; SADD myset &quot;three&quot;(integer) 1redis&gt; SPOP myset&quot;one&quot;redis&gt; SMEMBERS myset1) &quot;three&quot;2) &quot;two&quot;redis&gt; SADD myset &quot;four&quot;(integer) 1redis&gt; SADD myset &quot;five&quot;(integer) 1redis&gt; SPOP myset 31) &quot;five&quot;2) &quot;four&quot;3) &quot;two&quot;redis&gt; SMEMBERS myset1) &quot;three&quot;redis&gt; </code></pre><h2 id="11、点赞、签到、打卡"><a href="#11、点赞、签到、打卡" class="headerlink" title="11、点赞、签到、打卡"></a>11、点赞、签到、打卡</h2><p><img src="https://img-blog.csdnimg.cn/img_convert/201157552a906cdee10942c9e3acc2c3.png" alt="图片"></p><p>假如上面的微博ID是t1001，用户ID是u3001</p><p>用 like:t1001 来维护 t1001 这条微博的所有点赞用户</p><ul><li>  点赞了这条微博：sadd like:t1001 u3001</li><li>  取消点赞：srem like:t1001 u3001</li><li>  是否点赞：sismember like:t1001 u3001</li><li>  点赞的所有用户：smembers like:t1001</li><li>  点赞数：scard like:t1001</li></ul><p>是不是比数据库简单多了。</p><h2 id="12-商品标签"><a href="#12-商品标签" class="headerlink" title="12 商品标签"></a>12 商品标签</h2><p><img src="https://img-blog.csdnimg.cn/img_convert/c3af93df9d330c0c490667e497a6846e.png" alt="图片"></p><p>老规矩，用 tags:i5001 来维护商品所有的标签。</p><ul><li>  sadd tags:i5001 画面清晰细腻</li><li>  sadd tags:i5001 真彩清晰显示屏</li><li>  sadd tags:i5001 流程至极</li></ul><h3 id="13、好友关系、用户关注、推荐模型"><a href="#13、好友关系、用户关注、推荐模型" class="headerlink" title="13、好友关系、用户关注、推荐模型"></a>13、好友关系、用户关注、推荐模型</h3><p>这个场景最开始是是一篇介绍微博 Redis 应用的 PPT 中看到的，其中提到微博的 Redis 主要是用在在计数和好友关系两方面上，当时对好友关系方面的用法不太了解，后来看到《Redis 设计与实现》中介绍到作者最开始去使用 Redis 便是希望能通过<code>set</code>解决传统数据库无法快速计算集合中交集这个功能。后来联想到微博当前的业务场景，确实能够以这种方式实现，所以姑且猜测一下：</p><p>对于一个用户 A，将它的关注和粉丝的用户 id 都存放在两个 set 中：</p><ul><li><p>  <code>A:follow</code>：存放 A 所有关注的用户 id</p></li><li><p><code>A:follower</code>：存放 A 所有粉丝的用户 id</p><p>  那么通过<code>sinter</code>命令便可以根据<code>A:follow</code>和<code>A:follower</code>的交集得到与 A 互相关注的用户。当 A 进入另一个用户 B 的主页后，<code>A:follow</code>和<code>B:follow</code>的交集便是 A 和 B 的共同专注，<code>A:follow</code>和<code>B:follower</code>的交集便是 A 关注的人也关注了 B。</p></li></ul><h3 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h3><p>follow 关注 fans 粉丝</p><p>相互关注：</p><ul><li>  sadd 1:follow 2</li><li>  sadd 2:fans 1</li><li>  sadd 1:fans 2</li><li>  sadd 2:follow 1</li></ul><p>我关注的人也关注了他(取交集)：</p><ul><li>  sinter 1:follow 2:fans</li></ul><p>可能认识的人：</p><ul><li>  用户1可能认识的人(差集)：sdiff 2:follow 1:follow</li><li>  用户2可能认识的人：sdiff 1:follow 2:follow</li></ul><h2 id="14-排行榜"><a href="#14-排行榜" class="headerlink" title="14 .排行榜"></a>14 .排行榜</h2><p>使用<code>sorted set</code>(有序set)和一个计算热度的算法便可以轻松打造一个热度排行榜，<code>zrevrangebyscore</code>可以得到以分数倒序排列的序列，<code>zrank</code>可以得到一个成员在该排行榜的位置（是分数正序排列时的位置，如果要获取倒序排列时的位置需要用<code>zcard</code>-<code>zrank</code>）。</p><p>id 为6001 的新闻点击数加1：</p><pre><code>zincrby hotNews:20190926 1 n6001</code></pre><p>获取今天点击最多的15条：</p><pre><code>zrevrange hotNews:20190926 0 15 withscores</code></pre><h3 id="15-倒排索引"><a href="#15-倒排索引" class="headerlink" title="15 .倒排索引"></a>15 .倒排索引</h3><p>倒排索引是构造搜索功能的最常见方式，在 Redis 中也可以通过<code>set</code>进行建立倒排索引，这里以简单的拼音 + 前缀搜索城市功能举例：</p><p>假设一个城市<code>北京</code>，通过拼音词库将<code>北京</code>转为<code>beijing</code>，再通过前缀分词将这两个词分为若干个前缀索引，有：<code>北</code>、<code>北京</code>、<code>b</code>、<code>be</code>…<code>beijin</code>和<code>beijing</code>。将这些索引分别作为<code>set</code>的 key（例如:<code>index:北</code>）并存储<code>北京</code>的 id，倒排索引便建立好了。接下来只需要在搜索时通过关键词取出对应的<code>set</code>并得到其中的 id 即可。</p><h2 id="16-显示最新的项目列表"><a href="#16-显示最新的项目列表" class="headerlink" title="16 .显示最新的项目列表"></a><strong>16 .显示最新的项目列表</strong></h2><p>比如说，我们的一个Web应用想要列出用户贴出的最新20条评论。在最新的评论边上我们有一个“显示全部”的链接，点击后就可以获得更多的评论。</p><p>每次新评论发表时，我们会将它的ID添加到一个Redis列表。可以限定列表的长度为5000</p><p>LPUSH latest.comments</p><p>在Redis中我们的最新ID使用了常驻缓存，这是一直更新的。但是我们做了限制不能超过5000个ID，因此我们的获取ID函数会一直询问Redis。只有在超出了这个范围的时候，才需要去访问数据库。</p><h1 id="17、购物车"><a href="#17、购物车" class="headerlink" title="17、购物车"></a>17、购物车</h1><p>String 或hash。所有String可以做的hash都可以做</p><p><img src="https://img-blog.csdnimg.cn/bf8b92966ab448d88c48f0b45a262e0c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5oiR5Lus5LiA6LW35Y675aSn5Y6C,size_9,color_FFFFFF,t_70,g_se,x_16" alt="图片"></p><ul><li>  key：用户id；field：商品id；value：商品数量。</li><li>  +1：hincr。-1：hdecr。删除：hdel。全选：hgetall。商品数：hlen。</li></ul><h1 id="18、商品筛选"><a href="#18、商品筛选" class="headerlink" title="18、商品筛选"></a>18、商品筛选</h1><pre><code>// 获取差集sdiff set1 set2// 获取交集（intersection ）sinter set1 set2// 获取并集sunion set1 set2</code></pre><p><img src="https://img-blog.csdnimg.cn/d8db8ebb604848bca9646dac0a21859c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5oiR5Lus5LiA6LW35Y675aSn5Y6C,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><p>假如：iPhone11 上市了</p><pre><code>sadd brand:apple iPhone11sadd brand:ios iPhone11sad screensize:6.0-6.24 iPhone11sad screentype:lcd iPhone 11</code></pre><p>赛选商品，苹果的、ios的、屏幕在6.0-6.24之间的，屏幕材质是LCD屏幕</p><pre><code>sinter brand:apple brand:ios screensize:6.0-6.24 screentype:lcd</code></pre><h1 id="19、排行榜"><a href="#19、排行榜" class="headerlink" title="19、排行榜"></a>19、排行榜</h1><p>id 为6001 的新闻点击数加1：</p><blockquote><p>zincrby hotNews:20190926 1 n6001</p></blockquote><p>获取今天点击最多的15条：</p><blockquote><p>zrevrange hotNews:20190926 0 15 withscores</p></blockquote><p><img src="https://img-blog.csdnimg.cn/e61eb794e182400da1aa9f84b00e7800.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5oiR5Lus5LiA6LW35Y675aSn5Y6C,size_7,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; &lt;a href=&quot;https://blog.csdn.net/Number_oneEngineer/article/details/123229706&quot;&gt;https://blog.csdn.net/Number_oneEngineer/article/details/12</summary>
      
    
    
    
    <category term="redis" scheme="http://zhangyu.info/categories/redis/"/>
    
    
    <category term="redis" scheme="http://zhangyu.info/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>云原生微服务最佳实践</title>
    <link href="http://zhangyu.info/2022/05/28/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
    <id>http://zhangyu.info/2022/05/28/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</id>
    <published>2022-05-27T16:00:00.000Z</published>
    <updated>2022-05-28T06:20:51.855Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://developer.aliyun.com/article/891714?spm=5176.21213303.J_6704733920.7.22db53c9yXA1Zr&amp;scm=20140722.S_community@@%E6%96%87%E7%AB%A0@@891714._.ID_community@@%E6%96%87%E7%AB%A0@@891714-RL_%E4%BA%91%E5%8E%9F%E7%94%9F%E6%9E%B6%E6%9E%84%E4%B8%8B%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%80%89%E5%9E%8B%E5%92%8C%E6%BC%94%E8%BF%9B-LOC_main-OR_ser-V_2-P0_0">https://developer.aliyun.com/article/891714?spm=5176.21213303.J_6704733920.7.22db53c9yXA1Zr&amp;scm=20140722.S_community%40%40%E6%96%87%E7%AB%A0%40%40891714._.ID_community%40%40%E6%96%87%E7%AB%A0%40%40891714-RL_%E4%BA%91%E5%8E%9F%E7%94%9F%E6%9E%B6%E6%9E%84%E4%B8%8B%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%80%89%E5%9E%8B%E5%92%8C%E6%BC%94%E8%BF%9B-LOC_main-OR_ser-V_2-P0_0</a></p><p>作者：彦林<br>本文整理自阿里云智能高级技术专家彦林的线上直播分享《云原生微服务最佳实践》。视频回放地址：<a href="https://yqh.aliyun.com/live/detail/28454">https://yqh.aliyun.com/live/detail/28454</a></p><p><a href="https://developer.aliyun.com/article/891714?spm=5176.21213303.J_6704733920.7.22db53c9yXA1Zr&scm=20140722.S_community@@%E6%96%87%E7%AB%A0@@891714._.ID_community@@%E6%96%87%E7%AB%A0@@891714-RL_%E4%BA%91%E5%8E%9F%E7%94%9F%E6%9E%B6%E6%9E%84%E4%B8%8B%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%80%89%E5%9E%8B%E5%92%8C%E6%BC%94%E8%BF%9B-LOC_main-OR_ser-V_2-P0_0">云原生架构下的微服务选型和演进-阿里云开发者社区</a></p><blockquote><p>随着云原生的演进，微服务作为主流应用架构被广泛使用，其落地的难题逐步从如何建好延伸到如何用好。今天跟各位小伙伴分享一下我在微服务领域 10 余年的实践经验，如何以更高效的姿势把微服务这件事做扎实。</p><h2 id="阿里微服务发展历程"><a href="#阿里微服务发展历程" class="headerlink" title="阿里微服务发展历程"></a>阿里微服务发展历程</h2><h3 id="微服务-1-0-（1w-实例-微服务拆分-同城容灾）"><a href="#微服务-1-0-（1w-实例-微服务拆分-同城容灾）" class="headerlink" title="微服务 1.0 （1w 实例/微服务拆分/同城容灾）"></a>微服务 1.0 （1w 实例/微服务拆分/同城容灾）</h3><p>2008 年随着阿里业务规模不断增大，单体胖应用+硬负载的架构逐渐暴露性能瓶颈；随着研发人员逐步增多，协调效率也逐步下降，不能满足日益复杂的业务挑战，因此急需技术升级解决这些问题。<br> <img src="https://ucc.alicdn.com/pic/developer-ecology/755e59619c8c46f19ca8886caf9b725b.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650460882673-b82ca6e7-297e-42a4-817d-badbf61b1604.png?x-oss-process=image/resize,w_1165,limit_0"> </p><p>在当时 SOA 架构非常流行，也就成为我们技术演进的主要方向，当时有两种解决方案，一个是 Server Based 的解决方案，这种模式侵入小、方便集中管控，但是这种中心化方案会带来成本高、稳定性风险高、扩展性差；一个是 Client Based 的解决方案，这种模式去中心化，扩展性强，成本低，但是会带来一定侵入性，比较难以管理；当然很多人会问为什么不直接用 DNS 呢？主要是 DNS 不能满足 IDC 内部服务发现实时性，服务列表更新不能及时通知下有业务会导致业务流量损失。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650461250591-19bfb292-1d8d-4f87-918c-9629d5fc7cbd.png?x-oss-process=image/resize,w_1177,limit_0"> </p><p>在评估两种方案利弊之后，我们在网关这种需要集中管理安全和简单路由场景采用了 Server Based 的方案，基于 Nginx 演进出了阿里 Tengine 网关技术体系，从入口处解决安全、高可用、简单路由能力；在 IDC 内部采用了 Client Base 模式，孵化出 HSF/Dubbo+Nacos 技术体系，支撑了业务微服务拆分。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650461729968-5cb9547c-cd5d-4b9f-9399-364b98176bc1.png?x-oss-process=image/resize,w_1188,limit_0"> </p><p>随着第一代微服务架构落地，由于引入注册中心带来了稳定性风险，注册中心挂会导致调用链路全部中断；业务集中发布的时候注册中心压力会比较大。</p><p> <img src="https://ucc.alicdn.com/pic/developer-ecology/25993cdf295a410fa086fb6ff888c54a.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650508584813-db5f3b84-d992-4d65-8ecd-9c681bdcafd8.png?x-oss-process=image/resize,w_1114,limit_0"> </p><p>针对可用性问题我们提供了推空保护能力，即使注册中心挂也不会影响业务正常运行；为了提供更好性能我们提供了全异步架构；为了支持同城容灾我们提供了 AP 一致性协议，具体协议可以参考《Nacos 架构与原理》电子书。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650508698563-3d6d07b7-6003-449f-97aa-3313a3748faa.png?x-oss-process=image/resize,w_937,limit_0"> </p><p>随着阿里微服务 1.0 架构落地，帮助业务完成微服务拆分，解决了扩展性和协同效率问题，同时支撑了阿里同城容灾能力。对于正在做微服务的小伙伴可能问阿里如何做微服务架构演进的：</p><p><strong>前后端分离是第一步</strong>，因为前端变化多，变化快，后端相对变化小，演进慢，因此需要解耦发展，让前端更快的适应市场变化，以便在竞争中保持先机；</p><p><strong>后端无状态改造是第二步，</strong>把内存状态外置到 Redis，把持久化状态外置到 Mysql，这样业务就可以随意进行切分；</p><p><strong>第三步是模块化拆分，</strong>这块是最考验架构师的，因为拆分一个是按照业务属性拆分，一个是按照应用复杂度进行拆分，这个是一个相对动态过程，建议拆分模块后 2-3 人负责一个模块，拆到太细会有比较高的运维成本，拆的太粗又会带来研发协同问题，阿里内部也经历过合久必分，分久必合的几波震荡，最终走到相对稳态。这里值得一提就是 HSF/Dubbo 的一个优势，因为早期采用 SOA 架构思想设计，一个接口就是一个服务，这样其实非常方便服务的拆分和合并，当然同时带来一个问题是对注册中心性能压力比较大，这是一个架构选择和平衡问题。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650462151116-d659464c-9abf-47c1-aea3-ada1738d921e.png?x-oss-process=image/resize,w_1178,limit_0"> </p><h3 id="微服务-2-0（10w-实例-业务中台-异地多活）"><a href="#微服务-2-0（10w-实例-业务中台-异地多活）" class="headerlink" title="微服务 2.0（10w 实例/业务中台/异地多活）"></a>微服务 2.0（10w 实例/业务中台/异地多活）</h3><p>微服务 1.0 架构帮助阿里极大缓解性能和效率问题，但是由于阿里双十一的成功，技术上面临一个洪峰的技术挑战，我们必须在用户体验、资源成本、高可用之间做一个平衡。这个阶段我们最大的挑战是扩展性和稳定性，扩展性是要支撑业务 10w+实例扩容，但是单地资源有限，双十一商家投入的资金越来越大，导致我们双十一当天也不能出严重问题，不然损失非常大，因此对业务稳定性提出非常高的要求。<br> <img src="https://ucc.alicdn.com/pic/developer-ecology/caa299c0e6e84c40ad3a9c70f56303a9.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650462646607-791462f4-595f-4dfd-b16b-457a33ff0972.png?x-oss-process=image/resize,w_937,limit_0"> </p><p>因此阿里演进到微服务 2.0 支撑了异地多活的高可用体系，让阿里业务可以按照 IDC 级别水平扩展，新的机房，新的技术体系都可以在单元中进行验证，也加速了阿里技术体系演进速度。<br> <img src="https://ucc.alicdn.com/pic/developer-ecology/80e28a96536640fea086b733e79b0e69.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650463572269-62635384-a842-42d6-b7b6-5e948f9a57ae.png?x-oss-process=image/resize,w_1188,limit_0"> </p><p>在此期间 Nacos Server 间水平通知压力巨大，业务发布窗口容易把网卡打满，频繁推送会消耗业务大量内存和 CPU，进而影响业务的稳定性。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650508924614-ec9806bf-df64-4e93-b898-48c2350b3e01.png?x-oss-process=image/resize,w_937,limit_0"> </p><p>针对上述问题，我们在 Nacos Server 间做了聚合推送，将一定时间窗的变更合并聚合推送，推送过程中做了压缩推送，从而解决了上述问题。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650508934970-0f10fd5f-038f-4d64-9baa-a1178df0b7a7.png?x-oss-process=image/resize,w_937,limit_0"> </p><p>在微服务解决扩展性和高可用的同时，业务系统变多，重复建设，业务孤岛也越来越多，协同效率也越来越低，因此阿里业务在这个时候推出了业务中台能力，将扁平的微服务抽象分层，将基础服务抽象为中台服务解决上述问题，业务分层后支撑了阿里业务高速增长，也加速了技术架构统一。 <img src="https://ucc.alicdn.com/pic/developer-ecology/a772d2e42c8e4db6bb050c6679da3997.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650463819661-fc69a6f1-fb7e-4b4d-b1c2-f00659a3e49a.png?x-oss-process=image/resize,w_1160,limit_0"> </p><h3 id="微服务-3-0（100w-实例-业务域拆分-云原生）"><a href="#微服务-3-0（100w-实例-业务域拆分-云原生）" class="headerlink" title="微服务 3.0（100w 实例/业务域拆分/云原生）"></a>微服务 3.0（100w 实例/业务域拆分/云原生）</h3><p>微服务 2.0 架构支撑了阿里双十一的技术奇迹，阿里也陆续开启业务扩张，构建更完整的互联网版图。在这个阶段阿里收购了比较多的公司，技术体系不统一如何形成合力；从线上走到线下后，线下系统对系统稳定性要求更高；云计算发展，如何利用好云的弹性做双十一，这个阶段我们也推出了微服务的云产品，期望通过云产品支撑阿里双十一。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650464151858-72dfe7f9-b5bc-42b7-827b-553bdbf9ce89.png?x-oss-process=image/resize,w_937,limit_0"> </p><p>业务域切分比较容易，切完之后如何更好的互联互通是一个关键，因此我们内部推出了 Nacos-sync 和云原生网关两个产品。Nacos-sync 适合业务流量超大，协议一致场景。云原生网关适合网络不通，协议不同，跨 Region 等场景。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650465807802-a2d8f5f6-79a3-4597-b79d-e7f4cadafba9.png?x-oss-process=image/resize,w_1128,limit_0"> </p><p>即使从顶层做了业务域拆分，但是最大的电商集群往百万实例演进过程中对注册中心的压力越来越大，我们把聚合窗口时间不断拉长，推送慢了会导致业务发布时间变长，推送快了会对业务消耗较大，因此陷入了两难境地。</p><p> <img src="https://ucc.alicdn.com/pic/developer-ecology/c32c246c55d2432cb4885199b476ebc4.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650509243198-6fe13d99-5b6d-4e41-9bde-cfc8a59d45ab.png?x-oss-process=image/resize,w_937,limit_0"> </p><p>这个阶段我们进行问题的分解，首先根据服务列表大小做了一个切分，服务列表多的可以推送慢一些问题也不大，服务列表小的需要及时推送，因此我们优化了聚合推送逻辑，根据服务列表大小做了分级推送。还有一个优化思路是变更只有几个列表变化，因此我们提供了增量推送能力，大幅降低服务变更推送数据量。<br> <img src="https://ucc.alicdn.com/pic/developer-ecology/f8db6f13fb54416091568489a31be669.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650509262172-e9fa62ae-463d-425b-9933-806d2a6e4e2d.png?x-oss-process=image/resize,w_1087,limit_0"> </p><p>通过微服务 3.0 架构演进很好的解决了跨域互通和平滑上云的问题，新业务可以先上云，或者部分业务上云，通过网关做云上云下互通等问题，同时支撑了百万实例微服务架构演进。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650465843769-f8d72e1a-68f4-4da3-8f5b-a52690bbf47e.png?x-oss-process=image/resize,w_1158,limit_0"> </p><p> <img src="https://ucc.alicdn.com/pic/developer-ecology/ca0536204d5c4512baa2b0a37345c6fc.gif" alt="image.gif" title="image.gif"> 期望通过我分享阿里微服务发展历程给大家做微服务架构演进提供一些思路和启发。</p><h3 id="云原生微服务趋势"><a href="#云原生微服务趋势" class="headerlink" title="云原生微服务趋势"></a>云原生微服务趋势</h3><p>随着云原生技术演进，容器以不可变基础设施为理念，解决运维标准和资源利用率问题；微服务以可变运行时为理念，解决研发效率问题，提升系统整体扩展性和高可用。经常有人问我，为什么有了容器的服务发现机制，还需要微服务的注册中心呢？从架构上首先是分层的，小的时候确实也看不到明显区别，大一些就会发现问题，如阿里中心最大微服务集群，底层是多个 Kubernetes 集群，防止一个 Kubernetes 出问题影响全局，底层 Kubernetes 也可以水平扩展，如果依赖了 Kubernetes 的服务发现机制，跨 Kubernetes 服务发现就成了第一个问题。当然底层是一个 Kubernetes 上面也可以是多个微服务环境，微服务可以按照业务域切分。两层可以做解耦，自由环境组合。还有就是阿里微服务体系积累了推空保护、服务治理完整体系，而 Kubernetes 的 CoreDNS 将服务发现强制拉到业务调用链路，每次调用都会做域名解析，因此 CoreDNS 挂的时候业务全部中断。</p><p>对于阿里整体正在从百万实例往千万实例的规模演进，这部分也是阿里微服务 4.0 的内容，这部分给大部分公司的借鉴意义有限，因此不做展开。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650466402749-bdc504d9-a794-418a-b894-e6fbab042065.png?x-oss-process=image/resize,w_937,limit_0"> </p><h2 id="微服务最佳实践"><a href="#微服务最佳实践" class="headerlink" title="微服务最佳实践"></a>微服务最佳实践</h2><p>阿里微服务体系经过 10 余年的发展，目前已经通过开源被广泛使用，通过阿里云支撑了成千上万家企业做数字化升级。借此机会把我们的最佳实践总结分享给大家，期望都对大家用好微服务有所帮助。</p><h3 id="阿里微服务体系简介"><a href="#阿里微服务体系简介" class="headerlink" title="阿里微服务体系简介"></a>阿里微服务体系简介</h3><p>通过 MSE + ACK 能够完成第一步云原生技术升级，释放云弹性红利，释放研发效率红利，可以通过可观测和高可用进一步用好微服务体系。</p><p> <img src="https://ucc.alicdn.com/pic/developer-ecology/fba1762c8d8741fb995606b1d9165143.gif" alt="image.gif" title="image.gif"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467432533-a4f4ad8f-3655-4d9c-8d73-4e1ebb10d8a9.png?x-oss-process=image/resize,w_1148,limit_0"> </p><h3 id="微服务最佳实践-1"><a href="#微服务最佳实践-1" class="headerlink" title="微服务最佳实践"></a>微服务最佳实践</h3><p>通过注册&amp;配置中心完成微服务拆分；通过网关统一入口，从入口处解决安全和高可用问题；最后通过服务治理提升用户微服务的问题。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467575338-9a9707a4-40a6-4bbf-9daa-368e995787ae.png?x-oss-process=image/resize,w_961,limit_0"> </p><h3 id="网关最佳实践"><a href="#网关最佳实践" class="headerlink" title="网关最佳实践"></a>网关最佳实践</h3><p>云原生网关作为下一代网关，提供高集成、高可用、高性能、安全的一站式网关解决方案。</p><ul><li>  <strong>统一接入</strong>：将流量网关、 微服务网关、 WAF 三合一大幅降低资源和运维成本，需要强调的是云原生网关集成 WAF 的方案有非常好的性能优势，WAF 做为控制面下发防护规则到云原生网关，流量直接在云原生网关清洗完毕直接路由到后端机器，RT 短，运维成本低。</li><li>  <strong>统一入口安全防线：</strong>自动更新证书防过期，支持 JWT/OAuth2/OIDC/IDaaS 认证机制，支持黑白名单机制。</li><li>  <strong>统一东西南北流量</strong>：统一解决跨域互通问题，包括跨网络域，跨业务域，跨地域，跨安全域等。</li><li>  <strong>统一服务发现机制：</strong>支持 Nacos/Kubernetes/DNS/ 固定 IP 多种服务发现方式。</li><li>  <strong>统一观测平台：</strong>从入口做好 tracing 埋点全链路诊断，丰富业务大盘和告警模板大幅降低网关运维成本。</li><li>  <strong>统一服务治理：</strong>从入口做限流、降级、熔断等高可用能力，提供全链路灰度方案控制变更风险。<strong>统一性能优化：</strong>采用硬件加速性能提升 80%，Ingress 场景比 Nginx 性能高 90%，参数调优+模块优化提升 40%。</li></ul><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467595709-6a151762-5c02-4d8b-90a6-8a289b90aeba.png?x-oss-process=image/resize,w_1151,limit_0"> </p><p>云原生网关支持 WASM 扩展网关自定义功能，并且通过插件市场提供丰富的插件能力。 <img src="https://ucc.alicdn.com/pic/developer-ecology/4c2169fee946427991df5e136e9d481a.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650468450175-eff9c375-9488-4000-820d-fed14a1c3e49.png?x-oss-process=image/resize,w_937,limit_0"> </p><h3 id="服务治理最佳实践"><a href="#服务治理最佳实践" class="headerlink" title="服务治理最佳实践"></a>服务治理最佳实践</h3><p>提供零业务侵入，开发，测试，运维全覆盖服务治理能力，提升系统高可用。如发布阶段即使注册中心是毫秒级推送也会有延迟，这个期间就会导致流量损失，因此我们提供了无损上下线能力解决这个痛点。本月我们将服务治理能力通过 OpenSergo 开源，欢迎各位小伙伴参与共建！  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467610712-ac9fe081-caa4-4fa7-aa61-cabf61532870.png?x-oss-process=image/resize,w_1161,limit_0"> </p><h3 id="日常环境隔离最佳实践"><a href="#日常环境隔离最佳实践" class="headerlink" title="日常环境隔离最佳实践"></a>日常环境隔离最佳实践</h3><p>共享一套环境联调开发相互影响，所有环境都独立联调机器成本太高，这个是一个矛盾，我们通过全链路打标能力将流量隔离，让大家可以在一套环境隔离多个逻辑联调环境，巧妙的解决这个问题。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467627252-58a7dbaa-86ef-45a1-81ff-8d3a43e43af2.png?x-oss-process=image/resize,w_1144,limit_0"> </p><h3 id="配置管理最佳实践"><a href="#配置管理最佳实践" class="headerlink" title="配置管理最佳实践"></a>配置管理最佳实践</h3><p>随着应用规模变大，到每个机器去修改配置运维成本太高，因此需要配置中心统一维护应用配置，将静态业务动态化，动态修改业务运行时行为，提升应用运行时灵活性。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467667752-93728a9e-18e2-41aa-8e60-b421c77fee36.png?x-oss-process=image/resize,w_1164,limit_0"> </p><h3 id="服务网格最佳实践"><a href="#服务网格最佳实践" class="headerlink" title="服务网格最佳实践"></a>服务网格最佳实践</h3><p>对于多语言开发有诉求和对服务网关感兴趣的小伙伴可以通过 MSE+ASM 快速构建服务网格解决方案，完成服务互通，快速体验新的技术。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467681962-8065a419-aa38-4cab-b693-af8e5734d2bd.png?x-oss-process=image/resize,w_1147,limit_0"> </p><h3 id="微服务高可用最佳实践"><a href="#微服务高可用最佳实践" class="headerlink" title="微服务高可用最佳实践"></a>微服务高可用最佳实践</h3><p>随着业务复杂度变高，业务峰值不可测，面对失败的设计和微服务高可用工具使用就非常重要，可以通过 Sentinel 完成限流、降级、熔断的保护，可以通过 PTS 完成压测，可以通过混沌工程完成破坏性测试，从体整体提升系统高可用。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467697257-018ce835-63b2-4909-a051-256c61514a0b.png?x-oss-process=image/resize,w_1150,limit_0"> </p><h3 id="注册中心平滑迁移实践"><a href="#注册中心平滑迁移实践" class="headerlink" title="注册中心平滑迁移实践"></a>注册中心平滑迁移实践</h3><p>目前大规模场景推荐双注册，如 1w 实例以上，这样发布周期长，稳定性更高一些。如果不到 1w 实例可以通过 Nacos-sync 同步完成注册中心平滑前一，这样通用型强一些。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467714583-9e9eae9a-32d5-4258-9424-a014718acbec.png?x-oss-process=image/resize,w_1186,limit_0"> </p><h3 id="网关平衡迁移实践"><a href="#网关平衡迁移实践" class="headerlink" title="网关平衡迁移实践"></a>网关平衡迁移实践</h3><p>由于前面云原生网关三合一和性能优势，大家可以通过入口 DNS 灰度切换到云原生网关。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467728539-22275719-f7b8-43ab-af41-e47adc147c78.png?x-oss-process=image/resize,w_1144,limit_0"> </p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="微服务标杆客户"><a href="#微服务标杆客户" class="headerlink" title="微服务标杆客户"></a>微服务标杆客户</h2><p>用户上云中有两类典型客户，一类是传统的单体胖应用客户，一类是已经采用了微服务需要用好微服务的用户，我们通过两个标杆客户分享一下。</p><h3 id="斯凯奇微服务＋业务中台实践"><a href="#斯凯奇微服务＋业务中台实践" class="headerlink" title="斯凯奇微服务＋业务中台实践"></a>斯凯奇微服务＋业务中台实践</h3><p>斯凯奇 2021 年找到我们做数字化升级时间非常紧急，需要双十一前 3 个月左右要完成数字化升级，采用 MSE 微服务+中台解决方案，斯凯奇借助云原生网关完成了东西南北流量的统一控制，借助南北向云原生网关完成安全认证和入口限流，从入口做好流量防护；借助东西向网关完成了多个业务域的互通，新老系统的互通，1 个月左右完成了整个系统的搭建，1 个月左右完成了整个系统压测和高可用验证，并且最终大促业务非常成功，助力斯凯奇双十一 12 亿营收规模。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467744650-35f4135b-1fe3-49a0-801e-dcfd3c275490.png?x-oss-process=image/resize,w_1166,limit_0"> </p><h3 id="来电微服务全链路灰度最佳实践"><a href="#来电微服务全链路灰度最佳实践" class="headerlink" title="来电微服务全链路灰度最佳实践"></a>来电微服务全链路灰度最佳实践</h3><h4 id="来电的技术挑战"><a href="#来电的技术挑战" class="headerlink" title="来电的技术挑战"></a><strong>来电的技术挑战</strong></h4><p>来电科技的业务场景丰富且系统众多，在技术架构上已完成容器化以及微服务化改造，微服务框架使用的是 Spring Cloud 与 Dubbo。随着近年来的高速发展，充电宝设备节点以及业务量都在快速增加，系统的稳定性面临几点挑战:</p><p>1.在系统服务的发布过程中如何避免业务流量的损失；2.系统缺少简单有效的灰度能力，每次系统发布都存在一定的稳定性风险。MSE 微服务治理提供了开箱即用且无侵入的线上发布稳定性解决方案以及全链路灰度解决方案，帮助来电科技消除发布风险、提升线上稳定性。</p><h4 id="来电全链路灰度最佳实践"><a href="#来电全链路灰度最佳实践" class="headerlink" title="来电全链路灰度最佳实践"></a><strong>来电全链路灰度最佳实践</strong></h4><p>1.来电科技选用 MSE 微服务治理专业版来实现无侵入微服务治理能力，无缝支持市面上近 5 年所有的 Spring Cloud 和 Dubbo 的版本，不用改一行代码，不需要改变业务的现有架构就可以使用，没有绑定。</p><p>2.MSE 微服务治理专业版提供了全链路灰度解决方案帮助来电科技快速落地可灰度、可观测、可回滚的安全生产三板斧能力，满足业务高速发展情况下快速迭代和小心验证的诉求；</p><p>3.MSE 微服务治理的无损上下线能力，对系统服务的全流程进行防护，通过服务预热、无损下线、与 Kubernetes 微服务生命周期对齐、延迟发布等一系列能力，保证在服务冷启动或销毁过程中，业务连续无损。</p><p>4.MSE 微服务治理的离群实例摘除能力，可以做到让服务消费者自动检测其所调用提供者实例的可用性并进行实时的权重动态调整，以保证服务调用的成功率，从而提升业务稳定性和服务质量。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467760065-7aab61b1-4829-4de9-9f6b-8ab9ce978922.png?x-oss-process=image/resize,w_1160,limit_0"> </p><h2 id="阿里云微服务生态与规划"><a href="#阿里云微服务生态与规划" class="headerlink" title="阿里云微服务生态与规划"></a>阿里云微服务生态与规划</h2><p>阿里开源微服务会贴着服务治理帮助开发者用户微服务，云产品做好产品集成提升大家的使用体验。</p><p>ACK+MSE = 云原生架构升级解决方案</p><p>ASM+MSE = 服务网格解决方案</p><p>AHAS + MSE = 微服务高可用解决方案</p><p>ARMS + MSE = 微服务可观测解决方案</p><p>EDAS + MSE = APaaS解决方案</p><p>SAE + MSE = 微服务 Serverless 解决方案</p><p>WAF + 云盾 + IDaaS + MSE = 微服务安全解决方案</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650511793071-9ba68377-ae2e-4b3c-b9a0-fb0e2dd07360.png?x-oss-process=image/resize,w_977,limit_0"></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://developer.aliyun.com/article/891714?spm=5176.21213303.J_6704733920.7.22db53c9yXA1Zr&amp;amp;scm=20140722.S_community@@%E6%96</summary>
      
    
    
    
    <category term="微服务" scheme="http://zhangyu.info/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
    <category term="微服务" scheme="http://zhangyu.info/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>微服务之间的最佳调用方式</title>
    <link href="http://zhangyu.info/2022/05/28/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B9%8B%E9%97%B4%E7%9A%84%E6%9C%80%E4%BD%B3%E8%B0%83%E7%94%A8%E6%96%B9%E5%BC%8F/"/>
    <id>http://zhangyu.info/2022/05/28/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B9%8B%E9%97%B4%E7%9A%84%E6%9C%80%E4%BD%B3%E8%B0%83%E7%94%A8%E6%96%B9%E5%BC%8F/</id>
    <published>2022-05-27T16:00:00.000Z</published>
    <updated>2022-05-28T06:23:50.040Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/weixin_38748858/article/details/101062272">https://blog.csdn.net/weixin_38748858/article/details/101062272</a></p><p><a href="https://blog.csdn.net/weixin_38748858/article/details/101062272">微服务之间的最佳调用方式_倚天码农的博客-CSDN博客_微服务调用</a></p><blockquote><p>在微服务架构中，需要调用很多服务才能完成一项功能。服务之间如何互相调用就变成微服务架构中的一个关键问题。服务调用有两种方式，一种是RPC方式，另一种是事件驱动（Event-driven）方式，也就是发消息方式。消息方式是松耦合方式，比紧耦合的RPC方式要优越，但RPC方式如果用在适合的场景也有它的一席之地.</p><p><strong>耦合的种类：</strong><br>我们总在谈耦合，那么耦合到底意味着什么呢？</p><ol><li> 时间耦合：客户端和服务端必须同时上线才能工作。发消息时，接受消息队列必须运行，但后台处理程序暂时不工作也不影响。</li><li> 容量耦合：客户端和服务端的处理容量必须匹配。发消息时，如果后台处理能力不足也不要紧，消息队列会起到缓冲的作用。</li><li> 接口耦合：RPC调用有函数标签，而消息队列只是一个消息。例如买了商品之后要调用发货服务，如果是发消息，那么就只需发送一个商品被买消息。</li><li> 发送方式耦合：RPC是点对点方式，需要知道对方是谁，它的好处是能够传回返回值。消息既可以点对点，也可以用广播的方式，这样减少了耦合，但也使返回值比较困难。</li></ol><p>下面我们来逐一分析这些耦合的影响。 第一，时间耦合，对于多数应用来讲，你希望能马上得到回答，因此即使使用消息队列，后台也需要一直工作。第二，容量耦合，如果你对回复有时间要求，那么消息队列的缓冲功能作用不大，因为你希望及时响应。真正需要的是自动伸缩（Auto-scaling），它能自动调整服务端处理能力去匹配请求数量。第三和第四，接口耦合和发送方式耦合，这两个确实是RPC方式的软肋。</p><h3 id="事件驱动（Event-Driven）方式："><a href="#事件驱动（Event-Driven）方式：" class="headerlink" title="事件驱动（Event-Driven）方式："></a>事件驱动（Event-Driven）方式：</h3><p>Martin Fowler把事件驱动分成四种方式(<a href="https://martinfowler.com/articles/201701-event-driven.html">What do you mean by “Event-Driven”</a>)，简化之后本质上只有两种方式。 一种就是我们熟悉的的事件通知（Event Notification），另一种是事件溯源（Event Sourcing）。事件通知就是微服务之间不直接调用，而是通过发消息来进行合作。事件溯源有点像记账，它把所有的事件都记录下来，作为永久存储层，再在它的基础之上构建应用程序。实际上从应用的角度来讲，它们并不应该分属一类，它们的用途完全不同。事件通知是微服务的调用（或集成）方式，应该和RPC分在一起。事件溯源是一种存储数据的方式，应该和数据库分在一起。</p><h4 id="事件通知（Event-Notification）方式："><a href="#事件通知（Event-Notification）方式：" class="headerlink" title="事件通知（Event Notification）方式："></a>事件通知（Event Notification）方式：</h4><p>让我们用具体的例子来看一下。在下面的例子中，有三个微服务，“Order Service”， “Customer Service” 和“Product Service”.</p><p><img src="https://img-blog.csdnimg.cn/20190920153708185.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODc0ODg1OA==,size_16,color_FFFFFF,t_70" alt="file"></p><p><a href="https://www.infoq.com/presentations/aggregates-modular-microservices/">图片来源</a></p><p>先说读数据，假设要创建一个“Order”，在这个过程中需要读取“Customer”的数据和“Product”数据。如果用事件通知的方式就只能在“Order Service”本地也创建只读“Customer”和“Product”表，并把数据用消息的方式同步过来。</p><p>再说写数据，如果在创建一个“Order”时需要创建一个新的“Customer”或要修改“Customer”的信息，那么可以在界面上跳转到用户创建页面，然后在“Customer Service”创建用户之后再发”用户已创建“的消息，“Order Service”接到消息，更新本地“Customer”表。</p><p>这并不是一个很好的使用事件驱动的例子，因为事件驱动的优点就是不同的程序之间可以独立运行，没有绑定关系。但现在“Order Service”需要等待“Customer Service”创建完了之后才能继续运行，来完成整个创建“Order”的工作。主要是因为“Order”和“Customer”本身从逻辑上来讲就是紧耦合关系，没有“Customer”你是不能创建“Order”的。</p><p>在这种紧耦合的情况下，也可以使用RPC。你可以建立一个更高层级的管理程序来管理这些微服务之间的调用，这样“Order Service”就不必直接调用“Customer Service”了。当然它从本质上来讲并没有解除耦合，只是把耦合转移到了上一层，但至少现在“order Service”和“Customer Service”可以互不影响了。之所以不能根除这种紧耦合关系是因为它们在业务上是紧耦合的。</p><p>再举一个购物的例子。用户选好商品之后进行“Checkout”，生成“Order”，然后需要“payment”，再从“Inventory”取货，最后由“Shipment”发货，它们每一个都是微服务。这个例子用RPC方式和事件通知方式都可以完成。当用RPC方式时，由“Order”服务调用其他几个服务来完成整个功能。用事件通知方式时，“Checkout”服务完成之后发送“Order Placed”消息，“Payment”服务收到消息，接收用户付款，发送“Payment received”消息。“Inventory”服务收到消息，从仓库里取货，并发送“Goods fetched”消息。“Shipment”服务得到消息，发送货物，并发送“Goods shipped”消息。</p><p><img src="https://img-blog.csdnimg.cn/20190920153708514.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODc0ODg1OA==,size_16,color_FFFFFF,t_70" alt="file"></p><p><a href="https://blog.bernd-ruecker.com/the-microservice-workflow-automation-cheat-sheet-fc0a80dc25aa">图片来源</a></p><p>对这个例子来讲，使用事件驱动是一个不错的选择，因为每个服务发消息之后它不需要任何反馈，这个消息由下一个模块接收来完成下一步动作，时间上的要求也比上一个要宽松。用事件驱动的好处是降低了耦合度，坏处是你现在不能在程序里找到整个购物过程的步骤。如果一个业务逻辑有它自己相对固定的流程和步骤，那么使用RPC或业务流程管理（BPM）能够更方便地管理这些流程。在这种情况下选哪种方案呢？在我看来好处和坏处是大致相当的。从技术上来讲要选事件驱动，从业务上来讲要选RPC。不过现在越来越多的人采用事件通知作为微服务的集成方式，它似乎已经成了微服务之间的标椎调用方式。</p><h4 id="事件溯源-Event-Sourcing-："><a href="#事件溯源-Event-Sourcing-：" class="headerlink" title="事件溯源(Event Sourcing)："></a>事件溯源(Event Sourcing)：</h4><p>这是一种具有颠覆性质的的设计，它把系统中所有的数据都以事件（Event）的方式记录下来，它的持久存储叫Event Store， 一般是建立在数据库或消息队列（例如Kafka）基础之上，并提供了对事件进行操作的接口，例如事件的读写和查询。事件溯源是由领域驱动设计(<a href="https://dddcommunity.org/book/evans_2003/">Domain-Driven Design</a>)提出来的。DDD中有一个很重要的概念，有界上下文（<a href="https://martinfowler.com/bliki/BoundedContext.html">Bounded Context</a>），可以用有界上下文来划分微服务，每个有界上下文都可以是一个微服务。 下面是有界上下文的示例。下图中有两个服务“Sales”和“Support”。有界上下文的一个关键是如何处理共享成员， 在图中是“Customer”和“Product”。在不同的有界上下文中，共享成员的含义、用法以及他们的对象属性都会有些不同，DDD建议这些共享成员在各自的有界上下文中都分别建自己的类（包括数据库表），而不是共享。可以通过数据同步的手段来保持数据的一致性。下面还会详细讲解。</p><p><img src="https://img-blog.csdnimg.cn/201909201537097.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODc0ODg1OA==,size_16,color_FFFFFF,t_70" alt="file"><br><a href="https://martinfowler.com/bliki/BoundedContext.html">图片来源</a></p><p>事件溯源是微服务的一种存储方式，它是微服务的内部实现细节。因此你可以决定哪些微服务采用事件溯源方式，哪些不采用，而不必所有的服务都变成事件溯源的。 通常整个应用程序只有一个Event Store， 不同的微服务都通过向Event Store发送和接受消息而互相通信。Event Store内部可以分成不同的stream（相当于消息队列中的Topic）， 供不同的微服务中的领域实体（Domain Entity）使用。</p><p>事件溯源的一个短板是数据查询，它有两种方式来解决。第一种是直接对stream进行查询，这只适合stream比较小并且查询比较简单的情况。查询复杂的话，就要采用第二种方式，那就是建立一个只读数据库，把需要的数据放在库中进行查询。数据库中的数据通过监听Event Store中相关的事件来更新。</p><p>数据库存储方式只能保存当前状态，而事件溯源则存储了所有的历史状态，因而能根据需要回放到历史上任何一点的状态，具有很大优势。但它也不是一点问题都没有。第一，它的程序比较复杂，因为事件是一等公民，你必须把业务逻辑按照事件的方式整理出来，然后用事件来驱动程序。第二，如果你要想修改事件或事件的格式就比较麻烦，因为旧的事件已经存储在Event Store里了（事件就像日志，是只读的），没有办法再改。</p><p>由于事件溯源和事件通知表面上看起来很像，不少人都搞不清楚它们的区别。事件通知只是微服务的集成方式，程序内部是不使用事件溯源的，内部实现仍然是传统的数据库方式。只有当要与其他微服务集成时才会发消息。而在事件溯源中，事件是一等公民，可以不要数据库，全部数据都是按照事件的方式存储的。</p><p>虽然事件溯源的践行者有不同的意见，但有不少人都认为事件溯源不是微服务的集成方式，而是微服务的一种内部实现方式。因此，在一个系统中，可以某些微服务用事件溯源，另外一些微服务用数据库。当你要集成这些微服务时，你可以用事件通知的方式。注意现在有两种不同的事件需要区分开，一种是微服务的内部事件，是颗粒度比较细的，这种事件只发送到这个微服务的stream中，只被事件溯源使用。另一种是其他微服务也关心的，是颗粒度比较粗的，这种事件会放到另外一个或几个stream中，被多个微服务使用，是用来做服务之间集成的。这样做的好处是限制了事件的作用范围，减少了不相关事件对程序的干扰。详见”<a href="https://www.innoq.com/en/blog/domain-events-versus-event-sourcing/">Domain Events vs. Event Sourcing</a>“.</p><p>事件溯源出现已经很长时间了，虽然热度一直在上升（尤其是这两年），但总的来说非常缓慢，谈论的人不少，但生产环境使用的不多。究其原因就是应为它对现在的体系结构颠覆太大，需要更改数据存储结构和程序的工作方式，还是有一定风险的。另外，微服务已经形成了一整套体系，从程序部署，服务发现与注册，到监控，服务韧性（Service Resilience），它们基本上都是针对RPC的，虽然也支持消息，但成熟度就差多了，因此有不少工作还是要自己来做。有意思的是Kafka一直在推动它作为事件驱动的工具，也取得了很大的成功。但它却没有得到事件溯源圈内的认可（详见<a href="https://stackoverflow.com/a/49868866">这里</a>）。<br>多数事件溯源都使用一个叫<a href="https://eventstore.org/">evenstore</a>的开源Event Store，或是基于某个数据库的Event Store，只有比较少的人用Kafka做Event Store。 但如果用Kafka实现事件通知就一点问题都没有。总的来说，对大多数公司来讲事件溯源是有一定挑战的，应用时需要找到合适的场景。如果你要尝试的话，可以先拿一个微服务试水。</p><p>虽然现在事件驱动还有些生涩，但从长远来讲，还是很看好它的。像其他全新的技术一样，事件溯源需要大规模的适用场景来推动。例如容器技术就是因为微服务的流行和推动，才走向主流。事件溯源以前的适用场景只限于记账和源代码库，局限性较大。区块链可能会成为它的下一个机遇，因为它用的也是事件溯源技术。另外AI今后会渗入到具体程序中，使程序具有学习功能。而RPC模式注定没有自适应功能。事件驱动本身就具有对事件进行反应的能力，这是自我学习的基础。因此，这项技术长远来讲定会大放异彩，但短期内（3-5年）大概不会成为主流。</p><h3 id="RPC方式："><a href="#RPC方式：" class="headerlink" title="RPC方式："></a>RPC方式：</h3><p>RPC的方式就是远程函数调用，像RESTFul，gRPC, DUBBO 都是这种方式。它一般是同步的，可以马上得到结果。在实际中，大多数应用都要求立刻得到结果，这时同步方式更有优势，代码也更简单。</p><h4 id="服务网关（API-Gateway）"><a href="#服务网关（API-Gateway）" class="headerlink" title="服务网关（API Gateway）:"></a>服务网关（API Gateway）:</h4><p>熟悉微服务的人可能都知道服务网关（API Gateway）。当UI需要调用很多微服务时，它需要了解每个服务的接口，这个工作量很大。于是就用服务网关创建了一个Facade，把几个微服务封装起来，这样UI就只调用服务网关就可以了，不需要去对付每一个微服务。下面是API Gateway示例图：</p><p><img src="https://img-blog.csdnimg.cn/20190920153709420.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODc0ODg1OA==,size_16,color_FFFFFF,t_70" alt="file"></p><p><a href="https://microservices.io/patterns/apigateway.html">图片来源</a></p><p>服务网关（API Gateway）不是为了解决微服务之间调用的紧耦合问题，它主要是为了简化客户端的工作。其实它还可以用来降低函数之间的耦合度。 有了API Gateway之后，一旦服务接口修改，你可能只需要修改API Gateway， 而不必修改每个调用这个函数的客户端，这样就减少了程序的耦合性。</p><h4 id="服务调用："><a href="#服务调用：" class="headerlink" title="服务调用："></a>服务调用：</h4><p>可以借鉴API Gateway的思路来减少RPC调用的耦合度，例如把多个微服务组织起来形成一个完整功能的服务组合，并对外提供统一的服务接口。这种想法跟上面的API Gateway有些相似，都是把服务集中起来提供粗颗粒（Coarse Granular）服务，而不是细颗粒的服务（Fine Granular）。但这样建立的服务组合可能只适合一个程序使用，没有多少共享价值。因此如果有合适的场景就采用，否侧也不必强求。虽然我们不能降低RPC服务之间的耦合度，却可以减少这种紧耦合带来的影响。</p><h3 id="降低紧耦合的影响："><a href="#降低紧耦合的影响：" class="headerlink" title="降低紧耦合的影响："></a>降低紧耦合的影响：</h3><p>什么是紧耦合的主要问题呢？就是客户端和服务端的升级不同步。服务端总是先升级，客户端可能有很多，如果要求它们同时升级是不现实的。它们有各自的部署时间表，一般都会选择在下一次部署时顺带升级。</p><p>一般有两个办法可以解决这个问题：</p><ol><li> 同时支持多个版本：这个工作量比较大，因此大多数公司都不会采用这种方式。</li><li> 服务端向后兼容：这是更通用的方式。例如你要加一个新功能或有些客户要求给原来的函数增加一个新的参数，但别的客户不需要这个参数。这时你只好新建一个函数，跟原来的功能差不多，只是多了一个参数。这样新旧客户的需求都能满足。它的好处是向后兼容（当然这取决于你使用的协议）。它的坏处是当以后新的客户来了，看到两个差不多的函数就糊涂了，不知道该用那个。而且时间越长越严重，你的服务端可能功能增加的不多，但相似的函数却越来越多，无法选择。</li></ol><p>它的解决办法就是使用一个支持向后兼容的RPC协议，现在最好的就是Protobuf gRPC，尤其是在向后兼容上。它给每个服务定义了一个接口，这个接口是与编程语言无关的中性接口，然后你可以用工具生成各个语言的实现代码，供不同语言使用。函数定义的变量都有编号，变量可以是可选类型的，这样就比较好地解决了函数兼容的问题。就用上面的例子，当你要增加一个可选参数时，你就定义一个新的可选变量。由于它是可选的，原来的客户端不需要提供这个参数，因此不需要修改程序。而新的客户端可以提供这个参数。你只要在服务端能同时处理这两种情况就行了。这样服务端并没有增加新的函数，但用户的新需求满足了，而且还是向后兼容的。</p><h3 id="微服务的数量有没有上限？"><a href="#微服务的数量有没有上限？" class="headerlink" title="微服务的数量有没有上限？"></a>微服务的数量有没有上限？</h3><p>总的来说微服务的数量不要太多，不然会有比较重的运维负担。有一点需要明确的是微服务的流行不是因为技术上的创新，而是为了满足管理上的需要。单体程序大了之后，各个模块的部署时间要求不同，对服务器的优化要求也不同，而且团队人数众多，很难协调管理。把程序拆分成微服务之后，每个团队负责几个服务，就容易管理了，而且每个团队也可以按照自己的节奏进行创新，但它给运维带来了巨大的麻烦。所以在微服务刚出来时，我一直觉得它是一个退步，弊大于利。但由于管理上的问题没有其他解决方案，只有硬着头皮上了。值得庆幸的是微服务带来的麻烦都是可解的。直到后来，微服务建立了全套的自动化体系，从程序集成到部署，从全链路跟踪到日志，以及服务检测，服务发现和注册，这样才把微服务的工作量降了下来。虽然微服务在技术上一无是处，但它的流行还是大大推动了容器技术，服务网格（Service Mesh）和全链路跟踪等新技术的发展。不过它本身在技术上还是没有发现任何优势。。直到有一天，我意识到单体程序其实性能调试是很困难的（很难分离出瓶颈点），而微服务配置了全链路跟踪之后，能很快找到症结所在。看来微服务从技术来讲也不全是缺点，总算也有好的地方。但微服务的颗粒度不宜过细，否则工作量还是太大。</p><p>一般规模的公司十几个或几十个微服务都是可以承受的，但如果有几百个甚至上千个，那么绝不是一般公司可以管理的。尽管现有的工具已经很齐全了，而且与微服务有关的整个流程也已经基本上全部自动化了，但它还是会增加很多工作。Martin Fowler几年以前建议先从单体程序开始（详见 <a href="https://martinfowler.com/bliki/MonolithFirst.html">MonolithFirst</a>），然后再逐步把功能拆分出去，变成一个个的微服务。但是后来有人反对这个建议，他也有些松口了。如果单体程序不是太大，这是个好主意。可以用数据额库表的数量来衡量程序的大小，我见过大的单体程序有几百张表，这就太多了，很难管理。正常情况下，一个微服务可以有两、三张表到五、六张表，一般不超过十张表。但如果要减少微服务数量的话，可以把这个标准放宽到不要超过二十张表。用这个做为大致的指标来创建微程序，如果使用一段时间之后还是觉得太大了，那么再逐渐拆分。当然，按照这个标准建立的服务更像是服务组合，而不是单个的微服务。不过它会为你减少工作量。只要不影响业务部门的创新进度，这是一个不错的方案。</p><p>到底应不应该选择微服务呢？如果单体程序已经没法管理了，那么你别无选择。如果没有管理上的问题，那么微服务带给你的只有问题和麻烦。其实，一般公司都没有太多选择，只能采用微服务，不过你可以选择建立比较少的微服务。如果还是没法决定，有一个折中的方案，“内部微服务设计”。</p><h4 id="内部微服务设计："><a href="#内部微服务设计：" class="headerlink" title="内部微服务设计："></a>内部微服务设计：</h4><p>这种设计表面上看起来是一个单体程序，它只有一个源代码存储仓库，一个数据库，一个部署，但在程序内部可以按照微服务的思想来进行设计。它可以分成多个模块，每个模块是一个微服务，可以由不同的团队管理。</p><p><img src="https://img-blog.csdnimg.cn/20190920153709762.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODc0ODg1OA==,size_16,color_FFFFFF,t_70" alt="file"></p><p><a href="https://docs.microsoft.com/en-us/dotnet/architecture/microservices/architect-microservice-container-applications/identify-microservice-domain-model-boundaries">图片来源</a></p><p>用这张图做例子。这个图里的每个圆角方块大致是一个微服务，但我们可以把它作为一个单体程序来设计，内部有五个微服务。每个模块都有自己的数据库表，它们都在一个数据库中，但模块之间不能跨数据库访问（不要建立模块之间数据库表的外键）。“User”（在Conference Management模块中）是一个共享的类，但在不同的模块中的名字不同，含义和用法也不同，成员也不一样（例如，在“Customer Service”里叫“Customer”）。DDD（Domain-Driven Design）建议不要共享这个类，而是在每一个有界上下文（模块）中都建一个新类，并拥有新的名字。虽然它们的数据库中的数据应该大致相同，但DDD建议每一个有界上下文中都建一个新表，它们之间再进行数据同步。</p><p>这个所谓的“内部微服务设计”其实就是DDD，但当时还没有微服务，因此外表看起来是单体程序，但内部已经是微服务的设计了。它的书在2003就出版了，当时就很有名。但它更偏重于业务逻辑的设计，践行起来也比较困难，因此大家谈论得很多，真正用的较少。直到十年之后，微服务出来之后，人们发现它其实内部就是微服务，而且微服务的设计需要用它的思想来指导，于是就又重新焕发了青春，而且这次更猛，已经到了每个谈论微服务的人都不得不谈论DDD的地步。不过一本软件书籍，在十年之后还能指导新技术的设计，非常令人钦佩。</p><p>这样设计的好处是它是一个单体程序，省去了多个微服务带来的部署、运维的麻烦。但它内部是按微服务设计的，如果以后要拆分成微服务会比较容易。至于什么时候拆分不是一个技术问题。如果负责这个单体程序的各个团队之间不能在部署时间表，服务器优化等方面达成一致，那么就需要拆分了。当然你也要应对随之而来的各种运维麻烦。内部微服务设计是一个折中的方案，如果你想试水微服务，但又不愿意冒太大风险时，这是一个不错的选择。<br>微服务的数据库设计也有很多内容，包括如何把服务从单体程序一步步里拆分出来请参见<a href="https://blog.csdn.net/weixin_38748858/article/details/102634941">“微服务的数据库设计”</a>.</p><h4 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h4><p>微服务之间的调用有两种方式，RPC和事件驱动。事件驱动是更好的方式，因为它是松耦合的。但如果业务逻辑是紧耦合的，RPC方式也是可行的（它的好处是代码更简单），而且你还可以通过选取合适的协议（Protobuf gRPC）来降低这种紧耦合带来的危害。由于事件溯源和事件通知的相似性，很多人把两者弄混了，但它们实际上是完全不同的东西。微服务的数量不宜太多，可以先创建比较大的微服务（更像是服务组合）。如果你还是不能确定是否采用微服务架构，可以先从“内部微服务设计”开始，再逐渐拆分。</p><h4 id="索引："><a href="#索引：" class="headerlink" title="索引："></a>索引：</h4><p>[1] <a href="https://martinfowler.com/articles/201701-event-driven.html">What do you mean by “Event-Driven”</a></p><p>[2] <a href="https://dddcommunity.org/book/evans_2003/">Domain-Driven Design</a></p><p>[3] <a href="https://martinfowler.com/bliki/BoundedContext.html">BoundedContext</a></p><p>[4] <a href="https://www.innoq.com/en/blog/domain-events-versus-event-sourcing/">Domain Events vs. Event Sourcing</a></p><p>[5] <a href="https://stackoverflow.com/a/49868866">Using Kafka as a (CQRS) Eventstore. Good idea</a></p><p>[6] <a href="https://eventstore.org/">Evenstore</a></p><p>[7] <a href="https://martinfowler.com/bliki/MonolithFirst.html">MonolithFirst</a></p><p>[8] <a href="https://blog.csdn.net/weixin_38748858/article/details/102634941">微服务的数据库设计</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/weixin_38748858/article/details/101062272&quot;&gt;https://blog.csdn.net/weixin_38748858/article/details/101062272</summary>
      
    
    
    
    <category term="微服务" scheme="http://zhangyu.info/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
    <category term="微服务" scheme="http://zhangyu.info/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>解决gateway使用nacos重启报503ServiceUnavailable问题</title>
    <link href="http://zhangyu.info/2022/05/01/%E8%A7%A3%E5%86%B3gateway%E4%BD%BF%E7%94%A8nacos%E9%87%8D%E5%90%AF%E6%8A%A5503ServiceUnavailable%E9%97%AE%E9%A2%98/"/>
    <id>http://zhangyu.info/2022/05/01/%E8%A7%A3%E5%86%B3gateway%E4%BD%BF%E7%94%A8nacos%E9%87%8D%E5%90%AF%E6%8A%A5503ServiceUnavailable%E9%97%AE%E9%A2%98/</id>
    <published>2022-04-30T16:00:00.000Z</published>
    <updated>2022-05-01T06:10:29.038Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.jianshu.com/p/70f4c2ce6ac8">https://www.jianshu.com/p/70f4c2ce6ac8</a></p><blockquote><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>项目使用spring cloud gateway作为网关，nacos作为微服务注册中心，项目搭建好后正常访问都没问题，但是有个很烦人的小瑕疵：</p><ul><li>  当某个微服务重启后，通过网关调用这个服务时有时会出现<code>503 Service Unavailable(服务不可用)</code>的错误，但过了一会儿又可以访问了，这个等待时间有时很长有时很短，甚至有时候还不会出现</li><li>  导致每次重启某个项目都要顺便启动gateway项目才能保证立即可以访问，时间长了感觉好累，想彻底研究下为什么，并彻底解决</li></ul><p><em>接下来介绍我在解决整个过程的思路，如果没兴趣，可以直接跳到最后的最终解决方案</em></p><h2 id="gateway感知其它服务上下线"><a href="#gateway感知其它服务上下线" class="headerlink" title="gateway感知其它服务上下线"></a>gateway感知其它服务上下线</h2><p>首先在某个微服务上下线时，gateway的控制台可以立即看到有对应的输出</p><p><img src="https://upload-images.jianshu.io/upload_images/9112801-0168be1734dd7bf4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/793"></p><p>某服务下线gateway输出</p><p><img src="https://upload-images.jianshu.io/upload_images/9112801-6a09eaf1f1b91bee.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/761"></p><p>某服务上线gateway输出</p><p>这说明nacos提供了这种监听功能，在注册中心服务列表发生时可以第一时间通知客户端，而在我们的依赖<code>spring-cloud-starter-alibaba-nacos-discovery</code>中显然已经帮我们实现了这个监听</p><p>所以也就说明gateway是可以立即感知其它服务的上下线事件，但问题是明明感知到某个服务的上线，那为什么会出现<code>503 Service Unavailable</code>的错误，而且上面的输出有时出现了很久，但调用依然是<code>503 Service Unavailable</code>，对应的某服务明明下线，这是应该是<code>503 Service Unavailable</code>状态，可有时确会有一定时间的<code>500</code>错误</p><h2 id="ribbon"><a href="#ribbon" class="headerlink" title="ribbon"></a>ribbon</h2><p>为了调查事情的真相，我打开了gateway的debug日志模式，找到了503的罪魁祸首  </p><p><img src="https://upload-images.jianshu.io/upload_images/9112801-e761406118f10444.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1079"></p><p>503的控制台输出</p><p>在503错误输出前，有一行这样的日志<code>Zone aware logic disabled or there is only one zone</code>，而报这个信息的包就是ribbon-loadbalancer，也就是gateway默认所使用的负载均衡器</p><p>我的gateway配置文件路由方面设置如下</p><pre><code>routes:        - id: auth          uri: lb://demo-auth          predicates:            - Path=/auth/**          filters:            - StripPrefix=1</code></pre><p>其中在uri这一行，使用了lb:// ,代表使用了gateway的ribbon负载均衡功能，官方文档说明如下<br><strong>Note that this example also demonstrates (optional) Spring Cloud Netflix Ribbon load-balancing (defined the lb prefix on the destination URI)</strong></p><p>ribbon再调用时首先会获取所有服务列表(ip和端口信息)，然后根据负载均衡策略调用其中一个服务，选择服务的代码如下</p><pre><code>package com.netflix.loadbalancer;public class ZoneAwareLoadBalancer&lt;T extends Server&gt; extends DynamicServerListLoadBalancer&lt;T&gt; &#123;    // 选择服务的方法    public Server chooseServer(Object key) &#123;            if (!ENABLED.get() || getLoadBalancerStats().getAvailableZones().size() &lt;= 1) &#123;                logger.debug(&quot;Zone aware logic disabled or there is only one zone&quot;);                return super.chooseServer(key);            &#125;    ...     </code></pre><p>这就是上面的<code>Zone aware logic..</code>这行日志的出处，经调试发现在<code>getLoadBalancerStats().getAvailableZones()</code>这一步返回的服务是空列表，说明这里没有存储任何服务信息，所以才导致最终的<code>503 Service Unavailable</code><br>继续跟进去看<code>getAvailableZones</code>的代码，如下</p><pre><code>public class LoadBalancerStats implements IClientConfigAware &#123;    // 一个缓存所有服务的map    volatile Map&lt;String, List&lt;? extends Server&gt;&gt; upServerListZoneMap = new ConcurrentHashMap&lt;String, List&lt;? extends Server&gt;&gt;();    // 获取可用服务keys    public Set&lt;String&gt; getAvailableZones() &#123;        return upServerListZoneMap.keySet();    &#125;</code></pre><p>可以看到ribbon是在LoadBalancerStats中维护了一个map来缓存所有可用服务，而问题的原因也大概明了了：<strong>gateway获取到了服务变更事件，但并没有及时更新ribbon的服务列表缓存</strong></p><h2 id="ribbon的刷新缓存机制"><a href="#ribbon的刷新缓存机制" class="headerlink" title="ribbon的刷新缓存机制"></a>ribbon的刷新缓存机制</h2><p>现在的实际情况是：gateway获取到了服务变更事件，但并没有马上更新ribbon的服务列表缓存，但过一段时间可以访问说明缓存又刷新了，那么接下来就要找到ribbon的缓存怎么刷新的，进而进一步分析为什么没有及时刷新</p><p>在LoadBalancerStats查找到更新缓存的方法是<code>updateZoneServerMapping</code></p><pre><code>public class LoadBalancerStats implements IClientConfigAware &#123;    // 一个缓存所有服务的map    volatile Map&lt;String, List&lt;? extends Server&gt;&gt; upServerListZoneMap = new ConcurrentHashMap&lt;String, List&lt;? extends Server&gt;&gt;();    // 更新缓存    public void updateZoneServerMapping(Map&lt;String, List&lt;Server&gt;&gt; map) &#123;        upServerListZoneMap = new ConcurrentHashMap&lt;String, List&lt;? extends Server&gt;&gt;(map);        // make sure ZoneStats object exist for available zones for monitoring purpose        for (String zone: map.keySet()) &#123;            getZoneStats(zone);        &#125;    &#125;</code></pre><p>那么接下来看看这个方法的调用链，调用链有点长，最终找到了<code>DynamicServerListLoadBalancer</code>下的<code>updateListOfServers</code>方法，首先看<code>DynamicServerListLoadBalancer</code>翻译过来”动态服务列表负载均衡器”，说明它有动态获取服务列表的功能，那我们的bug它肯定难辞其咎，而<code>updateListOfServers</code>就是它刷新缓存的手段，那么就看看这个所谓的”动态服务列表负载均衡器”是如何使用<code>updateListOfServers</code>动态刷新缓存的</p><pre><code>public class DynamicServerListLoadBalancer&lt;T extends Server&gt; extends BaseLoadBalancer &#123;    // 封装成一个回调    protected final ServerListUpdater.UpdateAction updateAction = new ServerListUpdater.UpdateAction() &#123;        @Override        public void doUpdate() &#123;            updateListOfServers();        &#125;    &#125;;    // 初始化    public DynamicServerListLoadBalancer(IClientConfig clientConfig, IRule rule, IPing ping,                                         ServerList&lt;T&gt; serverList, ServerListFilter&lt;T&gt; filter,                                         ServerListUpdater serverListUpdater) &#123;        ...        this.serverListUpdater = serverListUpdater; // serverListUpdate赋值        ...        // 初始化时刷新服务        restOfInit(clientConfig);    &#125;    void restOfInit(IClientConfig clientConfig) &#123;        ...        // 开启动态刷新缓存        enableAndInitLearnNewServersFeature();        // 首先刷新一遍缓存        updateListOfServers();        ...    &#125;    // 开启动态刷新缓存    public void enableAndInitLearnNewServersFeature() &#123;        // 把更新的方法传递给serverListUpdater        serverListUpdater.start(updateAction);    &#125;</code></pre><p>可以看到初始化DynamicServerListLoadBalancer时，首先updateListOfServers获取了一次服务列表并缓存，这只能保证项目启动获取一次服务列表，而真正的动态更新实现是把updateListOfServers方法传递给内部<code>serverListUpdater.start</code>方法，serverListUpdater翻译过来就是“服务列表更新器”，所以再理一下思路：</p><p>DynamicServerListLoadBalancer只所以敢自称“动态服务列表负载均衡器”，是因为它内部有个serverListUpdater(“服务列表更新器”)，也就是<code>serverListUpdater.start</code>才是真正为ribbon提供动态更新服务列表的方法，也就是罪魁祸首</p><p>那么就看看<code>ServerListUpdater</code>到底是怎么实现的动态更新，首先<code>ServerListUpdater</code>是一个接口，它的实现也只有一个PollingServerListUpdater，那么肯定是它了，看一下它的<code>start</code>方法实现</p><pre><code>public class PollingServerListUpdater implements ServerListUpdater &#123;    @Override    public synchronized void start(final UpdateAction updateAction) &#123;        if (isActive.compareAndSet(false, true)) &#123;            // 定义一个runable，运行doUpdate放            final Runnable wrapperRunnable = new Runnable() &#123;                @Override                public void run() &#123;                    ....                    try &#123;                        updateAction.doUpdate(); // 执行更新服务列表方法                        lastUpdated = System.currentTimeMillis();                    &#125; catch (Exception e) &#123;                        logger.warn(&quot;Failed one update cycle&quot;, e);                    &#125;                &#125;            &#125;;            // 定时执行            scheduledFuture = getRefreshExecutor().scheduleWithFixedDelay(                    wrapperRunnable,                    initialDelayMs,                    refreshIntervalMs, // 默认30 * 1000                    TimeUnit.MILLISECONDS            );        &#125; else &#123;            logger.info(&quot;Already active, no-op&quot;);        &#125;    &#125;</code></pre><p>至此真相大白了，原来ribbon默认更新服务列表依靠的是<strong>定时任务</strong>，而且默认30秒一次，<strong>也就是说假如某个服务重启了，gateway的nacos客户端也感知到了，但是ribbon内部极端情况需要30秒才会重新获取服务列表</strong>，这也就解释了为什么会有那么长时间的<code>503 Service Unavailable</code>问题</p><p>而且因为定时任务，所以等待时间是0-30秒不等，有可能你刚重启完就获取了正常调用没问题，也有可能刚重启完时刚获取完一次，结果就得等30秒才能访问到新的节点</p><h2 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h2><p>问题的原因找到了，接下来就是解决了，最简单暴力的方式莫过于修改定时任务的间隔时间，默认30秒，可以改成10秒，5秒，1秒，只要你机器配置够牛逼</p><p>但是有没有更优雅的解决方案，我们的gateway明明已经感知到服务的变化，如果通知ribbon直接更新，问题不就完美解决了吗，这种思路定时任务都可以去掉了，性能还优化了</p><p>具体解决步骤如下</p><ul><li>  写一个新的更新器，替换掉默认的PollingServerListUpdater更新器</li><li>  更新器可以监听nacos的服务更新</li><li>  收到服务更新事件时，调用doUpdate方法更新ribbon缓存</li></ul><p>接下来一步步解决</p><p>首先看上面DynamicServerListLoadBalancer的代码，发现更新器是构造方法传入的，所以要找到构造方法的调用并替换成自己信息的更新器</p><p>在DynamicServerListLoadBalancer构造方法上打了个断点，看看它是如何被初始化的(<strong>并不是gateway启动就会初始化，而是首次调用某个服务，给对应的服务创建一个LoadBalancer，有点懒加载的意思</strong>)  </p><p><img src="https://upload-images.jianshu.io/upload_images/9112801-31bc7100ad4ad37f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1061"></p><p>构造方法断点</p><p><img src="https://upload-images.jianshu.io/upload_images/9112801-44f34f0c171f43c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200"></p><p>debugger</p><p>看一下debugger的函数调用，发现一个<code>doCreateBean&gt;&gt;&gt;createBeanInstance</code>的调用，其中createBeanInstance执行到如下地方  </p><p><img src="https://upload-images.jianshu.io/upload_images/9112801-7f8a73918993940e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/873"></p><p>createBeanInstance</p><p>熟悉spring源码的朋友应该看得出来DynamicServerListLoadBalancer是spring容器负责创建的，而且是FactoryBean模式。</p><p>这个bean的定义在spring-cloud-netflix-ribbon依赖中的RibbonClientConfiguration类</p><pre><code>package org.springframework.cloud.netflix.ribbon;@Configuration(proxyBeanMethods = false)@EnableConfigurationProperties@Import(&#123; HttpClientConfiguration.class, OkHttpRibbonConfiguration.class,        RestClientRibbonConfiguration.class, HttpClientRibbonConfiguration.class &#125;)public class RibbonClientConfiguration &#123;    ...    @Bean    @ConditionalOnMissingBean    public ServerListUpdater ribbonServerListUpdater(IClientConfig config) &#123;        return new PollingServerListUpdater(config);    &#125;    ...&#125;</code></pre><p>也就是通过我们熟知的@Configuration+@Bean模式创建的PollingServerListUpdater更新器，而且加了个注解<code>@ConditionalOnMissingBean</code></p><p>也就是说我们自己实现一个ServerListUpdater更新器，并加入spring容器，就可以代替PollingServerListUpdater成为ribbon的更新器</p><h2 id="最终解决方案"><a href="#最终解决方案" class="headerlink" title="最终解决方案"></a>最终解决方案</h2><p>我们的更新器是要订阅nacos的，收到事件做update处理，为了避免ribbon和nacos耦合抽象一个监听器再用nacos实现</p><h5 id="1-抽象监听器"><a href="#1-抽象监听器" class="headerlink" title="1.抽象监听器"></a>1.抽象监听器</h5><pre><code>/** * @Author pq * @Date 2022/4/26 17:19 * @Description 抽象监听器 */public interface ServerListListener &#123;    /**     * 监听     * @param serviceId 服务名     * @param eventHandler 回调     */    void listen(String serviceId, ServerEventHandler eventHandler);    @FunctionalInterface    interface ServerEventHandler &#123;        void update();    &#125;&#125;</code></pre><h5 id="自定义ServerListUpdater"><a href="#自定义ServerListUpdater" class="headerlink" title="自定义ServerListUpdater"></a>自定义ServerListUpdater</h5><pre><code>public class NotificationServerListUpdater implements ServerListUpdater &#123;    private static final Logger logger = LoggerFactory.getLogger(NotificationServerListUpdater.class);    private final ServerListListener listener;    public NotificationServerListUpdater(ServerListListener listener) &#123;        this.listener = listener;    &#125;    /**     * 开始运行     * @param updateAction     */    @Override    public void start(UpdateAction updateAction) &#123;        // 创建监听        String clientName = getClientName(updateAction);        listener.listen(clientName, ()-&gt; &#123;            logger.info(&quot;&#123;&#125; 服务变化, 主动刷新服务列表缓存&quot;, clientName);            // 回调直接更新            updateAction.doUpdate();        &#125;);    &#125;    /**     * 通过updateAction获取服务名，这种方法比较粗暴     * @param updateAction     * @return     */    private String getClientName(UpdateAction updateAction) &#123;        try &#123;            Class&lt;?&gt; bc = updateAction.getClass();            Field field = bc.getDeclaredField(&quot;this$0&quot;);            field.setAccessible(true);            BaseLoadBalancer baseLoadBalancer = (BaseLoadBalancer) field.get(updateAction);            return baseLoadBalancer.getClientConfig().getClientName();        &#125; catch (Exception e) &#123;            e.printStackTrace();            throw new IllegalStateException(e);        &#125;    &#125;</code></pre><h5 id="实现ServerListListener监控nacos并注入bean容器"><a href="#实现ServerListListener监控nacos并注入bean容器" class="headerlink" title="实现ServerListListener监控nacos并注入bean容器"></a>实现ServerListListener监控nacos并注入bean容器</h5><pre><code>@Slf4j@Componentpublic class NacosServerListListener implements ServerListListener &#123;    @Autowired    private NacosServiceManager nacosServiceManager;    private NamingService namingService;    @Autowired    private NacosDiscoveryProperties properties;    @PostConstruct    public void init() &#123;        namingService =  nacosServiceManager.getNamingService(properties.getNacosProperties());    &#125;    /**     * 创建监听器     */    @Override    public void listen(String serviceId, ServerEventHandler eventHandler) &#123;        try &#123;            namingService.subscribe(serviceId, event -&gt; &#123;                if (event instanceof NamingEvent) &#123;                    NamingEvent namingEvent = (NamingEvent) event;//                    log.info(&quot;服务名：&quot; + namingEvent.getServiceName());//                    log.info(&quot;实例：&quot; + namingEvent.getInstances());                    // 实际更新                    eventHandler.update();                &#125;            &#125;);        &#125; catch (NacosException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;</code></pre><h5 id="把自定义Updater注入bean"><a href="#把自定义Updater注入bean" class="headerlink" title="把自定义Updater注入bean"></a>把自定义Updater注入bean</h5><pre><code>@Configuration@ConditionalOnRibbonNacospublic class RibbonConfig &#123;    @Bean    public ServerListUpdater ribbonServerListUpdater(NacosServerListListener listener) &#123;        return new NotificationServerListUpdater(listener);    &#125;&#125;</code></pre><p>到此，大工告成，效果是gateway访问的某微服务停止后，调用马上503，启动后，马上可以调用</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本来想解决这个问题首先想到的是nacos或ribbon肯定留了扩展，比如说改了配置就可以平滑感知服务下线，但结果看了文档和源码，并没有发现对应的扩展点，所以只能大动干戈来解决问题，其实很多地方都觉得很粗暴，比如获取clientName，但也实在找不到更好的方案，如果谁知道，麻烦评论告诉我一下</p><p>实际上我的项目更新器还保留了定时任务刷新的逻辑，一来刚接触cloud对自己的修改自信不足，二来发现nacos的通知都是udp的通知方式，可能不可靠，不知道是否多余</p><p>nacos的监听主要使用namingService的subscribe方法，里面还有坑，还有一层缓存，以后细讲</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/70f4c2ce6ac8&quot;&gt;https://www.jianshu.com/p/70f4c2ce6ac8&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;h2 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述</summary>
      
    
    
    
    <category term="nacos" scheme="http://zhangyu.info/categories/nacos/"/>
    
    
    <category term="nacos" scheme="http://zhangyu.info/tags/nacos/"/>
    
  </entry>
  
</feed>
