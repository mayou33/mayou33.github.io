<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>大雨哥</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://zhangyu8.me/"/>
  <updated>2020-06-28T05:45:36.794Z</updated>
  <id>http://zhangyu8.me/</id>
  
  <author>
    <name>大雨哥</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>微服务为什么要配置中心</title>
    <link href="http://zhangyu8.me/2020/06/28/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"/>
    <id>http://zhangyu8.me/2020/06/28/微服务为什么要配置中心/</id>
    <published>2020-06-28T03:00:00.000Z</published>
    <updated>2020-06-28T05:45:36.794Z</updated>
    
    <content type="html"><![CDATA[<p>微服务为什么要配置中心?</p><p>架构师波波的专栏</p><p><a href="https://blog.csdn.net/yang75108/article/details/86987941" target="_blank" rel="noopener">https://blog.csdn.net/yang75108/article/details/86987941</a></p><blockquote><h2 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h2><p>在系统架构中，和安全、日志、监控等非功能需求一样，配置管理也是一种非功能需求。配置中心是整个微服务基础架构体系中的一个组件，如下图，它的功能看上去并不起眼，无非就是简单配置的管理和存取，但它是整个微服务架构中不可或缺的一环。另外，配置中心如果真得用好了，它还能推动技术组织持续交付和DevOps文化转型。<br><img src="https://img-blog.csdnimg.cn/20200212132045204.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lhbmc3NTEwOA==" width="100%" height="100%"></p><p>本文介绍在分布式微服务环境下，应用配置管理背后的业务需求，配置的各种分类和一些高级应用场景。</p><h2 id="二、配置定义和形态"><a href="#二、配置定义和形态" class="headerlink" title="二、配置定义和形态"></a>二、配置定义和形态</h2><p><strong>配置其实是独立于程序的可配变量</strong>，同一份程序在不同配置下会有不同的行为，常见的配置有连接字符串，应用配置和业务配置等。</p><p>配置有多种形态，下面是一些常见的：</p><ul><li><strong>程序内部hardcode</strong>，这种做法是反模式，一般我们<strong>不建议！</strong></li><li><strong>配置文件</strong>，比如Spring应用程序的配置一般放在<code>application.properties</code>文件中。</li><li><strong>环境变量</strong>，配置可以预置在操作系统的环境变量里头，程序运行时读取，这是很多PaaS平台，比如Heroku推荐的做法，参考12 factor app[附录9.1]。</li><li><strong>启动参数</strong>，可以在程序启动时一次性提供参数，例如java程序启动时可以通过<code>java -D</code>方式配启动参数。</li><li><strong>基于数据库</strong>，有经验的开发人员会把易变配置放在数据库中，这样可以在运行期灵活调整配置，这个做法和配置中心的思路已经有点接近了。</li></ul><p><img src="https://img-blog.csdnimg.cn/20200212132102689.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lhbmc3NTEwOA==,size_16,color_FFFFFF,t_70" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-9ECzTdDT-1581484808516)(http://jskillcloud.com/img/post/2018060701/config_format.png#pic_center)]"></p><h2 id="三、传统应用配置的痛点"><a href="#三、传统应用配置的痛点" class="headerlink" title="三、传统应用配置的痛点"></a>三、传统应用配置的痛点</h2><p>在没有引入配置中心之前，一般企业研发都会面临如下痛点：</p><h3 id="1-配置散乱格式不标准"><a href="#1-配置散乱格式不标准" class="headerlink" title="1. 配置散乱格式不标准"></a><strong>1. 配置散乱格式不标准</strong></h3><p>有的用properties格式，有的用xml格式，还有的存DB，团队倾向自造轮子，做法五花八门。</p><h3 id="2-主要采用本地静态配置，配置修改麻烦"><a href="#2-主要采用本地静态配置，配置修改麻烦" class="headerlink" title="2. 主要采用本地静态配置，配置修改麻烦"></a><strong>2. 主要采用本地静态配置，配置修改麻烦</strong></h3><p>配置修改一般需要经过一个较长的测试发布周期。在分布式微服务环境下，当服务实例很多时，修改配置费时费力。</p><h3 id="3-易引发生产事故"><a href="#3-易引发生产事故" class="headerlink" title="3. 易引发生产事故"></a><strong>3. 易引发生产事故</strong></h3><p>这个是我亲身经历，之前在一家互联网公司，有团队在发布的时候将测试环境的配置带到生产上，引发百万级资损事故。</p><h3 id="4-配置缺乏安全审计和版本控制功能"><a href="#4-配置缺乏安全审计和版本控制功能" class="headerlink" title="4. 配置缺乏安全审计和版本控制功能"></a><strong>4. 配置缺乏安全审计和版本控制功能</strong></h3><p>谁改的配置？改了什么？什么时候改的？无从追溯，出了问题也无法及时回滚。</p><h2 id="四、现代应用配置核心需求"><a href="#四、现代应用配置核心需求" class="headerlink" title="四、现代应用配置核心需求"></a>四、现代应用配置核心需求</h2><p>近年，持续交付和DevOps理念开始逐步被一线企业接受，微服务架构和容器云也逐渐在一线企业落地，这些都对应用配置管理提出了更高的要求：</p><p><img src="https://img-blog.csdnimg.cn/20200212132118751.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lhbmc3NTEwOA==,size_16,color_FFFFFF,t_70" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-q00lcjAM-1581484808517)(http://jskillcloud.com/img/post/2018060701/core_requirements.png#pic_center)]"></p><h3 id="1-交付件和配置分离"><a href="#1-交付件和配置分离" class="headerlink" title="1. 交付件和配置分离"></a><strong>1. 交付件和配置分离</strong></h3><p>传统做法应用在打包部署时，会为不同环境打出不同配置的包，例如为开发/测试/UAT/生产环境分别制作发布包，每个包里头包含环境特定配置。</p><p>现代微服务提倡云原生(Cloud Native)和不可变基础设施（Immutable Infrastructure）的理念，推荐采用如容器镜像这种方式打包和交付微服务，应用镜像一般只打一份，可以部署到不同环境。这就要求交付件（比如容器镜像）和配置进行分离，交付件只制作一份，并且是不可变的，可以部署到任意环境，而配置由配置中心集中管理，所有环境的配置都可以在配置中心集中配，运行期应用根据自身环境到配置中心动态拉取相应的配置。</p><h3 id="2-抽象标准化"><a href="#2-抽象标准化" class="headerlink" title="2. 抽象标准化"></a><strong>2. 抽象标准化</strong></h3><p>企业应该由框架或者中间件团队提供标准化的配置中心服务(Configuration as a Service)，封装屏蔽配置管理的细节和配置的不同格式，方便用户进行自助式的配置管理。一般用户只需要关注两个抽象和标准化的接口：</p><ol><li>配置管理界面UI，方便应用开发人员管理和发布配置，</li><li>封装好的客户端API，方便应用集成和获取配置。</li></ol><h3 id="3-多环境多集群"><a href="#3-多环境多集群" class="headerlink" title="3. 多环境多集群"></a><strong>3. 多环境多集群</strong></h3><p>现代微服务应用大都采用多环境部署，一般标准化的环境有开发/测试/UAT/生产等，有些应用还需要多集群部署，例如支持跨机房或者多版本部署。配置中心需要支持对多环境和多集群应用配置的集中式管理。</p><h3 id="4-高可用"><a href="#4-高可用" class="headerlink" title="4. 高可用"></a><strong>4. 高可用</strong></h3><p>配置中心必须保证高可用，不能随便挂，否则可能大面积影响微服务。在极端的情况下，如果配置中心不可用，客户端也需要有降级策略，保证应用可以不受影响。</p><h3 id="5-实时性"><a href="#5-实时性" class="headerlink" title="5. 实时性"></a><strong>5. 实时性</strong></h3><p>配置更新需要尽快通知到客户端，这个周期不能太长，理想应该是实时的。有些配置的实时性要求很高，比方说主备切换配置或者蓝绿部署配置，需要秒级切换配置的能力。</p><h3 id="6-治理"><a href="#6-治理" class="headerlink" title="6. 治理"></a><strong>6. 治理</strong></h3><p>配置需要治理，具体包括：</p><ul><li>配置审计，谁、在什么时间、修改了什么配置，需要详细的审计，方便出现问题时能够追溯。</li><li>配置版本控制，每次变更需要版本化，出现问题时候能够及时回滚到上一版本。</li><li>配置权限控制，配置变更发布需要认证授权，不是所有人都能修改和发布配置。</li><li>灰度发布，高级的配置治理支持灰度发布，配置发布时可以先让少数实例生效，确保没有问题再逐步放量。</li></ul><h2 id="五、配置分类"><a href="#五、配置分类" class="headerlink" title="五、配置分类"></a>五、配置分类</h2><p>配置目前还没有特别标准的分类方法，我简单把配置分为静态和动态两大类，每一类再分为若干子类，如下图：</p><p><img src="https://img-blog.csdnimg.cn/20200212132133488.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lhbmc3NTEwOA==,size_16,color_FFFFFF,t_70" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-57ZCzoGH-1581484808518)(http://jskillcloud.com/img/post/2018060701/config_category.png#pic_center)]"></p><h3 id="1-静态配置"><a href="#1-静态配置" class="headerlink" title="1. 静态配置"></a><strong>1. 静态配置</strong></h3><p>所谓静态配置，就是在程序启动前一次性配好，启动时一次性生效，在程序运行期一般不会变化的配置。具体包括：</p><h4 id="1-1-环境相关配置"><a href="#1-1-环境相关配置" class="headerlink" title="1.1 环境相关配置"></a>1.1 环境相关配置</h4><p>有些配置是和环境相关的，每个环境的配置不一样，例如数据库、中间件和其它服务的连接字符串配置。这些配置一次性配好，运行期一般不变。</p><h4 id="1-2-安全配置"><a href="#1-2-安全配置" class="headerlink" title="1.2 安全配置"></a>1.2 安全配置</h4><p>有些配置和安全相关，例如用户名，密码，访问令牌，许可证书等，这些配置也是一次性配好，运行期一般不变。因为涉及安全，相关信息一般需要加密存储，对配置访问需要权限控制。</p><h3 id="2-动态配置"><a href="#2-动态配置" class="headerlink" title="2. 动态配置"></a><strong>2. 动态配置</strong></h3><p>所谓动态配置，就是在程序的运行期可以根据需要动态调整的配置。动态配置让应用行为和功能的调整变得更加灵活，是持续交付和DevOps的最佳实践。具体包括：</p><h4 id="2-1-应用配置"><a href="#2-1-应用配置" class="headerlink" title="2.1 应用配置"></a>2.1 应用配置</h4><p>和应用相关的配置，例如服务请求超时，线程池和队列的大小，缓存过期时间，数据库连接池的容量，日志输出级别，限流熔断阀值，服务安全黑白名单等。一般开发或者运维会根据应用的实际运行情况调整这些配置。</p><h4 id="2-2-业务配置"><a href="#2-2-业务配置" class="headerlink" title="2.2 业务配置"></a>2.2 业务配置</h4><p>和业务相关的一些配置，例如促销规则，贷款额度，利率等业务参数，A/B测试参数等。一般产品运营或开发人员会根据实际的业务需求，动态调整这些参数。</p><h4 id="2-3-功能开关"><a href="#2-3-功能开关" class="headerlink" title="2.3 功能开关"></a>2.3 功能开关</h4><p>在英文中也称Feature Flag/Toggle/Switch，简单的只有真假两个值，复杂的可以是多值参数。功能开关是DevOps的一种最佳实践，在运维中有很多应用场景，比如蓝绿部署，灰度开关，降级开关，主备切换开关，数据库迁移开关等。功能开关在国外互联网公司用得比较多，国内还没有普及开，所以我在下一节会给出一些功能开关的高级应用场景。</p><h2 id="六、配置中心高级应用场景"><a href="#六、配置中心高级应用场景" class="headerlink" title="六、配置中心高级应用场景"></a>六、配置中心高级应用场景</h2><h3 id="场景一、蓝绿部署"><a href="#场景一、蓝绿部署" class="headerlink" title="场景一、蓝绿部署"></a>场景一、蓝绿部署</h3><p>蓝绿部署的传统做法是通过负载均衡器切流量来实现，如下图左边所示。这种做法一般研发人员无法自助操作，需要提交工单由运维介入操作，操作和反馈周期比较长，出了问题回退还需运维人员介入，所以回退也比较慢，总体风险比较高。</p><p><img src="https://img-blog.csdnimg.cn/20200212132148357.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lhbmc3NTEwOA==,size_16,color_FFFFFF,t_70" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-ZFkvyLnE-1581484808519)(http://jskillcloud.com/img/post/2018060701/blue_green_deployment.png#pic_center)]"></p><p>蓝绿部署也可以通过配置中心+功能开关的方式来实现，如上图右边所示。开发人员在上线新功能时先将新功能隐藏在动态开关后面，开关的值在配置中心里头配。刚上线时新功能暂不启用，走老功能逻辑，然后开发人员通过配置中心打开开关，这个时候新功能就启用了。一旦发现新功能有问题，可以随时把开关关掉切回老功能。这种做法开发人员可以全程自助实现蓝绿部署，不需要运维人员介入，反馈周期短效率高。</p><h3 id="场景二、限流降级"><a href="#场景二、限流降级" class="headerlink" title="场景二、限流降级"></a>场景二、限流降级</h3><p>当业务团队在搞促销，或者是系统受DDOS攻击的时候，如果没有好的限流降级机制，则系统很容易被洪峰流量冲垮，这个时候所有用户无法访问，体验糟糕，如下图左边所示。</p><p><img src="https://img-blog.csdnimg.cn/20200212132159343.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lhbmc3NTEwOA==,size_16,color_FFFFFF,t_70" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-ieWQQ5Mr-1581484808520)(http://jskillcloud.com/img/post/2018060701/rate_limiting_degrade.png#pic_center)]"></p><p>所以我们需要限流降级机制来应对流量洪峰。常见做法，我们一般会在应用的过滤器层或者是网关代理层添加限流降级逻辑，并且和配置中心配合，实现限流降级开关和参数的动态调整。如果促销出现流量洪峰，我们可以通过配置中心启动限流降级策略，比如对于普通用户，我们可以先给出“网络不给力，请稍后再试”的友好提示，对于高级VIP用户，我们仍然保证他们的正常访问。</p><p>国内电商巨头阿里，它内部的系统大量采用<font color="red">限流降级机制，实现方式基于其内部的diamond+sentinel配置管理系统。</font>如果没有限流降级机制的保护，则阿里的系统也无法抵御双十一带来的洪峰流量冲击。</p><h3 id="场景三、数据库迁移"><a href="#场景三、数据库迁移" class="headerlink" title="场景三、数据库迁移"></a>场景三、数据库迁移</h3><p>LaunchDarkly是一家提供配置既服务(Configuration as a Service)的SAAS服务公司，它在其博客上给出了一片关于使用功能开关实现数据库迁移的案例文章，该案例基于其内部一次成功的数据库迁移实践，从MongdoDB迁移到DynamoDB[参考附录9.2]，下图是展示了一个简化的迁移流程：</p><p><img src="https://img-blog.csdnimg.cn/20200212132212489.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lhbmc3NTEwOA==,size_16,color_FFFFFF,t_70" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-N4Q8XNdr-1581484808520)(http://jskillcloud.com/img/post/2018060701/ff_database_migration-768x1024.jpg#pic_center)]"></p><p>简化迁移腾挪流程如下：</p><ol><li>开发人员先在应用端的DAO层埋好数据双写双读、以及数据比对逻辑。双写双读逻辑由开关控制，开关的值可在配置中心配。</li><li>先保证应用100%读写mongoDB，然后先放开10%的DynamoDB双写，也称金丝雀写(Canary Write)，确保金丝雀写没有功能和性能问题。</li><li>逐步放量DyanamoDB写到100%，确保全量双写没有功能和性能问题。</li><li>放开10%的DynamoDB双读，也称金丝雀读(Canary Read)，通过比对逻辑确保金丝雀读没有逻辑和性能问题。</li><li>逐步放量DynamoDB读到100%，通过比对逻辑确保全量双读没有逻辑和性能问题。</li><li>关闭对mongoDB的读写，迁移完成。</li></ol><p>整个迁移流程受配置中心的开关控制，可以灵活调整开关和参数，有问题可以随时回滚，大大降低迁移风险。</p><h3 id="场景四、A-B测试"><a href="#场景四、A-B测试" class="headerlink" title="场景四、A/B测试"></a>场景四、A/B测试</h3><p>如果我们需要对电商平台的结账(checkout)功能进行改版，考虑到结账功能业务影响面大，一下子上线风险大，为了减低风险，我们可以在配置中心配合下，对结账功能进行A/B测试，简化逻辑如下图：</p><p><img src="https://img-blog.csdnimg.cn/20200212132223128.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lhbmc3NTEwOA==,size_16,color_FFFFFF,t_70" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-xlzC9otk-1581484808521)(http://jskillcloud.com/img/post/2018060701/ab_test.png#pic_center)]"></p><p>我们在配置中心中增加一个<code>ab_test_flag</code>开关，控制A/B测试逻辑：</p><ol><li>如果A/B测试开关是关闭的(<code>ab_test_flag==false</code>)，那么就走老的结账逻辑。</li><li>如果A/B测试开关是打开的(<code>ab_test_flag==true</code>，并且是普通用户(<code>user==regular</code>，可以检查数据库中用户类型)，那么就走老的结账逻辑。</li><li>如果A/B测试开关是打开的(<code>ab_test_flag==true</code>)，并且是beta用户（<code>user==beta</code>），那么就走改版后的新结账逻辑。</li></ol><p>通过配置中心，我们可以灵活调整开关，先对新功能进行充分的beta试验，再考虑全量上线，大大降低关键业务新功能的上线风险。</p><h2 id="七、公司案例和产品"><a href="#七、公司案例和产品" class="headerlink" title="七、公司案例和产品"></a>七、公司案例和产品</h2><p>在一线前沿的互联网公司，配置中心都是其技术体系中的关键基础服务，下图给出一些公司案例产品：</p><p><img src="https://img-blog.csdnimg.cn/20200212132236228.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lhbmc3NTEwOA==,size_16,color_FFFFFF,t_70" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-MA6Ky9GG-1581484808521)(http://jskillcloud.com/img/post/2018060701/config_center_products.png#pic_center)]"></p><ol><li>阿里巴巴中间件部门很早就自研了配置中心Diamond，并且是开源的。Diamond对阿里系统的灵活稳定性发挥了至关重要的作用。开源版本的Diamond由于研发时间比较早，使用的技术比较老，功能也不够完善，目前社区不热已经不维护了。</li><li>Facebook内部也有一整套完善的配置管理体系[可参考其论文，附录9.3]，其中一个产品叫Gatekeeper，目前没有开源。</li><li>Netflix内部有大量的微服务，它的服务的稳定灵活性也重度依赖于配置中心。Netflix开源了它的配置中心的客户端，叫变色龙Archaius[参考附录9.4]，比较可惜的是，Netflix没有开源它的配置中心的服务器端。</li><li>Apollo[参考附录9.5]是携程框架部研发并开源的一款配置中心产品，企业级治理功能完善，目前社区比较火，在github上有超过5k星，在国内众多互联网公司有落地案例。<strong>如果企业打算引入开源的配置中心，那么Apollo是我推荐的首选</strong>。</li><li>百度之前也开源过一个叫Disconf[参考附录9.6]的配置中心产品，作者是前百度资深工程师廖绮绮。在Apollo没有出来之前，Disconf在社区是比较火的，但是自从廖琦琦离开百度之后，他好像没有足够精力投入维护这个项目，目前社区活跃度已经大不如前。</li></ol><h2 id="八、结论"><a href="#八、结论" class="headerlink" title="八、结论"></a>八、结论</h2><ol><li>配置中心是微服务基础架构中不可或缺的核心组件，现代微服务架构和云原生环境，对应用配置管理提出了更高的要求。</li><li>配置中心有众多的应用场景，<strong>配置中心+功能开关是DevOps最佳实践</strong>。用好配置中心，它能帮助技术组织实现持续交付和DevOps文化转型。</li><li>携程开源的Apollo配置中心，企业级功能完善，经过大规模生产验证，社区活跃度高，是开源配置中心产品的首选。</li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;微服务为什么要配置中心?&lt;/p&gt;
&lt;p&gt;架构师波波的专栏&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/yang75108/article/details/86987941&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;htt
      
    
    </summary>
    
      <category term="配置中心" scheme="http://zhangyu8.me/categories/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"/>
    
    
      <category term="配置中心" scheme="http://zhangyu8.me/tags/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"/>
    
  </entry>
  
  <entry>
    <title>小米Redis的K8s容器化部署实践</title>
    <link href="http://zhangyu8.me/2020/06/22/%E5%B0%8F%E7%B1%B3Redis%E7%9A%84Kubernetes%E5%AE%B9%E5%99%A8%E5%8C%96%E9%83%A8%E7%BD%B2%E5%AE%9E%E8%B7%B5/"/>
    <id>http://zhangyu8.me/2020/06/22/小米Redis的Kubernetes容器化部署实践/</id>
    <published>2020-06-22T03:00:00.000Z</published>
    <updated>2020-06-22T03:13:53.486Z</updated>
    
    <content type="html"><![CDATA[<p>小米Redis的K8s容器化部署实践</p><p>原创 崔凯峰 小米云技术 </p><p><a href="https://mp.weixin.qq.com/s/WrUU3C-C8TBgJfGuOv3qGQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/WrUU3C-C8TBgJfGuOv3qGQ</a></p><blockquote><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>小米的Redis使用规模很大，现在有数万个实例，并且每天有百万亿次的访问频率，支撑了几乎所有的产品线和生态链公司。之前所有的Redis都部署在物理机上，也没有做资源隔离，给管理治理带来了很大的困难。我们的运维人员工作压力很大，机器宕机网络抖动导致的Redis节点下线都经常需要人工介入处理。由于没有做CPU的资源隔离，slave节点打RDB或者由于流量突增导致节点QPS升高造成的节点CPU使用率升高，都可能对本集群或其他集群的节点造成影响，导致无法预测的时延增加。</p><p>Redis分片方式采用社区的Redis Cluster协议，集群自主分片。Redis Cluster带来了一定的易用性的同时，也提高了应用开发的门槛，应用开发人员需要一定程度上了解Redis Cluster，同时需要使用智能客户端访问Redis Cluster。这些智能客户端配置参数繁多，应用开发人员并无法完全掌握并设置这些参数，踩了很多坑。同时，由于智能客户端需要做分片计算，给应用端的机器也带来了一定的负载。</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/sz_mmbiz_png/Re4KW51oYRpnDfGTj2hakEapXh4jdmcVtxn9dUon7LbJnGJOOQkEZziaRaedAMJIkY8TaKru5STJXBtKibNxt7Ow/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><h2 id="Why-K8S"><a href="#Why-K8S" class="headerlink" title="Why K8S"></a>Why K8S</h2><h2 id="资源隔离"><a href="#资源隔离" class="headerlink" title="资源隔离"></a><strong>资源隔离</strong></h2><p>当前的Redis Cluster部署在物理机集群上，为了提高资源利用率节约成本，多业务线的Redis集群都是混布的。由于没有做CPU的资源隔离，经常出现某Redis节点CPU使用率过高导致其他Redis集群的节点争抢不到CPU资源引起时延抖动。因为不同的集群混布，这类问题很难快速定位，影响运维效率。K8s容器化部署可以指定 CPU request 和 CPU limit ，在提高资源利用率的同时避免了资源争抢。</p><h2 id><a href="#" class="headerlink" title=" "></a> </h2><h2 id="自动化部署"><a href="#自动化部署" class="headerlink" title="自动化部署"></a><strong>自动化部署</strong></h2><p>自动化部署。当前Redis Cluster在物理机上的部署过程十分繁琐，需要通过查看元信息数据库查找有空余资源的机器，手动修改很多配置文件再逐个部署节点，最后使用redis_trib工具创建集群，新集群的初始化工作经常需要一两个小时。</p><p>K8s通过StatefulSet部署Redis集群，使用configmap管理配置文件，新集群部署时间只需要几分钟，大大提高了运维效率。</p><h2 id="How-K8S"><a href="#How-K8S" class="headerlink" title="How K8S"></a>How K8S</h2><p>客户端通过LVS的VIP统一接入，通过Redis Proxy转发服务请求到Redis Cluster集群。这里我们引入了Redis Proxy来转发请求。</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/sz_mmbiz_png/Re4KW51oYRpnDfGTj2hakEapXh4jdmcV9yKs0YScPnxtplmyDUUxl1miaEib7Ekn9L73dKS2Tia7fA6XCOd3CDTNA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><h2 id="Redis-Cluster部署方式"><a href="#Redis-Cluster部署方式" class="headerlink" title="Redis Cluster部署方式"></a><strong>Redis Cluster部署方式</strong></h2><p>Redis部署为StatefulSet，作为有状态的服务，选择StatefulSet最为合理，可以将节点的RDB/AOF持久化到分布式存储中。当节点重启漂移到其他机器上时，可通过挂载的PVC(PersistentVolumeClaim)拿到原来的RDB/AOF来同步数据。我们选择的持久化存储PV(PersistentVolume)是Ceph Block Service。Ceph的读写性能低于本地磁盘，会带来100~200ms的读写时延。但由于Redis的RDB/AOF的写出都是异步的，分布式存储带来的读写延迟对服务并没有影响。</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/sz_mmbiz_png/Re4KW51oYRpnDfGTj2hakEapXh4jdmcVPzdQYX28SbZqwYl5tlFBkqfpxM3xOC3IQa3qEq2hnEYISoMWmrXFqA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><h2 id="-1"><a href="#-1" class="headerlink" title=" "></a> </h2><h2 id="Proxy选型"><a href="#Proxy选型" class="headerlink" title="Proxy选型"></a><strong>Proxy选型</strong></h2><p>## </p><p>开源的Redis Proxy有很多，常见的开源Redis Proxy如下:</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/sz_mmbiz_png/Re4KW51oYRrJAgO3tqmgH2KF0EcfGqqW2pJcs1rgdmyqibPpJbRM4PiabXStSXeyObE7y8wqvZqeLZ7N4RVNfIog/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p>我们希望能够继续使用Redis Cluster来管理Redis集群，所以Codis和Twemproxy不再考虑。redis-cluster-proxy是Redis官方在6.0版本推出的支持Redis Cluster协议的Proxy，但是目前还没有稳定版，暂时也无法大规模应用。</p><p>备选就只有Cerberus和Predixy两种。我们在K8s环境上对Cerberus和Predixy进行了性能测试，结果如下:</p><h3 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a><strong>测试环境</strong></h3><p>测试工具: redis-benchmark</p><p>Proxy CPU: 2 core</p><p>Client CPU: 2 core</p><p>Redis Cluster: 3 master nodes, 1 CPU per node</p><h3 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a><strong>测试结果</strong></h3><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/sz_mmbiz_png/Re4KW51oYRrJAgO3tqmgH2KF0EcfGqqWdUeLMTycZ2acica48JEiahLtSuFbULukibvVAFqbDOC4fcQRqKhx8RqgQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/sz_mmbiz_png/Re4KW51oYRpnDfGTj2hakEapXh4jdmcVNwHM46icecJg2NzJJQMZqP9CicfnyK7LeTAt3kPoGe3ldvpRgZX5erwA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p>## </p><p>在相同workload和配置下，Predixy的最高QPS要优于Cerberus，时延也比较接近。综合来看，Predixy比Cerberus的性能要高33%~60%，并且数据的key/value越大，Predixy优势越明显，所以最后我们选择了Predixy。</p><p>为了适应业务和K8s环境，在上线前我们对Predixy做了大量的改动，增加了很多新的功能，比如动态切换后端Redis Cluster、黑白名单、异常操作审计等。</p><h2 id="Proxy部署方式"><a href="#Proxy部署方式" class="headerlink" title="Proxy部署方式"></a><strong>Proxy部署方式</strong></h2><p>Proxy作为deployment部署，无状态轻量化，通过LB对外提供服务，很容易做到动态扩缩容。同时，我们为Proxy开发了动态切换后端Redis Cluster的功能，可实现在线添加和切换Redis Cluster。</p><h2 id="-2"><a href="#-2" class="headerlink" title=" "></a> </h2><h2 id="Proxy自动扩缩容方式"><a href="#Proxy自动扩缩容方式" class="headerlink" title="Proxy自动扩缩容方式"></a><strong>Proxy自动扩缩容方式</strong></h2><p>我们使用K8s原生的HPA(Horizontal Pod Autoscaler)来实现Proxy的动态扩缩容。当Proxy所有pod的平均CPU使用率超过一定阈值时，会自动触发扩容，HPA会将Proxy的replica数加1，之后LVS就会探测到新的Proxy pod并将一部分流量切过去。如果扩容后CPU使用率仍然超过规定的阈值，会继续触发扩容逻辑。但是在扩容成功5分钟内，不论CPU使用率降到多低，都不会触发缩容逻辑，这样就避免了频繁的扩缩容给集群稳定性带来的影响。</p><p>HPA可配置集群的最少(MINPODS)和最多(MAXPODS)pod数量，集群负载再低也不会缩容到MINPODS以下数量的pods。建议客户可以根据自己的实际业务情况来决定MINPODS和MAXPODS的值。</p><h2 id="Why-Proxy"><a href="#Why-Proxy" class="headerlink" title="Why Proxy"></a>Why Proxy</h2><h2 id="Redis-pod重启可导致IP变化"><a href="#Redis-pod重启可导致IP变化" class="headerlink" title="Redis pod重启可导致IP变化"></a><strong>Redis pod重启可导致IP变化</strong></h2><p>使用Redis Cluster的Redis客户端，都需要配置集群的部分IP和Port，用于客户端重启时查找Redis Cluster的入口。对于物理机集群部署的Redis节点，即便遇到实例重启或者机器重启，IP和Port都可以保持不变，客户端依然能够找到Redis Cluster的拓扑。但是部署在K8s上的Redis Cluster，pod重启是不保证IP不变的(即便是重启在原来的K8s node上)，这样客户端重启时，就可能会找不到Redis Cluster的入口。</p><p>通过在客户端和Redis Cluster之间加上Proxy，就对客户端屏蔽了Redis Cluster的信息，Proxy可以动态感知Redis Cluster的拓扑变化，客户端只需要将LVS的IP:Port作为入口，请求转发到Proxy上，即可以像使用单机版Redis一样使用Redis Cluster集群，而不需要Redis智能客户端。</p><h2 id="Redis处理连接负载高"><a href="#Redis处理连接负载高" class="headerlink" title="Redis处理连接负载高"></a><strong>Redis处理连接负载高</strong></h2><p>在6.0版本之前，Redis都是单线程处理大部分任务的。当Redis节点的连接较高时，Redis需要消耗大量的CPU资源处理这些连接，导致时延升高。有了Proxy之后，大量连接都在Proxy上，而Proxy跟Redis实例之间只保持很少的连接，这样降低了Redis的负担，避免了因为连接增加而导致的Redis时延升高。</p><h2 id="集群迁移切换需要应用重启"><a href="#集群迁移切换需要应用重启" class="headerlink" title="集群迁移切换需要应用重启"></a><strong>集群迁移切换需要应用重启</strong></h2><p>在使用过程中，随着业务的增长，Redis集群的数据量会持续增加，当每个节点的数据量过高时，BGSAVE的时间会大大延长，降低集群的可用度。同时QPS的增加也会导致每个节点的CPU使用率增高。这都需要增加扩容集群来解决。目前Redis Cluster的横向扩展能力不是很好，原生的slots搬移方案效率很低。新增节点后，有些客户端比如Lettuce，会因为安全机制无法识别新节点。另外迁移时间也完全无法预估，迁移过程中遇到问题也无法回退。</p><p>当前物理机集群的扩容方案是：</p><ol><li><p>按需创建新集群</p></li><li><p>使用同步工具将数据从老集群同步到新集群</p></li><li><p>确认数据无误后，跟业务沟通，重启服务切换到新集群</p></li></ol><p>整个过程繁琐而且风险较大，还需要业务重启服务。</p><p>有了Proxy层，可以将后端的创建、同步和切换集群对客户端屏蔽掉。新老集群同步完成之后，向Proxy发送命令就可以将连接换到新集群，可以实现对客户端完全无感知的集群扩缩容。</p><h2 id="数据安全风险"><a href="#数据安全风险" class="headerlink" title="数据安全风险"></a><strong>数据安全风险</strong></h2><p>Redis是通过AUTH来实现鉴权操作，客户端直连Redis，密码还是需要在客户端保存。而使用Proxy，客户端只需要通过Proxy的密码来访问Proxy，不需要知道Redis的密码。Proxy还限制了FLUSHDB、CONFIG SET等操作，避免了客户误操作清空数据或修改Redis配置，大大提高了系统的安全性。</p><p>同时，Redis并没有提供审计功能。我们在Proxy上增加了高危操作的日志保存功能，可以在不影响整体性能的前提下提供审计能力。</p><h2 id="Proxy-带来的问题"><a href="#Proxy-带来的问题" class="headerlink" title="Proxy 带来的问题"></a>Proxy 带来的问题</h2><h2 id="多一跳带来的时延"><a href="#多一跳带来的时延" class="headerlink" title="多一跳带来的时延"></a><strong>多一跳带来的时延</strong></h2><p>Proxy在客户端和Redis实例之间，客户端访问Redis数据需要先访问Proxy再访问Redis节点，多了一跳，会导致时延增加。经测试，多一跳会增加0.2~0.3ms的时延，不过通常这对业务来说是可以接受的。</p><h2 id="Pod漂移造成IP变化"><a href="#Pod漂移造成IP变化" class="headerlink" title="Pod漂移造成IP变化"></a><strong>Pod漂移造成IP变化</strong></h2><p>Proxy在K8s上是通过deployment部署的，一样会有节点重启导致IP变化的问题。我们K8s的LB方案可以感知到Proxy的IP变化，动态的将LVS的流量切到重启后的Proxy上。</p><h2 id="LVS带来的时延"><a href="#LVS带来的时延" class="headerlink" title="LVS带来的时延"></a><strong>LVS带来的时延</strong></h2><p>LVS也会带来时延，如下表中的测试，不同的数据长度get/set操作，LVS引入的时延小于0.1ms。</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/sz_mmbiz_png/Re4KW51oYRrJAgO3tqmgH2KF0EcfGqqWNBgfVsEkDqxONt4P9Wicn7rg44gSnFS6GgK2bt97NbeWGQmiaFc6PQiaA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><h2 id="K8S-带来的好处"><a href="#K8S-带来的好处" class="headerlink" title="K8S 带来的好处"></a>K8S 带来的好处</h2><h2 id="部署方便"><a href="#部署方便" class="headerlink" title="部署方便"></a><strong>部署方便</strong></h2><p>通过运维平台调用K8s API部署集群，大大提高了运维效率。</p><h2 id="解决端口管理问题"><a href="#解决端口管理问题" class="headerlink" title="解决端口管理问题"></a><strong>解决端口管理问题</strong></h2><p>目前小米在物理机上部署Redis实例是通过端口来区分的，并且下线的端口不能复用，也就是说整个公司每个Redis实例都有唯一的端口号。目前65535个端口已经用到了40000多，按现在的业务发展速度，将在两年内耗尽端口资源。而通过K8s部署，每一个Redis实例对应的K8s pod都有独立的IP，不存在端口耗尽问题和复杂的管理问题。</p><h2 id="降低客户使用门槛"><a href="#降低客户使用门槛" class="headerlink" title="降低客户使用门槛"></a><strong>降低客户使用门槛</strong></h2><p>对应用来说，只需要使用单机版的非智能客户端连接VIP，降低了使用门槛，避免了繁琐复杂的参数设置。同时由于VIP和端口是固定不变的，应用程序不再需要自己管理Redis Cluster的拓扑。</p><h2 id="提高客户端性能"><a href="#提高客户端性能" class="headerlink" title="提高客户端性能"></a><strong>提高客户端性能</strong></h2><p>使用非智能客户端还可以降低客户端的负载，因为智能客户端需要在客户端对key进行hash以确定将请求发送到哪个Redis节点，在QPS比较高的情况下会消耗客户端机器的CPU资源。当然，为了降低客户端应用迁移的难度，我们让Proxy也支持了智能客户端协议。</p><h2 id="动态升级和扩缩容"><a href="#动态升级和扩缩容" class="headerlink" title="动态升级和扩缩容"></a><strong>动态升级和扩缩容</strong></h2><p>Proxy支持动态添加切换Redis Cluster的功能，这样Redis Cluster的集群升级和扩容切换过程可以做到对业务端完全无感知。例如，业务方使用30个节点的Redis Cluster集群，由于业务量的增加，数据量和QPS都增长的很快，需要将集群规模扩容两倍。如果在原有的物理机上扩容，需要以下过程:</p><ol><li><p>协调资源，部署60个节点的新集群</p></li><li><p>手动配置迁移工具，将当前集群的数据迁移到新集群</p></li><li><p>验证数据无误后，通知业务方修改Redis Cluster连接池拓扑，重启服务</p></li></ol><p>虽然Redis Cluster支持在线扩容，但是扩容过程中slots搬移会对线上业务造成影响，同时迁移时间不可控，所以现阶段很少采用这种方式，只有在资源严重不足时才会偶尔使用。</p><p>在新的K8s架构下，迁移过程如下：  </p><ol><li><p>通过API接口一键创建60个节点的新集群</p></li><li><p>同样通过API接口一键创建集群同步工具，将数据迁移到新集群</p></li><li><p>验证数据无误后，向Proxy发送命令添加新集群信息并完成切换</p></li></ol><p>整个过程对业务端完全无感知。</p><p>集群升级也很方便：如果业务方能接受一定的延迟毛刺，可以在低峰时通过StatefulSet滚动升级的方式来实现；如果业务对延迟有要求，可以通过创建新集群迁移数据的方式来实现。</p><h2 id="提高服务稳定性和资源利用率"><a href="#提高服务稳定性和资源利用率" class="headerlink" title="提高服务稳定性和资源利用率"></a><strong>提高服务稳定性和资源利用率</strong></h2><p>通过K8s自带的资源隔离能力，实现和其他不同类型应用混部，在提高资源利用率的同时，也能保证服务稳定性。</p><h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><h2 id="Pod重启导致数据丢失"><a href="#Pod重启导致数据丢失" class="headerlink" title="Pod重启导致数据丢失"></a><strong>Pod重启导致数据丢失</strong></h2><p>K8s的pod碰到问题重启时，由于重启速度过快，会在Redis Cluster集群发现并切主前将pod重启。如果pod上的Redis是slave，不会造成什么影响。但如果Redis是master，并且没有AOF，重启后原先内存的数据都被清空，Redis会reload之前存储的RDB文件，但是RDB文件并不是实时的数据。之后slave也会跟着把自己的数据同步成之前的RDB文件中的数据镜像，会造成部分数据丢失。</p><p>StatefulSet是有状态服务，部署的pod名是固定格式(StatefulSet名+编号)。我们在初始化Redis Cluster时，将相邻编号的pod设置为主从关系。在重启pod时，通过pod名确定它的slave，在重启pod前向从节点发送cluster failover命令，强制将活着的从节点切主。这样在重启后，该节点会自动以从节点方式加入集群。</p><p>LVS映射时延</p><p>Proxy的pod是通过LVS实现负载均衡的，LVS对后端IP:Port的映射生效有一定的时延，Proxy节点突然下线会导致部分连接丢失。为减少Proxy运维对业务造成影响，我们在Proxy的deployment模板中增加了如下选项：</p><pre><code>lifecycle:  preStop:    exec:      command:      - sleep      - &quot;171&quot;</code></pre><p>对于正常的Proxy pod下线，例如集群缩容、滚动更新Proxy版本以及其它K8s可控的pod下线，在pod下线前会发消息给LVS并等待171秒，这段时间足够LVS将这个pod的流量逐渐切到其他pod上，对业务无感知。</p><h2 id="K8s-StatefulSet无法满足Redis-Cluster部署要求"><a href="#K8s-StatefulSet无法满足Redis-Cluster部署要求" class="headerlink" title="K8s StatefulSet无法满足Redis Cluster部署要求"></a><strong>K8s StatefulSet无法满足Redis Cluster部署要求</strong></h2><p>K8s原生的StatefulSet不能完全满足Redis Cluster部署的要求：</p><ol><li><p>Redis Cluster不允许同为主备关系的节点部署在同一台机器上。这个很好理解，如果该机器宕机，会导致这个数据分片不可用。</p></li><li><p>Redis Cluster不允许集群超过一半的主节点失效，因为如果超过一半主节点失效，就无法有足够的节点投票来满足gossip协议的要求。因为Redis Cluster的主备是可能随时切换的，我们无法避免同一个机器上的所有节点都是主节点这种情况，所以在部署时不能允许集群中超过1/4的节点部署在同一台机器上。</p></li></ol><p>为了满足上面的要求，原生StatefulSet可以通过 anti-affinity 功能来保证相同集群在同一台机器上只部署一个节点，但是这样机器利用率很低。</p><p>因此我们开发了基于StatefulSet的CRD：RedisStatefulSet，会采用多种策略部署Redis节点。同时，还在RedisStatefulSet中加入了一些Redis管理功能。这些我们将会在其他文章中来继续详细探讨。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>目前集团内部已经有多个业务的数十个Redis集群部署到了K8s上并运行了半年多。得益于K8s的快速部署和故障迁移能力，这些集群的运维工作量比物理机上的Redis集群低很多，稳定性也得到了充分的验证。</p><p>在运维过程中我们也遇到了不少问题，文章中提到的很多功能都是根据实际需求提炼出来的。目前还是有很多问题需要在后续逐步解决，以进一步提高资源利用率和服务质量。</p><h2 id="混布-Vs-独立部署"><a href="#混布-Vs-独立部署" class="headerlink" title="混布 Vs. 独立部署"></a><strong>混布 Vs. 独立部署</strong></h2><p>物理机的Redis实例是独立部署的，单台物理机上部署的都是Redis实例，这样有利于管理，但是资源利用率并不高。Redis实例使用了CPU、内存和网络IO，但存储空间基本都是浪费的。在K8s上部署Redis实例，其所在的机器上可能也会部署其他任意类型的服务，这样虽然可以提高机器的利用率，但是对于Redis这样的可用性和时延要求都很高的服务来说，如果因为机器内存不足而被驱逐，是不能接受的。这就需要运维人员监控所有部署了Redis实例的机器内存，一旦内存不足，就切主和迁移节点，但这样又增加运维的工作量。</p><p>同时，如果混部的其他服务是网络吞吐很高的应用，也可能对Redis服务造成影响。虽然K8s的 anti-affinity 功能可以将Redis实例有选择地部署到没有这类应用的机器上，但是在机器资源紧张时，还是无法避免这种情况。</p><h2 id="Redis-Cluster管理"><a href="#Redis-Cluster管理" class="headerlink" title="Redis Cluster管理"></a><strong>Redis Cluster管理</strong></h2><p>Redis Cluster是一个P2P无中心节点的集群架构，依靠gossip协议传播协同自动化修复集群的状态，节点上下线和网络问题都可能导致Redis Cluster的部分节点状态出现问题，例如会在集群拓扑中出现failed或者handshake状态的节点，甚至脑裂。对这种异常状态，我们可以在Redis CRD上增加更多的功能来逐步解决，进一步提高运维效率。</p><h2 id="审计与安全"><a href="#审计与安全" class="headerlink" title="审计与安全"></a><strong>审计与安全</strong></h2><p>Redis本身只提供了Auth密码认证保护功能，没有权限管理，安全性较差。通过Proxy，我们可以通过密码区分客户端类型，管理员和普通用户使用不同的密码登录，可执行的操作权限也不同，这样就可以实现权限管理和操作审计等功能。</p><h2 id="支持多Redis-Cluster"><a href="#支持多Redis-Cluster" class="headerlink" title="支持多Redis Cluster"></a><strong>支持多Redis Cluster</strong></h2><p>单个Redis Cluster由于gossip协议的限制，横向扩展能力有限，集群规模在300个节点时，节点选主这类拓扑变更的效率就明显降低。同时，由于单个Redis实例的容量不宜过高，单个Redis Cluster也很难支持TB以上的数据规模。通过Proxy，我们可以对key做逻辑分片，这样单个Proxy就可以接入多个Redis Cluster，从客户端的视角来看，就相当于接入了一个能够支持更大数据规模的Redis集群。</p><p>最后，像Redis这种有状态服务的容器化部署在国内大厂都还没有非常成熟的经验，小米云平台也是在摸索中逐步完善。目前我们新增集群已经大部分部署在K8s上，更计划在一到两年内将集团内大部分的物理机Redis集群都迁移到K8s上。这样就可以有效地降低运维人员的负担，在不显著增加运维人员的同时维护更多的Redis集群。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;小米Redis的K8s容器化部署实践&lt;/p&gt;
&lt;p&gt;原创 崔凯峰 小米云技术 &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/WrUU3C-C8TBgJfGuOv3qGQ&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;
      
    
    </summary>
    
      <category term="redis" scheme="http://zhangyu8.me/categories/redis/"/>
    
    
      <category term="redis" scheme="http://zhangyu8.me/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>k8s桌面客户端Lens</title>
    <link href="http://zhangyu8.me/2020/06/18/K8s%E6%A1%8C%E9%9D%A2%E5%AE%A2%E6%88%B7%E7%AB%AFLens/"/>
    <id>http://zhangyu8.me/2020/06/18/K8s桌面客户端Lens/</id>
    <published>2020-06-18T03:00:00.000Z</published>
    <updated>2020-06-18T14:00:33.541Z</updated>
    
    <content type="html"><![CDATA[<p>Kubernetes 的桌面客户端有那么几个，  Kubernetic  (<a href="https://kubernetic.com/)应该是最好用的，但是收费。" target="_blank" rel="noopener">https://kubernetic.com/)应该是最好用的，但是收费。</a></p><p>最近有个叫 Lens 的 APP 改变了这个格局，功能比 Kubernetic 多，使用体验更好，适合广大系统重启工程师装逼。<br><a href="https://github.com/lensapp/lens" target="_blank" rel="noopener">https://github.com/lensapp/lens</a></p><p><a href="https://k8slens.dev/" target="_blank" rel="noopener">https://k8slens.dev/</a></p><p>Lens 就是一个强大的 IDE，可以实时查看集群状态，实时查看日志流，方便排查故障。<br>日志流界面可以选择显示或隐藏时间戳，也可以指定显示的行数</p><p>Lens 可以管理多集群，它使用内置的 kubectl 通过 kubeconfig  来访问集群，支持本地集群和外部集群（如EKS、AKS、GKE、Pharos、UCP、Rancher 等）</p><p>Lens 内置了资源利用率的仪表板，支持多种对接 Prometheus 的方式：</p><p>Lens 内置了 kubectl，它的内置终端会确保集群的 API Server 版本与 kubectl 版本兼容，所以你不需要在本地安装 kubectl。 </p><p>Lens 内置了 helm 模板商店，可直接点击安装：</p><p>下载安装<br><a href="https://github.com/lensapp/lens/releases/download/v3.5.0/Lens-Setup-3.5.0.exe" target="_blank" rel="noopener">https://github.com/lensapp/lens/releases/download/v3.5.0/Lens-Setup-3.5.0.exe</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Kubernetes 的桌面客户端有那么几个，  Kubernetic  (&lt;a href=&quot;https://kubernetic.com/)应该是最好用的，但是收费。&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://kubernetic.c
      
    
    </summary>
    
      <category term="kubernetes" scheme="http://zhangyu8.me/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="http://zhangyu8.me/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>java线程池里面到底该设置多少个线程</title>
    <link href="http://zhangyu8.me/2020/06/16/Java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E9%87%8C%E9%9D%A2%E5%88%B0%E5%BA%95%E8%AF%A5%E8%AE%BE%E7%BD%AE%E5%A4%9A%E5%B0%91%E4%B8%AA%E7%BA%BF%E7%A8%8B/"/>
    <id>http://zhangyu8.me/2020/06/16/Java线程池里面到底该设置多少个线程/</id>
    <published>2020-06-16T03:00:00.000Z</published>
    <updated>2020-06-18T14:07:24.226Z</updated>
    
    <content type="html"><![CDATA[<p>根据CPU核心数确定线程池并发线程数</p><p><a href="https://www.cnblogs.com/dennyzhangdd/p/6909771.html" target="_blank" rel="noopener">https://www.cnblogs.com/dennyzhangdd/p/6909771.html</a></p><blockquote><h2 id="一、抛出问题"><a href="#一、抛出问题" class="headerlink" title="一、抛出问题"></a>一、抛出问题</h2><p>关于如何计算并发线程数，一般分两派，来自两本书，且都是好书，到底哪个是对的？问题追踪后，整理如下：</p><p>第一派：《Java Concurrency in Practice》即《java并发编程实践》，如下图：</p><p><img src="https://images2015.cnblogs.com/blog/584866/201705/584866-20170526162253247-2075463115.png" alt></p><p>如上图，在《Java Concurrency in Practice》一书中，给出了估算线程池大小的公式：</p><p>Nthreads=Ncpu*Ucpu*(1+w/c)，其中</p><p>Ncpu=CPU核心数</p><p>Ucpu=cpu使用率，0~1</p><p>W/C=等待时间与计算时间的比率</p><p>第二派：《Programming Concurrency on the JVM Mastering》即《Java 虚拟机并发编程》</p><p><img src="https://images2015.cnblogs.com/blog/584866/201705/584866-20170526170508450-925520860.png" alt></p><p>线程数=Ncpu/（1-阻塞系数）</p></blockquote><blockquote><h2 id="二、分析"><a href="#二、分析" class="headerlink" title="二、分析"></a>二、分析</h2><p>对于派系一，假设cpu100%运转，即撇开CPU使用率这个因素，线程数\=Ncpu*(1+w/c)。</p><p>现在假设将派系二的公式等于派系一公式，即Ncpu/（1-阻塞系数）=Ncpu*(1+w/c),===》阻塞系数=w/(w+c)，即阻塞系数=阻塞时间/（阻塞时间+计算时间），这个结论在派系二后续中得到应征，如下图：</p><p><img src="https://images2015.cnblogs.com/blog/584866/201705/584866-20170526171225919-888895376.png" alt></p><p>由此可见，派系一和派系二其实是一个公式……这样我就放心了……</p></blockquote><blockquote><h2 id="三、实际应用"><a href="#三、实际应用" class="headerlink" title="三、实际应用"></a>三、实际应用</h2><p>那么实际使用中并发线程数如何设置呢？分析如下（我们以派系一公式为例）：</p><p>Nthreads=Ncpu*(1+w/c)</p><p>IO密集型：一般情况下，如果存在IO，那么肯定w/c&gt;1（阻塞耗时一般都是计算耗时的很多倍）,但是需要考虑系统内存有限（每开启一个线程都需要内存空间），这里需要上服务器测试具体多少个线程数适合（CPU占比、线程数、总耗时、内存消耗）。如果不想去测试，保守点取1即，Nthreads=Ncpu*(1+1)=2Ncpu。这样设置一般都OK。</p><p>计算密集型：假设没有等待w=0，则W/C=0. Nthreads=Ncpu。</p><p><strong>至此结论就是：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; </span><br><span class="line">&gt; ```计算密集型\=Ncpu（常出现于线程中：复杂算法）</span><br></pre></td></tr></table></figure></blockquote><blockquote><p><strong>java中：Ncpu=<code>Runtime.getRuntime().availableProcessors()</code></strong></p><p>=========================此处可略过=============================================</p><p>当然派系一种《Java Concurrency in Practice》还有一种说法，</p><p><img src="https://images2015.cnblogs.com/blog/584866/201705/584866-20170526173437372-976370152.png" alt></p><p>即对于计算密集型的任务，在拥有N个处理器的系统上，当线程池的大小为N+1时，通常能实现最优的效率。(即使当计算密集型的线程偶尔由于缺失故障或者其他原因而暂停时，这个额外的线程也能确保CPU的时钟周期不会被浪费。)</p><p><code>即，计算密集型\=Ncpu+1，但是这种做法导致的多一个cpu上下文切换是否值得</code>，这里不考虑。读者可自己考量。  </p><p>======================================================================</p></blockquote><blockquote><h2 id="四、总结："><a href="#四、总结：" class="headerlink" title="四、总结："></a><strong>四、总结</strong>：</h2><p>选择线程池并发线程数的因素很多：任务类型、内存等线程中使用到所有资源都需要考虑</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;根据CPU核心数确定线程池并发线程数&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/dennyzhangdd/p/6909771.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.cnblog
      
    
    </summary>
    
      <category term="java" scheme="http://zhangyu8.me/categories/java/"/>
    
    
      <category term="java" scheme="http://zhangyu8.me/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>做容灾，双活、多活、同城、异地、多云，到底应该怎么选</title>
    <link href="http://zhangyu8.me/2020/05/06/%E5%81%9A%E5%AE%B9%E7%81%BE%EF%BC%8C%E5%8F%8C%E6%B4%BB%E3%80%81%E5%A4%9A%E6%B4%BB%E3%80%81%E5%90%8C%E5%9F%8E%E3%80%81%E5%BC%82%E5%9C%B0%E3%80%81%E5%A4%9A%E4%BA%91%EF%BC%8C%E5%88%B0%E5%BA%95%E5%BA%94%E8%AF%A5%E6%80%8E%E4%B9%88%E9%80%89/"/>
    <id>http://zhangyu8.me/2020/05/06/做容灾，双活、多活、同城、异地、多云，到底应该怎么选/</id>
    <published>2020-05-06T06:00:00.000Z</published>
    <updated>2020-05-06T06:05:38.644Z</updated>
    
    <content type="html"><![CDATA[<p> 做容灾，双活、多活、同城、异地、多云，到底应该怎么选？<br><a href="https://mp.weixin.qq.com/s/_NGqq-xvDtFrvKwbdGIhwQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/_NGqq-xvDtFrvKwbdGIhwQ</a> </p><p> 原创 Cheng哥 成哥的世界 2019-03-11 </p><blockquote><p>去年写过一篇 &lt;&lt;做容灾，冷备是不是个好方案？&gt;&gt;，当时提出来，冷备或者主备，其实并不是一个理想的方案，而且绝大多数情况下，只能是一个心理安慰，真正发生故障的情况下，这样的容灾模式根本起不到作用。  </p><p>原因我就不重复了，大家如果有兴趣可以直接看那篇文章。</p><p>最近，公有云又出了些大故障，各大群和朋友圈又开始沸沸扬扬，但是整体看下来，声音无非两种：</p><ul><li><p>单站点不靠谱，要有容灾，出现这种情况就得马上切，所以回去赶紧建设容灾站点；</p></li><li><p>鸡蛋不能放在一个篮子里，单云不靠谱，要多云。所以，多云就要选我们家的xx云，或者我们提供xx多云服务。</p></li></ul><p>我在我的一个讨论群里就提出来，第一种声音是有意识的建设，有这个意识很好，但是把这个事情想得太简单了。第二种声音，基本就是不动脑子的瞎BB，原因我下面讲。</p><p>转回正题来，既然上篇提到主备模式不靠谱，那到底怎么选？而且整天见各类技术文章，不是双活，就是多活，不是同城，就是异地，现在又出来个多云，好复杂。</p><p>下面我就谈谈我的理解：</p><p>首先，这么多名词是什么含义，要搞清楚，然后再看适不适合。</p><p>先讲相对简单的双活（简不简单，看后面就明白了），其实就是两个站点，同时承载业务流量，可以根据用户ID、地域或者其他业务属性也决定怎么分担流量，当一个站点故障时，可以快速（分钟级）切换到另一个站点，理想情况下，对业务基本是无损或者非常小的。</p><p>这里就跟前面讲的主备不同了，主备的另一个站点完全是不承载任何流量的。</p><p>这里再往深里看一眼，同时承载流量，也要看承载到那一层，也就是流量在统一站点内闭环，所有调用都是本机房内完成，还是只有应用层这样的无状态组件双活，但是数据访问、异步消息这些有状态的部件还是回到主站点调用，这两种模式又是不一样的。</p><p>其实第二种，就比前面讲的主备模式要好一些，因为这样至少可以保证应用层随时可用，不过真出故障的时候，还是少不了数据层的切换，这个其实是非常耗时的。跟主备模式一样，基本无法演练，因为代价太高，数据会有损。（如果数据层没有这么复杂，只有几个数据库，那是没问题问题的，但是分布式的场景下，上百个，几百个实例切换，这个代价和成本还是很大的。）</p><p>所以，再往下推导，如果想要做到有效果的双活，就必须保证每个站点，都是独立运行，所有的调用都是本机房调用且闭环，底层做好数据同步即可。</p><p>只有做到这个程度，当一个站点发生故障不可用时，就可以从接入层把故障站点的流量切换到另一个站点，双活的效果也就有了。</p><p>不过，做到这个程度，就不是说我们想要做就能做到的，如果您做个类似的架构设计，你会知道这里有三个关键的技术点：</p><p><strong>第一个，本机房调用</strong></p><p>也就是一个分布式请求不能跨机房调来调去，这个是不行的，必须要保证本机房调用闭环。所以从分布式服务的路由策略上，以及服务化框架上，必须得支持这也中调用模式，同理，数据访问层，以及消息组件也要支持这种特性。</p><p><strong>第二个，数据分片和一致性</strong></p><p>为什么要做这个事情？我们知道一个系统中数据准确性、完整性和一致性是非常关键的，放到双活这个场景下，最关键的就是数据一致性，我们不能允许有同一个记录两边同时在变更，还要双向同步，比如用户交易和支付类的数据，同时变更的情况下，我们无法确认哪边是准确的。</p><p>前面提到，两个站点是同时承载不同的流量的，这就要根据一些业务属性来分配，比如用户ID、所属地域等等策略，这里为的就是能够在数据层面也要做好隔离，一个站点内只提供固定部分的用户访问。</p><p>这样就保证了单站点内同一分片的数据，不会在另外一个站点被变更，后续的同步也可以做到单向。</p><p>所以，这里的关键，就是数据要做分片，就要用到分布式的数据中间件，要做数据访问的路由设计，数据要同机房读写，还要做数据拆分这样的工作，技术门槛和工作量也不低。</p><p><strong>这两点如果能够做到，其实就是我们经常说的“单元化”架构达成了，理论上，我们可以选择任何一个机房和地域，把系统搭建起来，就可以提供业务访问了。</strong></p><p>但现实是更为复杂的，因为用户业务系统产生的数据，有可能会被其它系统用到，比如商品库存这样的系统，这就要涉及异步消息和数据的同步问题，而<strong>数据同步不仅仅是一个技术问题，而是个物理问题</strong>，我们接下来讲。</p><p><strong>第三个，数据同步。</strong></p><p>其实单从同步角度而言，目前很多的同步工具和开源产品已经比较完善，所以这里最大的问题，其实不在技术层面，而是在物理层面。</p><p>准确点，就是物理距离上的时延问题，这个无论是双活、多活，还是同城、异地，都绕不开的痛苦问题。</p><p>既然要双活，必然会选择另一个跟当前机房有一定距离的机房（同城或异地），而且距离必须得拉开才有意义，如果都在一个园区里面，就没有任何容灾意义了。</p><p>距离一旦拉开，物理距离就出来了，即使是专线相连，中间也要经过很多网络设备，如果是云化的网络架构下，经过的软硬设备就更多，还有可能涉及协议转换，如果中途跨运营商，就更难保障，这样一来时延肯定是几倍、十几倍，甚至是上百倍的上涨，直接从0.x毫秒，上涨到秒级别。</p><p>对于同城来说，这个问题还好，但是一旦跨省就完全不可控，特别是机房如果不是自己的，根本无法控制。所以，想大公司自建机房，一定会在这个层面做大量的优化，尽最大可能降低时延。</p><p>就以淘宝、天猫为例，按照之前了解的情况，基本也是杭州和上海这两个城市为主做双活，再远时延这个问题就绕不开了。</p><p>数据同步及时性为什么这么重要，一个是业务体验，不能说库存都没了，其他用户看到的还是有货，这个是不会被接受的。</p><p>再就是故障时，如果同步不及时，极有可能造成几秒钟内的交易数据丢失，或者不一致，像淘宝这样每秒4位数订单量的系统，丢几秒钟数据，造成的损失也是巨大的。所以，这里就必须要建设有一整套的数据完整性和一致性保障措施，尽最大程度降低业务损失。  </p><p>所以，数<strong>据同步所依赖的时延问题，其实就已经超出了绝大部分公司所能掌控的范畴，也不是单纯靠自身技术能解决的问题，要看天时和地利。</strong></p><p>讲到这里，我想多活就不用讲了，时延这个问题解决不了，多活就是扯淡，至于同城和异地，我想看明白的读者，也知道怎么选择了，其实一样，还是取决于时延。</p><p><strong>我们可以得出的几个结论：</strong></p><ul><li><p>不管怎么选择容灾方案，我们自己的业务系统，从<strong>自身架构上，一定要支持单元化，一定要支持数据同步才行</strong>，如果这都不支持，讲双活和多活，就是特么的扯淡。所以，打算搞双活，先从这里下手，当然牵出来就要涉及到分布式，还有很多大量细节技术问题。</p></li><li><p><strong>一个合理的建设节奏应该是，同城双活—异地双活—两地三中心（同城双活+异地多活）</strong>，因为你要解决的问题的复杂度和难度也是在逐步上升的，不可能一蹴而就。</p></li><li><p><strong>题目里这些个名词，不是孤立的</strong>，而是从不同维度看到的结论，但是如果你偏离自己的业务场景去看，孤立的去看，就一定会被带到沟里去，而且不知道该如何下手，所以，一定别偏离你的业务场景，然后把它们联系起来。</p></li><li><p><strong>一切都是ROI</strong>，为了保证高可用，就一定会有成本，高可用程度越高，成本就一定越高，所以成本投入得到的收益到底划不划算，这个只能自家公司自家评判。</p></li><li><p>现实情况，比我写的要复杂的多的多，推荐大家看两个成功案例，<strong>一个是毕玄的异地多活数据中心，一个是饿了么异地多活</strong>，几个关键字google一下就有了，里面涉及到的场景化的细节对大家理解这件事情的复杂度会有更帮助。</p></li></ul><p>写的有点多了，关于多云先不写了，就当问题吧，大家觉得是不是需要多云建设？你怎么看？</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; 做容灾，双活、多活、同城、异地、多云，到底应该怎么选？&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/_NGqq-xvDtFrvKwbdGIhwQ&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.wei
      
    
    </summary>
    
      <category term="容灾" scheme="http://zhangyu8.me/categories/%E5%AE%B9%E7%81%BE/"/>
    
    
      <category term="容灾" scheme="http://zhangyu8.me/tags/%E5%AE%B9%E7%81%BE/"/>
    
  </entry>
  
  <entry>
    <title>做容灾，冷备是不是个好方案</title>
    <link href="http://zhangyu8.me/2020/05/06/%E5%81%9A%E5%AE%B9%E7%81%BE%EF%BC%8C%E5%86%B7%E5%A4%87%E6%98%AF%E4%B8%8D%E6%98%AF%E4%B8%AA%E5%A5%BD%E6%96%B9%E6%A1%88/"/>
    <id>http://zhangyu8.me/2020/05/06/做容灾，冷备是不是个好方案/</id>
    <published>2020-05-06T06:00:00.000Z</published>
    <updated>2020-05-06T06:05:22.279Z</updated>
    
    <content type="html"><![CDATA[<p> 做容灾，冷备是不是个好方案？ </p><p> 原创 Cheng哥 成哥的世界 2018-09-30 </p><blockquote><p>主备、冷备、热备、双活、多活、同城、异地、多云，等等等等，这些保证业务高可用和容灾名词，我们经常会听到，不绝于耳。  </p><p>但是，真的当我们自己要去建设，选择方案时，就发现不知道该怎么选择和搭配了。</p><p>结合近期我们的一些讨论，准备用几篇文章简单分享下我们的理解，今天先聊冷备。</p><p><strong>冷备是不是个好方案？</strong></p><p>这里的<strong>冷备我们可以理解为，是主站系统核心链路的镜像站点</strong>，应用、各类分布式服务以及底层基础设施都是独立，且启动的。</p><p><strong>它跟主站唯一的差别就是，正常情况下，不承载任何线上流量。</strong></p><p>理论上，只要有状态的数据（也就是各类分布式服务，如数据库、缓存、消息等组件）同步好，接入层流量能够灵活调度，当出现问题的时候，切入口流量，就可以顺畅的切过去。</p><p>看上去很美好，但是<strong>实际操作起来，基本不可行</strong>。</p><p>这里有<strong>一个关键点，就是业务应用</strong>，应用的代码和配置是<strong>随时在变化的。</strong></p><p>原则上，我们可以通过持续交付和运维自动化等等手段，确保每次变更都能够同步到备站点，并通过流程约束不允许有外部操作。</p><p>所以，手段上，我们可以做到非常完备，流程上，我们可以设计的非常严密。</p><p>但是，我们始终绕不开的一个命题，<strong>只要不承载真实的线上业务流量，我们就无法证明这个系统是可用的。</strong></p><p>何况，有可能是好几个月我们都不会发生真实的切换动作，所以，一个几个月没有经过线上流量检验的系统，在真正需要切换时，不会有任何人敢决策直接切换的。</p><p>当然，以上是我们的直接推断，确实行不通。但是我们仍然要经过一些详细的论证，从其它角度看是否有解。</p><p><strong>从另外一个角度的论证过程</strong></p><p>当时我们讨论在冷备的前提下，应该怎么保证系统的可用性，没想到，论证的过程，<strong>反而进一步证实了冷备只是一个美好的愿望</strong>。</p><p><strong>1、通过模拟压测的方式。</strong></p><p>但是我们知道，压测的模型是根据线上业务模型来定制的，但是业务场景和逻辑每天都在发生变化，压测模型的同步有时是跟不上业务模型变化的。</p><p>况且这个日常工作量要靠人，无法做到自动生成，所以基本不可持续。</p><p>再就是，<strong>压测的结果检验是通过技术指标衡量**</strong>，而非业务指标，**也就是是否200ok，或者出现5xx之类的错误。</p><p>业务逻辑上是否正确，并没有办法确保。这种情况就极易造成数据污染。数据故障的影响范围远远超过服务不可用的影响。</p><p>所以，<strong>压测可以最大程度评估系统容量，但是无法保证系统业务正确性。</strong></p><p><strong>2、切换后，接入线上流量前，QA介入验证。</strong></p><p>理由同上，工作量大，也无法覆盖到所有场景，时间不可控，完全起不到冷备节点的快速承载业务效果。</p><p><strong>3、定期模拟演练，确保系统周期范围内可用</strong></p><p>但是这里就有一个前提，冷备站点的建设目标，并不是全量建设，而是在极端状况下，确保核心业务临时可用，当主站点恢复后，仍然要切回去。</p><p>这里暗含的一个意思就是，一旦需要做这个动作，业务必然有损，而且涉及范围非常大，这就意味着，每一次演练都要付出极大的业务代价。</p><p>从这个角度，产品运营及决策者们是不会允许你经常干这种事情的。</p><p>到这里，你会发现，连日常演练的条件都不具备了。</p><p><strong>4、一个绕不开的限制条件</strong></p><p>数据同步必然是单向的，为了保证数据一致，通常要确保备用站点是禁写的，以防止各类误操作引起的数据污染。</p><p>所以，即使上面几个方案可行，基础条件上又不满足，因为根本无法写入数据，关键的业务逻辑根本不具备验证条件。</p><p><strong>最后，结论</strong></p><p><strong>冷备只能是冷备</strong>，关键时刻并不能起到快速承载业务的效果，<strong>在业务容灾建设时，这个思路其实是不可行的。</strong></p><p>但是对于部分组件，比如数据库、大数据、文件，这些存储类的部件，做冷备是有重大意义的。</p><p>也就是，后面我们在提到冷备时，应该叫做数据冷备、文件冷备、源代码冷备才有意义，或许会更准确些。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; 做容灾，冷备是不是个好方案？ &lt;/p&gt;
&lt;p&gt; 原创 Cheng哥 成哥的世界 2018-09-30 &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;主备、冷备、热备、双活、多活、同城、异地、多云，等等等等，这些保证业务高可用和容灾名词，我们经常会听到，不绝于耳。  &lt;/p&gt;

      
    
    </summary>
    
      <category term="容灾" scheme="http://zhangyu8.me/categories/%E5%AE%B9%E7%81%BE/"/>
    
    
      <category term="容灾" scheme="http://zhangyu8.me/tags/%E5%AE%B9%E7%81%BE/"/>
    
  </entry>
  
  <entry>
    <title>MySQL如何优化cpu消耗</title>
    <link href="http://zhangyu8.me/2020/04/20/MySQL%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96cpu%E6%B6%88%E8%80%97/"/>
    <id>http://zhangyu8.me/2020/04/20/MySQL如何优化cpu消耗/</id>
    <published>2020-04-20T03:00:00.000Z</published>
    <updated>2020-04-20T03:14:15.521Z</updated>
    
    <content type="html"><![CDATA[<blockquote><h2 id="谁在消耗cpu"><a href="#谁在消耗cpu" class="headerlink" title="谁在消耗cpu?"></a>谁在消耗cpu?</h2><p><em><strong>用户+系统+IO等待+软硬中断+空闲</strong></em><br><img src="https://img2018.cnblogs.com/blog/1179590/201905/1179590-20190527220055993-65442699.png" alt></p><p><img src="https://img2018.cnblogs.com/blog/1179590/201905/1179590-20190527220154673-599033146.png" alt></p><h2 id="祸首是谁？"><a href="#祸首是谁？" class="headerlink" title="祸首是谁？"></a>祸首是谁？</h2><h3 id="用户"><a href="#用户" class="headerlink" title="用户"></a>用户</h3><p><em><strong>用户空间CPU消耗，各种逻辑运算</strong></em></p><blockquote><p>正在进行大量tps<br>函数/排序/类型转化/逻辑IO访问…</p></blockquote><p><em><strong>用户空间消耗大量cpu，产生的系统调用是什么？那些函数使用了cpu周期？</strong></em><br>参考<a href="https://www.cnblogs.com/YangJiaXin/p/10928160.html" target="_blank" rel="noopener"><br>Linux 性能优化解析</a><br><a href="https://www.cnblogs.com/YangJiaXin/p/10853560.html" target="_blank" rel="noopener">MySQL 几种调式分析利器</a></p><h3 id="IO等待"><a href="#IO等待" class="headerlink" title="IO等待"></a>IO等待</h3><p><em><strong>等待IO请求的完成</strong></em></p><blockquote><p>此时CPU实际上空闲</p></blockquote><p><em><strong>如vmstat中的wa 很高。但IO等待增加，wa也不一定会上升（请求I/O后等待响应，但进程从核上移开了）</strong></em><br><img src="https://img2018.cnblogs.com/blog/1179590/201905/1179590-20190527220232193-1150896123.png" alt></p><p><img src="https://img2018.cnblogs.com/blog/1179590/201905/1179590-20190527220252309-1933130433.png" alt></p><h3 id="产生影响"><a href="#产生影响" class="headerlink" title="产生影响"></a>产生影响</h3><blockquote><p>用户和IO等待消耗了大部分cpu</p></blockquote><p><em><strong>吞吐量下降（tps）</strong></em><br><em><strong>查询响应时间增加</strong></em><br><em><strong>慢查询数增加</strong></em><br><em><strong>对mysql的并发陡增，也会产生上述影响</strong></em></p><p><img src="https://img2018.cnblogs.com/blog/1179590/201905/1179590-20190527220350730-466848858.png" alt></p><h2 id="如何减少CPU消耗？"><a href="#如何减少CPU消耗？" class="headerlink" title="如何减少CPU消耗？"></a>如何减少CPU消耗？</h2><h3 id="减少等待"><a href="#减少等待" class="headerlink" title="减少等待"></a>减少等待</h3><p><em><strong>减少IO量</strong></em></p><blockquote><p>SQL/index，使用合适的索引减少扫描的行数（需平衡索引的正收益和维护开销，空间换时间）</p></blockquote><p><em><strong>提升IO处理能力</strong></em></p><blockquote><p>加cache/加磁盘/SSD</p></blockquote><p><img src="https://img2018.cnblogs.com/blog/1179590/201905/1179590-20190527220402693-1264789500.png" alt></p><h3 id="减少计算"><a href="#减少计算" class="headerlink" title="减少计算"></a>减少计算</h3><h4 id="减少逻辑运算量"><a href="#减少逻辑运算量" class="headerlink" title="减少逻辑运算量"></a>减少逻辑运算量</h4><blockquote><ul><li><em><strong>避免使用函数</strong></em>，将运算转移至易扩展的应用服务器中<br>如substr等字符运算，dateadd/datesub等日期运算，abs等数学函数</li><li><em><strong>减少排序</strong></em>，利用索引取得有序数据或避免不必要排序<br>如union all代替 union，order by 索引字段等</li><li><em><strong>禁止类型转换</strong></em>，使用合适类型并保证传入参数类型与数据库字段类型绝对一致<br>如数字用tiny/int/bigint等，必需转换的在传入数据库之前在应用中转好</li><li><em><strong>简单类型</strong></em>，尽量避免复杂类型，降低由于复杂类型带来的附加运算。更小的数据类型占用更少的磁盘、内存、cpu缓存和cpu周期</li><li>….</li></ul></blockquote><h4 id="减少逻辑IO量"><a href="#减少逻辑IO量" class="headerlink" title="减少逻辑IO量"></a>减少逻辑IO量</h4><blockquote><ul><li><p><em><strong>index</strong></em>，优化索引，减少不必要的表扫描<br>如增加索引，调整组合索引字段顺序，去除选择性很差的索引字段等等</p></li><li><p><em><strong>table</strong></em>，合理拆分，适度冗余<br>如将很少使用的大字段拆分到独立表，非常频繁的小字段冗余到“引用表”</p></li><li><p><em><strong>SQL</strong></em>，调整SQL写法，充分利用现有索引，避免不必要的扫描，排序及其他操作<br>如减少复杂join，减少order by，尽量union all，避免子查询等</p></li><li><p><em><strong>数据类型</strong></em>，够用就好，减少不必要使用大字段<br>如tinyint够用就别总是int，int够用也别老bigint，date够用也别总是timestamp</p></li><li><p><em><strong>….</strong></em></p></li></ul></blockquote><p><img src="https://img2018.cnblogs.com/blog/1179590/201905/1179590-20190527220428944-1005198827.png" alt></p><h4 id="减少query请求量（非数据库本身）"><a href="#减少query请求量（非数据库本身）" class="headerlink" title="减少query请求量（非数据库本身）"></a>减少query请求量（非数据库本身）</h4><blockquote><ul><li><em><strong>适当缓存</strong></em>，降低缓存数据粒度，对静态并被频繁请求的数据进行适当的缓存<br>如用户信息，商品信息等</li><li><em><strong>优化实现</strong></em>，尽量去除不必要的重复请求<br>如禁止同一页面多次重复请求相同数据的问题，通过跨页面参数传递减少访问等</li><li><em><strong>合理需求</strong></em>，评估需求产出比，对产出比极端底下的需求合理去除</li><li><em><strong>….</strong></em></li></ul></blockquote><p><img src="https://img2018.cnblogs.com/blog/1179590/201905/1179590-20190527220447492-64921986.png" alt></p><h3 id="升级cpu"><a href="#升级cpu" class="headerlink" title="升级cpu"></a>升级cpu</h3><ul><li><em><strong>若经过减少计算和减少等待后还不能满足需求，cpu利用率还高</strong></em></li><li>___是时候拿出最后的杀手锏了，<em>升级cpu</em>，是选择更快的cpu还是更多的cpu了？_**</li></ul><blockquote><ul><li><em>低延迟（快速响应）</em>，需要更快的cpu（每个查询只能使用一个cpu）</li><li><em>高吞吐</em>，同时运行很多查询语句，能从多个cpu处理查询中收益</li></ul></blockquote><p><em><strong>参考</strong></em><br><em><strong>《高性能MySQL》</strong></em><br><em><strong>《图解性能优化》</strong></em><br><em><strong>大部分整理自《MySQL Tuning For CPU Bottleneck》</strong></em></p><p>作者：jiaxin</p><p>出处：<a href="http://www.cnblogs.com/YangJiaXin/" target="_blank" rel="noopener">http://www.cnblogs.com/YangJiaXin/</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;h2 id=&quot;谁在消耗cpu&quot;&gt;&lt;a href=&quot;#谁在消耗cpu&quot; class=&quot;headerlink&quot; title=&quot;谁在消耗cpu?&quot;&gt;&lt;/a&gt;谁在消耗cpu?&lt;/h2&gt;&lt;p&gt;&lt;em&gt;&lt;strong&gt;用户+系统+IO等待+软硬中断+空闲&lt;/str
      
    
    </summary>
    
      <category term="mysql" scheme="http://zhangyu8.me/categories/mysql/"/>
    
    
      <category term="mysql" scheme="http://zhangyu8.me/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>MySQL性能优化实践</title>
    <link href="http://zhangyu8.me/2020/04/09/MySQL%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/"/>
    <id>http://zhangyu8.me/2020/04/09/MySQL性能优化实践/</id>
    <published>2020-04-09T06:00:00.000Z</published>
    <updated>2020-04-09T06:38:29.344Z</updated>
    
    <content type="html"><![CDATA[<p>##超全的珍藏版MySQL性能优化实践！</p><p> 来源：<a href="https://www.xttblog.com/?p=4951" target="_blank" rel="noopener">https://www.xttblog.com/?p=4951</a></p><p>##一 题记</p><p>最近公司项目添加新功能，上线后发现有些功能的列表查询时间很久。原因是新功能用到旧功能的接口，而这些旧接口的 SQL 查询语句关联5,6张表且编写不够规范，导致 MySQL 在执行 SQL 语句时索引失效，进行全表扫描。原本负责优化的同事有事请假回家，因此优化查询数据的问题落在笔者手中。笔者在查阅网上 SQL 优化的资料后成功解决了问题，在此从全局角度，记录和总结 MySQL 查询优化相关技巧。</p><p>##二、优化思路</p><p><strong>数据查询慢，不代表 SQL 语句写法有问题。</strong> 首先，我们需要找到问题的源头才能“对症下药”。笔者用一张流程图展示 MySQL 优化的思路：</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_jpg/JfTPiahTHJhqYoYCBMDfKtOOacVmxWyCS1gUnf8AB6Ona3ibLjOV9Ygy02BkQVqr1uLbiarnsNwq5Ph0xXRWynibEQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p>无需更多言语，从图中可以清楚地看出，导致数据查询慢的原因有多种，如：缓存失效，在此一段时间内由于高并发访问导致 MySQL 服务器崩溃；SQL 语句编写问题；MySQL 服务器参数问题；硬件配置限制 MySQL 服务性能问题等。</p><p>##三、查看 MySQL 服务器运行的状态值</p><p><strong>如果系统的并发请求数不高，且查询速度慢，可以忽略该步骤直接进行 SQL 语句调优步骤。</strong></p><p>执行命令：</p><pre><code>show status</code></pre><p>由于返回结果太多，此处不贴出结果。其中，再返回的结果中，我们主要关注 “Queries”、“Threadsconnected” 和 “Threadsrunning” 的值，即查询次数、线程连接数和线程运行数。</p><p>我们可以通过执行如下脚本监控 MySQL 服务器运行的状态值</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">while true</span><br><span class="line">do</span><br><span class="line">mysqladmin -uroot -p&quot;密码&quot; ext | awk &apos;/Queries/&#123;q=$4&#125;/Threads_connected/&#123;c=$4&#125;/Threads_running/&#123;r=$4&#125;END&#123;printf(&quot;%d %d %d\n&quot;,q,c,r)&#125;&apos; &gt;&gt; status.txt</span><br><span class="line">sleep 1</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>执行该脚本 24 小时，获取 status.txt 里的内容，再次通过 awk 计算==每秒请求 MySQL 服务的次数==</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">awk &apos;&#123;q=$1-last;last=$1&#125;&#123;printf(&quot;%d %d %d\n&quot;,q,$2,$3)&#125;&apos; status.txt</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">复制计算好的内容到 Excel 中生成图表观察数据周期性。</span><br><span class="line"> </span><br><span class="line">如果观察的数据有周期性的变化，如上图的解释，需要修改缓存失效策略。</span><br><span class="line"></span><br><span class="line">例如：</span><br><span class="line"></span><br><span class="line">通过随机数在[3,6,9] 区间获取其中一个值作为缓存失效时间，这样分散了缓存失效时间，从而节省了一部分内存的消耗。</span><br><span class="line"></span><br><span class="line">当访问高峰期时，一部分请求分流到未失效的缓存，另一部分则访问 MySQL 数据库，这样减少了 MySQL 服务器的压力。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">##四、获取需要优化的 SQL 语句</span><br><span class="line"> </span><br><span class="line">### 4.1 方式一：查看运行的线程</span><br><span class="line"></span><br><span class="line">执行命令：</span><br><span class="line"></span><br><span class="line">    show processlist</span><br><span class="line"></span><br><span class="line">返回结果：</span><br></pre></td></tr></table></figure><p>mysql&gt; show processlist;<br>+—-+——+———–+——+———+——+———-+——————+<br>| Id | User | Host      | db   | Command | Time | State    | Info             |<br>+—-+——+———–+——+———+——+———-+——————+<br>|  9 | root | localhost | test | Query   |    0 | starting | show processlist |<br>+—-+——+———–+——+———+——+———-+——————+<br>1 row in set (0.00 sec)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">从返回结果中我们可以了解该线程执行了什么命令/SQL 语句以及执行的时间。实际应用中，查询的返回结果会有 N 条记录。</span><br><span class="line"> </span><br><span class="line">其中, **返回的 State 的值是我们判断性能好坏的关键**，其值出现如下内容，则该行记录的 SQL 语句需要优化：</span><br></pre></td></tr></table></figure><p>Converting HEAP to MyISAM # 查询结果太大时，把结果放到磁盘，严重<br>Create tmp table #创建临时表，严重<br>Copying to tmp table on disk  #把内存临时表复制到磁盘，严重<br>locked #被其他查询锁住，严重<br>loggin slow query #记录慢查询<br>Sorting result #排序<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line">## 4.2 方式二：开启慢查询日志</span><br><span class="line"> </span><br><span class="line">在配置文件 my.cnf 中的 \[mysqld\] 一行下边添加两个参数：</span><br></pre></td></tr></table></figure></p><p>slow_query_log = 1<br>slow_query_log_file=/var/lib/mysql/slow-query.log<br>long_query_time = 2<br>log_queries_not_using_indexes = 1<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line">其中，slowquerylog = 1 表示开启慢查询；</span><br><span class="line"></span><br><span class="line">slowquerylogfile 表示慢查询日志存放的位置；</span><br><span class="line"></span><br><span class="line">longquerytime = 2 表示查询 =2 秒才记录日志；</span><br><span class="line"></span><br><span class="line">logqueriesnotusing_indexes = 1 记录没有使用索引的 SQL 语句。</span><br><span class="line"> </span><br><span class="line">**注意：slowquerylog_file 的路径不能随便写，否则 MySQL 服务器可能没有权限将日志文件写到指定的目录中。建议直接复制上文的路径。**</span><br><span class="line"> </span><br><span class="line">修改保存文件后，重启 MySQL 服务。在 /var/lib/mysql/ 目录下会创建 slow-query.log 日志文件。连接 MySQL 服务端执行如下命令可以查看配置情况。</span><br></pre></td></tr></table></figure></p><p>show variables like ‘slow_query%’;</p><p>show variables like ‘long_query_time’;<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line"> </span><br><span class="line">测试慢查询日志：</span><br></pre></td></tr></table></figure></p><p>mysql&gt; select sleep(2);<br>+———-+<br>| sleep(2) |<br>+———-+<br>|        0 |<br>+———-+<br>1 row in set (2.00 sec)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">打开慢查询日志文件</span><br></pre></td></tr></table></figure></p><p>[root@localhost mysql]# vim /var/lib/mysql/slow-query.log<br>/usr/sbin/mysqld, Version: 5.7.19-log (MySQL Community Server (GPL)). started with:<br>Tcp port: 0  Unix socket: /var/lib/mysql/mysql.sock<br>Time                 Id Command    Argument</p><h1 id="Time-2017-10-05T04-39-11-408964Z"><a href="#Time-2017-10-05T04-39-11-408964Z" class="headerlink" title="Time: 2017-10-05T04:39:11.408964Z"></a>Time: 2017-10-05T04:39:11.408964Z</h1><h1 id="User-Host-root-root-localhost-Id-3"><a href="#User-Host-root-root-localhost-Id-3" class="headerlink" title="User@Host: root[root] @ localhost []  Id:     3"></a>User@Host: root[root] @ localhost []  Id:     3</h1><h1 id="Query-time-2-001395-Lock-time-0-000000-Rows-sent-1-Rows-examined-0"><a href="#Query-time-2-001395-Lock-time-0-000000-Rows-sent-1-Rows-examined-0" class="headerlink" title="Query_time: 2.001395  Lock_time: 0.000000 Rows_sent: 1  Rows_examined: 0"></a>Query_time: 2.001395  Lock_time: 0.000000 Rows_sent: 1  Rows_examined: 0</h1><p>use test;<br>SET timestamp=1507178351;<br>select sleep(2);<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line">我们可以看到刚才执行了 2 秒的 SQL 语句被记录下来了。</span><br><span class="line"> </span><br><span class="line">虽然在慢查询日志中记录查询慢的 SQL 信息，但是日志记录的内容密集且不易查阅。因此，我们需要通过工具将 SQL 筛选出来。</span><br><span class="line"> </span><br><span class="line">MySQL 提供 mysqldumpslow 工具对日志进行分析。我们可以使用 mysqldumpslow --help 查看命令相关用法。</span><br><span class="line">  </span><br><span class="line">常用参数如下：</span><br></pre></td></tr></table></figure></p><pre><code>-s：排序方式，后边接着如下参数    c：访问次数    l：锁定时间    r：返回记录    t：查询时间al：平均锁定时间ar：平均返回记录书at：平均查询时间-t：返回前面多少条的数据-g：翻遍搭配一个正则表达式，大小写不敏感</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line"> </span><br><span class="line">案例：</span><br></pre></td></tr></table></figure><p>获取返回记录集最多的10个sql<br>mysqldumpslow -s r -t 10 /var/lib/mysql/slow-query.log</p><p>获取访问次数最多的10个sql<br>mysqldumpslow -s c -t 10 /var/lib/mysql/slow-query.log</p><p>获取按照时间排序的前10条里面含有左连接的查询语句<br>mysqldumpslow -s t -t 10 -g “left join” /var/lib/mysql/slow-query.log<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line">   </span><br><span class="line"> </span><br><span class="line">##五、分析 SQL 语句</span><br><span class="line"> </span><br><span class="line">### 5.1 方式一：explain</span><br><span class="line"> </span><br><span class="line">筛选出有问题的 SQL，我们可以使用 MySQL 提供的 explain 查看 SQL 执行计划情况（关联表，表查询顺序、索引使用情况等）。</span><br><span class="line"> </span><br><span class="line">用法：</span><br><span class="line"> </span><br><span class="line">     explain select * from category;</span><br><span class="line"> 返回结果：</span><br></pre></td></tr></table></figure></p><p>mysql&gt; explain select * from category;<br>+—-+————-+———-+————+——+—————+——+———+——+——+———-+——-+<br>| id | select_type | table    | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra |<br>+—-+————-+———-+————+——+—————+——+———+——+——+———-+——-+<br>|  1 | SIMPLE      | category | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    1 |   100.00 | NULL  |<br>+—-+————-+———-+————+——+—————+——+———+——+——+———-+——-+<br>1 row in set, 1 warning (0.00 sec)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">字段解释：1) id：select 查询序列号。id相同，执行顺序由上至下；id不同，id值越大优先级越高，越先被执行</span><br><span class="line"></span><br><span class="line">2) select_type：查询数据的操作类型，其值如下：</span><br><span class="line"></span><br><span class="line">-   simple：简单查询，不包含子查询或 union</span><br><span class="line">    </span><br><span class="line">-   primary:包含复杂的子查询，最外层查询标记为该值</span><br><span class="line">    </span><br><span class="line">-   subquery：在 select 或 where 包含子查询，被标记为该值</span><br><span class="line">    </span><br><span class="line">-   derived：在 from 列表中包含的子查询被标记为该值，MySQL 会递归执行这些子查询，把结果放在临时表</span><br><span class="line">    </span><br><span class="line">-   union：若第二个 select 出现在 union 之后，则被标记为该值。若 union 包含在 from 的子查询中，外层 select 被标记为 derived</span><br><span class="line">    </span><br><span class="line">-   union result：从 union 表获取结果的 select</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">3) table：显示该行数据是关于哪张表</span><br><span class="line"></span><br><span class="line">4) partitions：匹配的分区</span><br><span class="line"></span><br><span class="line">5) type：表的连接类型，其值，性能由高到底排列如下：</span><br><span class="line"></span><br><span class="line">-   system：表只有一行记录，相当于系统表</span><br><span class="line">    </span><br><span class="line">-   const：通过索引一次就找到，只匹配一行数据</span><br><span class="line">    </span><br><span class="line">-   eq_ref：唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常用于主键或唯一索引扫描</span><br><span class="line">    </span><br><span class="line">-   ref：非唯一性索引扫描，返回匹配某个单独值的所有行。用于=、&lt; 或  操作符带索引的列</span><br><span class="line">    </span><br><span class="line">-   range：只检索给定范围的行，使用一个索引来选择行。一般使用between、、&lt;情况</span><br><span class="line">    </span><br><span class="line">-   index：只遍历索引树</span><br><span class="line">    </span><br><span class="line">-   ALL：全表扫描，性能最差</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">**注：前5种情况都是理想情况的索引使用情况。通常优化至少到range级别，最好能优化到 ref**</span><br><span class="line"></span><br><span class="line">6) possible_keys：指出 MySQL 使用哪个索引在该表找到行记录。如果该值为 NULL，说明没有使用索引，可以建立索引提高性能</span><br><span class="line"></span><br><span class="line">7) key：显示 MySQL 实际使用的索引。如果为 NULL，则没有使用索引查询</span><br><span class="line"></span><br><span class="line">8) key_len：表示索引中使用的字节数，通过该列计算查询中使用的索引的长度。在不损失精确性的情况下，长度越短越好 显示的是索引字段的最大长度，并非实际使用长度</span><br><span class="line"></span><br><span class="line">9) ref：显示该表的索引字段关联了哪张表的哪个字段</span><br><span class="line"></span><br><span class="line">10) rows：根据表统计信息及选用情况，大致估算出找到所需的记录或所需读取的行数，数值越小越好</span><br><span class="line"></span><br><span class="line">11) filtered：返回结果的行数占读取行数的百分比，值越大越好</span><br><span class="line"></span><br><span class="line">12) extra：包含不合适在其他列中显示但十分重要的额外信息，常见的值如下：</span><br><span class="line"></span><br><span class="line">-   using filesort：说明 MySQL 会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。出现该值，应该优化 SQL</span><br><span class="line">    </span><br><span class="line">-   using temporary：使用了临时表保存中间结果，MySQL 在对查询结果排序时使用临时表。常见于排序 order by 和分组查询 group by。出现该值，应该优化 SQL</span><br><span class="line">    </span><br><span class="line">-   using index：表示相应的 select 操作使用了覆盖索引，避免了访问表的数据行，效率不错</span><br><span class="line">    </span><br><span class="line">-   using where：where 子句用于限制哪一行</span><br><span class="line">    </span><br><span class="line">-   using join buffer：使用连接缓存</span><br><span class="line">    </span><br><span class="line">-   distinct：发现第一个匹配后，停止为当前的行组合搜索更多的行</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">**注意：出现前 2 个值，SQL 语句必须要优化。**</span><br><span class="line"></span><br><span class="line">### 5.2 方式二：profiling</span><br><span class="line"></span><br><span class="line">使用 profiling 命令可以了解 SQL 语句消耗资源的详细信息（每个执行步骤的开销）。</span><br><span class="line"></span><br><span class="line">#### 5.2.1 查看 profile 开启情况</span><br><span class="line"></span><br><span class="line">select @@profiling;</span><br><span class="line"></span><br><span class="line">返回结果：</span><br></pre></td></tr></table></figure></p><p>mysql&gt; select @@profiling;<br>+————-+<br>| @@profiling |<br>+————-+<br>|           0 |<br>+————-+<br>1 row in set, 1 warning (0.00 sec)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line"> 0 表示关闭状态,1 表示开启</span><br><span class="line"> </span><br><span class="line">#### 5.2.2 启用 profile</span><br><span class="line"> </span><br><span class="line">set profiling = 1;  </span><br><span class="line"> </span><br><span class="line"> 返回结果：</span><br></pre></td></tr></table></figure></p><p>mysql&gt; set profiling = 1;<br>Query OK, 0 rows affected, 1 warning (0.00 sec)</p><p>mysql&gt; select @@profiling;<br>+————-+<br>| @@profiling |<br>+————-+<br>|           1 |<br>+————-+<br>1 row in set, 1 warning (0.00 sec)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line"> 在连接关闭后，profiling 状态自动设置为关闭状态。</span><br><span class="line"> </span><br><span class="line">#### 5.2.3 查看执行的 SQL 列表</span><br><span class="line"> </span><br><span class="line">     show profiles;</span><br><span class="line"> </span><br><span class="line"> 返回结果：</span><br></pre></td></tr></table></figure></p><p>mysql&gt; show profiles;<br>+———-+————+——————————+<br>| Query_ID | Duration   | Query                        |<br>+———-+————+——————————+<br>|        1 | 0.00062925 | select @@profiling           |<br>|        2 | 0.00094150 | show tables                  |<br>|        3 | 0.00119125 | show databases               |<br>|        4 | 0.00029750 | SELECT DATABASE()            |<br>|        5 | 0.00025975 | show databases               |<br>|        6 | 0.00023050 | show tables                  |<br>|        7 | 0.00042000 | show tables                  |<br>|        8 | 0.00260675 | desc role                    |<br>|        9 | 0.00074900 | select name,is_key from role |<br>+———-+————+——————————+<br>9 rows in set, 1 warning (0.00 sec)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line"> 该命令执行之前，需要执行其他 SQL 语句才有记录。</span><br><span class="line"> </span><br><span class="line">#### 5.2.4 查询指定 ID 的执行详细信息</span><br><span class="line"> </span><br><span class="line">     show profile for query Query_ID;</span><br><span class="line"> </span><br><span class="line"> 返回结果：</span><br></pre></td></tr></table></figure></p><p>mysql&gt; show profile for query 9;<br>+———————-+———-+<br>| Status               | Duration |<br>+———————-+———-+<br>| starting             | 0.000207 |<br>| checking permissions | 0.000010 |<br>| Opening tables       | 0.000042 |<br>| init                 | 0.000050 |<br>| System lock          | 0.000012 |<br>| optimizing           | 0.000003 |<br>| statistics           | 0.000011 |<br>| preparing            | 0.000011 |<br>| executing            | 0.000002 |<br>| Sending data         | 0.000362 |<br>| end                  | 0.000006 |<br>| query end            | 0.000006 |<br>| closing tables       | 0.000006 |<br>| freeing items        | 0.000011 |<br>| cleaning up          | 0.000013 |<br>+———————-+———-+<br>15 rows in set, 1 warning (0.00 sec)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line"> 每行都是状态变化的过程以及它们持续的时间。Status 这一列和 show processlist 的 State 是一致的。因此，需要优化的注意点与上文描述的一样。</span><br><span class="line"> </span><br><span class="line">#### 5.2.5 获取 CPU、 Block IO 等信息</span><br></pre></td></tr></table></figure></p><p>show profile block io,cpu for query Query_ID;</p><p>show profile cpu,block io,memory,swaps,context switches,source for query Query_ID;</p><p>show profile all for query Query_ID;<br><code>`</code> </p><p> 六、优化手段</p><p> 主要以查询优化、索引使用和表结构设计方面进行讲解。</p><h3 id="6-1-查询优化"><a href="#6-1-查询优化" class="headerlink" title="6.1 查询优化"></a>6.1 查询优化</h3><p> 1) 避免 SELECT *，需要什么数据，就查询对应的字段。</p><p> 2) 小表驱动大表，即小的数据集驱动大的数据集。如：以 A，B 两表为例，两表通过 id 字段进行关联。</p><p> 当 B 表的数据集小于 A 表时，用 in 优化 exist；使用 in ，两表执行顺序是先查 B 表，再查 A 表</p><pre><code>select * from A where id in (select id from B)</code></pre><p> 当 A 表的数据集小于 B 表时，用 exist 优化 in；使用 exists，两表执行顺序是先查 A 表，再查 B 表</p><pre><code>select * from A where exists (select 1 from B where B.id = A.id)</code></pre><p> 3) 一些情况下，可以使用连接代替子查询，因为使用 join，MySQL 不会在内存中创建临时表。</p><p> 4) 适当添加冗余字段，减少表关联。</p><p> 5) 合理使用索引（下文介绍）。如：为排序、分组字段建立索引，避免 filesort 的出现。</p><h3 id="6-2-索引使用"><a href="#6-2-索引使用" class="headerlink" title="6.2 索引使用"></a>6.2 索引使用</h3><h4 id="6-2-1-适合使用索引的场景"><a href="#6-2-1-适合使用索引的场景" class="headerlink" title="6.2.1 适合使用索引的场景"></a>6.2.1 适合使用索引的场景</h4><p> 1) 主键自动创建唯一索引</p><p> 2) 频繁作为查询条件的字段</p><p> 3) 查询中与其他表关联的字段</p><p> 4) 查询中排序的字段</p><p> 5) 查询中统计或分组字段</p><h4 id="6-2-2-不适合使用索引的场景"><a href="#6-2-2-不适合使用索引的场景" class="headerlink" title="6.2.2 不适合使用索引的场景"></a>6.2.2 不适合使用索引的场景</h4><p> 1) 频繁更新的字段</p><p> 2) where 条件中用不到的字段</p><p> 3) 表记录太少</p><p> 4) 经常增删改的表</p><p> 5) 字段的值的差异性不大或重复性高</p><h4 id="6-2-3-索引创建和使用原则"><a href="#6-2-3-索引创建和使用原则" class="headerlink" title="6.2.3 索引创建和使用原则"></a>6.2.3 索引创建和使用原则</h4><p> 1) 单表查询：哪个列作查询条件，就在该列创建索引</p><p> 2) 多表查询：left join 时，索引添加到右表关联字段；right join 时，索引添加到左表关联字段</p><p> 3) 不要对索引列进行任何操作（计算、函数、类型转换）</p><p> 4) 索引列中不要使用 !=，&lt; 非等于</p><p> 5) 索引列不要为空，且不要使用 is null 或 is not null 判断</p><p> 6) 索引字段是字符串类型，查询条件的值要加’’单引号,避免底层类型自动转换</p><p> <strong>违背上述原则可能会导致索引失效，具体情况需要使用 explain 命令进行查看</strong></p><h4 id="6-2-4-索引失效情况"><a href="#6-2-4-索引失效情况" class="headerlink" title="6.2.4 索引失效情况"></a>6.2.4 索引失效情况</h4><p> 除了违背索引创建和使用原则外，如下情况也会导致索引失效：</p><p> 1) 模糊查询时，以 % 开头</p><p> 2) 使用 or 时，如：字段1（非索引）or 字段2（索引）会导致索引失效。</p><p> 3) 使用复合索引时，不使用第一个索引列。</p><p> index(a,b,c) ，以字段 a,b,c 作为复合索引为例：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/JfTPiahTHJhqYoYCBMDfKtOOacVmxWyCS9frQ0UoHy2VYKkrR7o2ibmNNj4dRVJdeQbVtvLSbicUJ6Qqxscvwb8IA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><h3 id="6-3-1-选择合适的数据类型6-3-数据库表结构设计"><a href="#6-3-1-选择合适的数据类型6-3-数据库表结构设计" class="headerlink" title="6.3.1 选择合适的数据类型6.3 数据库表结构设计"></a>6.3.1 选择合适的数据类型6.3 数据库表结构设计</h3><p> 1) 使用可以存下数据最小的数据类型</p><p> 2) 使用简单的数据类型。int 要比 varchar 类型在mysql处理简单</p><p> 3) 尽量使用 tinyint、smallint、mediumint 作为整数类型而非 int</p><p> 4) 尽可能使用 not null 定义字段，因为 null 占用4字节空间</p><p> 5) 尽量少用 text 类型,非用不可时最好考虑分表</p><p> 6) 尽量使用 timestamp 而非 datetime</p><p> 7) 单表不要有太多字段，建议在 20 以内</p><h4 id="6-3-2-表的拆分"><a href="#6-3-2-表的拆分" class="headerlink" title="6.3.2 表的拆分"></a>6.3.2 表的拆分</h4><p> 当数据库中的数据非常大时，查询优化方案也不能解决查询速度慢的问题时，我们可以考虑拆分表，让每张表的数据量变小，从而提高查询效率。</p><p> 1) 垂直拆分：将表中多个列分开放到不同的表中。例如用户表中一些字段经常被访问，将这些字段放在一张表中，另外一些不常用的字段放在另一张表中。插入数据时，使用事务确保两张表的数据一致性。</p><p> 2) 水平拆分：按照行进行拆分。例如用户表中，使用用户ID，对用户ID取10的余数，将用户数据均匀的分配到0~9的10个用户表中。查找时也按照这个规则查询数据。</p><h4 id="6-3-3-读写分离"><a href="#6-3-3-读写分离" class="headerlink" title="6.3.3 读写分离"></a>6.3.3 读写分离</h4><p> 一般情况下对数据库而言都是“读多写少”。换言之，数据库的压力多数是因为大量的读取数据的操作造成的。我们可以采用数据库集群的方案，使用一个库作为主库，负责写入数据；其他库为从库，负责读取数据。这样可以缓解对数据库的访问压力。</p><p>##七、服务器参数调优</p><h3 id="7-1-内存相关"><a href="#7-1-内存相关" class="headerlink" title="7.1 内存相关"></a>7.1 内存相关</h3><p> sortbuffersize 排序缓冲区内存大小</p><p> joinbuffersize 使用连接缓冲区大小</p><p> readbuffersize 全表扫描时分配的缓冲区大小</p><h3 id="7-2-IO-相关"><a href="#7-2-IO-相关" class="headerlink" title="7.2 IO 相关"></a>7.2 IO 相关</h3><p> Innodblogfile_size 事务日志大小</p><p> Innodblogfilesingroup 事务日志个数</p><p> Innodblogbuffer_size 事务日志缓冲区大小</p><p> Innodbflushlogattrx_commit 事务日志刷新策略 ，其值如下：</p><p> 0：每秒进行一次 log 写入 cache，并 flush log 到磁盘</p><p> 1：在每次事务提交执行 log 写入 cache，并 flush log 到磁盘</p><p> 2：每次事务提交，执行 log 数据写到 cache，每秒执行一次 flush log 到磁盘</p><h3 id="7-3-安全相关"><a href="#7-3-安全相关" class="headerlink" title="7.3 安全相关"></a>7.3 安全相关</h3><p> expirelogsdays 指定自动清理 binlog 的天数</p><p> maxallowedpacket 控制 MySQL 可以接收的包的大小</p><p> skipnameresolve 禁用 DNS 查找</p><p> read_only 禁止非 super 权限用户写权限</p><p> skipslavestart 级你用 slave 自动恢复</p><h3 id="7-4-其他"><a href="#7-4-其他" class="headerlink" title="7.4 其他"></a>7.4 其他</h3><p> max_connections 控制允许的最大连接数</p><p> tmptablesize 临时表大小</p><p> maxheaptable_size 最大内存表大小</p><p> <strong>笔者并没有使用这些参数对 MySQL 服务器进行调优，具体详情介绍和性能效果请参考文章末尾的资料或另行百度。</strong></p><p>##八、硬件选购和参数优化</p><p> 硬件的性能直接决定 MySQL 数据库的性能。硬件的性能瓶颈，直接决定 MySQL 数据库的运行数据和效率。</p><p> <strong>作为软件开发程序员，我们主要关注软件方面的优化内容，以下硬件方面的优化作为了解即可</strong></p><h3 id="8-1-内存相关"><a href="#8-1-内存相关" class="headerlink" title="8.1 内存相关"></a>8.1 内存相关</h3><p> 内存的 IO 比硬盘的速度快很多，可以增加系统的缓冲区容量，使数据在内存停留的时间更长，以减少磁盘的 IO</p><h3 id="8-2-磁盘-I-O-相关"><a href="#8-2-磁盘-I-O-相关" class="headerlink" title="8.2 磁盘 I/O 相关"></a>8.2 磁盘 I/O 相关</h3><p> 1) 使用 SSD 或 PCle SSD 设备，至少获得数百倍甚至万倍的 IOPS 提升</p><p> 2) 购置阵列卡同时配备 CACHE 及 BBU 模块，可以明显提升 IOPS</p><p> 3) 尽可能选用 RAID-10，而非 RAID-5</p><h3 id="8-3-配置-CPU-相关"><a href="#8-3-配置-CPU-相关" class="headerlink" title="8.3 配置 CPU 相关"></a>8.3 配置 CPU 相关</h3><p> 在服务器的 BIOS 设置中，调整如下配置：</p><p> 1) 选择 Performance Per Watt Optimized（DAPC）模式，发挥 CPU 最大性能</p><p> 2) 关闭 C1E 和 C States 等选项，提升 CPU 效率</p><p> 3) Memory Frequency（内存频率）选择 Maximum Performance</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;##超全的珍藏版MySQL性能优化实践！&lt;/p&gt;
&lt;p&gt; 来源：&lt;a href=&quot;https://www.xttblog.com/?p=4951&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.xttblog.com/?p=4951&lt;
      
    
    </summary>
    
      <category term="mysql" scheme="http://zhangyu8.me/categories/mysql/"/>
    
    
      <category term="mysql" scheme="http://zhangyu8.me/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>Redis持久化讲解</title>
    <link href="http://zhangyu8.me/2020/03/17/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E8%AE%B2%E8%A7%A3/"/>
    <id>http://zhangyu8.me/2020/03/17/Redis持久化讲解/</id>
    <published>2020-03-17T09:00:00.000Z</published>
    <updated>2020-03-17T09:33:37.148Z</updated>
    
    <content type="html"><![CDATA[<p>好文转载</p><p><a href="http://www.wmyskxz.com/2020/03/13/redis-7-chi-jiu-hua-yi-wen-liao-jie/" target="_blank" rel="noopener">http://www.wmyskxz.com/2020/03/13/redis-7-chi-jiu-hua-yi-wen-liao-jie/</a></p><blockquote><h1 id="一、持久化简介"><a href="#一、持久化简介" class="headerlink" title="一、持久化简介"></a>一、持久化简介</h1><p><strong>Redis</strong> 的数据 <strong>全部存储</strong> 在 <strong>内存</strong> 中，如果 <strong>突然宕机</strong>，数据就会全部丢失，因此必须有一套机制来保证 Redis 的数据不会因为故障而丢失，这种机制就是 Redis 的 <strong>持久化机制</strong>，它会将内存中的数据库状态 <strong>保存到磁盘</strong> 中。</p><h2 id="持久化发生了什么-从内存到磁盘"><a href="#持久化发生了什么-从内存到磁盘" class="headerlink" title="持久化发生了什么 | 从内存到磁盘"></a>持久化发生了什么 | 从内存到磁盘</h2><p>我们来稍微考虑一下 <strong>Redis</strong> 作为一个 <strong>“内存数据库”</strong> 要做的关于持久化的事情。通常来说，从客户端发起请求开始，到服务器真实地写入磁盘，需要发生如下几件事情：</p><p><img src="http://www.wmyskxz.com/images/pasted-17.png" alt></p><p><strong>详细版</strong> 的文字描述大概就是下面这样：</p><ol><li><p>客户端向数据库 <strong>发送写命令</strong> <em>(数据在客户端的内存中)</em></p></li><li><p>数据库 <strong>接收</strong> 到客户端的 <strong>写请求</strong> <em>(数据在服务器的内存中)</em></p></li><li><p>数据库 <strong>调用系统 API</strong> 将数据写入磁盘 <em>(数据在内核缓冲区中)</em></p></li><li><p>操作系统将 <strong>写缓冲区</strong> 传输到 <strong>磁盘控控制器</strong> <em>(数据在磁盘缓存中)</em></p></li><li><p>操作系统的磁盘控制器将数据 <strong>写入实际的物理媒介</strong> 中 <em>(数据在磁盘中)</em></p></li></ol><p><strong>注意:</strong> 上面的过程其实是 <strong>极度精简</strong> 的，在实际的操作系统中，<strong>缓存</strong> 和 <strong>缓冲区</strong> 会比这 <strong>多得多</strong>…</p><h2 id="如何尽可能保证持久化的安全"><a href="#如何尽可能保证持久化的安全" class="headerlink" title="如何尽可能保证持久化的安全"></a>如何尽可能保证持久化的安全</h2><p>如果我们故障仅仅涉及到 <strong>软件层面</strong> <em>(该进程被管理员终止或程序崩溃)</em> 并且没有接触到内核，那么在 <em>上述步骤 3</em> 成功返回之后，我们就认为成功了。即使进程崩溃，操作系统仍然会帮助我们把数据正确地写入磁盘。</p><p>如果我们考虑 <strong>停电/ 火灾</strong> 等 <strong>更具灾难性</strong> 的事情，那么只有在完成了第 <strong>5</strong> 步之后，才是安全的。</p><p><img src="http://www.wmyskxz.com/images/pasted-18.png" alt></p><p>机房”火了“</p><p>所以我们可以总结得出数据安全最重要的阶段是：<strong>步骤三、四、五</strong>，即：</p><ul><li><p>数据库软件调用写操作将用户空间的缓冲区转移到内核缓冲区的频率是多少？</p></li><li><p>内核多久从缓冲区取数据刷新到磁盘控制器？</p></li><li><p>磁盘控制器多久把数据写入物理媒介一次？</p></li><li><p><strong>注意：</strong> 如果真的发生灾难性的事件，我们可以从上图的过程中看到，任何一步都可能被意外打断丢失，所以只能 <strong>尽可能地保证</strong> 数据的安全，这对于所有数据库来说都是一样的。</p></li></ul><p>我们从 <strong>第三步</strong> 开始。Linux 系统提供了清晰、易用的用于操作文件的 <code>POSIX file API</code>，<code>20</code> 多年过去，仍然还有很多人对于这一套 <code>API</code> 的设计津津乐道，我想其中一个原因就是因为你光从 <code>API</code> 的命名就能够很清晰地知道这一套 API 的用途：</p><pre><code>int open(const char *path, int oflag, .../*,mode_t mode */);int close (int filedes);int remove( const char *fname );ssize_t write(int fildes, const void *buf, size_t nbyte);ssize_t read(int fildes, void *buf, size_t nbyte);</code></pre><ul><li>参考自：API 设计最佳实践的思考 - <a href="https://www.cnblogs.com/yuanjiangw/p/10846560.html" target="_blank" rel="noopener">https://www.cnblogs.com/yuanjiangw/p/10846560.html</a></li></ul><p>所以，我们有很好的可用的 <code>API</code> 来完成 <strong>第三步</strong>，但是对于成功返回之前，我们对系统调用花费的时间没有太多的控制权。</p><p>然后我们来说说 <strong>第四步</strong>。我们知道，除了早期对电脑特别了解那帮人 <em>(操作系统就这帮人搞的)</em>，实际的物理硬件都不是我们能够 <strong>直接操作</strong> 的，都是通过 <strong>操作系统调用</strong> 来达到目的的。为了防止过慢的 I/O 操作拖慢整个系统的运行，操作系统层面做了很多的努力，譬如说 <strong>上述第四步</strong> 提到的 <strong>写缓冲区</strong>，并不是所有的写操作都会被立即写入磁盘，而是要先经过一个缓冲区，默认情况下，Linux 将在 <strong>30 秒</strong> 后实际提交写入。</p><p><img src="http://www.wmyskxz.com/images/pasted-19.png" alt></p><p>但是很明显，<strong>30 秒</strong> 并不是 Redis 能够承受的，这意味着，如果发生故障，那么最近 30 秒内写入的所有数据都可能会丢失。幸好 <code>PROSIX API</code> 提供了另一个解决方案：<code>fsync</code>，该命令会 <strong>强制</strong> 内核将 <strong>缓冲区</strong> 写入 <strong>磁盘</strong>，但这是一个非常消耗性能的操作，每次调用都会 <strong>阻塞等待</strong> 直到设备报告 IO 完成，所以一般在生产环境的服务器中，<strong>Redis</strong> 通常是每隔 1s 左右执行一次 <code>fsync</code> 操作。</p><p>到目前为止，我们了解到了如何控制 <code>第三步</code> 和 <code>第四步</code>，但是对于 <strong>第五步</strong>，我们 <strong>完全无法控制</strong>。也许一些内核实现将试图告诉驱动实际提交物理介质上的数据，或者控制器可能会为了提高速度而重新排序写操作，不会尽快将数据真正写到磁盘上，而是会等待几个多毫秒。这完全是我们无法控制的。</p><h1 id="二、Redis-中的两种持久化方式"><a href="#二、Redis-中的两种持久化方式" class="headerlink" title="二、Redis 中的两种持久化方式"></a>二、Redis 中的两种持久化方式</h1><h2 id="方式一：快照"><a href="#方式一：快照" class="headerlink" title="方式一：快照"></a>方式一：快照</h2><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_gif/ia1kbU3RS1H7PMcYtBZdH78LrPP2OrMV8eb76EtkgH2uiciaJhAgg0Pu8ibRCQ8BmjbqbO4MNwT3Hy6Gic1vHOVuN4Q/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt></p><p><strong>Redis 快照</strong> 是最简单的 Redis 持久性模式。当满足特定条件时，它将生成数据集的时间点快照，例如，如果先前的快照是在2分钟前创建的，并且现在已经至少有 <em>100</em> 次新写入，则将创建一个新的快照。此条件可以由用户配置 Redis 实例来控制，也可以在运行时修改而无需重新启动服务器。快照作为包含整个数据集的单个 <code>.rdb</code> 文件生成。</p><p>但我们知道，Redis 是一个 <strong>单线程</strong> 的程序，这意味着，我们不仅仅要响应用户的请求，还需要进行内存快照。而后者要求 Redis 必须进行 IO 操作，这会严重拖累服务器的性能。</p><p>还有一个重要的问题是，我们在 <strong>持久化的同时</strong>，<strong>内存数据结构</strong> 还可能在 <strong>变化</strong>，比如一个大型的 hash 字典正在持久化，结果一个请求过来把它删除了，可是这才刚持久化结束，咋办？</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_jpg/ia1kbU3RS1H7PMcYtBZdH78LrPP2OrMV8ibFtyVaHayfdG0hvmEDeGOgnVOdmYkxTmkad9JnVRicIq2m2dtVTDicNg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><h3 id="使用系统多进程-COW-Copy-On-Write-机制-fork-函数"><a href="#使用系统多进程-COW-Copy-On-Write-机制-fork-函数" class="headerlink" title="使用系统多进程 COW(Copy On Write) 机制 | fork 函数"></a>使用系统多进程 COW(Copy On Write) 机制 | fork 函数</h3><p>操作系统多进程 <strong>COW(Copy On Write) 机制</strong> 拯救了我们。<strong>Redis</strong> 在持久化时会调用 <code>glibc</code> 的函数 <code>fork</code> 产生一个子进程，简单理解也就是基于当前进程 <strong>复制</strong> 了一个进程，主进程和子进程会共享内存里面的代码块和数据段：</p><p><img src="http://www.wmyskxz.com/images/pasted-21.png" alt></p><p>这里多说一点，<strong>为什么 fork 成功调用后会有两个返回值呢？</strong> 因为子进程在复制时复制了父进程的堆栈段，所以两个进程都停留在了 <code>fork</code> 函数中 <em>(都在同一个地方往下继续”同时”执行)</em>，等待返回，所以 <strong>一次在父进程中返回子进程的 pid，另一次在子进程中返回零，系统资源不够时返回负数</strong>。<em>(伪代码如下)</em></p><pre><code>pid = os.fork()if pid &gt; 0:  handle_client_request()  # 父进程继续处理客户端请求if pid == 0:  handle_snapshot_write()  # 子进程处理快照写磁盘if pid &lt; 0:  # fork error</code></pre><p>所以 <strong>快照持久化</strong> 可以完全交给 <strong>子进程</strong> 来处理，<strong>父进程</strong> 则继续 <strong>处理客户端请求</strong>。<strong>子进程</strong> 做数据持久化，它 <strong>不会修改现有的内存数据结构</strong>，它只是对数据结构进行遍历读取，然后序列化写到磁盘中。但是 <strong>父进程</strong> 不一样，它必须持续服务客户端请求，然后对 <strong>内存数据结构进行不间断的修改</strong>。</p><p>这个时候就会使用操作系统的 COW 机制来进行 <strong>数据段页面</strong> 的分离。数据段是由很多操作系统的页面组合而成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复 制一份分离出来，然后 <strong>对这个复制的页面进行修改</strong>。这时 <strong>子进程</strong> 相应的页面是 <strong>没有变化的</strong>，还是进程产生时那一瞬间的数据。</p><p>子进程因为数据没有变化，它能看到的内存里的数据在进程产生的一瞬间就凝固了，再也不会改变，这也是为什么 <strong>Redis</strong> 的持久化 <strong>叫「快照」的原因</strong>。接下来子进程就可以非常安心的遍历数据了进行序列化写磁盘了。</p><h2 id="方式二：AOF"><a href="#方式二：AOF" class="headerlink" title="方式二：AOF"></a>方式二：AOF</h2><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_gif/ia1kbU3RS1H7PMcYtBZdH78LrPP2OrMV8x2OvibGxGibPh2tZPWATrYDrXtOVuHWzGLg0uMQ8Y4OCPFIRAVN9ibvDQ/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt></p><p><strong>快照不是很持久</strong>。如果运行 Redis 的计算机停止运行，电源线出现故障或者您 <code>kill -9</code> 的实例意外发生，则写入 Redis 的最新数据将丢失。尽管这对于某些应用程序可能不是什么大问题，但有些使用案例具有充分的耐用性，在这些情况下，快照并不是可行的选择。</p><p><strong>AOF(Append Only File - 仅追加文件)</strong> 它的工作方式非常简单：每次执行 <strong>修改内存</strong> 中数据集的写操作时，都会 <strong>记录</strong> 该操作。假设 AOF 日志记录了自 Redis 实例创建以来 <strong>所有的修改性指令序列</strong>，那么就可以通过对一个空的 Redis 实例 <strong>顺序执行所有的指令</strong>，也就是 <strong>「重放」</strong>，来恢复 Redis 当前实例的内存数据结构的状态。</p><p>为了展示 AOF 在实际中的工作方式，我们来做一个简单的实验：</p><pre><code>./redis-server --appendonly yes  # 设置一个新实例为 AOF 模式</code></pre><p>然后我们执行一些写操作：</p><pre><code>redis 127.0.0.1:6379&gt; set key1 HelloOKredis 127.0.0.1:6379&gt; append key1 &quot; World!&quot;(integer) 12redis 127.0.0.1:6379&gt; del key1(integer) 1redis 127.0.0.1:6379&gt; del non_existing_key(integer) 0</code></pre><p>前三个操作实际上修改了数据集，第四个操作没有修改，因为没有指定名称的键。这是 AOF 日志保存的文本：</p><pre><code>$ cat appendonly.aof*2$6SELECT$10*3$3set$4key1$5Hello*3$6append$4key1$7 World!*2$3del$4key1</code></pre><p>如您所见，最后的那一条 <code>DEL</code> 指令不见了，因为它没有对数据集进行任何修改。</p><p>就是这么简单。当 Redis 收到客户端修改指令后，会先进行参数校验、逻辑处理，如果没问题，就 <strong>立即</strong> 将该指令文本 <strong>存储</strong> 到 AOF 日志中，也就是说，<strong>先执行指令再将日志存盘</strong>。这一点不同于 <code>MySQL</code>、<code>LevelDB</code>、<code>HBase</code> 等存储引擎，如果我们先存储日志再做逻辑处理，这样就可以保证即使宕机了，我们仍然可以通过之前保存的日志恢复到之前的数据状态，但是 <strong>Redis 为什么没有这么做呢？</strong></p><blockquote><p>Emmm… 没找到特别满意的答案，引用一条来自知乎上的回答吧：</p><ul><li><p><strong>@缘于专注</strong> - 我甚至觉得没有什么特别的原因。仅仅是因为，由于AOF文件会比较大，为了避免写入无效指令（错误指令），必须先做指令检查？如何检查，只能先执行了。因为语法级别检查并不能保证指令的有效性，比如删除一个不存在的key。而MySQL这种是因为它本身就维护了所有的表的信息，所以可以语法检查后过滤掉大部分无效指令直接记录日志，然后再执行。</p></li><li><p>更多讨论参见：为什么Redis先执行指令，再记录AOF日志，而不是像其它存储引擎一样反过来呢？- <a href="https://www.zhihu.com/question/342427472" target="_blank" rel="noopener">https://www.zhihu.com/question/342427472</a></p></li></ul></blockquote><h3 id="AOF-重写"><a href="#AOF-重写" class="headerlink" title="AOF 重写"></a>AOF 重写</h3><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_jpg/ia1kbU3RS1H7PMcYtBZdH78LrPP2OrMV8LRC7fRaWoa3Y0yVhWBtibhtFXugAQLzMGTdbEIRfvIDvvTHs1mWaGzA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p><strong>Redis</strong> 在长期运行的过程中，AOF 的日志会越变越长。如果实例宕机重启，重放整个 AOF 日志会非常耗时，导致长时间 Redis 无法对外提供服务。所以需要对 <strong>AOF 日志 “瘦身”</strong>。</p><p><strong>Redis</strong> 提供了 <code>bgrewriteaof</code> 指令用于对 AOF 日志进行瘦身。其 <strong>原理</strong> 就是 <strong>开辟一个子进程</strong> 对内存进行 <strong>遍历</strong> 转换成一系列 Redis 的操作指令，<strong>序列化到一个新的 AOF 日志文件</strong> 中。序列化完毕后再将操作期间发生的 <strong>增量 AOF 日志</strong> 追加到这个新的 AOF 日志文件中，追加完毕后就立即替代旧的 AOF 日志文件了，瘦身工作就完成了。</p><h3 id="fsync"><a href="#fsync" class="headerlink" title="fsync"></a>fsync</h3><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_gif/ia1kbU3RS1H7PMcYtBZdH78LrPP2OrMV8OUwLyk4qWaVC5060sJUttyhaL9I9Q4wZPacnWCNwrOUXicRatz5xfmA/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt></p><p>AOF 日志是以文件的形式存在的，当程序对 AOF 日志文件进行写操作时，实际上是将内容写到了内核为文件描述符分配的一个内存缓存中，然后内核会异步将脏数据刷回到磁盘的。</p><p>就像我们 <em>上方第四步</em> 描述的那样，我们需要借助 <code>glibc</code> 提供的 <code>fsync(int fd)</code> 函数来讲指定的文件内容 <strong>强制从内核缓存刷到磁盘</strong>。但 <strong>“强制开车”</strong> 仍然是一个很消耗资源的一个过程，需要 <strong>“节制”</strong>！通常来说，生产环境的服务器，Redis 每隔 1s 左右执行一次 <code>fsync</code> 操作就可以了。</p><p>Redis 同样也提供了另外两种策略，一个是 <strong>永不 <code>fsync</code></strong>，来让操作系统来决定合适同步磁盘，很不安全，另一个是 <strong>来一个指令就 <code>fsync</code> 一次</strong>，非常慢。但是在生产环境基本不会使用，了解一下即可。</p><h2 id="Redis-4-0-混合持久化"><a href="#Redis-4-0-混合持久化" class="headerlink" title="Redis 4.0 混合持久化"></a>Redis 4.0 混合持久化</h2><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_gif/ia1kbU3RS1H7PMcYtBZdH78LrPP2OrMV80Hibf7Vu8Lu4eG1IcZRvIMSmperb6OsZD01Oicf9DJG3Oty8jEsCJ13w/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt></p><p>重启 Redis 时，我们很少使用 <code>rdb</code> 来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 <code>rdb</code> 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。</p><p><strong>Redis 4.0</strong> 为了解决这个问题，带来了一个新的持久化选项——<strong>混合持久化</strong>。将 <code>rdb</code> 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是 <strong>自持久化开始到持久化结束</strong> 的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小：</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/ia1kbU3RS1H7PMcYtBZdH78LrPP2OrMV8sicEbY3SLIW8PerMMmjy3A7abvbYXPnRxuWsVLecdjkB36To07BoC5g/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p>于是在 Redis 重启的时候，可以先加载 <code>rdb</code> 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。</p><h1 id="相关阅读"><a href="#相关阅读" class="headerlink" title="相关阅读"></a>相关阅读</h1><ol><li><p><a href="http://mp.weixin.qq.com/s?__biz=MzUyMTg0NDA2Ng==&amp;mid=2247483990&amp;idx=1&amp;sn=513e18c063d32a33a4c819a15fe79afe&amp;chksm=f9d5a65bcea22f4d92563d8ac84cb88d7c2e14507b398a5639d569b575b64c368175f00756ab&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Redis(1)——5种基本数据结构</a></p></li><li><p><a href="http://mp.weixin.qq.com/s?__biz=MzUyMTg0NDA2Ng==&amp;mid=2247484000&amp;idx=1&amp;sn=a7e02adebea31535c3870cc514719493&amp;chksm=f9d5a66dcea22f7b7cdf210993cbe6c057c0456967ac106d76c89fdd76ed5cb271c879a83f3e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Redis(2)——跳跃表</a></p></li><li><p><a href="http://mp.weixin.qq.com/s?__biz=MzUyMTg0NDA2Ng==&amp;mid=2247484005&amp;idx=1&amp;sn=0dcb0eb3f79649e0233a79d40094019a&amp;chksm=f9d5a668cea22f7e9a2b9b3a1a5659286bdb8ee9ac19192d74675c6c124be73c6c032b094e60&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Redis(3)——分布式锁深入探究</a></p></li><li><p><a href="http://mp.weixin.qq.com/s?__biz=MzUyMTg0NDA2Ng==&amp;mid=2247484012&amp;idx=1&amp;sn=3624989d388d17331e1f7ad78fc7a257&amp;chksm=f9d5a661cea22f7781ed997d05afee8f28da52a0013691961915a2831780e481ae94b6e9a1ae&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Reids(4)——神奇的HyperLoglog解决统计问题</a></p></li><li><p><a href="http://mp.weixin.qq.com/s?__biz=MzUyMTg0NDA2Ng==&amp;mid=2247484022&amp;idx=1&amp;sn=a98c479b4cac96c6af45f219a7c0bde4&amp;chksm=f9d5a67bcea22f6d03b30ce8660f3f3ded294390fd394e138a40a439d0f96d56c8dda2082203&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Redis(5)——亿级数据过滤和布隆过滤器</a></p></li><li><p><a href="http://mp.weixin.qq.com/s?__biz=MzUyMTg0NDA2Ng==&amp;mid=2247484027&amp;idx=1&amp;sn=6237212c01a009be9a5ca88e0e50a46d&amp;chksm=f9d5a676cea22f603e06d1e61d6293985c8ddb063621b1cdf2696da2eaeb1681e307ef2a3f20&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Redis(6)——GeoHash查找附近的人</a></p></li></ol><h1 id="扩展阅读"><a href="#扩展阅读" class="headerlink" title="扩展阅读"></a>扩展阅读</h1><ol><li><p>Redis 数据备份与恢复 | 菜鸟教程 - <a href="https://www.runoob.com/redis/redis-backup.html" target="_blank" rel="noopener">https://www.runoob.com/redis/redis-backup.html</a></p></li><li><p>Java Fork/Join 框架 - <a href="https://www.cnblogs.com/cjsblog/p/9078341.html" target="_blank" rel="noopener">https://www.cnblogs.com/cjsblog/p/9078341.html</a></p></li></ol><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><p>Redis persistence demystified | antirez weblog (作者博客) - <a href="http://oldblog.antirez.com/post/redis-persistence-demystified.html" target="_blank" rel="noopener">http://oldblog.antirez.com/post/redis-persistence-demystified.html</a></p></li><li><p>操作系统 — fork()函数的使用与底层原理 - <a href="https://blog.csdn.net/Dawn_sf/article/details/78709839" target="_blank" rel="noopener">https://blog.csdn.net/Dawn_sf/article/details/78709839</a></p></li><li><p>磁盘和内存读写简单原理 - <a href="https://blog.csdn.net/zhanghongzheng3213/article/details/54141202" target="_blank" rel="noopener">https://blog.csdn.net/zhanghongzheng3213/article/details/54141202</a></p></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;好文转载&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.wmyskxz.com/2020/03/13/redis-7-chi-jiu-hua-yi-wen-liao-jie/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://www.wm
      
    
    </summary>
    
      <category term="redis" scheme="http://zhangyu8.me/categories/redis/"/>
    
    
      <category term="redis" scheme="http://zhangyu8.me/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>被忽视的time命令</title>
    <link href="http://zhangyu8.me/2020/01/10/%E8%A2%AB%E5%BF%BD%E8%A7%86%E7%9A%84time%E5%91%BD%E4%BB%A4/"/>
    <id>http://zhangyu8.me/2020/01/10/被忽视的time命令/</id>
    <published>2020-01-10T09:13:47.000Z</published>
    <updated>2020-01-10T09:12:21.608Z</updated>
    
    <content type="html"><![CDATA[<p>火丁笔记<br> <a href="https://blog.huoding.com/2019/12/08/788" target="_blank" rel="noopener">https://blog.huoding.com/2019/12/08/788</a> </p><p> 如果要选 Linux 下最容易被忽视的命令，time 应该算一个。简单来说，它是一个用来计算命令运行时间的工具，之所以说它容易被忽视，一方面很多人根本不知道 time 的存在，而是习惯在命令启动前后记录两个时间戳，然后手动计算命令运行时间；另一方面很多人虽然知道 time 的存在，但是却并没有真正理解它的含义。</p><p> 下面让我们通过若干例子来理解 time 的真正含义：</p><p> #time ls</p><p> real    0m0.003s<br> user    0m0.001s<br> sys    0m0.002s</p><p> 大概意思是 ls 命令运行花了 0.003 秒，其中用户态花了 0.001 秒，内核态花了 0.002 秒，看上去似乎「real = user + sys」？此等式是否成立，在回答这个问题之前我们不妨看看 real、user、sys 的确切含义，如下定义源自 <a href="https://stackoverflow.com/questions/556405/what-do-real-user-and-sys-mean-in-the-output-of-time1" target="_blank" rel="noopener">Stackoverflow</a>：</p><ul><li><p>Real is wall clock time – time from start to finish of the call. This is all elapsed time including time slices used by other processes and time the process spends blocked (for example if it is waiting for I/O to complete).</p></li><li><p>User is the amount of CPU time spent in user-mode code (outside the kernel) within the process. This is only actual CPU time used in executing the process. Other processes and time the process spends blocked do not count towards this figure.</p></li><li><p>Sys is the amount of CPU time spent in the kernel within the process. This means executing CPU time spent in system calls within the kernel, as opposed to library code, which is still running in user-space. Like ‘user’, this is only CPU time used by the process.</p><p>总的来说，real 是我们直观感受到的消耗的时间，如果命令运行时被堵塞了，那么堵塞时间也是被统计在内的， user 统计在用户态态模式下消耗的 CPU 时间，如果命令运行时被堵塞了，那么堵塞时间并不被统计在内，sys 统计在内核态模式下消耗的 CPU 时间，如果命令运行时被堵塞了，那么堵塞时间并不被统计在内。</p><p>看上去是否统计堵塞时间是区分 real 和 user、sys 的关键，看看下面这个 sleep 例子：</p><p>#time sleep 1</p><p>real    0m1.002s<br>user    0m0.001s<br>sys    0m0.001s</p><p>那么除了堵塞时间，还有别的关键点么，让我们再看看下面两个例子：</p><p>#time find /etc -type f | xargs -n1 -I{} cat {}  /dev/null</p><p>real    0m2.050s<br>user    0m0.626s<br>sys    0m1.533s</p><p>#time find /etc -type f | xargs -n1 -I{} -P2 cat {}  /dev/null</p><p>real    0m1.079s<br>user    0m0.681s<br>sys    0m1.486s</p><p>前后两个例子的区别在于后者在使用 xargs 的时候通过「-P」选项激活了多进程，换句话说，后者可以同时用到多个 CPU。</p><p>了解了相关知识之后，我们通过 real、user、sys 的大小就可以判断程序的行为：</p></li><li><p>如果 real 远远大于 user + sys，那么说明程序可能有严重的堵塞问题。</p></li><li>如果 real 基本等于 user + sys，那么说明程序可能没有用到多 CPU 能力，</li><li><p>如果 real 远远小于 user + sys，那么说明程序可能用到了多 CPU 能力。</p><p>怎么样？看似简单的 time 命令，是不是远比你想的要复杂得多！</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;火丁笔记&lt;br&gt; &lt;a href=&quot;https://blog.huoding.com/2019/12/08/788&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://blog.huoding.com/2019/12/08/788&lt;/a&gt; &lt;/p
      
    
    </summary>
    
      <category term="好文转载" scheme="http://zhangyu8.me/categories/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/"/>
    
    
      <category term="好文转载" scheme="http://zhangyu8.me/tags/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>使用简单的逻辑方法进行独立思考</title>
    <link href="http://zhangyu8.me/2020/01/10/%E4%BD%BF%E7%94%A8%E7%AE%80%E5%8D%95%E7%9A%84%E9%80%BB%E8%BE%91%E6%96%B9%E6%B3%95%E8%BF%9B%E8%A1%8C%E7%8B%AC%E7%AB%8B%E6%80%9D%E8%80%83/"/>
    <id>http://zhangyu8.me/2020/01/10/使用简单的逻辑方法进行独立思考/</id>
    <published>2020-01-10T09:04:47.000Z</published>
    <updated>2020-01-10T09:07:14.140Z</updated>
    
    <content type="html"><![CDATA[<p>使用简单的逻辑方法进行独立思考<br> 酷 壳 - CoolShell<br><a href="https://coolshell.cn/articles/20533.html" target="_blank" rel="noopener">https://coolshell.cn/articles/20533.html</a></p><p> 这是一个非常复杂的世界，这个世界上有很多各式各样的观点和思维方式，作为一个程序员的我，也会有程序员的思维方式，程序员的思维方式更接近数学的思维方式，数学的思维方式让可以很容易地理清楚这个混乱的世界，其实，并不需要太复杂的数学逻辑，只需要使用一些简单的数学方法，就可以大幅提升自己的认识能力，所以，在这里，记录一篇我自己的思维方式，一方面给大家做个参考，另一方面也供更高阶的人给我进行指正。算是“开源我的思维方式”，开放不仅仅是为了输出，更是为了看看有没有更好的方式。</p><p> 我的思维方式中，使用数学逻辑的方式进行思考，通常来说，我会使用五步思考的方式：</p><p> <strong>第一步：信息数据可考证</strong>。如果一个观点或是一个见解的数据是错误的，那么就会造成后面的观点全是错的，所以，首要的是要进行数据的查证或考证。一般来说，如果一篇文章的作者足够严谨的话，他的需要给他的数据建立相关的引用或是可以考证的方法方式。如果一篇文章中出现的是，“有关专家表明”、“美国科学家证明”、“经济学家指出”，但是没有任出处，也没有点明这个专家或是科学家的名字，或是，也没有说明或引用让读者可以自己去验证的方法。那么，其引用的话或是数据是无法考证的，如果是无法考证的，那么，这篇文章的水份就非常大了。一般来说，当我读到一篇文章中的东西没有可考证的来源或是方法时，通常来说，我就不会再读了，因为这篇文章的价值已经不大了，如果我关心这篇文章中的东西，我会改为自己去查找的方式，虽然变“重”了，但是很安全。（所以，像Wikipedia这样的网站是我经常去获得信息的地方，因为信息可以被考证是其基本价值观）</p><p> <strong>第二步：处理集合和其包含关系</strong>。这是一个非常简单的人人都会的数学逻辑。比如：哲学家是人，柏拉图是哲学家，所以，柏拉图是人。就是一个在包含关系下的推理。你不要小看这个简单的逻辑，其实很多人并不会很好的应用，相反，当感情支配了他们以后，他们会以点代面，以特例代替普遍性。比如，地图炮就是一种，他们看到了多个案例，他们就开始把这个案例上升上更大的范围，比如：河南人新疆人都是小偷，上海人都是小市民。日本人都是变态和反人类……等等。除了这些地图炮外，还有否定整个人的，比如一个人犯了个错或是性格上有缺陷，就会把整个人全盘否定掉，员工抢个月饼就上升到其价值观有问题……。在数学的逻辑包含中，超集的定义可以适用于子集，通过子集的特征可以对超集进行探索，但是没法定义超集。另外，集合的大小也是一个很重要的事，<a href="https://zh.wikipedia.org/wiki/%E5%80%96%E5%AD%98%E8%80%85%E5%81%8F%E5%B7%AE" target="_blank" rel="noopener">幸存者偏差</a>会是一个很容易让人掉下去的陷阱，因为可能会有很大的样本集可能在你的视线盲区。</p><p> <strong>第三步：处理逻辑因果关系</strong>。所谓因果关系，其实就是分辨充分条件、必要条件和充分必要条件，然后处理其中的逻辑是否有关联性，而且有非常强的因果关系。没有能力分辨充分必要条件处理因果关系是很多人的硬伤。就像我在《<a href="https://coolshell.cn/articles/19271.html" target="_blank" rel="noopener">努力就会成功</a>》中说的一样，“努力” 和 “成功”是否有因果关系？各种逻辑混淆、概念偷换、模糊因果、似是而非全是在这里。比如：掩耳盗铃、刻舟求剑就是因果关系混乱的表现。人们会经常地混淆两个看来一起发生，但是并没有关联在一起的事。因果关系是最容易被模糊和偷换的，比如：很多人都容易混淆“加班”就会有“产出”，混淆了“行动”就会有“结果”，混淆了“抵制”就会赢得“尊重”，混淆了“批评”等于“反对”……等等。除了这些以外，微信公众号里的很多时评文章，他们的文章中的结论和其论据是没有因果关系的，好多文章就是混淆、模糊、偷换……<strong>因果关系出问题的文章读多了是对大脑有损伤的，要尽量远离</strong>。</p><p> <strong>第四步：找到靠谱的基准线</strong>。就像我们写代码一样，我们都是会去找一些最佳实践或是业内标准，原因是因为，这样的东西都是经过长时间被这个世界上很多人Review过的，是值得依赖和靠谱的，他们会考虑到很多你没有考虑过的问题。所以，你也会看到很多时评都会找欧美发达国家的作参考的做法，因为毕竟人家的文化是相对比较文明、科学、开放和先进的。找到世界或是国际的通行标准，会更容易让人进步。比如：以开放包容加强沟通的心态，就会比封闭抵制敌对的心态要好得多得多，智者建桥，愚者建墙。当然，我们也开始发现，有一些事上，有利于自己的就对标，不利于自己的就不对标，而且，除了好的事，不好的事也在找欧美作对标，于是开始“多基准线”和“乱基准线”，这种方式需要我们小心分辨。</p><p> <strong>第五步：更为深入和高维的思考</strong>。如果一件事情只在表面上进行思考其实只是一种浅度思考，在Amazon，线上系统出现故障的时候，需要写一个Correction of Errors的报告，其中需要Ask 5 Whys（参看 Wikipedia 的 <a href="https://en.wikipedia.org/wiki/Five_whys" target="_blank" rel="noopener">Five Whys 词条</a>），这种思考方式可以让你不断追问到深层次的本质问题，会让你自己做大量的调查和研究，让你不会成为一个只会在表面上进行思考的简单动物。比如：当你看到有出乎你意料的事件发生时（比如负面的暴力事件），你需要问一下，为什么会发生，原因是什么？然后罗列尽可能全的原因，再不断地追问并拷证下去（这跟写程序一样，需要从正向案例和负向案例进行考虑分析，才可能写出健壮性很强的代码），我们才会得出一个比较健壮的答案或结构。</p><p> 需要注意的是，在上述的这五种思维方式下，你的思考是不可能快得起来的，这是一个“慢思考”（注：如果读过《<a href="https://book.douban.com/subject/10785583//" target="_blank" rel="noopener">思考，快与慢</a>》这本书的人就知道我在说什么），独立思考是需要使用大脑中的“慢系统”，慢系统是反人性的，所以，能真正做到独立思考的人很少。更多的人的“独立思考”其实只不过是毫无章法的乱思考罢了。</p><p> 通过上述的这五点，我相信你是很容易识别或是分辨出哪些信息是靠谱的，哪些信息是很扯的，甚至会改善你自己的言论和思考。但是，<strong>请注意，这些方法并不能让你获得真理或是真相</strong>。但是这也够了，一个人如果拥有了能够分辨是非的能力，也是很不错的了。虽然不知道事实是什么，但是你也不会盲从和偏信，从而不会被人煽动，而成为幕后黑手的的一只“肉鸡”。</p><p> 多说两句，下面是一些我个人的一些实践：</p><ul><li>当新闻报道报道的不是客观事实，而是加入了很多观点，那么这篇新闻报道是不可信的。</li><li>对于评论性的文章，没有充足权威可信的论据时，不能完全相信。</li><li>不是当事人，不是见证人，还要装作自己是知情的……不知道这种人的自信怎么来的？</li><li>信息不公开的，并有意屏蔽信息的，不能作为可信的信息源。</li><li><p>当出现大是或是大非的事时，一定要非常小心，这个世界不存在完全的美和完全的丑，这样的观点通常来说都是危险的，此时要多看看不同角度的报道和评论，要多收集一些信息，还要多问问为什么。</p><p>欢迎你告诉我一些你的实践和思维方式。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;使用简单的逻辑方法进行独立思考&lt;br&gt; 酷 壳 - CoolShell&lt;br&gt;&lt;a href=&quot;https://coolshell.cn/articles/20533.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://coolshel
      
    
    </summary>
    
      <category term="好文转载" scheme="http://zhangyu8.me/categories/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/"/>
    
    
      <category term="好文转载" scheme="http://zhangyu8.me/tags/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>神器pt-kill</title>
    <link href="http://zhangyu8.me/2019/12/18/%E7%A5%9E%E5%99%A8pt-kill/"/>
    <id>http://zhangyu8.me/2019/12/18/神器pt-kill/</id>
    <published>2019-12-18T03:13:41.000Z</published>
    <updated>2020-01-10T06:51:32.836Z</updated>
    
    <content type="html"><![CDATA[<p>pt-kill是percona-toolkit中的一个工具，用来杀掉指定匹配条件的慢查询会话</p><p><a href="https://www.percona.com/doc/percona-toolkit/3.0/pt-kill.html" target="_blank" rel="noopener">https://www.percona.com/doc/percona-toolkit/3.0/pt-kill.html</a></p><p>##一、Percona Toolkit安装：<br> wget <a href="https://www.percona.com/downloads/percona-toolkit/3.1.0/binary/redhat/7/x86_64/percona-toolkit-3.1.0-2.el7.x86_64.rpm" target="_blank" rel="noopener">https://www.percona.com/downloads/percona-toolkit/3.1.0/binary/redhat/7/x86_64/percona-toolkit-3.1.0-2.el7.x86_64.rpm</a></p><p>yum install -y perl-CPAN perl-Time-HiRes<br>yum install -y percona-toolkit-3.1.0-2.el7.x86_64.rpm</p><p>##注意 pt-kill 运行会报错“Wide character in printf ”</p><p>在第二行前插入use open “:std”, “:encoding(UTF-8)”;<br> 执行<br>sed -i ‘2 i\use open “:std”, “:encoding(UTF-8)”;’   /usr/bin/pt-kill </p><p>##二、下面将pt-kill操作的日志记录在数据库中<br>在目标数据库里执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">CREATE DATABASE ptkill DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;</span><br><span class="line"></span><br><span class="line">use ptkill;</span><br><span class="line"></span><br><span class="line">也可以使用--create-log-table  自动创建表</span><br><span class="line"></span><br><span class="line">CREATE TABLE kill_log (</span><br><span class="line">   kill_id     int(10) unsigned NOT NULL AUTO_INCREMENT,</span><br><span class="line">   server_id   bigint(4) NOT NULL DEFAULT &apos;0&apos;,</span><br><span class="line">   timestamp   DATETIME,</span><br><span class="line">   reason      TEXT,</span><br><span class="line">   kill_error  TEXT,</span><br><span class="line">   Id          bigint(4) NOT NULL DEFAULT &apos;0&apos;,</span><br><span class="line">   User        varchar(16) NOT NULL DEFAULT &apos;&apos;,</span><br><span class="line">   Host        varchar(64) NOT NULL DEFAULT &apos;&apos;,</span><br><span class="line">   db          varchar(64) DEFAULT NULL,</span><br><span class="line">   Command     varchar(16) NOT NULL DEFAULT &apos;&apos;,</span><br><span class="line">   Time        int(7) NOT NULL DEFAULT &apos;0&apos;,</span><br><span class="line">   State       varchar(64) DEFAULT NULL,</span><br><span class="line">   Info        longtext,</span><br><span class="line">   Time_ms     bigint(21) DEFAULT &apos;0&apos;, # NOTE, TODO: currently not used</span><br><span class="line">   PRIMARY KEY (kill_id)</span><br><span class="line">) DEFAULT  CHARSET=utf8mb4 COLLATE utf8mb4_unicode_ci</span><br></pre></td></tr></table></figure></p><p>##执行<br>pt-kill  –host 192.168.1.1 –port 3306 –user ‘root’ –password ‘123456’ –charset utf8 –log-dsn D=ptkill,t=kill_log –match-info “SELECT|select” –busy-time 5  –victims all –interval 5 –print –kill-query –daemonize </p><p>说明</p><p>–log-dsn D=ptkill,t=kill_log   将pt-kill操作的日志记录在表中</p><p>–busy-time=5 执行时间超过5秒的<br>–print –kill-query   动作是 进行print和 kill query，<br>–match-info ‘SELECT|select’  只匹配SELECT 语句</p><p>#################其他</p><p>py-kill 属于简易版的 pt-kill 工具<br><a href="https://github.com/dongwenpeng/py-kill" target="_blank" rel="noopener">https://github.com/dongwenpeng/py-kill</a></p><p>支持后台或前台运行<br>支持邮件报警<br>支持多线程监控<br>pt-kill常规选项也都支持</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;pt-kill是percona-toolkit中的一个工具，用来杀掉指定匹配条件的慢查询会话&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.percona.com/doc/percona-toolkit/3.0/pt-kill.html&quot; target=&quot;_bla
      
    
    </summary>
    
      <category term="tools" scheme="http://zhangyu8.me/categories/tools/"/>
    
    
      <category term="tools" scheme="http://zhangyu8.me/tags/tools/"/>
    
  </entry>
  
  <entry>
    <title>邓宁-克鲁格效应</title>
    <link href="http://zhangyu8.me/2019/10/12/%E9%82%93%E5%AE%81-%E5%85%8B%E9%B2%81%E6%A0%BC%E6%95%88%E5%BA%94/"/>
    <id>http://zhangyu8.me/2019/10/12/邓宁-克鲁格效应/</id>
    <published>2019-10-12T04:13:47.000Z</published>
    <updated>2020-01-10T06:52:58.638Z</updated>
    
    <content type="html"><![CDATA[<p>好文转载</p><p><a href="https://www.jianshu.com/p/cf56ffebf9f2" target="_blank" rel="noopener">https://www.jianshu.com/p/cf56ffebf9f2</a></p><p><a href="https://www.jianshu.com/p/d3c5f798134a" target="_blank" rel="noopener">https://www.jianshu.com/p/d3c5f798134a</a></p><p><a href="https://www.jianshu.com/p/cf56ffebf9f2" target="_blank" rel="noopener">邓宁-克鲁格效应 - 简书</a></p><p> <img src="https://upload-images.jianshu.io/upload_images/6198628-cb79177413c0cdcf.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1078" alt></p><p> <img src="https://upload-images.jianshu.io/upload_images/6198628-4290120f0e93f00d.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/559" alt></p><p> <img src="https://upload-images.jianshu.io/upload_images/6198628-959438c9e29ddd2d.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200" alt></p><h1 id="愚昧颠覆："><a href="#愚昧颠覆：" class="headerlink" title="愚昧颠覆："></a>愚昧颠覆：</h1><p> 在图中，把高考完作为一个愚昧巅峰， 如果从进入社会的角度来说的话，确实 这是一个节点。 用通俗的话来说，这个点是不知道自己知道，或者说 以为世界是这样的，然后其实不是。 从思维角度来说， 这是一个思维被打破的时候， 认知发生了崩溃。</p><h1 id="绝望之谷："><a href="#绝望之谷：" class="headerlink" title="绝望之谷："></a>绝望之谷：</h1><p> 认知崩溃的过程非常的快， 就像摩天大厦的地基被打破了， 大厦将倾确实非常快。直到某一天 认知完全崩溃，开始建立新的认知。</p><h1 id="开悟之坡："><a href="#开悟之坡：" class="headerlink" title="开悟之坡："></a>开悟之坡：</h1><p> 这是一个慢慢重新构建认知的过程， 也是对思维模式进行重构。 而且是一点点，通过知识和经验慢慢重构。<br> 而大师就这事在不断重构的过程中慢慢完善自己的新的认知。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p> 总的来说，这个是一个升级的过程。 按照 <strong>原则</strong> 上面来说 这也是一个 <code>痛苦+反思=进步</code> 的过程。<br> 这个过程需要 极度透明的自我审查和谦虚的心态。</p><p>##########<br>DK效应图（图一）是在国外加工版（图二）的翻译基础上的夹带私货版，我猜测出自于那些目前流行的禅旗培训机构。</p><p> 图二在图三的基础上进行了加工，但这种篡改别人的理论的做法挺流氓的。</p><p> 图三是原版图。</p><p> 下面转述一下维基百科的内容：</p><p> 达克效应（英语：D-K effect），全称为邓宁-克鲁格效应（英语：Dunning–Kruger effect），是一种认知偏差，能力欠缺的人有一种虚幻的自我优越感，错误地认为自己比真实情况更加优秀。简言之即：庸人容易因欠缺自知之明而自我膨胀。  </p><p> Kruger和Dunning将其归咎于元认知上的缺陷，能力欠缺的人无法认识到自身的无能，不能准确评估自身的能力。他们的研究还表明，反之，非常能干的人会低估自己的能力，错误地假定他们自己能够很容易完成的任务，别人也能够很容易地完成。[1]康奈尔大学的David Dunning和Justin Kruger于1999年首次在实验中观测到此认识偏差。</p><p> Kruger和Dunning通过对人们阅读、驾驶、下棋或打网球等各种技能的研究发现：</p><p> 1. 能力差的人通常会高估自己的技能水准；</p><p> 2. 能力差的人不能正确认识到其他真正有此技能的人的水准；</p><p> 3. 能力差的人无法认知且正视自身的不足，及其不足之极端程度；</p><p> 4. 如果能力差的人能够经过恰当训练大幅度提高能力水准，他们最终会认知到且能承认他们之前的无能程度。</p><p> Dunning和Kruger认为这种效应是由于能力欠缺者的内在错觉和能干者对外界的错误认知：“无能者的错误标度源自于对自我的错误认知，而极有才能者的错误标度源自于对他人的错误认知。”[1]</p><p> 虽然达克效应早在1999年就被Dunningt和Kruger两人提出来了，但是虚幻优越性的认知偏差是众所周知的，历史上很多知识分子都说过关于这一方面的话，比如：</p><p> * 孔子（知之为知之，不知为不知，是知也）[2]</p><p> * 威廉莎士比亚 在皆大欢喜《As you like it》（”傻瓜认为自己是明智的，而聪明的人认为自己是个傻瓜”）[3]</p><p> * 查尔斯·达尔文（“无知比知识更容易招致自信”）[4]</p><p> * 伯特兰·罗素（“我们这个时代让人困扰的事之一是: 那些对事确信无疑的人其实很蠢，而那些富有想象力和理解力的人却总是怀疑和优柔寡断”）也列为发现这个现象的人。</p><p> Dunning和Kruger因为他们的论文《论无法正确认识能力不足如何导致过高自我评价》，被授予2000年的搞笑诺贝尔奖心理学奖。[5]</p><p> 1^ Kruger, Justin; David Dunning. Unskilled and Unaware of It: How Difficulties in Recognizing One’s Own Incompetence Lead to Inflated Self-Assessments. Journal of Personality and Social Psychology. 1999, 77 (6): 1121–34. PMID 10626367. doi:10.1037/0022-3514.77.6.1121. CiteSeerX: 10.1.1.64.2655.  </p><p> 2^ Dunning, David; Johnson, Kerri; Ehrlinger, Joyce; Kruger, Justin. Why people fail to recognize their own incompetence. Current Directions in Psychological Science. 2003, 12 (3): 83–87 [4 January 2016]. doi:10.1111/1467-8721.01235. （原始内容 (abstract)存档于2016年1月14日）.</p><p> 3^ Fuller, Geraint. Ignorant of ignorance?. Practical Neurology. 2011-12-01, 11 (6): 365–365. ISSN 1474-7758. PMID 22100949. doi:10.1136/practneurol-2011-000117 （英语）.</p><p> 4^ volume I, “Introduction”, page 3. [2018-11-23].</p><p> 5^ Ig Nobel Past Winners. [2011-03-07].</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;好文转载&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/cf56ffebf9f2&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.jianshu.com/p/cf56ffebf9f2&lt;/a&gt;&lt;/p
      
    
    </summary>
    
      <category term="好文转载" scheme="http://zhangyu8.me/categories/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/"/>
    
    
      <category term="好文转载" scheme="http://zhangyu8.me/tags/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>IT从运维到运营</title>
    <link href="http://zhangyu8.me/2019/10/11/IT%E4%BB%8E%E8%BF%90%E7%BB%B4%E5%88%B0%E8%BF%90%E8%90%A5/"/>
    <id>http://zhangyu8.me/2019/10/11/IT从运维到运营/</id>
    <published>2019-10-11T02:13:47.000Z</published>
    <updated>2020-01-10T06:52:27.101Z</updated>
    
    <content type="html"><![CDATA[<p>IT：从运维到运营</p><p>作者为优锘科技CEO陈傲寒</p><h2 id="IT运维？IT运营？"><a href="#IT运维？IT运营？" class="headerlink" title="IT运维？IT运营？"></a>IT运维？IT运营？</h2><p> 都是 IT Operations，有什么区别？</p><p> IT运维管理？IT运营管理？</p><p> 都是 ITOM，有什么区别？</p><p> 一字之差，只是翻译不同，还是另有玄机？</p><p> 其实，中文真的是一门更精确的语言 :-)</p><ul><li>IT运维是“活着”，IT运营是“活得好”；</li><li>IT运维更多是被动式“维持”，IT运营更多是主动式“经营”；</li><li>IT运维更多是面向基础设施面向软硬件，IT运营更多是面向业务面向服务面向人；</li><li>IT运维的关键词是“稳定”、“安全”、“可靠”；IT运营的关键词是“体验”、“效率”、“效益”；</li><li><p>IT运维管理工具更多是关注故障防范和修复的“监管控”，IT运营管理工具开始更多应用性能、用户感知、快速交付、数据分析和可视化。。。</p><p>企业IT正站在这样一个拐点上，要么从运维走向运营，要么从运维走向被代维</p><p><strong>正文之前的说明：IT运维和 IT运营都非常重要，运维是运营的基础，任何一个组织，首先是要活着，之后才要追求活得好，是 IT Operations的不同发展阶段，今天的 IT运维部门的工作内容其实包括本文所说的 IT运营。</strong></p><p>大多数ITOM领域的从业者，一直以来都约定俗成地把ITOM（IT Operation Management）翻译成IT运维管理，相应的也把IT Operations叫做IT运维。近两年来，开始有越来越多的人使用“IT运营管理”和“IT运营”这样的说法，对应的英文是一样的，但这里“运维”和“运营”是同样的意思吗？两者之间有什么异同？</p><p>关于这个问题，仁者见仁智者见智。有人认为其实运维就是运营，用个新名词只是哗众取宠的噱头而已；有人认为运维是面向IT设施的，运营是面向业务服务的；有人认为运维是关注IT指标，运营是关注业务指标的；甚至有人说，运维是“眼前的苟且”，运营是“诗和远方”:-)</p><p>总体来看，大多数人认为两者含义并不完全一样，很多人都认为IT运营比IT运维的层次更高，有些成熟度较高的大型IT组织已经提出并在执行“从IT运维到IT运营”的发展规划。但即使在提出这类理念和计划的组织内部，对于究竟什么是IT运维管理，什么是IT运营管理，也还没有非常清晰的分析和定义，更多的是将传统IT运维管理领域之外的一些新内容笼统的归到IT运营管理的部分里去。我在和某个正在执行此规划的IT组织中的某位高管交流时，他就提到：“From Operations to Operations？连定义都没搞清楚，怎么能成为指导方向和发展目标？”</p><p>他的问题让我这个ITOM的老兵也开始思考“IT运营”这个新“翻译”的真正含义，以及近几年来它日益流行的真实原因，在和许多同业交流之后，笔者在此分享一下我关于这个问题的一些想法和心得，作引玉之砖，希望能带来更多同业的讨论和指教。</p><p>首先，IT运维和IT运营，英文都是IT Operations，在老外来看，并无区别，是指关于IT运行的所有事情。而中文之所以有两种不同的翻译，是因为IT Operations包括的内容很多，IT运维和IT运营两种中文译法分别侧重其中某一部分的内容，假如归纳成一句话的话，可以说IT运维管理关注的是“活着”，而IT运营管理则有更高层次的需求，不仅要“活着”，还要“活得好”。</p><p>先看个实例，某大型数据中心IT服务能力的愿景是“以业务为中心，交付稳定、安全、高效的IT运营服务，构建业界领先的IT运营能力，支撑企业的持续发展和战略成功。”这个愿景中，“稳定、安全”就是解决活着的问题，属于传统IT运维管理的范畴，“以业务为中心”、“高效”、“业界领先”则属于如何“活得好”的范畴，更多的是IT运营管理的范畴。</p><p>能力建设是有循序渐进的过程的，任何一个组织，首先都要解决“活着”的问题，然后才有可能追求“活得好”，因此，过去三十年，在大多数IT组织面临IT设施规模快速扩张，IT应用数量不断增多，IT运行压力越来越大的挑战时，首先要确保IT系统“活着”，也就是能够持续“运行”，稳定“运转”，通过日常“维护”工作让系统少出故障，出了故障能快速“维修”，“维持”系统的正常“运转”。这个阶段把IT Operations翻译成IT运维，把ITOM翻译成IT运维管理，无可厚非。</p><p>IT运维管理阶段的关键词是“稳定”、“安全”、“可靠”，关注可用性指标（MTTR、MTTF、MTBF等）、可靠性指标（RTO、RPO）和安全合规。相应地，在技术、工具和流程上，都以稳定、安全、可靠作为最优先考虑的要素：</p></li><li><p><strong>技术上</strong>，倾向选择稳定成熟的技术架构和产品，愿意为提升可靠性支付大量溢价，上得起小型机的就上小型机，买得起大机那就大机，能备份的地方就备份，尽量采用全冗余架构；</p></li><li><strong>流程上</strong>，首先从事件管理和变更管理做起，主要目标是能确保故障事件得到追踪和及时解决，以及管控变更避免人为故障多发，关注重点还是在提升可用性；</li><li><p><strong>工具上</strong>，采用“监-管-控”架构，其中监控更关注设备级监控，重点发现故障节点，“管”就是配合实现变更和事件流程，至于“控”，此时上配置自动化工具，更关心的是实现配置的标准化和合规检查，重点还是在增强可靠性减少故障，而非减少运维人员工作量。</p><p>在以“活着”为主要目标，以“稳”为主要形态的IT运维和IT运维管理发展多年后，越来越多的IT组织开始走出这个解决基本生存需求的阶段，从“被动维持”走向“主动经营”，追求如何“活得好”，近十年来，APM、BSM、云计算、运维大数据等新的理念、技术和工具的出现、发展和变迁，都和IT正逐步开始从运维走向运营有密切关系，时至今日，从全局角度来看，可以说企业IT已经站在了从运维到运营的一个重要拐点上。</p><p>IT运营是建立在良好的IT运维的基础上的，没有“活着”，“活得好”就无从谈起。 但怎样才叫活得好呢？ 换言之，IT运营追求的目标究竟是什么？比IT运维多了哪些东西呢？</p><p>与IT运维更多地是面向基础设施不同，IT运营更多的是面向业务、面向服务，本质上是面向人。我们说某个人活得好不好，如何判断呢？大多数人认同的马斯洛需求层次理论说，在解决了基本的生存问题和安全感之后，一个人要感觉自己活得好，是需要有社会认同和自我实现的。对于CIO来说，他所管理的IT组织假如能让三类人满意，我们就可以说这个IT组织已经从基本的IT运维阶段走到IT运营阶段，已经处在活得好的状态了。</p><p>哪三类人呢？</p><p><strong>用户、老板和IT人。</strong>假如IT组织是一个独立公司的话，这三类人基本对应着客户、股东和员工，CIO如果是公司老板，就会知道其实这三类人是哪个都得罪不起的：客户不满意会流失，企业就没有生存之本；股东不满意会换人，说明企业没有竞争力；员工不满意会换地儿，企业就缺乏持久发展的能力。尽管行业特点和企业文化不同会带来优先级和侧重点的不同，但本质上，一个有长远发展前景的卓越公司，往往是做到了让客户、股东和员工都满意的公司。</p><p>IT运维阶段，IT组织更多地还是在解决三类人的基本需求，让用户能用，让老板批钱，让员工干活，当然也希望大家更满意，但受限于阶段性能力和各方面因素，先能保证这些基本需求就已经很不容易了，而做到这些，在相当长时间内也已经足够，主要因为几个原因：</p></li><li><p>各企业信息化之初，能够利用IT实现对业务和管理流程的优化、固化和自动化，就已经达到目标；</p></li><li>初期系统以内部员工为主要用户，且没有同类系统做对比，用户对系统效率和体验的容忍度高；</li><li><p>IT部门在企业内部的IT能力供给上基本是垄断的，用户没有其它选择。</p><p>因此，过去虽然IT部门提供的即使只是满足基本需求的服务，大多数情况下也并没有多大问题。但短短十年间，互联网和移动互联网大潮席卷世界的每个角落，每天用着微信滴滴淘宝携程的用户们的胃口已经越来越高了，过去能够忍受的一些小问题也已经变得忍无可忍了：</p></li><li><p>人家网站那么快，咱们的系统怎么都是老和尚，点一下鼠标要等一炷香才动一下？</p></li><li>人家网站第一次用没人教我就全部自己搞定，咱们系统怎么培训几回我都搞不清怎么用？</li><li>人家网站一看就是赏心悦目高大上，咱们系统怎么就总是Low逼的不行？</li><li><p>人家网站免费邮箱都无限容量，咱们怎么花那么多钱还每人限收发10M内邮件？</p><p>不知从哪天起，过去和企业IT八竿子打不着的“人家”一下子蹦出来，成了IT部门的变相竞争对手了，没抢走用户，但把用户满意度抢走了。更要命的是，随着云计算各种aaS的风起云涌，这些“人家”未来没准儿真的要来抢走用户了。假如IT部门不能与时俱进，还是停留在满足基本需求的运维上，而不主动向追求卓越的运营迈进，提供更有竞争力的优质IT服务，那就很可能会在几年后会碰到更大的挑战。</p><p>而在IT运营阶段，与IT运维阶段的关键词“稳定”、“安全”、“可靠”不同，关注的关键词变成了“体验”、“效率”、“效益”。回顾前面我们提到某大型数据中心的愿景中“以业务为中心”、“高效”两个运营关键词，其实“以业务为中心”就对应着“以用户为中心”，业务就是以用户为中心的吗，而用户关心的就是体验（稳定可靠也是体验的一部分）。“高效”则包含着高效率和高效益两个含义，一个关注敏捷性，交付速度、响应速度，一个关注成本收益，关注服务获取效率。</p><p>（假如说IT运维以“稳”为主，那么IT运营则以”敏“为主，在技术架构选择和IT管理流程和系统的建设上面，IT运营阶段都和传统IT运维阶段的关注重点有所转变，从而带来了新旧架构、新旧工具、新旧方法并存甚至交汇的复杂情况，Gartner在提的Bimodal，联想所说的双态IT，也都在反映这种状态。）</p><p>让我们围绕三类人的需求简单看看IT运营比之IT运维阶段要面临的新挑战，以及应对挑战在出现的一些新的理念、工具和技术：</p><h3 id="让用户满意"><a href="#让用户满意" class="headerlink" title="让用户满意"></a><strong>让用户满意</strong></h3><p>用户大致有两类，个人用户和业务部门：</p><p><strong>个人用户</strong>，不论是内部用户还是外部用户，更关心的是体验，体验主要是易用性、容错性和响应速度；要提升体验，对于IT运营管理领域就带来了新的要求，要在传统的设备和组件监控的基础上，增加端到端的用户体验感知能力、应用性能的深入探测和分析能力、应用及系统性能瓶颈的发现和优化能力。</p><p>越来越多IT组织开始关注用户体验，从而纷纷部署包括外部模拟仿真探测、流量数据分析、日志数据分析、嵌码采集探测等各种针对应用性能管理的手段工具 ，造就了近年来APM市场热度飙升。</p><p>这些采用不同手段的APM工具虽然有功能重叠的部分，但各有其侧重点，多种工具的部署能带来数据和功能的丰富性和多样性，对于准确测量和提升客户体验是有必要的，事实上在那些特别重视用户体验的IT组织里，已经或者正在进行全方位的工具部署，并在尝试在各种专业分析工具之间架设运营大数据工具，集成多样化数据，提供数据的统一可视化和整合分析等能力，提升故障和优化点的定位分析能力，深度改善用户体验。</p><p><strong>业务部门</strong>，除了关心最终用户的体验，更关心交付效率，与之相应的，IT部门开始在各个环节上采用新架构、新技术和新工具，从各个环节上提升效率，加快业务服务的交付速度。</p></li><li><p><strong>提高采购流程和硬件上架的效率</strong>：IaaS云和资源池模式改变了传统的按需采购模式，通过资源整合，将资源规划和资源准备的工作批量前移，极致地提高了预算、采购和硬件上架的效率；</p></li><li><p><strong>提高系统部署和应用发布更新的效率</strong>：采用各种云管理工具、云管理平台及DevOps工具，通过自动化部署、配置管理等功能组件的组合，或从横向的系统层次上，或从纵向的应用发布运行链条上，或者协同配合，不同程度地提高了应用组件甚至是整个业务系统的交付和发布效率，实现对业务部门交付需求的及时甚至实时响应，达到“敏捷”的程度。</p><h3 id="让老板满意"><a href="#让老板满意" class="headerlink" title="让老板满意"></a><strong>让老板满意</strong></h3><p>让用户满意是让老板满意的基础，假如业务部门天天在老板那儿告状，老板怎么都满意不了。但是即便业务部门都说你好话了，老板就会满意了吗？要是你真的这么认为，说明你太不了解老板这种动物了。</p><p>老板要的不只是结果，也一定会追求高效率和高效益，同样的成果，能否用更低的成本达成？我们现在的成本收益水平，对应业界同行，是人傻钱多还是精明高效？说要追求“业界领先”，怎么就是领先了？不能说技术更新应用更多就是领先吧？总要有个从效益角度的衡量方法吧？假如IT部门是一个独立运营的实体，作为给钱的股东，也是要问这些问题的。</p><p>效益本质上是投资回报率，成本越低，效益越好，做的事情越有用，效益越高。要追求高效益，首先面临的难题是要有一套成本收益的衡量体系，没有量化方法，既搞不清楚IT部门当前在同业中所处的水平，更无法通过指标考核的方式推动IT部门不断提高效益水平。在没有这套衡量体系的时候，往往只能采用一些非常粗线条甚至感性的衡量方式，比如看每年的IT采购金额、IT员工数量、工业标准产品的采购单价等，导致很多IT部门在采购时往往要求厂商保证提供同行业最低价，可当大家都这么要求的时候，显然很难真正起到效果。更为重要的是，由于每个企业在业务和IT服务方面存在的差异性，这些粗线条指标并不能反映IT部门的效率和效益水平。</p><p>ITIL体系中早就提出了IT服务财务管理的概念，许多IT组织在过去十年尝试了一些BSM（业务服务管理）和ITFM（IT财务管理）的项目，一个重要动因就是试图建立IT效益的衡量体系，可在内部IT部门中成功者寥寥，主要原因是全部精力投入到基础运维工作中还忙不过来，另一方面也和缺乏特别成功的最佳实践有关。</p><p>不过随着大家的不断尝试，伴随近年来IT架构的演进和公有云的兴起，一些走在前面的IT部门已经看到了建立IT效益衡量体系的可能性，并开始在某些架构层级上开始尝试性的探索：他们采用服务分层、成本归集、各自对标的方式，对DC层、IaaS层、PaaS层的资源单位成本、资源利用效率、能源单位成本、能源利用效率和人员运营效率进行分别统计和分析，并分别和IDC、IaaS云、PaaS云的外部供应商市场价位水平做对照，来衡量自己的效率和效益水平。</p><p>IT效益衡量体系的建立，也让IT自己可以从效益角度分解目标，推动IT内各个部门能够逐年不断提升效率和效益水平，让IT部门的思考方式从成本中心转变到利润中心。近年来绿色数据中心概念和PUE指标被关注，都反映了这一变化趋势。</p><p>要注意的是，即使建立了效益衡量体系，要让它真正发挥作用，离不开大量的数据统计和数据分析，以及关键效益指标的可视化和透明化，很多IT组织开始尝试建立IT运维/运营大数据平台，引入可视化和BVD概念，也都和追求IT效益可衡量有密切关系。而这些也会带来额外的投入，IT组织可以根据自身的规模和目标优先级，在有必要的情况下，选择合适和成熟的切入点，分步尝试，逐渐建立效益衡量体系。</p><h3 id="让员工满意"><a href="#让员工满意" class="headerlink" title="让员工满意"></a><strong>让员工满意</strong></h3><p>互联网企业的火热和各行业互联网+的热闹，都带来了IT人才的争夺，如何吸引和保留高素质的IT员工，已经成为许多IT部门不得不面对的新问题。要让IT员工满意，前面的两个满意（用户满意和老板满意）也是个重要基础，否则IT部门自己地位都不高，员工也没有成就感，士气低迷，满意度很难高起来。</p><p>但即使做到了前面两个满意，假如让IT员工每天都疲于奔命，员工满意度同样会差，也不是长久之计。要解决员工满意度的问题，有几个方面是要考虑到的：</p></li><li><p><strong>提高自动化水平</strong>：与运维阶段自动化更关注的是让标准化落地以减少故障不同，运营阶段更关注通过自动化减少员工的重复性劳动，更多地将精力放在能带来更大价值的标准制定和技术优化上面，让IT员工从技术工人变成真正的工程师；（自动化也会带来效益的提升，随着分布式、虚拟化和云计算的普及，自动化已经成为不可或缺的手段，在一些大型互联网公司，人均管理服务器数量早已超过了业界1:200的良好水平）</p></li><li><p><strong>增加人性化因素</strong>：传统运维阶段为了稳定安全不但在软硬件上投入巨大，而且往往在某种程度上不惜增加员工工作的繁琐程度，在人性化方面考虑较少。不少IT组织已经开始从几个方面进行改善：优化流程并引入新工具以减少员工的繁琐文案工作；提供场景化运维能力改善工具的易用性，让IT人员在运维和排障工作中更得心应手，提高IT系统稳定性的同时形成以工作场景为中心的运维方式；与时俱进引入新技术，在保持安全和风控水平的同时改善IT人员的操作复杂度（比如打破僵硬的网络隔离机制、实现移动化运维等）；</p></li><li><p><strong>尝试和引入先进技术</strong>：为追求稳定安全，传统IT运维在技术选择和使用上偏向保守，这固然有其道理，但优秀的IT人往往是对新技术有追求的，在技术演进日新月异、新技术传播和应用速度如飞的今天，假如工作中接触不到新技术新思路，IT人的技术追求被压抑，并往往会伴生强烈的技术危机感，会导致对IT人才吸引力和保持力不够。IT部门应在技术规划中重视这一因素，在保证关键业务稳定运行的前提下，有意识有计划地不断尝试和引进新技术，确保技术的先进性，抛开其它收益不谈，但就提高员工满意度和优秀人才吸引力而言，已经是非常值得的。</p><p>以上从三个满意的角度简单聊了聊从IT运维到IT运营的一些内容，有趣的是，这些满意是递进和包含的关系，让员工满意包括让老板满意，让老板满意包括让用户满意，让业务部门满意包括让个人用户满意，但每个满意之间又都有各自的个性化内容。</p><p>要做到三个满意，让IT从“活着”到“活得好”，从重点“维”稳走向经营业务价值，意味着IT管理要更加精细化、自动化、智能化，也必须建立多样化的数据采集、多维度的数据分析/挖掘和全方位的可视化的能力，IT运营管理的架构也将在传统监管控的IT运维管理架构上有所发展和变化，以适应IT运营在体验、效率和效益方面的更多要求。</p><p>需要注意的是，IT涉及到规划、设计、开发和运营多个环节，我们更多的是从运营的角度来谈的，事实上要从IT运维走向IT运营，不仅需要运营部门（不再只是运维部门啦）的努力，也需要规划、管理和开发部门的协同配合和齐头并进。</p><p>从IT运维到IT运营，其实标志着IT组织成熟度的提升，假如借用Gartner的I&amp;O成熟度模型来看的话，IT运维更多是在前几个阶段，而更多开始关注IT运营，则标志着IT组织走到了后两个阶段：Service Aligned和Business Partnership，开始把IT本身当做业务来运营，以客户为中心，关注客户体验，运营效率和成本收益。</p><p>以上是关于IT运维到IT运营的一些不成熟的思考，抛砖引玉，希望能得到大家的批评和指教。</p><p>从IT运维到IT运营，许多IT组织已经在路上，同样也有许多IT产品和IT服务的提供商已经洞悉到这一发展趋势，配合IT运营的要求，开发和提供了许多新的运营工具和运营服务，我们希望能够与各位有志于ITOM领域的同仁们一起，齐心协力，精益求精，共同提供优秀的ITOM产品和服务，为IT从运维到运营做一点事情，让IT不仅活着，而且要活得好，活得精彩。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;IT：从运维到运营&lt;/p&gt;
&lt;p&gt;作者为优锘科技CEO陈傲寒&lt;/p&gt;
&lt;h2 id=&quot;IT运维？IT运营？&quot;&gt;&lt;a href=&quot;#IT运维？IT运营？&quot; class=&quot;headerlink&quot; title=&quot;IT运维？IT运营？&quot;&gt;&lt;/a&gt;IT运维？IT运营？&lt;/h2&gt;&lt;p&gt;
      
    
    </summary>
    
      <category term="好文转载" scheme="http://zhangyu8.me/categories/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/"/>
    
    
      <category term="好文转载" scheme="http://zhangyu8.me/tags/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>世界上没有技术驱动型公司</title>
    <link href="http://zhangyu8.me/2019/10/10/%E4%B8%96%E7%95%8C%E4%B8%8A%E6%B2%A1%E6%9C%89%E6%8A%80%E6%9C%AF%E9%A9%B1%E5%8A%A8%E5%9E%8B%E5%85%AC%E5%8F%B8/"/>
    <id>http://zhangyu8.me/2019/10/10/世界上没有技术驱动型公司/</id>
    <published>2019-10-10T07:13:47.000Z</published>
    <updated>2020-01-10T06:50:42.182Z</updated>
    
    <content type="html"><![CDATA[<p> 别傻了，你还真相信世界上有技术驱动型公司？ </p><p> 世界上没有技术驱动型公司，不论Google、Facebook，还是腾讯、阿里，都不是技术驱动型公司。<strong>因为技术不是源头，需求才是。</strong></p><p> 因此一切技术问题，都要服从产品交付和市场反馈。所以，任何公司都不可能以技术去驱动自身。人可以以技术驱动自己进步，但公司不行。</p><p> 一家公司可以以技术切入某个市场，但如果它想生存下去，就一定不能以技术为导向，坚持以技术为导向的公司的生命力为零，其下场有两个：破产或者在破产之前被收购。</p><p> 如果你真的很痴迷钻研技术，请读研读博最后留校，或者进研究院让国家用纳税人的钱养你。</p><p> <strong>0x01</strong></p><p> <strong>每个人都得加班</strong></p><p> 资本富集的地方，人都得加班，加班的本质，是人跟着机器跑、人跟着钱跑。</p><p> 更为本质地说，资本富集的地方，人作为劳动力，也是资本的一种。<strong>即人是资本而不是人本身。</strong></p><p> 资本的运转是不能停的，因为停一下损失的钱太多了，中国和外国都一样。</p><p> 知道发达国家为什么产业工人不加班吗？因为制造业已经不是这些国家主要创造财富的领域了。</p><p> 发达国家资本富集的地方是金融行业，所以西方国家的金融狗一样加班。</p><p> 劳动法？加班费？都不存在的。劳动法和加班费只有在资本离开这个市场后才能给你保证。</p><p> 一般公司的策略是：付给你高于其他行业的薪水、换取你“自愿”加班。不想加班的同学们，你们可以去考公务员或者去欧洲做IT，我保证你不加班、不但不用加班，你甚至会很闲。</p><p> <strong>0x02</strong></p><p> <strong>先想后写</strong></p><p> IT是工科，不是理科，和IT行业相似度最高的行业是盖楼房。真的，相似度相当惊人。</p><p> IT领域最重要的是经验，而不是你有多聪明，不聪明的人，或者更准确地说，不适合做这个行业的人，大学毕业后就改行了。</p><p> 记住：你做得好不好，不取决于你是否聪明，而取决于你是否愿意不断读书、不断学习和不断积累。因此，如果你打算投身这个行业，还在学校的话就请抓紧一切时间多读书。</p><p> 公司是你创造财富的地方，公司不是学校。你可以在工作中学习，但你不能放下工作然后去学习，除非你的工作已经做完了。</p><p> <strong>能大规模商用的技术，都不需要智商，否则这种技术就不可能规模化</strong>。某些程序员们，请停止你们的蜜汁自信。</p><p> 技术栈，一旦确立了，就很难改了。一个技术人员是如此，一家公司也是如此。根本原因是：每一个栈的size都太深了，就像是ulimit -s unlimited过一样。</p><p> 一个程序员，应该花80%的时间做代码设计、画UML图、画时序图，20%的时间写Code和Debug，菜鸟程序员的这个比例恰好是反的。</p><p> 一句话，不论这个需求有多紧急，你都一定要“想好再动手”。“想好”的标志就是设计文档写好了，文档一旦写好，写代码就是纯粹的无脑工作。</p><p> 写文档的目的是让你在Code的时候，不需要停下来思考，更不需要推倒重来。如果没有文档也可以做到这一点，你当然可以不写文档，同时思考下自己水平这么高是不是可以要求升职加薪了。</p><p> 或者，你是不是在做无聊的if else编码工作？</p><p> <strong>0x03</strong></p><p> <strong>关注软技能</strong></p><p> 英语，很重要。能否使用英语查阅资料，是区分技术人员水平的重要指示之一。寄希望于“有人迟早会翻译成中文”的人是愚蠢的、是会被淘汰的。</p><p> <strong>要有分享精神，不要担心你知道的东西告诉别人后你就没价值了。你最大的价值在于你知道那些东西的过程，而不是那些东西本身。</strong></p><p> 你愿意和别人分享，别人自然也会愿意和你分享，最终达到1+1大于2的效果。</p><p> 不分享，就像一个失去了互联网的程序员，试问他还能创造多少价值？恐怕他连日常工作都无法展开了。</p><p> 持有“我把别人知道的都学会，把自己知道的都藏起来，别让别人学去”想法的人，其实是默认全世界只有你聪明别人都是傻瓜，这样的人，在信息传输成本高的时代，可以活下去，但是在今天这个时代，他们的路会越走越窄，最后会自己走入死胡同。</p><p> 当然，如果你真的知道了了不得的黑科技，那就请你保护好自己的知识产权，然后自己开公司玩吧。</p><p> <strong>0x04</strong></p><p> <strong>工作要有热情</strong></p><p> 智商决定你的起点，情商决定你能走多远爬多高。混职场，靠的是情商。</p><p> 情商高就是：别人愿意和你一起工作、你有问题的时候别人愿意帮你。智商有时候可以稍微弥补一下情商，但不起决定性的作用。</p><p> 现代管理学的精髓，就是让每个人（包括老板本人）都变得可替代。如果你觉得自己不可替代，要么是你的错觉，要么是你在一家管理非常原始的、摇摇欲坠马上要完蛋的公司。</p><p> <strong>0x05</strong></p><p> <strong>写好文档</strong></p><p> 怎样让程序员变得可替代？三个字：写文档。</p><p> 不愿意写文档的程序员，应该立刻马上毫不犹豫地开掉。程序员工作创造的价值，至少一半是通过文档体现出来才对。</p><p> “一个项目换一个人就要让项目大地震一下”，“解决Bug换一个人就不行，因为只有老人知道要改哪一行的哪个关键字”，这不说明这个项目所涉及的技术有多复杂、不说明这个老人是什么技术大牛，而只说明这个项目的项目经理很蠢，这个项目已经失控了。</p><p> 文档不是事无巨细的流水账，写文档以及组织文档是需要智商的、是需要架构师去设计的。</p><p> 美国的航天飞机那么复杂，但是在Pilot手里的手册也就那么多，而这个手册可以在航天飞机出问题的时候协助Pilot快速定位绝大多数问题。</p><p> <strong>不可替代的打工者只有一种：以中高层领导的身份跟完了一个项目，而且这个项目正处于大红大紫的阶段</strong>，公司为了防止你跳槽到竞争对手那里，愿意付给你薪水，养着你天天在办公室喝茶。只要项目一直红着，公司就愿意一直养着你。</p><p> <strong>0x06</strong></p><p> <strong>开发人员的文档的作用</strong></p><p> 给正在Code的自己看、给几个月后已经忘记这个模块当初是怎么开发的自己看、给要接手自己工作的新人看、给周边有关联开发任务的同事看、给领导等有关人员看，这是产品出bug的时候用来和别人怼的武器。</p><p> 如果没有文档，这些工作量都会成倍增长。</p><p> 代码再精简再直观，也不可能有人类语言直观，谁觉得自己厉害到读代码和读人类语言写的文档速度一样快，那我给你一个我上大学时候写的小程序，麻烦你读一下代码，看看你多长时间可以看明白。</p><p> 参考链接：<a href="https://github.com/YvesZHI/FallingCode" target="_blank" rel="noopener">https://github.com/YvesZHI/FallingCode</a></p><p> 这段代码本身并不复杂，应该说非常简单，但是没有文档……读读看吧。</p><p> 简而言之，文档，就像盖楼房的设计图，没有图纸，你是不能开始搬砖的。</p><p> 领导有没有给你看需求分析文档？有没有拿着需求分析文档给你宣讲你要做什么？没有？不干活。</p><p> 测试的同事有没有给你看测试用例文档？有没有给你宣讲？没有？不干活。</p><p> 你自己明白领导的意图了吗？明白测试同事的意图了吗？想明白后，开始想自己要开发的模块里的各个功能模块之间的关系，可以画时序图。</p><p> 时序图画完了，看看是否有（可能）频繁变化的模块/需求，如果有，请务必使用一些设计模式，如果要用设计模式，请务必画UML类图，如果没有频繁变化的模块/需求，请一定不要用设计模式。</p><p> 最后，看看在一个功能模块中，有没有逻辑比较复杂的地方，如果有，请画流程图。</p><p> 模块和模块之间有没有需要明确的协议？如果有，请把协议写出来。</p><p> 上面这一段话，就是你要写的文档，这个文档的读者主要是你，在你的模块出问题之前，别人通常不会读这个文档（不排除你的领导会要求看你这个文档）。</p><p> 如果你既不需要时序图又不需要类图又没什么协议需要明确，那么，你就可以不写这个文档。另外，如果这个文档写得好，你的代码是不需要任何注释的。</p><p> <strong>0x07</strong></p><p> <strong>技术驱动</strong></p><p> 如果一家公司打着“我们是技术驱动型公司”的名号在招人，我劝你一定要想好考察好，再决定是否去这家公司。</p><p> 为什么呢？因为我知道他的那句“技术驱动”很吸引你，你<strong>想学东西，但是对小公司来说，它最大的任务是活下去，然后才是其他。</strong></p><p> 我不是说小公司学不到东西，我只是说小公司很难很难做到真正的技术驱动。</p><p> 有人坚持认为微软这种公司是技术驱动，但微软从没大张旗鼓地说自己是“技术驱动”公司，并以此忽悠新人。</p><p> 以华为为例。华为成功的内在原因，早就敲锣打鼓地告诉全世界了：以客户为中心，以奋斗者为本，长期艰苦奋斗，坚持自我批判。</p><p> 这四句话，没一句是直接和技术相关的。</p><p> 这里我先特别声明一下，我不是说，技术人员在华为就不会搞技术、不会提升自己的技术水平、华为的技术水平差。我绝不是这个意思。</p><p> 华为的技术，不需要我多说，全世界的人都是有目共睹的，华为公司的技术专利数就摆在那里，那是谁也抹杀不了的，华为公司里的技术大牛多了去了。</p><p> 但在这里，我要说的还是第一段的意思：一个人可以以技术驱动，但一家公司不行。</p><p> 华为公司的核心理念，本质就是“成就客户”，你把客户成就了，你就把自己成就了，华为不是先成就自己再去成就客户的公司。</p><p> 你去华为工作，你可以以技术驱动自己，但华为不能这样做。</p><p> 这一点和微软与IBM的合作极其相似：IBM说，你们微软现在搞的东西我愿意用，但是我需要你们给我搞个操作系统，这样我们才能继续合作。</p><p> 然后微软怎么做的呢？它马上购买了另外一家公司搞的DOS操作系统，然后直接授权给IBM使用。</p><p> 这里面有四个问题值得思考：</p><ol><li><p>为什么那家开发DOS的公司没能直接和IBM合作？</p></li><li><p>微软购买DOS系统的钱哪里来的？</p></li><li><p>微软为什么不自己开发操作系统？</p></li><li><p>技术在前三个问题中的角色和作用是什么？</p></li></ol><p> 至于有人说Intel是技术驱动公司，我建议大家可以去了解一下Intel为什么放弃了手机市场：重点关注Intel决定放弃手机市场的原因，你就会发现，这个原因的本质，就是一种技术情节的产物。</p><p> Intel放弃手机市场与华为决定进军手机市场是截然不同的。华为本来是做基站、路由器和交换机的，这是它的主营业务。</p><p> 那么华为为什么决定进入手机市场？是什么原因驱使华为在没有任何技术积累的前提下进入手机市场？以至于最初华为的手机被华为员工戏称为“暖手宝”，倒贴钱都没人愿意用，而现在却如此成功？</p><p> <strong>所以，我还是那个观点：世界上没有技术驱动型公司。</strong></p><p> 我本人就是程序员，我一直都以技术在驱动自己，努力提升自己的技术水平。但是我还是要说：世界上没有技术驱动型公司。</p><p> 一个新的team要开发一款软件，它首先要解决的问题，是在产品1.0开发出来并且赚到钱之前这个team的经费。</p><p> 其次，它要提前找好产品的客户群和可能存在的销售渠道，并且做完相应的工作。</p><p> 再次，它要做产品规划，如什么时候出1.0版本的产品、哪个模块开发大概要多久、什么类型的问题可以暂时搁置、什么类型的问题不能搁置、要组织公关组公关等（全是项目管理相关内容，和技术没有直接关系）。</p><p> 最后，进入产品开发阶段。一旦进入产品开发，就像工厂的流水线一样，是不可能出现什么导致产品开发进行不下去的技术难点的（否则技术leader就是白痴，这种产品在头脑风暴阶段就应该被拍死才对）。</p><p> <strong>所以，“期望出现决定产品生死的技术难点，然后自己nb闪闪地搞定”这种事情，是不可能发生的。</strong></p><p> 同时，在开发过程中，难免出现各种意料之外的bug，比如，你负责的模块出现了三个bug，其中一个是必现问题，且直接影响功能实现，那这是一定要搞定的，如果你搞不定，team会找其他老手和你一起攻关。</p><p> 攻关结果有两种，一种是bug解决了，但是不知道为什么；另一种是bug解决了也知道了是为什么。</p><p> 对于第一种情况，team是不会为了找到原因而让你潜心研究几个月的，为什么？</p><p> 因为你还有后续工作要完成，而这个bug已经解决了，不影响用户使用了。</p><p> 什么时候才有可能让你继续跟进这个问题呢？1.0版本的产品市场反馈符合预期，且公司决定要继续投入2.0版本 ——只有这个条件满足，你才有可能继续跟进这个问题，为什么是有可能呢？</p><p> 因为这个bug已经不影响客户使用了，没必要投入人力去研究了，你如果花几个月的时间去找这个bug的原因，那么请问：2.0版本的工作谁做？</p><p> 在很多项目中，类似这种“问题解决了但是不知道原因”的bug，是比较常见的，很多时候，直到这个产品生命周期结束，这些bug的原因都没有找到。</p><p> 因此，“期望碰到神秘bug，然后自己潜心研究几个月，终于把原因找到”这种事情，很多时候是不存在的。</p><p> 接着上面的“三个bug”继续：另外两个bug，是概率发生且发生概率很低。</p><p> 这个时候如果工期比较赶，公司会想办法绕过这两个bug，比如定时重启服务器、定时清理缓存等（这些方法通常可以绕开低概率bug），不会给你“潜心研究三个月然后把bug解决”的机会的。</p><p> 什么时候才有可能让你继续研究这两个bug呢？和第一个bug一样，只有后续继续开发，才有可能让你继续跟进。</p><p> <strong>现在，请各位再重新品味一下“技术驱动”这个词。到底什么是技术驱动？</strong></p><p> 其实这个词真正的含义就是：我们公司效益很好，能养活nb的技术团队，所以产品能不断迭代演进开发，随着产品的不断迭代，技术人员有可能会遇到一些其他公司遇不到的问题。</p><p> 所以，如果一家新成立的小公司说自己是技术驱动的……连1.0版本的产品都没有，就敢说自己是技术驱动？你信吗？不管你信不信，反正我不信。</p><p> <strong>简而言之，“技术驱动”的同义词就是“我们公司很有钱”+“我们公司不是炒股炒房而是做产品的公司”。</strong></p><p> 至于为什么不直接这么说呢？这是因为这种说法不容易被十年寒窗苦读、潜心研究技术的同学接受……</p><p> 被“技术驱动”迷惑的同学，其实就是读书读傻了，什么叫“读书读傻了”？就是把社会和学校等同成同样的东西……</p><p> “很有钱的做IT产品的公司”，这个世界上当然是有的，但是这样的公司，根本不会用“技术驱动”这种词来忽悠新人。</p><p> 最后，隔行如隔山，但隔行不隔理。如果你读完上面的东西，对自己所处的行业有了进一步的认识，我以为，是很正常的。</p><p> 来源：<a href="https://www.zhihu.com/question/312019918/answer/608965942" target="_blank" rel="noopener">https://www.zhihu.com/question/312019918/answer/608965942</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; 别傻了，你还真相信世界上有技术驱动型公司？ &lt;/p&gt;
&lt;p&gt; 世界上没有技术驱动型公司，不论Google、Facebook，还是腾讯、阿里，都不是技术驱动型公司。&lt;strong&gt;因为技术不是源头，需求才是。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt; 因此一切技术问题，都要服从产品
      
    
    </summary>
    
      <category term="好文转载" scheme="http://zhangyu8.me/categories/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/"/>
    
    
      <category term="好文转载" scheme="http://zhangyu8.me/tags/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>HTTP的前世今生</title>
    <link href="http://zhangyu8.me/2019/10/09/HTTP%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"/>
    <id>http://zhangyu8.me/2019/10/09/HTTP的前世今生/</id>
    <published>2019-10-08T16:00:00.000Z</published>
    <updated>2020-06-28T08:11:24.746Z</updated>
    
    <content type="html"><![CDATA[<p>HTTP的前世今生</p><p>( Chrome、Firefox 和 Cloudflare 均已支持 HTTP/3 )]</p><p> 来源：_酷壳_</p><p> 原文：<em><a href="https://url.cn/56Z548W" target="_blank" rel="noopener">https://url.cn/56Z548W</a></em></p><p> HTTP (Hypertext transfer protocol) 翻译成中文是超文本传输协议，是互联网上重要的一个协议。由欧洲核子研究委员会 CERN 的英国工程师 Tim Berners-Lee v 发明的，同时他也是 WWW 的发明人，最初的主要是用于传递通过 HTML 封装过的数据。</p><p> 在 1991 年发布了 HTTP 0.9 版，在 1996 年发布 1.0 版。1997 年是 1.1 版，1.1 版也是到今天为止传输最广泛的版本（初始 RFC 2068 在 1997 年发布， 然后在 1999 年被 RFC 2616 取代，再在 2014 年被 RFC 7230/7231/7232/7233/7234/7235 取代）。</p><p> 2015 年发布了 2.0 版，其极大的优化了 HTTP/1.1 的性能和安全性，而 2018 年发布的 3.0 版，继续优化 HTTP/2，激进地使用 UDP 取代 TCP 协议。</p><p> 目前，HTTP/3 在 2019 年 9 月 26 日 被 Chrome、Firefox、和 Cloudflare 支持。所以我想写下这篇文章，简单地说一下 HTTP 的前世今生，让大家学到一些知识，并希望可以在推动一下 HTTP 标准协议的发展。</p><p> <strong>_1_</strong></p><p> <strong>HTTP 0.9 / 1.0</strong></p><p> 0.9 和 1.0 这两个版本，就是最传统的 Request – Response 的模式了。HTTP 0.9 版本的协议简单到极点，请求时不支持请求头，只支持 GET 方法，没了。HTTP 1.0 扩展了 0.9 版，其中主要增加了几个变化：</p><ul><li><p>在请求中加入了 HTTP 版本号，如：GET /coolshell/index.html HTTP/1.0</p></li><li><p>HTTP 开始有 Header了，不管是 Request 还是 Response 都有 Header 了。</p></li><li><p>增加了 HTTP Status Code 标识相关的状态码。</p></li><li><p>还有 Content-Type 可以传输其它的文件了。</p></li></ul><p> 我们可以看到，HTTP 1.0 开始让这个协议变得很文明了，一种工程文明。因为：</p><ul><li><p>一个协议有没有版本管理，是一个工程化的象征。</p></li><li><p>Header 可以说是把元数据和业务数据解耦，也可以说是控制逻辑和业务逻辑的分离。</p></li><li><p>Status Code 的出现可以让请求双方以及第三方的监控或管理程序有了统一的认识。最关键是还是控制错误和业务错误的分离。</p></li></ul><p> 注：国内很多公司 HTTP 无论对错只返回 200，这种把 HTTP Status Code 全部抹掉完全是一种工程界的倒退。</p><p> 但是，HTTP 1.0 性能上有一个很大的问题，那就是每请求一个资源都要新建一个 TCP 链接。而且是串行请求，所以就算网络变快了，打开网页的速度也还是很慢。所以，HTTP 1.0 应该是一个必须要淘汰的协议了。</p><p> <strong>_2_</strong></p><p> <strong>HTTP/1.1</strong></p><p> HTTP/1.1 主要解决了 HTTP 1.0 的网络性能的问题，以及增加了一些新的东西：</p><ul><li><p>可以设置 Keepalive 来让 HTTP 重用 TCP 链接，重用 TCP 链接可以省了每次请求都要在广域网上进行的 TCP 的三次握手的巨大开销。这是所谓的 “HTTP 长链接” 或是 “请求响应式的 HTTP 持久链接”。英文叫 HTTP Persistent Connection.</p></li><li><p>然后支持 Pipeline 网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。（注：非幂等的 POST 方法或是有依赖的请求是不能被 Pipeline 化的）</p></li><li><p>支持 Chunked Responses，也就是说，在 Response 的时候，不必说明 Content-Length 这样，客户端就不能断连接，直到收到服务端的 EOF 标识。这种技术又叫 “服务端 Push 模型”，或是 “服务端 Push 式的 HTTP 持久链接”</p></li><li><p>还增加了 Cache Control 机制。</p></li><li><p>协议头增加了 Language、Encoding、Type 等等头，让客户端可以跟服务器端进行更多的协商。</p></li><li><p>还正式加入了一个很重要的头 —— HOST 这样的话，服务器就知道你要请求哪个网站了。因为可以有多个域名解析到同一个 IP 上，要区分用户是请求的哪个域名，就需要在 HTTP 的协议中加入域名的信息，而不是被 DNS 转换过的 IP 信息。</p></li><li><p>正式加入了 OPTIONS 方法，其主要用于 CORS – Cross Origin Resource Sharing 应用。</p></li></ul><p> HTTP/1.1 应该分成两个时代，一个是 2014 年前，一个是 2014 年后。因为 2014 年 HTTP/1.1 有了一组 RFC（7230 /7231/7232/7233/7234/7235），这组 RFC 又叫 “HTTP/2 预览版”。其中影响 HTTP 发展的是两个大的需求：</p><ul><li><p>一个需要是加大了 HTTP 的安全性，这样就可以让 HTTP 应用得广泛。比如，使用 TLS 协议。</p></li><li><p>另一个是让 HTTP 可以支持更多的应用，在 HTTP/1.1 下，HTTP 已经支持四种网络协议：</p></li></ul><ul><li><p>传统的短链接。</p></li><li><p>可重用 TCP 的的长链接模型。</p></li><li><p>服务端 Push 的模型。</p></li><li><p>WebSocket 模型。</p></li></ul><p> 自从 2005 年以来，整个世界的应用 API 越来多，这些都造就了整个世界在推动 HTTP 的前进。我们可以看到，自 2014 的 HTTP/1.1 以来，这个世界基本的应用协议的标准基本上都是向 HTTP 看齐了。也许 2014 年前，还有一些专用的 RPC 协议。但是 2014 年以后，HTTP 协议的增强，让我们实在找不出什么理由不向标准靠拢，还要重新发明轮子了。</p><p> <strong>_3_</strong></p><p> <strong>HTTP/2</strong></p><p> 虽然 HTTP/1.1 已经开始变成应用层通讯协议的一等公民了，但是还是有性能问题，虽然 HTTP/1.1 可以重用 TCP 链接，但是请求还是一个一个串行发的，需要保证其顺序。然而，大量的网页请求中都是些资源类的东西，这些东西占了整个 HTTP 请求中最多的传输数据量。所以，理论上来说，如果能够并行这些请求，那就会增加更大的网络吞吐和性能。</p><p> 另外，HTTP/1.1 传输数据时，是以文本的方式。借助耗 CPU 的 Zip 压缩的方式减少网络带宽，但是耗了前端和后端的 CPU。这也是为什么很多 RPC 协议诟病 HTTP 的一个原因，就是数据传输的成本比较大。</p><p> 其实，在 2010 年时，Google 就在搞一个实验型的协议，这个协议叫 SPDY。这个协议成为了 HTTP/2 的基础（也可以说成 HTTP/2 就是 SPDY 的复刻）。HTTP/2 基本上解决了之前的这些性能问题，其和 HTTP/1.1 最主要的不同是：</p><ul><li><p>HTTP/2 是一个二进制协议，增加了数据传输的效率。</p></li><li><p>HTTP/2 是可以在一个 TCP 链接中并发请求多个 HTTP 请求，移除了 HTTP/1.1 中的串行请求。</p></li><li><p>HTTP/2 会压缩头，如果你同时发出多个请求，他们的头是一样的或是相似的。那么，协议会帮你消除重复的部分。这就是所谓的 HPACK 算法（参看 RFC 7541 附录 A）</p></li><li><p>HTTP/2 允许服务端在客户端放 Cache，又叫服务端 Push，也就是说，你没有请求的东西，我服务端可以先送给你放在你的本地缓存中。比如，你请求 X，我服务端知道 X 依赖于 Y，虽然你没有的请求 Y，但我把 Y 跟着 X 的请求一起返回客户端。</p></li></ul><p> 对于这些性能上的改善，在 Medium 上有篇文章 “ HTTP/2: the difference between HTTP/1.1, benefits and how to use it (<a href="https://url.cn/5Ij0hXz" target="_blank" rel="noopener">https://url.cn/5Ij0hXz</a>) ” 你可看一下相关的细节说明和测试。</p><p> 当然，还需要注意到的是 HTTP/2 的协议复杂度比之前所有的 HTTP 协议的复杂度都上升了许多许多。其内部还有很多看不见的东西，比如其需要维护一个 “优先级树” 来用于来做一些资源和请求的调度和控制。如此复杂的协议，自然会产生一些不同的声音，或是降低协议的可维护和可扩展性。所以也有一些争议。尽管如此，HTTP/2 还是很快地被世界所采用。</p><p> HTTP/2 是 2015 年推出的。其发布后，Google 宣布移除对 SPDY 的支持，拥抱标准的 HTTP/2。过了一年后，就有 8.7% 的网站开启了 HTTP/2，根据这份报告 (<a href="https://url.cn/5YOuflM" target="_blank" rel="noopener">https://url.cn/5YOuflM</a>) ，截止至本文发布时（2019 年 10 月 1 日）， 在全世界范围内已经有 41% 的网站开启了 HTTP/2。</p><p> HTTP/2 的官方组织在 Github 上维护了一份各种语言对 HTTP/2 的实现列表，大家可以去看看。</p><p> 我们可以看到，HTTP/2 在性能上对 HTTP 有质的提高。所以，HTTP/2 被采用的也很快。如果你在你的公司内负责架构的话，HTTP/2 是你一个非常重要的需要推动的一个事。除了因为性能上的问题，推动标准落地也是架构师的主要职责。因为，你企业内部的架构越标准，你可以使用到开源软件，或是开发方式就会越有效率。跟随着工业界的标准的发展，你的企业会非常自然的享受到标准所带来的红利。</p><p> <strong>_4_</strong></p><p> <strong>HTTP/3</strong></p><p> 然而，这个世界没有完美的解决方案。HTTP/2 也不例外，其主要的问题是：若干个 HTTP 的请求在复用一个 TCP 的连接，底层的 TCP 协议是不知道上层有多少个 HTTP 的请求的。所以，一旦发生丢包，造成的问题就是所有的 HTTP 请求都必须等待这个丢了的包被重传回来，哪怕丢的那个包不是我这个 HTTP 请求的。因为 TCP 底层是没有这个知识了。</p><p> 这个问题又叫 Head-of-Line Blocking 问题，这也是一个比较经典的流量调度的问题。这个问题最早主要的发生的交换机上。下图来自 Wikipedia。</p><p> <img src="https://coolshell.cn/wp-content/uploads/2019/10/HOL_blocking.png" alt></p><p> 图中，左边的是输入队列。其中的 1、2、3、4 表示四个队列，四个队列中的 1、2、3、4 要去右边的 Output 的端口号。此时，第一个队列和第三个队列都要写右边的第四个端口。然后，一个时刻只能处理一个包。所以，一个队列只能在那等另一个队列写完。其此时的 3 号或 1 号端口是空闲的，而队列中的要去 1 和 3 号端口号的数据，被第四号端口给 Block 住了。这就是所谓的 HOL Blocking 问题。</p><p> HTTP/1.1 中的 Pipeline 中如果有一个请求 Block 了，那么队列后请求也统统被 Block 住了；HTTP/2 多请求复用一个 TCP 连接，一旦发生丢包就会 Block 住所有的 HTTP 请求。这样的问题很讨厌。好像基本无解了。</p><p> 是的 TCP 是无解了，但是 UDP 是有解的 ！于是 HTTP/3 破天荒地把 HTTP 底层的 TCP 协议改成了 UDP！</p><p> 然后又是 Google 家的协议进入了标准 – QUIC （Quick UDP Internet Connections）。接下来是 QUIC 协议的几个重要的特性，为了讲清楚这些特性，我需要带着问题来讲（注：下面的网络知识，如果你看不懂的话，你需要学习一下 《TCP/IP 详解》 一书（ 在我写 Blog 的这 15 年里，这本书推荐了无数次了），或是看一下本站的 《 TCP 的那些事》。）：</p><ul><li><p>首先是上面的 Head-of-Line Blocking 问题，在 UDP 的世界中，这个就没了。这个应该比较好理解，因为 UDP 不管顺序，不管丢包（当然，QUIC 的一个任务是要像 TCP 的一个稳定，所以 QUIC 有自己的丢包重传的机制）</p></li><li><p>TCP 是一个无私的协议，也就是说，如果网络上出现拥塞，大家都会丢包，于是大家都会进入拥塞控制的算法中。这个算法会让所有人都 “冷静” 下来，然后进入一个 “慢启动” 的过程，包括在 TCP 连接建立时，这个慢启动也在，所以导致 TCP 性能迸发地比较慢。QUIC 基于 UDP，使用更为激进的方式。同时，QUIC 有一套自己的丢包重传和拥塞控制的协议，一开始 QUIC 是重新实现 TCP 的 CUBIC 算法。但是随着 BBR 算法的成熟（BBR 也在借鉴 CUBIC 算法的数学模型），QUIC 也可以使用 BBR 算法。这里，多说几句，从模型来说，以前的 TCP 的拥塞控制算法玩的是数学模型，而新型的 TCP 拥塞控制算法是以 BBR 为代表的测量模型。理论上来说，后者会更好，但 QUIC 的团队在一开始觉得 BBR 不如 CUBIC 的算法好，所以没有用。现在的 BBR 2.x 借鉴了 CUBIC 数学模型让拥塞控制更公平。这里有文章大家可以一读 “TCP BBR : Magic dust for network performance. ”</p></li><li><p>接下来，现在要建立一个 HTTPS 的连接。先是 TCP 的三次握手，然后是 TLS 的三次握手，要整出六次网络交互，一个连接才建好。虽说 HTTP/1.1 和 HTTP/2 的连接复用解决这个问题，但是基于 UDP 后，UDP 也得要实现这个事。于是 QUIC 直接把 TCP 的和 TLS 的合并成了三次握手（对此，在 HTTP/2 的时候，是否默认开启 TLS 业内是有争议的。反对派说，TLS 在一些情况下是不需要的，比如企业内网的时候。而支持派则说，TLS 的那些开销，什么也不算了）。</p></li></ul><p> <img src="https://coolshell.cn/wp-content/uploads/2019/10/http-request-over-tcp-tls@2x-292x300.png" alt></p><p> 所以，QUIC 是一个在 UDP 之上的伪 TCP + TLS + HTTP/2 的多路复用的协议。</p><p> 但是对于 UDP 还是有一些挑战的，这个挑战主要来自互联网上的各种网络设备。这些设备根本不知道是什么 QUIC，他们看 QUIC 就只能看到的就是 UDP，所以，在一些情况下，UDP 就是有问题的。</p><ul><li><p>比如在 NAT 的环境下，如果是 TCP 话，NAT 路由或是代理服务器，可以通过记录 TCP 的四元组（源地址、源端口、目标地址、目标端口）来做连接映射的。然而，在 UDP 的情况下不行了。于是，QUIC 引入了个叫 Connection ID 的不透明的 ID 来标识一个链接，用这种业务 ID 很爽的一个事是如果你从你的 3G/4G 的网络切到 WiFi网络（或是反过来），你的链接不会断，因为我们用的是 Connection ID，而不是四元组。</p></li><li><p>然而就算引用了 Connection ID，也还是会有问题，比如一些不够 “聪明” 的等价路由交换机。这些交换机会通过四元组来做 Hash 把你的请求的 IP 转到后端的实际的服务器上。然而，他们不懂 Connection ID，只懂四元组。这么导致属于同一个 Connection ID 但是四元组不同的网络包就转到了不同的服务器上，这就是导致数据不能传到同一台服务器上，数据不完整，链接只能断了。所以，你需要更聪明的算法（可以参看 Facebook 的 Katran 开源项目 ）</p></li></ul><p> 好了，就算搞定上面的东西，还有一些业务层的事没解。这个事就是 HTTP/2 的头压缩算法 HPACK，HPACK 需要维护一个动态的字典表来分析请求的头中哪些是重复的，HPACK 的这个数据结构需要在 Encoder 和 Decoder 端同步这个东西。在 TCP 上，这种同步是透明的，然而在 UDP 上这个事不好干了。所以，这个事也必须要重新设计了，基于 QUIC 的 QPACK 就出来了，利用两个附加的 QUIC Steam，一个用来发送这个字典表的更新给对方，另一个用来 Ack 对方发过来的 Update。</p><p> 目前看下来，HTTP/3 目前看上去没有太多的协议业务逻辑上的东西，更多是 HTTP/2 + QUIC 协议。但 HTTP/3 因为动到了底层协议，所以，在普及方面上可能会比 HTTP/2 要慢的多的多。但是，可以看到 QUIC 协议的强大。细思及恐，QUIC 这个协议真对 TCP 是个威胁，如果 QUIC成熟了，TCP 是不是会有可能成为历史呢？</p><p> 未来十年，让我们看看 UDP 是否能够逆袭 TCP……</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;HTTP的前世今生&lt;/p&gt;
&lt;p&gt;( Chrome、Firefox 和 Cloudflare 均已支持 HTTP/3 )]&lt;/p&gt;
&lt;p&gt; 来源：_酷壳_&lt;/p&gt;
&lt;p&gt; 原文：&lt;em&gt;&lt;a href=&quot;https://url.cn/56Z548W&quot; target=&quot;_bl
      
    
    </summary>
    
      <category term="web" scheme="http://zhangyu8.me/categories/web/"/>
    
    
      <category term="web" scheme="http://zhangyu8.me/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>Linux内核优化详解-天师巨献</title>
    <link href="http://zhangyu8.me/2019/09/20/Linux%E5%86%85%E6%A0%B8%E4%BC%98%E5%8C%96%E8%AF%A6%E8%A7%A3/"/>
    <id>http://zhangyu8.me/2019/09/20/Linux内核优化详解/</id>
    <published>2019-09-19T16:00:00.000Z</published>
    <updated>2019-09-20T06:37:21.078Z</updated>
    
    <content type="html"><![CDATA[<p>linux内核配置文件</p><p>centos6 —-/etc/sysctl.conf </p><p>centos7—- /usr/lib/sysctl.d/00-system.conf  </p><p>注意：/etc/sysctl.conf文件中设置的内核运行时参数可能会被应用调优的配置文件覆盖.</p><p>但是也可以自建一个单独的配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br></pre></td><td class="code"><pre><span class="line">###参考 CIS-LINUX centos7</span><br><span class="line">其他国外专家推荐</span><br><span class="line">ibm调优</span><br><span class="line"></span><br><span class="line">https://www.ibm.com/developerworks/community/wikis/home?lang=en#!/wiki/Welcome%20to%20High%20Performance%20Computing%20%28HPC%29%20Central/page/Linux%20System%20Tuning%20Recommendations</span><br><span class="line"></span><br><span class="line">https://www.ibm.com/developerworks/community/wikis/home?lang=en#!/wiki/Welcome%20to%20High%20Performance%20Computing%20%28HPC%29%20Central/page/Linux%20System%20Tuning%20Recommendations</span><br><span class="line"></span><br><span class="line">##############################################################</span><br><span class="line"></span><br><span class="line">#####</span><br><span class="line"></span><br><span class="line"># Kernel sysctl configuration file for Red Hat Linux</span><br><span class="line">#</span><br><span class="line"># For binary values, 0 is disabled, 1 is enabled.  See sysctl(8) and</span><br><span class="line"># sysctl.conf(5) for more details.</span><br><span class="line"></span><br><span class="line"># Controls IP packet forwarding</span><br><span class="line">#0，表示禁止数据包转发，1表示允许</span><br><span class="line">###net.ipv4.ip_forward = 0</span><br><span class="line">##docker环境要开启</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"># rp_filter用于实现反向过滤技术</span><br><span class="line">#  0 - No source validation.</span><br><span class="line">#        1 - Strict mode as defined in RFC3704 Strict Reverse Path</span><br><span class="line">#            Each incoming packet is tested against the FIB and if the interface</span><br><span class="line">#            is not the best reverse path the packet check will fail.</span><br><span class="line">#            By default failed packets are discarded.  默认情况下，丢弃失败的数据包。</span><br><span class="line">#RFC3704中定义的严格模式严格反向路径每个传入数据包都针对FIB进行测试，如果接口不是最佳反向路径，则数据包检查将失败。</span><br><span class="line">#        2 - Loose mode as defined in RFC3704 Loose Reverse Path</span><br><span class="line">#            Each incoming packet&apos;s source address is also tested against the FIB</span><br><span class="line">#            and if the source address is not reachable via any interface</span><br><span class="line">#            the packet check will fail.</span><br><span class="line"># RFC3704中定义的松散模式宽松反向路径每个传入数据包的源地址还针对FIB进行测试，如果源地址无法通过任何接口访问，则数据包检查将失败。</span><br><span class="line">#        Current recommended practice in RFC3704 is to enable strict mode</span><br><span class="line"> #       to prevent IP spoofing from DDos attacks. If using asymmetric routing</span><br><span class="line"> #       or other complicated routing, then loose mode is recommended.</span><br><span class="line">#RFC3704中的当前推荐做法是启用严格模式以防止DDoS攻击的IP欺骗。 如果使用非对称路由或其他复杂路由，建议使用松散模式。</span><br><span class="line">#The default value is 0, but note that some distributions enable it in startup scripts.</span><br><span class="line">net.ipv4.conf.all.rp_filter = 1</span><br><span class="line">net.ipv4.conf.default.rp_filter = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"># 多网卡接收多播 arp_filter</span><br><span class="line">#0 - (default) The kernel can respond to ARP requests with addresses from other interfaces. This may seem wrong but it usually makes sense, because it increases the chance of successful communication.  IP addresses are owned by the complete host on Linux, not by particular interfaces. Only for more complex setups like load-balancing, does this behaviour cause problems.</span><br><span class="line">#1 - Allows you to have multiple network interfaces on the same subnet, and have the ARPs for each interface be answered based on whether or not the kernel would route a packet from the ARP&apos;d IP out that interface (therefore you must use source based routing for this to work). In other words it allows control of which cards (usually 1) will respond to an ARP request.</span><br><span class="line">#arp_filter for the interface will be enabled if at least one of conf/&#123;all,interface&#125;/arp_filter is set to 1, it will be disabled otherwise.</span><br><span class="line">net.ipv4.conf.all.arp_filter = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line"># Do not accept source routing</span><br><span class="line"># 处理无源路由的包</span><br><span class="line">#Accept packets with SRR option.</span><br><span class="line">#conf/all/accept_source_route must also be set to 1 to accept packets with SRR option on the interface.</span><br><span class="line">#Default: 1 (router), 0 (host).</span><br><span class="line"></span><br><span class="line">net.ipv4.conf.all.accept_source_route = 0</span><br><span class="line">net.ipv4.conf.default.accept_source_route = 0</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">##http://fedoraproject.org/wiki/QA/Sysrq</span><br><span class="line"># Controls the System Request debugging functionality of the kernel</span><br><span class="line">#SysRq 经常被称为 Magic System Request，它被定义为一系列按键组合。之所以说它神奇，是因为它在系统挂起，大多数服务已无法响应的情况下，还能通过按键组合来完成一系列预先定义的系统操作。通过它，不但可以在保证磁盘数据安全的情况下重启一台挂起的服务器，避免数据丢失和重启后长时间的文件系统检查，还可以收集包括系统内存使用，CPU 任务处理，进程运行状态等系统运行信息，甚至还可能在无需重启的情况下挽回一台已经停止响应的服务器。</span><br><span class="line">#0 不启用 SysRq ，1 启用</span><br><span class="line">kernel.sysrq = 0</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"># Controls whether core dumps will append the PID to the core filename.</span><br><span class="line"># Useful for debugging multi-threaded applications.</span><br><span class="line">#当系统中的一些程序在遇到一些错误以及crash时，系统会自动产生core file记录crash时刻系统信息包括内存和寄存器信息，用以程序员日后debug时可以使用。这些错误包括断错误，非法指令，总线错误和用户自己生成的退出信号等等。一般的，core file会在当前文件夹中存放。</span><br><span class="line">kernel.core_uses_pid = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"># Controls the use of TCP syncookies</span><br><span class="line">#开启SYN洪水攻击保护</span><br><span class="line">#表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；</span><br><span class="line">##这个参数也可以不添加。该参数对应系统路径为：/proc/sys/net/ipv4/tcp_syncookies</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"># Controls the default maxmimum size of a mesage queue</span><br><span class="line">#该文件指定一个消息队列的最大长度（bytes)缺省设置：16384</span><br><span class="line">kernel.msgmnb = 1073741824</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"># Controls the maximum size of a message, in bytes</span><br><span class="line">#该文件指定了从一个进程发送到另一个进程的消息的最大长度（bytes）。进程间的消息传递是在内核的内存中进行的，不会交换到磁盘上，所以如果增加该值，则将增加操作系统所使用的内存数量。</span><br><span class="line">kernel.msgmax = 20480000</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"># Controls the maximum shared segment size, in bytes</span><br><span class="line">#该文件表示内核所允许的最大共享内存段的大小（bytes）。</span><br><span class="line">#缺省设置：33554432</span><br><span class="line">#建议设置：物理内存 * 50%</span><br><span class="line">## Oracle-Validated setting for kernel.shmmax is 4398046511104</span><br><span class="line">kernel.shmmax = 4398046511104</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"></span><br><span class="line"># Controls the maximum number of shared memory segments, in pages</span><br><span class="line">#该文件表示在任何给定时刻，系统上可以使用的共享内存的总量（bytes）。</span><br><span class="line">kernel.shmall = 4294967296</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">#该文件指定消息队列标识的最大数目，即系统范围内最大多少个消息队列。缺省设置：16</span><br><span class="line">kernel.msgmni = 4096000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"></span><br><span class="line">######## https://fasterdata.es.net/host-tuning/linux</span><br><span class="line">##For a host with a 10G NIC optimized for network paths up to 200ms RTT, and for friendliness to single and parallel stream tools, or a 40G NIC up on paths up to 50ms RTT:</span><br><span class="line">#对于具有10G网卡的主机，针对高达200ms RTT的网络路径进行了优化，适用于单一和并行流工具，或40G网卡，路径长达50ms RTT</span><br><span class="line"></span><br><span class="line"># allow testing with buffers up to128MB</span><br><span class="line">＃允许使用高达128MB的缓冲区进行测试</span><br><span class="line">#指定了接收窗口套接字缓冲区大小的最大值，单位是字节。</span><br><span class="line">net.core.rmem_max = 134217728</span><br><span class="line">#指定了发送套接字缓冲区大小的最大值，单位是字节。</span><br><span class="line">net.core.wmem_max = 134217728</span><br><span class="line"></span><br><span class="line">#默认的TCP数据发送窗口大小（字节）。</span><br><span class="line">net.core.wmem_default = 11059200</span><br><span class="line"></span><br><span class="line">#默认的TCP数据接收窗口大小（字节）。</span><br><span class="line">net.core.rmem_default = 11059200</span><br><span class="line">##表示每个套接字所允许的最大缓冲区的大小。缺省设置：10240</span><br><span class="line">net.core.optmem_max= 2048000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#为自动调优定义每个 socket 使用的内存。第一个值是为 socket 的发送缓冲区分配的最少字节数。第二个值是默认值（该值会被 wmem_default 覆盖），缓冲区在系统负载不重的情况下可以增长到这个值。第三个值是发送缓冲区空间的最大字节数（该值会被 wmem_max 覆盖）。</span><br><span class="line"> ##https://fasterdata.es.net/host-tuning/linux</span><br><span class="line">#该文件包含3个整数值，分别是：min，default，max</span><br><span class="line">#Min：为TCP socket预留用于接收/接收缓冲的内存数量，即使在内存出现紧张情况下TCP socket都至少会有这么多数量的内存用于接收缓冲。</span><br><span class="line">#Default：为TCP socket预留用于接收/缓冲的内存数量，默认情况下该值影响其它协议使用的 net.core.wmem中default的 值。该值决定了在tcp_adv_win_scale、tcp_app_win和tcp_app_win的默认值情况下，TCP 窗口大小为65535。</span><br><span class="line">#Max：为TCP socket预留用于接收/缓冲的内存最大值。该值不会影响 net.core.wmem中max的值，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#与 tcp_wmem 类似，不过它表示的是为自动调优所使用的接收缓冲区的值。</span><br><span class="line">net.ipv4.tcp_rmem = 4096 87380 67108864 </span><br><span class="line"></span><br><span class="line">＃将Linux自动调优TCP缓冲区限制增加到64MB </span><br><span class="line">net.ipv4.tcp_wmem = 4096 65536 67108864 </span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">###linux自动调整内存分配的功能 cat /proc/sys/net/ipv4/tcp_moderate_rcvbuf </span><br><span class="line">###系统默认tcp_moderate_rcvbuf配置为1，表示打开了TCP内存自动调整功能。若配置为0，这个功能将不会生效（慎用）。</span><br><span class="line">###net.ipv4.tcp_moderate_rcvbuf = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"># recommended default congestion control is htcp 超文本缓冲 </span><br><span class="line">###### There seem to be bugs in both bic and cubic for a number of versions of the Linux kernel up to version 2.6.33. We recommend using htcp with older kernels to be safe.</span><br><span class="line">#If cubic and/or htcp are not listed try the following, as most distributions include them as loadable kernel modules:</span><br><span class="line">#要加入开机自启</span><br><span class="line">#/sbin/modprobe tcp_htcp</span><br><span class="line">#/sbin/modprobe tcp_cubic</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">#为CentOS7 / Debian8主机推荐</span><br><span class="line">##https://fasterdata.es.net/host-tuning/packet-pacing/</span><br><span class="line">##数据包调度使用FQ（公平队列）调度程序</span><br><span class="line">##从Linux内核3.11或更高版本开始，有一个新的“公平排队”调度程序，其中包含的代码可以更好地从快速主机中调出数据包。有关更多详细信息，请参阅https://lwn.net/Articles/564978/。对于基于RHEL的操作系统，FQ已经在v7.2中被移植到3.10.0-327内核。</span><br><span class="line"></span><br><span class="line">net.core.default_qdisc = fq</span><br><span class="line">##还有执行下面 的命令To both pace and shape the bandwidth:</span><br><span class="line">##https://www.systutorials.com/docs/linux/man/8-tc-fq/</span><br><span class="line">##tc qdisc add dev（网卡名 ens192） root fq maxrate 10gbit</span><br><span class="line"></span><br><span class="line">##内核版本低于4.9的，用htcp。</span><br><span class="line">##net.ipv4.tcp_congestion_control=htcp</span><br><span class="line">##内核版本高于等于4.9的，用google的bbr。</span><br><span class="line">net.ipv4.tcp_congestion_control=bbr</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"># recommended for hosts with jumbo frames enabled 开启系统巨型帧</span><br><span class="line">#如果您使用的是巨帧，我们建议设置tcp_mtu_probing = 1来帮助避免MTU黑洞的问题。将其设置为2有时会导致性能问题</span><br><span class="line">#＃为启用了巨型帧的主机推荐</span><br><span class="line">net.ipv4.tcp_mtu_probing=1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"></span><br><span class="line">##########################TIME_WAIT 相关参数</span><br><span class="line">###https://ieevee.com/tech/2017/07/19/tcp-tw-recycle.html</span><br><span class="line">#net.ipv4.tcp_max_tw_buckets 表示系统同时保持TIME_WAIT套接字sockets的最大数量，</span><br><span class="line"></span><br><span class="line">#如果超过这个数值，TIME_WAIT套接字将立刻被清除并打印警告信息。默认为180000</span><br><span class="line">#对于Apache、Nginx等服务器来说可以将其调低一点，如改为5000~30000，不通业务的服务器也可以给大一点，比如LVS、Squid。此项参数可以控制TIME_WAIT套接字的最大数量，避免Squid服务器被大量的TIME_WAIT套接字拖死。该参数对应系统路径为：/proc/sys/net/ipv4/tcp_max_tw_buckets</span><br><span class="line"></span><br><span class="line"># TIME_WAIT 只在主动关闭的一端出现</span><br><span class="line"> </span><br><span class="line">#之所以要设定这个限制，纯粹为了抵御那些简单的 DoS 攻击，千万不要人为的降低这个限制，</span><br><span class="line">#不过，如果网络条件需要比默认值更多，则可以提高它(或许还要增加内存)。</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 1440000</span><br><span class="line"></span><br><span class="line">#####下面两个参数</span><br><span class="line">###如果开启，在NAT环境下会引发问题。开启tcp_tw_recycle会引起上述syn报文被丢弃的问题。</span><br><span class="line">## 实际的网络情况中 公司家庭网络都走NAT。只能依赖于NAT分享同一个公网IP。</span><br><span class="line"></span><br><span class="line">#开启TCP连接中TIME-WAIT sockets的快速回收，该参数对应系统路径为：/proc/sys/net/ipv4/tcp_tw_recycle，默认为0，表示关闭。</span><br><span class="line">net.ipv4.tcp_tw_recycle = 0</span><br><span class="line"></span><br><span class="line">#tcp_timestamps用来支持RTT的来回时间计算。默认打开的 .</span><br><span class="line"></span><br><span class="line">#tcp_tw_recycle/tcp_timestamps都开启的条件下，60s内同一源ip主机的socket connect请求中的timestamp必须是递增的,导致部分通过NAT上网client无法正确连接服务器，故障表现为client发出SYN后无法收到server返回 的SYN+ACK，推荐的解决方法是关闭</span><br><span class="line">net.ipv4.tcp_timestamps = 0</span><br><span class="line"></span><br><span class="line">##复用TIME_WAIT连接---表示是否允许重新应用处于TIME-WAIT状态的socket用于新的TCP连接。</span><br><span class="line">#默认为0，表示关闭。如果使用tcp_tw_reuse，请激活tcp_timestamps，否则无效.</span><br><span class="line">#1表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，该参数对应系统路径为：/proc/sys/net/ipv4/tcp_tw_reuse</span><br><span class="line">net.ipv4.tcp_tw_reuse = 0</span><br><span class="line"></span><br><span class="line">##提示：reuse和recycle这两个参数是为防止生产环境下Web、Squid等业务服务器time_wait网络状态数量过多设置的。不同文章观点不一样。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 表示如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间.默认值是 60秒,该参数对应系统路径为：/proc/sys/net/ipv4/tcp_fin_timeout</span><br><span class="line">net.ipv4.tcp_fin_timeout = 2</span><br><span class="line"></span><br><span class="line">#################################################</span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"></span><br><span class="line">##使用 Selective ACK﹐它可以用来查找特定的遗失的数据报— 因此有助于快速恢复状态。</span><br><span class="line">#表示是否启用有选择的应答（Selective Acknowledgment），这可以通过有选择地应答乱序接收到的报文来提高性能（这样可以让发送者只发送丢失的报文段）。</span><br><span class="line">#(对于广域网通信来说这个选项应该启用，但是这会增加对 CPU 的占用。)</span><br><span class="line">net.ipv4.tcp_sack = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">###启用转发应答（Forward Acknowledgment），这可以进行有选择应答（SACK）从而减少拥塞情况的发生；这个选项也应该启用。</span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_fack = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"></span><br><span class="line">###启用 RFC 1323 定义的 window scaling；要支持超过 64KB 的窗口，必须启用该值。</span><br><span class="line">net.ipv4.tcp_window_scaling = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">#https://cwiki.apache.org/confluence/display/GEODE/Network+Configuration+Best+Practices</span><br><span class="line">##该参数对应系统路径为：/proc/sys/net/ipv4/tcp_max_orphans 65536</span><br><span class="line">#系统所能处理不属于任何进程的TCP sockets最大数量。假如超过这个数量，那么不属于任何进程的连接会被立即reset，并同时显示警告信息。</span><br><span class="line">#之所以要设定这个限制﹐纯粹为了抵御那些简单的 DoS 攻击﹐千万不要依赖这个或是人为的降低这个限制，更应该增加这个值(如果增加了内存之后)。</span><br><span class="line">#每个套接字最多能够吃掉你64K不可交换的内存。</span><br><span class="line">net.ipv4.tcp_max_orphans = 400000</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">##https://www.frozentux.net/ipsysctl-tutorial/chunkyhtml/tcpvariables.html</span><br><span class="line"># </span><br><span class="line">##指定所能接受SYN同步包的最大客户端数量，即半连接上限</span><br><span class="line">#该参数为服务器端用于记录那些尚未收到客户端确认信息的连接请求最大值。该参数对象系统路径为：/proc/sys/net/ipv4/tcp_max_syn_backlog</span><br><span class="line">#表示SYN队列的长度，默认为1024，加大队列长度 可以容纳更多等待连接的网络连接数。</span><br><span class="line">##具体取决于您拥有的内存量。</span><br><span class="line">###下面是tcp(7) - Linux man page的说法--</span><br><span class="line">#我没有在源码找到include/net/tcp.h里面的TCP_SYNQ_HSIZE</span><br><span class="line">###如果将此值提高到大于1024的值，则最有可能更改TCP_SYNQ_HSIZE值并重新编译##内核。修改include/net/tcp.h里面的TCP_SYNQ_HSIZE</span><br><span class="line">###应设置此值以使此公式保持为真：</span><br><span class="line">##TCP_SYNQ_HSIZE * 16 &lt;= tcp_max_syn_backlog</span><br><span class="line">###换句话说，TCP_SYNQ_HSIZE乘以16应该小于或等于tcp_max_syn_backlog。</span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 1000000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">##http://www.saunix.cn/1255.html</span><br><span class="line">##这个参数用于调节系统同时发起的TCP连接数，在高并发的请求中，默认的值可能会导致链接超时或重传，因此，需要结合并发请求数来调节此值。该参数对应系统路径为：/proc/sys/net/core/somaxconn</span><br><span class="line">#服务端所能accept即处理数据的最大客户端数量，即完成连接上限。</span><br><span class="line">###最大数量可以是1到2147483647</span><br><span class="line">#表示socket监听（listen）的backlog上限。什么是backlog呢？backlog就是socket的监听队列，当一个请求（request）尚未被处理或建立时，他会进入backlog。</span><br><span class="line">#tcp_max_syn_backlog用于指定酒席现场面积允许容纳多少人进来；</span><br><span class="line">#somaxconn用于指定有多少个座位。</span><br><span class="line">###tcp_max_syn_backlog &gt;= somaxconn。</span><br><span class="line">net.core.somaxconn = 1000000</span><br><span class="line">################################</span><br><span class="line">#-------------------华丽的分割线--------------。</span><br><span class="line"># 处理不过来干脆就直接拒绝连接了</span><br><span class="line">##当守护进程太忙而不能接受新的连接，就象对方发送reset消息，默认值是false。这意味着当溢出的原因是因为一个偶然的猝发，那么连接将恢复状态。只有在你确信守护进程真的不能完成连接请求时才打开该选项，该选项会影响客户的使用。(对待已经满载的sendmail,apache这类服务的时候,这个可以很快让客户端终止连接,可以给予服务程序处理已有连接的缓冲机会,所以很多防火墙上推荐打开它)</span><br><span class="line">##默认值是0，建议是0</span><br><span class="line">tcp_abort_on_overflow=0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"></span><br><span class="line">#对于一个新建连接，内核要发送多少个 SYN 连接请求才决定放弃。不应该大于255，默认值是5，即每一个连线要在约 180 秒 (3 分钟) 后才确定超时</span><br><span class="line"># 表示在内核放弃建立连接之前发送SYN包的数量。该参数对应系统路径为：/proc/sys/net/ipv4/tcp_syn_retries</span><br><span class="line">net.ipv4.tcp_syn_retries = 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">##net.ipv4.tcp_synack_retries 参数的值决定了内核放弃连接之前发送SYN+ACK包的数量。该参数对应系统路径为：/proc/sys/net/ipv4/tcp_synack_retries </span><br><span class="line">###表示回应第二个握手包（SYN+ACK包）给客户端IP后，如果收不到第三次握手包（ACK包）后，不进行重试，加快回收“半连接”，不要耗光资源。</span><br><span class="line">#</span><br><span class="line">#默认为5，表示重发5次，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 2^6 -1 = 63s，TCP才会把断开这个连接。即“半连接”默认hold住大约180秒。(可以根据上面的 tcp_syn_retries 来决定这个值)</span><br><span class="line">net.ipv4.tcp_synack_retries = 1</span><br><span class="line"></span><br><span class="line">#####################</span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">#确定 TCP 栈应该如何反映内存使用；每个值的单位都是内存页（通常是 4KB）。第一个值是内存使用的下限。第二个值是内存压力模式开始对缓冲区使用应用压力的上限。第三个值是内存上限。在这个层次上可以将报文丢弃，从而减少对内存的使用。对于较大的 BDP 可以增大这些值（但是要记住，其单位是内存页，而不是字节）。</span><br><span class="line"></span><br><span class="line">#该文件包含3个整数值，分别是：low，pressure，high</span><br><span class="line">#low：当TCP使用了低于该值的内存页面数时，TCP不会考虑释放内存。(理想情况下，这个值应与指定给 tcp_wmem 的第 2 个值相匹配 - 这第 2 个值表明，最大页面大小乘以最大并发请求数除以页大小 (131072 * 300 / 4096)。 )</span><br><span class="line">#pressure：当TCP使用了超过该值的内存页面数量时，TCP试图稳定其内存使用，进入pressure模式，当内存消耗低于low值时则退出pressure状态。(理想情况下这个值应该是 TCP 可以使用的总缓冲区大小的最大值 (204800 * 300 / 4096)。 )</span><br><span class="line">#high：允许所有tcp sockets用于排队缓冲数据报的页面量。(如果超过这个值，TCP 连接将被拒绝，这就是为什么不要令其过于保守 (512000 * 300 / 4096) 的原因了。 在这种情况下，提供的价值很大，它能处理很多连接，是所预期的 2.5 倍；或者使现有连接能够传输 2.5 倍的数据。 我的网络里为192000 300000 732000)</span><br><span class="line">#一般情况下这些值是在系统启动时根据系统内存数量计算得到的。</span><br><span class="line">#缺省设置：24576 32768 49152</span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_mem = 94500000 915000000 927000000</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"></span><br><span class="line">#######这3个参数与TCP KeepAlive有关</span><br><span class="line">#net.ipv4.tcp_keepalive_time 表示当keepalive启用时，TCP发送keepalive消息的频度。默认值是7200(2小时)，建议改为10分钟。该参数对应系统路径为：/proc/sys/net/ipv4/tcp_keepalive_time 。#表示TCP链接在多少秒之后没有数据报文传输启动探测报文; </span><br><span class="line">#特别是如果服务于大量仅需要短暂连接的客户端。很好的例子是Web服务器。这里的诀窍是通过将net.ipv4.tcp_keepalive_time调整到30分钟以内，可以减少安静的TCP连接的长度。</span><br><span class="line"></span><br><span class="line">#/proc/sys/net/ipv4/tcp_keepalive_intvl单位是也秒,表示前一个探测报文和后一个探测报文之间的时间间隔，缺省是75秒。</span><br><span class="line"></span><br><span class="line">#/proc/sys/net/ipv4/tcp_keepalive_probes表示探测的次数。在认定连接失效之前，发送多少个TCP的keepalive探测包。默认值是9。这个值乘以tcp_keepalive_intvl之后决定了，一个连接发送了keepalive之后可以有多少时间没有回应</span><br><span class="line"></span><br><span class="line">#tcp_retries2是系统在删除连接之前允许的重传次数，TCP默认最多做15次重传。根据RTO(retransmission timeout)不同，最后一次重传间隔大概是13到30分钟左右。如果15次重传都做完了，TCP/IP就会告诉应用层说：“搞不定了，包怎么都传不过去！”(这个值根据目前的网络设置,可以适当地改小,我的网络内修改为了5)</span><br><span class="line"></span><br><span class="line">##web服务器 推荐用如下配置</span><br><span class="line">#net.ipv4.tcp_keepalive_time = 300</span><br><span class="line">#net.ipv4.tcp_keepalive_probes = 3</span><br><span class="line">#net.ipv4.tcp_keepalive_intvl = 10</span><br><span class="line">#net.ipv4.tcp_retries2 = 5</span><br><span class="line">#意思是如果某个TCP连接在idle 300秒后,内核才发起probe.如果probe 3次(每次10秒)不成功,内核才彻底放弃,认为该连接已失效.</span><br><span class="line"></span><br><span class="line">##高可用应用服务器 推荐用如下配置</span><br><span class="line">net.ipv4.tcp_keepalive_time = 5</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 3</span><br><span class="line">net.ipv4.tcp_keepalive_intvl = 5</span><br><span class="line">net.ipv4.tcp_retries2 = 3</span><br><span class="line">#意思是如果某个TCP连接在idle 5秒后,内核才发起probe.如果probe 3次(每次5秒)不成功,内核才彻底放弃,认为该连接已失效.</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">#该选项用来设定允许系统打开的端口范围，即用于向外连接的端口范围。该参数对应系统路径为：/proc/sys/net/ipv4/ip_local_port_range</span><br><span class="line">#This applies to both TCP and UDP connections.</span><br><span class="line"># 本地自动分配的TCP UDP端口号范围</span><br><span class="line">#一般web应用服务器上可以设置9000 65535 来避开常用应用端口</span><br><span class="line">#类似nginx服务器可以用1025 65500</span><br><span class="line">net.ipv4.ip_local_port_range = 1025 65535</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">#明确的拥塞通知（英语：Explicit Congestion Notification，简称ECN）</span><br><span class="line">#许多现代产品中的TCP/IP协议已部分支持ECN；但是，大多数产品默认禁用ECN</span><br><span class="line">#0 – 禁用ECN，不发起也不接受</span><br><span class="line">#1 – 启用ECN，当传入连接请求时，并也在传出连接时尝试请求ECN</span><br><span class="line">#2 – （默认）传入连接请求时启用ECN，但不在传出连接上请求ECN</span><br><span class="line">#从2015年6月发布的Linux内核4.1开始，tcp_ecn_fallback机制按RFC 3168中的规定，在ECN被启用（值为1）时默认启用。</span><br><span class="line">#该回退机制在传出连接的初始设置时尝试ECN连接，对没有ECN能力的传输实行良好回退，缓解不支持ECN的主机或防火墙问题。</span><br><span class="line">net.ipv4.tcp_ecn = 0</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------                             </span><br><span class="line">###路由緩存刷新頻率，當一個路由失敗後多長時間跳到另一個路由，默認是300seconds </span><br><span class="line">net.ipv4.route.gc_timeout = 100</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">#If you ping the broadcast address of a network, all hosts are supposed to respond. </span><br><span class="line">#抵御 DDoS-- This makes for a dandy denial-of-service tool. Set this to 1 to ignore these broadcast messages.  </span><br><span class="line">#Ignoring &quot;broadcast pings&quot;                   </span><br><span class="line">net.ipv4.icmp_echo_ignore_broadcasts = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">#&quot;bad error messages&quot; protection</span><br><span class="line">net.ipv4.icmp_ignore_bogus_error_responses = 1    </span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">#禁止Ping，默认是允许ping。-This will advise the kernel to drop any ICMP packets of type 0 (zero)</span><br><span class="line">#net.ipv4.icmp_echo_ignore_all = 1</span><br><span class="line"></span><br><span class="line">####cis 推荐</span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">##禁止转发ICMP重定向报文</span><br><span class="line">net.ipv4.conf.all.send_redirects=0</span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">##禁止转发ICMP重定向报文</span><br><span class="line">net.ipv4.conf.default.send_redirects=0</span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">###禁止包含源路由的ip包</span><br><span class="line">net.ipv4.conf.all.accept_redirects=0</span><br><span class="line">net.ipv4.conf.default.accept_redirects=0</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line"> ####禁止转发安全ICMP重定向报文</span><br><span class="line">net.ipv4.conf.all.secure_redirects=0</span><br><span class="line">net.ipv4.conf.default.secure_redirects=0</span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line"> ####禁止ipv6路由广播</span><br><span class="line">net.ipv6.conf.all.accept_ra=0</span><br><span class="line">net.ipv6.conf.default.accept_ra=0</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line"> #####禁止ipv6路由重定向</span><br><span class="line">net.ipv6.conf.all.accept_redirects=0</span><br><span class="line">net.ipv6.conf.default.accept_redirects=0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">#For   CentOS5/6 </span><br><span class="line">##表示在每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。/proc/sys/net/core/netdev_max_backlog，默认值为1000</span><br><span class="line"></span><br><span class="line">#因为Oracle或者一些Science / HPC指南使用net.core.netdev_max_backlog = 300000</span><br><span class="line">##感觉.netdev_max_backlog=/proc/sys/net/netfilter/nf_conntrack_max 这个值，设置600000</span><br><span class="line">net.core.netdev_max_backlog = 600000</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">#oracle 12cR1 requisite</span><br><span class="line">#内核所能分配到的最大句柄数 ，</span><br><span class="line">##淘宝优化推荐7672460</span><br><span class="line">fs.file-max = 7672460</span><br><span class="line"></span><br><span class="line">#####设置的信号量，这4个参数内容大小固定。</span><br><span class="line">#一般kernel.sem = 250 32000 100 128</span><br><span class="line">#上面的4个数据分别对应:SEMMSL、SEMMNS、SEMOPM、SEMMNI这四个核心参数，具体含义和配置如下。</span><br><span class="line">#SEMMSL ：用于控制每个信号集的最大信号数量。</span><br><span class="line">#          Oracle 建议将 SEMMSL 设置为 init.ora 文件（用于 Linux 系统中的所有数据库）中的最大 PROCESS 实例参数的设置值再加上 10 。此外， Oracle 建议将 SEMMSL 的值设置为不少于 100 。</span><br><span class="line">#SEMMNS：用于控制整个 Linux 系统中信号（而不是信号集）的最大数。</span><br><span class="line">#       Oracle 建议将 SEMMNS 设置为：系统中每个数据库的 PROCESSES 实例参数设置值的总和，加上最大 PROCESSES 值的两倍，最后根据系统中 Oracle 数据库的数量，每个加 10 。 使用以下计算式来确定在 Linux 系统中可以分配的信号的最大数量。它将是以下两者中较小的一个值：SEMMNS 或 (SEMMSL * SEMMNI)</span><br><span class="line">#SEMOPM： 内核参数用于控制每个 semop 系统调用可以执行的信号操作的数量。semop 系统调用（函数）提供了利用一个 semop 系统调用完成多项信号操作的功能。一个信号集能够拥有每个信号集中最大数量的SEMMSL 信号，因此建议设置 SEMOPM 等于SEMMSL 。</span><br><span class="line">#        Oracle 建议将 SEMOPM 的值设置为不少于 100 。</span><br><span class="line">#SEMMNI ：内核参数用于控制整个 Linux 系统中信号集的最大数量。</span><br><span class="line">#         Oracle 建议将 SEMMNI 的值设置为不少于 100</span><br><span class="line">#淘宝 PostgreSQL 优化</span><br><span class="line">kernel.sem = 50100 64128000 50100 1280</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#内核异步 I/O (KAIO) 请求 最大数量 </span><br><span class="line">fs.aio-max-nr = 1048576</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">#关闭ipv6</span><br><span class="line">####net.ipv6.conf.all.disable_ipv6 = 1</span><br><span class="line">####net.ipv6.conf.default.disable_ipv6 = 1</span><br><span class="line"> </span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">#This file contains the maximum number of memory map areas a process may have. Memory map areas are used as a side-effect of calling malloc, directly by mmap and mprotect, and also when loading shared libraries.</span><br><span class="line">#While most applications need less than a thousand maps, certain programs, particularly malloc debuggers, may consume lots of them, e.g., up to one or two maps per allocation.</span><br><span class="line">#The default value is 65536.</span><br><span class="line">#max_map_count这个参数就是允许一个进程在VMAs(虚拟内存区域)拥有最大数量，VMA是一个连续的虚拟地址空间，当进程创建一个内存映像文件时VMA的地址空间就会增加，当达到max_map_count了就是返回out of memory errors。</span><br><span class="line">vm.max_map_count = 1048575</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">##TCP Fast Open（TFO）——一种对TCP协议的扩展，允许在TCP握手期间的TCP-SYN 和TCP-SYN/ACK数据包中夹带数据，这样就减少了一个RTT。</span><br><span class="line">#内核最好升级4.x版本</span><br><span class="line">net.ipv4.tcp_fastopen = 3</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">#vm.swappiness = 0 The kernel will swap only to avoid an out of memory condition</span><br><span class="line"> #  关闭交换分区</span><br><span class="line">#vm.swappiness = 1 Kernel version 3.5 and over, --------“1”是最小可能的“有效交换”设置</span><br><span class="line">#vm.swappiness = 10 设置为10，意味着当RAM为90％满时，交换将被使用，因此如果您有足够的RAM内存，可以轻松提高系统的性能。</span><br><span class="line">#vm.swappiness = 60 The default value.参数值设置为“60”表示当RAM达到40％容量时，内核将交换swap。</span><br><span class="line">#vm.swappiness = 100 表示积极的使用swap分区，并且把内存上的数据及时的搬运到swap空间里面</span><br><span class="line"></span><br><span class="line">vm.swappiness = 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">##该文件表示脏数据到达系统整体内存的百分比，此时触发pdflush进程把脏数据写回磁盘。缺省设置：0，禁用Block Debug模式</span><br><span class="line">vm.dirty_background_ratio = 5</span><br><span class="line"></span><br><span class="line">#该文件表示如果进程产生的脏数据到达系统整体内存的百分比，此时进程自行把脏数据写回磁盘。</span><br><span class="line"> #  如果系统进程刷脏页太慢，使得系统脏页超过内存 10 % 时，则用户进程如果有写磁盘的操作（如fsync, fdatasync等调用），则需要主动把系统脏页刷出。</span><br><span class="line"></span><br><span class="line">vm.dirty_ratio = 10</span><br><span class="line"></span><br><span class="line"># 系统脏页到达这个值，系统后台刷脏页调度进程 pdflush（或其他） 自动将(dirty_expire_centisecs/100）秒前的脏页刷到磁盘</span><br><span class="line"></span><br><span class="line">vm.dirty_background_bytes = 102400000</span><br><span class="line"></span><br><span class="line">#  比这个值老的脏页，将被刷到磁盘。6000表示60秒。</span><br><span class="line">vm.dirty_expire_centisecs = 6000    </span><br><span class="line"></span><br><span class="line"> # pdflush（或其他）后台刷脏页进程的唤醒间隔， 50表示0.5秒。</span><br><span class="line">vm.dirty_writeback_centisecs = 50 </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">##https://ieevee.com/tech/2017/09/10/overcommit.html</span><br><span class="line">#该文件指定了内核针对内存分配的策略，其值可以是0、1、2。缺省设置：0</span><br><span class="line">#0， 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。</span><br><span class="line">#允许用户轻微的overcommit。</span><br><span class="line">##这是Linux的默认策略，Heuristic overcommit handling。在这种情况下，除了一些特别夸张的内存申请，一般的内存申请都会被允许。</span><br><span class="line">###什么样的内存申请算是“夸张”呢？</span><br><span class="line">###如果申请的内存，比剩余内存+swap抠掉共享内存、抠掉保留内存(如sysctl_admin_reserve_kbytes、totalreserve_pages)以后还要大，那么就认为这是“夸张的”，内存申请会返回ENOMEM。</span><br><span class="line"></span><br><span class="line">#1， 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。任何情况下都允许申请内存overcommit, 比较危险，常用于一些科学计算应用。典型的例子是使用稀疏矩阵，并且虚拟内存的很多页全部是0。</span><br><span class="line"></span><br><span class="line">#2， 表示内核允许分配超过所有物理内存和交换空间总和的内存（参照overcommit_ratio）。Committed_AS不能大于CommitLimit。</span><br><span class="line">###使用此模式，Linux会严格统计的内存使用情况，并且只会在物理内存可用时才会允许内存申请。由于检查是在分配时完成的，请求内存的程序可以正常处理该故障的情况下，并清理遇到该错误的会话。</span><br><span class="line">###overcommit 2会分配一部分物理RAM用于内核使用。分配的数量由设置vm.overcommit_ratio配置。</span><br><span class="line">###这意味着可用于程序的虚拟内存的数量实际上是 RAM *（overcommit_ratio / 100） + SWAP</span><br><span class="line">##当然也可以根据vm.overcommit_kbytes来设置。</span><br><span class="line">###注意，需要ratio不能设置的太高，还需要保留内存用于IO缓冲区和系统调用等，据说有些系统上光网络缓冲区一次就需要超过25 GB的内存，量还是比较大的。</span><br><span class="line"></span><br><span class="line"> ##overcommit限制的初衷是malloc后，内存并不是立即使用掉，</span><br><span class="line">##所以如果多个进程同时申请一批内存的话，不允许OVERCOMMIT可能导致某些进程申请内存失败，但实际上内存是还有的。</span><br><span class="line">##所以Linux内核给出了几种选择，</span><br><span class="line">##2是比较靠谱或者温柔的做法。</span><br><span class="line">##1的话风险有点大，虽然可以申请内存，但是实际上可能已经没有足够的内存给程序使用，最终可能会导致OOM。</span><br><span class="line">##0是最常见的，允许少量的overcommit，但是对于需要超很多内存的情况，不允许。</span><br><span class="line">##还可以参考代码 :</span><br><span class="line">##security/commoncap.c::cap_vm_enough_memory()</span><br><span class="line"></span><br><span class="line">##所以当数据库无法启动时，要么你降低一下数据库申请内存的大小（例如降低shared_buffer或者max conn），要么就是修改一下overcommit的风格。</span><br><span class="line"></span><br><span class="line">####如何选择overcommit策略</span><br><span class="line">##案例1：Greenplum要求，必须设置overcommit模式为2。</span><br><span class="line">##案例2：kubernetes将overcommit策略特意改为了1，即放飞自我，想要多少内存就有多少内存。</span><br><span class="line"></span><br><span class="line">#案例3 radis必须设置overcommit模式为1</span><br><span class="line"></span><br><span class="line">##默认就设置为0，具体应用就设置相应要求的值</span><br><span class="line">vm.overcommit_memory = 0 </span><br><span class="line"></span><br><span class="line">####设置inotifywait或inotifywatch命令可以监视的文件数量(单进程)</span><br><span class="line">####fs.inotify.max_user_watches：表示同一用户同时可以添加的watch数目（watch一般是针对目录，决定了同时同一用户可以监控的目录数量）</span><br><span class="line">fs.inotify.max_user_watches=1000000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">###turned off on bridge devices.--没有docker环境 </span><br><span class="line">##net.bridge.bridge-nf-call-iptables=0 </span><br><span class="line">###net.bridge.bridge-nf-call-arptables=0 </span><br><span class="line">###net.bridge.bridge-nf-call-ip6tables=0 </span><br><span class="line">但是在docker环境里就要开启</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.bridge.bridge-nf-call-arptables = 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">###docker的网络设置</span><br><span class="line">##https://blog.codeship.com/running-1000-containers-in-docker-swarm/</span><br><span class="line">###https://lunatine.net/2018/04/12/nf_conntrackgwa-docker/</span><br><span class="line">#一个 64 位 16G内存 的机器</span><br><span class="line"># Connection tracking to prevent dropped connections (usually issue on LBs)</span><br><span class="line">net.netfilter.nf_conntrack_max=604139</span><br><span class="line">net.netfilter.nf_conntrack_buckets=151034</span><br><span class="line">net.ipv4.netfilter.ip_conntrack_generic_timeout=120</span><br><span class="line">net.netfilter.nf_conntrack_tcp_timeout_established=54000</span><br><span class="line">net.netfilter.nf_conntrack_tcp_timeout_close_wait = 60</span><br><span class="line">net.netfilter.nf_conntrack_tcp_timeout_fin_wait = 120</span><br><span class="line">net.netfilter.nf_conntrack_tcp_timeout_time_wait = 120</span><br><span class="line">net.netfilter.nf_conntrack_generic_timeout = 600</span><br><span class="line"></span><br><span class="line"># ARP cache settings for a highly loaded docker swarm</span><br><span class="line">net.ipv4.neigh.default.gc_thresh1=8096</span><br><span class="line">net.ipv4.neigh.default.gc_thresh2=12288</span><br><span class="line">net.ipv4.neigh.default.gc_thresh3=16384</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;linux内核配置文件&lt;/p&gt;
&lt;p&gt;centos6 —-/etc/sysctl.conf &lt;/p&gt;
&lt;p&gt;centos7—- /usr/lib/sysctl.d/00-system.conf  &lt;/p&gt;
&lt;p&gt;注意：/etc/sysctl.conf文件中设置的内核运行时参
      
    
    </summary>
    
      <category term="内核" scheme="http://zhangyu8.me/categories/%E5%86%85%E6%A0%B8/"/>
    
    
      <category term="内核" scheme="http://zhangyu8.me/tags/%E5%86%85%E6%A0%B8/"/>
    
  </entry>
  
  <entry>
    <title>中台禁区</title>
    <link href="http://zhangyu8.me/2019/09/10/%E4%B8%AD%E5%8F%B0%E7%A6%81%E5%8C%BA/"/>
    <id>http://zhangyu8.me/2019/09/10/中台禁区/</id>
    <published>2019-09-09T16:00:00.000Z</published>
    <updated>2019-09-10T05:52:20.903Z</updated>
    
    <content type="html"><![CDATA[<p>中台禁区-为什么最关键的组织架构却鲜少人谈？</p><p><a href="https://mp.weixin.qq.com/s/qgbSvoTabIljYYuMCmlHcw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/qgbSvoTabIljYYuMCmlHcw</a></p><p>转载自公众号 InfoQ   作者 赵钰莹</p><p> 1 写在前面</p><p> 中台确实是一个热度极高的话题，InfoQ 也曾在过往做过很多类似的选题，但是每当涉及到<strong>组织架构调整</strong>的话题，大部分采访嘉宾都选择了沉默，一位地产企业的 IT 架构师曾在我的追问下表示：<strong>组织架构一定要调整，但动组织架构就意味着在动“权力、金钱和人员”。**</strong>不难看出，这个话题太敏感。**</p><p> 因此，InfoQ 尝试从组织架构调整入手，了解整个过程以及对中台实践的影响。最终，在我们的不懈努力下（先后被 BAT 以各种原因拒绝，当然也可能是因为没找到合适的人？），终于联系到三位接受我们采访的嘉宾，他们是：网易副总裁、网易杭州研究院执行院长汪源，百分点大数据平台负责人贾喜顺和 ThoughtWorks 首席咨询师王健，再次感谢这三位专家。</p><p> 2 中台禁区：战略下的矛盾和冲突</p><p> 在中台战略制定中，组织架构调整的矛盾与冲突时刻存在，即便是阿里的“共享业务事业部（业务中台）”，早期也是非常艰难地活在淘宝和天猫的夹缝中。汪源在采访中表示：建设中台需要考虑组织、支撑技术和方法论三个方面的因素，一般来讲后两者都可以买到，但组织买不到。所以，最关键的是要对中台组织怎么构建有明确的方案，并下决心去推行。</p><p> 为什么大量中台只抄到了阿里的“形”？</p><p> 关于中台，很多人都喜欢研究阿里，但很少有人钻研阿里每年两次组织架构调整背后的原因。钟华（花名：古谦）在《企业 IT 架构转型之道（阿里巴巴中台战略思想与架构实战》一书开篇提到：</p><p>  与任何公司一样，阿里巴巴组织架构的战略调整势必对公司现有组织架构、部门间的协作等各方面都将带来深远影响…… 假若没能很好地控制战略执行过程中带来的风险，对组织架构的动荡过大，都会给现有业务带来不小的影响。</p><p> 因此，企业的每一次组织架构调整都是需要经过慎重考虑的，并且也需要让每一位员工清楚自己的定位。采访中，王健表示：“我认为阿里的中台战略之所以能够成功落地，最关键得益于其组织架构调整的能力。组织架构调整最难的就是让每个员工都能快速了解其背后的战略意图，并快速适应新的组织架构，知道接下来在新的组织架构下自己该干什么，从而让战略调整落地，这是需要一套机制和文化基础来保证的。我看到很多企业在学阿里，高层不断的在调整组织，但底下的员工基本都是懵的，不知道为什么调整，以及接下来自己要做什么。”</p><p> 虽然没有采访到阿里，但我们可以通过公开信的方式来获取阿里当年的组织架构调整情况。</p><p> 2015 年底，阿里巴巴集团对外宣布全面启动阿里巴巴集团 2018 年中台战略，构建符合 DT 时代的更具创新性、灵活性的“<strong>大中台、小前台</strong>”组织机制和业务机制。与此同时，张勇在致员工信中宣布了新的组织架构调整计划，如下图：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VOVT07wjhHugYnzCFI96WQ5bMI9okJnT04yYYOh6YYGM3uRbrTfZbtt2KOZPVzKfsaH6RMtibqrn6A/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 不难看出，阿里推进中台战略的关键人物是<strong>行癫</strong>（现任阿里巴巴集团首席技术官），他直接向张勇汇报。在公开信中，张勇表示：</p><p>  行癫是淘宝第一代的技术 Leader 和产品经理，后来成功转型为业务 Leader, 在 1688、淘宝、天猫、聚划算等多项业务中为集团做出过突出的贡献。作为集团内为数不多的兼具技术和商业背景和经验的领导者，行癫是担纲落实集团中台战略的最佳人选。他也将作为阿里集团和蚂蚁金融服务集团统一中台体系的总架构师，全面负责两大集团中台体系的规划和建设。</p><p> 这次组织架构调整让阿里正式开启中台战略，但阿里建设中台最早可以追溯至 2009 年共享业务事业部的诞生。当时，淘宝的技术团队同时支持着淘宝和天猫的业务，这样的组织架构决定了技术团队对来自淘宝的业务需求满足的优先级一定要优于天猫，这让天猫的业务团队怨声载道。此外，当时的淘宝和天猫电商系统是完全独立的两套体系，都包含商品、交易、评价、支付、物流等功能。</p><p> 基于上述原因，共享业务事业部诞生，在组织架构上与淘宝、天猫具有同样级别的事业部。然而，如前文言，这个事业部起初受到了天猫和淘宝事业部的双重碾压，团队成员如何加班都很难及时、周到地满足两大业务部门的需求，连带着话语权几乎没有（注意：职级相同并不代表话语权相同，想必很多人都对此深有同感）。钟华在书中是这样描述的：员工则是有苦说不出，只能默默流泪。</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VOVT07wjhHugYnzCFI96WQ58r96Sa20uj7wDibctHfkeSqh25yfwFXlVGC4b7xgbj0nmzyXp2zaIRw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 图源：《企业 IT 架构转型之道（阿里巴巴中台战略思想与架构实战》</p><p> 2010 年，聚划算出现，淘宝和天猫都希望接入。据不完全统计，这至少可以带来 25 倍的销售额增长，这时的阿里高层做出了一个对后来产生重大影响的决定，也是这个决定才让共享业务事业部得以真正成长起来：<strong>电商平台要想接入聚划算必须先通过共享业务事业部。</strong>钟华认为，这让整个共享业务事业群有了极强的业务抓手，而这对天猫、淘宝、1688（当时已经出现）事业部而言，也是一次权力的调整，这意味着要想获得更高的增长（接入聚划算），就必须接入共享业务事业部。</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VOVT07wjhHugYnzCFI96WQ5VGibx99gk8DoPSwOiaroUNZnJ60WpjAfCH132IE8nWmFdtkCqseHSRVQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 图源：《企业 IT 架构转型之道（阿里巴巴中台战略思想与架构实战》</p><p> 此外，这种调整不仅停留在集团层面，团队内部也进行了相应调整。早期，淘宝技术团队的组织人员组成跟今天企业中信息中心和技术部门的人员组成几乎一样，整个团队基本都是拥有较强技术技能的人员组成。阿里巴巴集团在构建共享服务体系之后，对各技术团队的组织架构也做了如下调整：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VOVT07wjhHugYnzCFI96WQ5TaqmqU6YzlahclDCicVuIPL6ROGFEdvLaPS2Zr3dibLSwQl1ZicshJvibQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 图源：《企业 IT 架构转型之道（阿里巴巴中台战略思想与架构实战》</p><p> 针对每一个建设的服务中心，从组织架构的形态上发生对应调整，不同角色的人员（架构师、开发人员、UED 工程师等）组建成了一个新的组织，每一个这样的组织都针对某一服务中心提供持续的服务能力——开发及运维。所以，在如今的阿里巴巴共享服务体系中，每一个服务中心都是由一个少则 100 多人，多则 4、5 百人的团队对负责的服务中心进行专业的运营。</p><p> 如果回顾整个阿里中台战略的推进过程，组织架构其实一直伴随着整个战略执行，只是每次调整解决的问题不尽相同（感兴趣的同学推荐阅读《企业 IT 架构转型之道（阿里巴巴中台战略思想与架构实战》，此处不再赘述）。在接受 InfoQ 采访时，贾喜顺表示，<strong>这种组织架构的调整其实是与业务复杂性相关的，</strong>类似阿里、京东等大厂需要调整组织架构来保障战略的顺利推进，但一些规模较小的企业可能不必如此复杂，这也要看企业对中台的态度，上述大厂已经将中台看做为重要战略，因此陆续进行了组织架构调整。</p><p> 如果要说<strong>组织架构调整的过程是否会出现矛盾和冲突</strong>，贾喜顺明确表示：“<strong>肯定会有</strong>”。</p><p> 他补充道，任何组织架构调整都涉及到这种矛盾，尤其是集中式的组织结构变更：一方面，这会把责任和权限更聚集，涉及组织管理的权力缩减问题；另一方面，业务边界的划分上需要进行磨合，要理清中台、前台的边界在哪里，如果边界尚不确定，就会涉及很多矛盾、冲突。</p><p> 当然，不排除有些边界很难界定，比如基于数据中台出指标体系，统计访问业务的 PV、UV 这种关键指标，不同部门统计的口径不一样，定义中台之后，类似的会有成千上万的指标需要重新进行边界划分，确定哪些指标体系由中台提供，哪些由前台搭建，很多情况下需要一事一议，不是那么容易能划分清楚的。</p><p> 既然这并非易事，为什么很多人不愿意谈论这个问题呢？</p><p> 为什么鲜少人谈组织架构？</p><p> 如果说完全没有人公开对外讨论这个话题，确实太过绝对也不准确，但大部分讨论还是比较委婉的，如开篇所言，这是一个非常敏感的话题。此外，如果不是整个中台战略的重要负责人也很难说清楚这个问题。</p><p> “中台是一个跨团队、跨业务的问题，这是一个企业级的问题，这就是为什么我说它是一个企业级治理的问题”，王健在采访中说道：“互联网公司做中台，每一家企业都有不同的背景和原因，如果把这些推到传统企业，有各种条件需要解决，比如组织能不能调，如果不可以调，那很可能做到一定程度就不能再往前走了，会碰到一个组织的天花板，或者说是组织先行，还是技术先行，这与互联网公司的情况还不太一样，<strong>传统企业在组织架构调整上是一个大的坎，调组织就是在动利益关系，这个很难**</strong>。**”</p><p> 因此，王健表示，这就需要中台推动者（下文详述这一人选如何确定）给出一把“尚方宝剑”，不然难以切动这些利益。具体来说，中台团队最初的处境可能会如阿里的“共享业务事业部”一样，不被相关事业部接受，这很容易理解，原事业部已经存在只为此事业部服务的技术支持团队，所有需求都可以得到及时响应，如果接入中台这样一个同时服务多事业群的技术支持团队，如何确保业务需求可以被及时响应。此外，一旦接入中台，这意味着原有团队的人员需要进行调整，决策权可能也会被缩减，这种情况下，中台团队的处境十分艰难。</p><p> <strong>如果想做，能不能照搬阿里的组织架构呢？</strong></p><p> 这个肯定不可以，这里还需要区分中台的类型和原有企业的组织架构方式，毕竟现在有关中台的概念太多，比如数据中台、技术中台和业务中台等，类型不同、目的不同，调整的方式也有所区别。</p><p> 贾喜顺基于数据中台的搭建经验表示，如果企业在搭建数据中台后相应地进行架构调整，肯定会对中台落地提供更大保障。这是因为，中台涉及各业务系统数据的汇集、治理、标准和推广，这些都需要从组织层面来保障。就原来垂直业务线的团队而言，部门人员很大可能会缩减，中台是把以往企业各部门做的同样的事情进行集中，这样的话，其中有部分人员可能要被调整到其他部门，比如偏业务分析类工作；另一部分比较偏底层的技术人员在垂直业务领域就可能不需要了。此外，人员结构也会有变化：原有的底层技术、研发人员会缩减，在实践数据中台的垂直业务线团队更偏重面向业务的应用产品研发人员和业务分析人员。</p><p> 在王健看来，数据中台和技术中台其实是传统企业最喜欢率先引入建设的，因为相对而言，传统企业内部对于技术和数据团队的划分相对明确，尤其是业务并不是非常杂的时候，技术团队和数据团队往往就是一个独立的、全面支持的角色，比如原来做数据平台的团队，现在就可以直接继续承担数据中台的建设，不需要做太多结构上的调整，毕竟不是非常影响业务，而业务中台则是一定要动组织的，这个过程涉及多条业务线的利益关系，这之间的屏障很难打破。照搬肯定不行，其他人调整是为了业务的横向扩展（例如做全球化），你的目的是为了纵向数据打通，这显然不可复制，还是得想清楚调整的目的是什么。</p><p> 然而，在汪源的定义中，<strong>所有的中台都是业务中台</strong>，数据中台是一种特殊的业务中台，一般指以负责数据采集、数据集成、数据治理，指标体系和数据仓库统一建设等数据管理活动的组织。当前阶段，他认为不存在技术中台，现在业界所谓的技术中台其实都是云计算、AI 算法等技术平台，这些技术平台没有业务属性，做这些平台的人也不懂业务，称做中台是不合适的。</p><p> 管理上的困难主要来自于技术属性较弱的 PMO（Project Management Office）、推荐搜索、数据分析等专业能力部门，这些部门的发展存在很大的不稳定性，如果能力不能持续的提升和沉淀，就可能导致部门的分拆。这么多年分分合合都有。正是基于这些经历，汪源才提出以能力组、技术平台和方法论为主的标准能力组织、包含专向组的胖中台组织、中台组织到平台组织的转化等方法，以应对不同的情况。</p><p> 中台和各前台业务团队是支撑和合作的关系，这两类团队需要一起制定工作规划，一起确定绩效目标，<strong>因为有一些绩效目标是中台和前台业务团队一起背</strong>。除此之外，中台团队应该有部分人员是专职对接和服务每个核心的前台业务，这些人应该和前台业务团队坐在一起，团建应该一起去，汪源称之为“专人就位”，这样才能塑造信任和默契。如果前台团建都不叫你去，那你这个中台就危险了。（阿里各服务中心的核心架构师和运营人员会定期参与前端业务方的业务会议或重要项目的研讨会）</p><p> 对于前台业务团队来说，最大的变化是得放弃完全控制权，承担一定风险，换回来的是更低成本、更高效率、更高质量的服务，更强的能力。</p><p> 基于如上种种可能发生的变化，中台的组织架构调整问题鲜少人谈。</p><p> 3 组织架构怎么调？</p><p>  中台往往是企业里面最费力不讨好、最容易失败的团队，做不好看起来就是在给各个团队制造麻烦。——王健</p><p> 组织架构调整是一个很大的问题，典型的组织架构就包括：直线职能型（U）、事业部型（M）、矩阵型、网络型、平台型，还不算各种组合和变体；如果结合经营模式，还需要了解大家常常提到的阿米巴经营模式以及海尔的自主经营体……所以，这些肯定不是一篇文章就可以讲清楚的，此处着重讲解中台战略的推动者和中台团队的人员构成。</p><p> 中台的推动者</p><p> 如上文言，阿里推进中台战略的关键人物是行癫，行癫在 2015 年 3 月份开始已经是阿里巴巴中国零售平台负责人；2018 年底，京东商城调整组织架构，中台组织规划（如下图）首次完整亮相，负责人徐雷是京东零售集团的轮值 CEO；2019 年 1 月 4 日，腾讯正式宣布成立技术委员会，腾讯高级执行副总裁、技术工程事业群总裁卢山和腾讯高级执行副总裁、云与智慧产业事业群总裁汤道生两名腾讯总办成员牵头，几大事业群的技术负责人悉数进入技术委员会决策圈，这被评为中台战略的良好开端……</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VOVT07wjhHugYnzCFI96WQ58g74iahkicoCtrarpia2sMApyAZICBK13icZP06gvoicoic0TtPbNFZM27mQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 综上，大厂推进中台战略的决策人物（团队成员）的职级均不低，三位专家在采访中也在这一点上达成了统一：<strong>中台战略的推进过程一定是自顶向下的，至少是 CIO/CTO 层面向下推动，一定需要得到高层的支持。**</strong>否则，很难切动组织架构调整中的利益网。**</p><p> “中台建设的前期可能没有给业务带来多大帮助，反而制造了很多问题，如果没有 CIO、CTO 甚至 CEO，或者技术委员会、战略规划部门等的支持，很难进行，可能原来想做一个业务中台，后来因为无法撬动业务，数据也拿不到，最终的建设效果就会大打折扣”，王健进一步补充道，“如果这时领导层没有驱动力帮助继续推进这件事情，这个中台推也不是，不推也不是，因此我认为中台建设应该是一个自上而下的驱动过程。”</p><p> 此外，大部分员工是很难站在一定的高度去做一个”看十年、做一年“的规划，特别是当一件事和眼前的 KPI 难以达成平衡时，中台的工作会受到各个方面的挑战。因此高层的坚定支持是中台战略的第一必要条件。中台的价值是有条件的，搭建完成后还得有机会来享受成果，这个判断也需要高层来完成。额外的，高层还需要推动一些规范的建设，如交互规范、视觉规范、视觉配套的前端组件规范等，在这些规范的约束下，中台服务搭建的难度会大大降低。</p><p> 对于数据中台的建设，贾喜顺同样表示：“数据中台是“一把手”工程，需要从上到下进行。中台数据是战略层面的事情而不是战术层面，自下向上推动几乎没有可能，比如涉及标准统一，从下而上只能看到一个点，难免会以偏概全。”</p><p> 中台团队的人员构成</p><p> 建设中台对原有垂直业务线的人员可能会有很大影响，那么，中台团队的人员又是从哪来的呢？</p><p> 就数据中台团队的搭建而言，贾喜顺表示，这与团队一把手的想法也有关系，通常会从企业内部的垂直业务线进行人才筛选，在组织架构调整或者成立中台团队中，会有一部分人从垂直业务线剥离出来。这是因为企业内部的人更了解业务，会比外部招聘的人更容易进入状态。不过，对于传统企业，其内部更偏管理，数据中台团队建设更多的需要借助外部力量，如搭建数据中台的企业，再在企业内部辅助配一些团队人员进行支撑。</p><p> 王健也基本赞同上述观点，一开始大多是从前台抽调，毕竟企业资源有限，不可能纯招一批人，这些人可能包含架构师等实力非常强的人，因为业务中台的建设者要比各垂直业务线更懂业务，不仅仅是懂技术就可以的，尤其是很多公司是产品型文化，可能还会配备产品经理，这可能与传统企业里面的项目经理有些类似，但要有很强的沟通和协调能力，需要跟所有业务线战斗，然后服务好所有业务方，但如果没处理好组织关系，业务方给到中台的人可能是自己不想用的。</p><p> 汪源同样认为：外部招聘对于构建中台团队往往很难，因为中台团队一要懂业务，还需要得到前台业务的信任，所以最好是从内部培养和选拔，可以从平台团队选拔，但此时要配置懂业务的人配合，也可以从业务线抽调。</p><p> 中台团队的核心管理层要求具备业务经验和敏感度，中台一要懂业务；二要有强的执行力、目标感和沟通能力，因为中台要跨部门推动工作落地；三要有强的逻辑分析能力，因为中台工作比较抽象，要提炼。</p><p> 综上，中台团队的人员组成就比较清晰了：<strong>内部抽调是重要来源；**</strong>人员大都既懂业务，又得懂技术；<strong>**团队内部最好有一个沟通和协调能力较强的人员，这个人是中台团队对外沟通的桥梁，不同企业叫法不同，比如阿里最为核心的角色是业务架构师，但可以简单理解为中台的产品经理。</strong></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VOVT07wjhHugYnzCFI96WQ5fsTgFaQrvtqcFoMqJf346jN5yXibicnx9WbzVf6zibW5Vn8YQ5GYWD0Hw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 图源：《我的一年中台实战录》</p><p> 如上图，中台产品经理也被认为是 B 端产品经理的一种类型，有 B 端通用的能力要求，比如擅长做抽象建模、具备一定的研发技术功底、懂 UML 等，不同企业要求不同，此处就不一一展开了。</p><p> 4 造中台，钱应该谁出？</p><p> 企业在推动一些决策落地时，往往背后还有两个重要考量：这件事情能带来成本的节省吗？如果不能，这件事情可以带来更多营收吗？如果都不能，这件事情如此复杂，做的必要性是什么？</p><p> 众所周知，阿里建设中台最初源于马云带领集团高管拜访 Supercell 说起，这是一家位于赫尔辛基的移动游戏公司，这家公司号称是世界上最成功的移动游戏公司，其当时已经在使用“中台模式”接连推出爆款游戏，<strong>在不到 200 人的情况下成为了年税前利润 15 亿美元的公司。**</strong>2016 年 6 月，中国腾讯公司以 86 亿美元收购了这家公司 84.3% 的股权，每一名员工人均贡献估值超过 3.54 亿人民币。**</p><p> 通过建设中台，Supercell 拥有了快速推出产品、快速试错（一旦产品公测期间反馈不好，团队会快速决定放弃）的能力，进而可以在人数不多的情况下创造如此大的利润。<strong>虽然中台可能创造的利润非常可观，但是企业在建设中台的过程中，对前路尚不清晰时，钱应该谁来出呢？</strong></p><p> 对于技术服务类企业，中台对外售卖，这个问题很好解决，起码这个团队是盈利的，但在很多传统企业，技术往往仅支持内部业务，是一个纯成本的部门，当然这肯定是为业务带来了价值，只是直观来看，这是一个不营收的部门。如果站在为业务赋能的角度，业务中台的钱显然需要业务部门出一部分，建成之后可能还需要从业务方分走部分利润。</p><p> 但这条路很难走通，每条业务线都有自己的 OKR 或者 KPI，这件事情对各业务部门的考核可能没有直接帮助，甚至于在局部较短时间内是阻碍当年 KPI 达成的。</p><p> 王健表示，试想一下，如果一家企业要推出一款产品，很少有上来就采用众筹模式，让用户预付款，这样会对产品产生很大的短期交付压力，也不利于产品的初始阶段研发。相反，现在很多企业推出的产品，前期都是免费的，先通过投资机构注资研发，快速推向市场获取用户反馈，再不断改进并适时考虑向用户增值收费。如果考虑让公司从战略投资层面出这个钱，那么公司肯定也是要考虑收支平衡问题，投资的目的是什么，需要多长时间可以带来收益，如何合理制定中台团队的 OKR，这些都是需要提前想清楚的。</p><p> 比如，阿里业务中台团队的绩效考核会考虑服务稳定性、业务创新、服务接入量以及客户满意度四项指标。其中，服务稳定是重中之重，这部分的考核比重会占整体的 40% 左右；适当允许一定数量因为创新业务上线带来的事故，鼓励团队创新，这部分可能会在 25% 左右；吸引更多前端业务方接入，一般会占 20% 左右，剩下的是客户满意度。</p><p> 但是，贾喜顺也提醒道：建设数据中台是个长期过程，不是三个月或者半年就能出成效的，决策者需要在理念上进行转变。言外之意，即便企业决定通过战略投资的方式建设中台，但短期内也未必可以看到收益。</p><p> 5 结束语</p><p> 建设中台是一个非常复杂的过程，这不是简单的决策而是战略层面的调整。汪源在采访最后表示：“建设中台是比较复杂的，所以首先要判断是否有必要，比如是否觉得核心能力确实存在较大短板；跨业务或项目的共享做得不够；需求变化快且多；数据经常出错或者不一致等。如果需求不大，时机不成熟，可以再观察观察。”</p><p> 对于确实规划建设中台的，汪源还是建议要从组织、支撑技术和方法论三个方面都要做好准备，这方面的内容很多，很难给出几条简单的建议就能起到很大的作用。建议第一步先做自主研究，对建设中台有一个总体的理解和把握；第二步找有建设经验的团队学习。</p><p> 最后，本文引用王健在采访中的一句话作为结尾：建设中台不能天天喊口号，如果既不敢调动资源，也不敢调整组织架构，还整天担心对前台业务的影响，难以承担失败可能带来的风险，这很难成功。中台承载的是企业最核心的业务能力，最核心的差异化竞争力，是战略层面的事情，没有战略层面的决心和耐心坚持下来就很难看到成果，有的时候，中台建设确实也需要“因为相信，所以看见”。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;中台禁区-为什么最关键的组织架构却鲜少人谈？&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/qgbSvoTabIljYYuMCmlHcw&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixi
      
    
    </summary>
    
      <category term="好文转载" scheme="http://zhangyu8.me/categories/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/"/>
    
    
      <category term="好文转载" scheme="http://zhangyu8.me/tags/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>自学是门手艺</title>
    <link href="http://zhangyu8.me/2019/08/14/%E8%87%AA%E5%AD%A6%E6%98%AF%E9%97%A8%E6%89%8B%E8%89%BA/"/>
    <id>http://zhangyu8.me/2019/08/14/自学是门手艺/</id>
    <published>2019-08-13T16:00:00.000Z</published>
    <updated>2019-09-10T05:55:30.023Z</updated>
    
    <content type="html"><![CDATA[<p> <a href="http://the-craft-of-selfteaching.surge.sh/#/" target="_blank" rel="noopener">http://the-craft-of-selfteaching.surge.sh/#/</a></p><p> 没有自学能力的人没有未来</p><p>李笑来 </p><p> 都说，人要有一技之长。那这一技究竟应该是什么呢？</p><p>  自学能力是唯一值得被不断磨练的长技。</p><p> 磨练出自学能力的好处在于，无论这世界需要我们学什么的时候，我们都可以主动去学，并且还是马上开始 —— 不需要等别人教、等别人带。</p><p> 哪怕有很强的自学能力的意思也并不是说，什么都能马上学会、什么都能马上学好，到最后无所不精无所不通…… 因为这里有个时间问题。无论学什么，都需要耗费时间和精力，与此同时更难的事情在于不断填补耐心以防它过早耗尽。另外，在极端的情况下，多少也面临天分问题。比如身高可能影响打篮球的表现，比如长相可能影响表演的效果，比如唱歌跑调貌似是很难修复的，比如有些人的粗心大意其实是基因决定的，等等。不过，以我的观察，无论是什么，哪怕只是学会一点点，都比不会强。哪怕只是中等水平，就足够应付生活、工作、养家糊口的需求。</p><p> 我在大学里学的是会计专业，毕业后找不到对口工作，只好去做销售 —— 没人教啊！怎么办？自学。也有自学不怎么样的时候，比如当年研究生课程我就读不完。后来想去新东方教书 —— 因为听说那里赚钱多 —— 可英语不怎么样啊！怎么办？自学。离开新东方去创业，时代早就变了，怎么办？自学，学的不怎么样，怎么办？硬挺。虽然创业这事儿后来也没怎么大成，但竟然在投资领域开花结果 —— 可赚了钱就一切平安如意了吗？并不是，要面对之前从来没可能遇到的一些险恶与困境，怎么办？自学。除了困境之外，更痛苦的发现在于对投资这件事来说，并没有受过任何有意义的训练，怎么办？自学。觉得自己理解的差不多了，一出手就失败，怎么办？接着学。</p><p> 我出身一般，父母是穷教师。出生在边疆小镇，儿时受到的教育也一般，也是太淘气 —— 后来也没考上什么好大学。说实话，我自认天资也一般，我就是那种被基因决定了经常马虎大意的人。岁数都这么大了，情商也都不是一般的差 —— 还是跟年轻的时候一样，经常莫名其妙就把什么人给得罪透了……</p><p> 但，我过得一直不算差。</p><p> 靠什么呢？人么，一个都靠不上。到最后，我觉得只有一样东西真正可靠 —— <strong>自学能力</strong>。于是，经年累月，我磨练出了一套属于我自己的本领：只要我觉得有必要，我什么都肯学，学什么都能学会到够用的程度…… 编程，我不是靠上课学会的；英语，不是哪个老师教我的；写作，也不是谁能教会我的；教书，更没有上过师范课程；投资，更没人能教我 —— 我猜，也没人愿意教我…… 自己用的东西自己琢磨，挺好。</p><p> 关键在于，自学这事儿并不难，也不复杂，挺简单的，因为它所需要的一切都很朴素。</p><p> 于是，从某个层面上来看，我每天都过的很开心。为什么？因为我有未来。凭什么那么确信？因为我知道我自己有自学能力。</p><p> <strong>—— 我希望你也有。</strong></p><p> 准确地讲，希望你有个更好的未来。</p><p> 而现在我猜，此刻，你心中也是默默如此作想的罢。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; &lt;a href=&quot;http://the-craft-of-selfteaching.surge.sh/#/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://the-craft-of-selfteaching.surge.sh/#/&lt;/a&gt;&lt;/
      
    
    </summary>
    
      <category term="好文转载" scheme="http://zhangyu8.me/categories/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/"/>
    
    
      <category term="好文转载" scheme="http://zhangyu8.me/tags/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>1小时学会ansible</title>
    <link href="http://zhangyu8.me/2019/07/23/1%E5%B0%8F%E6%97%B6%E5%AD%A6%E4%BC%9Aansible/"/>
    <id>http://zhangyu8.me/2019/07/23/1小时学会ansible/</id>
    <published>2019-07-22T16:00:00.000Z</published>
    <updated>2019-09-10T05:55:42.486Z</updated>
    
    <content type="html"><![CDATA[<p>本文转自</p><p><a href="https://mp.weixin.qq.com/s?src=11&amp;timestamp=1564380781&amp;ver=1757&amp;signature=h8aBLRflHl*ZDJzG13jy*MTf9v97KNW432JT0AyrjYKcY*fymfm2-qBPJ9axObRK4OmLojNYGZ28yoZUVlofFR2jQEi5IpmlgZdttmrFtejNCWqlVmgf56VxAAf305*f&amp;new=1" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?src=11&amp;timestamp=1564380781&amp;ver=1757&amp;signature=h8aBLRflHl*ZDJzG13jy*MTf9v97KNW432JT0AyrjYKcY*fymfm2-qBPJ9axObRK4OmLojNYGZ28yoZUVlofFR2jQEi5IpmlgZdttmrFtejNCWqlVmgf56VxAAf305*f&amp;new=1</a></p><h2 id="不想说话，任性！！！-🙃"><a href="#不想说话，任性！！！-🙃" class="headerlink" title="不想说话，任性！！！ 🙃"></a>不想说话，任性！！！ 🙃</h2><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgA3uoniaxZIVy1BfS9EDqQTo0l3rwFkd6bWh6wkgOjQhrcLaQ0nYaicDg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgaerLicx0RgibYuOZ7ZTIVXiaNxJicKEx7XbPicmcFWuyrYTl1Q8Km8SZoYA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgOeycml7OtknUChlSc5iajibEkUWeiaGYYOMEpOdib8gAxfagaicA8yeHSMA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgzds9hMwZibwNgNg7lUtNibnIS4ntyjQo1icG1WjwlLTbiaIuXnOzPhicMGg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgYbZNDEPk3x13ia7mVjlTL8YEUkvNd8hZgNbY52icAKuQ69kZuduFWLtQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgqvZ208oYCAxPWAb2x56Yl55WS9sHdVu28j7Kf7dVR9fonsxIVohGoA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgGRfDXsau99piaU6otN2ibT1FtjRungJ4DMxJ3RAKfGUbs5bC5Z9c7kLQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgNUKEmka0YrRpBfPUkboGAVmMgUZuYhDBfjuICbPwxPCSP5CsOiahG8A/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgNPIxlPJ44FjcvibFJXY10zIWnf1b7ERSyZNwKS9WVc2yw5GCjic10WRw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgQoArXT8B3icbMtU95aup0X2q1UMpEGtGcwjhiaKdvtYBPAggiaSpahBdQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtg0h2pkP1COD9jNbuOic5VkQ5JzdFTZNeevyHVgurhtsnfm8iadgmicUTwg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgiaficiaxW35bMnogJ0sUwArvdU445asTmSmrh70m1RGOkdjCzofqwMGCw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgrPTPnMGb36e01dh331bQibibKWPJCcx4oumfcVSSiaiaudUYSgSCuFs9Kg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtghgheTLkOSqCrR9zJ23TjnqYSgMHFHb5UeIYF2icibLibESdRiaL7KjqsgQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgbaAmXt0G7YKmV3QXicHhr7AbyB1GcI6Q3nPkLYc5KVWB31dH01OMPuw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgN3apv59fm11Q1wur640kt0Rjym8N43Z9ichNkRV31BjOWToBCLq6c2w/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgUn45LLHA2kXCeECSwWQlyATnapteY5FGXV0KtLlOajj0KZ3YXnqeRQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgtEiak3wDqRzEo6OicIJbXzZeiaY08Zo8LkY82nQKcE2not8dBvIfpNL0A/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文转自&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?src=11&amp;amp;timestamp=1564380781&amp;amp;ver=1757&amp;amp;signature=h8aBLRflHl*ZDJzG13jy*MTf9v97KN
      
    
    </summary>
    
      <category term="ansible" scheme="http://zhangyu8.me/categories/ansible/"/>
    
    
      <category term="ansible" scheme="http://zhangyu8.me/tags/ansible/"/>
    
  </entry>
  
</feed>
