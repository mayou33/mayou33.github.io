<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>大雨哥</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://zhangyu8.me/"/>
  <updated>2019-09-20T06:19:55.958Z</updated>
  <id>http://zhangyu8.me/</id>
  
  <author>
    <name>zhangyu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Linux内核优化详解-必备</title>
    <link href="http://zhangyu8.me/2019/09/20/Linux%E5%86%85%E6%A0%B8%E4%BC%98%E5%8C%96%E8%AF%A6%E8%A7%A3/"/>
    <id>http://zhangyu8.me/2019/09/20/Linux内核优化详解/</id>
    <published>2019-09-19T16:00:00.000Z</published>
    <updated>2019-09-20T06:19:55.958Z</updated>
    
    <content type="html"><![CDATA[<p>centos6 </p><p> /etc/sysctl.conf </p><p>centos7</p><p>sysctl -p /usr/lib/sysctl.d/00-system.conf  </p><p>注意：/etc/sysctl.conf文件中设置的内核运行时参数可能会被应用调优的配置文件覆盖.</p><p>但是也可以自建一个单独的配置文件</p><hr><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br></pre></td><td class="code"><pre><span class="line">###参考 CIS-LINUX centos7</span><br><span class="line">其他国外专家推荐</span><br><span class="line">ibm调优</span><br><span class="line"></span><br><span class="line">https://www.ibm.com/developerworks/community/wikis/home?lang=en#!/wiki/Welcome%20to%20High%20Performance%20Computing%20%28HPC%29%20Central/page/Linux%20System%20Tuning%20Recommendations</span><br><span class="line"></span><br><span class="line">https://www.ibm.com/developerworks/community/wikis/home?lang=en#!/wiki/Welcome%20to%20High%20Performance%20Computing%20%28HPC%29%20Central/page/Linux%20System%20Tuning%20Recommendations</span><br><span class="line"></span><br><span class="line">##############################################################</span><br><span class="line"></span><br><span class="line">#####</span><br><span class="line"></span><br><span class="line"># Kernel sysctl configuration file for Red Hat Linux</span><br><span class="line">#</span><br><span class="line"># For binary values, 0 is disabled, 1 is enabled.  See sysctl(8) and</span><br><span class="line"># sysctl.conf(5) for more details.</span><br><span class="line"></span><br><span class="line"># Controls IP packet forwarding</span><br><span class="line">#0，表示禁止数据包转发，1表示允许</span><br><span class="line">###net.ipv4.ip_forward = 0</span><br><span class="line">##docker环境要开启</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"># rp_filter用于实现反向过滤技术</span><br><span class="line">#  0 - No source validation.</span><br><span class="line">#        1 - Strict mode as defined in RFC3704 Strict Reverse Path</span><br><span class="line">#            Each incoming packet is tested against the FIB and if the interface</span><br><span class="line">#            is not the best reverse path the packet check will fail.</span><br><span class="line">#            By default failed packets are discarded.  默认情况下，丢弃失败的数据包。</span><br><span class="line">#RFC3704中定义的严格模式严格反向路径每个传入数据包都针对FIB进行测试，如果接口不是最佳反向路径，则数据包检查将失败。</span><br><span class="line">#        2 - Loose mode as defined in RFC3704 Loose Reverse Path</span><br><span class="line">#            Each incoming packet&apos;s source address is also tested against the FIB</span><br><span class="line">#            and if the source address is not reachable via any interface</span><br><span class="line">#            the packet check will fail.</span><br><span class="line"># RFC3704中定义的松散模式宽松反向路径每个传入数据包的源地址还针对FIB进行测试，如果源地址无法通过任何接口访问，则数据包检查将失败。</span><br><span class="line">#        Current recommended practice in RFC3704 is to enable strict mode</span><br><span class="line"> #       to prevent IP spoofing from DDos attacks. If using asymmetric routing</span><br><span class="line"> #       or other complicated routing, then loose mode is recommended.</span><br><span class="line">#RFC3704中的当前推荐做法是启用严格模式以防止DDoS攻击的IP欺骗。 如果使用非对称路由或其他复杂路由，建议使用松散模式。</span><br><span class="line">#The default value is 0, but note that some distributions enable it in startup scripts.</span><br><span class="line">net.ipv4.conf.all.rp_filter = 1</span><br><span class="line">net.ipv4.conf.default.rp_filter = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"># 多网卡接收多播 arp_filter</span><br><span class="line">#0 - (default) The kernel can respond to ARP requests with addresses from other interfaces. This may seem wrong but it usually makes sense, because it increases the chance of successful communication.  IP addresses are owned by the complete host on Linux, not by particular interfaces. Only for more complex setups like load-balancing, does this behaviour cause problems.</span><br><span class="line">#1 - Allows you to have multiple network interfaces on the same subnet, and have the ARPs for each interface be answered based on whether or not the kernel would route a packet from the ARP&apos;d IP out that interface (therefore you must use source based routing for this to work). In other words it allows control of which cards (usually 1) will respond to an ARP request.</span><br><span class="line">#arp_filter for the interface will be enabled if at least one of conf/&#123;all,interface&#125;/arp_filter is set to 1, it will be disabled otherwise.</span><br><span class="line">net.ipv4.conf.all.arp_filter = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line"># Do not accept source routing</span><br><span class="line"># 处理无源路由的包</span><br><span class="line">#Accept packets with SRR option.</span><br><span class="line">#conf/all/accept_source_route must also be set to 1 to accept packets with SRR option on the interface.</span><br><span class="line">#Default: 1 (router), 0 (host).</span><br><span class="line"></span><br><span class="line">net.ipv4.conf.all.accept_source_route = 0</span><br><span class="line">net.ipv4.conf.default.accept_source_route = 0</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">##http://fedoraproject.org/wiki/QA/Sysrq</span><br><span class="line"># Controls the System Request debugging functionality of the kernel</span><br><span class="line">#SysRq 经常被称为 Magic System Request，它被定义为一系列按键组合。之所以说它神奇，是因为它在系统挂起，大多数服务已无法响应的情况下，还能通过按键组合来完成一系列预先定义的系统操作。通过它，不但可以在保证磁盘数据安全的情况下重启一台挂起的服务器，避免数据丢失和重启后长时间的文件系统检查，还可以收集包括系统内存使用，CPU 任务处理，进程运行状态等系统运行信息，甚至还可能在无需重启的情况下挽回一台已经停止响应的服务器。</span><br><span class="line">#0 不启用 SysRq ，1 启用</span><br><span class="line">kernel.sysrq = 0</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"># Controls whether core dumps will append the PID to the core filename.</span><br><span class="line"># Useful for debugging multi-threaded applications.</span><br><span class="line">#当系统中的一些程序在遇到一些错误以及crash时，系统会自动产生core file记录crash时刻系统信息包括内存和寄存器信息，用以程序员日后debug时可以使用。这些错误包括断错误，非法指令，总线错误和用户自己生成的退出信号等等。一般的，core file会在当前文件夹中存放。</span><br><span class="line">kernel.core_uses_pid = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"># Controls the use of TCP syncookies</span><br><span class="line">#开启SYN洪水攻击保护</span><br><span class="line">#表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；</span><br><span class="line">##这个参数也可以不添加。该参数对应系统路径为：/proc/sys/net/ipv4/tcp_syncookies</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"># Controls the default maxmimum size of a mesage queue</span><br><span class="line">#该文件指定一个消息队列的最大长度（bytes)缺省设置：16384</span><br><span class="line">kernel.msgmnb = 1073741824</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"># Controls the maximum size of a message, in bytes</span><br><span class="line">#该文件指定了从一个进程发送到另一个进程的消息的最大长度（bytes）。进程间的消息传递是在内核的内存中进行的，不会交换到磁盘上，所以如果增加该值，则将增加操作系统所使用的内存数量。</span><br><span class="line">kernel.msgmax = 20480000</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"># Controls the maximum shared segment size, in bytes</span><br><span class="line">#该文件表示内核所允许的最大共享内存段的大小（bytes）。</span><br><span class="line">#缺省设置：33554432</span><br><span class="line">#建议设置：物理内存 * 50%</span><br><span class="line">## Oracle-Validated setting for kernel.shmmax is 4398046511104</span><br><span class="line">kernel.shmmax = 4398046511104</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"></span><br><span class="line"># Controls the maximum number of shared memory segments, in pages</span><br><span class="line">#该文件表示在任何给定时刻，系统上可以使用的共享内存的总量（bytes）。</span><br><span class="line">kernel.shmall = 4294967296</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">#该文件指定消息队列标识的最大数目，即系统范围内最大多少个消息队列。缺省设置：16</span><br><span class="line">kernel.msgmni = 4096000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"></span><br><span class="line">######## https://fasterdata.es.net/host-tuning/linux</span><br><span class="line">##For a host with a 10G NIC optimized for network paths up to 200ms RTT, and for friendliness to single and parallel stream tools, or a 40G NIC up on paths up to 50ms RTT:</span><br><span class="line">#对于具有10G网卡的主机，针对高达200ms RTT的网络路径进行了优化，适用于单一和并行流工具，或40G网卡，路径长达50ms RTT</span><br><span class="line"></span><br><span class="line"># allow testing with buffers up to128MB</span><br><span class="line">＃允许使用高达128MB的缓冲区进行测试</span><br><span class="line">#指定了接收窗口套接字缓冲区大小的最大值，单位是字节。</span><br><span class="line">net.core.rmem_max = 134217728</span><br><span class="line">#指定了发送套接字缓冲区大小的最大值，单位是字节。</span><br><span class="line">net.core.wmem_max = 134217728</span><br><span class="line"></span><br><span class="line">#默认的TCP数据发送窗口大小（字节）。</span><br><span class="line">net.core.wmem_default = 11059200</span><br><span class="line"></span><br><span class="line">#默认的TCP数据接收窗口大小（字节）。</span><br><span class="line">net.core.rmem_default = 11059200</span><br><span class="line">##表示每个套接字所允许的最大缓冲区的大小。缺省设置：10240</span><br><span class="line">net.core.optmem_max= 2048000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#为自动调优定义每个 socket 使用的内存。第一个值是为 socket 的发送缓冲区分配的最少字节数。第二个值是默认值（该值会被 wmem_default 覆盖），缓冲区在系统负载不重的情况下可以增长到这个值。第三个值是发送缓冲区空间的最大字节数（该值会被 wmem_max 覆盖）。</span><br><span class="line"> ##https://fasterdata.es.net/host-tuning/linux</span><br><span class="line">#该文件包含3个整数值，分别是：min，default，max</span><br><span class="line">#Min：为TCP socket预留用于接收/接收缓冲的内存数量，即使在内存出现紧张情况下TCP socket都至少会有这么多数量的内存用于接收缓冲。</span><br><span class="line">#Default：为TCP socket预留用于接收/缓冲的内存数量，默认情况下该值影响其它协议使用的 net.core.wmem中default的 值。该值决定了在tcp_adv_win_scale、tcp_app_win和tcp_app_win的默认值情况下，TCP 窗口大小为65535。</span><br><span class="line">#Max：为TCP socket预留用于接收/缓冲的内存最大值。该值不会影响 net.core.wmem中max的值，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#与 tcp_wmem 类似，不过它表示的是为自动调优所使用的接收缓冲区的值。</span><br><span class="line">net.ipv4.tcp_rmem = 4096 87380 67108864 </span><br><span class="line"></span><br><span class="line">＃将Linux自动调优TCP缓冲区限制增加到64MB </span><br><span class="line">net.ipv4.tcp_wmem = 4096 65536 67108864 </span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">###linux自动调整内存分配的功能 cat /proc/sys/net/ipv4/tcp_moderate_rcvbuf </span><br><span class="line">###系统默认tcp_moderate_rcvbuf配置为1，表示打开了TCP内存自动调整功能。若配置为0，这个功能将不会生效（慎用）。</span><br><span class="line">###net.ipv4.tcp_moderate_rcvbuf = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"># recommended default congestion control is htcp 超文本缓冲 </span><br><span class="line">###### There seem to be bugs in both bic and cubic for a number of versions of the Linux kernel up to version 2.6.33. We recommend using htcp with older kernels to be safe.</span><br><span class="line">#If cubic and/or htcp are not listed try the following, as most distributions include them as loadable kernel modules:</span><br><span class="line">#要加入开机自启</span><br><span class="line">#/sbin/modprobe tcp_htcp</span><br><span class="line">#/sbin/modprobe tcp_cubic</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">#为CentOS7 / Debian8主机推荐</span><br><span class="line">##https://fasterdata.es.net/host-tuning/packet-pacing/</span><br><span class="line">##数据包调度使用FQ（公平队列）调度程序</span><br><span class="line">##从Linux内核3.11或更高版本开始，有一个新的“公平排队”调度程序，其中包含的代码可以更好地从快速主机中调出数据包。有关更多详细信息，请参阅https://lwn.net/Articles/564978/。对于基于RHEL的操作系统，FQ已经在v7.2中被移植到3.10.0-327内核。</span><br><span class="line"></span><br><span class="line">net.core.default_qdisc = fq</span><br><span class="line">##还有执行下面 的命令To both pace and shape the bandwidth:</span><br><span class="line">##https://www.systutorials.com/docs/linux/man/8-tc-fq/</span><br><span class="line">##tc qdisc add dev（网卡名 ens192） root fq maxrate 10gbit</span><br><span class="line"></span><br><span class="line">##内核版本低于4.9的，用htcp。</span><br><span class="line">##net.ipv4.tcp_congestion_control=htcp</span><br><span class="line">##内核版本高于等于4.9的，用google的bbr。</span><br><span class="line">net.ipv4.tcp_congestion_control=bbr</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"># recommended for hosts with jumbo frames enabled 开启系统巨型帧</span><br><span class="line">#如果您使用的是巨帧，我们建议设置tcp_mtu_probing = 1来帮助避免MTU黑洞的问题。将其设置为2有时会导致性能问题</span><br><span class="line">#＃为启用了巨型帧的主机推荐</span><br><span class="line">net.ipv4.tcp_mtu_probing=1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"></span><br><span class="line">##########################TIME_WAIT 相关参数</span><br><span class="line">###https://ieevee.com/tech/2017/07/19/tcp-tw-recycle.html</span><br><span class="line">#net.ipv4.tcp_max_tw_buckets 表示系统同时保持TIME_WAIT套接字sockets的最大数量，</span><br><span class="line"></span><br><span class="line">#如果超过这个数值，TIME_WAIT套接字将立刻被清除并打印警告信息。默认为180000</span><br><span class="line">#对于Apache、Nginx等服务器来说可以将其调低一点，如改为5000~30000，不通业务的服务器也可以给大一点，比如LVS、Squid。此项参数可以控制TIME_WAIT套接字的最大数量，避免Squid服务器被大量的TIME_WAIT套接字拖死。该参数对应系统路径为：/proc/sys/net/ipv4/tcp_max_tw_buckets</span><br><span class="line"></span><br><span class="line"># TIME_WAIT 只在主动关闭的一端出现</span><br><span class="line"> </span><br><span class="line">#之所以要设定这个限制，纯粹为了抵御那些简单的 DoS 攻击，千万不要人为的降低这个限制，</span><br><span class="line">#不过，如果网络条件需要比默认值更多，则可以提高它(或许还要增加内存)。</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 1440000</span><br><span class="line"></span><br><span class="line">#####下面两个参数</span><br><span class="line">###如果开启，在NAT环境下会引发问题。开启tcp_tw_recycle会引起上述syn报文被丢弃的问题。</span><br><span class="line">## 实际的网络情况中 公司家庭网络都走NAT。只能依赖于NAT分享同一个公网IP。</span><br><span class="line"></span><br><span class="line">#开启TCP连接中TIME-WAIT sockets的快速回收，该参数对应系统路径为：/proc/sys/net/ipv4/tcp_tw_recycle，默认为0，表示关闭。</span><br><span class="line">net.ipv4.tcp_tw_recycle = 0</span><br><span class="line"></span><br><span class="line">#tcp_timestamps用来支持RTT的来回时间计算。默认打开的 .</span><br><span class="line"></span><br><span class="line">#tcp_tw_recycle/tcp_timestamps都开启的条件下，60s内同一源ip主机的socket connect请求中的timestamp必须是递增的,导致部分通过NAT上网client无法正确连接服务器，故障表现为client发出SYN后无法收到server返回 的SYN+ACK，推荐的解决方法是关闭</span><br><span class="line">net.ipv4.tcp_timestamps = 0</span><br><span class="line"></span><br><span class="line">##复用TIME_WAIT连接---表示是否允许重新应用处于TIME-WAIT状态的socket用于新的TCP连接。</span><br><span class="line">#默认为0，表示关闭。如果使用tcp_tw_reuse，请激活tcp_timestamps，否则无效.</span><br><span class="line">#1表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，该参数对应系统路径为：/proc/sys/net/ipv4/tcp_tw_reuse</span><br><span class="line">net.ipv4.tcp_tw_reuse = 0</span><br><span class="line"></span><br><span class="line">##提示：reuse和recycle这两个参数是为防止生产环境下Web、Squid等业务服务器time_wait网络状态数量过多设置的。不同文章观点不一样。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 表示如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间.默认值是 60秒,该参数对应系统路径为：/proc/sys/net/ipv4/tcp_fin_timeout</span><br><span class="line">net.ipv4.tcp_fin_timeout = 2</span><br><span class="line"></span><br><span class="line">#################################################</span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"></span><br><span class="line">##使用 Selective ACK﹐它可以用来查找特定的遗失的数据报— 因此有助于快速恢复状态。</span><br><span class="line">#表示是否启用有选择的应答（Selective Acknowledgment），这可以通过有选择地应答乱序接收到的报文来提高性能（这样可以让发送者只发送丢失的报文段）。</span><br><span class="line">#(对于广域网通信来说这个选项应该启用，但是这会增加对 CPU 的占用。)</span><br><span class="line">net.ipv4.tcp_sack = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">###启用转发应答（Forward Acknowledgment），这可以进行有选择应答（SACK）从而减少拥塞情况的发生；这个选项也应该启用。</span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_fack = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"></span><br><span class="line">###启用 RFC 1323 定义的 window scaling；要支持超过 64KB 的窗口，必须启用该值。</span><br><span class="line">net.ipv4.tcp_window_scaling = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">#https://cwiki.apache.org/confluence/display/GEODE/Network+Configuration+Best+Practices</span><br><span class="line">##该参数对应系统路径为：/proc/sys/net/ipv4/tcp_max_orphans 65536</span><br><span class="line">#系统所能处理不属于任何进程的TCP sockets最大数量。假如超过这个数量，那么不属于任何进程的连接会被立即reset，并同时显示警告信息。</span><br><span class="line">#之所以要设定这个限制﹐纯粹为了抵御那些简单的 DoS 攻击﹐千万不要依赖这个或是人为的降低这个限制，更应该增加这个值(如果增加了内存之后)。</span><br><span class="line">#每个套接字最多能够吃掉你64K不可交换的内存。</span><br><span class="line">net.ipv4.tcp_max_orphans = 400000</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">##https://www.frozentux.net/ipsysctl-tutorial/chunkyhtml/tcpvariables.html</span><br><span class="line"># </span><br><span class="line">##指定所能接受SYN同步包的最大客户端数量，即半连接上限</span><br><span class="line">#该参数为服务器端用于记录那些尚未收到客户端确认信息的连接请求最大值。该参数对象系统路径为：/proc/sys/net/ipv4/tcp_max_syn_backlog</span><br><span class="line">#表示SYN队列的长度，默认为1024，加大队列长度 可以容纳更多等待连接的网络连接数。</span><br><span class="line">##具体取决于您拥有的内存量。</span><br><span class="line">###下面是tcp(7) - Linux man page的说法--</span><br><span class="line">#我没有在源码找到include/net/tcp.h里面的TCP_SYNQ_HSIZE</span><br><span class="line">###如果将此值提高到大于1024的值，则最有可能更改TCP_SYNQ_HSIZE值并重新编译##内核。修改include/net/tcp.h里面的TCP_SYNQ_HSIZE</span><br><span class="line">###应设置此值以使此公式保持为真：</span><br><span class="line">##TCP_SYNQ_HSIZE * 16 &lt;= tcp_max_syn_backlog</span><br><span class="line">###换句话说，TCP_SYNQ_HSIZE乘以16应该小于或等于tcp_max_syn_backlog。</span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 1000000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">##http://www.saunix.cn/1255.html</span><br><span class="line">##这个参数用于调节系统同时发起的TCP连接数，在高并发的请求中，默认的值可能会导致链接超时或重传，因此，需要结合并发请求数来调节此值。该参数对应系统路径为：/proc/sys/net/core/somaxconn</span><br><span class="line">#服务端所能accept即处理数据的最大客户端数量，即完成连接上限。</span><br><span class="line">###最大数量可以是1到2147483647</span><br><span class="line">#表示socket监听（listen）的backlog上限。什么是backlog呢？backlog就是socket的监听队列，当一个请求（request）尚未被处理或建立时，他会进入backlog。</span><br><span class="line">#tcp_max_syn_backlog用于指定酒席现场面积允许容纳多少人进来；</span><br><span class="line">#somaxconn用于指定有多少个座位。</span><br><span class="line">###tcp_max_syn_backlog &gt;= somaxconn。</span><br><span class="line">net.core.somaxconn = 1000000</span><br><span class="line">################################</span><br><span class="line">#-------------------华丽的分割线--------------。</span><br><span class="line"># 处理不过来干脆就直接拒绝连接了</span><br><span class="line">##当守护进程太忙而不能接受新的连接，就象对方发送reset消息，默认值是false。这意味着当溢出的原因是因为一个偶然的猝发，那么连接将恢复状态。只有在你确信守护进程真的不能完成连接请求时才打开该选项，该选项会影响客户的使用。(对待已经满载的sendmail,apache这类服务的时候,这个可以很快让客户端终止连接,可以给予服务程序处理已有连接的缓冲机会,所以很多防火墙上推荐打开它)</span><br><span class="line">##默认值是0，建议是0</span><br><span class="line">tcp_abort_on_overflow=0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"></span><br><span class="line">#对于一个新建连接，内核要发送多少个 SYN 连接请求才决定放弃。不应该大于255，默认值是5，即每一个连线要在约 180 秒 (3 分钟) 后才确定超时</span><br><span class="line"># 表示在内核放弃建立连接之前发送SYN包的数量。该参数对应系统路径为：/proc/sys/net/ipv4/tcp_syn_retries</span><br><span class="line">net.ipv4.tcp_syn_retries = 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">##net.ipv4.tcp_synack_retries 参数的值决定了内核放弃连接之前发送SYN+ACK包的数量。该参数对应系统路径为：/proc/sys/net/ipv4/tcp_synack_retries </span><br><span class="line">###表示回应第二个握手包（SYN+ACK包）给客户端IP后，如果收不到第三次握手包（ACK包）后，不进行重试，加快回收“半连接”，不要耗光资源。</span><br><span class="line">#</span><br><span class="line">#默认为5，表示重发5次，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 2^6 -1 = 63s，TCP才会把断开这个连接。即“半连接”默认hold住大约180秒。(可以根据上面的 tcp_syn_retries 来决定这个值)</span><br><span class="line">net.ipv4.tcp_synack_retries = 1</span><br><span class="line"></span><br><span class="line">#####################</span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">#确定 TCP 栈应该如何反映内存使用；每个值的单位都是内存页（通常是 4KB）。第一个值是内存使用的下限。第二个值是内存压力模式开始对缓冲区使用应用压力的上限。第三个值是内存上限。在这个层次上可以将报文丢弃，从而减少对内存的使用。对于较大的 BDP 可以增大这些值（但是要记住，其单位是内存页，而不是字节）。</span><br><span class="line"></span><br><span class="line">#该文件包含3个整数值，分别是：low，pressure，high</span><br><span class="line">#low：当TCP使用了低于该值的内存页面数时，TCP不会考虑释放内存。(理想情况下，这个值应与指定给 tcp_wmem 的第 2 个值相匹配 - 这第 2 个值表明，最大页面大小乘以最大并发请求数除以页大小 (131072 * 300 / 4096)。 )</span><br><span class="line">#pressure：当TCP使用了超过该值的内存页面数量时，TCP试图稳定其内存使用，进入pressure模式，当内存消耗低于low值时则退出pressure状态。(理想情况下这个值应该是 TCP 可以使用的总缓冲区大小的最大值 (204800 * 300 / 4096)。 )</span><br><span class="line">#high：允许所有tcp sockets用于排队缓冲数据报的页面量。(如果超过这个值，TCP 连接将被拒绝，这就是为什么不要令其过于保守 (512000 * 300 / 4096) 的原因了。 在这种情况下，提供的价值很大，它能处理很多连接，是所预期的 2.5 倍；或者使现有连接能够传输 2.5 倍的数据。 我的网络里为192000 300000 732000)</span><br><span class="line">#一般情况下这些值是在系统启动时根据系统内存数量计算得到的。</span><br><span class="line">#缺省设置：24576 32768 49152</span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_mem = 94500000 915000000 927000000</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line"></span><br><span class="line">#######这3个参数与TCP KeepAlive有关</span><br><span class="line">#net.ipv4.tcp_keepalive_time 表示当keepalive启用时，TCP发送keepalive消息的频度。默认值是7200(2小时)，建议改为10分钟。该参数对应系统路径为：/proc/sys/net/ipv4/tcp_keepalive_time 。#表示TCP链接在多少秒之后没有数据报文传输启动探测报文; </span><br><span class="line">#特别是如果服务于大量仅需要短暂连接的客户端。很好的例子是Web服务器。这里的诀窍是通过将net.ipv4.tcp_keepalive_time调整到30分钟以内，可以减少安静的TCP连接的长度。</span><br><span class="line"></span><br><span class="line">#/proc/sys/net/ipv4/tcp_keepalive_intvl单位是也秒,表示前一个探测报文和后一个探测报文之间的时间间隔，缺省是75秒。</span><br><span class="line"></span><br><span class="line">#/proc/sys/net/ipv4/tcp_keepalive_probes表示探测的次数。在认定连接失效之前，发送多少个TCP的keepalive探测包。默认值是9。这个值乘以tcp_keepalive_intvl之后决定了，一个连接发送了keepalive之后可以有多少时间没有回应</span><br><span class="line"></span><br><span class="line">#tcp_retries2是系统在删除连接之前允许的重传次数，TCP默认最多做15次重传。根据RTO(retransmission timeout)不同，最后一次重传间隔大概是13到30分钟左右。如果15次重传都做完了，TCP/IP就会告诉应用层说：“搞不定了，包怎么都传不过去！”(这个值根据目前的网络设置,可以适当地改小,我的网络内修改为了5)</span><br><span class="line"></span><br><span class="line">##web服务器 推荐用如下配置</span><br><span class="line">#net.ipv4.tcp_keepalive_time = 300</span><br><span class="line">#net.ipv4.tcp_keepalive_probes = 3</span><br><span class="line">#net.ipv4.tcp_keepalive_intvl = 10</span><br><span class="line">#net.ipv4.tcp_retries2 = 5</span><br><span class="line">#意思是如果某个TCP连接在idle 300秒后,内核才发起probe.如果probe 3次(每次10秒)不成功,内核才彻底放弃,认为该连接已失效.</span><br><span class="line"></span><br><span class="line">##高可用应用服务器 推荐用如下配置</span><br><span class="line">net.ipv4.tcp_keepalive_time = 5</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 3</span><br><span class="line">net.ipv4.tcp_keepalive_intvl = 5</span><br><span class="line">net.ipv4.tcp_retries2 = 3</span><br><span class="line">#意思是如果某个TCP连接在idle 5秒后,内核才发起probe.如果probe 3次(每次5秒)不成功,内核才彻底放弃,认为该连接已失效.</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">#该选项用来设定允许系统打开的端口范围，即用于向外连接的端口范围。该参数对应系统路径为：/proc/sys/net/ipv4/ip_local_port_range</span><br><span class="line">#This applies to both TCP and UDP connections.</span><br><span class="line"># 本地自动分配的TCP UDP端口号范围</span><br><span class="line">#一般web应用服务器上可以设置9000 65535 来避开常用应用端口</span><br><span class="line">#类似nginx服务器可以用1025 65500</span><br><span class="line">net.ipv4.ip_local_port_range = 1025 65535</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">#明确的拥塞通知（英语：Explicit Congestion Notification，简称ECN）</span><br><span class="line">#许多现代产品中的TCP/IP协议已部分支持ECN；但是，大多数产品默认禁用ECN</span><br><span class="line">#0 – 禁用ECN，不发起也不接受</span><br><span class="line">#1 – 启用ECN，当传入连接请求时，并也在传出连接时尝试请求ECN</span><br><span class="line">#2 – （默认）传入连接请求时启用ECN，但不在传出连接上请求ECN</span><br><span class="line">#从2015年6月发布的Linux内核4.1开始，tcp_ecn_fallback机制按RFC 3168中的规定，在ECN被启用（值为1）时默认启用。</span><br><span class="line">#该回退机制在传出连接的初始设置时尝试ECN连接，对没有ECN能力的传输实行良好回退，缓解不支持ECN的主机或防火墙问题。</span><br><span class="line">net.ipv4.tcp_ecn = 0</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------                             </span><br><span class="line">###路由緩存刷新頻率，當一個路由失敗後多長時間跳到另一個路由，默認是300seconds </span><br><span class="line">net.ipv4.route.gc_timeout = 100</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">#If you ping the broadcast address of a network, all hosts are supposed to respond. </span><br><span class="line">#抵御 DDoS-- This makes for a dandy denial-of-service tool. Set this to 1 to ignore these broadcast messages.  </span><br><span class="line">#Ignoring &quot;broadcast pings&quot;                   </span><br><span class="line">net.ipv4.icmp_echo_ignore_broadcasts = 1</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">#&quot;bad error messages&quot; protection</span><br><span class="line">net.ipv4.icmp_ignore_bogus_error_responses = 1    </span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">#禁止Ping，默认是允许ping。-This will advise the kernel to drop any ICMP packets of type 0 (zero)</span><br><span class="line">#net.ipv4.icmp_echo_ignore_all = 1</span><br><span class="line"></span><br><span class="line">####cis 推荐</span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">##禁止转发ICMP重定向报文</span><br><span class="line">net.ipv4.conf.all.send_redirects=0</span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">##禁止转发ICMP重定向报文</span><br><span class="line">net.ipv4.conf.default.send_redirects=0</span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">###禁止包含源路由的ip包</span><br><span class="line">net.ipv4.conf.all.accept_redirects=0</span><br><span class="line">net.ipv4.conf.default.accept_redirects=0</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line"> ####禁止转发安全ICMP重定向报文</span><br><span class="line">net.ipv4.conf.all.secure_redirects=0</span><br><span class="line">net.ipv4.conf.default.secure_redirects=0</span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line"> ####禁止ipv6路由广播</span><br><span class="line">net.ipv6.conf.all.accept_ra=0</span><br><span class="line">net.ipv6.conf.default.accept_ra=0</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line"> #####禁止ipv6路由重定向</span><br><span class="line">net.ipv6.conf.all.accept_redirects=0</span><br><span class="line">net.ipv6.conf.default.accept_redirects=0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">#For   CentOS5/6 </span><br><span class="line">##表示在每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。/proc/sys/net/core/netdev_max_backlog，默认值为1000</span><br><span class="line"></span><br><span class="line">#因为Oracle或者一些Science / HPC指南使用net.core.netdev_max_backlog = 300000</span><br><span class="line">##感觉.netdev_max_backlog=/proc/sys/net/netfilter/nf_conntrack_max 这个值，设置600000</span><br><span class="line">net.core.netdev_max_backlog = 600000</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">#oracle 12cR1 requisite</span><br><span class="line">#内核所能分配到的最大句柄数 ，</span><br><span class="line">##淘宝优化推荐7672460</span><br><span class="line">fs.file-max = 7672460</span><br><span class="line"></span><br><span class="line">#####设置的信号量，这4个参数内容大小固定。</span><br><span class="line">#一般kernel.sem = 250 32000 100 128</span><br><span class="line">#上面的4个数据分别对应:SEMMSL、SEMMNS、SEMOPM、SEMMNI这四个核心参数，具体含义和配置如下。</span><br><span class="line">#SEMMSL ：用于控制每个信号集的最大信号数量。</span><br><span class="line">#          Oracle 建议将 SEMMSL 设置为 init.ora 文件（用于 Linux 系统中的所有数据库）中的最大 PROCESS 实例参数的设置值再加上 10 。此外， Oracle 建议将 SEMMSL 的值设置为不少于 100 。</span><br><span class="line">#SEMMNS：用于控制整个 Linux 系统中信号（而不是信号集）的最大数。</span><br><span class="line">#       Oracle 建议将 SEMMNS 设置为：系统中每个数据库的 PROCESSES 实例参数设置值的总和，加上最大 PROCESSES 值的两倍，最后根据系统中 Oracle 数据库的数量，每个加 10 。 使用以下计算式来确定在 Linux 系统中可以分配的信号的最大数量。它将是以下两者中较小的一个值：SEMMNS 或 (SEMMSL * SEMMNI)</span><br><span class="line">#SEMOPM： 内核参数用于控制每个 semop 系统调用可以执行的信号操作的数量。semop 系统调用（函数）提供了利用一个 semop 系统调用完成多项信号操作的功能。一个信号集能够拥有每个信号集中最大数量的SEMMSL 信号，因此建议设置 SEMOPM 等于SEMMSL 。</span><br><span class="line">#        Oracle 建议将 SEMOPM 的值设置为不少于 100 。</span><br><span class="line">#SEMMNI ：内核参数用于控制整个 Linux 系统中信号集的最大数量。</span><br><span class="line">#         Oracle 建议将 SEMMNI 的值设置为不少于 100</span><br><span class="line">#淘宝 PostgreSQL 优化</span><br><span class="line">kernel.sem = 50100 64128000 50100 1280</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#内核异步 I/O (KAIO) 请求 最大数量 </span><br><span class="line">fs.aio-max-nr = 1048576</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">#关闭ipv6</span><br><span class="line">####net.ipv6.conf.all.disable_ipv6 = 1</span><br><span class="line">####net.ipv6.conf.default.disable_ipv6 = 1</span><br><span class="line"> </span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">#This file contains the maximum number of memory map areas a process may have. Memory map areas are used as a side-effect of calling malloc, directly by mmap and mprotect, and also when loading shared libraries.</span><br><span class="line">#While most applications need less than a thousand maps, certain programs, particularly malloc debuggers, may consume lots of them, e.g., up to one or two maps per allocation.</span><br><span class="line">#The default value is 65536.</span><br><span class="line">#max_map_count这个参数就是允许一个进程在VMAs(虚拟内存区域)拥有最大数量，VMA是一个连续的虚拟地址空间，当进程创建一个内存映像文件时VMA的地址空间就会增加，当达到max_map_count了就是返回out of memory errors。</span><br><span class="line">vm.max_map_count = 1048575</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">##TCP Fast Open（TFO）——一种对TCP协议的扩展，允许在TCP握手期间的TCP-SYN 和TCP-SYN/ACK数据包中夹带数据，这样就减少了一个RTT。</span><br><span class="line">#内核最好升级4.x版本</span><br><span class="line">net.ipv4.tcp_fastopen = 3</span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">#vm.swappiness = 0 The kernel will swap only to avoid an out of memory condition</span><br><span class="line"> #  关闭交换分区</span><br><span class="line">#vm.swappiness = 1 Kernel version 3.5 and over, --------“1”是最小可能的“有效交换”设置</span><br><span class="line">#vm.swappiness = 10 设置为10，意味着当RAM为90％满时，交换将被使用，因此如果您有足够的RAM内存，可以轻松提高系统的性能。</span><br><span class="line">#vm.swappiness = 60 The default value.参数值设置为“60”表示当RAM达到40％容量时，内核将交换swap。</span><br><span class="line">#vm.swappiness = 100 表示积极的使用swap分区，并且把内存上的数据及时的搬运到swap空间里面</span><br><span class="line"></span><br><span class="line">vm.swappiness = 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线-------------- </span><br><span class="line">##该文件表示脏数据到达系统整体内存的百分比，此时触发pdflush进程把脏数据写回磁盘。缺省设置：0，禁用Block Debug模式</span><br><span class="line">vm.dirty_background_ratio = 5</span><br><span class="line"></span><br><span class="line">#该文件表示如果进程产生的脏数据到达系统整体内存的百分比，此时进程自行把脏数据写回磁盘。</span><br><span class="line"> #  如果系统进程刷脏页太慢，使得系统脏页超过内存 10 % 时，则用户进程如果有写磁盘的操作（如fsync, fdatasync等调用），则需要主动把系统脏页刷出。</span><br><span class="line"></span><br><span class="line">vm.dirty_ratio = 10</span><br><span class="line"></span><br><span class="line"># 系统脏页到达这个值，系统后台刷脏页调度进程 pdflush（或其他） 自动将(dirty_expire_centisecs/100）秒前的脏页刷到磁盘</span><br><span class="line"></span><br><span class="line">vm.dirty_background_bytes = 102400000</span><br><span class="line"></span><br><span class="line">#  比这个值老的脏页，将被刷到磁盘。6000表示60秒。</span><br><span class="line">vm.dirty_expire_centisecs = 6000    </span><br><span class="line"></span><br><span class="line"> # pdflush（或其他）后台刷脏页进程的唤醒间隔， 50表示0.5秒。</span><br><span class="line">vm.dirty_writeback_centisecs = 50 </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">##https://ieevee.com/tech/2017/09/10/overcommit.html</span><br><span class="line">#该文件指定了内核针对内存分配的策略，其值可以是0、1、2。缺省设置：0</span><br><span class="line">#0， 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。</span><br><span class="line">#允许用户轻微的overcommit。</span><br><span class="line">##这是Linux的默认策略，Heuristic overcommit handling。在这种情况下，除了一些特别夸张的内存申请，一般的内存申请都会被允许。</span><br><span class="line">###什么样的内存申请算是“夸张”呢？</span><br><span class="line">###如果申请的内存，比剩余内存+swap抠掉共享内存、抠掉保留内存(如sysctl_admin_reserve_kbytes、totalreserve_pages)以后还要大，那么就认为这是“夸张的”，内存申请会返回ENOMEM。</span><br><span class="line"></span><br><span class="line">#1， 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。任何情况下都允许申请内存overcommit, 比较危险，常用于一些科学计算应用。典型的例子是使用稀疏矩阵，并且虚拟内存的很多页全部是0。</span><br><span class="line"></span><br><span class="line">#2， 表示内核允许分配超过所有物理内存和交换空间总和的内存（参照overcommit_ratio）。Committed_AS不能大于CommitLimit。</span><br><span class="line">###使用此模式，Linux会严格统计的内存使用情况，并且只会在物理内存可用时才会允许内存申请。由于检查是在分配时完成的，请求内存的程序可以正常处理该故障的情况下，并清理遇到该错误的会话。</span><br><span class="line">###overcommit 2会分配一部分物理RAM用于内核使用。分配的数量由设置vm.overcommit_ratio配置。</span><br><span class="line">###这意味着可用于程序的虚拟内存的数量实际上是 RAM *（overcommit_ratio / 100） + SWAP</span><br><span class="line">##当然也可以根据vm.overcommit_kbytes来设置。</span><br><span class="line">###注意，需要ratio不能设置的太高，还需要保留内存用于IO缓冲区和系统调用等，据说有些系统上光网络缓冲区一次就需要超过25 GB的内存，量还是比较大的。</span><br><span class="line"></span><br><span class="line"> ##overcommit限制的初衷是malloc后，内存并不是立即使用掉，</span><br><span class="line">##所以如果多个进程同时申请一批内存的话，不允许OVERCOMMIT可能导致某些进程申请内存失败，但实际上内存是还有的。</span><br><span class="line">##所以Linux内核给出了几种选择，</span><br><span class="line">##2是比较靠谱或者温柔的做法。</span><br><span class="line">##1的话风险有点大，虽然可以申请内存，但是实际上可能已经没有足够的内存给程序使用，最终可能会导致OOM。</span><br><span class="line">##0是最常见的，允许少量的overcommit，但是对于需要超很多内存的情况，不允许。</span><br><span class="line">##还可以参考代码 :</span><br><span class="line">##security/commoncap.c::cap_vm_enough_memory()</span><br><span class="line"></span><br><span class="line">##所以当数据库无法启动时，要么你降低一下数据库申请内存的大小（例如降低shared_buffer或者max conn），要么就是修改一下overcommit的风格。</span><br><span class="line"></span><br><span class="line">####如何选择overcommit策略</span><br><span class="line">##案例1：Greenplum要求，必须设置overcommit模式为2。</span><br><span class="line">##案例2：kubernetes将overcommit策略特意改为了1，即放飞自我，想要多少内存就有多少内存。</span><br><span class="line"></span><br><span class="line">#案例3 radis必须设置overcommit模式为1</span><br><span class="line"></span><br><span class="line">##默认就设置为0，具体应用就设置相应要求的值</span><br><span class="line">vm.overcommit_memory = 0 </span><br><span class="line"></span><br><span class="line">####设置inotifywait或inotifywatch命令可以监视的文件数量(单进程)</span><br><span class="line">####fs.inotify.max_user_watches：表示同一用户同时可以添加的watch数目（watch一般是针对目录，决定了同时同一用户可以监控的目录数量）</span><br><span class="line">fs.inotify.max_user_watches=1000000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">###turned off on bridge devices.--没有docker环境 </span><br><span class="line">##net.bridge.bridge-nf-call-iptables=0 </span><br><span class="line">###net.bridge.bridge-nf-call-arptables=0 </span><br><span class="line">###net.bridge.bridge-nf-call-ip6tables=0 </span><br><span class="line">但是在docker环境里就要开启</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.bridge.bridge-nf-call-arptables = 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#-------------------华丽的分割线--------------</span><br><span class="line">###docker的网络设置</span><br><span class="line">##https://blog.codeship.com/running-1000-containers-in-docker-swarm/</span><br><span class="line">###https://lunatine.net/2018/04/12/nf_conntrackgwa-docker/</span><br><span class="line">#一个 64 位 16G内存 的机器</span><br><span class="line"># Connection tracking to prevent dropped connections (usually issue on LBs)</span><br><span class="line">net.netfilter.nf_conntrack_max=604139</span><br><span class="line">net.netfilter.nf_conntrack_buckets=151034</span><br><span class="line">net.ipv4.netfilter.ip_conntrack_generic_timeout=120</span><br><span class="line">net.netfilter.nf_conntrack_tcp_timeout_established=54000</span><br><span class="line">net.netfilter.nf_conntrack_tcp_timeout_close_wait = 60</span><br><span class="line">net.netfilter.nf_conntrack_tcp_timeout_fin_wait = 120</span><br><span class="line">net.netfilter.nf_conntrack_tcp_timeout_time_wait = 120</span><br><span class="line">net.netfilter.nf_conntrack_generic_timeout = 600</span><br><span class="line"></span><br><span class="line"># ARP cache settings for a highly loaded docker swarm</span><br><span class="line">net.ipv4.neigh.default.gc_thresh1=8096</span><br><span class="line">net.ipv4.neigh.default.gc_thresh2=12288</span><br><span class="line">net.ipv4.neigh.default.gc_thresh3=16384</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;centos6 &lt;/p&gt;
&lt;p&gt; /etc/sysctl.conf &lt;/p&gt;
&lt;p&gt;centos7&lt;/p&gt;
&lt;p&gt;sysctl -p /usr/lib/sysctl.d/00-system.conf  &lt;/p&gt;
&lt;p&gt;注意：/etc/sysctl.conf文件中设置的内核运
      
    
    </summary>
    
      <category term="内核" scheme="http://zhangyu8.me/categories/%E5%86%85%E6%A0%B8/"/>
    
    
      <category term="内核" scheme="http://zhangyu8.me/tags/%E5%86%85%E6%A0%B8/"/>
    
  </entry>
  
  <entry>
    <title>中台禁区</title>
    <link href="http://zhangyu8.me/2019/09/10/%E4%B8%AD%E5%8F%B0%E7%A6%81%E5%8C%BA/"/>
    <id>http://zhangyu8.me/2019/09/10/中台禁区/</id>
    <published>2019-09-09T16:00:00.000Z</published>
    <updated>2019-09-10T05:52:20.903Z</updated>
    
    <content type="html"><![CDATA[<p>中台禁区-为什么最关键的组织架构却鲜少人谈？</p><p><a href="https://mp.weixin.qq.com/s/qgbSvoTabIljYYuMCmlHcw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/qgbSvoTabIljYYuMCmlHcw</a></p><p>转载自公众号 InfoQ   作者 赵钰莹</p><p> 1 写在前面</p><p> 中台确实是一个热度极高的话题，InfoQ 也曾在过往做过很多类似的选题，但是每当涉及到<strong>组织架构调整</strong>的话题，大部分采访嘉宾都选择了沉默，一位地产企业的 IT 架构师曾在我的追问下表示：<strong>组织架构一定要调整，但动组织架构就意味着在动“权力、金钱和人员”。**</strong>不难看出，这个话题太敏感。**</p><p> 因此，InfoQ 尝试从组织架构调整入手，了解整个过程以及对中台实践的影响。最终，在我们的不懈努力下（先后被 BAT 以各种原因拒绝，当然也可能是因为没找到合适的人？），终于联系到三位接受我们采访的嘉宾，他们是：网易副总裁、网易杭州研究院执行院长汪源，百分点大数据平台负责人贾喜顺和 ThoughtWorks 首席咨询师王健，再次感谢这三位专家。</p><p> 2 中台禁区：战略下的矛盾和冲突</p><p> 在中台战略制定中，组织架构调整的矛盾与冲突时刻存在，即便是阿里的“共享业务事业部（业务中台）”，早期也是非常艰难地活在淘宝和天猫的夹缝中。汪源在采访中表示：建设中台需要考虑组织、支撑技术和方法论三个方面的因素，一般来讲后两者都可以买到，但组织买不到。所以，最关键的是要对中台组织怎么构建有明确的方案，并下决心去推行。</p><p> 为什么大量中台只抄到了阿里的“形”？</p><p> 关于中台，很多人都喜欢研究阿里，但很少有人钻研阿里每年两次组织架构调整背后的原因。钟华（花名：古谦）在《企业 IT 架构转型之道（阿里巴巴中台战略思想与架构实战》一书开篇提到：</p><p>  与任何公司一样，阿里巴巴组织架构的战略调整势必对公司现有组织架构、部门间的协作等各方面都将带来深远影响…… 假若没能很好地控制战略执行过程中带来的风险，对组织架构的动荡过大，都会给现有业务带来不小的影响。</p><p> 因此，企业的每一次组织架构调整都是需要经过慎重考虑的，并且也需要让每一位员工清楚自己的定位。采访中，王健表示：“我认为阿里的中台战略之所以能够成功落地，最关键得益于其组织架构调整的能力。组织架构调整最难的就是让每个员工都能快速了解其背后的战略意图，并快速适应新的组织架构，知道接下来在新的组织架构下自己该干什么，从而让战略调整落地，这是需要一套机制和文化基础来保证的。我看到很多企业在学阿里，高层不断的在调整组织，但底下的员工基本都是懵的，不知道为什么调整，以及接下来自己要做什么。”</p><p> 虽然没有采访到阿里，但我们可以通过公开信的方式来获取阿里当年的组织架构调整情况。</p><p> 2015 年底，阿里巴巴集团对外宣布全面启动阿里巴巴集团 2018 年中台战略，构建符合 DT 时代的更具创新性、灵活性的“<strong>大中台、小前台</strong>”组织机制和业务机制。与此同时，张勇在致员工信中宣布了新的组织架构调整计划，如下图：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VOVT07wjhHugYnzCFI96WQ5bMI9okJnT04yYYOh6YYGM3uRbrTfZbtt2KOZPVzKfsaH6RMtibqrn6A/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 不难看出，阿里推进中台战略的关键人物是<strong>行癫</strong>（现任阿里巴巴集团首席技术官），他直接向张勇汇报。在公开信中，张勇表示：</p><p>  行癫是淘宝第一代的技术 Leader 和产品经理，后来成功转型为业务 Leader, 在 1688、淘宝、天猫、聚划算等多项业务中为集团做出过突出的贡献。作为集团内为数不多的兼具技术和商业背景和经验的领导者，行癫是担纲落实集团中台战略的最佳人选。他也将作为阿里集团和蚂蚁金融服务集团统一中台体系的总架构师，全面负责两大集团中台体系的规划和建设。</p><p> 这次组织架构调整让阿里正式开启中台战略，但阿里建设中台最早可以追溯至 2009 年共享业务事业部的诞生。当时，淘宝的技术团队同时支持着淘宝和天猫的业务，这样的组织架构决定了技术团队对来自淘宝的业务需求满足的优先级一定要优于天猫，这让天猫的业务团队怨声载道。此外，当时的淘宝和天猫电商系统是完全独立的两套体系，都包含商品、交易、评价、支付、物流等功能。</p><p> 基于上述原因，共享业务事业部诞生，在组织架构上与淘宝、天猫具有同样级别的事业部。然而，如前文言，这个事业部起初受到了天猫和淘宝事业部的双重碾压，团队成员如何加班都很难及时、周到地满足两大业务部门的需求，连带着话语权几乎没有（注意：职级相同并不代表话语权相同，想必很多人都对此深有同感）。钟华在书中是这样描述的：员工则是有苦说不出，只能默默流泪。</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VOVT07wjhHugYnzCFI96WQ58r96Sa20uj7wDibctHfkeSqh25yfwFXlVGC4b7xgbj0nmzyXp2zaIRw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 图源：《企业 IT 架构转型之道（阿里巴巴中台战略思想与架构实战》</p><p> 2010 年，聚划算出现，淘宝和天猫都希望接入。据不完全统计，这至少可以带来 25 倍的销售额增长，这时的阿里高层做出了一个对后来产生重大影响的决定，也是这个决定才让共享业务事业部得以真正成长起来：<strong>电商平台要想接入聚划算必须先通过共享业务事业部。</strong>钟华认为，这让整个共享业务事业群有了极强的业务抓手，而这对天猫、淘宝、1688（当时已经出现）事业部而言，也是一次权力的调整，这意味着要想获得更高的增长（接入聚划算），就必须接入共享业务事业部。</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VOVT07wjhHugYnzCFI96WQ5VGibx99gk8DoPSwOiaroUNZnJ60WpjAfCH132IE8nWmFdtkCqseHSRVQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 图源：《企业 IT 架构转型之道（阿里巴巴中台战略思想与架构实战》</p><p> 此外，这种调整不仅停留在集团层面，团队内部也进行了相应调整。早期，淘宝技术团队的组织人员组成跟今天企业中信息中心和技术部门的人员组成几乎一样，整个团队基本都是拥有较强技术技能的人员组成。阿里巴巴集团在构建共享服务体系之后，对各技术团队的组织架构也做了如下调整：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VOVT07wjhHugYnzCFI96WQ5TaqmqU6YzlahclDCicVuIPL6ROGFEdvLaPS2Zr3dibLSwQl1ZicshJvibQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 图源：《企业 IT 架构转型之道（阿里巴巴中台战略思想与架构实战》</p><p> 针对每一个建设的服务中心，从组织架构的形态上发生对应调整，不同角色的人员（架构师、开发人员、UED 工程师等）组建成了一个新的组织，每一个这样的组织都针对某一服务中心提供持续的服务能力——开发及运维。所以，在如今的阿里巴巴共享服务体系中，每一个服务中心都是由一个少则 100 多人，多则 4、5 百人的团队对负责的服务中心进行专业的运营。</p><p> 如果回顾整个阿里中台战略的推进过程，组织架构其实一直伴随着整个战略执行，只是每次调整解决的问题不尽相同（感兴趣的同学推荐阅读《企业 IT 架构转型之道（阿里巴巴中台战略思想与架构实战》，此处不再赘述）。在接受 InfoQ 采访时，贾喜顺表示，<strong>这种组织架构的调整其实是与业务复杂性相关的，</strong>类似阿里、京东等大厂需要调整组织架构来保障战略的顺利推进，但一些规模较小的企业可能不必如此复杂，这也要看企业对中台的态度，上述大厂已经将中台看做为重要战略，因此陆续进行了组织架构调整。</p><p> 如果要说<strong>组织架构调整的过程是否会出现矛盾和冲突</strong>，贾喜顺明确表示：“<strong>肯定会有</strong>”。</p><p> 他补充道，任何组织架构调整都涉及到这种矛盾，尤其是集中式的组织结构变更：一方面，这会把责任和权限更聚集，涉及组织管理的权力缩减问题；另一方面，业务边界的划分上需要进行磨合，要理清中台、前台的边界在哪里，如果边界尚不确定，就会涉及很多矛盾、冲突。</p><p> 当然，不排除有些边界很难界定，比如基于数据中台出指标体系，统计访问业务的 PV、UV 这种关键指标，不同部门统计的口径不一样，定义中台之后，类似的会有成千上万的指标需要重新进行边界划分，确定哪些指标体系由中台提供，哪些由前台搭建，很多情况下需要一事一议，不是那么容易能划分清楚的。</p><p> 既然这并非易事，为什么很多人不愿意谈论这个问题呢？</p><p> 为什么鲜少人谈组织架构？</p><p> 如果说完全没有人公开对外讨论这个话题，确实太过绝对也不准确，但大部分讨论还是比较委婉的，如开篇所言，这是一个非常敏感的话题。此外，如果不是整个中台战略的重要负责人也很难说清楚这个问题。</p><p> “中台是一个跨团队、跨业务的问题，这是一个企业级的问题，这就是为什么我说它是一个企业级治理的问题”，王健在采访中说道：“互联网公司做中台，每一家企业都有不同的背景和原因，如果把这些推到传统企业，有各种条件需要解决，比如组织能不能调，如果不可以调，那很可能做到一定程度就不能再往前走了，会碰到一个组织的天花板，或者说是组织先行，还是技术先行，这与互联网公司的情况还不太一样，<strong>传统企业在组织架构调整上是一个大的坎，调组织就是在动利益关系，这个很难**</strong>。**”</p><p> 因此，王健表示，这就需要中台推动者（下文详述这一人选如何确定）给出一把“尚方宝剑”，不然难以切动这些利益。具体来说，中台团队最初的处境可能会如阿里的“共享业务事业部”一样，不被相关事业部接受，这很容易理解，原事业部已经存在只为此事业部服务的技术支持团队，所有需求都可以得到及时响应，如果接入中台这样一个同时服务多事业群的技术支持团队，如何确保业务需求可以被及时响应。此外，一旦接入中台，这意味着原有团队的人员需要进行调整，决策权可能也会被缩减，这种情况下，中台团队的处境十分艰难。</p><p> <strong>如果想做，能不能照搬阿里的组织架构呢？</strong></p><p> 这个肯定不可以，这里还需要区分中台的类型和原有企业的组织架构方式，毕竟现在有关中台的概念太多，比如数据中台、技术中台和业务中台等，类型不同、目的不同，调整的方式也有所区别。</p><p> 贾喜顺基于数据中台的搭建经验表示，如果企业在搭建数据中台后相应地进行架构调整，肯定会对中台落地提供更大保障。这是因为，中台涉及各业务系统数据的汇集、治理、标准和推广，这些都需要从组织层面来保障。就原来垂直业务线的团队而言，部门人员很大可能会缩减，中台是把以往企业各部门做的同样的事情进行集中，这样的话，其中有部分人员可能要被调整到其他部门，比如偏业务分析类工作；另一部分比较偏底层的技术人员在垂直业务领域就可能不需要了。此外，人员结构也会有变化：原有的底层技术、研发人员会缩减，在实践数据中台的垂直业务线团队更偏重面向业务的应用产品研发人员和业务分析人员。</p><p> 在王健看来，数据中台和技术中台其实是传统企业最喜欢率先引入建设的，因为相对而言，传统企业内部对于技术和数据团队的划分相对明确，尤其是业务并不是非常杂的时候，技术团队和数据团队往往就是一个独立的、全面支持的角色，比如原来做数据平台的团队，现在就可以直接继续承担数据中台的建设，不需要做太多结构上的调整，毕竟不是非常影响业务，而业务中台则是一定要动组织的，这个过程涉及多条业务线的利益关系，这之间的屏障很难打破。照搬肯定不行，其他人调整是为了业务的横向扩展（例如做全球化），你的目的是为了纵向数据打通，这显然不可复制，还是得想清楚调整的目的是什么。</p><p> 然而，在汪源的定义中，<strong>所有的中台都是业务中台</strong>，数据中台是一种特殊的业务中台，一般指以负责数据采集、数据集成、数据治理，指标体系和数据仓库统一建设等数据管理活动的组织。当前阶段，他认为不存在技术中台，现在业界所谓的技术中台其实都是云计算、AI 算法等技术平台，这些技术平台没有业务属性，做这些平台的人也不懂业务，称做中台是不合适的。</p><p> 管理上的困难主要来自于技术属性较弱的 PMO（Project Management Office）、推荐搜索、数据分析等专业能力部门，这些部门的发展存在很大的不稳定性，如果能力不能持续的提升和沉淀，就可能导致部门的分拆。这么多年分分合合都有。正是基于这些经历，汪源才提出以能力组、技术平台和方法论为主的标准能力组织、包含专向组的胖中台组织、中台组织到平台组织的转化等方法，以应对不同的情况。</p><p> 中台和各前台业务团队是支撑和合作的关系，这两类团队需要一起制定工作规划，一起确定绩效目标，<strong>因为有一些绩效目标是中台和前台业务团队一起背</strong>。除此之外，中台团队应该有部分人员是专职对接和服务每个核心的前台业务，这些人应该和前台业务团队坐在一起，团建应该一起去，汪源称之为“专人就位”，这样才能塑造信任和默契。如果前台团建都不叫你去，那你这个中台就危险了。（阿里各服务中心的核心架构师和运营人员会定期参与前端业务方的业务会议或重要项目的研讨会）</p><p> 对于前台业务团队来说，最大的变化是得放弃完全控制权，承担一定风险，换回来的是更低成本、更高效率、更高质量的服务，更强的能力。</p><p> 基于如上种种可能发生的变化，中台的组织架构调整问题鲜少人谈。</p><p> 3 组织架构怎么调？</p><p>  中台往往是企业里面最费力不讨好、最容易失败的团队，做不好看起来就是在给各个团队制造麻烦。——王健</p><p> 组织架构调整是一个很大的问题，典型的组织架构就包括：直线职能型（U）、事业部型（M）、矩阵型、网络型、平台型，还不算各种组合和变体；如果结合经营模式，还需要了解大家常常提到的阿米巴经营模式以及海尔的自主经营体……所以，这些肯定不是一篇文章就可以讲清楚的，此处着重讲解中台战略的推动者和中台团队的人员构成。</p><p> 中台的推动者</p><p> 如上文言，阿里推进中台战略的关键人物是行癫，行癫在 2015 年 3 月份开始已经是阿里巴巴中国零售平台负责人；2018 年底，京东商城调整组织架构，中台组织规划（如下图）首次完整亮相，负责人徐雷是京东零售集团的轮值 CEO；2019 年 1 月 4 日，腾讯正式宣布成立技术委员会，腾讯高级执行副总裁、技术工程事业群总裁卢山和腾讯高级执行副总裁、云与智慧产业事业群总裁汤道生两名腾讯总办成员牵头，几大事业群的技术负责人悉数进入技术委员会决策圈，这被评为中台战略的良好开端……</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VOVT07wjhHugYnzCFI96WQ58g74iahkicoCtrarpia2sMApyAZICBK13icZP06gvoicoic0TtPbNFZM27mQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 综上，大厂推进中台战略的决策人物（团队成员）的职级均不低，三位专家在采访中也在这一点上达成了统一：<strong>中台战略的推进过程一定是自顶向下的，至少是 CIO/CTO 层面向下推动，一定需要得到高层的支持。**</strong>否则，很难切动组织架构调整中的利益网。**</p><p> “中台建设的前期可能没有给业务带来多大帮助，反而制造了很多问题，如果没有 CIO、CTO 甚至 CEO，或者技术委员会、战略规划部门等的支持，很难进行，可能原来想做一个业务中台，后来因为无法撬动业务，数据也拿不到，最终的建设效果就会大打折扣”，王健进一步补充道，“如果这时领导层没有驱动力帮助继续推进这件事情，这个中台推也不是，不推也不是，因此我认为中台建设应该是一个自上而下的驱动过程。”</p><p> 此外，大部分员工是很难站在一定的高度去做一个”看十年、做一年“的规划，特别是当一件事和眼前的 KPI 难以达成平衡时，中台的工作会受到各个方面的挑战。因此高层的坚定支持是中台战略的第一必要条件。中台的价值是有条件的，搭建完成后还得有机会来享受成果，这个判断也需要高层来完成。额外的，高层还需要推动一些规范的建设，如交互规范、视觉规范、视觉配套的前端组件规范等，在这些规范的约束下，中台服务搭建的难度会大大降低。</p><p> 对于数据中台的建设，贾喜顺同样表示：“数据中台是“一把手”工程，需要从上到下进行。中台数据是战略层面的事情而不是战术层面，自下向上推动几乎没有可能，比如涉及标准统一，从下而上只能看到一个点，难免会以偏概全。”</p><p> 中台团队的人员构成</p><p> 建设中台对原有垂直业务线的人员可能会有很大影响，那么，中台团队的人员又是从哪来的呢？</p><p> 就数据中台团队的搭建而言，贾喜顺表示，这与团队一把手的想法也有关系，通常会从企业内部的垂直业务线进行人才筛选，在组织架构调整或者成立中台团队中，会有一部分人从垂直业务线剥离出来。这是因为企业内部的人更了解业务，会比外部招聘的人更容易进入状态。不过，对于传统企业，其内部更偏管理，数据中台团队建设更多的需要借助外部力量，如搭建数据中台的企业，再在企业内部辅助配一些团队人员进行支撑。</p><p> 王健也基本赞同上述观点，一开始大多是从前台抽调，毕竟企业资源有限，不可能纯招一批人，这些人可能包含架构师等实力非常强的人，因为业务中台的建设者要比各垂直业务线更懂业务，不仅仅是懂技术就可以的，尤其是很多公司是产品型文化，可能还会配备产品经理，这可能与传统企业里面的项目经理有些类似，但要有很强的沟通和协调能力，需要跟所有业务线战斗，然后服务好所有业务方，但如果没处理好组织关系，业务方给到中台的人可能是自己不想用的。</p><p> 汪源同样认为：外部招聘对于构建中台团队往往很难，因为中台团队一要懂业务，还需要得到前台业务的信任，所以最好是从内部培养和选拔，可以从平台团队选拔，但此时要配置懂业务的人配合，也可以从业务线抽调。</p><p> 中台团队的核心管理层要求具备业务经验和敏感度，中台一要懂业务；二要有强的执行力、目标感和沟通能力，因为中台要跨部门推动工作落地；三要有强的逻辑分析能力，因为中台工作比较抽象，要提炼。</p><p> 综上，中台团队的人员组成就比较清晰了：<strong>内部抽调是重要来源；**</strong>人员大都既懂业务，又得懂技术；<strong>**团队内部最好有一个沟通和协调能力较强的人员，这个人是中台团队对外沟通的桥梁，不同企业叫法不同，比如阿里最为核心的角色是业务架构师，但可以简单理解为中台的产品经理。</strong></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VOVT07wjhHugYnzCFI96WQ5fsTgFaQrvtqcFoMqJf346jN5yXibicnx9WbzVf6zibW5Vn8YQ5GYWD0Hw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 图源：《我的一年中台实战录》</p><p> 如上图，中台产品经理也被认为是 B 端产品经理的一种类型，有 B 端通用的能力要求，比如擅长做抽象建模、具备一定的研发技术功底、懂 UML 等，不同企业要求不同，此处就不一一展开了。</p><p> 4 造中台，钱应该谁出？</p><p> 企业在推动一些决策落地时，往往背后还有两个重要考量：这件事情能带来成本的节省吗？如果不能，这件事情可以带来更多营收吗？如果都不能，这件事情如此复杂，做的必要性是什么？</p><p> 众所周知，阿里建设中台最初源于马云带领集团高管拜访 Supercell 说起，这是一家位于赫尔辛基的移动游戏公司，这家公司号称是世界上最成功的移动游戏公司，其当时已经在使用“中台模式”接连推出爆款游戏，<strong>在不到 200 人的情况下成为了年税前利润 15 亿美元的公司。**</strong>2016 年 6 月，中国腾讯公司以 86 亿美元收购了这家公司 84.3% 的股权，每一名员工人均贡献估值超过 3.54 亿人民币。**</p><p> 通过建设中台，Supercell 拥有了快速推出产品、快速试错（一旦产品公测期间反馈不好，团队会快速决定放弃）的能力，进而可以在人数不多的情况下创造如此大的利润。<strong>虽然中台可能创造的利润非常可观，但是企业在建设中台的过程中，对前路尚不清晰时，钱应该谁来出呢？</strong></p><p> 对于技术服务类企业，中台对外售卖，这个问题很好解决，起码这个团队是盈利的，但在很多传统企业，技术往往仅支持内部业务，是一个纯成本的部门，当然这肯定是为业务带来了价值，只是直观来看，这是一个不营收的部门。如果站在为业务赋能的角度，业务中台的钱显然需要业务部门出一部分，建成之后可能还需要从业务方分走部分利润。</p><p> 但这条路很难走通，每条业务线都有自己的 OKR 或者 KPI，这件事情对各业务部门的考核可能没有直接帮助，甚至于在局部较短时间内是阻碍当年 KPI 达成的。</p><p> 王健表示，试想一下，如果一家企业要推出一款产品，很少有上来就采用众筹模式，让用户预付款，这样会对产品产生很大的短期交付压力，也不利于产品的初始阶段研发。相反，现在很多企业推出的产品，前期都是免费的，先通过投资机构注资研发，快速推向市场获取用户反馈，再不断改进并适时考虑向用户增值收费。如果考虑让公司从战略投资层面出这个钱，那么公司肯定也是要考虑收支平衡问题，投资的目的是什么，需要多长时间可以带来收益，如何合理制定中台团队的 OKR，这些都是需要提前想清楚的。</p><p> 比如，阿里业务中台团队的绩效考核会考虑服务稳定性、业务创新、服务接入量以及客户满意度四项指标。其中，服务稳定是重中之重，这部分的考核比重会占整体的 40% 左右；适当允许一定数量因为创新业务上线带来的事故，鼓励团队创新，这部分可能会在 25% 左右；吸引更多前端业务方接入，一般会占 20% 左右，剩下的是客户满意度。</p><p> 但是，贾喜顺也提醒道：建设数据中台是个长期过程，不是三个月或者半年就能出成效的，决策者需要在理念上进行转变。言外之意，即便企业决定通过战略投资的方式建设中台，但短期内也未必可以看到收益。</p><p> 5 结束语</p><p> 建设中台是一个非常复杂的过程，这不是简单的决策而是战略层面的调整。汪源在采访最后表示：“建设中台是比较复杂的，所以首先要判断是否有必要，比如是否觉得核心能力确实存在较大短板；跨业务或项目的共享做得不够；需求变化快且多；数据经常出错或者不一致等。如果需求不大，时机不成熟，可以再观察观察。”</p><p> 对于确实规划建设中台的，汪源还是建议要从组织、支撑技术和方法论三个方面都要做好准备，这方面的内容很多，很难给出几条简单的建议就能起到很大的作用。建议第一步先做自主研究，对建设中台有一个总体的理解和把握；第二步找有建设经验的团队学习。</p><p> 最后，本文引用王健在采访中的一句话作为结尾：建设中台不能天天喊口号，如果既不敢调动资源，也不敢调整组织架构，还整天担心对前台业务的影响，难以承担失败可能带来的风险，这很难成功。中台承载的是企业最核心的业务能力，最核心的差异化竞争力，是战略层面的事情，没有战略层面的决心和耐心坚持下来就很难看到成果，有的时候，中台建设确实也需要“因为相信，所以看见”。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;中台禁区-为什么最关键的组织架构却鲜少人谈？&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/qgbSvoTabIljYYuMCmlHcw&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixi
      
    
    </summary>
    
      <category term="好文转载" scheme="http://zhangyu8.me/categories/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/"/>
    
    
      <category term="好文转载" scheme="http://zhangyu8.me/tags/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>自学是门手艺</title>
    <link href="http://zhangyu8.me/2019/08/14/%E8%87%AA%E5%AD%A6%E6%98%AF%E9%97%A8%E6%89%8B%E8%89%BA/"/>
    <id>http://zhangyu8.me/2019/08/14/自学是门手艺/</id>
    <published>2019-08-13T16:00:00.000Z</published>
    <updated>2019-09-10T05:55:30.023Z</updated>
    
    <content type="html"><![CDATA[<p> <a href="http://the-craft-of-selfteaching.surge.sh/#/" target="_blank" rel="noopener">http://the-craft-of-selfteaching.surge.sh/#/</a></p><p> 没有自学能力的人没有未来</p><p>李笑来 </p><p> 都说，人要有一技之长。那这一技究竟应该是什么呢？</p><p>  自学能力是唯一值得被不断磨练的长技。</p><p> 磨练出自学能力的好处在于，无论这世界需要我们学什么的时候，我们都可以主动去学，并且还是马上开始 —— 不需要等别人教、等别人带。</p><p> 哪怕有很强的自学能力的意思也并不是说，什么都能马上学会、什么都能马上学好，到最后无所不精无所不通…… 因为这里有个时间问题。无论学什么，都需要耗费时间和精力，与此同时更难的事情在于不断填补耐心以防它过早耗尽。另外，在极端的情况下，多少也面临天分问题。比如身高可能影响打篮球的表现，比如长相可能影响表演的效果，比如唱歌跑调貌似是很难修复的，比如有些人的粗心大意其实是基因决定的，等等。不过，以我的观察，无论是什么，哪怕只是学会一点点，都比不会强。哪怕只是中等水平，就足够应付生活、工作、养家糊口的需求。</p><p> 我在大学里学的是会计专业，毕业后找不到对口工作，只好去做销售 —— 没人教啊！怎么办？自学。也有自学不怎么样的时候，比如当年研究生课程我就读不完。后来想去新东方教书 —— 因为听说那里赚钱多 —— 可英语不怎么样啊！怎么办？自学。离开新东方去创业，时代早就变了，怎么办？自学，学的不怎么样，怎么办？硬挺。虽然创业这事儿后来也没怎么大成，但竟然在投资领域开花结果 —— 可赚了钱就一切平安如意了吗？并不是，要面对之前从来没可能遇到的一些险恶与困境，怎么办？自学。除了困境之外，更痛苦的发现在于对投资这件事来说，并没有受过任何有意义的训练，怎么办？自学。觉得自己理解的差不多了，一出手就失败，怎么办？接着学。</p><p> 我出身一般，父母是穷教师。出生在边疆小镇，儿时受到的教育也一般，也是太淘气 —— 后来也没考上什么好大学。说实话，我自认天资也一般，我就是那种被基因决定了经常马虎大意的人。岁数都这么大了，情商也都不是一般的差 —— 还是跟年轻的时候一样，经常莫名其妙就把什么人给得罪透了……</p><p> 但，我过得一直不算差。</p><p> 靠什么呢？人么，一个都靠不上。到最后，我觉得只有一样东西真正可靠 —— <strong>自学能力</strong>。于是，经年累月，我磨练出了一套属于我自己的本领：只要我觉得有必要，我什么都肯学，学什么都能学会到够用的程度…… 编程，我不是靠上课学会的；英语，不是哪个老师教我的；写作，也不是谁能教会我的；教书，更没有上过师范课程；投资，更没人能教我 —— 我猜，也没人愿意教我…… 自己用的东西自己琢磨，挺好。</p><p> 关键在于，自学这事儿并不难，也不复杂，挺简单的，因为它所需要的一切都很朴素。</p><p> 于是，从某个层面上来看，我每天都过的很开心。为什么？因为我有未来。凭什么那么确信？因为我知道我自己有自学能力。</p><p> <strong>—— 我希望你也有。</strong></p><p> 准确地讲，希望你有个更好的未来。</p><p> 而现在我猜，此刻，你心中也是默默如此作想的罢。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; &lt;a href=&quot;http://the-craft-of-selfteaching.surge.sh/#/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://the-craft-of-selfteaching.surge.sh/#/&lt;/a&gt;&lt;/
      
    
    </summary>
    
      <category term="好文转载" scheme="http://zhangyu8.me/categories/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/"/>
    
    
      <category term="好文转载" scheme="http://zhangyu8.me/tags/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>1小时学会ansible</title>
    <link href="http://zhangyu8.me/2019/07/23/1%E5%B0%8F%E6%97%B6%E5%AD%A6%E4%BC%9Aansible/"/>
    <id>http://zhangyu8.me/2019/07/23/1小时学会ansible/</id>
    <published>2019-07-22T16:00:00.000Z</published>
    <updated>2019-09-10T05:55:42.486Z</updated>
    
    <content type="html"><![CDATA[<p>本文转自</p><p><a href="https://mp.weixin.qq.com/s?src=11&amp;timestamp=1564380781&amp;ver=1757&amp;signature=h8aBLRflHl*ZDJzG13jy*MTf9v97KNW432JT0AyrjYKcY*fymfm2-qBPJ9axObRK4OmLojNYGZ28yoZUVlofFR2jQEi5IpmlgZdttmrFtejNCWqlVmgf56VxAAf305*f&amp;new=1" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?src=11&amp;timestamp=1564380781&amp;ver=1757&amp;signature=h8aBLRflHl*ZDJzG13jy*MTf9v97KNW432JT0AyrjYKcY*fymfm2-qBPJ9axObRK4OmLojNYGZ28yoZUVlofFR2jQEi5IpmlgZdttmrFtejNCWqlVmgf56VxAAf305*f&amp;new=1</a></p><h2 id="不想说话，任性！！！-🙃"><a href="#不想说话，任性！！！-🙃" class="headerlink" title="不想说话，任性！！！ 🙃"></a>不想说话，任性！！！ 🙃</h2><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgA3uoniaxZIVy1BfS9EDqQTo0l3rwFkd6bWh6wkgOjQhrcLaQ0nYaicDg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgaerLicx0RgibYuOZ7ZTIVXiaNxJicKEx7XbPicmcFWuyrYTl1Q8Km8SZoYA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgOeycml7OtknUChlSc5iajibEkUWeiaGYYOMEpOdib8gAxfagaicA8yeHSMA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgzds9hMwZibwNgNg7lUtNibnIS4ntyjQo1icG1WjwlLTbiaIuXnOzPhicMGg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgYbZNDEPk3x13ia7mVjlTL8YEUkvNd8hZgNbY52icAKuQ69kZuduFWLtQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgqvZ208oYCAxPWAb2x56Yl55WS9sHdVu28j7Kf7dVR9fonsxIVohGoA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgGRfDXsau99piaU6otN2ibT1FtjRungJ4DMxJ3RAKfGUbs5bC5Z9c7kLQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgNUKEmka0YrRpBfPUkboGAVmMgUZuYhDBfjuICbPwxPCSP5CsOiahG8A/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgNPIxlPJ44FjcvibFJXY10zIWnf1b7ERSyZNwKS9WVc2yw5GCjic10WRw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgQoArXT8B3icbMtU95aup0X2q1UMpEGtGcwjhiaKdvtYBPAggiaSpahBdQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtg0h2pkP1COD9jNbuOic5VkQ5JzdFTZNeevyHVgurhtsnfm8iadgmicUTwg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgiaficiaxW35bMnogJ0sUwArvdU445asTmSmrh70m1RGOkdjCzofqwMGCw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgrPTPnMGb36e01dh331bQibibKWPJCcx4oumfcVSSiaiaudUYSgSCuFs9Kg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtghgheTLkOSqCrR9zJ23TjnqYSgMHFHb5UeIYF2icibLibESdRiaL7KjqsgQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgbaAmXt0G7YKmV3QXicHhr7AbyB1GcI6Q3nPkLYc5KVWB31dH01OMPuw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgN3apv59fm11Q1wur640kt0Rjym8N43Z9ichNkRV31BjOWToBCLq6c2w/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgUn45LLHA2kXCeECSwWQlyATnapteY5FGXV0KtLlOajj0KZ3YXnqeRQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5ySPTYCz0iawyHfbRBU9bUtgtEiak3wDqRzEo6OicIJbXzZeiaY08Zo8LkY82nQKcE2not8dBvIfpNL0A/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文转自&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?src=11&amp;amp;timestamp=1564380781&amp;amp;ver=1757&amp;amp;signature=h8aBLRflHl*ZDJzG13jy*MTf9v97KN
      
    
    </summary>
    
      <category term="ansible" scheme="http://zhangyu8.me/categories/ansible/"/>
    
    
      <category term="ansible" scheme="http://zhangyu8.me/tags/ansible/"/>
    
  </entry>
  
  <entry>
    <title>正确的时间管理</title>
    <link href="http://zhangyu8.me/2019/06/02/%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/"/>
    <id>http://zhangyu8.me/2019/06/02/正确的时间管理/</id>
    <published>2019-06-01T16:00:00.000Z</published>
    <updated>2019-09-10T05:56:02.066Z</updated>
    
    <content type="html"><![CDATA[<p>来源：本文转自公众号“彭小六” </p><p><a href="https://mp.weixin.qq.com/s/Apu1RyBR6ArKTBVWttS-OQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/Apu1RyBR6ArKTBVWttS-OQ</a></p><p> <strong>时间管理几乎人人都听说过，但多数人错误理解了时间管理。</strong>  </p><p> 很多人是这样理解时间管理的：</p><p>  1、每天做一个时间计划，密密麻麻排满各种事；</p><p>  2、抓紧利用碎片化时间，多看点书、学点知识；</p><p>  3、立志建立好习惯，比如跑步、健身等等</p><p>  …</p><p> 但是，他们很快就会发现：坚持不下去啊~~~ 累！</p><p> 于是乎，打回原形，原来咋样还咋样。</p><p> <strong>时间管理，并不是单纯的将时间安排满，或是快速进化为自律超人，这样只能适得其反。</strong></p><p> 那么，什么是正确的时间管理？</p><p> 时间管理有两个关键话题：</p><p>  1、时间管理的本质是什么？<br>  2、有什么可快速见效的时间管理方法？</p><p> <strong>时间管理的本质是什么？</strong></p><p> 关键在于两个词：第一个词叫<strong>价值</strong>，第二个词叫<strong>效率</strong>。</p><p>  为什么是价值？</p><p> 举一个栗子：同样两件事，都是1天能完成，难度差不多。第一件事的回报是500元，而第二件事的回报是1000元。</p><p> 两件事只能选一件，你做哪件？</p><p> 用脚想都知道，选第二件事，因为价值更大呀。</p><p> 时间管理的道理也是如此。</p><p> <strong>我们要将时间用在高价值的事上，少做低价值的事。这样才能发挥出时间的作用。</strong></p><p>  为什么是效率？</p><p> 又来举一个栗子：乌龟和兔子比赛跑步，到达终点就是胜利。兔子花1小时就跑到了终点，干别的去了；而乌龟呢，花了一整天时间才慢悠悠爬到了终点。</p><p> 请问你，要做那只兔子还是乌龟呀？</p><p> 毫无疑问，我们要做那只兔子。因为他的效率高，可以节约出大把时间。</p><p> 所以，在完成高价值的事情时，我们要做到高效率。</p><p> 我们不仅要将时间用在高价值的事上，更要高效率地完成这些事。</p><p> 一句话总结：<strong>正确的时间管理，就是高效率地完成高价值的事。</strong></p><p> 那我们怎样才能做到高价值和高效率呢？</p><p> <strong>可落地的正确方法。</strong></p><p> 唯有将方法落地，时间管理才能真正有效。</p><p> 限于篇幅，我只讲三个有用的方法。</p><h4 id="1-用待办事项列表，管理每天要做的事"><a href="#1-用待办事项列表，管理每天要做的事" class="headerlink" title="1 用待办事项列表，管理每天要做的事"></a>1 用待办事项列表，管理每天要做的事</h4><p> 待办事项列表，就是把要去完成的事情记录下来，然后列表去做。</p><p> 注意，简单把事情一股脑的列出来没用，我们需要用到<strong>“ABC分类法”</strong>。</p><p> ABC分类法核心是两步：第一步叫分类，第二步叫排序。</p><p> 分类，就是把一天的事情分为A、B、C三类。</p><p>  A类代表很重要、今天必须完成的事，比如今天必须参加一个会议；</p><p>  B类代表比较重要、今天尽量要去完成的事，比如今天要写一个重要方案；</p><p>  C类代表不那么重要、看心情去完成的事。</p><p> 做完了分类之后，紧接就要排序。</p><p> 先做大类排序：A类事情放前面，B类事情放中间，最后是C类。</p><p> 再针对每类事项，按照时间的紧急程度做排序。</p><p> 比如，A类有两件事情，上午提交报告和下午参加会议。上午提交报告更紧急，因此就把这件事排在前面，而把下午参加会议这件事排在后面。</p><p> <strong>使用待办事项和ABC分类法，就是把要做的事情按价值高低、紧急程度进行了梳理和排序。</strong></p><p> 在具体操作时，我们原则上就要按照列表的顺序，一件件来干。</p><h4 id="2-用番茄工作法，提升做事的效率"><a href="#2-用番茄工作法，提升做事的效率" class="headerlink" title="2 用番茄工作法，提升做事的效率"></a>2 用番茄工作法，提升做事的效率</h4><p> 不知道大家有没有这样的感受：</p><p> 做一个事情，只要时间稍长，我们就很容易疲倦，会遇到各种干扰，产生各种分心。</p><p> 因此，我们需要使用番茄工作法。</p><p> <strong>番茄工作法，就是针对一个待完成的工作任务，以25分钟（一个番茄钟）为周期专注工作，中途不允许做任何与该任务无关的事。</strong></p><p> 以读一本书为例，建设需要100分钟，那么：</p><p>  1、先设定四个番茄钟；</p><p>  2、对每个番茄钟设定一个小目标，比如第一个钟完成一遍通读；第二个钟精读1/3、第三个钟再精读1/3，第四个钟完成精读。</p><p>  3、开始执行，每个番茄钟结束时，短暂休息一下（5分钟就行）。</p><p>  4个番茄钟结束后，休息20分钟。</p><p> 番茄工作法把耗时长的事情做了分解，劳逸结合，同时严格控制干扰，能明显地提高工作的效率。</p><h4 id="3-快速记录法"><a href="#3-快速记录法" class="headerlink" title="3 快速记录法"></a>3 快速记录法</h4><p> 很多小伙伴有这样的困扰：正在工作时，大脑会时不时产生杂念。</p><p> 脑补这样一个场景：你正在进行阅读，突然想起来水电费忘记交了，于是你打开支付宝交了水电费。</p><p> 等了交水电费的时候，你又会想，微信上是不是有谁给我留言了？于是乎，阅读的这件事情就被中断了。</p><p> 正确的方法是：使用快速记录法。</p><p>  1、工作前，提前准备好纸和本子。</p><p>  2、当工作时，当大脑中出现了突如其来的想法，立刻把想法写到纸上，但是不去处理。</p><p>  3、完成手头上的事的时候，再处理纸上的事情。</p><p> <strong>快速记录法，可以让我们保持专注，不受到大脑杂念的影响。</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;来源：本文转自公众号“彭小六” &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/Apu1RyBR6ArKTBVWttS-OQ&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.c
      
    
    </summary>
    
      <category term="管理" scheme="http://zhangyu8.me/categories/Management/"/>
    
    
      <category term="管理" scheme="http://zhangyu8.me/tags/%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>一个牛逼的创业公司后台技术栈搭建方案</title>
    <link href="http://zhangyu8.me/2019/05/15/%E4%B8%80%E4%B8%AA%E7%89%9B%E9%80%BC%E7%9A%84%E5%88%9B%E4%B8%9A%E5%85%AC%E5%8F%B8%E5%90%8E%E5%8F%B0%E6%8A%80%E6%9C%AF%E6%A0%88%E6%90%AD%E5%BB%BA%E6%96%B9%E6%A1%88/"/>
    <id>http://zhangyu8.me/2019/05/15/一个牛逼的创业公司后台技术栈搭建方案/</id>
    <published>2019-05-14T16:00:00.000Z</published>
    <updated>2019-09-10T05:55:52.199Z</updated>
    
    <content type="html"><![CDATA[<p>51CTO技术栈<br><a href="https://mp.weixin.qq.com/s/xYaWlZDxBaLASi4I4GK7hA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/xYaWlZDxBaLASi4I4GK7hA</a>)</p><p> 今天要说的后台是大后台的概念，放在服务器上的东西都属于后台的东西，比如使用的框架，语言，数据库，服务，操作系统等等。</p><p> 整个后台技术栈，我的理解包括四个层面的内容：</p><ul><li><p><strong>语言：</strong>用了哪些开发语言，如：C++/Java/Go/PHP/Python/Ruby 等等。</p></li><li><p><strong>组件：</strong>用了哪些组件，如：MQ 组件，数据库组件等等。</p></li><li><p><strong>流程：</strong>怎样的流程和规范，如：开发流程，项目流程，发布流程，监控告警流程，代码规范等等。</p></li><li><p><strong>系统：</strong>系统化建设，上面的流程需要有系统来保证，如：规范发布流程的发布系统，代码管理系统等等。</p></li></ul><p> 结合以上的的 4 个层面的内容，整个后台技术栈的结构如图 2 所示：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNlCQLutAgiaIuxERdrptkmOH0xL5AqDsFZl5FuTBrR54DbXiaBIKEQWG1dXxgiabhR1tZMYdznkfFCibg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <em>图 2：后台技术栈结构</em></p><p> 以上的这些内容都需要我们从零开始搭建，在创业公司，没有大公司那些完善的基础设施，需要我们从开源界，从云服务商甚至有些需要自己去组合，去拼装，去开发一个适合自己的组件或系统以达成我们的目标。</p><p> 咱们一个个系统和组件的做选型，最终形成我们的后台技术栈。</p><p> 各系统组件选型</p><p> <strong>项目管理/Bug 管理/问题管理</strong></p><p> 项目管理软件是整个业务的需求，问题，流程等等的集中地，大家的跨部门沟通协同大多依赖于项目管理工具。</p><p> 有一些 SaaS 的项目管理服务可以使用，但是很多时间不满足需求，此时我们可以选择一些开源的项目，这些项目本身有一定的定制能力，有丰富的插件可以使用。</p><p> 一般的创业公司需求基本上都能得到满足，常用的项目如下：</p><ul><li><p><strong>Redmine：</strong>用 Ruby 开发的，有较多的插件可以使用，能自定义字段，集成了项目管理，Bug 问题跟踪，WiKi 等功能，不过好多插件 N 年没有更新了。</p></li><li><p><strong>Phabricator：</strong>用 PHP 开发的，Facebook 之前的内部工具，开发这工具的哥们离职后自己搞了一个公司专门做这个软件，集成了代码托管， Code Review，任务管理，文档管理，问题跟踪等功能，强烈推荐较敏捷的团队使用。</p></li><li><p><strong>Jira：</strong>用 Java 开发的，有用户故事，Task 拆分，燃尽图等等，可以做项目管理，也可以应用于跨部门沟通场景，较强大。</p></li><li><p><strong>悟空 CRM ：</strong>这个不是项目管理，这个是客户管理，之所以在这里提出来，是因为在 To B 的创业公司里面，往往是以客户为核心来做事情的，可以将项目管理和问题跟进的在悟空 CRM 上面来做。</p><p>它的开源版本已经基本实现了 CRM 的核心功能，还带有一个任务管理功能，用于问题跟进，不过用这个的话，还是需要另一个项目管理的软件协助，顺便说一嘴，这个系统的代码写得很难维护，只能适用于客户规模小（1 万以内）时。  </p></li></ul><p> <strong>DNS</strong></p><p> DNS 是一个很通用的服务，创业公司基本上选择一个合适的云厂商就行了，国内主要是两家：</p><ul><li><p><strong>阿里万网：</strong>阿里 2014 年收购了万网，整合了其域名服务，最终形成了现在的阿里万网，其中就包含 DNS 这块的服务。</p></li><li><p><strong>腾讯 DNSPod：</strong>腾讯 2012 年以 4000 万收购 DNSPod 100% 股份，主要提供域名解析和一些防护功能。</p></li></ul><p> 如果你的业务是在国内，主要就是这两家，选 一个就好，像今日头条这样的企业用的也是 DNSPod 的服务，除非一些特殊的原因才需要自建，比如一些 CDN 厂商，或者对区域有特殊限制的。</p><p> 要实惠一点用阿里最便宜的基础版就好了，要成功率高一些，还是用 DNSPod 的贵的那种。</p><p> 在国外还是选择亚马逊吧，阿里的 DNS 服务只有在日本和美国有节点，东南亚最近才开始部点，DNSPod 也只有美国和日本，像一些出海的企业，其选择的云服务基本都是亚马逊。</p><p> 如果是线上产品，DNS 强烈建议用付费版，阿里的那几十块钱的付费版基本可以满足需求。</p><p> 如果还需要一些按省份或按区域调试的逻辑，则需要加钱，一年也就几百块，省钱省力。</p><p> 如果是国外，优先选择亚马逊，如果需要国内外互通并且有自己的 App 的话，建议还是自己实现一些容灾逻辑或者智能调度。</p><p> 因为没有一个现成的 DNS 服务能同时较好的满足国内外场景，或者用多个域名，不同的域名走不同的 DNS 。</p><p> <strong>LB（负载均衡）</strong></p><p> LB（负载均衡）是一个通用服务，一般云厂商的 LB 服务基本都有如下功能：</p><ul><li><p><strong>支持四层协议请求（包括 TCP、UDP 协议）</strong></p></li><li><p><strong>支持七层协议请求（包括 HTTP、<a href="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https" target="_blank" rel="noopener">http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https</a> 协议）</strong></p></li><li><p><strong>集中化的证书管理系统支持 <a href="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https" target="_blank" rel="noopener">http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https</a> 协议</strong></p></li><li><p><strong>健康检查</strong></p></li></ul><p> 如果你线上的服务机器都是用的云服务，并且是在同一个云服务商的话，可以直接使用云服务商提供的 LB 服务，如阿里云的 SLB，腾讯云的 CLB，亚马逊的 ELB 等等。如果是自建机房基本都是 LVS + Nginx。</p><p> <strong>CDN</strong></p><p> CDN 现在已经是一个很红很红的市场，基本上只能挣一些辛苦钱，都是贴着成本在卖。</p><p> 国内以网宿为龙头，他们家占据整个国内市场份额的 40% 以上，后面就是腾讯，阿里。网宿有很大一部分是因为直播的兴起而崛起。</p><p> 国外，Amazon 和 Akamai 合起来占比大概在 50%，曾经的国际市场老大 Akamai 拥有全球超一半的份额，在 Amazon CDN入局后，份额跌去了将近 20%，众多中小企业都转向后者，Akamai 也是无能为力。</p><p> 国内出海的 CDN 厂商，更多的是为国内的出海企业服务，三家大一点的 CDN 服务商里面也就网宿的节点多一些，但是也多不了多少。阿里和腾讯还处于前期阶段，仅少部分国家有节点。</p><p> 就创业公司来说，CDN 用腾讯云或阿里云即可，其相关系统较完善，能轻松接入，网宿在系统支持层面相对较弱一些，而且还贵一些。</p><p> 并且，当流量上来后，CDN 不能只用一家，需要用多家，不同的 CDN 在全国的节点覆盖不一样。</p><p> 而且针对不同的客户云厂商内部有些区分客户集群，并不是全节点覆盖（但有些云厂商说自己是全网节点），除了节点覆盖的问题，多 CDN 也在一定程度上起到容灾的作用。</p><p> <strong>RPC 框架</strong></p><p> 维基百科对 RPC 的定义是：远程过程调用（Remote Procedure Call，RPC）是一个计算机通信协议。</p><p> 该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。</p><p> 通俗来讲，一个完整的 RPC 调用过程，就是 Server 端实现了一个函数，客户端使用 RPC 框架提供的接口，调用这个函数的实现，并获取返回值的过程。</p><p> 业界 RPC 框架大致分为两大流派，一种侧重跨语言调用，另一种是偏重服务治理。</p><p> 跨语言调用型的 RPC 框架有 Thrift、gRPC、Hessian、Hprose 等。这类 RPC 框架侧重于服务的跨语言调用，能够支持大部分的语言进行语言无关的调用，非常适合多语言调用场景。</p><p> 但这类框架没有服务发现相关机制，实际使用时需要代理层进行请求转发和负载均衡策略控制。</p><p> 其中，gRPC 是 Google 开发的高性能、通用的开源 RPC 框架，其由 Google 主要面向移动应用开发并基于 HTTP/2 协议标准而设计，基于 ProtoBuf（Protocol Buffers）序列化协议开发，且支持众多开发语言。本身它不是分布式的，所以要实现框架的功能需要进一步的开发。</p><p> Hprose（High Performance Remote Object Service Engine）是一个 MIT 开源许可的新型轻量级跨语言跨平台的面向对象的高性能远程动态通讯中间件。</p><p> 服务治理型的 RPC 框架的特点是功能丰富，提供高性能的远程调用、服务发现及服务治理能力，适用于大型服务的服务解耦及服务治理，对于特定语言(Java)的项目可以实现透明化接入。</p><p> 缺点是语言耦合度较高，跨语言支持难度较大。国内常见的冶理型 RPC 框架如下：</p><ul><li><p><strong>Dubbo：</strong>Dubbo 是阿里巴巴公司开源的一个 Java 高性能优秀的服务框架，使得应用可通过高性能的 RPC 实现服务的输出和输入功能，可以和 Spring 框架无缝集成。</p><p>当年在淘宝内部，Dubbo 由于跟淘宝另一个类似的框架 HSF 有竞争关系，导致 Dubbo 团队解散，最近又活过来了，有专职同学投入。</p></li><li><p><strong>DubboX：</strong>DubboX 是由当当在基于 Dubbo 框架扩展的一个 RPC 框架，支持 REST 风格的远程调用、Kryo/FST 序列化，增加了一些新的 feature。</p><p>Motan：Motan 是新浪微博开源的一个 Java 框架。它诞生的比较晚，起于 2013 年，2016 年 5 月开源。Motan 在微博平台中已经广泛应用，每天为数百个服务完成近千亿次的调用。</p></li><li><p><strong>RPCX：</strong>RPCX 是一个类似阿里巴巴 Dubbo 和微博 Motan 的分布式的 RPC 服务框架，基于 Golang NET/RPC 实现。</p><p>但是 RPCX 基本只有一个人在维护，没有完善的社区，使用前要慎重，之前做 Golang 的 RPC 选型时也有考虑这个，最终还是放弃了，选择了 gRPC，如果想自己自研一个 RPC 框架，可以参考学习一下。  </p></li></ul><p> <strong>名字发现/服务发现</strong></p><p> 名字发现和服务发现分为两种模式，一个是客户端发现模式，一种是服务端发现模式。框架中常用的服务发现是客户端发现模式。</p><p> 所谓服务端发现模式是指客户端通过一个负载均衡器向服务发送请求，负载均衡器查询服务注册表并把请求路由到一台可用的服务实例上。现在常用的负载均衡器都是此类模式，常用于微服务中。</p><p> 所有的名字发现和服务发现都要依赖于一个可用性非常高的服务注册表，业界常用的服务注册表有如下三个：</p><ul><li><p><strong>Etcd：</strong>一个高可用、分布式、一致性、Key-Value 方式的存储，被用在分享配置和服务发现中。两个著名的项目使用了它：Kubernetes 和 Cloud Foundry。</p></li><li><p><strong>Consul：</strong>一个发现和配置服务的工具，为客户端注册和发现服务提供了API，Consul 还可以通过执行健康检查决定服务的可用性。</p></li><li><p><strong>Apache ZooKeeper：</strong>一个广泛使用、高性能的针对分布式应用的协调服务。Apache ZooKeeper 本来是 Hadoop 的子工程，现在已经是顶级工程了。</p></li></ul><p> 除此之外也可以自己实现服务实现，或者用 Redis 也行，只是需要自己实现高可用性。</p><p> <strong>关系数据库</strong></p><p> 关系数据库分为两种，一种是传统关系数据库，如 Oracle，MySQL，Maria，DB2，PostgreSQL 等等。</p><p> 另一种是 NewSQL，即至少要满足以下五点的新型关系数据库：</p><ul><li><p>完整地支持 SQL，支持 JOIN / GROUP BY /子查询等复杂 SQL 查询。</p></li><li><p>支持传统数据标配的 ACID 事务，支持强隔离级别。</p></li><li><p>具有弹性伸缩的能力，扩容缩容对于业务层完全透明。</p></li><li><p>真正的高可用，异地多活、故障恢复的过程不需要人为的接入，系统能够自动地容灾和进行强一致的数据恢复。</p></li><li><p>具备一定的大数据分析能力。</p></li></ul><p> 传统关系数据库用得最多的是 MySQL，因为成熟，稳定，一些基本的需求都能满足，在一定数据量级之前基本单机传统数据库都可以搞定。</p><p> 而且现在较多的开源系统都是基于 MySQL，开箱即用，再加上主从同步和前端缓存，百万 PV 的应用都可以搞定了。</p><p> 不过 CentOS 7 已经放弃了 MySQL，而改使用 MariaDB。MariaDB 数据库管理系统是 MySQL 的一个分支，主要由开源社区在维护，采用 GPL 授权许可。</p><p> 开发这个分支的原因之一是：甲骨文公司收购了 MySQL 后，有将 MySQL 闭源的潜在风险，因此社区采用分支的方式来避开这个风险。</p><p> 在 Google 发布了 F1: A Distributed SQL Database That Scales 和 Spanner: Google’s Globally-Distributed Databasa 之后，业界开始流行起 NewSQL。</p><p> 于是有了 CockroachDB，然后有了奇叔公司的 TiDB。国内已经有比较多的公司使用 TiDB，之前在创业公司时在大数据分析时已经开始应用 TiDB，当时应用的主要原因是 MySQL 要使用分库分表，逻辑开发比较复杂，扩展性不够。</p><p> <strong>NoSQL</strong></p><p> NoSQL 顾名思义就是 Not-Only SQL，也有人说是 No–SQL，个人偏向于 Not-Only SQL，它并不是用来替代关系库，而是作为关系型数据库的补充而存在。</p><p> 常见 NoSQL 有四个类型：</p><ul><li><p><strong>键值，</strong>适用于内容缓存，适合混合工作负载并发高扩展要求大的数据集，其优点是简单，查询速度快，缺点是缺少结构化数据，常见的有 Redis，Memcache，BerkeleyDB 和 Voldemort 等等。</p></li><li><p><strong>列式，</strong>以列簇式存储，将同一列数据存在一起，常见于分布式的文件系统，其中以 Hbase，Cassandra 为代表。</p><p>Cassandra 多用于写多读少的场景，国内用得比较多的有 360，大概 1500 台机器的集群，国外大规模使用的公司比较多，如 eBay，Instagram，Apple 和沃尔玛等等。</p></li><li><p><strong>文档，</strong>数据存储方案非常适用承载大量不相关且结构差别很大的复杂信息。性能介于 KV 和关系数据库之间，它的灵感来自 Lotus Notes，常见的有 MongoDB，CouchDB 等等。</p></li><li><p><strong>图形，</strong>图形数据库擅长处理任何涉及关系的状况，比如社交网络，推荐系统等。专注于构建关系图谱，需要对整个图做计算才能得出结果，不容易做分布式的集群方案，常见的有 Neo4J，InfoGrid 等。</p></li></ul><p> 除了以上 4 种类型，还有一些特种的数据库，如对象数据库，XML 数据库，这些都有针对性对某些存储类型做了优化的数据库。</p><p> 在实际应用场景中，何时使用关系数据库，何时使用 NoSQL，使用哪种类型的数据库，这是我们在做架构选型时一个非常重要的考量，甚至会影响整个架构的方案。</p><p> <strong>消息中间件</strong></p><p> 消息中间件在后台系统中是必不可少的一个组件，一般我们会在以下场景中使用消息中间件：</p><ul><li><p><strong>异步处理：</strong>异步处理是使用消息中间件的一个主要原因，在工作中最常见的异步场景有用户注册成功后需要发送注册成功邮件、缓存过期时先返回老的数据，然后异步更新缓存、异步写日志等等。</p><p>通过异步处理，可以减少主流程的等待响应时间，让非主流程或者非重要业务通过消息中间件做集中的异步处理。</p></li><li><p><strong>系统解耦：</strong>比如在电商系统中，当用户成功支付完成订单后，需要将支付结果通知 ERP 系统、发票系统、WMS、推荐系统、搜索系统、风控系统等进行业务处理。</p><p>这些业务处理不需要实时处理、不需要强一致，只需要最终一致性即可，因此可以通过消息中间件进行系统解耦。通过这种系统解耦还可以应对未来不明确的系统需求。</p></li><li><p><strong>削峰填谷：</strong>当系统遇到大流量时，监控图上会看到一个一个的山峰样的流量图，通过使用消息中间件将大流量的请求放入队列，通过消费者程序将队列中的处理请求慢慢消化，达到削峰填谷的效果。</p><p>最典型的场景是秒杀系统，在电商的秒杀系统中下单服务往往会是系统的瓶颈，因为下单需要对库存等做数据库操作，需要保证强一致性，此时使用消息中间件进行下单排队和流控，让下单服务慢慢把队列中的单处理完，保护下单服务，以达到削峰填谷的作用。  </p></li></ul><p> 业界消息中间件是一个非常通用的东西，大家在做选型时有使用开源的，也有自己造轮子的，甚至有直接用 MySQL 或 Redis 做队列的，关键看是否满足你的需求。</p><p> 如果是使用开源的项目，以下的表格在选型时可以参考：</p><p> <img src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" alt></p><p> <em>图 3</em></p><p> 以上图的纬度为：名字、成熟度、所属社区/公司、文档、授权方式、开发语言、支持的协议、客户端支持的语言、性能、持久化、事务、集群、负载均衡、管理界面、部署方式、评价。</p><p> <strong>代码管理</strong></p><p> 代码是互联网创业公司的命脉之一，代码管理很重要，常见的考量点包括两块：</p><ul><li><p><strong>安全和权限管理，</strong>将代码放到内网并且对于关系公司命脉的核心代码做严格的代码控制和机器的物理隔离。</p></li><li><p><strong>代码管理工具，</strong>Git 作为代码管理的不二之选，你值得拥有。GitLab 是当今最火的开源 Git 托管服务端，没有之一，虽然有企业版，但是其社区版基本能满足我们大部分需求，结合 Gerrit 做 Code Review，基本就完美了。</p><p>当然 GitLab 也有代码对比，但没 Gerrit 直观。Gerrit 比 GitLab 提供了更好的代码检查界面与主线管理体验，更适合在对代码质量有高要求的文化下使用。  </p></li></ul><p> <strong>持续集成</strong></p><p> 持续集成简称 CI（continuous integration），是一种软件开发实践，即团队开发成员经常集成他们的工作，每天可能会发生多次集成。</p><p> 每次集成都通过自动化的构建（包括编译，发布，自动化测试）来验证，从而尽早地发现集成错误。</p><p> 持续集成为研发流程提供了代码分支管理/比对、编译、检查、发布物输出等基础工作，为测试的覆盖率版本编译、生成等提供统一支持。</p><p> 业界免费的持续集成工具中，系统我们有如下一些选择：</p><ul><li><p><strong>Jenkins：</strong>Java 写的有强大的插件机制，MIT 协议开源 （免费，定制化程度高，它可以在多台机器上进行分布式地构建和负载测试）。</p><p>Jenkins 可以算是无所不能，基本没有 Jenkins 做不了的，无论从小型团队到大型团队 Jenkins 都可以搞定。不过如果要大规模使用，还是需要有人力来学习和维护。</p></li><li><p><strong>TeamCity：</strong>TeamCity 与 Jenkins 相比使用更加友好，也是一个高度可定制化的平台。但是用的人多了，TeamCity 就要收费了。</p></li><li><p><strong>Strider：</strong>Strider 是一个开源的持续集成和部署平台，使用 Node.js 实现，存储使用的是 MongoDB，BSD 许可证，概念上类似 Travis 和 Jenkins。</p></li><li><p><strong>GitLab CI：</strong>从 GitLab 8.0 开始，GitLab CI 就已经集成在 GitLab，我们只要在项目中添加一个 .gitlab-ci.yml 文件，然后添加一个 Runner，即可进行持续集成。</p><p>并且 GitLab 与 Docker 有着非常好的相互协作的能力。免费版与付费版本的不同可以参见：<a href="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://about.gitlab.com/products/feature-comparison/。" target="_blank" rel="noopener">http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://about.gitlab.com/products/feature-comparison/。</a></p></li><li><p><strong>Travis：</strong>Travis 和 GitHub 强关联；闭源代码使用 SaaS 还需考虑安全问题；不可定制；开源项目免费，其他收费。</p></li><li><p><strong>Go：</strong>Go 是 ThoughtWorks 公司最新的 Cruise Control 的化身。除了 ThoughtWorks 提供的商业支持，Go 是免费的。它适用于 Windows，Mac 和各种 Linux 发行版。</p></li></ul><p> <strong>日志系统</strong></p><p> 日志系统一般包括打日志，采集，中转，收集，存储，分析，呈现，搜索还有分发等。</p><p> 一些特殊的如染色，全链条跟踪或者监控都可能需要依赖于日志系统实现。</p><p> 日志系统的建设不仅仅是工具的建设，还有规范和组件的建设，最好一些基本的日志在框架和组件层面加就行了，比如全链接跟踪之类的。</p><p> 对于常规日志系统 ELK 能满足大部分的需求，ELK 包括如下组件：</p><ul><li><p>ElasticSearch 是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，RESTful 风格接口，多数据源，自动搜索负载等。</p></li><li><p>Logstash 是一个完全开源的工具，它可以对你的日志进行收集、分析，并将其存储供以后使用。</p></li><li><p>Kibana 是一个开源和免费的工具，它可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。</p></li><li><p>Filebeat 已经完全替代了 Logstash-Forwarder 成为新一代的日志采集器，同时鉴于它轻量、安全等特点，越来越多人开始使用它。</p></li></ul><p> 因为免费的 ELK 没有任何安全机制，所以这里使用了 Nginx 作反向代理，避免用户直接访问 Kibana 服务器。</p><p> 加上配置 Nginx 实现简单的用户认证，一定程度上提高安全性。另外，Nginx 本身具有负载均衡的作用，能够提高系统访问性能。</p><p> ELK 架构如图 4 所示：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNlCQLutAgiaIuxERdrptkmOHLFF2gW7tmic4hyRdpYnibVhB6WcqmtBAzgibNJU1icF5jMH8XLzl81TWmw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <em>图 4：ELK 流程图</em></p><p> 对于有实时计算的需求，可以使用 Flume + Kafka + Storm + MySQL 方案，一般架构如图 5 所示：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNlCQLutAgiaIuxERdrptkmOHZGKMw47wt7BibvfmgdW7avvTjn6TI3iadzUtiaiaUyPPkjQrunNd5rpQVQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <em>图 5：实时分析系统架构图</em></p><p> 其中：</p><ul><li><p>Flume 是一个分布式、可靠、和高可用的海量日志采集、聚合和传输的日志收集系统，支持在日志系统中定制各类数据发送方，用于收集数据。</p><p>同时，Flume 提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。</p></li><li><p>Kafka 是由 Apache 软件基金会开发的一个开源流处理平台，由 Scala 和 Java 编写。</p><p>其本质上是一个“按照分布式事务日志架构的大规模发布/订阅消息队列”，它以可水平扩展和高吞吐率而被广泛使用。  </p></li></ul><p> Kafka 追求的是高吞吐量、高负载，Flume 追求的是数据的多样性，二者结合起来简直完美。</p><p> <strong>监控系统</strong></p><p> 监控系统只包含与后台相关的，这里主要是两块，一个是操作系统层的监控，比如机器负载，IO，网络流量，CPU，内存等操作系统指标的监控。</p><p> 另一个是服务质量和业务质量的监控，比如服务的可用性，成功率，失败率，容量，QPS 等等。</p><p> 常见业务的监控系统先有操作系统层面的监控（这部分较成熟），然后扩展出其他监控，如 Zabbix，小米的 Open-Falcon，也有一出来就是两者都支持的，如 Prometheus。</p><p> 如果对业务监控要求比较高一些，在创业选型中建议可以优先考虑 Prometheus。</p><p> 这里有一个有趣的分布，如图 6 所示：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNlCQLutAgiaIuxERdrptkmOHPTl2rLk8lqYOgrYOBChNlO5YqHLibGxNqVAxKMgQ8b1ibncdsdxxI3lA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <em>图 6：监控系统分布</em></p><p> 亚洲区域使用 Zabbix 较多，而美洲和欧洲，以及澳大利亚使用 Prometheus 居多，换句话说，英文国家地区（发达国家？）使用 Prometheus 较多。</p><p> Prometheus 是由 Sound Cloud 开发的开源监控报警系统和时序列数据库（TSDB）。</p><p> Prometheus 使用 Go 语言开发，是 Google BorgMon 监控系统的开源版本。</p><p> 相对于其他监控系统使用的 Push 数据的方式，Prometheus 使用的是 Pull 的方式，其架构如图 7 所示：</p><p> <img src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" alt></p><p> <em>图 7：Prometheus 架构图</em></p><p> 如上图所示，Prometheus 包含的主要组件如下：</p><ul><li><p><strong>Prometheus Server：</strong>主要负责数据采集和存储，提供 PromQL 查询语言的支持。Server 通过配置文件、文本文件、ZooKeeper、Consul、DNS SRV Lookup 等方式指定抓取目标。</p><p>根据这些目标，Server 会定时去抓取 Metrics 数据，每个抓取目标需要暴露一个 HTTP 服务的接口给它定时抓取。</p></li><li><p><strong>客户端 SDK：</strong>官方提供的客户端类库有 Go、Java、Scala、Python、Ruby，其他还有很多第三方开发的类库，支持 Nodejs、PHP、Erlang 等。</p></li><li><p><strong>Push Gateway：</strong>支持临时性 Job 主动推送指标的中间网关。</p></li><li><p><strong>Exporter Exporter：</strong>是 Prometheus 的一类数据采集组件的总称。它负责从目标处搜集数据，并将其转化为 Prometheus 支持的格式。</p><p>与传统的数据采集组件不同的是，它并不向中央服务器发送数据，而是等待中央服务器主动前来抓取。</p><p>Prometheus 提供多种类型的 Exporter 用于采集各种不同服务的运行状态。目前支持的有数据库、硬件、消息中间件、存储系统、HTTP 服务器、JMX 等。</p></li><li><p><strong>Alertmanager：</strong>是一个单独的服务，可以支持 Prometheus 的查询语句，提供十分灵活的报警方式。</p></li><li><p>Prometheus HTTP API 的查询方式，自定义所需要的输出。</p></li><li><p><strong>Grafana：</strong>是一套开源的分析监视平台，支持 Graphite，InfluxDB，OpenTSDB，Prometheus，Elasticsearch，CloudWatch 等数据源，其 UI 非常漂亮且高度定制化。</p></li></ul><p> 创业公司选择 Prometheus + Grafana 的方案，再加上统一的服务框架（如 gRPC），可以满足大部分中小团队的监控需求。</p><p> <strong>配置系统</strong></p><p> 随着程序功能的日益复杂，程序的配置日益增多：各种功能的开关、降级开关，灰度开关，参数的配置、服务器的地址、数据库配置等等。</p><p> 除此之外，对后台程序配置的要求也越来越高：配置修改后实时生效，灰度发布，分环境、分用户，分集群管理配置，完善的权限、审核机制等等。</p><p> 在这样的大环境下，传统的通过配置文件、数据库等方式已经越来越无法满足开发人员对配置管理的需求。</p><p> 业界有如下两种方案：</p><ul><li><p>基于 ZK 和 Etcd，支持界面和 API ，用数据库来保存版本历史，预案，走审核流程，最后下发到 ZK 或 Etcd 这种有推送能力的存储里（服务注册本身也是用 ZK 或 Etcd，选型就一块了）。</p><p>客户端都直接和 ZK 或 Etcd 打交道。至于灰度发布，各家不同，有一种实现是同时发布一个需要灰度的 IP 列表，客户端监听到配置节点变化时，对比一下自己是否属于该列表。</p><p>PHP 这种无状态的语言和其他 ZK/Etcd 不支持的语言，只好自己在客户端的机器上起一个 Agent 来监听变化，再写到配置文件或共享内存，如 360 的 Qconf。</p></li><li><p>基于运维自动化的配置文件的推送，审核流程，配置数据管理和方案一类似，下发时生成配置文件，基于运维自动化工具如 Puppet，Ansible 推送到每个客户端，而应用则定时重新读取这个外部的配置文件，灰度发布在下发配置时指定 IP 列表。</p></li></ul><p> 创业公司前期不需要这种复杂，直接上 ZK，弄一个界面管理 ZK 的内容，记录一下所有人的操作日志，程序直连 ZK，或者或者用 Qconf 等基于 ZK 优化后的方案。</p><p> <strong>发布系统/部署系统</strong></p><p> 从软件生产的层面看，代码到最终服务的典型流程如图 8 所示：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNlCQLutAgiaIuxERdrptkmOHDB8dBw5ibetFngvwEyqItQEmIqXA9QGiaZ7EPOHktRCKTQeGZ6SlF9Uw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <em>图 8：流程图</em></p><p> 从上图中可以看出，从开发人员写下代码到服务最终用户是一个漫长过程，整体可以分成三个阶段：</p><ul><li><p>从代码（Code）到成品库（Artifact）这个阶段主要对开发人员的代码做持续构建并把构建产生的制品集中管理，是为部署系统准备输入内容的阶段。</p></li><li><p>从制品到可运行服务 这个阶段主要完成制品部署到指定环境，是部署系统的最基本工作内容。</p></li><li><p>从开发环境到最终生产环境 这个阶段主要完成一次变更在不同环境的迁移，是部署系统上线最终服务的核心能力。</p></li></ul><p> 发布系统集成了制品管理，发布流程，权限控制，线上环境版本变更，灰度发布，线上服务回滚等几方面的内容，是开发人员工作结晶最终呈现的重要通道。</p><p> 开源的项目中没有完全满足的项目，如果只是 Web 类项目，Walle、Piplin 都是可用的，但是功能不太满足，创业初期可以集成 Jenkins + Gitlab + Walle（可以考虑两天时间完善一下）。</p><p> 以上方案基本包括制品管理，发布流程，权限控制，线上环境版本变更，灰度发布（需要自己实现），线上服务回滚等功能。</p><p> <strong>跳板机</strong></p><p> 跳板机面对的是需求是要有一种能满足角色管理与授权审批、信息资源访问控制、操作记录和审计、系统变更和维护控制要求，并生成一些统计报表配合管理规范来不断提升 IT 内控的合规性。</p><p> 它能对运维人员操作行为的进行控制和审计，对误操作、违规操作导致的操作事故，快速定位原因和责任人。其功能模块一般包括：帐户管理、认证管理、授权管理、审计管理等等。</p><p> 开源项目中，Jumpserver 能够实现跳板机常见需求，如授权、用户管理、服务器基本信息记录等，同时又可批量执行脚本等功能。</p><p> 其中录像回放、命令搜索、实时监控等特点，又能帮助运维人员回溯操作历史，方便查找操作痕迹，便于管理其他人员对服务器的操作控制。</p><p> <strong>机器管理</strong></p><p> 机器管理的工具选择的考量可以包含以下三个方面：</p><ul><li><p>是否简单，是否需要每台机器部署 Agent（客户端）。</p></li><li><p>语言的选择（Puppet/Chef vs Ansible/SaltStack ）开源技术，不看官网不足以熟练，不懂源码不足以精通；Puppet、Chef 基于 Ruby 开发，Ansible、SaltStack 基于 Python 开发的。</p></li><li><p>速度的选择（Ansible vs SaltStack），Ansible 基于 SSH 协议传输数据，SaltStack 使用消息队列 zeroMQ 传输数据。</p><p>大规模并发的能力对于几十台到 200 台规模的兄弟来讲，Ansible 的性能也可接受，如果一次操作上千台，用 SaltStack 好一些。  </p></li></ul><p> 如图 9 所示：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNlCQLutAgiaIuxERdrptkmOHDiaic1j2PcAC2XINp7jGic5xNEibEATFTyQvl94ibSbuuDdibzK0acuYt4Dw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <em>图 9：机器管理软件对比</em></p><p> 一般创业公司选择 Ansible 能解决大部分问题，其简单，不需要安装额外的客户端，可以从命令行来运行，不需要使用配置文件。</p><p> 至于比较复杂的任务，Ansible 配置通过名为 Playbook 的配置文件中的 YAML 语法来加以处理。Playbook 还可以使用模板来扩展其功能。</p><p> 创业公司的选择</p><p> 选择合适的语言：</p><ul><li><p>选择团队熟悉的/能掌控的，创业公司人少事多，无太多冗余让研发团队熟悉新的语言，能快速上手，能快速出活，出了问题能快速解决的问题的语言才是好的选择。</p></li><li><p>选择更现代一些的，这里的现代是指语言本身已经完成一些之前需要特殊处理的特性，比如内存管理，线程等等。</p></li><li><p>选择开源轮子多的或者社区活跃度高的，这个原则是为了保证在开发过程中减少投入，有稳定可靠的轮子可以使用，遇到问题可以在网上快速搜索到答案。</p></li><li><p>选择好招人的一门合适的语言会让创业团队减少招聘的成本，快速招到合适的人。</p></li><li><p>选择能让人有兴趣的与上面一点相关，让人感兴趣，在后面留人时有用。</p></li></ul><p> 选择合适的组件和云服务商：</p><ul><li><p>选择靠谱的云服务商。</p></li><li><p>选择云服务商的组件。</p></li><li><p>选择成熟的开源组件，而不是最新出的组件。</p></li><li><p>选择采用在一线互联网公司落地并且开源的，且在社区内形成良好口碑的产品。</p></li><li><p>开源社区活跃度。</p></li></ul><p> 选择靠谱的云服务商，其实这是一个伪命题，因为哪个服务商都不靠谱，他们所承诺的那些可用性问题基本上都会在你的身上发生。</p><p> 这里我们还是需要自己做一些工作，比如多服务商备份，如用 CDN，你一定不要只选一家，至少选两家，一个是灾备，保持后台切换的能力，另一个是多点覆盖，不同的服务商在 CDN 节点上的资源是不一样的。</p><p> 选择了云服务商以后，就会有很多的产品你可以选择了，比较存储，队列这些都会有现成的产品，这个时候就纠结了，是用呢？还是自己在云主机上搭呢？</p><p> 在这里我的建议是前期先用云服务商的，大了后再自己搞，这样会少掉很多运维的事情，但是这里要多了解一下云服务商的组件特性以及一些坑。</p><p> 比如他们内网会经常断开，他们升级也会闪断，所以在业务侧要做好容错和规避。</p><p> 关于开源组件，尽可能选择成熟的，成熟的组件经历了时间的考验，基本不会出大的问题，并且有成套的配套工具，出了问题在网上也可以很快的找到答案，你所遇到的坑基本上都有人踩过了。</p><p> 制定流程和规范：</p><ul><li><p>制定开发的规范，代码及代码分支管理规范，关键性代码仅少数人有权限</p></li><li><p>制定发布流程规范，从发布系统落地</p></li><li><p>制定运维规范</p></li><li><p>制定数据库操作规范，收拢数据库操作权限</p></li><li><p>制定告警处理流程，做到告警有人看有人处理</p></li><li><p>制定汇报机制，晨会/周报</p></li></ul><p> <strong>自研和选型合适的辅助系统</strong></p><p> 所有的流程和规范都需要用系统来固化，否则就是空中楼阁，如何选择这些系统呢？</p><p> 参照上个章节咱们那些开源的，对比一下选择的语言，组件之类的，选择一个最合适的即可。</p><p> 比如项目管理的，看下自己是什么类型的公司，开发的节奏是怎样的，瀑布，敏捷的按项目划分，还是按客户划分等等，平时是按项目组织还是按任务组织等等。</p><p> 比如日志系统，之前是打的文本，那么上一个 ELK，规范化一些日志组件，基本上很长一段时间内不用考虑日志系统的问题，最多拆分一下或者扩容一下。等到组织大了，自己搞一个日志系统。</p><p> 比如代码管理，项目管理系统这些都放内网，安全，在互联网公司来说，属于命脉了，命脉的东西还是放在别人拿不到或很难拿到的地方会比较靠谱一些。</p><p> <strong>选择过程中需要思考的问题</strong></p><p> 技术栈的选择有点像做出了某种承诺，在一定的时间内这种承诺没法改变，于是我们需要在选择的时候有一些思考。</p><p> 看前面内容，有一个词出现了三次，合适，选择是合适的，不是最好，也不是最新，是最合适，适合是针对当下，这种选择是最合适的吗？</p><p> 比如用 Go 这条线的东西，技术比较新，业界组件储备够吗？组织内的人员储备够吗？学习成本多少？写出来的东西能满足业务性能要求吗？能满足时间要求吗？</p><p> 向未来看一眼，在一年到三年内，我们需要做出改变吗？技术栈要做根本性的改变吗？如果组织发展很快，在 200 人，500 人时，现有的技术栈是否需要大动？</p><p> 创业过程中需要考虑成本，这里的成本不仅仅是花费多少钱，付出多少工资，有时更重要的是时间成本，很多业务在创业时大家拼的就是时间，就是一个时间窗，过了就没你什么事儿了。</p><p> 基于云的创业公司后台技术架构</p><p> 结合上面内容的考量，在对一个个系统和组件的做选型之后，以云服务为基础，一个创业公司的后台技术架构如图 10 所示：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNlCQLutAgiaIuxERdrptkmOHrjKmmogtoqibZgUrAdv9Mnhh7ic0eIw8odciaEG9OfNqpYPeeNmfXkTqA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <em>图 10：后台技术架构</em></p><p> <em>作者：潘锦</em></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;51CTO技术栈&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/xYaWlZDxBaLASi4I4GK7hA&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s/xYaWlZD
      
    
    </summary>
    
      <category term="方案" scheme="http://zhangyu8.me/categories/%E6%96%B9%E6%A1%88/"/>
    
    
      <category term="方案" scheme="http://zhangyu8.me/tags/%E6%96%B9%E6%A1%88/"/>
    
  </entry>
  
  <entry>
    <title>python操作mysql的多个方案</title>
    <link href="http://zhangyu8.me/2019/04/11/python%E6%93%8D%E4%BD%9Cmysql%E7%9A%84%E5%A4%9A%E4%B8%AA%E6%96%B9%E6%A1%88/"/>
    <id>http://zhangyu8.me/2019/04/11/python操作mysql的多个方案/</id>
    <published>2019-04-10T16:00:00.000Z</published>
    <updated>2019-04-11T14:00:02.641Z</updated>
    
    <content type="html"><![CDATA[<p>python操作mysql的多个方案</p><p><a href="http://www.runoob.com/python/python-mysql.html" target="_blank" rel="noopener">http://www.runoob.com/python/python-mysql.html</a></p><p><a href="https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python" target="_blank" rel="noopener">https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python</a></p><p>官方规范：Python数据库API规范v2.0</p><p>PEP 249 -- Python Database API Specification v2.0</p><p><a href="https://www.python.org/dev/peps/pep-0249/" target="_blank" rel="noopener">https://www.python.org/dev/peps/pep-0249/</a></p><p>mysql 官方--MySQL Python API</p><p><a href="https://dev.mysql.com/doc/refman/5.7/en/apis-python.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.7/en/apis-python.html</a></p><p>连接mysql</p><p>方案一：mysql-connector 是 MySQL 官方提供的驱动器</p><p>安装：</p><p>rpm -ivh<br><a href="ftp://ftp.jaist.ac.jp/pub/mysql/Downloads/Connector-Python/mysql-connector-python-cext-2.1.7-1.el7.x86\_64.rpm" target="_blank" rel="noopener">ftp://ftp.jaist.ac.jp/pub/mysql/Downloads/Connector-Python/mysql-connector-python-cext-2.1.7-1.el7.x86\_64.rpm</a></p><p>rpm -ivh<br><a href="ftp://ftp.jaist.ac.jp/pub/mysql/Downloads/Connector-Python/mysql-connector-python-2.1.7-1.el7.x86\_64.rpm" target="_blank" rel="noopener">ftp://ftp.jaist.ac.jp/pub/mysql/Downloads/Connector-Python/mysql-connector-python-2.1.7-1.el7.x86\_64.rpm</a></p><p>或者</p><p>python -m pip install mysql-connector 被废弃</p><p>新版</p><p>pip install mysql-connector-python</p><p>教程<br><a href="http://www.runoob.com/python3/python-mysql-connector.html" target="_blank" rel="noopener">[http://www.runoob.com/python3/python-mysql-connector.html]{.underline}</a></p><p>举例：</p><p>import mysql.connector cnx = mysql.connector.connect(user=\’scott\’,<br>password=\’tiger\’, host=\’127.0.0.1\’, database=\’employees\’) try:<br>cursor = cnx.cursor() cursor.execute(\”\”\” select 3 from your_table<br>\”\”\”) result = cursor.fetchall() print result finally: cnx.close()</p><p>-----------------------------------------------------------------------------------------</p><p>方案二</p><p>Python3 使用 PyMySQL</p><p><a href="https://github.com/PyMySQL/PyMySQL" target="_blank" rel="noopener">[https://github.com/PyMySQL/PyMySQL]{.underline}</a></p><p>pip3 install PyMySQL</p><p>python3 -m pip install PyMySQL</p><p>方案三：Python2中则使用mysqldb</p><p>#yum install gcc libffi-devel python-devel openssl-devel urpmi xterm<br>freetds -y</p><p>#yum install MySQL-python</p><p>或者</p><p>rpm -ivh MySQL-python-1.3.6-3.fc22.x86_64.rpm</p><p>或者pip install MySQL-python</p><p>import MySQLdb</p><p>安装MySQLdb，<br><a href="https://pypi.python.org/pypi/MySQL-python" target="_blank" rel="noopener">[https://pypi.python.org/pypi/MySQL-python]{.underline}</a>)从这里可选择适合您的平台的安装包，分为预编译的二进制文件和源代码安装包。</p><p>如果您选择二进制文件发行版本的话，安装过程基本安装提示即可完成。如果从源代码进行安装的话，则需要切换到MySQLdb发行版本的顶级目录，并键入下列命令:</p><p>\$ gunzip MySQL-python-1.2.2.tar.gz \$ tar -xvf MySQL-python-1.2.2.tar\$<br>cd MySQL-python-1.2.2\$ python setup.py build \$ python setup.py install</p><p><strong>注意：</strong>请确保您有root权限来安装上述模块。</p><p>################################</p><p>方案4：<strong>mysqlclient --django官方推荐</strong></p><p>本质是方案三mysqldb第三方修改版支持python3的</p><p>首先安装一下mysql-devel</p><p>yum install python-devel mysql-devel</p><p><strong>Python 3</strong></p><p>yum install python36-devel.x86_64</p><p>然后就可以直接安装mysqlclient了</p><p>pip install mysqlclient</p><p><a href="https://pypi.org/project/mysqlclient/" target="_blank" rel="noopener">[https://pypi.org/project/mysqlclient/]{.underline}</a></p><p><a href="https://github.com/PyMySQL/mysqlclient-python" target="_blank" rel="noopener">[https://github.com/PyMySQL/mysqlclient-python]{.underline}</a></p><p>##############</p><p>方案5：CyMySQL----------For python 3.3</p><p>pip install cymysql</p><p>import cymysql</p><p><a href="https://github.com/nakagami/CyMySQL" target="_blank" rel="noopener">https://github.com/nakagami/CyMySQL</a></p><p>###]<strong>[Python]代码 </strong></p><p>#-*- encoding: utf-8 -*-</p><p><strong>import</strong> os, sys, string</p><p><strong>import</strong> MySQLdb</p><p># 连接数据库　</p><p><strong>try</strong>:</p><pre><code>conn **=**</code></pre><p>MySQLdb.connect(host<strong>=</strong>\’localhost\’,user<strong>=</strong>\’root\’,passwd<strong>=</strong>\’xxxx\’,db<strong>=</strong>\’test1\’)</p><p><strong>except</strong> Exception, e:</p><pre><code>print esys.exit()</code></pre><p># 获取cursor对象来进行操作</p><p>cursor <strong>=</strong> conn.cursor()</p><p># 创建表</p><p>sql <strong>=</strong> \”create table if not exists test1(name varchar(128) primary<br>key, age int(4))\”</p><p>cursor.execute(sql)</p><p># 插入数据</p><p>sql <strong>=</strong> \”insert into test1(name, age) values (\’%s\’, %d)\” <strong>%</strong><br>(\”zhaowei\”, 23)</p><p><strong>try</strong>:</p><pre><code>cursor.execute(sql)</code></pre><p><strong>except</strong> Exception, e:</p><pre><code>print e</code></pre><p>sql <strong>=</strong> \”insert into test1(name, age) values (\’%s\’, %d)\” <strong>%</strong><br>(\”张三\”, 21)</p><p><strong>try</strong>:</p><pre><code>cursor.execute(sql)</code></pre><p><strong>except</strong> Exception, e:</p><pre><code>print e</code></pre><p># 插入多条</p><p>sql <strong>=</strong> \”insert into test1(name, age) values (%s, %s)\”</p><p>val <strong>=</strong> ((\”李四\”, 24), (\”王五\”, 25), (\”洪六\”, 26))</p><p><strong>try</strong>:</p><pre><code>cursor.executemany(sql, val)</code></pre><p><strong>except</strong> Exception, e:</p><pre><code>print e</code></pre><p>#查询出数据</p><p>sql <strong>=</strong> \”select * from test1\”</p><p>cursor.execute(sql)</p><p>alldata <strong>=</strong> cursor.fetchall()</p><p># 如果有数据返回，就循环输出, alldata是有个二维的列表</p><p><strong>if</strong> alldata:</p><pre><code>**for** rec **in** alldata:    print rec\[0\], rec\[1\]</code></pre><p>cursor.close()</p><p>conn.close()</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;python操作mysql的多个方案&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.runoob.com/python/python-mysql.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://www.runoob.com/p
      
    
    </summary>
    
      <category term="mysql" scheme="http://zhangyu8.me/categories/mysql/"/>
    
    
      <category term="mysql" scheme="http://zhangyu8.me/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>谈谈我的三观</title>
    <link href="http://zhangyu8.me/2019/02/28/%E8%B0%88%E8%B0%88%E6%88%91%E7%9A%84%E4%B8%89%E8%A7%82/"/>
    <id>http://zhangyu8.me/2019/02/28/谈谈我的三观/</id>
    <published>2019-02-27T16:00:00.000Z</published>
    <updated>2019-09-10T05:56:15.134Z</updated>
    
    <content type="html"><![CDATA[<p>谈谈我的三观</p><p>酷 壳 - CoolShell</p><p><a href="https://coolshell.cn/articles/19085.html" target="_blank" rel="noopener">https://coolshell.cn/articles/19085.html</a></p><p> 也许是人到了四十多了，敢写这么大的命题，我也醉了，不过，我还是想把我的想法记录下来，算是对我思考的一个snapshot，给未来的我看看，要么被未来的我打脸，要么打未来我的脸。无论怎么样，我觉得对我自己都很有意义。注意，这篇文章是长篇大论。</p><p> 三观是世界观、人生观和价值观，</p><ul><li><strong>世界观代表你是怎么看这个世界的。</strong>是左还是右，是激进还是保守，是理想还是现实，是乐观还是悲观……</li><li><strong>人生观代表你要想成为什么样的人。</strong>是成为有钱人，还是成为人生的体验者，是成为老师，还是成为行业专家，是成为有思想的人，还是成为有创造力的人……</li><li><p><strong>价值观则是你觉得什么对你来说更重要</strong>。是名是利，是过程还是结果，是付出还是索取，是国家还是自己，是家庭还是职业……</p><p>人的三观其实是会变的，回顾一下我的过去，我感觉我的三观至少有这么几比较明显的变化，学生时代、刚走上社会的年轻时代，三十岁后的时代，还有现在。估计人都差不多吧……</p></li><li><p>学生时代的三观更多的是学校给的，用各种标准答案给的，是又红又专的</p></li><li>刚走上社会后发现完全不是这么一回事，但学生时代的三观根深蒂固，三观开始分裂，内心开始挣扎</li><li>三十岁后，不如意的事越来越多，对社会越来越了解，有些人屈从现实，有些人不服输继续奋斗，而有些人展露才能开始影响社会，而分裂的三观开始收敛，我属于还在继续奋斗的人。</li><li><p>四十岁时，经历过的事太多，发现留给自己的时间不多，世界太复杂，而还有好多事没做，从而变得与世无争，也变得更为地自我。</p><h4 id="面对世界"><a href="#面对世界" class="headerlink" title="面对世界"></a>面对世界</h4><p>年轻的时候，抵制过日货，虽然没上过街，但是也激动过，一次是1999南斯拉夫大使馆被炸，一次是2005反日示威，以前，我也是一个爱国愤青。但是后来，有过各种机会出国长时间生活工作，加拿大、英国、美国、日本……随着自己的经历和眼界的开阔，自己的三观自己也随着有了很多的变化，发现有些事并不是自己一开始所认识的那样，而且还是截然相反的。<strong>我深深感觉到，要有一个好的世界观，你需要亲身去经历和体会这个世界，而不是听别人说</strong>。所以，当我看到身边的人情绪激动地要抵制这个国家，搞死那个民族的时候，我都会建议他去趟那个国家最好在在那个国家呆上一段时间，亲自感受一下。</p><p>再后来发现，要抵制的越来越多，小时候的美英帝国主义，然后是日本，再后面是法国、韩国、菲利宾、印度、德国、瑞典、加拿大……从小时候的台独到现在的港独、藏独、疆独……发现再这样下去，基本上来说，自己的人生也不用干别的事了……另外，随着自己的成长，越来越明白，<strong>抵制这个抵制那个只不过是幼稚和狭隘的爱国主义，真想强国，想别让他人看得起，就应该把时间和精力放在努力学习放在精益求精上，做出比他们更好的东西来。</strong>另外，感觉用对内的爱国主义解决对外的外交问题也有点驴唇不对马嘴，无非也就是转移一下内部的注意力罢了，另外还发现爱国主义还可以成为消费营销手段……<strong>不是我不爱国，是我觉得世道变复杂了，我只是一个普通的老百姓，能力有限，请不要赋予我那么大的使命，我只想在我的专业上精进，能力所能及地帮助身边的人，过一个简单纯粹安静友善的生活</strong>……</p><p>另外，为什么国与国之间硬要比个你高我低，硬要分个高下，硬要争出个输赢，我也不是太理解，世界都已经发展到全球化的阶段了，很多产品早就是你中有我，我中有你的情况了。举个例子，一部手机中的元件，可能来自全世界数十个国家，我们已经说不清楚一部手机是究竟是哪个国家生产的了。即然，整个世界都在以一种合作共赢全球化的姿态下运作，认准自己的位置，拥抱世界，持续向先进国家学习，互惠互利，不好吗？你可能会说，不是我们不想这样，是别人不容我们发展……<strong>老实说，大的层面我也感受不到，但就我在的互联网计算机行业方面，我觉得整个世界的开放性越来越好，开源项目空前地繁荣，世界上互联网文化也空前的开放，在计算机和互联网行业，我们享受了太多的开源和开放的红利，人家不开放，我们可能在很多领域还落后数十年。然而现在很多资源我们都访问不了，用个VPN也非法，你说是谁阻碍了发展？我只想能够流畅地访问互联网，让我的工作能够更有效率，然而，我在自己的家里却像做贼一样去学习新知识新技术，随时都有可能被抓进监狱……</strong></p><p>随着自己的经历越多，发现这个世界越复杂，也发现自己越渺小，很多国家大事并不是我不关心，是我觉得那根本不是我这个平头老百姓可以操心的事，这个世界有这个世界运作的规律和方法，而还有很多事情超出了我能理解的范围，也超出了我能控制的范围，我关心不关心都一个样，这些大事都不会由我的意志所决定的。而所谓的关心，无非就是喊喊口号，跟人争论一下，试图改变其它老百姓的想法，然而，对事情的本身的帮助却没有多大意义。过上几天，生活照旧，人家该搞你还不是继续搞你，而你自己并不因为做这些事而过得更好。</p><p><strong>我对国与国之间的关系的态度是，有礼有节，不卑不亢，对待外国人，有礼貌但也要有节气，既不卑躬屈膝，也不趾高气昂</strong>，整体上，我并不觉得我们比国外有多差，但我也不觉得我们比国外有多好，我们还在成长，还需要帮助和协作，四海之内皆兄弟，无论在哪个国家，在老百姓的世界里，哪有那么多矛盾。<strong>有机会多出去走走，多结交几个其它民族的朋友，你会觉得，在友善和包容的环境下，你的心情和生活可以更好</strong>。</p><p>我现在更多关心的是和我生活相关的东西，比如：上网、教育、医疗、食品、治安、税务、旅游、收入、物价、个人权益、个人隐私……这些东西对我的影响会更大一些，也更值得关注，可以看到过去的几十年，我们国家已经有了长足的进步，这点也让我让感到很开心和自豪的，在一些地方也不输别人。但是，依然有好些事的仍然没有达到我的预期，而且还很糟糕，这个也要承认。而对，未来的变数谁也不好说，我在这个国度里的安全感似乎还不足够，所以，我还是要继续努力，以便我可以有更多的选项。有选项总比没得选要好。所以，<strong>我想尽一切办法，努力让选项多起来，无法改变无法影响，那就只能提高自己有可选择的可能性</strong>。</p><h4 id="面对社会"><a href="#面对社会" class="headerlink" title="面对社会"></a>面对社会</h4><p>另外，在网上与别人对一些事或观点的争论，我觉得越来越无聊，以前被怼了，一定要怼回去，现在不会了，视而不见，不是怕了，是因为，网络上的争论在我看来大多数都是些没有章法，逻辑混乱的争论。</p></li><li><p>很多讨论不是说事，直接就是怼人骂人。随意就给人扣个帽子。</p></li><li>非黑即白的划分，你说这个不是黑的，他们就把你划到白的那边。</li><li>飘移观点，复杂化问题。东拉西扯，牵强附会，还扯出其它不相关的事来混淆。</li><li><p>杠精很多，不关心你的整体观点，抓住一个小辫子大作文章。</p><p>很明显，<strong>与其花时间教育这些人，不如花时间提升自己，让自己变得更优秀，这样就有更高的可能性去接触更聪明更成功更高层次的人</strong>。因为，一方面，你改变不了他们，另外，改变他们对你自己也没什么意义，改变自己，提升自己，让自己成长才有意义。时间是宝贵的，那些人根本不值得花时间，应该花时间去结交更有素质更聪明的人，做更有价值的事。</p><p>美国总统富兰克林·罗斯福妻子埃莉诺·罗斯福（Eleanor Roosevelt）说过下面的一句话。</p><p><strong>Great minds discuss ideas;<br>Average minds discuss events;<br>Small minds discuss people</strong></p><p>把时间多放在一些想法上，对自己对社会都是有意义的，把时间放在八卦别人，说长到短，你也不可能改善自己的生活，<strong>你批评这个批评那个，看不上这个看不起那个，不会让你有成长，也不会提升你的影响力，你的影响力不是你对别人说长道短的能力，而是别人信赖你并希望得到你的帮助的现象</strong>。多交一些有想法的朋友，多把自己的想法付诸实践，那怕没有成功，你的人生也会比别人过得有意义。</p><p>如果你看过我以前的文章，你会看到一些吐槽性质的文章，而后面就再也没有了。另外，我也不再没有针对具体的某个人做出评价，因为人太复杂的了，经历的越多，你就会发现你很难评价人，与其花时间在评论人和事上，不如把时间花在做一些力所能及的事来改善自己或身边的环境。所以，<strong>我建议大家少一些对人的指责和批评，通过对一件事来引发你的思考，想一想有什么可以改善，有什么方法可以做得更好，有哪些是自己可以添砖加瓦的？你会发现，只要你坚持这么做，你个人的提升和对社会的价值会越来越大，而你的影响力也会越来越大</strong>。</p><h4 id="面对人生"><a href="#面对人生" class="headerlink" title="面对人生"></a>面对人生</h4><p>现在的我，即不是左派也不是右派，我不喜欢爱国主义，我也不喜欢崇洋媚外，我更多的时候是一个自由派，哪边我都不站，我站我自己。因为，生活在这样的一个时代，能让自己过好都是一些比较奢望的事了。</p><p>《教父》里有这样的人生观：<strong>第一步要努力实现自我价值，第二步要全力照顾好家人，第三步要尽可能帮助善良的人，第四步为族群发声，第五步为国家争荣誉。事实上作为男人，前两步成功，人生已算得上圆满，做到第三步堪称伟大，而随意颠倒次序的那些人，一般不值得信任</strong>。这也是古人的“修身齐家治国平天下”！所以，在你我准备要开始要“平天下”的时候，也得先想想，自己的生活有没有过好了，家人照顾好了么，身边有哪些力所能及的事是可以去改善的……</p><p>穷则独善其身，达则兼济天下。提升自己，实现自我，照顾好自己的家人，帮助身边的人。这已经很不错了！</p><p>什么样的人干什么样的事，什么样的阶段做什么样的选择，<strong>有人的说，选择比努力更重要的，我深以为然，而且，我觉得选择和决定，比努力更难</strong>，努力是认准了一个事后不停地发力，而决定要去认准哪个事是自己该坚持努力的，则是令人彷徨和焦虑的（半途而废的人也很多）。面对人生，你每天都在作一个一个的决定，在做一个又一个的选择，有的决定大，有的决定小，你的人生的轨迹就是被这一个一个的决定和选择所走走出来的。</p><p>我在24岁放弃了一房子离开银行到小公司的时候，我就知道，人生的选择就是一个翘翘板，你要一头就没有另一头，<strong>选择是有代价的，你不选择的代价更大；选择是要冒险的，你不敢冒险的风险更大；选择是需要放弃的，因为无论怎么选你都会要放弃。想想你老了以后，回头一看，好多事情在年轻的时候都不敢做，而你再也没有机会，你就知道不敢选择不敢冒险的代价有多大了。</strong>选择就是一种 trade-off，这世上根本不会有什么完美，只要你想做事，你有雄心壮志，你的人生就是一个坑接着一个坑，你所能做的就是找到你喜欢的方向跳坑。</p><p>所以， 你要想清楚你要什么，不要什么，而且还不能要得太多，这样你才好做选择。否则，你影响你的因子太多，决定不好做，也做不好。</p><p>就像最前面说的一样，你是激进派还是保守派，你是喜欢领导还是喜欢跟从，你是注重长期还是注重短期，你是注重过程还是注重结果……等等，你对这些东西的坚持和守护，成为了你的“三观”，而你的三观则影响着你的选择，而你的选择影响着你的人生。</p><h4 id="价值取向"><a href="#价值取向" class="headerlink" title="价值取向"></a>价值取向</h4><p>下面是一些大家经常在说，可能也是大多数人关心的问题，就这些问题，我也谈谈我的价值取向。</p><p><strong>挣钱</strong>。挣钱是一个大家都想做的事，但你得解决一个很核心的问题，那就是为什么别人愿意给你钱？对于挣钱的价值观从我大学毕业到现我就没怎么变过，那就是我更多关注的是怎么提高自己的能力，让自己值那个价钱，让别人愿意付钱。另外一方面，我发现，<strong>越是有能力的人，就越不计较一些短期得失，越计较短期得失的人往往都是很平庸的人</strong>。有能力的人不会关心自己的年终奖得拿多少，会不会晋升，他们更多的关心自己真正的实力有没有超过更多的人，更多的关注的是自己长远的成长，而不是一时的利益。聪明的人从来不关心眼前的得失，不会关心表面上的东西，他们更多关心的是长期利益，关心长期利益的人一定不是投机者，一定是投资者，<strong>投资会把自己的时间精力金钱投资在能让自己成长和提升的地方，那些让自己可以操更大的盘的地方，他们培养自己的领导力和影响力。</strong>而投机者在职场上会通过溜须拍马讨好领导，在学习上追求速成，在投资上使用跟随策略，在创业上甚至会不择手段，当风险来临时，投机者是几乎完全没有抗风险能力的，他们所谓的能力只不过因为形势好。</p><p><strong>技术</strong>。对于计算机技术来说，要学的东西实在是太多，我并不害怕要学的东西很多，因为学习能力是一个好的工程师必需具备的事，我不惧怕困难和挑战。我觉得在语言和技术争论谁好谁坏是一种幼稚的表现， 没有完美的技术，Engineering 玩的是 Tradeoff。所以，我对没有完美的技术并不担心，但是我反而担心的是，当我们进入到一些公司后，这些公司会有一些技术上的沉淀也就是针对公司自己的专用技术，比如一些中间件，一些编程框架，lib库什么的。老实说，我比较害怕公司的专用技术，因为一旦失业，我建立在这些专用技术上的技能也会随之瓦解，有时候，我甚至害怕把我的技术建立在某一个平台上，小众的不用说了，大众的我也比较担扰，比如Windows或Unix/Linux上，因为一旦这个平台不流行或是被取代，那么我也会随之淘汰（过去的这20年已经发生过太多这样的事了）。为了应对这样的焦虑，<strong>我更愿意花时间在技术的原理和技术的本质上，这导致我需要了解各种各样的技术的设计方法，以及内在原理。</strong>所以，当国内的绝大多数程序员们更多的关注架构性能的今天，我则花更多的时间去了解编程范式，代码重构，软件设计，计算机系统原理，领域设计，工程方法……因为只有原理、本质和设计思想才可能让我不会被绑在某个专用技术或平台上，除非，我们人类的计算机这条路没走对。</p><p><strong>职业</strong>。在过去20多年的职业生涯中，我从基层工程师做到管理，很多做技术的人都会转管理，但我却还是扎根技术，就算是在今天，还是会抠很多技术细节，包括写代码。因为我心里觉得，不写代码的人一定是做不好技术管理的，因为做技术管理有人要做技术决定，从不上手技术的人是做不好技术决定的，另一方面，我觉得管理是支持性的工作，不是产出性的工作，大多数的管理者无非是因为组织大了，所以需要管人管事，所以，必然要花大量的时间和精力处理各种问题，甚至办公室政治，然而，如果有一天失业了，大环境变得不好了，一个管理者和一个程序员要出去找工作，程序员会比管理者更能自食其力。所以，我并不觉得管理者这个职业有意思，我还是觉得程序员这个有创造性的职业更有趣。<strong>通常来说，管理者的技能力需要到公司和组织里才能展现，而有创造力的技能的人是可以自己独立的能力，所以，我觉得程序员的技能比管理者的技能能让我更稳定更自地活着</strong>。所以，我更喜欢“<a href="https://coolshell.cn/articles/4951.html" target="_blank" rel="noopener">电影工作组</a>”那样的团队和组织形式。</p><p><strong>打工</strong>。对于打工，也就是加入一家公司工作，无论是在一家小公司还是一家大公司工作，都会有好的和不好的，任何公司都有其不完美的地方，这个需要承认。首先第一的肯定是完成公司交给你的任务（但我也不会是傻傻地完成工作，对于一些有问题的任务我也会提出我的看法），然后我会尽我所能在工作找到可以提高效率的地方进行改善。在推动公司/部门/团队在一技术和工程方面进步并不是一件很容易的事，因为进步是需要成本的，有时候，这种成本并不一定是公司和团队愿意接受的，而另外，从客观规律上来说，一件事的进步一定是会有和现状有一些摩擦的。有的人害怕有摩擦而忍了，而我则不是，我觉得与别人的摩擦并不可怕，因为大家的目标都是基本一致的，只是做事的标准和方式不一样，这是可能沟通的，始终是会相互理解的。而如果你没有去推动一个事，我觉得对于公司对于我个人来说，都是一种对人生的浪费，敬业也好，激情也好，其就是体现在你是否愿意冒险去推动一件于公于私都有利的事，而不是成为一个“听话”、“随大流”、“懒政”的人，即耽误了公司也耽误了自己。所以，我更信仰的是《<a href="http://www.aqee.net/post/do-the-right-thing-wait-to-get-fired.html" target="_blank" rel="noopener">做正确的事情，等着被开除</a>》，这些东西，可参看《<a href="https://coolshell.cn/articles/17972.html" target="_blank" rel="noopener">我看绩效考核</a>》，以及我在<a href="https://mp.weixin.qq.com/s?__biz=MzUyOTA1NTkzNw==&amp;mid=2247484417&amp;idx=1&amp;sn=316f9f6d6ac7cdca97123815a67a665a&amp;chksm=fa67adafcd1024b948caed0e5528c4817a7ef2b1b1a3ab8da34e0ff4231b28c2659ee9951112#rd" target="_blank" rel="noopener">Gitchat上的一些问答</a>。</p><p><strong>创业</strong>。前两天，有个小伙来跟我说，说他要离开BAT要去创业公司了，说在那些更自由一些，没有大公司的种种问题。我毫不犹豫地教育了他一下，我说，你选择这个创业公司的动机不对啊，你无非就是在逃避一些东西罢了，你把创业公司当做是一个避风港，这是不对的，创业公司的问题可能会更多，去创业公司的更好的心态是，这个创业公司在干的事业是不是你的事业？说白了，如果你是为了你的事业，为了解决个什么，为了改进个什么，那么，创业是适合你的，<strong>也只有在做自己事业的时候，你才能不惧困难，才会勇敢地面对一切</strong>。<strong>那种想找一个安稳的避风港呆着的心态是不会让你平静地，你要知道世界本来就是不平静的，找了自己的归宿和目标才可能让你真正的平静</strong>。所以，在我现的创业团队，我不要求大家加班，我也不鸡汤洗脑，对于想要加入的人，我会跟他讲我现在遇到的各种问题以及各种机遇，并一直在让他自己思考，我们在做的事是不是自己的事业诉求？还可不可以更好？<strong>每个人都应该为自己的事业为自己的理想去活一次，追逐自己的事业和理想并不容易，需要有很大的付出，而也只有你心底里的那个理想值得这么大的付出</strong>……</p><p><strong>客户</strong>。基于上述的价值观，在我现在创业的时候，我在面对客户的时候，也是一样的，我并不会完全的迁就于客户，我的一些银行客户和互联网客户应该体会到我的做的方式了，我并不觉得迁就用户，用户要什么我就应该给什么，用户想听什么，我就说什么，虽然这样可以省着精力，更圆滑，但这都不是我喜欢的，<strong>我更愿意鲜明地表达我的观点，并拉着用户跟我一起成长，因为我并不觉得完成客户的项目有成就感，我的成就感来自客户的成长</strong>。所以，面对客户有些做得不对有问题有隐患的地方，或是有什么做错的事，我基本上都是直言不讳地说出来，因为我觉得把真实的相法说出来是对客户和对自己最基本的尊重，不管客户最终的选择是什么，我都要把利弊跟客户讲清楚。我并不是在这里装，因为，我也想做一些更高级更有技术含量的事，所以，对于一些还达到的客户，我如果不把他们拉上来，我也对不起自己。</p><p>在我“不惑之年”形成了这些价值观体系，也许未来还会变，也许还不成熟，总之，我不愿跟大多数人一样，因为大多数人都是随遇而安随大流的，因为这样风险最小，而我想走一条属于自己的路，做真正的自己，就像我24岁从银行里出来时想的那样，<strong>我选择对了一个正确的专业（计算机科学），呆在了一个正确的年代（信息化革命），这样的“狗屎运”几百年不遇，如果我还患得患失，那我岂不辜负活在这样一个刺激的时代？！我所要做的就是在这个时代中做有价值的事就好了！这个时代真的是太好了！</strong></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;谈谈我的三观&lt;/p&gt;
&lt;p&gt;酷 壳 - CoolShell&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://coolshell.cn/articles/19085.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://coolshell.
      
    
    </summary>
    
      <category term="胡说八道" scheme="http://zhangyu8.me/categories/%E8%83%A1%E8%AF%B4%E5%85%AB%E9%81%93/"/>
    
    
      <category term="胡说八道" scheme="http://zhangyu8.me/tags/%E8%83%A1%E8%AF%B4%E5%85%AB%E9%81%93/"/>
    
  </entry>
  
  <entry>
    <title>闲扯Nginx的accept_mutex配置</title>
    <link href="http://zhangyu8.me/2019/02/28/%E9%97%B2%E6%89%AFNginx%E7%9A%84accept_mutex%E9%85%8D%E7%BD%AE/"/>
    <id>http://zhangyu8.me/2019/02/28/闲扯Nginx的accept_mutex配置/</id>
    <published>2019-02-27T16:00:00.000Z</published>
    <updated>2019-09-10T05:56:25.210Z</updated>
    
    <content type="html"><![CDATA[<p> 闲扯Nginx的accept_mutex配置</p><p><a href="https://huoding.com/2013/08/24/281" target="_blank" rel="noopener">https://huoding.com/2013/08/24/281</a><br> 让我们看看accept_mutex的意义：当一个新连接到达时，如果激活了accept_mutex，那么多个Worker将以串行方式来处理，其中有一个Worker会被唤醒，其他的Worker继续保持休眠状态；如果没有激活accept_mutex，那么所有的Worker都会被唤醒，不过只有一个Worker能获取新连接，其它的Worker会重新进入休眠状态，这就是「<a href="http://en.wikipedia.org/wiki/Thundering_herd_problem" target="_blank" rel="noopener">惊群问题</a>」。</p><p> Nginx缺省激活了accept_mutex，也就是说不会有惊群问题，但真的有那么严重么？实际上Nginx作者Igor Sysoev曾经给过相关的<a href="http://forum.nginx.org/read.php?2,1641,1686#msg-1686" target="_blank" rel="noopener">解释</a>：</p><p>  OS may wake all processes waiting on accept() and select(), this is called thundering herd problem. This is a problem if you have a lot of workers as in Apache (hundreds and more), but this insensible if you have just several workers as nginx usually has. Therefore turning accept_mutex off is as scheduling incoming connection by OS via select/kqueue/epoll/etc (but not accept()).</p><p> 简单点说：Apache动辄就会启动成百上千的进程，如果发生惊群问题的话，影响相对较大；但是对Nginx而言，一般来说，<a href="http://wiki.nginx.org/CoreModule#worker_processes" target="_blank" rel="noopener">worker_processes</a>会设置成CPU个数，所以最多也就几十个，即便发生惊群问题的话，影响相对也较小。</p><p> …</p><p> 假设你养了一百只小鸡，现在你有一粒粮食，那么有两种喂食方法：</p><ul><li>你把这粒粮食直接扔到小鸡中间，一百只小鸡一起上来抢，最终只有一只小鸡能得手，其它九十九只小鸡只能铩羽而归。这就相当于关闭了accept_mutex。</li><li><p>你主动抓一只小鸡过来，把这粒粮食塞到它嘴里，其它九十九只小鸡对此浑然不知，该睡觉睡觉。这就相当于激活了accept_mutex。</p><p>可以看到此场景下，激活accept_mutex相对更好一些，让我们修改一下问题的场景，我不再只有一粒粮食，而是一盆粮食，怎么办？</p><p>此时如果仍然采用主动抓小鸡过来塞粮食的做法就太低效了，一盆粮食不知何年何月才能喂完，大家可以设想一下几十只小鸡排队等着喂食时那种翘首以盼的情景。此时更好的方法是把这盆粮食直接撒到小鸡中间，让它们自己去抢，虽然这可能会造成一定程度的混乱，但是整体的效率无疑大大增强了。</p><p>Nginx缺省激活了accept_mutex（最新版缺省禁用），是一种保守的选择。如果关闭了它，可能会引起一定程度的惊群问题，表现为上下文切换增多（sar -w）或者负载上升，但是如果你的网站访问量比较大，为了系统的吞吐量，我还是建议大家关闭它。</p></li></ul><p>最新 nginx-1.11.4开始默认关闭了accept_mutex。</p><p>从tengine2.2开始accept_mutex 参数由默认的 on 改为了 off ，为什么要改呢。与时俱进。</p><p>当初这个参数是为了避免在 epoll_wait 所出现惊群效应。可以参考（<a href="https://www.jianshu.com/p/21c3e5b99f4a）。" target="_blank" rel="noopener">https://www.jianshu.com/p/21c3e5b99f4a）。</a></p><p>新版内核已经有了处理这个方法，不再需要 nginx 单独配置。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; 闲扯Nginx的accept_mutex配置&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://huoding.com/2013/08/24/281&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://huoding.com/2013/08/24
      
    
    </summary>
    
      <category term="nginx" scheme="http://zhangyu8.me/categories/nginx/"/>
    
    
      <category term="nginx" scheme="http://zhangyu8.me/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>SRE工程师到底是做什么的？</title>
    <link href="http://zhangyu8.me/2019/02/28/SRE%E5%B7%A5%E7%A8%8B%E5%B8%88%E5%88%B0%E5%BA%95%E6%98%AF%E5%81%9A%E4%BB%80%E4%B9%88%E7%9A%84/"/>
    <id>http://zhangyu8.me/2019/02/28/SRE工程师到底是做什么的/</id>
    <published>2019-02-27T16:00:00.000Z</published>
    <updated>2019-09-10T05:56:33.487Z</updated>
    
    <content type="html"><![CDATA[<p>SRE工程师到底是做什么的？ </p><p><a href="https://mp.weixin.qq.com/s/j5Sgrsm90B94jMwn1mA1Gg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/j5Sgrsm90B94jMwn1mA1Gg</a></p><p> 作者 | Erik Dietrich  </p><p> 译者 | 无明</p><p> 你是否也对站点可靠性工程师（SRE）这个角色存在很多疑问？本文介绍了 SRE 工程师的职责。</p><p> 尽管站点可靠性工程已经存在了一段时间，但也只是最近才在业界获得一些名声。但人们对于站点可靠性工程师（SRE）的作用仍然存在很多疑问。我们所知道的大部分内容来自谷歌的《站点可靠性工程》一书。我们将在这篇文章中多次提到这本书。</p><p> 人们将 SRE 与运营、系统管理员等进行比较，但这种比较不足以说明他们在现代软件环境中所发挥的作用。他们承担的责任多于运营。他们通常具有系统管理背景，同时也具备软件开发技能。SRE 结合了所有这些技能，确保复杂的分布式系统能够顺利运行。</p><p> 那么他们是怎么做到这一切呢？</p><p> 自动化一切</p><p> 自动化是 SRE 角色与传统运营团队之间的一个区别。在过去，运营人员会通过执行脚本、按下按钮和其他手动操作来让软件系统保持运行。然而，在 SRE 世界中，人们非常重视自动化。这种驱动力来自 SRE 角色的工程方面。</p><p> 当软件开发人员处于日复一日重复相同功能的境地时，他们将被迫实现自动化。这就是软件开发人员最擅长的事情。自动化并不仅限于对软件构建和一些验收测试进行自动化，还包括 CI/CD 和基础设施的创建和修补，以及监控、警报和自动响应某些事件。在谷歌的《站点可靠性工程》一书中，这也被称为消除辛劳：</p><p> 辛劳是一种与运行生产服务相关的工作，它往往是手动的、重复的、可自动化的、战术性的，缺乏持久的价值，并随着服务的增长呈线性增长。</p><p> 那么为什么我们要如此关注如何减少辛劳呢？减少工作量不仅使流程可重复和自动化，而且还为 SRE 提供了更多的时间用于构建工具和研究基础设施变更以便进一步提高站点可靠性。总之，工作量越少，用于确保软件生态系统可靠运行的时间和资源就越多，你就能越快地实现业务价值。</p><p> 监控分布式系统</p><p> 随着分布式系统的普及，对监控的需求也在增长。仅仅启动和运行应用程序是不够的。我们还需要确保基础设施运行正常，并确保所有其他内部依赖项都可访问且运行正常。此外，应用程序的业务功能应该提供适当的监控功能，以验证它们是否运行正常。</p><p> 提供待命支持</p><p> 与传统的运营角色类似，SRE 也有轮班待命的职责。除了监控基础设施和他们自己的服务之外，开发团队还可以向他们咨询和请他们一起进行故障排除。</p><p> 轮班待命看起来是怎样的？通常，SRE 根据计划表进行轮班待命，计划表可以让其他 SRE 专注于工程方面，而且不会导致轮班待命工程师感到倦怠。轮换待命可以从几天到一周不等，或者更长时间。</p><p> 在发生高优先级的事件时，SRE 需要调查和诊断问题。他们还可能会要求其他工程师或软件开发人员一起来解决问题。根据系统的 SLA，他们可能需要一起工作才能在几分钟内解决问题。对于低优先级问题，SRE 通常会在工作时间内处理它们。对于那些不喜欢在凌晨 3 点钟起床的工程师来说，这是一个好消息。</p><p> 管理事件</p><p> 管理事件时 SRE 角色的另一个重要部分。你可能会说这与轮班待命没有什么两样。找到问题然后解决它，这能有多难？</p><p> 好吧，在管理事件时，SRE 需要运用额外的专业技能来确保一切顺利。例如，在发生中断时，可能有很多方法来诊断和解决问题。因此，为了妥善管理事件，必须有人监督和促进所有相关人员的行为。这就需要定义明确的角色。</p><p> 虽然并非所有公司都包含谷歌推荐的角色，但我们至少应该考虑它们。这些角色包括：</p><ul><li><p>一名事件指挥官，对所发生的一切都保持高度关注；</p></li><li><p>处理或修改基础设施或系统的工程师；</p></li><li><p>将正确的信息传递给客户和管理层的沟通者角色；</p></li><li><p>负责规划会议、交接和后勤需求的规划者角色；</p></li><li><p>如果 SRE 没有明确定义的角色，那么当他们在尝试不同的解决方案时，如果没有前期协调和沟通，就容易发生混乱。</p></li></ul><p> 事后调查</p><p> 我们已经经历并解决了一个事件，现在准备好进行事后调查。通常，SRE 会促进或参与这些事后调查。</p><p> 在进行事后调查时，所有相关方都被汇聚在一起，目标是分析事故期间都发生了什么，并找出根本原因。参与者还将决定将来如何防止或修复同样的事件。下面列出了事后调查将产出的内容：</p><ul><li><p>提高可靠性的故事或监控；</p></li><li><p>附加文档，以协助未来事件的处理；</p></li><li><p>进一步调查或测试，以证实与事件有关的任何假设。</p></li></ul><p> 跟踪中断</p><p> SRE 的另一个职责是跟踪中断。这最终有助于识别长期趋势和创建合理的 SLO 和 SLA。</p><p> 跟踪中断的用途包括监控低优先级事件。这些事件可能不会给消费者带来真正的问题，但是观察长期趋势和时间可以帮助隔离和解决那些似乎找不到原因的烦人 bug。</p><p> 与开发团队合作</p><p> 除了在轮班待命期间为开发团队提供支持，SRE 还提供咨询和故障排除服务。这样可以帮助其他 SRE 团队和软件开发团队，这些团队苦于处理运营或可靠性问题。</p><p> 在这种情况下，SRE 将评估当前问题，并确定哪些可以通过自动化或工程工作进行改进。SRE 还可为可靠性问题提出解决方案。最重要的是，SRE 将推动团队流程的变革。这些变化将确保站点可靠性工程团队能够增强团队交付价值的能力。</p><p> 创建服务水平指标和目标</p><p> 当你听到有人说服务已经达到或正在努力达到 99.99％的正常运行时间时，他们指的是服务水平目标（SLO）。服务水平指标（SLI）用于衡量这些目标。换句话说，SLI 是关于如何衡量 SLO 的协议。SRE 通过提供历史服务性能数据来协助这些工作。它们还有助于为未来提供切合实际的目标，并可能为客户提供适当的 SLA 建议。</p><p> 然后，SRE 会确保你的应用程序满足（但不超过）规定的 SLO。现在你可能会认为没有超过 SLO 会很奇怪。然而，制造超出实际需要的东西是对资源的浪费。SRE 平衡了客户需求和所提供服务的目标。</p><p> 职责可能会有所不同</p><p> 在这篇文章中，我们讨论了站点可靠性工程师参与的各种活动。虽然这些活动是由 SRE 完成的，但并不是一成不变的。公司会根据需要改变 SRE 的角色和职责。一般而言，处于 SRE 过程不同阶段的公司可能有不同的需求。</p><p> 例如，新公司可能需要 SRE 的支持才能控制一般性中断。大部分能量都趋向于可靠性的基本水平。但是，在这一过程中走得更远的其他公司可能已经消除了公司范围的中断。他们可能会花更多时间来改进或验证与业务相关的服务指标。例如，在网站的普遍可用性达到稳定和可靠的状态之后，你的披萨店应用程序可能需要对披萨推荐机制进行新的监控。</p><pre><code>结论   </code></pre><p> 正如你所读到的，SRE 将时间花在技术和流程方面的职责上。他们不仅仅是运营或系统管理团队。他们利用自己的工程技能自动化和减少管理任务所需的人工干预。此外，他们还与其他工程团队合作，提供适当的监控、事件响应和管理。</p><p> 随着时间的推移，这些职能提高了分布式系统的可靠性并降低维护成本。最后，他们通过组织传播站点可靠性工程文化，让所有团队都能学会在做出决策时以可靠性作为出发点。</p><p> 英文原文：<a href="https://www.scalyr.com/blog/site-reliability-engineer/" target="_blank" rel="noopener">https://www.scalyr.com/blog/site-reliability-engineer/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;SRE工程师到底是做什么的？ &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/j5Sgrsm90B94jMwn1mA1Gg&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.co
      
    
    </summary>
    
      <category term="devops" scheme="http://zhangyu8.me/categories/devops/"/>
    
    
      <category term="devops" scheme="http://zhangyu8.me/tags/devops/"/>
    
  </entry>
  
  <entry>
    <title>2019运维技能风向标</title>
    <link href="http://zhangyu8.me/2019/02/27/2019%E8%BF%90%E7%BB%B4%E6%8A%80%E8%83%BD%E9%A3%8E%E5%90%91%E6%A0%87/"/>
    <id>http://zhangyu8.me/2019/02/27/2019运维技能风向标/</id>
    <published>2019-02-26T16:00:00.000Z</published>
    <updated>2019-09-10T05:56:42.223Z</updated>
    
    <content type="html"><![CDATA[<p>2019运维技能风向标</p><p><a href="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://blog.51cto.com/ixdba/2338362" target="_blank" rel="noopener">http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://blog.51cto.com/ixdba/2338362</a></p><p> 运维是一个融合多学科(网络、系统、开发、安全、应用架构、存储等)的综合性技术岗位，从最初的网络管理（网管）发展到现在的系统运维工程师、网络运维工程师、安全运维工程师、运维开发工程师等，可以看出，运维的分工一直在细化，并且对综合技能要求越来越高，可以看出，未来运维的发展趋势是高、精、尖，高表示高度，精表示精通，尖表示尖端，也就是运维职场一定要站在一定的技术高度，在多个技术领域中，要精通某项技能，同时对尖端前沿技术一定要能掌控趋势。</p><h2 id="一、运维职位的发展和趋势"><a href="#一、运维职位的发展和趋势" class="headerlink" title="一、运维职位的发展和趋势"></a>一、运维职位的发展和趋势</h2><p> 根据不同的运维领域和技术面以及分工流程三个方面来了解下2019年运维职位的发展趋势。</p><h3 id="1、按领域来划分"><a href="#1、按领域来划分" class="headerlink" title="1、按领域来划分"></a>1、按领域来划分</h3><p> 1）、基础设施运维：IDC/网络运维、服务器/存储设备运维<br> 2）、系统运维：系统中间件运维、云计算平台运维<br> 3）、数据运维：数据库运维、大数据技术平台运维<br> 4）、应用运维：应用软件系统<br> 5）、云平台运维：公有云平台运维<br> 6）、容器运维：基于容器服务的运维</p><h3 id="2、按技术切面来分"><a href="#2、按技术切面来分" class="headerlink" title="2、按技术切面来分"></a>2、按技术切面来分</h3><p> 1）、安全运维<br> 2）、性能运维<br> 3）、数据运维<br> 4）、集成运维</p><h3 id="3、按流程来划分"><a href="#3、按流程来划分" class="headerlink" title="3、按流程来划分"></a>3、按流程来划分</h3><p> 1）、构建/持续集成、发布<br> 2）、安装部署、升级、迁移、合并、扩展<br> 3）、配置、初始化、配置变更<br> 4）、备份、传输、恢复<br> 5）、日志、监控、预警<br> 6）、诊断排查、优化</p><h2 id="二、系统运维技能图谱"><a href="#二、系统运维技能图谱" class="headerlink" title="二、系统运维技能图谱"></a>二、系统运维技能图谱</h2><p> 系统运维是运维的基础，新的一年中，对基础运维技能要求也在提高，打好系统运维基础，才能深入学习后面的各种运维技能。</p><p> 下图列出了系统运维要掌握的必备技能：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201901/04/aceccbfc12aa1334ec232bc960452948.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=" alt></p><h2 id="三、web运维技能图谱"><a href="#三、web运维技能图谱" class="headerlink" title="三、web运维技能图谱"></a>三、web运维技能图谱</h2><p> web运维是运维岗位中岗位最多的一个，薪资也相对较高，但需要掌握的知识点也比较多，新的技能要掌握，老的运维技能也不能丢，下图列出了web运维要掌握的各种必备技能。</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201901/04/8a6bb665472eb9fbf74b6367c91f0bb4.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=" alt></p><h2 id="四、大数据运维技能图谱"><a href="#四、大数据运维技能图谱" class="headerlink" title="四、大数据运维技能图谱"></a>四、大数据运维技能图谱</h2><p> 大数据从2017年开始逐渐走到生活的各个角落，2018年在逐渐落地，而在2019年，大数据依然火热，加上国家对大数据产业的扶持，大数据产业在新的一年岗位需求一定会更加大，因此掌握大数据运维技能，就走在了运维的前沿，下图列出了大数据运维要掌握的各种必备技能。</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201901/04/c20162d6a930e86e9916af86120f1b5d.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=" alt></p><h2 id="五、容器运维技能图谱"><a href="#五、容器运维技能图谱" class="headerlink" title="五、容器运维技能图谱"></a>五、容器运维技能图谱</h2><p> 容器的产生，是一次IT行业的革命，2015 年到 2016 年，是业界普遍认为的容器技术爆发的一年，短短一年多时间里，容器技术在中国大陆完成了从零星概念到烽火燎原的壮举。</p><p> 时至今日，容器技术在国内大多数企业中落地已成为一种共识，而国内的生态系统，也呈现出了企业产品、开源社区和公有云齐头并进的良好局面。因此，2019年也是容器继续快速落地的一年，下图列出了大数据运维要掌握的各种必备技能。</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201901/04/51af4c346b4711b68eae808fc9ddb58c.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=" alt></p><h2 id="六、数据为王的时代"><a href="#六、数据为王的时代" class="headerlink" title="六、数据为王的时代"></a>六、数据为王的时代</h2><p> 万丈高楼平地起，高楼稳不稳取决于地基是否扎实。运维数据便是运维管理这座高楼的地基。运维数据大致分为CMDB、日志、生产DB、知识库四个方面。</p><ul><li><p>CMDB中文是配置管理数据库，存储与管理企业IT架构中设备的各种配置信息，主要是IT资产管理信息。</p></li><li><p>日志数据保护了企业服务器上运行的各种系统产生的应用日志，系统日志、设备日志、数据库日志等数据，这部分数据是企业数据的核心。</p></li><li><p>DB数据主要是所有IT系统的数据库信息，包括运维管理系统本身的数据库，数据库包含生产数据库、测试数据库、开发数据库三种类型。</p></li><li><p>知识库主要存储日常开发、测试、运维管理中发生的事件、问题以及一些经典问题的解决和常用的解决方案，主要起到运维管理辅助的功能。</p><p>对数据的维护和管理只管重要，特别是日志数据，对运维来说，通过日志可以比较准确全面地知道系统或是设备的运行情况，可以返查问题产生的原因，还原问题发生的整个过程。通过日志也可以提前预测系统可能要发生的问题或是故障，如系统安全日志，如果网络攻 击会在系统安全日志中有一定的体现。</p><p>下面简单介绍下，运维重点收集的日志数据有哪些部分以及用途。</p><h3 id="1、系统日志"><a href="#1、系统日志" class="headerlink" title="1、系统日志"></a>1、系统日志</h3><p>系统日志主要指的是操作系统的日志，主要在/var/log下的各种日志信息。包含系统操作日志、系统安全日志、定时任务日志等。系统日志是运维管理安全模块中审计的重要依据。一般默认的操作系统日志不能满足要求，需要对系统的参数进行修改，如为history命令加上时间戳、IP，并且长久保留历史等功能。并且对日志文件进行处理，不允许用户进行清空命令，只能追加。</p><h3 id="2、应用日志"><a href="#2、应用日志" class="headerlink" title="2、应用日志"></a>2、应用日志</h3><p>应用日志主要记录应用服务的健康运行情况以及业务操作的具体日志两部分。应用监控运行情况反应应用服务的健康状态，如果应用占用CPU或是内存过高或是忽高忽低不定，都可以通过分析应用日志结合业务操作日志得出结论。业务操作日志可以为业务审计提供主要依据。有一些系统喜欢把业务操作日志写到数据库中，这个也是需要注意的。不过不管在哪个地方，要求是不可缺少的，它为以后业务审计和问题返查提供依据。</p><h3 id="3、数据库日志"><a href="#3、数据库日志" class="headerlink" title="3、数据库日志"></a>3、数据库日志</h3><p>数据库日志主要反馈数据库的运行情况。通过监控和管理数据库的日志，及时了解数据库的运行情况，遇到问题及时解决等。可以通过数据库日志结合数据库系统自带的数据库如Oracle的系统视图v$开头，MySQL的performance_schema等。虽然数据库的一些信息不是存在日志中而是在数据库里面，但是也可以作为数据库日志的一部分进行管理和监控，已便我们及时知道数据库的监控状况，从而预防可能出现的问题。</p><h3 id="4、设备日志"><a href="#4、设备日志" class="headerlink" title="4、设备日志"></a>4、设备日志</h3><p>设备日志一般是一个比较容易忽略的地方，但设备日志往往可以反映设备的运行情况。交换机故障，防火墙故障等设备故障都可能引起大面积的系统和服务故障。所以设备日志一定要收集，分析和监控预警。常用的设备日志有交换机日志、防火墙日志、网络安全设备日志等。</p><p>这么多的日志，运维要通过各种手段完成日志的收集、过滤分析、可视化展示，那么如何实现这些功能呢，方法很多，例如ELK集成套件（Elasticsearch , Logstash, Kibana）就可以轻松实现日志数据的实时收集、分析传输以及图形化展示。</p></li><li><p>Elasticsearch是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。</p></li><li><p>Logstash主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式。一般工作方式为c/s架构，client端安装在需要收集日志的主机上，server端负责将收到的各节点日志进行过滤、修改等操作在一并发往elasticsearch上去。</p></li><li><p>Kibana 也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。</p><p>另外，还有Filebeat可以替换Logstash作为日志收集工具，Filebeat隶属于Beats。目前Beats包含四种工具：</p><p>Packetbeat（搜集网络流量数据）<br>Topbeat（搜集系统、进程和文件系统级别的 CPU 和内存使用情况等数据）<br>Filebeat（搜集文件数据）<br>Winlogbeat（搜集Windows事件日志数据）</p><p>可以看到，Beats涵盖了所有收集日志数据的各个方面。</p><p>那么要如何使用ELK呢，根据日志量的不同，对应的ELK架构也不尽相同，看下面几个常见架构：</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201901/03/39e84f4e6f6df0b5f95439dd60549a2c.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=" alt></p><p>此架构主要是将Logstash部署在各个节点上搜集相关日志、数据，并经过分析、过滤后发送给远端服务器上的Elasticsearch进行存储。Elasticsearch再将数据以分片的形式压缩存储，并提供多种API供用户查询、操作。用户可以通过Kibana Web直观的对日志进行查询，并根据需求生成数据报表。<br>此架构的优点是搭建简单，易于上手。缺点是Logstash消耗系统资源比较大，运行时占用CPU和内存资源较高。另外，由于没有消息队列缓存，可能存在数据丢失的风险。此架构建议供初学者或数据量小的环境使用。</p><p>由此衍生出来了第二种架构：</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201901/03/6e3c45e35972df117c08252aecaed9d0.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=" alt></p><p>此架构主要特点是引入了消息队列机制，位于各个节点上的Logstash Agent（一级Logstash，主要用来传输数据）先将数据传递给消息队列（常见的有Kafka、Redis等），接着，Logstash server（二级Logstash，主要用来拉取消息队列数据，过滤并分析数据）将格式化的数据传递给Elasticsearch进行存储。最后，由Kibana将日志和数据呈现给用户。由于引入了Kafka（或者Redis）缓存机制，即使远端Logstash server因故障停止运行，数据也不会丢失，因为数据已经被存储下来了。</p><p>这种架构适合于较大集群、数据量一般的应用环境，但由于二级Logstash要分析处理大量数据，同时Elasticsearch也要存储和索引大量数据，因此它们的负荷会比较重，解决的方法是将它们配置为集群模式，以分担负载。</p><p>此架构的优点在于引入了消息队列机制，均衡了网络传输，从而降低了网络闭塞尤其是丢失数据的可能性，但依然存在Logstash占用系统资源过多的问题，在海量数据应用场景下，可能会出现性能瓶颈。</p><p>最后，还有第三种架构：</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201901/03/d8d817a64ddfa9fa98d85f7382b7bf1e.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=" alt></p><p>这个架构是在上面第二个架构基础上改进而来的，主要是将前端收集数据的Logstash Agent换成了filebeat，消息队列使用了kafka集群，然后将Logstash和Elasticsearch都通过集群模式进行构建，此架构适合大型集群、海量数据的业务场景，它通过将前端Logstash Agent替换成filebeat，有效降低了收集日志对业务系统资源的消耗。同时，消息队列使用kafka集群架构，有效保障了收集数据的安全性和稳定性，而后端Logstash和Elasticsearch均采用集群模式搭建，从整体上提高了ELK系统的高效性、扩展性和吞吐量。</p><h2 id="三、用大数据思维做运维监控"><a href="#三、用大数据思维做运维监控" class="headerlink" title="三、用大数据思维做运维监控"></a>三、用大数据思维做运维监控</h2><p>大数据分析最早就来源于运维人的日志分析，到逐渐发展对各种业务的分析，人们发现这些数据蕴涵着非常大的价值，通过实时监测、跟踪研究对象在互联网上产生的海量行为数据，进行挖掘分析，揭示出规律性的东西，提出研究结论和对策。这就是大数据的用途。</p><p>同样，通过大数据分析，我们可以得到各种指标，例如：</p><p>1、在业务层面，如团购业务每秒访问数，团购券每秒验券数，每分钟支付、创建订单等。</p><p>2、在应用层面，每个应用的错误数，调用过程，访问的平均耗时，最大耗时，95线等</p><p>3、在系统资源层面：如cpu、内存、swap、磁盘、load、主进程存活等</p><p>4、在网络层面： 如丢包、ping存活、流量、tcp连接数等</p><p>而这些指标，刚好是运维特别需要的东西。通过大数据分析出的这些指标，可以解决如下方面的问题：</p><p>系统健康状况监控<br>查找故障根源<br>系统瓶颈诊断和调优<br>追踪安全相关问题</p><p>那么如何用大数据思维做运维呢，大数据架构上的一个思维就是：提供一个平台让运维方便解决这些问题， 而不是，让大数据平台去解决出现的问题。</p><p>基本的一个大数据运维架构是这样的：</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201901/03/9538a93fd4823503b00dff94658e9a50.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=" alt></p><p>对于运维的监控，利用大数据思维，需要分三步走：</p><p>获取需要的数据<br>过滤出异常数据并设置告警阀值<br>通过第三方监控平台进行告警</p><p>所有系统最可靠的就是日志输出，系统是不是正常，发生了什么情况，我们以前是出了问题去查日志，或者自己写个脚本定时去分析。现在这些事情都可以整合到一个已有的平台上，我们唯一要做的就是定义分析日志的的逻辑。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;2019运维技能风向标&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;amp;url=https://blog.51cto.com/ixdba/2338362&quot; targ
      
    
    </summary>
    
      <category term="运维" scheme="http://zhangyu8.me/categories/ops/"/>
    
    
      <category term="运维" scheme="http://zhangyu8.me/tags/%E8%BF%90%E7%BB%B4/"/>
    
  </entry>
  
  <entry>
    <title>一小时快速掌握zabbix配置的高效学习法</title>
    <link href="http://zhangyu8.me/2019/02/27/%E4%B8%80%E5%B0%8F%E6%97%B6%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1zabbix%E9%85%8D%E7%BD%AE%E7%9A%84%E9%AB%98%E6%95%88%E5%AD%A6%E4%B9%A0%E6%B3%95/"/>
    <id>http://zhangyu8.me/2019/02/27/一小时快速掌握zabbix配置的高效学习法/</id>
    <published>2019-02-26T16:00:00.000Z</published>
    <updated>2019-09-10T05:56:51.239Z</updated>
    
    <content type="html"><![CDATA[<p>一小时快速掌握zabbix配置的高效学习法</p><p><a href="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://blog.51cto.com/ixdba/2346602" target="_blank" rel="noopener">http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://blog.51cto.com/ixdba/2346602</a></p><p> 有人说zabbix难点在配置，面对很多的配置项，不知道所以然了，其实我觉得这是没掌握好zabbix的学习方法，要掌握了zabbix的学习思路，可以在一个小时内快速掌握zabbix的各种配置，下面我将重点讲述下如何快速、高效的对zabbix进行配置，已完成zabbix灵活的监控功能。</p><p> zabbix的配置全部都在zabbix web上完成，这点我非常喜欢，登录到zabbix web平台后，默认是英文界面，不过可以切换为中文界面，选择导航栏中的“Administration”选项，然后选择二级标签“Users”选项，在“Users”选项下列出了当前zabbix的用户信息，默认只有一个管理员用户Admin可用于登录zabbix web，点开Admin用户，进入属性设置界面，然后在“Language”选项中找到“Chinese（zh_CN）”选中即可切换到中文界面，刷新浏览器即可看到效果。</p><p> 下面就以zabbix的中文界面为主进行介绍，所有涉及到的截图和内容描述都以zabbix中文界面显示作为标准。</p><h2 id="1-1、模板的管理与使用"><a href="#1-1、模板的管理与使用" class="headerlink" title="1.1、模板的管理与使用"></a>1.1、模板的管理与使用</h2><p> 模板是zabbix的核心，因为模板集成了所有要监控的内容以及展示的图形等等，zabbix的安装部署完成后，自带了很多模板（网络设备模板、操作系统模板、常见应用软件模板），这些模板能够满足我们80%左右的应用需要，所以一般情况下不需要我们单独创建模板了。</p><p> 点击web上面的“配置”选项，然后选择“模板”，就可以看到很多默认的模板，而模板是有多个内置项目组成的，基本的内置项目有应用集、监控项、触发器、图形、聚合图形、自动发现、Web监测、链接的模板等这8个部分组成。在这8个部分中，监控项、触发器、图形、自动发现这4个部分是重点，也是难点。下面也会重点介绍着四个部分的具体实现过程。</p><p> 在zabbix自带的模板中，大部分是可以直接拿来使用的，这里我们不需要对每个模板都进行了解，只需要对常用的一些模板重点掌握就行了。</p><h2 id="1-2、创建应用集"><a href="#1-2、创建应用集" class="headerlink" title="1.2、创建应用集"></a>1.2、创建应用集</h2><p> 点击web上面的“配置”选项，然后选择“模板”，任意选择一个模块，或者新建一个模板，在模板下，可以看到有应用集选项。进入应用集后，可以看到已有的应用集，也可以创建新的应用集。</p><p> 应用集的创建很简单，它其实是一个模板中，针对一类监控项的集合，例如要对CPU的属性进行监控，那么可以创建一个针对CPU的应用集，这个应用集下可以创建针对CPU的多个监控项。</p><p> 应用集的出现主要是便于对监控项进行分类和管理，在有多个监控项，多种监控类型需要监控的情况下，就需要创建应用集。</p><p> 这里以“Template OS Linux”模板为例，进入此模板后，点开应用集，可以发现已经存在多个应用集，如下图所示：<br> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/0111d2e557eb3058897d82818f5524e7.png" alt></p><p> 如果有新的监控项需要加入，还可以点击右上角的“创建应用集”创建一个新的应用集。</p><h2 id="1-3、创建监控项"><a href="#1-3、创建监控项" class="headerlink" title="1.3、创建监控项"></a>1.3、创建监控项</h2><p> 点击web上面的“配置”选项，然后选择“模板”，任意选择一个模块，或者新建一个模板，在模板下，可以看到有监控项选项。</p><p> 监控项是zabbix监控的基础，默认的模板下都存在了很多监控项，这里以“Template OS Linux”模板为例，进入此模板后，点开监控项，可以发现已经存在多个监控项，如下图所示：<br> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/5e26977140f9cc6a61934a5a49393799.png" alt></p><p> 从图中可以看出，默认的监控项的内容，每个监控项都对应一个键值，就是具体要监控的内容，键值的写法是有统一规范的，zabbix针对不同监控项自带了很多键值，用户也可以自定义键值，此外，每个监控项还可以添加对应的触发器，也就是说这个监控项如果需要告警的话，就可以添加一个触发器，触发器专门用来触发告警。当然不是说每个监控项一定要有一个触发器，需要根据监控项的内容而定。</p><p> 点击右上角的“创建监控项”，开始创建一个自定义监控项，如下图所示：<br> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/9c4e08662d77ab46e9ce7e9523402178.png" alt></p><p> 在这个界面中，重点是红框标识出来的几个地方，首先，“名称”是创建的监控项的名称，自定义一个即可，但是要能表达其监控项的含义，第二个“类型”是设置此监控项通过什么方式进行监控，zabbix可选的监控类型有很多，常用的有zabbix客户端、zabbix客户端（主动式）、简单检查、SNMP客户端、zabbix采集器等类型，zabbix客户端监控也称为zabbix客户端（被动式）监控，就是通过在要监控的机器上安装zabbix agent，然后zabbix server主动去agent上抓取数据来实现的监控，这是最常用的监控类型。而zabbix客户端（主动式）监控也需要在被监控的机器上安装zabbix agent，只不过zabbix agent会主动汇报数据到zabbix server，这是与zabbix客户端（被动式）监控不同的地方。</p><p> 接着下来就是对“键值”的设置，这是个难点，键值可以使用zabbix默认自带的，也可以自定义自己的键值，zabbix自带了很多键值，可满足我们90%的需求，比如这里我们想对服务器上某个端口的状态做监控，就可以使用“net.tcp.service.perf[service,&lt;ip,&lt;port]”这个键值，此键值就是zabbix自带的，如果要查看更多zabbix自带键值，可以点击上图中“键值”选项后面的“选择”按钮，zabbix自带的键值就可以全部显示出来，如下图所示：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/017325111e7eef0598dac335aa7f45a0.png" alt></p><p> 可以看到，zabbix自带的键值根据监控类型的不同，也分了不同的监控键值种类，每个键值的含义也都做了很详细的描述，我们可以根据需要的监控内容，选择对应的键值即可。</p><p> “net.tcp.service.perf[service,&lt;ip,&lt;port]”这个键值用来检查TCP服务的性能，当服务down时返回0，否则，返回连接服务花费的秒数，此键值既可用在“zabbix客户端”类型的监控中，也可用在“简单监控”类型中。</p><p> 这个键值中，“net.tcp.service.perf”部分是键值的名称，后面中括号中的内容是键值的监控选项，每个选项含义如下：</p><ul><li><p>service：表示服务名，包含ssh、ntp、 ldap、 smtp、ftp、http、pop、 nntp、imap、 tcp、 <a href="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https、telnet" target="_blank" rel="noopener">http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https、telnet</a></p></li><li><p>ip：表示IP地址，默认是127.0.0.1，可留空。</p></li><li><p>port：表示端口，默认情况为每个服务对应的标准端口，例如ssh服务是22端口等。</p></li></ul><p> 比如要监控某个或某批服务器80端口的运行状态，可以设置如下键值：</p><p> net.tcp.service.perf[http,,80]</p><p> 此键值返回的信息类型是浮点型的，因此，在“信息类型”中要选择“浮点数”。在创建监控项中，还有一个“更新间隔”，这个是用来设置多久去更新一次监控数据，可根据对监控项灵敏度的需求来设定，默认是30秒更新一次。</p><p> 在创建监控项的最后，还有一个应用集的选择，也就是将这个监控项放到哪个监控分类中，可以选择已存在的应用集，也可以添加一个新的应用集。</p><p> 所有设置完成后，最后点击“添加”即可完成一个监控项的添加。</p><p>  监控项可以添加到一个已经存在的模板中，也可以在一个新创建的模板中添加监控项，还可以在一个主机下创建监控项，推荐的做法是新建一个模板，然后在此模板下添加需要的应用集、监控项，然后在后面添加主机的时候，将这个创建的模板链接到主机下即可。不推荐在主机下创建监控项的原因是，如果有多个主机，每个主机都有相同的监控内容，那么就需要在每个主机下都创建相同的监控项。</p><p> <strong>因此，构建zabbix监控，推荐的做法是，首先创建一个模板，然后在此模板下创建需要的监控项、触发器等内容，最后在添加主机时直接将此模板链接到每个主机下即可，这样，每个主机就自动链接上了模板中的所有监控项和触发器。</strong></p><h2 id="1-4、创建触发器"><a href="#1-4、创建触发器" class="headerlink" title="1.4、创建触发器"></a>1.4、创建触发器</h2><p> 触发器是用于故障告警的一个设置，将一个监控项添加触发器后，此监控项如果出现问题，就会出激活触发器，然后触发器将自动连接告警动作，最后触发告警。</p><p> 触发器同样也推荐在模板中进行创建，点击web上面的“配置”选项，然后选择“模板”，任意选择一个模块，或者新建一个模板，在模板下，可以看到有触发器选项。</p><p> 点击触发器，可以看到有默认存在的触发器，如下图所示：<br> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/8562363cde9a35211265bc5f38dc6e5d.png" alt></p><p> 从图中可以看到，有触发器的严重级别，触发器名称，触发器表达式等几个小选项，这里面难点是触发器表达式的编写，要学会写触发器表达式，首先需要了解表达式中常用的一些函数及其含义。</p><p> 在上图我们看到，有diff、avg、last、nodata等这些标识，这就是触发器表达式中的函数，下面就介绍下常用的一些触发器表达式函数及其含义。</p><p> 1、diff</p><p> 参数：不需要参数<br> 支持值类型：float,int,str,text,log<br> 作用：返回值为1表示最近的值与之前的值不同，即值发生变化，0表示无变化。</p><p> 2、last</p><p> 参数：#num<br> 支持值类型：float,int,str,text,log<br> 作用：获取最近的值，“#num”表示最近第N个值，请注意当前的#num和其他一些函数的#num的意思是不同的，例如：<br> last(0)或last()等价于last(#1)，表示获取最新的值，last(#3)表示最近第3个值（并不是最近的三个值），注意，last函数使用不同的参数将会得到不同的值，#2表示倒数第二新的数据。例入从老到最新值为1,2,3,4,5,6,7,8,9,10，last(#2)得到的值为9，last(#9)得到的值为2。<br> 另外，last函数必须包含参数。</p><p> 3、avg</p><p> 参数：秒或#num<br> 支持类型：float,int<br> 作用：返回一段时间的平均值<br> 例如，avg(5)表示最后5秒的平均值，avg(#5）表示最近5次得到值的平均值，avg(3600,86400）表示一天前的一个小时的平均值。<br> 如果仅有一个参数，表示指定时间的平均值，从现在开始算起，如果有第二个参数，表示漂移，从第二个参数前开始算时间，#n表示最近n次的值。</p><p> 4、change</p><p> 参数：无需参数<br> 支持类型：float,int,str,text,log<br> 作用：返回最近获得值与之前获得值的差值，返回字符串0表示相等，1表示不同。<br> 例如，change(0)n表示最近得到的值与上一个值的差值大于n，其中，0表示忽略参数。</p><p> 5、nodata</p><p> 参数：秒<br> 支持值类型：any<br> 作业：探测是否能接收到数据，当返回值为1表示指定的间隔(间隔不应小于30秒)没有接收到数据，0表示其正常接收数据。</p><p> 在了解了触发器表达式函数的含义之后，我们就可以创建和编写触发器表达式了，在触发器页面中，添加右上角的“创建触发器”即可进入触发器创建页面了，如下图所示：<br> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/f7023bfec63aa226adb88fadb4df55be.png" alt></p><p> 这个就是创建触发器的页面，首先输入触发器的名称，然后标记触发器的严重性，可以有6个等级选择，这里选择一般严重，接下来就是表达式的编写了，点击表达式项后面的“添加”按钮，即可开始构建表达式了，在构建表达式页面，首先要选择给哪个监控项添加触发器，在“条件”界面下点击后面的“选择”按钮，即可打开已经添加好的所有监控项，这里就选择刚刚添加好的“httpd server 80 status”这个监控项，接着，开始选择触发器表达式的条件，也就是上面介绍过的触发器表达式函数，点击“功能”下拉菜单，可以发现很多触发器表达式函数，那么如何选择函数呢，当然是根据这个监控项的含义和监控返回值。</p><p> “httpd server 80 status”这个监控项的返回值是浮点数，当服务故障时返回0，当监控的服务正常时返回连接服务所花费的秒数。因此，我们就将返回0作为一个判断的标准，也就是将返回值为0作为触发器表达式的条件，要获得监控项的最新返回值，那就是使用last（）函数，因此选择last()函数，接着，还有有个“间隔（秒）”选项，这个保持默认即可，重点是最后这个“结果”，这里是设置last()函数返回值是多少时才进行触发，根据前面对监控项的了解，last()函数返回0表示服务故障，因此这里填上0即可。</p><p> 这样，一个触发器表达式就创建完成了，完整的触发器表达式内容是：</p><p> {Template OS Linux:net.tcp.service.perf[http,,80].last()}=0</p><p> 可以看出，触发器表达式由4部分组成，第一部分是模板或主机的名称，第二部分是监控项对应的键值，第三部分是触发器表达式函数，最后一部分就是监控项的值。这个表达式所表示的含义是：http服务的80端口获取到的最新值如果等于0，那么这个表达式就成立，或者返回true。</p><p> 触发器创建完成后，两个监控的核心基本就完成了，后面还有创建“图形”、“聚合图形”等选项，这些都比较简单，就不过多介绍了。</p><h2 id="1-5、创建主机组和主机"><a href="#1-5、创建主机组和主机" class="headerlink" title="1.5、创建主机组和主机"></a>1.5、创建主机组和主机</h2><p> 点击web上面的“配置”选项，然后选择“主机群组”，即可到添加主机群组界面，默认情况下，已经有很多主机群组了，可以使用已经存在的主机群组，也可以创建新的主机群组，点击右上角“创建主机群组”可以创建一个新的群组，主机群组要先于主机创建，因为在主机创建界面中，已经没有创建群组的选项了。</p><p> 主机群组创建完成后，点击web上面的“配置”选项，然后选择“主机”，即可到添加主机界面，默认情况下，只有一个zabbix server主机，要添加主机，点击右上角“创建主机”按钮，即可进入如下页面：<br> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/2c9a224063ac5a57f94b94e11e0c8b3e.png" alt></p><p> 主机的创建很简单，需要重点关注红框标注的内容，首先，“主机名称”这个需要特别注意，可以填写主机名，也可以写IP地址，但是都要和zabbix agent主机配置文件zabbix_agent.conf里面的Hostname配置的内容一致才行。</p><p> “群组”就是指定主机在哪个主机群组里面，点击后面的“选择”即可查看目前的主机群组，选择一个即可，最后要添加的是“agent代理程序接口”，也就是zabbix server从哪个地址去获取zabbix agent的监控数据，这里填写的是zabbix agent的ip地址和端口号，此外，根据监控方式的不同，zabbix支持多种获取监控数据的方式，支持SNMP接口、JMX接口、IPMI接口等，可根据监控方式不同选择需要的接口即可。</p><p> 主机的设置项主要就这几个，最后还需要设置主机链接的模板，点击主机下面的“模板”标签，即可显示主机和模板的链接界面，如下图所示：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/1d5f34cd48d29352a701cac55ac9c4ae.png" alt></p><p> 点击“链接指示器”后面的“选择”按钮，即可显示上图的界面，这里可以选择要将哪些模板链接到此主机下，根据模板的用途，这里我们选择了“Template OS Linux”模板，当然也可以选择多个模板连接到同一个主机下，选择完成，点击“选择”即可回到下图所示界面：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/ad76108fcf9024f03bae8b4ab08115dd.png" alt></p><p> 这个界面的操作需要小心，在刚刚添加了模板后，需要先点击上面的那个“添加”按钮，这样刚才选择的模板才能生效，最后在点击最下面的“添加”按钮，172.16.213.232主机添加完成。</p><p> 最后，点击刚刚创建好的主机，即可进入主机编辑模式，可以看到，在主机下，已经有应用集、监控项、触发器、图形等选项和内容了，这就是链接模板后，自动导入到主机下面的，当然在主机编辑界面下也可以创建或修改应用集、监控项、触发器、图形等内容。</p><h2 id="1-6、触发器动作配置"><a href="#1-6、触发器动作配置" class="headerlink" title="1.6、触发器动作配置"></a>1.6、触发器动作配置</h2><p> 动作的配置也是zabbix的一个重点，点击web上面的“配置”选项，然后选择“动作”，即可到“动作”设置界面，动作的添加根据事件源的不同，可分为触发器动作、自动发现动作、自动注册动作等，这里首先介绍下触发器动作的配置方式。</p><p> 在此界面的右上角，先选择事件源为“触发器”，然后点击“创建动作”按钮，开始创建一个基于触发器的动作，如下图所示：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/93a0edade3f25dfe3b951da92afaab52.png" alt></p><p> 触发器动作配置，其实是设置监控项在故障时发出的信息，以及故障恢复后发送的信息设置，动作的“名称”可以随意设置，动作的状态设置为“已启用”，接着点开“操作”标签，此标签就是设置监控项在故障的时候发送信息的标题和消息内容以及一些发送的频率和接收人，如下图所示：<br> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/fac2517fabeabf34deaef862a8fdb488.png" alt></p><p> 在这个界面中，重点是设置发送消息的“默认操作步骤持续时间”、“默认标题”以及“消息内容”， “默认操作步骤持续时间”就是监控项发生故障后，持续发送故障信息的时间，这个时间范围为”60” 和 “604800” 之间，单位是秒。</p><p> “默认标题”以及“消息内容”是通过zabbix的内置宏变量实现的，例如{TRIGGER.STATUS}、{TRIGGER.SEVERITY}、{TRIGGER.NAME}、{HOST.NAME}等都是zabbix的内置宏变量，不需要加“$”就可以直接引用。这些宏变量会在发送信息的时候转换为具体的内容。</p><p> “默认标题”以及“消息内容”设置完成后，还需配置消息内容的发送频率和接收人，点击上图中“操作”步骤中的“新的”按钮，即可显示如下图界面：<br> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/f6ed85a2d5c25a3b846b9d331b0e4b99.png" alt></p><p> 在这个设置界面中，重点看操作细节部分，“步骤”是设置发送消息事件的次数，0表示无穷大，也就是持续一直发送，“步骤持续时间”是发送消息事件的间隔，默认值是60秒，输入0也表示默认值，“操作类型”有发送消息和远程命令两个选项，这里选择“发送消息”，“发送到用户群组”和“发送到用户”是指定将消息发送给指定的用户组和用户，一般选择将消息发送到用户群组即可，因为这样更方便，后期有新用户加入的话，直接将此用户加入用户群组中即可，省去了有新用户时每次都要修改消息发送设置的麻烦。最后，还有一个“仅送到”选项，这里是设置将消息通过什么媒介发送，默认有Email、Jabber、SMS三种方式，可以选择所有，也可以选择任意一个，这里选择Email，也就是通过邮件方式发送消息。</p><p> 综上所述，这个操作过程表达的意思是：事件的持续时间是1个小时（3600s），每隔1分钟（60s）产生一个消息事件，一共产生3个消息事件，产生消息事件时，发送给Zabbix administrators用户组中的所有用户，最后消息内容会使用Email媒介发送给用户。</p><p> 所有设置完成后，一定要点击上图左下角的“添加”按钮，这样刚才的设置才能保存生效。</p><p> 接着，再看创建动作中的“恢复操作”标签，如下图所示：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/72fcbda25b325f5abc5d75ad9a579789.png" alt></p><p> “恢复操作”跟“操作”标签类似，是用来设置监控项故障恢复后，发送消息事件的默认标题和消息内容，这两部分就是通过zabbix的内部宏变量实现的，重点看最下面的“操作”选项，点击“新的”按钮，即可打开操作的具体设置界面，如下图所示：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/783ea43d79107e875d4afb5049907fc4.png" alt></p><p> 这个界面是设置当监控项故障恢复后，向Zabbix administrators用户组中的所有用户通过Email介质发送消息。也就是故障恢复消息。</p><p> 最后，还是要点击上图左下角的“添加”按钮，这样刚才的设置才能保存生效。</p><h2 id="1-7、报警媒介类型配置"><a href="#1-7、报警媒介类型配置" class="headerlink" title="1.7、报警媒介类型配置"></a>1.7、报警媒介类型配置</h2><p> 报警媒介类型是用来设置监控告警的方式，也就是通过什么方式将告警信息发送出去，常用的告警媒介有很多，例如Email、Jabber、SMS等，这是三种默认方式，还可以扩展到微信告警、钉钉告警等方式，至于选择哪种告警方式，以爱好和习惯来定就行了。</p><p> 默认使用较多的是通过Email方式进行消息的发送告警，邮件告警方式的优势是简单、免费，加上现在有很多手机邮件客户端工具（网易邮件大师、QQ邮箱），通过简单的邮件告警设置，几乎可以做到实时收取告警信息。</p><p> 点击web上面的“管理”选项，然后选择“报警媒介类型”，即可到报警媒介设置界面，然后点击“Email”进入编辑页面，如下图所示：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/30/035d3811294d4895d13f87db1bca641f.png" alt></p><p> 这个界面是设置Email报警属性，“名称”可以是任意名字，这里输入“Email”，“类型”选择“电子邮件”，当然也可以选择“脚本”、“短信”等类型，“SMTP服务器”是设置邮件告警的发件服务器，我们这里使用网易163邮箱进行邮件告警，因此设置为“smtp.163.com”即可，接着是“SMTP”服务器端口，输入默认“25”，“SMTP HELO”可保持默认即可，“SMTP电邮”就是发件人的邮箱地址，输入一个网易163邮箱地址即可，安全连接选择默认的“无”即可，“认证”方式选择“用户名密码”认证，然后输入发件人邮箱登录的用户名和密码即可。</p><p> 所有设置完成，点击“添加”按钮完成邮件媒介告警的添加。到这里为止，zabbix中一个监控项的添加流程完成了。</p><p> 最后，我们再来梳理下一个监控项添加的流程，一般操作步骤是这样的：</p><p> 首先新创建一个模板，或者在默认模板基础上新增监控项、监控项添加完成，接着对此监控项添加一个触发器，如果有必要，还可以对此监控项添加图形，接着，开始添加主机组和主机，在主机中引用已经存在的或新增的模板，然后创建触发器动作，设置消息发送事件，最后，设置报警媒介，配置消息发送的介质，这就是一个完整的zabbix配置过程。</p><h2 id="1-8、监控状态查看"><a href="#1-8、监控状态查看" class="headerlink" title="1.8、监控状态查看"></a>1.8、监控状态查看</h2><p> 当一个监控项配置完成后，要如何看是否获取到数据了呢，点击web上面的“监测中”选项，然后选择“最新数据”，即可看到监控项是否获取到了最新数据，如下图所示：<br> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/30/bfcf5c8eb59a755f561073d080bd990d.png" alt></p><p> 在查看最新监控数据时，可以通过此界面提供的过滤器快速获取想查看的主机或者监控项的内容，这里我们选择“linux servers”主机组，“http server”应用集下所有监控项的数据，点击“应用”按钮，即可显示过滤出来的数据信息，重点看“最新数据”一列的内容，那个“0.0005”就是获取的最新数据，通过不断刷新此页面，可以看到最新数据的变化。如果你的监控项获取不到最新数据，那么显示的结果将会是浅灰色。要想查看一段时间的历史数据，还可以点击右边的那个“图形”链接，即可通过图形方式展示一段时间的数据趋势，如下图所示：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/30/23036519791968b63f125154a32c4c4f.png" alt></p><p> 这个就是监控项“httpd server 80 status”的趋势数据，此图形曲线是自动生成，无需设置，由于我们使用的是中文界面，在图形展示数据的时候，可能会在左下角有中文的地方出现乱码，这是默认编码非中文字体导致的，需要简单做如下处理，过程如下：</p><p> 1、进入 C:\Windows\Fonts选择其中任意一种中文字体例如 “黑体” (SIMHEI.TTF)<br> 2、将Windows下的中文字体文件上传到zabbix web目录下的fonts目录(本例是/usr/local/nginx/html/zabbix/fonts)<br> 3、修改zabbix的web前端的字体设置，将如下两行修改为：<br> 打开/usr/local/nginx/html/zabbix/include/defines.inc.php文件，找到如下两行：</p><p> define(‘ZBX_FONT_NAME’, ‘DejaVuSans’);<br> define(‘ZBX_GRAPH_FONT_NAME’, ‘DejaVuSans’);<br> 修改为<br> define(‘ZBX_FONT_NAME’,  ‘simhei’);<br> define(‘ZBX_GRAPH_FONT_NAME’,  ‘simhei’);</p><p> 其中simhei为字库名字，不用写ttf后缀。这样就行了，刷新一下浏览器，中文字体显示应该就正常了。</p><p> 好啦，zabbix的核心配置就这么多，很简单吧，掌握这个学习思路，那zabbix就简单多了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;一小时快速掌握zabbix配置的高效学习法&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;amp;url=https://blog.51cto.com/ixdba/234
      
    
    </summary>
    
      <category term="zabbix" scheme="http://zhangyu8.me/categories/zabbix/"/>
    
    
      <category term="zabbix" scheme="http://zhangyu8.me/tags/zabbix/"/>
    
  </entry>
  
  <entry>
    <title>学习Kubernetes和容器技术体系的最佳方法</title>
    <link href="http://zhangyu8.me/2019/02/14/%E5%AD%A6%E4%B9%A0Kubernetes%20%E5%92%8C%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E4%BD%93%E7%B3%BB%E7%9A%84%E6%9C%80%E4%BD%B3%E6%96%B9%E6%B3%95/"/>
    <id>http://zhangyu8.me/2019/02/14/学习Kubernetes 和容器技术体系的最佳方法/</id>
    <published>2019-02-13T16:00:00.000Z</published>
    <updated>2019-09-10T05:57:02.874Z</updated>
    
    <content type="html"><![CDATA[<p>学习Kubernetes和容器技术体系的最佳方法</p><p><a href="https://www.infoq.cn/article/3yijOyajjpq-Fg809NIj" target="_blank" rel="noopener">https://www.infoq.cn/article/3yijOyajjpq-Fg809NIj</a>)</p><p> 你好，我是 Kubernetes 社区资深成员与项目维护者张磊，也是极客时间 《深入剖析 Kubernetes 》的专栏作者。今天我来与你谈一谈，学习 Kubernetes 和容器技术体系的最佳方法，到底是什么。</p><p> 我认为，学习一门综合性的技术，不应该着急一头扎进去看源码。理清楚自己的定位，才是最重要的。</p><h2 id="定位一：纯粹的开发人员"><a href="#定位一：纯粹的开发人员" class="headerlink" title="定位一：纯粹的开发人员"></a>定位一：纯粹的开发人员</h2><p> 如果你是一位纯粹的开发人员，无论是前端、后端，还是应用、游戏的开发，你首先应该明白这样两个道理：</p><ul><li>Kubernetes 和容器技术主要解决的，是代码编写完成后的事情。这不单单是发布或者 CI/CD，而是指从你执行完 git commit &amp;&amp; git push 之后开始，都应该进入容器化的管理流程当中，当然包括后续的发布、运维、升级、回滚等所有阶段。</li><li><p>Kubernetes 体系的核心，是为开发者提供编写代码过程中的“微服务编程范式”。</p><p>比如，在你编写代码的时候，你应该清楚地知道：我该如何划分模块，就能更方便地利用到 Kubernetes 的 Pod 模型，来构建更加低耦合、高内聚的代码制品，让我后面的升级和重构工作更加容易。</p><p><a href="https://time.geekbang.org/column/article/40092" target="_blank" rel="noopener">拓展阅读「为什么我们需要 pod？」</a></p><p>再比如，当你的代码需要与一个外部资源进行交互的时候，你应该首先想到：我的这个外部资源，是不是可以作为一个 Kubernetes 的 CRD 放到 Etcd 里面。这样，我编写的代码，就可以遵循一个自定义 Controller 或者 Operator 的编程范式，通过声明式 API 的方式来执行业务逻辑。这样写出来的代码一定会更加简单、健壮、容易维护。</p><p>这样的例子其实非常多。<strong>作为开发人员，你最应该关注的，是 Kubernetes API 对象的细节、容器设计模式以及 Kubernetes API 编程范式。</strong><br><img src="https://static001.infoq.cn/resource/image/6d/e5/6df92fe2c06b8ccb27f57934aff244e5.png" alt><br>（Kubernetes 里的所有 API 对象）</p><p>你应该习惯于把你的服务想象成一个个容器，把整个应用想象成一个 Pod，学会把基于容器和 Kubernetes 的设计思想和架构方式，融入到自己平常的工程实践当中。你应该大量实践这些思想和设计模式，编写各种各样的 CRD 和 Controller，并想办法提高这些自己编写的自定义 Controller 项目的性能和服务能力。你应该尝试扮演公司或者组织中推广微服务和云原生体系倡导者，并热心地帮助团队成员共同学习 Kubernetes 的设计思想和 API，全力帮助 Istio 或者 Knative 这样的 Service Mesh 和 PaaS 平台在组织中落地。</p><p>这些，都是增强你在即将到来的云计算时代竞争力的有效手段。</p><p>当然，如果你对 Kubernetes API 以及编程范式还不熟悉，甚至对 Kubernetes API 的普适性还有所怀疑，那么你可以阅读一下《深入剖析 Kubernetes》的最后一篇文章<a href="https://time.geekbang.org/column/article/74278" target="_blank" rel="noopener">「Kubernetes：赢开发者赢天下」</a>。相信 Kubernetes API 成为云上编程标准的故事，一定会对你有所启迪。</p><h2 id="定位二：专注于服务器端的编程人员-运维工程师"><a href="#定位二：专注于服务器端的编程人员-运维工程师" class="headerlink" title="定位二：专注于服务器端的编程人员 / 运维工程师"></a>定位二：专注于服务器端的编程人员 / 运维工程师</h2><p>而如果<strong>你是一位专注于服务器端的编程人员，或者运维工程师</strong>，那么你更应该关注的是 Kubernetes 这个项目背后的实现原理，它所体现出来的 Borg 和 Omega 项目多年来大规模集群管理的经验教训。</p><p>比如，声明式 API 的设计与实现原理，Informer、Controller 这些机制的实现方式，为什么说 Etcd 最适合的场景是配置管理，集中式集群调度器的核心机制与常用策略都有哪些。</p><p>此外，Kubernetes 项目的各个可扩展性接口，也是你需要重点关注和理解的对象，比如 CNI 和网络插件的工作方式、CSI 和存储插件的设计、Kubernetes Volume 管理的完整流程，以及 CRI 的设计和各种 container runtime 的异同。</p><p>从这个角度来说，Kubernetes 项目就是当前云计算平台层开源项目的事实标准，熟悉它的思想、架构、实现细节甚至核心组件的源码，不仅是学习这项技术的必经之路，也是传统后端技术人员向云端转型的最佳途径。<br><img src="https://static001.infoq.cn/resource/image/7c/2a/7c43e584fb71bbcb48f47a0bb318cd2a.png" alt><br>（Kubernetes 通过存储插件管理容器持久化存储的原理）</p><p>你应该尝试扮演公司和组织中进行云原生和基础架构转型的关键角色，而不是充当传统和守旧那一方。你应该尝试用容器和 Kubernetes 化的思想来影响周边的每一位工程师。<strong>要记住，这个进程每前进一步，你的价值就放大一分。</strong></p><p><a href="https://time.geekbang.org/column/article/44245" target="_blank" rel="noopener">拓展阅读「编写自己的存储插件」</a></p><h2 id="定位三：学生、刚刚入行的初学者"><a href="#定位三：学生、刚刚入行的初学者" class="headerlink" title="定位三：学生、刚刚入行的初学者"></a>定位三：学生、刚刚入行的初学者</h2><p>而<strong>作为学生、刚刚入行的初学者</strong>，或者是对这个领域充满兴趣准备在这里作为一番的后端从业人员，我希望你对容器和 Kubernetes 技术体系的学习和实践，更要关注这个项目和平台背后更深层的基础和底盘部分，这包括：</p><p>1. 了解操作系统和硬件的实际工作方式，尤其是 CPU、存储和网络。</p><p>2. 充分理解操作系统的设计，甚至可以根据需要重新实现或者绕过某些部分，这是你后面进行系统性能优化的关键所在。</p><p>3. 理解“所有系统都是分布式系统”的道理。了解经典的分布式系统设计的思想，并从实际的工程实践中理解这些解决思路，这也是 Kubernetes 这个分布式项目构建的基础。</p><p>只有清楚了自己的定位，你才能够在 Kubernetes 这样一个大而全的技术体系面前做到“有所放矢，有的放矢”，才能够把容器和 Kubernetes 这项技术发展浪潮，与自己的技术路线和个人成长历程，真正地关联起来。<br><img src="https://static001.infoq.cn/resource/image/e7/6c/e7a7ad7a95e77d36014d63824a4aa76c.png" alt><br>（Kubernetes 项目核心功能的“全景图”）</p><p>一旦明确了定位，抓到了这其中的精髓和主线，那么接下来的学习过程对于你来说，其实就是“无招胜有招”，可以随心所欲地按照你实际的项目、所关心的领域逐步展开，而完全不必拘泥于某种特定的套路了。</p><p><a href="https://time.geekbang.org/column/article/23132" target="_blank" rel="noopener">拓展阅读：「从容器到容器云：谈谈 Kubernetes 的本质」</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;学习Kubernetes和容器技术体系的最佳方法&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.infoq.cn/article/3yijOyajjpq-Fg809NIj&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.in
      
    
    </summary>
    
      <category term="kubernetes" scheme="http://zhangyu8.me/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="http://zhangyu8.me/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>万兆网卡的Server与千兆网卡的client之间传输问题</title>
    <link href="http://zhangyu8.me/2019/02/13/%E4%B8%87%E5%85%86%E7%BD%91%E5%8D%A1%E7%9A%84Server%E4%B8%8E%E5%8D%83%E5%85%86%E7%BD%91%E5%8D%A1%E7%9A%84client%E4%B9%8B%E9%97%B4%E4%BC%A0%E8%BE%93%E9%97%AE%E9%A2%98/"/>
    <id>http://zhangyu8.me/2019/02/13/万兆网卡的Server与千兆网卡的client之间传输问题/</id>
    <published>2019-02-12T16:00:00.000Z</published>
    <updated>2019-02-13T08:51:29.093Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://linux.vbird.org/faq.php#20190211" target="_blank" rel="noopener">http://linux.vbird.org/faq.php#20190211</a></p><p>情况：</p><p> 就是10G –&gt; 1GB 的方向，网路频宽使用非常糟糕～一下子到500Mbps， 一下自降到10Mbps 的情况，导致效能非常恶劣<br>～但是1GB –&gt; 10G 就没有这个问题～同时， 10G –&gt; 10G 也同样没问题</p><p>分析：</p><p>1GB –&gt; 10G 的方向，因为 10G 原本就能够覆载 1G 以上的速度，所以当然没问题！<br> 那如果 10G –&gt; 1GB 时，如果没有特别的控制，那么 GB 的网卡当然会抵挡不住 10G 来的大量封包！</p><p>参考这两篇相当有趣的分析文章：</p><p>10G 网卡错误假设，与最佳设置方式：AIXpert Blog<br><a href="https://www.ibm.com/developerworks/community/blogs/aixpert/entry/10gbit_ethernet_bad_assumption_and_best_practice_part_137?lang=en" target="_blank" rel="noopener">https://www.ibm.com/developerworks/community/blogs/aixpert/entry/10gbit_ethernet_bad_assumption_and_best_practice_part_137?lang=en</a></p><p>NETApp vs VMWare Flow control dilemma：Ranjit Singh<br><a href="http://rjapproves.com/netapp-vs-vmware-flow-control-dilemma/" target="_blank" rel="noopener">http://rjapproves.com/netapp-vs-vmware-flow-control-dilemma/</a></p><p>结论：</p><p>这两篇的大意是说，10G switch 上面可能会安插不同速度的网卡，例如我们的环境中，10G 网卡与1G 网卡都安插在10G switch 上面， 虽然透过自动协商机制，10G 自己跑10G， 1G 自己跑1G，速度倒是正常没问题～但是，当1G 与10G 进行交流时， 如果switch 没有设定流量控制(flow control) 时，那么慢速的网卡可能会出现来不及接收高速网卡的情况～</p><p>因此上头第一篇建议， 全部的10G switch port 都启动flow control。不过，在鸟哥的测试中，没有flow control 确实速度会高出这么一点点(10G 效能可达到9.7Gbps 左右， 加上flow control 则大约到9.5Gbps 左右)，但是，在考虑到不同设备间的资料传输，</p><p>一般 switch，预设的情况就是关闭 flow control 的</p><p>鸟哥个人确实建议将所有的switch 的flow control 通通启用比较好！至少让你的速度不会差太多！</p><p>解决：</p><p> 直接改 switch 的 port settings ，将 flow control 勾选，解决！</p><p>涉及到不同速度的连结 (10G and 1G)，所以建议所有的装置 (交换机 and 网卡) 都要启用 flow control 才好！</p><p>10G switch 与 10G NIC 的 flow control 一定要启用！<br>    增加 10G 网卡的(queue)队列个数到硬体最大支援个数<br>    如果有固定的用户端 IP 环境，将 queue 的机制改成 multiq ，并且加上分流 (filter) 处置！</p><p>查看结果</p><p>命令：ethtool em4</p><p>如果是 Intel 的 10G 卡，只会出现『Advertised pause frame use: Symmetric』， 如果出现的是『Advertised pause frame use: No』，则代表网卡与 switch 之间不支持 flow control 喔！</p><p>而如果是 Broadcom 的网卡， 基本上则是出现『Link partner advertised pause frame use: Symmetric』，如果出现的是『Link partner advertised pause frame use: No』， 也是代表不支持的意思！</p><p>一般来说，如果你没有调整过 Linux NIC 的设定，预设的网卡 flow control 是启动的！因此，如果透过上述指令查看到结果为 No 时， 那就代表 10G switch 没有启动 flow control 啰！</p><p>#####################<br><a href="http://linux.vbird.org/linux_enterprise/switch_10g_tune.php" target="_blank" rel="noopener">http://linux.vbird.org/linux_enterprise/switch_10g_tune.php</a></p><p>#####################<br>iperf3 使用</p><p>透过scp 虽然可以直接使用到网路的频宽，不过，如果大量传输资料时，例如10G 的流量情况底下，被读取​​的档案速度可能会卡住在磁盘I/O 上面， 所以，透过scp来直接评判网路状态，似乎是怪怪的。那怎办？没关系，我们可以透过 iperf3 这个软件来处理即可！这个软件可以简单的在网路两端启动， 一边启动 server 模式，一边启动 client 模式来存取资料，就能够自动的判断网路频宽了！你 </p><pre><code>https://iperf.fr/iperf-download.php</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;http://linux.vbird.org/faq.php#20190211&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://linux.vbird.org/faq.php#20190211&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;情况：&lt;/
      
    
    </summary>
    
      <category term="linux" scheme="http://zhangyu8.me/categories/linux/"/>
    
    
      <category term="linux" scheme="http://zhangyu8.me/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>面试必备指南-你的系统如何支撑高并发</title>
    <link href="http://zhangyu8.me/2019/01/24/%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E6%8C%87%E5%8D%97-%E4%BD%A0%E7%9A%84%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E6%94%AF%E6%92%91%E9%AB%98%E5%B9%B6%E5%8F%91/"/>
    <id>http://zhangyu8.me/2019/01/24/面试必备指南-你的系统如何支撑高并发/</id>
    <published>2019-01-23T16:00:00.000Z</published>
    <updated>2019-09-10T05:57:29.822Z</updated>
    
    <content type="html"><![CDATA[<p> <em>作者：__中华石杉</em></p><p> _出处：转载自微信公众号：石杉的架构笔记（ID：shishan100）<br><a href="https://mp.weixin.qq.com/s/poRrtaqBJjgfj8ZOUxcD-A" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/poRrtaqBJjgfj8ZOUxcD-A</a>) </p><p> 一道面试题的背景引入</p><p> 大多数同学被问到这个问题压根儿没什么思路去回答，不知道从什么地方说起，其实本质就是没经历过一些真正有高并发系统的锤炼罢了。</p><p> 因为没有过相关的项目经历，所以就没法从真实的自身体会和经验中提炼出一套回答，然后系统的阐述出来自己负责过的系统如何支撑高并发的。</p><p> 所以，这篇文章就从这个角度切入来简单说说这个问题，用一个最简单的思路来回答，大致如何应对。</p><p> 当然这里首先说清楚一个前提：高并发系统各不相同。比如每秒百万并发的中间件系统、每日百亿请求的网关系统、瞬时每秒几十万请求的秒杀大促系统。</p><p> 他们在应对高并发的时候，因为系统各自特点的不同，所以应对架构都是不一样的。</p><p> 另外，比如电商平台中的订单系统、商品系统、库存系统，在高并发场景下的架构设计也是不同的，因为背后的业务场景什么的都不一样。</p><p> 所以，这篇文章主要是给大家提供一个回答这类问题的思路，不涉及任何复杂架构设计，让你不至于在面试中被问到这个问题时，跟面试官大眼瞪小眼。</p><p> 具体要真能在面试的时候回答好这个问题，建议各位参考一下本文思路，然后对你自己手头负责的系统多去思考一下，最好做一些相关的架构实践。</p><p> 先考虑一个最简单的系统架构</p><p> 假设刚刚开始你的系统就部署在一台机器上，背后就连接了一台数据库，数据库部署在一台服务器上。</p><p> 我们甚至可以再现实点，给个例子，你的系统部署的机器是 4 核 8G，数据库服务器是 16 核 32G。</p><p> 此时假设你的系统用户量总共就 10 万，用户量很少，日活用户按照不同系统的场景有区别，我们取一个较为客观的比例，10% 吧，每天活跃的用户就 1 万。</p><p> 按照 28 法则，每天高峰期算它 4 个小时，高峰期活跃的用户占比达到 80%，就是 8000 人活跃在 4 小时内。</p><p> 然后每个人对你的系统发起的请求，我们算他每天是 20 次吧。那么高峰期 8000 人发起的请求也才 16 万次，平均到 4 小时内的每秒（14400 秒），每秒也就 10 次请求。</p><p> 好吧！完全跟高并发搭不上边，对不对？</p><p> 然后系统层面每秒是 10 次请求，对数据库的调用每次请求都会有好几次数据库操作的，比如做做 crud 之类的。</p><p> 那么我们取一个一次请求对应 3 次数据库请求吧，那这样的话，数据库层每秒也就 30 次请求，对不对？</p><p> 按照这台数据库服务器的配置，支撑是绝对没问题的。上述描述的系统，用一张图表示，就是下面这样：</p><p> <img src="https://mmbiz.qpic.cn/mmbiz_jpg/MOwlO0INfQquiaCoVZfsYr7nAVKnvhdibibrQPBkHgpibw5hftAlMmePV0LrxzbR5sMnBjjFMCJicz9FG5bV6tdhFXw/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 系统集群化部署</p><p> 假设此时你的用户数开始快速增长，比如注册用户量增长了 50 倍，上升到了 500 万。</p><p> 此时日活用户是 50 万，高峰期对系统每秒请求是 500/s。然后对数据库的每秒请求数量是 1500/s，这个时候会怎么样呢？</p><p> 按照上述的机器配置来说，如果你的系统内处理的是较为复杂的一些业务逻辑，是那种重业务逻辑的系统的话，是比较耗费 CPU 的。</p><p> 此时，4 核 8G 的机器每秒请求达到 500/s 的时候，很可能你会发现你的机器 CPU 负载较高了。</p><p> 然后数据库层面，以上述的配置而言，其实基本上 1500/s 的高峰请求压力的话，还算可以接受。</p><p> 这个主要是要观察数据库所在机器的磁盘负载、网络负载、CPU 负载、内存负载，按照我们的线上经验而言，那个配置的数据库在 1500/s 请求压力下是没问题的。</p><p> 所以此时你需要做的一个事情，首先就是要支持你的系统集群化部署。</p><p> 你可以在前面挂一个负载均衡层，把请求均匀打到系统层面，让系统可以用多台机器集群化支撑更高的并发压力。</p><p> 比如说这里假设给系统增加部署一台机器，那么每台机器就只有 250/s 的请求了。</p><p> 这样一来，两台机器的 CPU 负载都会明显降低，这个初步的“高并发”不就先 cover 住了吗？</p><p> 要是连这个都不做，那单台机器负载越来越高的时候，极端情况下是可能出现机器上部署的系统无法有足够的资源响应请求了，然后出现请求卡死，甚至系统宕机之类的问题。</p><p> 所以，简单小结，第一步要做的：</p><ul><li><p>添加负载均衡层，将请求均匀打到系统层。</p></li><li><p>系统层采用集群化部署多台机器，扛住初步的并发压力。</p></li></ul><p> 此时的架构图变成下面的样子：</p><p> <img src="https://mmbiz.qpic.cn/mmbiz_jpg/MOwlO0INfQquiaCoVZfsYr7nAVKnvhdibibaLEFBVU3oJeZG0GhJFPss3mJWKZw5vDDIiclGjEVUV649avJc3RiaM5w/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 数据库分库分表 + 读写分离</p><p> 假设此时用户量继续增长，达到了 1000 万注册用户，然后每天日活用户是 100 万。</p><p> 那么此时对系统层面的请求量会达到每秒 1000/s，系统层面，你可以继续通过集群化的方式来扩容，反正前面的负载均衡层会均匀分散流量过去的。</p><p> 但是，这时数据库层面接受的请求量会达到 3000/s，这个就有点问题了。</p><p> 此时数据库层面的并发请求翻了一倍，你一定会发现线上的数据库负载越来越高。</p><p> 每次到了高峰期，磁盘 IO、网络 IO、内存消耗、CPU 负载的压力都会很高，大家很担心数据库服务器能否抗住。</p><p> 没错，一般来说，对那种普通配置的线上数据库，建议就是读写并发加起来，按照上述我们举例的那个配置，不要超过 3000/s。</p><p> 因为数据库压力过大，首先一个问题就是高峰期系统性能可能会降低，因为数据库负载过高对性能会有影响。</p><p> 另外一个，压力过大把你的数据库给搞挂了怎么办？</p><p> 所以此时你必须得对系统做分库分表 + 读写分离，也就是把一个库拆分为多个库，部署在多个数据库服务上，这是作为主库承载写入请求的。</p><p> 然后每个主库都挂载至少一个从库，由从库来承载读请求。</p><p> 此时假设对数据库层面的读写并发是 3000/s，其中写并发占到了 1000/s，读并发占到了 2000/s。</p><p> 那么一旦分库分表之后，采用两台数据库服务器上部署主库来支撑写请求，每台服务器承载的写并发就是 500/s。</p><p> 每台主库挂载一个服务器部署从库，那么 2 个从库每个从库支撑的读并发就是 1000/s。</p><p> 简单总结，并发量继续增长时，我们就需要 focus 在数据库层面：分库分表、读写分离。</p><p> 此时的架构图如下所示：</p><p> <img src="https://mmbiz.qpic.cn/mmbiz_jpg/MOwlO0INfQquiaCoVZfsYr7nAVKnvhdibibKREyUicsPjHMEoPxx7uqnLodbMlLrSnaMD6XhSyb3ycHsUK1goscbow/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 缓存集群引入</p><p> 接着就好办了，如果你的注册用户量越来越大，此时你可以不停的加机器，比如说系统层面不停加机器，就可以承载更高的并发请求。</p><p> 然后数据库层面如果写入并发越来越高，就扩容加数据库服务器，通过分库分表是可以支持扩容机器的，如果数据库层面的读并发越来越高，就扩容加更多的从库。</p><p> 但是这里有一个很大的问题：数据库其实本身不是用来承载高并发请求的，所以通常来说，数据库单机每秒承载的并发就在几千的数量级，而且数据库使用的机器都是比较高配置，比较昂贵的机器，成本很高。</p><p> 如果你就是简单的不停的加机器，其实是不对的。</p><p> 所以在高并发架构里通常都有缓存这个环节，缓存系统的设计就是为了承载高并发而生。</p><p> 所以单机承载的并发量都在每秒几万，甚至每秒数十万，对高并发的承载能力比数据库系统要高出一到两个数量级。</p><p> 所以你完全可以根据系统的业务特性，对那种写少读多的请求，引入缓存集群。</p><p> 具体来说，就是在写数据库的时候同时写一份数据到缓存集群里，然后用缓存集群来承载大部分的读请求。</p><p> 这样的话，通过缓存集群，就可以用更少的机器资源承载更高的并发。</p><p> 比如说上面那个图里，读请求目前是每秒 2000/s，两个从库各自抗了 1000/s 读请求，但是其中可能每秒 1800 次的读请求都是可以直接读缓存里的不怎么变化的数据的。</p><p> 那么此时你一旦引入缓存集群，就可以抗下来这 1800/s 读请求，落到数据库层面的读请求就 200/s。</p><p> 同样，给大家来一张架构图，一起来感受一下：</p><p> <img src="https://mmbiz.qpic.cn/mmbiz_jpg/MOwlO0INfQquiaCoVZfsYr7nAVKnvhdibibanyxPWZ80waHYJAiaZLgOpJSPMrAVhFrdwSlP939PnDrg51VYF747ew/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 按照上述架构，它的好处是什么呢？</p><p> 可能未来你的系统读请求每秒都几万次了，但是可能 80%~90% 都是通过缓存集群来读的，而缓存集群里的机器可能单机每秒都可以支撑几万读请求，所以耗费机器资源很少，可能就两三台机器就够了。</p><p> 你要是换成是数据库来试一下，可能就要不停的加从库到 10 台、20 台机器才能抗住每秒几万的读并发，那个成本是极高的。</p><p> 好了，我们再来简单小结，承载高并发需要考虑的第三个点：</p><ul><li><p>不要盲目进行数据库扩容，数据库服务器成本昂贵，且本身就不是用来承载高并发的。</p></li><li><p>针对写少读多的请求，引入缓存集群，用缓存集群抗住大量的读请求。</p></li></ul><p> 引入消息中间件集群</p><p> 接着再来看看数据库写这块的压力，其实是跟读类似的。</p><p> 假如说你所有写请求全部都落地数据库的主库层，当然是没问题的，但是写压力要是越来越大了呢？</p><p> 比如每秒要写几万条数据，此时难道也是不停的给主库加机器吗？</p><p> 可以当然也可以，但是同理，你耗费的机器资源是很大的，这个就是数据库系统的特点所决定的。</p><p> 相同的资源下，数据库系统太重太复杂，所以并发承载能力就在几千/s的量级，所以此时你需要引入别的一些技术。</p><p> 比如说消息中间件技术，也就是 MQ 集群，它可以非常好的做写请求异步化处理，实现削峰填谷的效果。</p><p> 假如说，你现在每秒是 1000/s 次写请求，其中比如 500 次请求是必须请求过来立马写入数据库中的，但是另外 500 次写请求是可以允许异步化等待个几十秒，甚至几分钟后才落入数据库内的。</p><p> 那么此时你完全可以引入消息中间件集群，把允许异步化的每秒 500 次请求写入 MQ，然后基于 MQ 做一个削峰填谷。</p><p> 比如就以平稳的 100/s 的速度消费出来，然后落入数据库中即可，此时就会大幅度降低数据库的写入压力。</p><p> 此时，架构图变成了下面这样：</p><p> <img src="https://mmbiz.qpic.cn/mmbiz_jpg/MOwlO0INfQquiaCoVZfsYr7nAVKnvhdibibUUbpBAIVD4EPS1ttpib8xDZZsx5m1wFBmSxUGAhchLdUibxmk90ibqwOA/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 大家看上面的架构图，首先消息中间件系统本身也是为高并发而生，所以通常单机都是支撑几万甚至十万级的并发请求的。  </p><p> 所以，它本身也跟缓存系统一样，可以用很少的资源支撑很高的并发请求，用它来支撑部分允许异步化的高并发写入是没问题的，比使用数据库直接支撑那部分高并发请求要减少很多的机器使用量。</p><p> 而且经过消息中间件的削峰填谷之后，比如就用稳定的 100/s 的速度写数据库，那么数据库层面接收的写请求压力，不就成了 500/s + 100/s  = 600/s 了么？</p><p> 大家看看，是不是发现减轻了数据库的压力？到目前为止，通过下面的手段，我们已经可以让系统架构尽可能用最小的机器资源抗住了最大的请求压力，减轻了数据库的负担：</p><ul><li><p>系统集群化。</p></li><li><p>数据库层面的分库分表+读写分离。</p></li><li><p>针对读多写少的请求，引入缓存集群。</p></li><li><p>针对高写入的压力，引入消息中间件集群。</p></li></ul><p> 初步来说，简单的一个高并发系统的阐述是说完了。但是，故事到这里还远远没有结束。</p><p> 现在能 Hold 住高并发面试题了吗？</p><p> 看完了这篇文章，你觉得自己能回答好面试里的高并发问题了吗？</p><p> 很遗憾，答案是不能。而且我觉得单单凭借几篇文章是绝对不可能真的让你完全回答好这个问题的，这里有很多原因在里面。</p><p> 首先，高并发这个话题本身是非常复杂的，远远不是一些文章可以说的清楚的，它的本质就在于，真实的支撑复杂业务场景的高并发系统架构其实是非常复杂的。</p><p> 比如说每秒百万并发的中间件系统、每日百亿请求的网关系统、瞬时每秒几十万请求的秒杀大促系统、支撑几亿用户的大规模高并发电商平台架构，等等。</p><p> 为了支撑高并发请求，在系统架构的设计时，会结合具体的业务场景和特点，设计出各种复杂的架构，这需要大量底层技术支撑，需要精妙的架构和机制设计的能力。</p><p> 最终，各种复杂系统呈现出来的架构复杂度会远远超出大部分没接触过的同学的想象。</p><p> 但是那么复杂的系统架构，通过一些文章是很难说的清楚里面的各种细节以及落地生产的过程的。</p><p> 其次，高并发这话题本身包含的内容也远远不止本文说的这么几个 topic：分库分表、缓存、消息。</p><p> 一个完整而复杂的高并发系统架构中，一定会包含：</p><ul><li><p>各种复杂的自研基础架构系统。</p></li><li><p>各种精妙的架构设计（比如热点缓存架构设计、多优先级高吞吐 MQ 架构设计、系统全链路并发性能优化设计，等等）。</p></li><li><p>还有各种复杂系统组合而成的高并发架构整体技术方案。</p></li><li><p>还有 NoSQL（Elasticsearch 等）/负载均衡/Web 服务器等相关技术。</p></li></ul><p> 所以大家切记要对技术保持敬畏之心，这些东西都很难通过一些文章来表述清楚。</p><p> 最后，真正在生产落地的时候，高并发场景下你的系统会出现大量的技术问题。</p><p> 比如说消息中间件吞吐量上不去需要优化、磁盘写压力过大性能太差、内存消耗过大容易撑爆、分库分表中间件不知道为什么丢了数据，等等吧。</p><p> 诸如此类的问题非常多，这些也不可能通过文章给全部说清楚。</p><p> 本文能带给你什么启发？</p><p> 其实本文的定位，就是对高并发这个面试 topic 做一个扫盲，因为我发现大部分来问我这个问题的同学，连本文阐述的最最基本的高并发架构演进思路可能都没理解。</p><p> 当然，也是因为毕竟没真的做过高并发系统，没相关经验，确实很难理解好这个问题。</p><p> 所以本文就是让很多没接触过的同学有一个初步的感知，这个高并发到底是怎么回事儿，到底对系统哪里有压力，要在系统架构里引入什么东西，才可以比较好的支撑住较高的并发压力。</p><p> 而且你可以顺着本文的思路继续思考下去，结合你自己熟悉和知道的一些技术继续思考。</p><p> 比如说，你熟悉 Elasticsearch 技术，那么你就可以思考，在高并发的架构之下，是不是可以通过分布式架构的 ES 技术支撑高并发的搜索？</p><p> 上面所说，权当抛砖引玉。大家自己平时一定要多思考，多画图，盘点自己手头系统的请求压力。</p><p> 计算一下分散到各个中间件层面的请求压力，到底应该如何利用最少的机器资源最好的支撑更高的并发请求。</p><p> 这才是一个好的高并发架构设计思路。</p><p> 如果起到这个效果，本文就成功了。剩下的，还是建议各位同学，对高并发这个话题，结合自己手头负责的系统多做思考。</p><p> 比如当前业务场景下，你的系统有多大的请求压力？如果请求压力增长 10 倍，你的架构如何支撑？如果请求压力增长 100 倍，你的架构如何支撑？如果请求压力增长 1000 倍，你的架构如何支撑？</p><p> 平时一定多给自己设置一些技术挑战，敦促自己去思考自己的系统，最好多做写架构上的演练、落地和实践，实际操作一下，才有更好的感知。</p><p> 然后在面试的时候，起码自己做过一定深度的思考，结合自己负责的系统做过一些实践，可以跟面试官有一个较为清晰和系统的阐述。</p><p> 虽然大部分同学可能没机会经历那种真正大规模超高并发的系统架构的设计，但是本文如果能让大家平时对自己的项目多一些思考。在面试的时候，有一些系统性的思路和阐述，那么也就达到本文的目的了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; &lt;em&gt;作者：__中华石杉&lt;/em&gt;&lt;/p&gt;
&lt;p&gt; _出处：转载自微信公众号：石杉的架构笔记（ID：shishan100）&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/poRrtaqBJjgfj8ZOUxcD-A&quot; target=&quot;_b
      
    
    </summary>
    
      <category term="架构" scheme="http://zhangyu8.me/categories/architecture/"/>
    
    
      <category term="架构" scheme="http://zhangyu8.me/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>记一次Kubernetes/Docker网络排障</title>
    <link href="http://zhangyu8.me/2019/01/23/%E8%AE%B0%E4%B8%80%E6%AC%A1KubernetesDocker%E7%BD%91%E7%BB%9C%E6%8E%92%E9%9A%9C/"/>
    <id>http://zhangyu8.me/2019/01/23/记一次KubernetesDocker网络排障/</id>
    <published>2019-01-22T16:00:00.000Z</published>
    <updated>2019-01-23T06:22:38.180Z</updated>
    
    <content type="html"><![CDATA[<p>酷 壳</p><p><a href="https://coolshell.cn/articles/18654.html" target="_blank" rel="noopener">https://coolshell.cn/articles/18654.html</a> </p><blockquote><h1 id="记一次Kubernetes-Docker网络排障"><a href="#记一次Kubernetes-Docker网络排障" class="headerlink" title="记一次Kubernetes/Docker网络排障"></a>记一次Kubernetes/Docker网络排障</h1></blockquote><blockquote><p>昨天周五晚上，临下班的时候，用户给我们报了一个比较怪异的Kubernetes集群下的网络不能正常访问的问题，让我们帮助查看一下，我们从下午5点半左右一直跟进到晚上十点左右，在远程不能访问用户机器只能远程遥控用户的情况找到了的问题。这个问题比较有意思，我个人觉得其中的调查用到的的命令以及排障的一些方法可以分享一下，所以写下了这篇文章。</p><h4 id="问题的症状"><a href="#问题的症状" class="headerlink" title="问题的症状"></a>问题的症状</h4><p>用户直接在微信里说，他们发现在Kuberbnetes下的某个pod被重启了几百次甚至上千次，于是开启调查这个pod，发现上面的服务时而能够访问，时而不能访问，也就是有一定概率不能访问，不知道是什么原因。而且并不是所有的pod出问题，而只是特定的一两个pod出了网络访问的问题。用户说这个pod运行着Java程序，为了排除是Java的问题，用户用 <code>docker exec -it</code> 命令直接到容器内启了一个 Python的 SimpleHttpServer来测试发现也是一样的问题。</p><p>我们大概知道用户的集群是这样的版本，Kuberbnetes 是1.7，网络用的是flannel的gw模式，Docker版本未知，操作系统CentOS 7.4，直接在物理机上跑docker，物理的配置很高，512GB内存，若干CPU核，上面运行着几百个Docker容器。</p><h4 id="问题的排查"><a href="#问题的排查" class="headerlink" title="问题的排查"></a>问题的排查</h4><h5 id="问题初查"><a href="#问题初查" class="headerlink" title="问题初查"></a>问题初查</h5><p>首先，我们排除了flannel的问题，因为整个集群的网络通信都正常，只有特定的某一两个pod有问题。而用 <code>telnet ip port</code> 的命令手工测试网络连接时有很大的概率出现 <code>connection refused</code> 错误，大约 1/4的概率，而3/4的情况下是可以正常连接的。</p><p>当时，我们让用户抓个包看看，然后，用户抓到了有问题的TCP连接是收到了 <code>SYN</code> 后，立即返回了 <code>RST, ACK</code></p><p><img src="https://coolshell.cn/wp-content/uploads/2018/12/tcpdump.png" alt></p><p>我问一下用户这两个IP所在的位置，知道了，<code>10.233.14.129</code> 是 <code>docker0</code>，<code>10.233.14.145</code> 是容器内的IP。所以，这基本上可以排除了所有和kubernets或是flannel的问题，这就是本地的Docker上的网络的问题。</p><p>对于这样被直接 Reset 的情况，在 <code>telnet</code> 上会显示 <code>connection refused</code> 的错误信息，对于我个人的经验，这种 <code>SYN</code>完直接返回 <code>RST, ACK</code>的情况只会有三种情况：</p><ol><li>TCP链接不能建立，不能建立连接的原因基本上是标识一条TCP链接的那五元组不能完成，绝大多数情况都是服务端没有相关的端口号。</li><li>TCP链接建错误，有可能是因为修改了一些TCP参数，尤其是那些默认是关闭的参数，因为这些参数会导致TCP协议不完整。</li><li>有防火墙iptables的设置，其中有 <code>REJECT</code> 规则。</li></ol><p>因为当时还在开车，在等红灯的时候，我感觉到有点像 NAT 的网络中服务端开启了 <code>tcp_tw_recycle</code> 和 <code>tcp_tw_reuse</code> 的症况（详细参看《<a href="https://coolshell.cn/articles/11564.html" target="_blank" rel="noopener">TCP的那些事（上）</a>》），所以，让用户查看了一上TCP参数，发现用户一个TCP的参数都没有改，全是默认的，于是我们排除了TCP参数的问题。</p><p>然后，我也不觉得容器内还会设置上iptables，而且如果有那就是100%的问题，不会时好时坏。所以，我怀疑容器内的端口号没有侦听上，但是马上又好了，这可能会是应用的问题。于是我让用户那边看一下，应用的日志，并用 <code>kublet describe</code>看一下运行的情况，并把宿主机的 iptables 看一下。</p><p>然而，我们发现并没有任何的问题。这时，<strong>我们失去了所有的调查线索，感觉不能继续下去了……</strong></p><h5 id="重新梳理"><a href="#重新梳理" class="headerlink" title="重新梳理"></a>重新梳理</h5><p>这个时候，回到家，大家吃完饭，和用户通了一个电话，把所有的细节再重新梳理了一遍，这个时候，用户提供了一个比较关键的信息—— “<strong>抓包这个事，在 <code>docker0</code> 上可以抓到，然而到了容器内抓不到容器返回 <code>RST, ACK</code></strong> ” ！然而，根据我的知识，我知道在 <code>docker0</code> 和容器内的 <code>veth</code> 网卡上，中间再也没有什么网络设备了（参看《<a href="https://coolshell.cn/articles/17029.html" target="_blank" rel="noopener">Docker基础技术：LINUX NAMESPACE（下）</a>》）!</p><p>于是这个事把我们逼到了最后一种情况 —— IP地址冲突了！</p><p>Linux下看IP地址冲突还不是一件比较简单事的，而在用户的生产环境下没有办法安装一些其它的命令，所以只能用已有的命令，这个时候，我们发现用户的机器上有 <code>arping</code> 于是我们用这个命令来检测有没有冲突的IP地址。使用了下面的命令：</p><p><code>$ arping -D -I docker0 -c 2 10.233.14.145</code></p><p><code>$</code> <code>echo</code> <code>$?</code></p><p>根据文档，<code>-D</code> 参数是检测IP地址冲突模式，如果这个命令的退状态是 <code>0</code> 那么就有冲突。结果返回了 <code>1</code> 。而且，我们用 <code>arping</code> IP的时候，没有发现不同的mac地址。 <strong>这个时候，似乎问题的线索又断了</strong>。</p><p>因为客户那边还在处理一些别的事情，所以，我们在时断时续的情况下工作，而还一些工作都需要用户完成，所以，进展有点缓慢，但是也给我们一些时间思考问题。</p><h5 id="柳暗花明"><a href="#柳暗花明" class="headerlink" title="柳暗花明"></a>柳暗花明</h5><p>现在我们知道，IP冲突的可能性是非常大的，但是我们找不出来是和谁的IP冲突了。而且，我们知道只要把这台机器重启一下，问题一定就解决掉了，但是我们觉得这并不是解决问题的方式，因为重启机器可以暂时的解决掉到这个问题，而如果我们不知道这个问题怎么发生的，那么未来这个问题还会再来。而重启线上机器这个成本太高了。</p><p>于是，我们的好奇心驱使我们继续调查。我让用户 <code>kubectl delete</code> 其中两个有问题的pod，因为本来就服务不断重启，所以，删掉也没有什么问题。删掉这两个pod后（一个是IP为 <code>10.233.14.145</code> 另一个是 <code>10.233.14.137</code>），我们发现，kubernetes在其它机器上重新启动了这两个服务的新的实例。然而，<strong>在问题机器上，这两个IP地址居然还可以ping得通</strong>。</p><p>好了，IP地址冲突的问题可以确认了。因为<code>10.233.14.xxx</code> 这个网段是 docker 的，所以，这个IP地址一定是在这台机器上。所以，我们想看看所有的 network namespace 下的 veth 网卡上的IP。</p><p>在这个事上，我们费了点时间，因为对相关的命令也 很熟悉，所以花了点时间Google，以及看相关的man。</p><ul><li>首先，我们到 <code>/var/run/netns</code>目录下查看系统的network namespace，发现什么也没有。</li><li>然后，我们到 <code>/var/run/docker/netns</code> 目录下查看Docker的namespace，发现有好些。</li><li>于是，我们用指定位置的方式查看Docker的network namespace里的IP地址</li></ul><p>这里要动用 <code>nsenter</code> 命令，这个命令可以进入到namespace里执行一些命令。比如</p></blockquote><blockquote><p><code>$ nsenter --net=`</code>/var/run/docker/netns/421bdb2accf1<code></code>ifconfig<code></code>-a`</p><p>上述的命令，到 <code>var/run/docker/netns/421bdb2accf1</code> 这个network namespace里执行了 <code>ifconfig -a</code> 命令。于是我们可以用下面 命令来遍历所有的network namespace。</p><p>1</p><p><code>$</code> <code>ls</code> <code>/var/run/docker/netns</code> <code>|</code> <code>xargs</code> <code>-I {} nsenter --net=`</code>/var/run/docker/netns/<code></code>{} ip addr`</p><p>然后，我们发现了比较诡异的事情。</p><ul><li><code>10.233.14.145</code> 我们查到了这个IP，说明，docker的namespace下还有这个IP。</li><li><code>10.233.14.137</code>，这个IP没有在docker的network namespace下查到。</li></ul><p>有namespace leaking？于是我上网查了一下，发现了一个docker的bug – 在docker remove/stop 一个容器的时候，没有清除相应的network namespace，这个问题被报告到了 <a href="https://github.com/moby/moby/issues/31597" target="_blank" rel="noopener">Issue#31597</a> 然后被fix在了 <a href="https://github.com/moby/moby/pull/31996" target="_blank" rel="noopener">PR#31996</a>，并Merge到了 Docker的 17.05版中。而用户的版本是 17.09，应该包含了这个fix。不应该是这个问题，感觉又走不下去了。</p><p>不过， <code>10.233.14.137</code> 这个IP可以ping得通，说明这个IP一定被绑在某个网卡，而且被隐藏到了某个network namespace下。</p><p>到这里，要查看所有network namespace，只有最后一条路了，那就是到 <code>/proc/</code> 目录下，把所有的pid下的 <code>/proc/&lt;pid&gt;/ns</code> 目录给穷举出来。好在这里有一个比较方便的命令可以干这个事 ： <code>lsns</code></p><p>于是我写下了如下的命令：</p><p>1</p><p><code>$ lsns -t net |</code> <code>awk</code> <code>‘{print $4}&#39; |</code> <code>xargs</code> <code>-t -I {} nsenter -t {}&amp;nbsp;-n ip addr |</code> <code>grep</code> <code>-C 4</code> <code>&quot;10.233.14.137&quot;</code></p><p>解释一下。</p><ul><li><code>lsns -t net</code> 列出所有开了network namespace的进程，其第4列是进程PID</li><li>把所有开过network namespace的进程PID拿出来，转给 <code>xargs</code> 命令</li><li>由 <code>xargs</code> 命令把这些PID 依次传给 <code>nsenter</code> 命令，<ul><li><code>xargs -t</code> 的意思是会把相关的执行命令打出来，这样我知道是那个PID。</li><li><code>xargs -I {}</code>  是声明一个占位符来替换相关的PID</li></ul></li></ul><p>最后，我们发现，虽然在 <code>/var/run/docker/netns</code> 下没有找到 <code>10.233.14.137</code> ，但是在 <code>lsns</code> 中找到了三个进程，他们都用了<code>10.233.14.137</code> 这个IP（冲突了这么多），<strong>而且他们的MAC地址全是一样的！</strong>（怪不得arping找不到）。通过<code>ps</code> 命令，可以查到这三个进程，有两个是java的，还有一个是<code>/pause</code> （这个应该是kubernetes的沙盒）。</p><p>我们继续乘胜追击，穷追猛打，用<code>pstree</code>命令把整个进程树打出来。发现上述的三个进程的父进程都在多个同样叫 <code>docker-contiane</code> 的进程下！</p><p><strong>这明显还是docker的，但是在<code>docker ps</code> 中却找不道相应的容器，什么鬼！快崩溃了……</strong></p><p>继续看进程树，发现，这些 <code>docker-containe</code> 的进程的父进程不在 <code>dockerd</code> 下面，而是在 <code>systemd</code> 这个超级父进程PID 1下，我靠！进而发现了一堆这样的野进程（这种野进程或是僵尸进程对系统是有害的，至少也是会让系统进入亚健康的状态，因为他们还在占着资源）。</p><p><code>docker-contiane</code> 应该是 <code>dockerd</code> 的子进程，被挂到了 <code>pid 1</code> 只有一个原因，那就是父进程“飞”掉了，只能找 pid 1 当养父。这说明，这台机器上出现了比较严重的 <code>dockerd</code> 进程退出的问题，而且是非常规的，因为 <code>systemd</code> 之所以要成为 pid 1，其就是要监管所有进程的子子孙孙，居然也没有管理好，说明是个非常规的问题。（注，关于 systemd，请参看《<a href="https://coolshell.cn/articles/17998.html" target="_blank" rel="noopener">Linux PID 1 和 Systemd</a> 》，关于父子进程的事，请参看《Unix高级环境编程》一书）</p><p>接下来就要看看 <code>systemd</code> 为 <code>dockerd</code> 记录的日志了…… （然而日志只有3天的了，这3天<code>dockerd</code>没有任何异常）</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>通过这个调查，可以总结一下，</p><p>1） 对于问题调查，需要比较扎实的基础知识，知道问题的成因和范围。</p><p>2）如果走不下去了，要重新梳理一下，回头仔细看一下一些蛛丝马迹，认真推敲每一个细节。</p><p>3） 各种诊断工具要比较熟悉，这会让你事半功倍。</p><p>4）系统维护和做清洁比较类似，需要经常看看系统中是否有一些僵尸进程或是一些垃圾东西，这些东西要及时清理掉。</p><p>最后，多说一下，很多人都说，<strong>Docker适合放在物理机内运行，这并不完全对，因为他们只考虑到了性能成本，没有考虑到运维成本，在这样512GB中启动几百个容器的玩法，其实并不好，因为这本质上是个大单体，因为你一旦要重启某些关键进程或是机器，你的影响面是巨大的</strong>。</p><p>———————— 更新 2018/12/10 —————————</p><h4 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h4><p>这两天在自己的环境下测试了一下，发现，只要是通过 <code>systemctl start/stop docker</code> 这样的命令来启停 Docker， 是可以把所有的进程和资源全部干掉的。这个是没有什么问题的。我唯一能重现用户问题的的操作就是直接 <code>kill -9 &lt;dockerd pid&gt;</code> 但是这个事用户应该不会干。而 Docker 如果有 crash 事件时，Systemd 是可以通过 <code>journalctl -u docker</code> 这样的命令查看相关的系统日志的。</p><p>于是，我找用户了解一下他们在Docker在启停时的问题，用户说，<strong>他们的执行 <code>systemctl stop docker</code> 这个命令的时候，发现这个命令不响应了，有可能就直接按了 <code>Ctrl +C</code> 了</strong>！</p><p>这个应该就是导致大量的 <code>docker-containe</code> 进程挂到 <code>PID 1</code> 下的原因了。前面说过，用户的一台物理机上运行着上百个容器，所以，那个进程树也是非常庞大的，我想，停服的时候，系统一定是要遍历所有的docker子进程来一个一个发退出信号的，这个过程可能会非常的长。导致操作员以为命令假死，而直接按了 <code>Ctrl + C</code> ，最后导致很多容器进程并没有终止……</p><h4 id="其它事宜"><a href="#其它事宜" class="headerlink" title="其它事宜"></a>其它事宜</h4><p>有同学问，为什么我在这个文章里写的是 <code>docker-containe</code> 而不是 <code>containd</code> 进程？这是因为被 <code>pstree</code> 给截断了，用 <code>ps</code> 命令可以看全，只是进程名的名字有一个 <code>docker-</code>的前缀。</p><p>下面是这两种不同安装包的进程树的差别（其中 <code>sleep</code> 是我用 <code>buybox</code> 镜像启动的）</p><p>CentOS 系统安装包</p></blockquote><blockquote><p><code>systemd───dockerd─┬─docker-contained─┬─3*[docker-contained-shim─┬─`</code>sleep<code></code>]`</p><p><code>│                 │                    └─9*[{docker-containe}]]</code></p><p><code>│                 ├─docker-contained-shim─┬─`</code>sleep`</p><p><code>│                 │                 └─10*[{docker-containe}]</code></p><p><code>│                 └─14*[{docker-contained-shim}]</code></p><p><code>└─17*[{dockerd}]</code></p><p>Docker 官方安装包</p></blockquote><blockquote><p><code>systemd───dockerd─┬─containerd─┬─3*[containerd-shim─┬─`</code>sleep<code></code>]`</p><p><code>│            │                 └─9*[{containerd-shim}]</code></p><p><code>│            ├─2*[containerd-shim─┬─`</code>sleep<code></code>]`</p><p><code>│            │                    └─9*[{containerd-shim}]]</code></p><p><code>│            └─11*[{containerd}]</code></p><p><code>└─10*[{dockerd}]</code></p><p>顺便说一下，自从 Docker 1.11版以后，Docker进程组模型就改成上面这个样子了.</p><ul><li><code>dockerd</code> 是 Docker Engine守护进程，直接面向操作用户。<code>dockerd</code> 启动时会启动 <code>containerd</code> 子进程，他们之前通过RPC进行通信。</li><li><code>containerd</code> 是<code>dockerd</code>和<code>runc</code>之间的一个中间交流组件。他与 <code>dockerd</code> 的解耦是为了让Docker变得更为的中立，而支持OCI 的标准 。</li><li><code>containerd-shim</code>  是用来真正运行的容器的，每启动一个容器都会起一个新的shim进程， 它主要通过指定的三个参数：容器id，boundle目录（containerd的对应某个容器生成的目录，一般位于：<code>/var/run/docker/libcontainerd/containerID</code>）， 和运行命令（默认为 <code>runc</code>）来创建一个容器。</li><li><code>docker-proxy</code> 你有可能还会在新版本的Docker中见到这个进程，这个进程是用户级的代理路由。只要你用 <code>ps -elf</code> 这样的命令把其命令行打出来，你就可以看到其就是做端口映射的。如果你不想要这个代理的话，你可以在 <code>dockerd</code> 启动命令行参数上加上：  <code>--userland-proxy=false</code> 这个参数。</li></ul><p>更多的细节，大家可以自行Google。这里推荐两篇文章：</p><ul><li><a href="https://hackernoon.com/docker-containerd-standalone-runtimes-heres-what-you-should-know-b834ef155426" target="_blank" rel="noopener">Docker, Containerd &amp; Standalone Runtimes — Here’s What You Should Know</a></li><li><a href="http://alexander.holbreich.org/docker-components-explained/" target="_blank" rel="noopener">Docker components explained</a></li></ul><p>（全文完）</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;酷 壳&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://coolshell.cn/articles/18654.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://coolshell.cn/articles/18654.html&lt;/a&gt;
      
    
    </summary>
    
      <category term="docker" scheme="http://zhangyu8.me/categories/docker/"/>
    
    
      <category term="docker" scheme="http://zhangyu8.me/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>网站访问速度慢</title>
    <link href="http://zhangyu8.me/2018/12/26/%E7%BD%91%E7%AB%99%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6%E6%85%A2/"/>
    <id>http://zhangyu8.me/2018/12/26/网站访问速度慢/</id>
    <published>2018-12-25T16:00:00.000Z</published>
    <updated>2018-12-26T03:15:41.472Z</updated>
    
    <content type="html"><![CDATA[<p>网站访问速度慢</p><p><a href="https://www.ssforce.cn/archives/362" target="_blank" rel="noopener">https://www.ssforce.cn/archives/362</a></p><p>a&gt; 访问者自己硬件设备（硬盘、CPU、网口、运营商带宽）资源不足</p><p>b&gt; 服务器硬件设备（硬盘、CPU、网口、运营商带宽）资源不足</p><p>c&gt; 图片未做优化太大、太多导致资源加载太多而慢</p><p>d&gt; 应用程序代码质量差导致性能消耗大、响应速度慢</p><p>e&gt; 页面设计不合理，导致资源整合过多（图片、css、js、前后端请求等）</p><p>f&gt; 其它DNS、安全入侵等问题</p><p>通常解决掉a b c可以帮我们解决80%的问题只需要花费20%的精力，d e f可以帮我们解决掉剩下的20%问题但需要花费80%的精力。</p><p><img src="https://raw.githubusercontent.com/mayou33/other/master/%E7%BD%91%E7%AB%99%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6%E6%85%A2.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;网站访问速度慢&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.ssforce.cn/archives/362&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.ssforce.cn/archives/362&lt;/a&gt;&lt;/p&gt;
&lt;
      
    
    </summary>
    
      <category term="web" scheme="http://zhangyu8.me/categories/web/"/>
    
    
      <category term="web" scheme="http://zhangyu8.me/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>谈运维转型期的感悟和分享</title>
    <link href="http://zhangyu8.me/2018/12/26/%E8%B0%88%E8%BF%90%E7%BB%B4%E8%BD%AC%E5%9E%8B%E6%9C%9F%E7%9A%84%E6%84%9F%E6%82%9F%E5%92%8C%E5%88%86%E4%BA%AB/"/>
    <id>http://zhangyu8.me/2018/12/26/谈运维转型期的感悟和分享/</id>
    <published>2018-12-25T16:00:00.000Z</published>
    <updated>2018-12-26T02:01:44.596Z</updated>
    
    <content type="html"><![CDATA[<p> <a href="https://www.ssforce.cn/archives/314" target="_blank" rel="noopener">https://www.ssforce.cn/archives/314</a></p><p>结论：要么成为20%的Ops，要么职能尽量更前置、更顶端</p><p>最初研发兼任运维职能，而后发现运维需要专业化分工，遂拆分独立工种。</p><p>拆分发展期间各方技术&amp;理念不断进化，但运维实质上一直处于被动，成为优质的“背锅侠”，其属性在独立工种阶段难以扭转，这是因为在这期间运维所起到的价值并非由运维自身所决定，而是由整个软件交付体系&amp;生命周期、产品市场运营体系、甚至公司层面所决定。</p><p>在一家公司业务快速扩张过程中，上业务、抢市场这无可厚非，但很可悲的是一方面位于技术体系末端的运维往往眼睛很难看到技术、业务的前头，另一方面，作为优质的“兜底”牺牲自身发展成全业务也是天生其“使命”。</p><p>但自然生存法则不会考虑这些，只认结果，所以大部分Ops如果不能成为20%（跑的更快前置于技术&amp;业务、提升价值&amp;定位），其实结果一定是悲剧的。</p><p>现在无论是谁发起DevOps还是OpsDev，那都是因为运维的职能无法从更宏观角度去满足技术、业务发展的要求，原本对称的社会的供需关系失衡而已，但不管你承认与否，这就是强迫被迫转型而已，只不过有了更好的由头。</p><p>退一步，无论跑的再快快到前置在技术&amp;业务前；积极运作转型，提升运营价值、拔高定位，又如何？况且在一个复杂的技术体系和业务迭代动态过程中，能否做到这点也是个疑问。</p><p>所以，如果作为运维你现在无法抉择，未来是选择技术继续攻坚还是选择管理。没关系，在职能选择上：尽量选择一个更前置、更顶端的职能。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; &lt;a href=&quot;https://www.ssforce.cn/archives/314&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.ssforce.cn/archives/314&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;结论：要么成为20%的O
      
    
    </summary>
    
      <category term="运维" scheme="http://zhangyu8.me/categories/ops/"/>
    
    
      <category term="运维" scheme="http://zhangyu8.me/tags/%E8%BF%90%E7%BB%B4/"/>
    
  </entry>
  
  <entry>
    <title>浅谈TLS1.3</title>
    <link href="http://zhangyu8.me/2018/12/26/%E6%B5%85%E8%B0%88TLS1.3/"/>
    <id>http://zhangyu8.me/2018/12/26/浅谈TLS1.3/</id>
    <published>2018-12-25T16:00:00.000Z</published>
    <updated>2018-12-26T03:09:34.530Z</updated>
    
    <content type="html"><![CDATA[<p> 小米运维<br><a href="https://mp.weixin.qq.com/s/uNKrLV4taafS0AluSBUznw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/uNKrLV4taafS0AluSBUznw</a> </p><p>  <strong>TLS简介</strong></p><p> 按照维基百科的定义，TLS 是一种用于为计算机网络通信提供安全性的密码协议，其前身安全套接层（SSL）想必很多人都听说过。TLS 被广泛应用于基于 IP 的网络协议，如 HTTP、SMTP、FTP 等。最近几年内，Let’s Encrypt 提供的免费证书服务、浏览器只对 HTTPS 站点启用 HTTP/2 和把未使用 HTTPS 而要求输入密码的网站标记为不安全等因素强力推动了 HTTPS 的部署，国际上 HTTPS 的部署率现已超过 50%。在各种因素的推动下，国内站点和应用也在大力推广 TLS 等密码协议的使用。</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/Re4KW51oYRpfwee8BkZnflunRvfWAycY1hhnHltT8Z0lw235avib3baOZZicUvfhoZoXFFY2uYL6NVJwUzPcHNjw/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> Figure 1: 数据来自谷歌 Transparency Report，2018年9月14日获取</p><p> <strong> TLS 1.3的优势</strong></p><p> <strong>安全保护</strong></p><p> TLS 1.3 移除了很多过时的密码学原型和功能（例如压缩、重协商），强制要求完美前向安全。TLS 1.2 支持了很多加密算法（包括 3DES、静态 DH 等），这导致了 FREAK、Logjam、Sweet32 等攻击的出现。TLS 1.3 缩紧了对加密原型的限制，避免了因服务器启用不安全的算法导致协议的安全性受到影响。在这方面的简化也使得运维和开发者配置 TLS 变得更容易，不再容易误用不安全的配置。</p><p> TLS 1.3 之前，整个握手环节都是没有加密保护的，这泄漏了很多信息，包括客户端和服务器的身份。TLS 1.3 对握手的绝大部分信息进行了加密，这保护了用户隐私，也在一定程度上防止了协议僵化问题。</p><p> <strong>性能提升</strong></p><p> 虽然电脑越变越快，但在互联网上传输数据耗费的时间依然受限于光速，所以两个节点间来回传输一次的时间（RTT）成为了限制协议性能的因素之一。TLS 1.3 只需要一个 RTT 就能完成握手，相比 TLS 1.2 省去了一个 RTT。并且 TLS 1.3 支持 “0-RTT” 模式，在该模式下客户端可以在握手的同时发送数据，极大地加快了页面的加载速度。TLS 1.3 还增加了 ChaCha20/Poly1305 支持，在不支持 AES 硬件指令的老设备上能提升加、解密性能。</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/Re4KW51oYRpfwee8BkZnflunRvfWAycYjx1icDTU5eT9xhB8KvUK0GjibmHoFqyLvfGZfsearE7H5OtC94wV1CXQ/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/Re4KW51oYRpfwee8BkZnflunRvfWAycYE5oLTsPBS1fefianWRPAatYaBDgY8088AO9XyHiamwtvVsQSS6KYlECA/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> <strong> TLS 1.3的部署</strong></p><p> Tengine 2.2.2 / nginx 1.13.0 提供了 TLS 1.3 支持，和 OpenSSL 1.1.1 配合即可将网站升级到 TLS 1.3。在配置文件里将 TLSv1.3 加到 ssl_protocols 中就可以启用 TLS 1.3 支持了。Qualys 的 SSL 服务器测试[1]是很方便的 TLS 配置测试工具，可以很方便地检测公网站点的 TLS 配置及其安全性。</p><p> <strong>协议僵化问题</strong></p><p> 当一个互联网协议长时间不发生变化时，基于该协议开发的设备就可能无视其预留的变通手段而对其特性作出超出标准的假设，这就是协议僵化现象。在 TLS 1.3 的完善过程中，新的协议因协议僵化问题而不得不模拟老协议的一些行为，这大大拖慢了 TLS 1.3 标准化的进度。尽管在制定 TLS 1.3 标准时工作组针对很多实际测试时出现的问题进行了处理，但我们部署到线上环境还是需要注意可能出现的兼容性问题。</p><p> <strong> TLS 1.3发展时间线</strong></p><ul><li><p>2017年4月25日，nginx 1.13.0 发布，增加了 TLS 1.3 支持。</p></li><li><p>2018年3月21日，IESG 批准了 TLS 1.3 草案。</p></li><li><p>2018年4月17日，Chrome 66 默认开启了对 TLS 1.3 草案的支持。</p></li><li><p>2018年5月9日，Firefox 60 默认开启了对 TLS 1.3 草案的支持。</p></li><li><p>2018年8月10日，IETF 发布了 TLS 1.3 标准。</p></li><li><p>2018年9月11日，OpenSSL 1.1.1 (LTS) 版本发布，提供 TLS 1.3 支持。TLS 1.3 超过 TLS 1.0 成为 Cloudflare 上使用率排名第二的 TLS 版本。</p></li><li><p>2018年10月16日，Chrome 70 支持 TLS 1.3 正式标准。</p></li><li><p>2018年10月23日，Firefox 63 支持 TLS 1.3 正式标准。</p></li></ul><p>  <strong>参考资料</strong></p><p> [1]<a href="https://www.ssllabs.com/ssltest/" target="_blank" rel="noopener">https://www.ssllabs.com/ssltest/</a></p><p> [2]<a href="https://tools.ietf.org/html/rfc8446" target="_blank" rel="noopener">https://tools.ietf.org/html/rfc8446</a></p><p> [3]<a href="https://en.wikipedia.org/wiki/Transport\_Layer\_Security" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Transport\_Layer\_Security</a></p><p> [4]<a href="https://blog.mozilla.org/security/2018/08/13/tls-1-3-published-in-firefox-today/" target="_blank" rel="noopener">https://blog.mozilla.org/security/2018/08/13/tls-1-3-published-in-firefox-today/</a></p><p> [5]<a href="https://ietf.org/blog/tls13/" target="_blank" rel="noopener">https://ietf.org/blog/tls13/</a></p><p> [6]<a href="https://kinsta.com/blog/tls-1-3/" target="_blank" rel="noopener">https://kinsta.com/blog/tls-1-3/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; 小米运维&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/uNKrLV4taafS0AluSBUznw&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s/uNKrLV4taa
      
    
    </summary>
    
      <category term="web" scheme="http://zhangyu8.me/categories/web/"/>
    
    
      <category term="web" scheme="http://zhangyu8.me/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>被抛弃的tcp_recycle</title>
    <link href="http://zhangyu8.me/2018/12/05/%E8%A2%AB%E6%8A%9B%E5%BC%83%E7%9A%84tcp_recycle/"/>
    <id>http://zhangyu8.me/2018/12/05/被抛弃的tcp_recycle/</id>
    <published>2018-12-04T16:00:00.000Z</published>
    <updated>2018-12-05T06:15:29.263Z</updated>
    
    <content type="html"><![CDATA[<p>原创： SRE 小米运维<br><a href="https://mp.weixin.qq.com/s/uwykopNnkcRL5JXTVufyBw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/uwykopNnkcRL5JXTVufyBw</a></p><p> 1</p><p> 背景</p><p> 最近准备搭建一个新的kubernetes集群，将内核从3.18更新到了4.14版本，并执行一些常规的优化操作。在执行sysctl -p操作时突然报错如下：</p><pre><code>sysctl: cannot stat /proc/sys/net/ipv4/tcp_tw_recycle: No such file or directory</code></pre><p> 2</p><p> 问题原因</p><p> Linux 从4.12内核版本开始移除了 tcp_tw_recycle 配置。</p><p> 参考：[1]_tcp:remove tcp_tw_recycle 4396e460_</p><p> 移除sysctl.conf中关于net.ipv4.tcp_tw_recycle的配置内容，再次尝试sysctl -p就不再提示报错了。</p><p> 3</p><p> 深入解析</p><p> tcp_tw_recycle通常会和tcp_tw_reuse参数一起使用，用于解决服务器TIME_WAIT状态连接过多的问题。</p><p> 3.1</p><p> <strong>TIME_WAIT状态出现原因与查看</strong></p><p> 让我们回顾一下四次挥手的流程：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_jpg/Re4KW51oYRqZFnOjFRDiaOHz3WztCtNDncIialDaHtqKfRIy8I2KibjuZMwT6SKr13T2QIGpbCQ78rIK9LaooJiagw/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> TIME_WAIT永远是出现在主动发送断开连接请求的一方(下文中我们称之为客户)，划重点：这一点面试的时候经常会被问到。  </p><p> 客户在收到服务器端发送的FIN(表示”我们也要断开连接了”)后发送ACK报文，并且进入TIME_WAIT状态，等待2MSL(MaximumSegmentLifetime 最大报文生存时间)。对于Linux，字段为TCP_TIMEWAIT_LEN硬编码为30秒，对于windows为2分钟(可自行调整)。</p><p> 为什么客户端不直接进入CLOSED状态，而是要在TIME_WAIT等待那么久呢，基于如下考虑：</p><p> 1.确保远程端处于关闭状态。也就是说需要确保客户端发出的最后一个ACK报文能够到达服务器。由于网络不可靠，有可能最后一个ACK报文丢失，如果服务器没有收到客户端的ACK，则会重新发送FIN报文，客户端就可以在2MSL时间段内收到这个这个重发的报文，并且重发ACK报文。但如果客户端跳过TIME_WAIT阶段进入了CLOSED，服务端始终无法得到响应，就会处于LAST-ACK状态，此时假如客户端发起了一个新连接，则会以失败告终。</p><p> 异常流程如下：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/Re4KW51oYRqZFnOjFRDiaOHz3WztCtNDnektVT22fqXfgIXK9H6ZJpyC3gHGG2RTd98JLefRCicRX4Ucb5n8YAFQ/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 2.防止上一次连接中的包，迷路后重新出现，影响新连接(经过2MSL,上一次连接中所有的重复包都会消失)，这一点和为啥要执行三次握手而不是两次的原因是一样的。</p><p> 异常流程如下：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/Re4KW51oYRqZFnOjFRDiaOHz3WztCtNDn06zNjGmAGkn2S1HS3iabJVy8gZGu6gMogsh83KnN1vjmWwvF7rEI0oA/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 查看方式有两种：</p><p> （1）ss -tan state time-wait|wc -l</p><p> （2）netstat -n | awk ‘/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}’</p><p> 3.2</p><p> <strong>TIME_WAIT的危害</strong></p><p> 对于一个处理大量连接的处理器TIME_WAIT是有危害的，表现如下：  </p><p> 1.占用连接资源</p><p> TIME_WAIT占用的1分钟时间内，相同四元组(源地址，源端口，目标地址，目标端口)的连接无法创建，通常一个ip可以开启的端口为net.ipv4.ip_local_port_range指定的32768-61000，如果TIME_WAIT状态过多，会导致无法创建新连接。</p><p> 2.占用内存资源</p><p> 这个占用资源并不是很多，可以不用担心。</p><p> 3.3</p><p> <strong>TIME_WAIT的解决</strong></p><p> 可以考虑如下方式：  </p><p> 1.修改为长连接，代价较大，长连接对服务器性能有影响。</p><p> 2.增加可用端口范围(修改net.ipv4.ip_local_port_range); 增加服务端口，比如采用80，81等多个端口提供服务; 增加客户端ip(适用于负载均衡，比如nginx，采用多个ip连接后端服务器); 增加服务端ip; 这些方式治标不治本，只能缓解问题。</p><p> 3.将net.ipv4.tcp_max_tw_buckets设置为很小的值(默认是18000). 当TIME_WAIT连接数量达到给定的值时，所有的TIME_WAIT连接会被立刻清除，并打印警告信息。但这种粗暴的清理掉所有的连接，意味着有些连接并没有成功等待2MSL，就会造成通讯异常。</p><p> 4.修改TCP_TIMEWAIT_LEN值，减少等待时间，但这个需要修改内核并重新编译。</p><p> 5.打开tcp_tw_recycle和tcp_timestamps选项。</p><p> 6.打开tcp_tw_reuse和tcp_timestamps选项。</p><p> 3.4</p><p> <strong>net.ipv4.tcp_tw_{reuse,recycle}</strong></p><p> 需要明确两个点：  </p><p> 解决方式已经给出，那我们需要了解一下net.ipv4.tcp_tw_reuse和net.ipv4.tcp_tw_recycle有啥区别</p><p> 1.两个选项都需要打开对TCP时间戳的支持，即net.ipv4.tcp_timestamps=1(默认即为1)。</p><p> RFC 1323中实现了TCP拓展规范，以便保证网络繁忙的情况下的高可用。并定义了一个新的TCP选项-两个四字节的timestamp字段，第一个是TCP发送方的当前时钟时间戳，第二个是从远程主机接收到的最新时间戳。</p><p> 2.两个选项默认都是关闭状态，即等于0。</p><p> 3.4.1 - net.ipv4.tcp_tw_reuse：更安全的设置</p><p> 将处于TIME_WAIT状态的socket用于新的TCP连接，影响连出的连接。</p><p> [2]<em>kernel sysctl 官方指南</em>中是这么写的：</p><p> Allow to reuse TIME-WAIT sockets for new connections when it is safe from protocol viewpoint. Default value is 0.</p><p> It should not be changed without advice/request of technical experts.</p><p> 协议安全主要指的是两点：</p><p> 1.只适用于客户端(连接发起方)</p><p> <strong>net/ipv4/inet_hashtables.c</strong></p><pre><code>static int __inet_check_established(struct inet_timewait_death_row *death_row,                    struct sock *sk, __u16 lport,                    struct inet_timewait_sock **twp){    /* ……省略…… */    sk_nulls_for_each(sk2, node, &amp;head-chain) {            if (sk2-sk_hash != hash)                        continue;                                    if (likely(INET_MATCH(sk2, net, acookie,                    saddr, daddr, ports, dif))) {                        if (sk2-sk_state == TCP_TIME_WAIT) {                            tw = inet_twsk(sk2);                            if (twsk_unique(sk, sk2, twp))                                break;            }            goto not_unique;        }    }    /* ……省略…… */}</code></pre><p> 2.TIME_WAIT创建时间超过1秒才可以被复用</p><p> <strong>net/ipv4/tcp_ipv4.c</strong></p><pre><code>int tcp_twsk_unique(struct sock *sk, struct sock *sktw, void *twp){    /* ……省略…… */    if (tcptw-tw_ts_recent_stamp &amp;&amp;        (!twp || (sock_net(sk)-ipv4.sysctl_tcp_tw_reuse &amp;&amp;         get_seconds() - tcptw-tw_ts_recent_stamp  1))) {         /* ……省略…… */         return 1;    }    return 0;}</code></pre><p> 满足以上两个条件才会被认为是”safe from protocol viewpoint”的状况。启用net.ipv4.tcp_tw_reuse后，如果新的时间戳比之前存储的时间戳更大，那么Linux将会从TIME-WAIT状态的存活连接中选取一个，重新分配给新的连接出去的的TCP连接，这种情况下，TIME-WAIT的连接相当于只需要1秒就可以被复用了。</p><p> 重新回顾为什么要引入TIME-WAIT：</p><p> 第一个作用就是避免新连接接收到重复的数据包，由于使用了时间戳，重复的数据包会因为时间戳过期被丢弃。</p><p> 第二个作用是确保远端不是处于LAST-ACK状态，如果ACK包丢失，远端没有成功获取到最后一个ACK包，则会重发FIN包。直到：</p><p> 1.放弃(连接断开)</p><p> 2.收到ACK包</p><p> 3.收到RST包</p><p> 如果FIN包被及时接收到，并且本地端仍然是TIME-WAIT状态，那ACK包会被发送，此时就是正常的四次挥手流程。</p><p> 如果TIME-WAIT的条目已经被新连接所复用，则新连接的SYN包会被忽略掉，并且会收到FIN包的重传，本地会回复一个RST包(因为此时本地连接为SYN-SENT状态)，这会让远程端跳出LAST-ACK状态，最初的SYN包也会在1秒后重新发送，然后完成连接的建立，整个过程不会中断，只是有轻微的延迟。流程如下:</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/Re4KW51oYRqZFnOjFRDiaOHz3WztCtNDnXqUciblrAiaWZeVicfHRNNGJ5cW2YnP9GFxH1vFPjl0PUu6YhJcG2mpmg/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt></p><p> 需要注意，连接被复用后，TWrecycled计数器会增加(/proc/net/netstat中TWrecycled值)</p><p> 3.4.2 - net.ipv4.tcp_tw_recycle：更激进的设置</p><p> 启用TIME_WAIT 状态的sockets的快速回收，影响所有连入和连出的连接</p><p> [3]_kernel sysctl 官方指南 _是这么写的</p><p> Enable fast recycling TIME-WAIT sockets. Default value is 0. It should not be changed without advice/request of technical experts.</p><p> 这次表述的更加模糊，继续翻看源码：</p><p> <strong>net/ipv4/tcp_input.c</strong></p><p> int tcp_conn_request(struct request_sock_ops <em>rsk_ops,<br>             const struct tcp_request_sock_ops </em>af_ops,<br>             struct sock *sk, struct sk_buff *skb)<br> {<br>   /* ……省略…… <em>/  if (!want_cookie &amp;&amp; !isn) { /\</em> ……省略…… */<br>  if (net-ipv4.tcp_death_row.sysctl_tw_recycle) {<br>          bool strict;</p><p> dst = af_ops-route_req(sk, &amp;fl, req, &amp;strict); if (dst &amp;&amp; strict &amp;&amp;<br>               !tcp_peer_is_proven(req, dst, true,<br>                       tmp_opt.saw_tstamp)) {<br>               NET_INC_STATS(sock_net(sk), LINUX_MIB_PAWSPASSIVEREJECTED);<br>               goto drop_and_release;<br>        }<br>      }<br>  /* ……省略…… <em>/ isn = af_ops-init_seq(skb, &amp;tcp_rsk(req)-ts_off);<br>    }/\</em> ……省略…… */  </p><p> drop_and_release:<br>             dst_release(dst);<br>        drop_and_free:<br>             reqsk_free(req);<br>        drop:<br>             tcp_listendrop(sk);<br>             return  0;<br> }</p><p> 简单来说就是，Linux会丢弃所有来自远端的timestramp时间戳小于上次记录的时间戳(由同一个远端发送的)的任何数据包。也就是说要使用该选项，则必须保证数据包的时间戳是单调递增的。</p><p> 问题在于，此处的时间戳并不是我们通常意义上面的绝对时间，而是一个相对时间。很多情况下，我们是没法保证时间戳单调递增的，比如使用了nat，lvs等情况。</p><p> 而这也是很多优化文章中并没有提及的一点，大部分文章都是简单的推荐将net.ipv4.tcp_tw_recycle设置为1，却忽略了该选项的局限性，最终造成严重的后果(比如我们之前就遇到过部署在nat后端的业务网站有的用户访问没有问题，但有的用户就是打不开网页)。</p><p> 3.5</p><p> <strong>被抛弃的tcp_tw_recycle</strong></p><p> 如果说之前内核中tcp_tw_recycle仅仅不适用于nat和lvs环境，那么从4.10内核开始，官方修改了时间戳的生成机制。</p><p> 参考：[4] <em>tcp: randomize tcp timestamp offsets for each connection 95a22ca</em></p><p> 在这种情况下，无论任何时候，tcp_tw_recycle都不应该开启。故被抛弃也是理所应当的了。</p><p> 4</p><p> 总结</p><ul><li><p>tcp_tw_recycle 选项在4.10内核之前还只是不适用于NAT/LB的情况(其他情况下，我们也非常不推荐开启该选项)，但4.10内核后彻底没有了用武之地，并且在4.12内核中被移除.</p></li><li><p>tcp_tw_reuse 选项仍然可用。在服务器上面，启用该选项对于连入的TCP连接来说不起作用，但是对于客户端(比如服务器上面某个服务以客户端形式运行，比如nginx反向代理)等是一个可以考虑的方案。</p></li><li><p>修改TCP_TIMEWAIT_LEN是非常不建议的行为。</p></li></ul><p> 5<br> 参考链接</p><p> [1]<a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=4396e46187ca5070219b81773c4e65088dac50cc" target="_blank" rel="noopener">https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=4396e46187ca5070219b81773c4e65088dac50cc</a></p><p> [2]<a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/networking/ip-sysctl.txt?h=v4.11#n648" target="_blank" rel="noopener">https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/networking/ip-sysctl.txt?h=v4.11#n648</a></p><p> [3]<a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/networking/ip-sysctl.txt?h=v4.11#n643" target="_blank" rel="noopener">https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/networking/ip-sysctl.txt?h=v4.11#n643</a></p><p> [4]<a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=95a22caee396cef0bb2ca8fafdd82966a49367bb" target="_blank" rel="noopener">https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=95a22caee396cef0bb2ca8fafdd82966a49367bb</a>  </p><p> [5]Coping with the TCP TIME-WAIT state on busy Linux servers：<a href="https://vincent.bernat.ch/en/blog/2014-tcp-time-wait-state-linux" target="_blank" rel="noopener">https://vincent.bernat.ch/en/blog/2014-tcp-time-wait-state-linux</a></p><p> [6]net.ipv4.tcp_tw_recycle は廃止されました ― その危険性を理解する：<a href="https://qiita.com/tmshn/items/b49f1b51bfc472968b30" target="_blank" rel="noopener">https://qiita.com/tmshn/items/b49f1b51bfc472968b30</a></p><p> [7]tcp_tw_reuse、tcp_tw_recycle 使用场景及注意事项：<a href="https://www.cnblogs.com/lulu/p/4149312.html" target="_blank" rel="noopener">https://www.cnblogs.com/lulu/p/4149312.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;原创： SRE 小米运维&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/uwykopNnkcRL5JXTVufyBw&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s/uwy
      
    
    </summary>
    
      <category term="内核" scheme="http://zhangyu8.me/categories/%E5%86%85%E6%A0%B8/"/>
    
    
      <category term="内核" scheme="http://zhangyu8.me/tags/%E5%86%85%E6%A0%B8/"/>
    
  </entry>
  
</feed>
