<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>大雨哥</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://zhangyu33.com/"/>
  <updated>2019-04-11T14:00:02.641Z</updated>
  <id>http://zhangyu33.com/</id>
  
  <author>
    <name>zhangyu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>python操作mysql的多个方案</title>
    <link href="http://zhangyu33.com/2019/04/11/python%E6%93%8D%E4%BD%9Cmysql%E7%9A%84%E5%A4%9A%E4%B8%AA%E6%96%B9%E6%A1%88/"/>
    <id>http://zhangyu33.com/2019/04/11/python操作mysql的多个方案/</id>
    <published>2019-04-10T16:00:00.000Z</published>
    <updated>2019-04-11T14:00:02.641Z</updated>
    
    <content type="html"><![CDATA[<p>python操作mysql的多个方案</p><p><a href="http://www.runoob.com/python/python-mysql.html" target="_blank" rel="noopener">http://www.runoob.com/python/python-mysql.html</a></p><p><a href="https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python" target="_blank" rel="noopener">https://stackoverflow.com/questions/372885/how-do-i-connect-to-a-mysql-database-in-python</a></p><p>官方规范：Python数据库API规范v2.0</p><p>PEP 249 -- Python Database API Specification v2.0</p><p><a href="https://www.python.org/dev/peps/pep-0249/" target="_blank" rel="noopener">https://www.python.org/dev/peps/pep-0249/</a></p><p>mysql 官方--MySQL Python API</p><p><a href="https://dev.mysql.com/doc/refman/5.7/en/apis-python.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.7/en/apis-python.html</a></p><p>连接mysql</p><p>方案一：mysql-connector 是 MySQL 官方提供的驱动器</p><p>安装：</p><p>rpm -ivh<br>ftp://ftp.jaist.ac.jp/pub/mysql/Downloads/Connector-Python/mysql-connector-python-cext-2.1.7-1.el7.x86_64.rpm</p><p>rpm -ivh<br>ftp://ftp.jaist.ac.jp/pub/mysql/Downloads/Connector-Python/mysql-connector-python-2.1.7-1.el7.x86_64.rpm</p><p>或者</p><p>python -m pip install mysql-connector 被废弃</p><p>新版</p><p>pip install mysql-connector-python</p><p>教程<br><a href="http://www.runoob.com/python3/python-mysql-connector.html" target="_blank" rel="noopener">[http://www.runoob.com/python3/python-mysql-connector.html]{.underline}</a></p><p>举例：</p><p>import mysql.connector cnx = mysql.connector.connect(user=\’scott\’,<br>password=\’tiger\’, host=\’127.0.0.1\’, database=\’employees\’) try:<br>cursor = cnx.cursor() cursor.execute(\”\”\” select 3 from your_table<br>\”\”\”) result = cursor.fetchall() print result finally: cnx.close()</p><p>-----------------------------------------------------------------------------------------</p><p>方案二</p><p>Python3 使用 PyMySQL</p><p><a href="https://github.com/PyMySQL/PyMySQL" target="_blank" rel="noopener">[https://github.com/PyMySQL/PyMySQL]{.underline}</a></p><p>pip3 install PyMySQL</p><p>python3 -m pip install PyMySQL</p><p>方案三：Python2中则使用mysqldb</p><p>#yum install gcc libffi-devel python-devel openssl-devel urpmi xterm<br>freetds -y</p><p>#yum install MySQL-python</p><p>或者</p><p>rpm -ivh MySQL-python-1.3.6-3.fc22.x86_64.rpm</p><p>或者pip install MySQL-python</p><p>import MySQLdb</p><p>安装MySQLdb，<br><a href="https://pypi.python.org/pypi/MySQL-python" target="_blank" rel="noopener">[https://pypi.python.org/pypi/MySQL-python]{.underline}</a>)从这里可选择适合您的平台的安装包，分为预编译的二进制文件和源代码安装包。</p><p>如果您选择二进制文件发行版本的话，安装过程基本安装提示即可完成。如果从源代码进行安装的话，则需要切换到MySQLdb发行版本的顶级目录，并键入下列命令:</p><p>\$ gunzip MySQL-python-1.2.2.tar.gz \$ tar -xvf MySQL-python-1.2.2.tar\$<br>cd MySQL-python-1.2.2\$ python setup.py build \$ python setup.py install</p><p><strong>注意：</strong>请确保您有root权限来安装上述模块。</p><p>################################</p><p>方案4：<strong>mysqlclient --django官方推荐</strong></p><p>本质是方案三mysqldb第三方修改版支持python3的</p><p>首先安装一下mysql-devel</p><p>yum install python-devel mysql-devel</p><p><strong>Python 3</strong></p><p>yum install python36-devel.x86_64</p><p>然后就可以直接安装mysqlclient了</p><p>pip install mysqlclient</p><p><a href="https://pypi.org/project/mysqlclient/" target="_blank" rel="noopener">[https://pypi.org/project/mysqlclient/]{.underline}</a></p><p><a href="https://github.com/PyMySQL/mysqlclient-python" target="_blank" rel="noopener">[https://github.com/PyMySQL/mysqlclient-python]{.underline}</a></p><p>##############</p><p>方案5：CyMySQL----------For python 3.3</p><p>pip install cymysql</p><p>import cymysql</p><p><a href="https://github.com/nakagami/CyMySQL" target="_blank" rel="noopener">https://github.com/nakagami/CyMySQL</a></p><p>###]<strong>[Python]代码 </strong></p><p>#-*- encoding: utf-8 -*-</p><p><strong>import</strong> os, sys, string</p><p><strong>import</strong> MySQLdb</p><p># 连接数据库　</p><p><strong>try</strong>:</p><pre><code>conn **=**</code></pre><p>MySQLdb.connect(host<strong>=</strong>\’localhost\’,user<strong>=</strong>\’root\’,passwd<strong>=</strong>\’xxxx\’,db<strong>=</strong>\’test1\’)</p><p><strong>except</strong> Exception, e:</p><pre><code>print esys.exit()</code></pre><p># 获取cursor对象来进行操作</p><p>cursor <strong>=</strong> conn.cursor()</p><p># 创建表</p><p>sql <strong>=</strong> \”create table if not exists test1(name varchar(128) primary<br>key, age int(4))\”</p><p>cursor.execute(sql)</p><p># 插入数据</p><p>sql <strong>=</strong> \”insert into test1(name, age) values (\’%s\’, %d)\” <strong>%</strong><br>(\”zhaowei\”, 23)</p><p><strong>try</strong>:</p><pre><code>cursor.execute(sql)</code></pre><p><strong>except</strong> Exception, e:</p><pre><code>print e</code></pre><p>sql <strong>=</strong> \”insert into test1(name, age) values (\’%s\’, %d)\” <strong>%</strong><br>(\”张三\”, 21)</p><p><strong>try</strong>:</p><pre><code>cursor.execute(sql)</code></pre><p><strong>except</strong> Exception, e:</p><pre><code>print e</code></pre><p># 插入多条</p><p>sql <strong>=</strong> \”insert into test1(name, age) values (%s, %s)\”</p><p>val <strong>=</strong> ((\”李四\”, 24), (\”王五\”, 25), (\”洪六\”, 26))</p><p><strong>try</strong>:</p><pre><code>cursor.executemany(sql, val)</code></pre><p><strong>except</strong> Exception, e:</p><pre><code>print e</code></pre><p>#查询出数据</p><p>sql <strong>=</strong> \”select * from test1\”</p><p>cursor.execute(sql)</p><p>alldata <strong>=</strong> cursor.fetchall()</p><p># 如果有数据返回，就循环输出, alldata是有个二维的列表</p><p><strong>if</strong> alldata:</p><pre><code>**for** rec **in** alldata:    print rec\[0\], rec\[1\]</code></pre><p>cursor.close()</p><p>conn.close()</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;python操作mysql的多个方案&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.runoob.com/python/python-mysql.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://www.runoob.com/p
      
    
    </summary>
    
      <category term="mysql" scheme="http://zhangyu33.com/categories/mysql/"/>
    
    
      <category term="mysql" scheme="http://zhangyu33.com/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>SRE工程师到底是做什么的？</title>
    <link href="http://zhangyu33.com/2019/02/28/SRE%E5%B7%A5%E7%A8%8B%E5%B8%88%E5%88%B0%E5%BA%95%E6%98%AF%E5%81%9A%E4%BB%80%E4%B9%88%E7%9A%84/"/>
    <id>http://zhangyu33.com/2019/02/28/SRE工程师到底是做什么的/</id>
    <published>2019-02-27T16:00:00.000Z</published>
    <updated>2019-02-28T06:45:48.733Z</updated>
    
    <content type="html"><![CDATA[<p>SRE工程师到底是做什么的？ </p><p><a href="https://mp.weixin.qq.com/s/j5Sgrsm90B94jMwn1mA1Gg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/j5Sgrsm90B94jMwn1mA1Gg</a></p><blockquote><p>作者 | Erik Dietrich  </p><p>译者 | 无明</p><p>你是否也对站点可靠性工程师（SRE）这个角色存在很多疑问？本文介绍了 SRE 工程师的职责。</p><p>尽管站点可靠性工程已经存在了一段时间，但也只是最近才在业界获得一些名声。但人们对于站点可靠性工程师（SRE）的作用仍然存在很多疑问。我们所知道的大部分内容来自谷歌的《站点可靠性工程》一书。我们将在这篇文章中多次提到这本书。</p><p>人们将 SRE 与运营、系统管理员等进行比较，但这种比较不足以说明他们在现代软件环境中所发挥的作用。他们承担的责任多于运营。他们通常具有系统管理背景，同时也具备软件开发技能。SRE 结合了所有这些技能，确保复杂的分布式系统能够顺利运行。</p><p>那么他们是怎么做到这一切呢？</p><p>自动化一切</p><p>自动化是 SRE 角色与传统运营团队之间的一个区别。在过去，运营人员会通过执行脚本、按下按钮和其他手动操作来让软件系统保持运行。然而，在 SRE 世界中，人们非常重视自动化。这种驱动力来自 SRE 角色的工程方面。</p><p>当软件开发人员处于日复一日重复相同功能的境地时，他们将被迫实现自动化。这就是软件开发人员最擅长的事情。自动化并不仅限于对软件构建和一些验收测试进行自动化，还包括 CI/CD 和基础设施的创建和修补，以及监控、警报和自动响应某些事件。在谷歌的《站点可靠性工程》一书中，这也被称为消除辛劳：</p><p>辛劳是一种与运行生产服务相关的工作，它往往是手动的、重复的、可自动化的、战术性的，缺乏持久的价值，并随着服务的增长呈线性增长。</p><p>那么为什么我们要如此关注如何减少辛劳呢？减少工作量不仅使流程可重复和自动化，而且还为 SRE 提供了更多的时间用于构建工具和研究基础设施变更以便进一步提高站点可靠性。总之，工作量越少，用于确保软件生态系统可靠运行的时间和资源就越多，你就能越快地实现业务价值。</p><p>监控分布式系统</p><p>随着分布式系统的普及，对监控的需求也在增长。仅仅启动和运行应用程序是不够的。我们还需要确保基础设施运行正常，并确保所有其他内部依赖项都可访问且运行正常。此外，应用程序的业务功能应该提供适当的监控功能，以验证它们是否运行正常。</p><p>提供待命支持</p><p>与传统的运营角色类似，SRE 也有轮班待命的职责。除了监控基础设施和他们自己的服务之外，开发团队还可以向他们咨询和请他们一起进行故障排除。</p><p>轮班待命看起来是怎样的？通常，SRE 根据计划表进行轮班待命，计划表可以让其他 SRE 专注于工程方面，而且不会导致轮班待命工程师感到倦怠。轮换待命可以从几天到一周不等，或者更长时间。</p><p>在发生高优先级的事件时，SRE 需要调查和诊断问题。他们还可能会要求其他工程师或软件开发人员一起来解决问题。根据系统的 SLA，他们可能需要一起工作才能在几分钟内解决问题。对于低优先级问题，SRE 通常会在工作时间内处理它们。对于那些不喜欢在凌晨 3 点钟起床的工程师来说，这是一个好消息。</p><p>管理事件</p><p>管理事件时 SRE 角色的另一个重要部分。你可能会说这与轮班待命没有什么两样。找到问题然后解决它，这能有多难？</p><p>好吧，在管理事件时，SRE 需要运用额外的专业技能来确保一切顺利。例如，在发生中断时，可能有很多方法来诊断和解决问题。因此，为了妥善管理事件，必须有人监督和促进所有相关人员的行为。这就需要定义明确的角色。</p><p>虽然并非所有公司都包含谷歌推荐的角色，但我们至少应该考虑它们。这些角色包括：</p><ul><li><p>一名事件指挥官，对所发生的一切都保持高度关注；</p></li><li><p>处理或修改基础设施或系统的工程师；</p></li><li><p>将正确的信息传递给客户和管理层的沟通者角色；</p></li><li><p>负责规划会议、交接和后勤需求的规划者角色；</p></li><li><p>如果 SRE 没有明确定义的角色，那么当他们在尝试不同的解决方案时，如果没有前期协调和沟通，就容易发生混乱。</p></li></ul><p>事后调查</p><p>我们已经经历并解决了一个事件，现在准备好进行事后调查。通常，SRE 会促进或参与这些事后调查。</p><p>在进行事后调查时，所有相关方都被汇聚在一起，目标是分析事故期间都发生了什么，并找出根本原因。参与者还将决定将来如何防止或修复同样的事件。下面列出了事后调查将产出的内容：</p><ul><li><p>提高可靠性的故事或监控；</p></li><li><p>附加文档，以协助未来事件的处理；</p></li><li><p>进一步调查或测试，以证实与事件有关的任何假设。</p></li></ul><p>跟踪中断</p><p>SRE 的另一个职责是跟踪中断。这最终有助于识别长期趋势和创建合理的 SLO 和 SLA。</p><p>跟踪中断的用途包括监控低优先级事件。这些事件可能不会给消费者带来真正的问题，但是观察长期趋势和时间可以帮助隔离和解决那些似乎找不到原因的烦人 bug。</p><p>与开发团队合作</p><p>除了在轮班待命期间为开发团队提供支持，SRE 还提供咨询和故障排除服务。这样可以帮助其他 SRE 团队和软件开发团队，这些团队苦于处理运营或可靠性问题。</p><p>在这种情况下，SRE 将评估当前问题，并确定哪些可以通过自动化或工程工作进行改进。SRE 还可为可靠性问题提出解决方案。最重要的是，SRE 将推动团队流程的变革。这些变化将确保站点可靠性工程团队能够增强团队交付价值的能力。</p><p>创建服务水平指标和目标</p><p>当你听到有人说服务已经达到或正在努力达到 99.99％的正常运行时间时，他们指的是服务水平目标（SLO）。服务水平指标（SLI）用于衡量这些目标。换句话说，SLI 是关于如何衡量 SLO 的协议。SRE 通过提供历史服务性能数据来协助这些工作。它们还有助于为未来提供切合实际的目标，并可能为客户提供适当的 SLA 建议。</p><p>然后，SRE 会确保你的应用程序满足（但不超过）规定的 SLO。现在你可能会认为没有超过 SLO 会很奇怪。然而，制造超出实际需要的东西是对资源的浪费。SRE 平衡了客户需求和所提供服务的目标。</p><p>职责可能会有所不同</p><p>在这篇文章中，我们讨论了站点可靠性工程师参与的各种活动。虽然这些活动是由 SRE 完成的，但并不是一成不变的。公司会根据需要改变 SRE 的角色和职责。一般而言，处于 SRE 过程不同阶段的公司可能有不同的需求。</p><p>例如，新公司可能需要 SRE 的支持才能控制一般性中断。大部分能量都趋向于可靠性的基本水平。但是，在这一过程中走得更远的其他公司可能已经消除了公司范围的中断。他们可能会花更多时间来改进或验证与业务相关的服务指标。例如，在网站的普遍可用性达到稳定和可靠的状态之后，你的披萨店应用程序可能需要对披萨推荐机制进行新的监控。</p><p>   结论   </p><p>正如你所读到的，SRE 将时间花在技术和流程方面的职责上。他们不仅仅是运营或系统管理团队。他们利用自己的工程技能自动化和减少管理任务所需的人工干预。此外，他们还与其他工程团队合作，提供适当的监控、事件响应和管理。</p><p>随着时间的推移，这些职能提高了分布式系统的可靠性并降低维护成本。最后，他们通过组织传播站点可靠性工程文化，让所有团队都能学会在做出决策时以可靠性作为出发点。</p><p>英文原文：<a href="https://www.scalyr.com/blog/site-reliability-engineer/" target="_blank" rel="noopener">https://www.scalyr.com/blog/site-reliability-engineer/</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;SRE工程师到底是做什么的？ &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/j5Sgrsm90B94jMwn1mA1Gg&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.co
      
    
    </summary>
    
      <category term="devops" scheme="http://zhangyu33.com/categories/devops/"/>
    
    
      <category term="devops" scheme="http://zhangyu33.com/tags/devops/"/>
    
  </entry>
  
  <entry>
    <title>闲扯Nginx的accept_mutex配置</title>
    <link href="http://zhangyu33.com/2019/02/28/%E9%97%B2%E6%89%AFNginx%E7%9A%84accept_mutex%E9%85%8D%E7%BD%AE/"/>
    <id>http://zhangyu33.com/2019/02/28/闲扯Nginx的accept_mutex配置/</id>
    <published>2019-02-27T16:00:00.000Z</published>
    <updated>2019-02-28T07:15:00.000Z</updated>
    
    <content type="html"><![CDATA[<p> 闲扯Nginx的accept_mutex配置</p><p><a href="https://huoding.com/2013/08/24/281" target="_blank" rel="noopener">https://huoding.com/2013/08/24/281</a></p><blockquote><p>让我们看看accept_mutex的意义：当一个新连接到达时，如果激活了accept_mutex，那么多个Worker将以串行方式来处理，其中有一个Worker会被唤醒，其他的Worker继续保持休眠状态；如果没有激活accept_mutex，那么所有的Worker都会被唤醒，不过只有一个Worker能获取新连接，其它的Worker会重新进入休眠状态，这就是「<a href="http://en.wikipedia.org/wiki/Thundering_herd_problem" target="_blank" rel="noopener">惊群问题</a>」。</p><p>Nginx缺省激活了accept_mutex，也就是说不会有惊群问题，但真的有那么严重么？实际上Nginx作者Igor Sysoev曾经给过相关的<a href="http://forum.nginx.org/read.php?2,1641,1686#msg-1686" target="_blank" rel="noopener">解释</a>：</p><blockquote><p>OS may wake all processes waiting on accept() and select(), this is called thundering herd problem. This is a problem if you have a lot of workers as in Apache (hundreds and more), but this insensible if you have just several workers as nginx usually has. Therefore turning accept_mutex off is as scheduling incoming connection by OS via select/kqueue/epoll/etc (but not accept()).</p></blockquote><p>简单点说：Apache动辄就会启动成百上千的进程，如果发生惊群问题的话，影响相对较大；但是对Nginx而言，一般来说，<a href="http://wiki.nginx.org/CoreModule#worker_processes" target="_blank" rel="noopener">worker_processes</a>会设置成CPU个数，所以最多也就几十个，即便发生惊群问题的话，影响相对也较小。</p><p>…</p><p>假设你养了一百只小鸡，现在你有一粒粮食，那么有两种喂食方法：</p><ul><li>你把这粒粮食直接扔到小鸡中间，一百只小鸡一起上来抢，最终只有一只小鸡能得手，其它九十九只小鸡只能铩羽而归。这就相当于关闭了accept_mutex。</li><li>你主动抓一只小鸡过来，把这粒粮食塞到它嘴里，其它九十九只小鸡对此浑然不知，该睡觉睡觉。这就相当于激活了accept_mutex。</li></ul><p>可以看到此场景下，激活accept_mutex相对更好一些，让我们修改一下问题的场景，我不再只有一粒粮食，而是一盆粮食，怎么办？</p><p>此时如果仍然采用主动抓小鸡过来塞粮食的做法就太低效了，一盆粮食不知何年何月才能喂完，大家可以设想一下几十只小鸡排队等着喂食时那种翘首以盼的情景。此时更好的方法是把这盆粮食直接撒到小鸡中间，让它们自己去抢，虽然这可能会造成一定程度的混乱，但是整体的效率无疑大大增强了。</p><p>Nginx缺省激活了accept_mutex（最新版缺省禁用），是一种保守的选择。如果关闭了它，可能会引起一定程度的惊群问题，表现为上下文切换增多（sar -w）或者负载上升，但是如果你的网站访问量比较大，为了系统的吞吐量，我还是建议大家关闭它。</p></blockquote><p>最新 nginx-1.11.4开始默认关闭了accept_mutex。</p><p>从tengine2.2开始accept_mutex 参数由默认的 on 改为了 off ，为什么要改呢。与时俱进。</p><p>当初这个参数是为了避免在 epoll_wait 所出现惊群效应。可以参考（<a href="https://www.jianshu.com/p/21c3e5b99f4a）。" target="_blank" rel="noopener">https://www.jianshu.com/p/21c3e5b99f4a）。</a></p><p>新版内核已经有了处理这个方法，不再需要 nginx 单独配置。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; 闲扯Nginx的accept_mutex配置&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://huoding.com/2013/08/24/281&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://huoding.com/2013/08/24
      
    
    </summary>
    
      <category term="nginx" scheme="http://zhangyu33.com/categories/nginx/"/>
    
    
      <category term="nginx" scheme="http://zhangyu33.com/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>谈谈我的三观</title>
    <link href="http://zhangyu33.com/2019/02/28/%E8%B0%88%E8%B0%88%E6%88%91%E7%9A%84%E4%B8%89%E8%A7%82/"/>
    <id>http://zhangyu33.com/2019/02/28/谈谈我的三观/</id>
    <published>2019-02-27T16:00:00.000Z</published>
    <updated>2019-02-28T09:26:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>谈谈我的三观</p><p>酷 壳 - CoolShell</p><p><a href="https://coolshell.cn/articles/19085.html" target="_blank" rel="noopener">https://coolshell.cn/articles/19085.html</a></p><blockquote><p>也许是人到了四十多了，敢写这么大的命题，我也醉了，不过，我还是想把我的想法记录下来，算是对我思考的一个snapshot，给未来的我看看，要么被未来的我打脸，要么打未来我的脸。无论怎么样，我觉得对我自己都很有意义。注意，这篇文章是长篇大论。</p><p>三观是世界观、人生观和价值观，</p><ul><li><strong>世界观代表你是怎么看这个世界的。</strong>是左还是右，是激进还是保守，是理想还是现实，是乐观还是悲观……</li><li><strong>人生观代表你要想成为什么样的人。</strong>是成为有钱人，还是成为人生的体验者，是成为老师，还是成为行业专家，是成为有思想的人，还是成为有创造力的人……</li><li><strong>价值观则是你觉得什么对你来说更重要</strong>。是名是利，是过程还是结果，是付出还是索取，是国家还是自己，是家庭还是职业……</li></ul><p>人的三观其实是会变的，回顾一下我的过去，我感觉我的三观至少有这么几比较明显的变化，学生时代、刚走上社会的年轻时代，三十岁后的时代，还有现在。估计人都差不多吧……</p><ul><li>学生时代的三观更多的是学校给的，用各种标准答案给的，是又红又专的</li><li>刚走上社会后发现完全不是这么一回事，但学生时代的三观根深蒂固，三观开始分裂，内心开始挣扎</li><li>三十岁后，不如意的事越来越多，对社会越来越了解，有些人屈从现实，有些人不服输继续奋斗，而有些人展露才能开始影响社会，而分裂的三观开始收敛，我属于还在继续奋斗的人。</li><li>四十岁时，经历过的事太多，发现留给自己的时间不多，世界太复杂，而还有好多事没做，从而变得与世无争，也变得更为地自我。</li></ul><h4 id="面对世界"><a href="#面对世界" class="headerlink" title="面对世界"></a>面对世界</h4><p>年轻的时候，抵制过日货，虽然没上过街，但是也激动过，一次是1999南斯拉夫大使馆被炸，一次是2005反日示威，以前，我也是一个爱国愤青。但是后来，有过各种机会出国长时间生活工作，加拿大、英国、美国、日本……随着自己的经历和眼界的开阔，自己的三观自己也随着有了很多的变化，发现有些事并不是自己一开始所认识的那样，而且还是截然相反的。<strong>我深深感觉到，要有一个好的世界观，你需要亲身去经历和体会这个世界，而不是听别人说</strong>。所以，当我看到身边的人情绪激动地要抵制这个国家，搞死那个民族的时候，我都会建议他去趟那个国家最好在在那个国家呆上一段时间，亲自感受一下。</p><p>再后来发现，要抵制的越来越多，小时候的美英帝国主义，然后是日本，再后面是法国、韩国、菲利宾、印度、德国、瑞典、加拿大……从小时候的台独到现在的港独、藏独、疆独……发现再这样下去，基本上来说，自己的人生也不用干别的事了……另外，随着自己的成长，越来越明白，<strong>抵制这个抵制那个只不过是幼稚和狭隘的爱国主义，真想强国，想别让他人看得起，就应该把时间和精力放在努力学习放在精益求精上，做出比他们更好的东西来。</strong>另外，感觉用对内的爱国主义解决对外的外交问题也有点驴唇不对马嘴，无非也就是转移一下内部的注意力罢了，另外还发现爱国主义还可以成为消费营销手段……<strong>不是我不爱国，是我觉得世道变复杂了，我只是一个普通的老百姓，能力有限，请不要赋予我那么大的使命，我只想在我的专业上精进，能力所能及地帮助身边的人，过一个简单纯粹安静友善的生活</strong>……</p><p>另外，为什么国与国之间硬要比个你高我低，硬要分个高下，硬要争出个输赢，我也不是太理解，世界都已经发展到全球化的阶段了，很多产品早就是你中有我，我中有你的情况了。举个例子，一部手机中的元件，可能来自全世界数十个国家，我们已经说不清楚一部手机是究竟是哪个国家生产的了。即然，整个世界都在以一种合作共赢全球化的姿态下运作，认准自己的位置，拥抱世界，持续向先进国家学习，互惠互利，不好吗？你可能会说，不是我们不想这样，是别人不容我们发展……<strong>老实说，大的层面我也感受不到，但就我在的互联网计算机行业方面，我觉得整个世界的开放性越来越好，开源项目空前地繁荣，世界上互联网文化也空前的开放，在计算机和互联网行业，我们享受了太多的开源和开放的红利，人家不开放，我们可能在很多领域还落后数十年。然而现在很多资源我们都访问不了，用个VPN也非法，你说是谁阻碍了发展？我只想能够流畅地访问互联网，让我的工作能够更有效率，然而，我在自己的家里却像做贼一样去学习新知识新技术，随时都有可能被抓进监狱……</strong></p><p>随着自己的经历越多，发现这个世界越复杂，也发现自己越渺小，很多国家大事并不是我不关心，是我觉得那根本不是我这个平头老百姓可以操心的事，这个世界有这个世界运作的规律和方法，而还有很多事情超出了我能理解的范围，也超出了我能控制的范围，我关心不关心都一个样，这些大事都不会由我的意志所决定的。而所谓的关心，无非就是喊喊口号，跟人争论一下，试图改变其它老百姓的想法，然而，对事情的本身的帮助却没有多大意义。过上几天，生活照旧，人家该搞你还不是继续搞你，而你自己并不因为做这些事而过得更好。</p><p><strong>我对国与国之间的关系的态度是，有礼有节，不卑不亢，对待外国人，有礼貌但也要有节气，既不卑躬屈膝，也不趾高气昂</strong>，整体上，我并不觉得我们比国外有多差，但我也不觉得我们比国外有多好，我们还在成长，还需要帮助和协作，四海之内皆兄弟，无论在哪个国家，在老百姓的世界里，哪有那么多矛盾。<strong>有机会多出去走走，多结交几个其它民族的朋友，你会觉得，在友善和包容的环境下，你的心情和生活可以更好</strong>。</p><p>我现在更多关心的是和我生活相关的东西，比如：上网、教育、医疗、食品、治安、税务、旅游、收入、物价、个人权益、个人隐私……这些东西对我的影响会更大一些，也更值得关注，可以看到过去的几十年，我们国家已经有了长足的进步，这点也让我让感到很开心和自豪的，在一些地方也不输别人。但是，依然有好些事的仍然没有达到我的预期，而且还很糟糕，这个也要承认。而对，未来的变数谁也不好说，我在这个国度里的安全感似乎还不足够，所以，我还是要继续努力，以便我可以有更多的选项。有选项总比没得选要好。所以，<strong>我想尽一切办法，努力让选项多起来，无法改变无法影响，那就只能提高自己有可选择的可能性</strong>。</p><h4 id="面对社会"><a href="#面对社会" class="headerlink" title="面对社会"></a>面对社会</h4><p>另外，在网上与别人对一些事或观点的争论，我觉得越来越无聊，以前被怼了，一定要怼回去，现在不会了，视而不见，不是怕了，是因为，网络上的争论在我看来大多数都是些没有章法，逻辑混乱的争论。</p><ul><li>很多讨论不是说事，直接就是怼人骂人。随意就给人扣个帽子。</li><li>非黑即白的划分，你说这个不是黑的，他们就把你划到白的那边。</li><li>飘移观点，复杂化问题。东拉西扯，牵强附会，还扯出其它不相关的事来混淆。</li><li>杠精很多，不关心你的整体观点，抓住一个小辫子大作文章。</li></ul><p>很明显，<strong>与其花时间教育这些人，不如花时间提升自己，让自己变得更优秀，这样就有更高的可能性去接触更聪明更成功更高层次的人</strong>。因为，一方面，你改变不了他们，另外，改变他们对你自己也没什么意义，改变自己，提升自己，让自己成长才有意义。时间是宝贵的，那些人根本不值得花时间，应该花时间去结交更有素质更聪明的人，做更有价值的事。</p><p>美国总统富兰克林·罗斯福妻子埃莉诺·罗斯福（Eleanor Roosevelt）说过下面的一句话。</p><blockquote><p><strong>Great minds discuss ideas;<br>Average minds discuss events;<br>Small minds discuss people</strong></p></blockquote><p>把时间多放在一些想法上，对自己对社会都是有意义的，把时间放在八卦别人，说长到短，你也不可能改善自己的生活，<strong>你批评这个批评那个，看不上这个看不起那个，不会让你有成长，也不会提升你的影响力，你的影响力不是你对别人说长道短的能力，而是别人信赖你并希望得到你的帮助的现象</strong>。多交一些有想法的朋友，多把自己的想法付诸实践，那怕没有成功，你的人生也会比别人过得有意义。</p><p>如果你看过我以前的文章，你会看到一些吐槽性质的文章，而后面就再也没有了。另外，我也不再没有针对具体的某个人做出评价，因为人太复杂的了，经历的越多，你就会发现你很难评价人，与其花时间在评论人和事上，不如把时间花在做一些力所能及的事来改善自己或身边的环境。所以，<strong>我建议大家少一些对人的指责和批评，通过对一件事来引发你的思考，想一想有什么可以改善，有什么方法可以做得更好，有哪些是自己可以添砖加瓦的？你会发现，只要你坚持这么做，你个人的提升和对社会的价值会越来越大，而你的影响力也会越来越大</strong>。</p><h4 id="面对人生"><a href="#面对人生" class="headerlink" title="面对人生"></a>面对人生</h4><p>现在的我，即不是左派也不是右派，我不喜欢爱国主义，我也不喜欢崇洋媚外，我更多的时候是一个自由派，哪边我都不站，我站我自己。因为，生活在这样的一个时代，能让自己过好都是一些比较奢望的事了。</p><p>《教父》里有这样的人生观：<strong>第一步要努力实现自我价值，第二步要全力照顾好家人，第三步要尽可能帮助善良的人，第四步为族群发声，第五步为国家争荣誉。事实上作为男人，前两步成功，人生已算得上圆满，做到第三步堪称伟大，而随意颠倒次序的那些人，一般不值得信任</strong>。这也是古人的“修身齐家治国平天下”！所以，在你我准备要开始要“平天下”的时候，也得先想想，自己的生活有没有过好了，家人照顾好了么，身边有哪些力所能及的事是可以去改善的……</p><p>穷则独善其身，达则兼济天下。提升自己，实现自我，照顾好自己的家人，帮助身边的人。这已经很不错了！</p><p>什么样的人干什么样的事，什么样的阶段做什么样的选择，<strong>有人的说，选择比努力更重要的，我深以为然，而且，我觉得选择和决定，比努力更难</strong>，努力是认准了一个事后不停地发力，而决定要去认准哪个事是自己该坚持努力的，则是令人彷徨和焦虑的（半途而废的人也很多）。面对人生，你每天都在作一个一个的决定，在做一个又一个的选择，有的决定大，有的决定小，你的人生的轨迹就是被这一个一个的决定和选择所走走出来的。</p><p>我在24岁放弃了一房子离开银行到小公司的时候，我就知道，人生的选择就是一个翘翘板，你要一头就没有另一头，<strong>选择是有代价的，你不选择的代价更大；选择是要冒险的，你不敢冒险的风险更大；选择是需要放弃的，因为无论怎么选你都会要放弃。想想你老了以后，回头一看，好多事情在年轻的时候都不敢做，而你再也没有机会，你就知道不敢选择不敢冒险的代价有多大了。</strong>选择就是一种 trade-off，这世上根本不会有什么完美，只要你想做事，你有雄心壮志，你的人生就是一个坑接着一个坑，你所能做的就是找到你喜欢的方向跳坑。</p><p>所以， 你要想清楚你要什么，不要什么，而且还不能要得太多，这样你才好做选择。否则，你影响你的因子太多，决定不好做，也做不好。</p><p>就像最前面说的一样，你是激进派还是保守派，你是喜欢领导还是喜欢跟从，你是注重长期还是注重短期，你是注重过程还是注重结果……等等，你对这些东西的坚持和守护，成为了你的“三观”，而你的三观则影响着你的选择，而你的选择影响着你的人生。</p><h4 id="价值取向"><a href="#价值取向" class="headerlink" title="价值取向"></a>价值取向</h4><p>下面是一些大家经常在说，可能也是大多数人关心的问题，就这些问题，我也谈谈我的价值取向。</p><p><strong>挣钱</strong>。挣钱是一个大家都想做的事，但你得解决一个很核心的问题，那就是为什么别人愿意给你钱？对于挣钱的价值观从我大学毕业到现我就没怎么变过，那就是我更多关注的是怎么提高自己的能力，让自己值那个价钱，让别人愿意付钱。另外一方面，我发现，<strong>越是有能力的人，就越不计较一些短期得失，越计较短期得失的人往往都是很平庸的人</strong>。有能力的人不会关心自己的年终奖得拿多少，会不会晋升，他们更多的关心自己真正的实力有没有超过更多的人，更多的关注的是自己长远的成长，而不是一时的利益。聪明的人从来不关心眼前的得失，不会关心表面上的东西，他们更多关心的是长期利益，关心长期利益的人一定不是投机者，一定是投资者，<strong>投资会把自己的时间精力金钱投资在能让自己成长和提升的地方，那些让自己可以操更大的盘的地方，他们培养自己的领导力和影响力。</strong>而投机者在职场上会通过溜须拍马讨好领导，在学习上追求速成，在投资上使用跟随策略，在创业上甚至会不择手段，当风险来临时，投机者是几乎完全没有抗风险能力的，他们所谓的能力只不过因为形势好。</p><p><strong>技术</strong>。对于计算机技术来说，要学的东西实在是太多，我并不害怕要学的东西很多，因为学习能力是一个好的工程师必需具备的事，我不惧怕困难和挑战。我觉得在语言和技术争论谁好谁坏是一种幼稚的表现， 没有完美的技术，Engineering 玩的是 Tradeoff。所以，我对没有完美的技术并不担心，但是我反而担心的是，当我们进入到一些公司后，这些公司会有一些技术上的沉淀也就是针对公司自己的专用技术，比如一些中间件，一些编程框架，lib库什么的。老实说，我比较害怕公司的专用技术，因为一旦失业，我建立在这些专用技术上的技能也会随之瓦解，有时候，我甚至害怕把我的技术建立在某一个平台上，小众的不用说了，大众的我也比较担扰，比如Windows或Unix/Linux上，因为一旦这个平台不流行或是被取代，那么我也会随之淘汰（过去的这20年已经发生过太多这样的事了）。为了应对这样的焦虑，<strong>我更愿意花时间在技术的原理和技术的本质上，这导致我需要了解各种各样的技术的设计方法，以及内在原理。</strong>所以，当国内的绝大多数程序员们更多的关注架构性能的今天，我则花更多的时间去了解编程范式，代码重构，软件设计，计算机系统原理，领域设计，工程方法……因为只有原理、本质和设计思想才可能让我不会被绑在某个专用技术或平台上，除非，我们人类的计算机这条路没走对。</p><p><strong>职业</strong>。在过去20多年的职业生涯中，我从基层工程师做到管理，很多做技术的人都会转管理，但我却还是扎根技术，就算是在今天，还是会抠很多技术细节，包括写代码。因为我心里觉得，不写代码的人一定是做不好技术管理的，因为做技术管理有人要做技术决定，从不上手技术的人是做不好技术决定的，另一方面，我觉得管理是支持性的工作，不是产出性的工作，大多数的管理者无非是因为组织大了，所以需要管人管事，所以，必然要花大量的时间和精力处理各种问题，甚至办公室政治，然而，如果有一天失业了，大环境变得不好了，一个管理者和一个程序员要出去找工作，程序员会比管理者更能自食其力。所以，我并不觉得管理者这个职业有意思，我还是觉得程序员这个有创造性的职业更有趣。<strong>通常来说，管理者的技能力需要到公司和组织里才能展现，而有创造力的技能的人是可以自己独立的能力，所以，我觉得程序员的技能比管理者的技能能让我更稳定更自地活着</strong>。所以，我更喜欢“<a href="https://coolshell.cn/articles/4951.html" target="_blank" rel="noopener">电影工作组</a>”那样的团队和组织形式。</p><p><strong>打工</strong>。对于打工，也就是加入一家公司工作，无论是在一家小公司还是一家大公司工作，都会有好的和不好的，任何公司都有其不完美的地方，这个需要承认。首先第一的肯定是完成公司交给你的任务（但我也不会是傻傻地完成工作，对于一些有问题的任务我也会提出我的看法），然后我会尽我所能在工作找到可以提高效率的地方进行改善。在推动公司/部门/团队在一技术和工程方面进步并不是一件很容易的事，因为进步是需要成本的，有时候，这种成本并不一定是公司和团队愿意接受的，而另外，从客观规律上来说，一件事的进步一定是会有和现状有一些摩擦的。有的人害怕有摩擦而忍了，而我则不是，我觉得与别人的摩擦并不可怕，因为大家的目标都是基本一致的，只是做事的标准和方式不一样，这是可能沟通的，始终是会相互理解的。而如果你没有去推动一个事，我觉得对于公司对于我个人来说，都是一种对人生的浪费，敬业也好，激情也好，其就是体现在你是否愿意冒险去推动一件于公于私都有利的事，而不是成为一个“听话”、“随大流”、“懒政”的人，即耽误了公司也耽误了自己。所以，我更信仰的是《<a href="http://www.aqee.net/post/do-the-right-thing-wait-to-get-fired.html" target="_blank" rel="noopener">做正确的事情，等着被开除</a>》，这些东西，可参看《<a href="https://coolshell.cn/articles/17972.html" target="_blank" rel="noopener">我看绩效考核</a>》，以及我在<a href="https://mp.weixin.qq.com/s?__biz=MzUyOTA1NTkzNw==&amp;mid=2247484417&amp;idx=1&amp;sn=316f9f6d6ac7cdca97123815a67a665a&amp;chksm=fa67adafcd1024b948caed0e5528c4817a7ef2b1b1a3ab8da34e0ff4231b28c2659ee9951112#rd" target="_blank" rel="noopener">Gitchat上的一些问答</a>。</p><p><strong>创业</strong>。前两天，有个小伙来跟我说，说他要离开BAT要去创业公司了，说在那些更自由一些，没有大公司的种种问题。我毫不犹豫地教育了他一下，我说，你选择这个创业公司的动机不对啊，你无非就是在逃避一些东西罢了，你把创业公司当做是一个避风港，这是不对的，创业公司的问题可能会更多，去创业公司的更好的心态是，这个创业公司在干的事业是不是你的事业？说白了，如果你是为了你的事业，为了解决个什么，为了改进个什么，那么，创业是适合你的，<strong>也只有在做自己事业的时候，你才能不惧困难，才会勇敢地面对一切</strong>。<strong>那种想找一个安稳的避风港呆着的心态是不会让你平静地，你要知道世界本来就是不平静的，找了自己的归宿和目标才可能让你真正的平静</strong>。所以，在我现的创业团队，我不要求大家加班，我也不鸡汤洗脑，对于想要加入的人，我会跟他讲我现在遇到的各种问题以及各种机遇，并一直在让他自己思考，我们在做的事是不是自己的事业诉求？还可不可以更好？<strong>每个人都应该为自己的事业为自己的理想去活一次，追逐自己的事业和理想并不容易，需要有很大的付出，而也只有你心底里的那个理想值得这么大的付出</strong>……</p><p><strong>客户</strong>。基于上述的价值观，在我现在创业的时候，我在面对客户的时候，也是一样的，我并不会完全的迁就于客户，我的一些银行客户和互联网客户应该体会到我的做的方式了，我并不觉得迁就用户，用户要什么我就应该给什么，用户想听什么，我就说什么，虽然这样可以省着精力，更圆滑，但这都不是我喜欢的，<strong>我更愿意鲜明地表达我的观点，并拉着用户跟我一起成长，因为我并不觉得完成客户的项目有成就感，我的成就感来自客户的成长</strong>。所以，面对客户有些做得不对有问题有隐患的地方，或是有什么做错的事，我基本上都是直言不讳地说出来，因为我觉得把真实的相法说出来是对客户和对自己最基本的尊重，不管客户最终的选择是什么，我都要把利弊跟客户讲清楚。我并不是在这里装，因为，我也想做一些更高级更有技术含量的事，所以，对于一些还达到的客户，我如果不把他们拉上来，我也对不起自己。</p><p>在我“不惑之年”形成了这些价值观体系，也许未来还会变，也许还不成熟，总之，我不愿跟大多数人一样，因为大多数人都是随遇而安随大流的，因为这样风险最小，而我想走一条属于自己的路，做真正的自己，就像我24岁从银行里出来时想的那样，<strong>我选择对了一个正确的专业（计算机科学），呆在了一个正确的年代（信息化革命），这样的“狗屎运”几百年不遇，如果我还患得患失，那我岂不辜负活在这样一个刺激的时代？！我所要做的就是在这个时代中做有价值的事就好了！这个时代真的是太好了！</strong></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;谈谈我的三观&lt;/p&gt;
&lt;p&gt;酷 壳 - CoolShell&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://coolshell.cn/articles/19085.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://coolshell.
      
    
    </summary>
    
      <category term="胡说八道" scheme="http://zhangyu33.com/categories/%E8%83%A1%E8%AF%B4%E5%85%AB%E9%81%93/"/>
    
    
      <category term="胡说八道" scheme="http://zhangyu33.com/tags/%E8%83%A1%E8%AF%B4%E5%85%AB%E9%81%93/"/>
    
  </entry>
  
  <entry>
    <title>2019运维技能风向标</title>
    <link href="http://zhangyu33.com/2019/02/27/2019%E8%BF%90%E7%BB%B4%E6%8A%80%E8%83%BD%E9%A3%8E%E5%90%91%E6%A0%87/"/>
    <id>http://zhangyu33.com/2019/02/27/2019运维技能风向标/</id>
    <published>2019-02-26T16:00:00.000Z</published>
    <updated>2019-02-27T10:12:20.016Z</updated>
    
    <content type="html"><![CDATA[<p>2019运维技能风向标</p><p><a href="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://blog.51cto.com/ixdba/2338362" target="_blank" rel="noopener">http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://blog.51cto.com/ixdba/2338362</a></p><blockquote><p>运维是一个融合多学科(网络、系统、开发、安全、应用架构、存储等)的综合性技术岗位，从最初的网络管理（网管）发展到现在的系统运维工程师、网络运维工程师、安全运维工程师、运维开发工程师等，可以看出，运维的分工一直在细化，并且对综合技能要求越来越高，可以看出，未来运维的发展趋势是高、精、尖，高表示高度，精表示精通，尖表示尖端，也就是运维职场一定要站在一定的技术高度，在多个技术领域中，要精通某项技能，同时对尖端前沿技术一定要能掌控趋势。</p><h2 id="一、运维职位的发展和趋势"><a href="#一、运维职位的发展和趋势" class="headerlink" title="一、运维职位的发展和趋势"></a>一、运维职位的发展和趋势</h2><p>根据不同的运维领域和技术面以及分工流程三个方面来了解下2019年运维职位的发展趋势。</p><h3 id="1、按领域来划分"><a href="#1、按领域来划分" class="headerlink" title="1、按领域来划分"></a>1、按领域来划分</h3><p>1）、基础设施运维：IDC/网络运维、服务器/存储设备运维<br>2）、系统运维：系统中间件运维、云计算平台运维<br>3）、数据运维：数据库运维、大数据技术平台运维<br>4）、应用运维：应用软件系统<br>5）、云平台运维：公有云平台运维<br>6）、容器运维：基于容器服务的运维</p><h3 id="2、按技术切面来分"><a href="#2、按技术切面来分" class="headerlink" title="2、按技术切面来分"></a>2、按技术切面来分</h3><p>1）、安全运维<br>2）、性能运维<br>3）、数据运维<br>4）、集成运维</p><h3 id="3、按流程来划分"><a href="#3、按流程来划分" class="headerlink" title="3、按流程来划分"></a>3、按流程来划分</h3><p>1）、构建/持续集成、发布<br>2）、安装部署、升级、迁移、合并、扩展<br>3）、配置、初始化、配置变更<br>4）、备份、传输、恢复<br>5）、日志、监控、预警<br>6）、诊断排查、优化</p><h2 id="二、系统运维技能图谱"><a href="#二、系统运维技能图谱" class="headerlink" title="二、系统运维技能图谱"></a>二、系统运维技能图谱</h2><p>系统运维是运维的基础，新的一年中，对基础运维技能要求也在提高，打好系统运维基础，才能深入学习后面的各种运维技能。</p><p>下图列出了系统运维要掌握的必备技能：</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201901/04/aceccbfc12aa1334ec232bc960452948.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=" alt=""></p><h2 id="三、web运维技能图谱"><a href="#三、web运维技能图谱" class="headerlink" title="三、web运维技能图谱"></a>三、web运维技能图谱</h2><p>web运维是运维岗位中岗位最多的一个，薪资也相对较高，但需要掌握的知识点也比较多，新的技能要掌握，老的运维技能也不能丢，下图列出了web运维要掌握的各种必备技能。</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201901/04/8a6bb665472eb9fbf74b6367c91f0bb4.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=" alt=""></p><h2 id="四、大数据运维技能图谱"><a href="#四、大数据运维技能图谱" class="headerlink" title="四、大数据运维技能图谱"></a>四、大数据运维技能图谱</h2><p>大数据从2017年开始逐渐走到生活的各个角落，2018年在逐渐落地，而在2019年，大数据依然火热，加上国家对大数据产业的扶持，大数据产业在新的一年岗位需求一定会更加大，因此掌握大数据运维技能，就走在了运维的前沿，下图列出了大数据运维要掌握的各种必备技能。</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201901/04/c20162d6a930e86e9916af86120f1b5d.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=" alt=""></p><h2 id="五、容器运维技能图谱"><a href="#五、容器运维技能图谱" class="headerlink" title="五、容器运维技能图谱"></a>五、容器运维技能图谱</h2><p>容器的产生，是一次IT行业的革命，2015 年到 2016 年，是业界普遍认为的容器技术爆发的一年，短短一年多时间里，容器技术在中国大陆完成了从零星概念到烽火燎原的壮举。</p><p>时至今日，容器技术在国内大多数企业中落地已成为一种共识，而国内的生态系统，也呈现出了企业产品、开源社区和公有云齐头并进的良好局面。因此，2019年也是容器继续快速落地的一年，下图列出了大数据运维要掌握的各种必备技能。</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201901/04/51af4c346b4711b68eae808fc9ddb58c.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=" alt=""></p><h2 id="六、数据为王的时代"><a href="#六、数据为王的时代" class="headerlink" title="六、数据为王的时代"></a>六、数据为王的时代</h2><p>万丈高楼平地起，高楼稳不稳取决于地基是否扎实。运维数据便是运维管理这座高楼的地基。运维数据大致分为CMDB、日志、生产DB、知识库四个方面。</p><blockquote><ul><li><p>CMDB中文是配置管理数据库，存储与管理企业IT架构中设备的各种配置信息，主要是IT资产管理信息。</p></li><li><p>日志数据保护了企业服务器上运行的各种系统产生的应用日志，系统日志、设备日志、数据库日志等数据，这部分数据是企业数据的核心。</p></li><li><p>DB数据主要是所有IT系统的数据库信息，包括运维管理系统本身的数据库，数据库包含生产数据库、测试数据库、开发数据库三种类型。</p></li><li><p>知识库主要存储日常开发、测试、运维管理中发生的事件、问题以及一些经典问题的解决和常用的解决方案，主要起到运维管理辅助的功能。</p></li></ul></blockquote><p>对数据的维护和管理只管重要，特别是日志数据，对运维来说，通过日志可以比较准确全面地知道系统或是设备的运行情况，可以返查问题产生的原因，还原问题发生的整个过程。通过日志也可以提前预测系统可能要发生的问题或是故障，如系统安全日志，如果网络攻 击会在系统安全日志中有一定的体现。</p><p>下面简单介绍下，运维重点收集的日志数据有哪些部分以及用途。</p><h3 id="1、系统日志"><a href="#1、系统日志" class="headerlink" title="1、系统日志"></a>1、系统日志</h3><p>系统日志主要指的是操作系统的日志，主要在/var/log下的各种日志信息。包含系统操作日志、系统安全日志、定时任务日志等。系统日志是运维管理安全模块中审计的重要依据。一般默认的操作系统日志不能满足要求，需要对系统的参数进行修改，如为history命令加上时间戳、IP，并且长久保留历史等功能。并且对日志文件进行处理，不允许用户进行清空命令，只能追加。</p><h3 id="2、应用日志"><a href="#2、应用日志" class="headerlink" title="2、应用日志"></a>2、应用日志</h3><p>应用日志主要记录应用服务的健康运行情况以及业务操作的具体日志两部分。应用监控运行情况反应应用服务的健康状态，如果应用占用CPU或是内存过高或是忽高忽低不定，都可以通过分析应用日志结合业务操作日志得出结论。业务操作日志可以为业务审计提供主要依据。有一些系统喜欢把业务操作日志写到数据库中，这个也是需要注意的。不过不管在哪个地方，要求是不可缺少的，它为以后业务审计和问题返查提供依据。</p><h3 id="3、数据库日志"><a href="#3、数据库日志" class="headerlink" title="3、数据库日志"></a>3、数据库日志</h3><p>数据库日志主要反馈数据库的运行情况。通过监控和管理数据库的日志，及时了解数据库的运行情况，遇到问题及时解决等。可以通过数据库日志结合数据库系统自带的数据库如Oracle的系统视图v$开头，MySQL的performance_schema等。虽然数据库的一些信息不是存在日志中而是在数据库里面，但是也可以作为数据库日志的一部分进行管理和监控，已便我们及时知道数据库的监控状况，从而预防可能出现的问题。</p><h3 id="4、设备日志"><a href="#4、设备日志" class="headerlink" title="4、设备日志"></a>4、设备日志</h3><p>设备日志一般是一个比较容易忽略的地方，但设备日志往往可以反映设备的运行情况。交换机故障，防火墙故障等设备故障都可能引起大面积的系统和服务故障。所以设备日志一定要收集，分析和监控预警。常用的设备日志有交换机日志、防火墙日志、网络安全设备日志等。</p><p>这么多的日志，运维要通过各种手段完成日志的收集、过滤分析、可视化展示，那么如何实现这些功能呢，方法很多，例如ELK集成套件（Elasticsearch , Logstash, Kibana）就可以轻松实现日志数据的实时收集、分析传输以及图形化展示。</p><blockquote><ul><li><p>Elasticsearch是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。</p></li><li><p>Logstash主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式。一般工作方式为c/s架构，client端安装在需要收集日志的主机上，server端负责将收到的各节点日志进行过滤、修改等操作在一并发往elasticsearch上去。</p></li><li><p>Kibana 也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。</p></li></ul></blockquote><p>另外，还有Filebeat可以替换Logstash作为日志收集工具，Filebeat隶属于Beats。目前Beats包含四种工具：</p><blockquote><p>Packetbeat（搜集网络流量数据）<br>Topbeat（搜集系统、进程和文件系统级别的 CPU 和内存使用情况等数据）<br>Filebeat（搜集文件数据）<br>Winlogbeat（搜集Windows事件日志数据）</p></blockquote><p>可以看到，Beats涵盖了所有收集日志数据的各个方面。</p><p>那么要如何使用ELK呢，根据日志量的不同，对应的ELK架构也不尽相同，看下面几个常见架构：</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201901/03/39e84f4e6f6df0b5f95439dd60549a2c.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=" alt=""></p><p>此架构主要是将Logstash部署在各个节点上搜集相关日志、数据，并经过分析、过滤后发送给远端服务器上的Elasticsearch进行存储。Elasticsearch再将数据以分片的形式压缩存储，并提供多种API供用户查询、操作。用户可以通过Kibana Web直观的对日志进行查询，并根据需求生成数据报表。<br>此架构的优点是搭建简单，易于上手。缺点是Logstash消耗系统资源比较大，运行时占用CPU和内存资源较高。另外，由于没有消息队列缓存，可能存在数据丢失的风险。此架构建议供初学者或数据量小的环境使用。</p><p>由此衍生出来了第二种架构：</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201901/03/6e3c45e35972df117c08252aecaed9d0.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=" alt=""></p><p>此架构主要特点是引入了消息队列机制，位于各个节点上的Logstash Agent（一级Logstash，主要用来传输数据）先将数据传递给消息队列（常见的有Kafka、Redis等），接着，Logstash server（二级Logstash，主要用来拉取消息队列数据，过滤并分析数据）将格式化的数据传递给Elasticsearch进行存储。最后，由Kibana将日志和数据呈现给用户。由于引入了Kafka（或者Redis）缓存机制，即使远端Logstash server因故障停止运行，数据也不会丢失，因为数据已经被存储下来了。</p><p>这种架构适合于较大集群、数据量一般的应用环境，但由于二级Logstash要分析处理大量数据，同时Elasticsearch也要存储和索引大量数据，因此它们的负荷会比较重，解决的方法是将它们配置为集群模式，以分担负载。</p><p>此架构的优点在于引入了消息队列机制，均衡了网络传输，从而降低了网络闭塞尤其是丢失数据的可能性，但依然存在Logstash占用系统资源过多的问题，在海量数据应用场景下，可能会出现性能瓶颈。</p><p>最后，还有第三种架构：</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201901/03/d8d817a64ddfa9fa98d85f7382b7bf1e.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=" alt=""></p><p>这个架构是在上面第二个架构基础上改进而来的，主要是将前端收集数据的Logstash Agent换成了filebeat，消息队列使用了kafka集群，然后将Logstash和Elasticsearch都通过集群模式进行构建，此架构适合大型集群、海量数据的业务场景，它通过将前端Logstash Agent替换成filebeat，有效降低了收集日志对业务系统资源的消耗。同时，消息队列使用kafka集群架构，有效保障了收集数据的安全性和稳定性，而后端Logstash和Elasticsearch均采用集群模式搭建，从整体上提高了ELK系统的高效性、扩展性和吞吐量。</p><h2 id="三、用大数据思维做运维监控"><a href="#三、用大数据思维做运维监控" class="headerlink" title="三、用大数据思维做运维监控"></a>三、用大数据思维做运维监控</h2><p>大数据分析最早就来源于运维人的日志分析，到逐渐发展对各种业务的分析，人们发现这些数据蕴涵着非常大的价值，通过实时监测、跟踪研究对象在互联网上产生的海量行为数据，进行挖掘分析，揭示出规律性的东西，提出研究结论和对策。这就是大数据的用途。</p><p>同样，通过大数据分析，我们可以得到各种指标，例如：</p><p>1、在业务层面，如团购业务每秒访问数，团购券每秒验券数，每分钟支付、创建订单等。</p><p>2、在应用层面，每个应用的错误数，调用过程，访问的平均耗时，最大耗时，95线等</p><p>3、在系统资源层面：如cpu、内存、swap、磁盘、load、主进程存活等</p><p>4、在网络层面： 如丢包、ping存活、流量、tcp连接数等</p><p>而这些指标，刚好是运维特别需要的东西。通过大数据分析出的这些指标，可以解决如下方面的问题：</p><blockquote><p>系统健康状况监控<br>查找故障根源<br>系统瓶颈诊断和调优<br>追踪安全相关问题</p></blockquote><p>那么如何用大数据思维做运维呢，大数据架构上的一个思维就是：提供一个平台让运维方便解决这些问题， 而不是，让大数据平台去解决出现的问题。</p><p>基本的一个大数据运维架构是这样的：</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201901/03/9538a93fd4823503b00dff94658e9a50.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=" alt=""></p><p>对于运维的监控，利用大数据思维，需要分三步走：</p><blockquote><p>获取需要的数据<br>过滤出异常数据并设置告警阀值<br>通过第三方监控平台进行告警</p></blockquote><p>所有系统最可靠的就是日志输出，系统是不是正常，发生了什么情况，我们以前是出了问题去查日志，或者自己写个脚本定时去分析。现在这些事情都可以整合到一个已有的平台上，我们唯一要做的就是定义分析日志的的逻辑。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;2019运维技能风向标&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;amp;url=https://blog.51cto.com/ixdba/2338362&quot; targ
      
    
    </summary>
    
      <category term="运维" scheme="http://zhangyu33.com/categories/ops/"/>
    
    
      <category term="运维" scheme="http://zhangyu33.com/tags/%E8%BF%90%E7%BB%B4/"/>
    
  </entry>
  
  <entry>
    <title>一小时快速掌握zabbix配置的高效学习法</title>
    <link href="http://zhangyu33.com/2019/02/27/%E4%B8%80%E5%B0%8F%E6%97%B6%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1zabbix%E9%85%8D%E7%BD%AE%E7%9A%84%E9%AB%98%E6%95%88%E5%AD%A6%E4%B9%A0%E6%B3%95/"/>
    <id>http://zhangyu33.com/2019/02/27/一小时快速掌握zabbix配置的高效学习法/</id>
    <published>2019-02-26T16:00:00.000Z</published>
    <updated>2019-02-27T10:12:09.964Z</updated>
    
    <content type="html"><![CDATA[<p>一小时快速掌握zabbix配置的高效学习法</p><p><a href="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://blog.51cto.com/ixdba/2346602" target="_blank" rel="noopener">http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://blog.51cto.com/ixdba/2346602</a></p><blockquote><p>有人说zabbix难点在配置，面对很多的配置项，不知道所以然了，其实我觉得这是没掌握好zabbix的学习方法，要掌握了zabbix的学习思路，可以在一个小时内快速掌握zabbix的各种配置，下面我将重点讲述下如何快速、高效的对zabbix进行配置，已完成zabbix灵活的监控功能。</p><p>zabbix的配置全部都在zabbix web上完成，这点我非常喜欢，登录到zabbix web平台后，默认是英文界面，不过可以切换为中文界面，选择导航栏中的“Administration”选项，然后选择二级标签“Users”选项，在“Users”选项下列出了当前zabbix的用户信息，默认只有一个管理员用户Admin可用于登录zabbix web，点开Admin用户，进入属性设置界面，然后在“Language”选项中找到“Chinese（zh_CN）”选中即可切换到中文界面，刷新浏览器即可看到效果。</p><p>下面就以zabbix的中文界面为主进行介绍，所有涉及到的截图和内容描述都以zabbix中文界面显示作为标准。</p><h2 id="1-1、模板的管理与使用"><a href="#1-1、模板的管理与使用" class="headerlink" title="1.1、模板的管理与使用"></a>1.1、模板的管理与使用</h2><p>模板是zabbix的核心，因为模板集成了所有要监控的内容以及展示的图形等等，zabbix的安装部署完成后，自带了很多模板（网络设备模板、操作系统模板、常见应用软件模板），这些模板能够满足我们80%左右的应用需要，所以一般情况下不需要我们单独创建模板了。</p><p>点击web上面的“配置”选项，然后选择“模板”，就可以看到很多默认的模板，而模板是有多个内置项目组成的，基本的内置项目有应用集、监控项、触发器、图形、聚合图形、自动发现、Web监测、链接的模板等这8个部分组成。在这8个部分中，监控项、触发器、图形、自动发现这4个部分是重点，也是难点。下面也会重点介绍着四个部分的具体实现过程。</p><p>在zabbix自带的模板中，大部分是可以直接拿来使用的，这里我们不需要对每个模板都进行了解，只需要对常用的一些模板重点掌握就行了。</p><h2 id="1-2、创建应用集"><a href="#1-2、创建应用集" class="headerlink" title="1.2、创建应用集"></a>1.2、创建应用集</h2><p>点击web上面的“配置”选项，然后选择“模板”，任意选择一个模块，或者新建一个模板，在模板下，可以看到有应用集选项。进入应用集后，可以看到已有的应用集，也可以创建新的应用集。</p><p>应用集的创建很简单，它其实是一个模板中，针对一类监控项的集合，例如要对CPU的属性进行监控，那么可以创建一个针对CPU的应用集，这个应用集下可以创建针对CPU的多个监控项。</p><p>应用集的出现主要是便于对监控项进行分类和管理，在有多个监控项，多种监控类型需要监控的情况下，就需要创建应用集。</p><p>这里以“Template OS Linux”模板为例，进入此模板后，点开应用集，可以发现已经存在多个应用集，如下图所示：<br><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/0111d2e557eb3058897d82818f5524e7.png" alt=""></p><p>如果有新的监控项需要加入，还可以点击右上角的“创建应用集”创建一个新的应用集。</p><h2 id="1-3、创建监控项"><a href="#1-3、创建监控项" class="headerlink" title="1.3、创建监控项"></a>1.3、创建监控项</h2><p>点击web上面的“配置”选项，然后选择“模板”，任意选择一个模块，或者新建一个模板，在模板下，可以看到有监控项选项。</p><p>监控项是zabbix监控的基础，默认的模板下都存在了很多监控项，这里以“Template OS Linux”模板为例，进入此模板后，点开监控项，可以发现已经存在多个监控项，如下图所示：<br><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/5e26977140f9cc6a61934a5a49393799.png" alt=""></p><p>从图中可以看出，默认的监控项的内容，每个监控项都对应一个键值，就是具体要监控的内容，键值的写法是有统一规范的，zabbix针对不同监控项自带了很多键值，用户也可以自定义键值，此外，每个监控项还可以添加对应的触发器，也就是说这个监控项如果需要告警的话，就可以添加一个触发器，触发器专门用来触发告警。当然不是说每个监控项一定要有一个触发器，需要根据监控项的内容而定。</p><p>点击右上角的“创建监控项”，开始创建一个自定义监控项，如下图所示：<br><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/9c4e08662d77ab46e9ce7e9523402178.png" alt=""></p><p>在这个界面中，重点是红框标识出来的几个地方，首先，“名称”是创建的监控项的名称，自定义一个即可，但是要能表达其监控项的含义，第二个“类型”是设置此监控项通过什么方式进行监控，zabbix可选的监控类型有很多，常用的有zabbix客户端、zabbix客户端（主动式）、简单检查、SNMP客户端、zabbix采集器等类型，zabbix客户端监控也称为zabbix客户端（被动式）监控，就是通过在要监控的机器上安装zabbix agent，然后zabbix server主动去agent上抓取数据来实现的监控，这是最常用的监控类型。而zabbix客户端（主动式）监控也需要在被监控的机器上安装zabbix agent，只不过zabbix agent会主动汇报数据到zabbix server，这是与zabbix客户端（被动式）监控不同的地方。</p><p>接着下来就是对“键值”的设置，这是个难点，键值可以使用zabbix默认自带的，也可以自定义自己的键值，zabbix自带了很多键值，可满足我们90%的需求，比如这里我们想对服务器上某个端口的状态做监控，就可以使用“net.tcp.service.perf[service,<ip>,<port>]”这个键值，此键值就是zabbix自带的，如果要查看更多zabbix自带键值，可以点击上图中“键值”选项后面的“选择”按钮，zabbix自带的键值就可以全部显示出来，如下图所示：</port></ip></p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/017325111e7eef0598dac335aa7f45a0.png" alt=""></p><p>可以看到，zabbix自带的键值根据监控类型的不同，也分了不同的监控键值种类，每个键值的含义也都做了很详细的描述，我们可以根据需要的监控内容，选择对应的键值即可。</p><p>“net.tcp.service.perf[service,<ip>,<port>]”这个键值用来检查TCP服务的性能，当服务down时返回0，否则，返回连接服务花费的秒数，此键值既可用在“zabbix客户端”类型的监控中，也可用在“简单监控”类型中。</port></ip></p><p>这个键值中，“net.tcp.service.perf”部分是键值的名称，后面中括号中的内容是键值的监控选项，每个选项含义如下：</p><blockquote><ul><li><p>service：表示服务名，包含ssh、ntp、 ldap、 smtp、ftp、http、pop、 nntp、imap、 tcp、 <a href="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https、telnet" target="_blank" rel="noopener">http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https、telnet</a></p></li><li><p>ip：表示IP地址，默认是127.0.0.1，可留空。</p></li><li><p>port：表示端口，默认情况为每个服务对应的标准端口，例如ssh服务是22端口等。</p></li></ul></blockquote><p>比如要监控某个或某批服务器80端口的运行状态，可以设置如下键值：</p><p>net.tcp.service.perf[http,,80]</p><p>此键值返回的信息类型是浮点型的，因此，在“信息类型”中要选择“浮点数”。在创建监控项中，还有一个“更新间隔”，这个是用来设置多久去更新一次监控数据，可根据对监控项灵敏度的需求来设定，默认是30秒更新一次。</p><p>在创建监控项的最后，还有一个应用集的选择，也就是将这个监控项放到哪个监控分类中，可以选择已存在的应用集，也可以添加一个新的应用集。</p><p>所有设置完成后，最后点击“添加”即可完成一个监控项的添加。</p><blockquote><p>监控项可以添加到一个已经存在的模板中，也可以在一个新创建的模板中添加监控项，还可以在一个主机下创建监控项，推荐的做法是新建一个模板，然后在此模板下添加需要的应用集、监控项，然后在后面添加主机的时候，将这个创建的模板链接到主机下即可。不推荐在主机下创建监控项的原因是，如果有多个主机，每个主机都有相同的监控内容，那么就需要在每个主机下都创建相同的监控项。</p></blockquote><p><strong>因此，构建zabbix监控，推荐的做法是，首先创建一个模板，然后在此模板下创建需要的监控项、触发器等内容，最后在添加主机时直接将此模板链接到每个主机下即可，这样，每个主机就自动链接上了模板中的所有监控项和触发器。</strong></p><h2 id="1-4、创建触发器"><a href="#1-4、创建触发器" class="headerlink" title="1.4、创建触发器"></a>1.4、创建触发器</h2><p>触发器是用于故障告警的一个设置，将一个监控项添加触发器后，此监控项如果出现问题，就会出激活触发器，然后触发器将自动连接告警动作，最后触发告警。</p><p>触发器同样也推荐在模板中进行创建，点击web上面的“配置”选项，然后选择“模板”，任意选择一个模块，或者新建一个模板，在模板下，可以看到有触发器选项。</p><p>点击触发器，可以看到有默认存在的触发器，如下图所示：<br><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/8562363cde9a35211265bc5f38dc6e5d.png" alt=""></p><p>从图中可以看到，有触发器的严重级别，触发器名称，触发器表达式等几个小选项，这里面难点是触发器表达式的编写，要学会写触发器表达式，首先需要了解表达式中常用的一些函数及其含义。</p><p>在上图我们看到，有diff、avg、last、nodata等这些标识，这就是触发器表达式中的函数，下面就介绍下常用的一些触发器表达式函数及其含义。</p><p>1、diff</p><p>参数：不需要参数<br>支持值类型：float,int,str,text,log<br>作用：返回值为1表示最近的值与之前的值不同，即值发生变化，0表示无变化。</p><p>2、last</p><p>参数：#num<br>支持值类型：float,int,str,text,log<br>作用：获取最近的值，“#num”表示最近第N个值，请注意当前的#num和其他一些函数的#num的意思是不同的，例如：<br>last(0)或last()等价于last(#1)，表示获取最新的值，last(#3)表示最近第3个值（并不是最近的三个值），注意，last函数使用不同的参数将会得到不同的值，#2表示倒数第二新的数据。例入从老到最新值为1,2,3,4,5,6,7,8,9,10，last(#2)得到的值为9，last(#9)得到的值为2。<br>另外，last函数必须包含参数。</p><p>3、avg</p><p>参数：秒或#num<br>支持类型：float,int<br>作用：返回一段时间的平均值<br>例如，avg(5)表示最后5秒的平均值，avg(#5）表示最近5次得到值的平均值，avg(3600,86400）表示一天前的一个小时的平均值。<br>如果仅有一个参数，表示指定时间的平均值，从现在开始算起，如果有第二个参数，表示漂移，从第二个参数前开始算时间，#n表示最近n次的值。</p><p>4、change</p><p>参数：无需参数<br>支持类型：float,int,str,text,log<br>作用：返回最近获得值与之前获得值的差值，返回字符串0表示相等，1表示不同。<br>例如，change(0)&gt;n表示最近得到的值与上一个值的差值大于n，其中，0表示忽略参数。</p><p>5、nodata</p><p>参数：秒<br>支持值类型：any<br>作业：探测是否能接收到数据，当返回值为1表示指定的间隔(间隔不应小于30秒)没有接收到数据，0表示其正常接收数据。</p><p>在了解了触发器表达式函数的含义之后，我们就可以创建和编写触发器表达式了，在触发器页面中，添加右上角的“创建触发器”即可进入触发器创建页面了，如下图所示：<br><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/f7023bfec63aa226adb88fadb4df55be.png" alt=""></p><p>这个就是创建触发器的页面，首先输入触发器的名称，然后标记触发器的严重性，可以有6个等级选择，这里选择一般严重，接下来就是表达式的编写了，点击表达式项后面的“添加”按钮，即可开始构建表达式了，在构建表达式页面，首先要选择给哪个监控项添加触发器，在“条件”界面下点击后面的“选择”按钮，即可打开已经添加好的所有监控项，这里就选择刚刚添加好的“httpd server 80 status”这个监控项，接着，开始选择触发器表达式的条件，也就是上面介绍过的触发器表达式函数，点击“功能”下拉菜单，可以发现很多触发器表达式函数，那么如何选择函数呢，当然是根据这个监控项的含义和监控返回值。</p><p>“httpd server 80 status”这个监控项的返回值是浮点数，当服务故障时返回0，当监控的服务正常时返回连接服务所花费的秒数。因此，我们就将返回0作为一个判断的标准，也就是将返回值为0作为触发器表达式的条件，要获得监控项的最新返回值，那就是使用last（）函数，因此选择last()函数，接着，还有有个“间隔（秒）”选项，这个保持默认即可，重点是最后这个“结果”，这里是设置last()函数返回值是多少时才进行触发，根据前面对监控项的了解，last()函数返回0表示服务故障，因此这里填上0即可。</p><p>这样，一个触发器表达式就创建完成了，完整的触发器表达式内容是：</p><p>{Template OS Linux:net.tcp.service.perf[http,,80].last()}=0</p><p>可以看出，触发器表达式由4部分组成，第一部分是模板或主机的名称，第二部分是监控项对应的键值，第三部分是触发器表达式函数，最后一部分就是监控项的值。这个表达式所表示的含义是：http服务的80端口获取到的最新值如果等于0，那么这个表达式就成立，或者返回true。</p><p>触发器创建完成后，两个监控的核心基本就完成了，后面还有创建“图形”、“聚合图形”等选项，这些都比较简单，就不过多介绍了。</p><h2 id="1-5、创建主机组和主机"><a href="#1-5、创建主机组和主机" class="headerlink" title="1.5、创建主机组和主机"></a>1.5、创建主机组和主机</h2><p>点击web上面的“配置”选项，然后选择“主机群组”，即可到添加主机群组界面，默认情况下，已经有很多主机群组了，可以使用已经存在的主机群组，也可以创建新的主机群组，点击右上角“创建主机群组”可以创建一个新的群组，主机群组要先于主机创建，因为在主机创建界面中，已经没有创建群组的选项了。</p><p>主机群组创建完成后，点击web上面的“配置”选项，然后选择“主机”，即可到添加主机界面，默认情况下，只有一个zabbix server主机，要添加主机，点击右上角“创建主机”按钮，即可进入如下页面：<br><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/2c9a224063ac5a57f94b94e11e0c8b3e.png" alt=""></p><p>主机的创建很简单，需要重点关注红框标注的内容，首先，“主机名称”这个需要特别注意，可以填写主机名，也可以写IP地址，但是都要和zabbix agent主机配置文件zabbix_agent.conf里面的Hostname配置的内容一致才行。</p><p>“群组”就是指定主机在哪个主机群组里面，点击后面的“选择”即可查看目前的主机群组，选择一个即可，最后要添加的是“agent代理程序接口”，也就是zabbix server从哪个地址去获取zabbix agent的监控数据，这里填写的是zabbix agent的ip地址和端口号，此外，根据监控方式的不同，zabbix支持多种获取监控数据的方式，支持SNMP接口、JMX接口、IPMI接口等，可根据监控方式不同选择需要的接口即可。</p><p>主机的设置项主要就这几个，最后还需要设置主机链接的模板，点击主机下面的“模板”标签，即可显示主机和模板的链接界面，如下图所示：</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/1d5f34cd48d29352a701cac55ac9c4ae.png" alt=""></p><p>点击“链接指示器”后面的“选择”按钮，即可显示上图的界面，这里可以选择要将哪些模板链接到此主机下，根据模板的用途，这里我们选择了“Template OS Linux”模板，当然也可以选择多个模板连接到同一个主机下，选择完成，点击“选择”即可回到下图所示界面：</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/ad76108fcf9024f03bae8b4ab08115dd.png" alt=""></p><p>这个界面的操作需要小心，在刚刚添加了模板后，需要先点击上面的那个“添加”按钮，这样刚才选择的模板才能生效，最后在点击最下面的“添加”按钮，172.16.213.232主机添加完成。</p><p>最后，点击刚刚创建好的主机，即可进入主机编辑模式，可以看到，在主机下，已经有应用集、监控项、触发器、图形等选项和内容了，这就是链接模板后，自动导入到主机下面的，当然在主机编辑界面下也可以创建或修改应用集、监控项、触发器、图形等内容。</p><h2 id="1-6、触发器动作配置"><a href="#1-6、触发器动作配置" class="headerlink" title="1.6、触发器动作配置"></a>1.6、触发器动作配置</h2><p>动作的配置也是zabbix的一个重点，点击web上面的“配置”选项，然后选择“动作”，即可到“动作”设置界面，动作的添加根据事件源的不同，可分为触发器动作、自动发现动作、自动注册动作等，这里首先介绍下触发器动作的配置方式。</p><p>在此界面的右上角，先选择事件源为“触发器”，然后点击“创建动作”按钮，开始创建一个基于触发器的动作，如下图所示：</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/93a0edade3f25dfe3b951da92afaab52.png" alt=""></p><p>触发器动作配置，其实是设置监控项在故障时发出的信息，以及故障恢复后发送的信息设置，动作的“名称”可以随意设置，动作的状态设置为“已启用”，接着点开“操作”标签，此标签就是设置监控项在故障的时候发送信息的标题和消息内容以及一些发送的频率和接收人，如下图所示：<br><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/fac2517fabeabf34deaef862a8fdb488.png" alt=""></p><p>在这个界面中，重点是设置发送消息的“默认操作步骤持续时间”、“默认标题”以及“消息内容”， “默认操作步骤持续时间”就是监控项发生故障后，持续发送故障信息的时间，这个时间范围为”60” 和 “604800” 之间，单位是秒。</p><p>“默认标题”以及“消息内容”是通过zabbix的内置宏变量实现的，例如{TRIGGER.STATUS}、{TRIGGER.SEVERITY}、{TRIGGER.NAME}、{HOST.NAME}等都是zabbix的内置宏变量，不需要加“$”就可以直接引用。这些宏变量会在发送信息的时候转换为具体的内容。</p><p>“默认标题”以及“消息内容”设置完成后，还需配置消息内容的发送频率和接收人，点击上图中“操作”步骤中的“新的”按钮，即可显示如下图界面：<br><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/f6ed85a2d5c25a3b846b9d331b0e4b99.png" alt=""></p><p>在这个设置界面中，重点看操作细节部分，“步骤”是设置发送消息事件的次数，0表示无穷大，也就是持续一直发送，“步骤持续时间”是发送消息事件的间隔，默认值是60秒，输入0也表示默认值，“操作类型”有发送消息和远程命令两个选项，这里选择“发送消息”，“发送到用户群组”和“发送到用户”是指定将消息发送给指定的用户组和用户，一般选择将消息发送到用户群组即可，因为这样更方便，后期有新用户加入的话，直接将此用户加入用户群组中即可，省去了有新用户时每次都要修改消息发送设置的麻烦。最后，还有一个“仅送到”选项，这里是设置将消息通过什么媒介发送，默认有Email、Jabber、SMS三种方式，可以选择所有，也可以选择任意一个，这里选择Email，也就是通过邮件方式发送消息。</p><p>综上所述，这个操作过程表达的意思是：事件的持续时间是1个小时（3600s），每隔1分钟（60s）产生一个消息事件，一共产生3个消息事件，产生消息事件时，发送给Zabbix administrators用户组中的所有用户，最后消息内容会使用Email媒介发送给用户。</p><p>所有设置完成后，一定要点击上图左下角的“添加”按钮，这样刚才的设置才能保存生效。</p><p>接着，再看创建动作中的“恢复操作”标签，如下图所示：</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/72fcbda25b325f5abc5d75ad9a579789.png" alt=""></p><p>“恢复操作”跟“操作”标签类似，是用来设置监控项故障恢复后，发送消息事件的默认标题和消息内容，这两部分就是通过zabbix的内部宏变量实现的，重点看最下面的“操作”选项，点击“新的”按钮，即可打开操作的具体设置界面，如下图所示：</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/29/783ea43d79107e875d4afb5049907fc4.png" alt=""></p><p>这个界面是设置当监控项故障恢复后，向Zabbix administrators用户组中的所有用户通过Email介质发送消息。也就是故障恢复消息。</p><p>最后，还是要点击上图左下角的“添加”按钮，这样刚才的设置才能保存生效。</p><h2 id="1-7、报警媒介类型配置"><a href="#1-7、报警媒介类型配置" class="headerlink" title="1.7、报警媒介类型配置"></a>1.7、报警媒介类型配置</h2><p>报警媒介类型是用来设置监控告警的方式，也就是通过什么方式将告警信息发送出去，常用的告警媒介有很多，例如Email、Jabber、SMS等，这是三种默认方式，还可以扩展到微信告警、钉钉告警等方式，至于选择哪种告警方式，以爱好和习惯来定就行了。</p><p>默认使用较多的是通过Email方式进行消息的发送告警，邮件告警方式的优势是简单、免费，加上现在有很多手机邮件客户端工具（网易邮件大师、QQ邮箱），通过简单的邮件告警设置，几乎可以做到实时收取告警信息。</p><p>点击web上面的“管理”选项，然后选择“报警媒介类型”，即可到报警媒介设置界面，然后点击“Email”进入编辑页面，如下图所示：</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/30/035d3811294d4895d13f87db1bca641f.png" alt=""></p><p>这个界面是设置Email报警属性，“名称”可以是任意名字，这里输入“Email”，“类型”选择“电子邮件”，当然也可以选择“脚本”、“短信”等类型，“SMTP服务器”是设置邮件告警的发件服务器，我们这里使用网易163邮箱进行邮件告警，因此设置为“smtp.163.com”即可，接着是“SMTP”服务器端口，输入默认“25”，“SMTP HELO”可保持默认即可，“SMTP电邮”就是发件人的邮箱地址，输入一个网易163邮箱地址即可，安全连接选择默认的“无”即可，“认证”方式选择“用户名密码”认证，然后输入发件人邮箱登录的用户名和密码即可。</p><p>所有设置完成，点击“添加”按钮完成邮件媒介告警的添加。到这里为止，zabbix中一个监控项的添加流程完成了。</p><p>最后，我们再来梳理下一个监控项添加的流程，一般操作步骤是这样的：</p><p>首先新创建一个模板，或者在默认模板基础上新增监控项、监控项添加完成，接着对此监控项添加一个触发器，如果有必要，还可以对此监控项添加图形，接着，开始添加主机组和主机，在主机中引用已经存在的或新增的模板，然后创建触发器动作，设置消息发送事件，最后，设置报警媒介，配置消息发送的介质，这就是一个完整的zabbix配置过程。</p><h2 id="1-8、监控状态查看"><a href="#1-8、监控状态查看" class="headerlink" title="1.8、监控状态查看"></a>1.8、监控状态查看</h2><p>当一个监控项配置完成后，要如何看是否获取到数据了呢，点击web上面的“监测中”选项，然后选择“最新数据”，即可看到监控项是否获取到了最新数据，如下图所示：<br><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/30/bfcf5c8eb59a755f561073d080bd990d.png" alt=""></p><p>在查看最新监控数据时，可以通过此界面提供的过滤器快速获取想查看的主机或者监控项的内容，这里我们选择“linux servers”主机组，“http server”应用集下所有监控项的数据，点击“应用”按钮，即可显示过滤出来的数据信息，重点看“最新数据”一列的内容，那个“0.0005”就是获取的最新数据，通过不断刷新此页面，可以看到最新数据的变化。如果你的监控项获取不到最新数据，那么显示的结果将会是浅灰色。要想查看一段时间的历史数据，还可以点击右边的那个“图形”链接，即可通过图形方式展示一段时间的数据趋势，如下图所示：</p><p><img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://s1.51cto.com/images/blog/201810/30/23036519791968b63f125154a32c4c4f.png" alt=""></p><p>这个就是监控项“httpd server 80 status”的趋势数据，此图形曲线是自动生成，无需设置，由于我们使用的是中文界面，在图形展示数据的时候，可能会在左下角有中文的地方出现乱码，这是默认编码非中文字体导致的，需要简单做如下处理，过程如下：</p><p>1、进入 C:\Windows\Fonts选择其中任意一种中文字体例如 “黑体” (SIMHEI.TTF)<br>2、将Windows下的中文字体文件上传到zabbix web目录下的fonts目录(本例是/usr/local/nginx/html/zabbix/fonts)<br>3、修改zabbix的web前端的字体设置，将如下两行修改为：<br>打开/usr/local/nginx/html/zabbix/include/defines.inc.php文件，找到如下两行：</p><p>define(‘ZBX_FONT_NAME’, ‘DejaVuSans’);<br>define(‘ZBX_GRAPH_FONT_NAME’, ‘DejaVuSans’);<br>修改为<br>define(‘ZBX_FONT_NAME’,  ‘simhei’);<br>define(‘ZBX_GRAPH_FONT_NAME’,  ‘simhei’);</p><p>其中simhei为字库名字，不用写ttf后缀。这样就行了，刷新一下浏览器，中文字体显示应该就正常了。</p><p>好啦，zabbix的核心配置就这么多，很简单吧，掌握这个学习思路，那zabbix就简单多了。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;一小时快速掌握zabbix配置的高效学习法&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;amp;url=https://blog.51cto.com/ixdba/234
      
    
    </summary>
    
      <category term="zabbix" scheme="http://zhangyu33.com/categories/zabbix/"/>
    
    
      <category term="zabbix" scheme="http://zhangyu33.com/tags/zabbix/"/>
    
  </entry>
  
  <entry>
    <title>学习Kubernetes和容器技术体系的最佳方法</title>
    <link href="http://zhangyu33.com/2019/02/14/%E5%AD%A6%E4%B9%A0Kubernetes%20%E5%92%8C%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E4%BD%93%E7%B3%BB%E7%9A%84%E6%9C%80%E4%BD%B3%E6%96%B9%E6%B3%95/"/>
    <id>http://zhangyu33.com/2019/02/14/学习Kubernetes 和容器技术体系的最佳方法/</id>
    <published>2019-02-13T16:00:00.000Z</published>
    <updated>2019-02-14T09:56:42.811Z</updated>
    
    <content type="html"><![CDATA[<p>学习Kubernetes和容器技术体系的最佳方法</p><p><a href="https://www.infoq.cn/article/3yijOyajjpq-Fg809NIj" target="_blank" rel="noopener">https://www.infoq.cn/article/3yijOyajjpq-Fg809NIj</a>)</p><blockquote><p>你好，我是 Kubernetes 社区资深成员与项目维护者张磊，也是极客时间 《深入剖析 Kubernetes 》的专栏作者。今天我来与你谈一谈，学习 Kubernetes 和容器技术体系的最佳方法，到底是什么。</p><p>我认为，学习一门综合性的技术，不应该着急一头扎进去看源码。理清楚自己的定位，才是最重要的。</p><h2 id="定位一：纯粹的开发人员"><a href="#定位一：纯粹的开发人员" class="headerlink" title="定位一：纯粹的开发人员"></a>定位一：纯粹的开发人员</h2><p>如果你是一位纯粹的开发人员，无论是前端、后端，还是应用、游戏的开发，你首先应该明白这样两个道理：</p><ul><li>Kubernetes 和容器技术主要解决的，是代码编写完成后的事情。这不单单是发布或者 CI/CD，而是指从你执行完 git commit &amp;&amp; git push 之后开始，都应该进入容器化的管理流程当中，当然包括后续的发布、运维、升级、回滚等所有阶段。</li><li>Kubernetes 体系的核心，是为开发者提供编写代码过程中的“微服务编程范式”。</li></ul><p>比如，在你编写代码的时候，你应该清楚地知道：我该如何划分模块，就能更方便地利用到 Kubernetes 的 Pod 模型，来构建更加低耦合、高内聚的代码制品，让我后面的升级和重构工作更加容易。</p><p><a href="https://time.geekbang.org/column/article/40092" target="_blank" rel="noopener">拓展阅读「为什么我们需要 pod？」</a></p><p>再比如，当你的代码需要与一个外部资源进行交互的时候，你应该首先想到：我的这个外部资源，是不是可以作为一个 Kubernetes 的 CRD 放到 Etcd 里面。这样，我编写的代码，就可以遵循一个自定义 Controller 或者 Operator 的编程范式，通过声明式 API 的方式来执行业务逻辑。这样写出来的代码一定会更加简单、健壮、容易维护。</p><p>这样的例子其实非常多。<strong>作为开发人员，你最应该关注的，是 Kubernetes API 对象的细节、容器设计模式以及 Kubernetes API 编程范式。</strong><br><img src="https://static001.infoq.cn/resource/image/6d/e5/6df92fe2c06b8ccb27f57934aff244e5.png" alt=""><br>（Kubernetes 里的所有 API 对象）</p><p>你应该习惯于把你的服务想象成一个个容器，把整个应用想象成一个 Pod，学会把基于容器和 Kubernetes 的设计思想和架构方式，融入到自己平常的工程实践当中。你应该大量实践这些思想和设计模式，编写各种各样的 CRD 和 Controller，并想办法提高这些自己编写的自定义 Controller 项目的性能和服务能力。你应该尝试扮演公司或者组织中推广微服务和云原生体系倡导者，并热心地帮助团队成员共同学习 Kubernetes 的设计思想和 API，全力帮助 Istio 或者 Knative 这样的 Service Mesh 和 PaaS 平台在组织中落地。</p><p>这些，都是增强你在即将到来的云计算时代竞争力的有效手段。</p><p>当然，如果你对 Kubernetes API 以及编程范式还不熟悉，甚至对 Kubernetes API 的普适性还有所怀疑，那么你可以阅读一下《深入剖析 Kubernetes》的最后一篇文章<a href="https://time.geekbang.org/column/article/74278" target="_blank" rel="noopener">「Kubernetes：赢开发者赢天下」</a>。相信 Kubernetes API 成为云上编程标准的故事，一定会对你有所启迪。</p><h2 id="定位二：专注于服务器端的编程人员-运维工程师"><a href="#定位二：专注于服务器端的编程人员-运维工程师" class="headerlink" title="定位二：专注于服务器端的编程人员 / 运维工程师"></a>定位二：专注于服务器端的编程人员 / 运维工程师</h2><p>而如果<strong>你是一位专注于服务器端的编程人员，或者运维工程师</strong>，那么你更应该关注的是 Kubernetes 这个项目背后的实现原理，它所体现出来的 Borg 和 Omega 项目多年来大规模集群管理的经验教训。</p><p>比如，声明式 API 的设计与实现原理，Informer、Controller 这些机制的实现方式，为什么说 Etcd 最适合的场景是配置管理，集中式集群调度器的核心机制与常用策略都有哪些。</p><p>此外，Kubernetes 项目的各个可扩展性接口，也是你需要重点关注和理解的对象，比如 CNI 和网络插件的工作方式、CSI 和存储插件的设计、Kubernetes Volume 管理的完整流程，以及 CRI 的设计和各种 container runtime 的异同。</p><p>从这个角度来说，Kubernetes 项目就是当前云计算平台层开源项目的事实标准，熟悉它的思想、架构、实现细节甚至核心组件的源码，不仅是学习这项技术的必经之路，也是传统后端技术人员向云端转型的最佳途径。<br><img src="https://static001.infoq.cn/resource/image/7c/2a/7c43e584fb71bbcb48f47a0bb318cd2a.png" alt=""><br>（Kubernetes 通过存储插件管理容器持久化存储的原理）</p><p>你应该尝试扮演公司和组织中进行云原生和基础架构转型的关键角色，而不是充当传统和守旧那一方。你应该尝试用容器和 Kubernetes 化的思想来影响周边的每一位工程师。<strong>要记住，这个进程每前进一步，你的价值就放大一分。</strong></p><p><a href="https://time.geekbang.org/column/article/44245" target="_blank" rel="noopener">拓展阅读「编写自己的存储插件」</a></p><h2 id="定位三：学生、刚刚入行的初学者"><a href="#定位三：学生、刚刚入行的初学者" class="headerlink" title="定位三：学生、刚刚入行的初学者"></a>定位三：学生、刚刚入行的初学者</h2><p>而<strong>作为学生、刚刚入行的初学者</strong>，或者是对这个领域充满兴趣准备在这里作为一番的后端从业人员，我希望你对容器和 Kubernetes 技术体系的学习和实践，更要关注这个项目和平台背后更深层的基础和底盘部分，这包括：</p><p>1. 了解操作系统和硬件的实际工作方式，尤其是 CPU、存储和网络。</p><p>2. 充分理解操作系统的设计，甚至可以根据需要重新实现或者绕过某些部分，这是你后面进行系统性能优化的关键所在。</p><p>3. 理解“所有系统都是分布式系统”的道理。了解经典的分布式系统设计的思想，并从实际的工程实践中理解这些解决思路，这也是 Kubernetes 这个分布式项目构建的基础。</p><p>只有清楚了自己的定位，你才能够在 Kubernetes 这样一个大而全的技术体系面前做到“有所放矢，有的放矢”，才能够把容器和 Kubernetes 这项技术发展浪潮，与自己的技术路线和个人成长历程，真正地关联起来。<br><img src="https://static001.infoq.cn/resource/image/e7/6c/e7a7ad7a95e77d36014d63824a4aa76c.png" alt=""><br>（Kubernetes 项目核心功能的“全景图”）</p><p>一旦明确了定位，抓到了这其中的精髓和主线，那么接下来的学习过程对于你来说，其实就是“无招胜有招”，可以随心所欲地按照你实际的项目、所关心的领域逐步展开，而完全不必拘泥于某种特定的套路了。</p><p><a href="https://time.geekbang.org/column/article/23132" target="_blank" rel="noopener">拓展阅读：「从容器到容器云：谈谈 Kubernetes 的本质」</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;学习Kubernetes和容器技术体系的最佳方法&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.infoq.cn/article/3yijOyajjpq-Fg809NIj&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.in
      
    
    </summary>
    
      <category term="kubernetes" scheme="http://zhangyu33.com/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="http://zhangyu33.com/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>万兆网卡的Server与千兆网卡的client之间传输问题</title>
    <link href="http://zhangyu33.com/2019/02/13/%E4%B8%87%E5%85%86%E7%BD%91%E5%8D%A1%E7%9A%84Server%E4%B8%8E%E5%8D%83%E5%85%86%E7%BD%91%E5%8D%A1%E7%9A%84client%E4%B9%8B%E9%97%B4%E4%BC%A0%E8%BE%93%E9%97%AE%E9%A2%98/"/>
    <id>http://zhangyu33.com/2019/02/13/万兆网卡的Server与千兆网卡的client之间传输问题/</id>
    <published>2019-02-12T16:00:00.000Z</published>
    <updated>2019-02-13T08:51:29.093Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://linux.vbird.org/faq.php#20190211" target="_blank" rel="noopener">http://linux.vbird.org/faq.php#20190211</a></p><p>情况：</p><p> 就是10G –&gt; 1GB 的方向，网路频宽使用非常糟糕～一下子到500Mbps， 一下自降到10Mbps 的情况，导致效能非常恶劣<br>～但是1GB –&gt; 10G 就没有这个问题～同时， 10G –&gt; 10G 也同样没问题</p><p>分析：</p><p>1GB –&gt; 10G 的方向，因为 10G 原本就能够覆载 1G 以上的速度，所以当然没问题！<br> 那如果 10G –&gt; 1GB 时，如果没有特别的控制，那么 GB 的网卡当然会抵挡不住 10G 来的大量封包！</p><p>参考这两篇相当有趣的分析文章：</p><p>10G 网卡错误假设，与最佳设置方式：AIXpert Blog<br><a href="https://www.ibm.com/developerworks/community/blogs/aixpert/entry/10gbit_ethernet_bad_assumption_and_best_practice_part_137?lang=en" target="_blank" rel="noopener">https://www.ibm.com/developerworks/community/blogs/aixpert/entry/10gbit_ethernet_bad_assumption_and_best_practice_part_137?lang=en</a></p><p>NETApp vs VMWare Flow control dilemma：Ranjit Singh<br><a href="http://rjapproves.com/netapp-vs-vmware-flow-control-dilemma/" target="_blank" rel="noopener">http://rjapproves.com/netapp-vs-vmware-flow-control-dilemma/</a></p><p>结论：</p><p>这两篇的大意是说，10G switch 上面可能会安插不同速度的网卡，例如我们的环境中，10G 网卡与1G 网卡都安插在10G switch 上面， 虽然透过自动协商机制，10G 自己跑10G， 1G 自己跑1G，速度倒是正常没问题～但是，当1G 与10G 进行交流时， 如果switch 没有设定流量控制(flow control) 时，那么慢速的网卡可能会出现来不及接收高速网卡的情况～</p><p>因此上头第一篇建议， 全部的10G switch port 都启动flow control。不过，在鸟哥的测试中，没有flow control 确实速度会高出这么一点点(10G 效能可达到9.7Gbps 左右， 加上flow control 则大约到9.5Gbps 左右)，但是，在考虑到不同设备间的资料传输，</p><p>一般 switch，预设的情况就是关闭 flow control 的</p><p>鸟哥个人确实建议将所有的switch 的flow control 通通启用比较好！至少让你的速度不会差太多！</p><p>解决：</p><p> 直接改 switch 的 port settings ，将 flow control 勾选，解决！</p><p>涉及到不同速度的连结 (10G and 1G)，所以建议所有的装置 (交换机 and 网卡) 都要启用 flow control 才好！</p><p>10G switch 与 10G NIC 的 flow control 一定要启用！<br>    增加 10G 网卡的(queue)队列个数到硬体最大支援个数<br>    如果有固定的用户端 IP 环境，将 queue 的机制改成 multiq ，并且加上分流 (filter) 处置！</p><p>查看结果</p><p>命令：ethtool em4</p><p>如果是 Intel 的 10G 卡，只会出现『Advertised pause frame use: Symmetric』， 如果出现的是『Advertised pause frame use: No』，则代表网卡与 switch 之间不支持 flow control 喔！</p><p>而如果是 Broadcom 的网卡， 基本上则是出现『Link partner advertised pause frame use: Symmetric』，如果出现的是『Link partner advertised pause frame use: No』， 也是代表不支持的意思！</p><p>一般来说，如果你没有调整过 Linux NIC 的设定，预设的网卡 flow control 是启动的！因此，如果透过上述指令查看到结果为 No 时， 那就代表 10G switch 没有启动 flow control 啰！</p><p>#####################<br><a href="http://linux.vbird.org/linux_enterprise/switch_10g_tune.php" target="_blank" rel="noopener">http://linux.vbird.org/linux_enterprise/switch_10g_tune.php</a></p><p>#####################<br>iperf3 使用</p><p>透过scp 虽然可以直接使用到网路的频宽，不过，如果大量传输资料时，例如10G 的流量情况底下，被读取​​的档案速度可能会卡住在磁盘I/O 上面， 所以，透过scp来直接评判网路状态，似乎是怪怪的。那怎办？没关系，我们可以透过 iperf3 这个软件来处理即可！这个软件可以简单的在网路两端启动， 一边启动 server 模式，一边启动 client 模式来存取资料，就能够自动的判断网路频宽了！你 </p><pre><code>https://iperf.fr/iperf-download.php</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;http://linux.vbird.org/faq.php#20190211&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://linux.vbird.org/faq.php#20190211&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;情况：&lt;/
      
    
    </summary>
    
      <category term="linux" scheme="http://zhangyu33.com/categories/linux/"/>
    
    
      <category term="linux" scheme="http://zhangyu33.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>面试必备指南-你的系统如何支撑高并发</title>
    <link href="http://zhangyu33.com/2019/01/24/%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E6%8C%87%E5%8D%97-%E4%BD%A0%E7%9A%84%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E6%94%AF%E6%92%91%E9%AB%98%E5%B9%B6%E5%8F%91/"/>
    <id>http://zhangyu33.com/2019/01/24/面试必备指南-你的系统如何支撑高并发/</id>
    <published>2019-01-23T16:00:00.000Z</published>
    <updated>2019-01-24T06:22:16.773Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><em>作者：__中华石杉</em></p><p>_出处：转载自微信公众号：石杉的架构笔记（ID：shishan100）<br><a href="https://mp.weixin.qq.com/s/poRrtaqBJjgfj8ZOUxcD-A" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/poRrtaqBJjgfj8ZOUxcD-A</a>) </p><p>一道面试题的背景引入</p><p>大多数同学被问到这个问题压根儿没什么思路去回答，不知道从什么地方说起，其实本质就是没经历过一些真正有高并发系统的锤炼罢了。</p><p>因为没有过相关的项目经历，所以就没法从真实的自身体会和经验中提炼出一套回答，然后系统的阐述出来自己负责过的系统如何支撑高并发的。</p><p>所以，这篇文章就从这个角度切入来简单说说这个问题，用一个最简单的思路来回答，大致如何应对。</p><p>当然这里首先说清楚一个前提：高并发系统各不相同。比如每秒百万并发的中间件系统、每日百亿请求的网关系统、瞬时每秒几十万请求的秒杀大促系统。</p><p>他们在应对高并发的时候，因为系统各自特点的不同，所以应对架构都是不一样的。</p><p>另外，比如电商平台中的订单系统、商品系统、库存系统，在高并发场景下的架构设计也是不同的，因为背后的业务场景什么的都不一样。</p><p>所以，这篇文章主要是给大家提供一个回答这类问题的思路，不涉及任何复杂架构设计，让你不至于在面试中被问到这个问题时，跟面试官大眼瞪小眼。</p><p>具体要真能在面试的时候回答好这个问题，建议各位参考一下本文思路，然后对你自己手头负责的系统多去思考一下，最好做一些相关的架构实践。</p><p>先考虑一个最简单的系统架构</p><p>假设刚刚开始你的系统就部署在一台机器上，背后就连接了一台数据库，数据库部署在一台服务器上。</p><p>我们甚至可以再现实点，给个例子，你的系统部署的机器是 4 核 8G，数据库服务器是 16 核 32G。</p><p>此时假设你的系统用户量总共就 10 万，用户量很少，日活用户按照不同系统的场景有区别，我们取一个较为客观的比例，10% 吧，每天活跃的用户就 1 万。</p><p>按照 28 法则，每天高峰期算它 4 个小时，高峰期活跃的用户占比达到 80%，就是 8000 人活跃在 4 小时内。</p><p>然后每个人对你的系统发起的请求，我们算他每天是 20 次吧。那么高峰期 8000 人发起的请求也才 16 万次，平均到 4 小时内的每秒（14400 秒），每秒也就 10 次请求。</p><p>好吧！完全跟高并发搭不上边，对不对？</p><p>然后系统层面每秒是 10 次请求，对数据库的调用每次请求都会有好几次数据库操作的，比如做做 crud 之类的。</p><p>那么我们取一个一次请求对应 3 次数据库请求吧，那这样的话，数据库层每秒也就 30 次请求，对不对？</p><p>按照这台数据库服务器的配置，支撑是绝对没问题的。上述描述的系统，用一张图表示，就是下面这样：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/MOwlO0INfQquiaCoVZfsYr7nAVKnvhdibibrQPBkHgpibw5hftAlMmePV0LrxzbR5sMnBjjFMCJicz9FG5bV6tdhFXw/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p><p>系统集群化部署</p><p>假设此时你的用户数开始快速增长，比如注册用户量增长了 50 倍，上升到了 500 万。</p><p>此时日活用户是 50 万，高峰期对系统每秒请求是 500/s。然后对数据库的每秒请求数量是 1500/s，这个时候会怎么样呢？</p><p>按照上述的机器配置来说，如果你的系统内处理的是较为复杂的一些业务逻辑，是那种重业务逻辑的系统的话，是比较耗费 CPU 的。</p><p>此时，4 核 8G 的机器每秒请求达到 500/s 的时候，很可能你会发现你的机器 CPU 负载较高了。</p><p>然后数据库层面，以上述的配置而言，其实基本上 1500/s 的高峰请求压力的话，还算可以接受。</p><p>这个主要是要观察数据库所在机器的磁盘负载、网络负载、CPU 负载、内存负载，按照我们的线上经验而言，那个配置的数据库在 1500/s 请求压力下是没问题的。</p><p>所以此时你需要做的一个事情，首先就是要支持你的系统集群化部署。</p><p>你可以在前面挂一个负载均衡层，把请求均匀打到系统层面，让系统可以用多台机器集群化支撑更高的并发压力。</p><p>比如说这里假设给系统增加部署一台机器，那么每台机器就只有 250/s 的请求了。</p><p>这样一来，两台机器的 CPU 负载都会明显降低，这个初步的“高并发”不就先 cover 住了吗？</p><p>要是连这个都不做，那单台机器负载越来越高的时候，极端情况下是可能出现机器上部署的系统无法有足够的资源响应请求了，然后出现请求卡死，甚至系统宕机之类的问题。</p><p>所以，简单小结，第一步要做的：</p><ul><li><p>添加负载均衡层，将请求均匀打到系统层。</p></li><li><p>系统层采用集群化部署多台机器，扛住初步的并发压力。</p></li></ul><p>此时的架构图变成下面的样子：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/MOwlO0INfQquiaCoVZfsYr7nAVKnvhdibibaLEFBVU3oJeZG0GhJFPss3mJWKZw5vDDIiclGjEVUV649avJc3RiaM5w/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p><p>数据库分库分表 + 读写分离</p><p>假设此时用户量继续增长，达到了 1000 万注册用户，然后每天日活用户是 100 万。</p><p>那么此时对系统层面的请求量会达到每秒 1000/s，系统层面，你可以继续通过集群化的方式来扩容，反正前面的负载均衡层会均匀分散流量过去的。</p><p>但是，这时数据库层面接受的请求量会达到 3000/s，这个就有点问题了。</p><p>此时数据库层面的并发请求翻了一倍，你一定会发现线上的数据库负载越来越高。</p><p>每次到了高峰期，磁盘 IO、网络 IO、内存消耗、CPU 负载的压力都会很高，大家很担心数据库服务器能否抗住。</p><p>没错，一般来说，对那种普通配置的线上数据库，建议就是读写并发加起来，按照上述我们举例的那个配置，不要超过 3000/s。</p><p>因为数据库压力过大，首先一个问题就是高峰期系统性能可能会降低，因为数据库负载过高对性能会有影响。</p><p>另外一个，压力过大把你的数据库给搞挂了怎么办？</p><p>所以此时你必须得对系统做分库分表 + 读写分离，也就是把一个库拆分为多个库，部署在多个数据库服务上，这是作为主库承载写入请求的。</p><p>然后每个主库都挂载至少一个从库，由从库来承载读请求。</p><p>此时假设对数据库层面的读写并发是 3000/s，其中写并发占到了 1000/s，读并发占到了 2000/s。</p><p>那么一旦分库分表之后，采用两台数据库服务器上部署主库来支撑写请求，每台服务器承载的写并发就是 500/s。</p><p>每台主库挂载一个服务器部署从库，那么 2 个从库每个从库支撑的读并发就是 1000/s。</p><p>简单总结，并发量继续增长时，我们就需要 focus 在数据库层面：分库分表、读写分离。</p><p>此时的架构图如下所示：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/MOwlO0INfQquiaCoVZfsYr7nAVKnvhdibibKREyUicsPjHMEoPxx7uqnLodbMlLrSnaMD6XhSyb3ycHsUK1goscbow/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p><p>缓存集群引入</p><p>接着就好办了，如果你的注册用户量越来越大，此时你可以不停的加机器，比如说系统层面不停加机器，就可以承载更高的并发请求。</p><p>然后数据库层面如果写入并发越来越高，就扩容加数据库服务器，通过分库分表是可以支持扩容机器的，如果数据库层面的读并发越来越高，就扩容加更多的从库。</p><p>但是这里有一个很大的问题：数据库其实本身不是用来承载高并发请求的，所以通常来说，数据库单机每秒承载的并发就在几千的数量级，而且数据库使用的机器都是比较高配置，比较昂贵的机器，成本很高。</p><p>如果你就是简单的不停的加机器，其实是不对的。</p><p>所以在高并发架构里通常都有缓存这个环节，缓存系统的设计就是为了承载高并发而生。</p><p>所以单机承载的并发量都在每秒几万，甚至每秒数十万，对高并发的承载能力比数据库系统要高出一到两个数量级。</p><p>所以你完全可以根据系统的业务特性，对那种写少读多的请求，引入缓存集群。</p><p>具体来说，就是在写数据库的时候同时写一份数据到缓存集群里，然后用缓存集群来承载大部分的读请求。</p><p>这样的话，通过缓存集群，就可以用更少的机器资源承载更高的并发。</p><p>比如说上面那个图里，读请求目前是每秒 2000/s，两个从库各自抗了 1000/s 读请求，但是其中可能每秒 1800 次的读请求都是可以直接读缓存里的不怎么变化的数据的。</p><p>那么此时你一旦引入缓存集群，就可以抗下来这 1800/s 读请求，落到数据库层面的读请求就 200/s。</p><p>同样，给大家来一张架构图，一起来感受一下：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/MOwlO0INfQquiaCoVZfsYr7nAVKnvhdibibanyxPWZ80waHYJAiaZLgOpJSPMrAVhFrdwSlP939PnDrg51VYF747ew/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p><p>按照上述架构，它的好处是什么呢？</p><p>可能未来你的系统读请求每秒都几万次了，但是可能 80%~90% 都是通过缓存集群来读的，而缓存集群里的机器可能单机每秒都可以支撑几万读请求，所以耗费机器资源很少，可能就两三台机器就够了。</p><p>你要是换成是数据库来试一下，可能就要不停的加从库到 10 台、20 台机器才能抗住每秒几万的读并发，那个成本是极高的。</p><p>好了，我们再来简单小结，承载高并发需要考虑的第三个点：</p><ul><li><p>不要盲目进行数据库扩容，数据库服务器成本昂贵，且本身就不是用来承载高并发的。</p></li><li><p>针对写少读多的请求，引入缓存集群，用缓存集群抗住大量的读请求。</p></li></ul><p>引入消息中间件集群</p><p>接着再来看看数据库写这块的压力，其实是跟读类似的。</p><p>假如说你所有写请求全部都落地数据库的主库层，当然是没问题的，但是写压力要是越来越大了呢？</p><p>比如每秒要写几万条数据，此时难道也是不停的给主库加机器吗？</p><p>可以当然也可以，但是同理，你耗费的机器资源是很大的，这个就是数据库系统的特点所决定的。</p><p>相同的资源下，数据库系统太重太复杂，所以并发承载能力就在几千/s的量级，所以此时你需要引入别的一些技术。</p><p>比如说消息中间件技术，也就是 MQ 集群，它可以非常好的做写请求异步化处理，实现削峰填谷的效果。</p><p>假如说，你现在每秒是 1000/s 次写请求，其中比如 500 次请求是必须请求过来立马写入数据库中的，但是另外 500 次写请求是可以允许异步化等待个几十秒，甚至几分钟后才落入数据库内的。</p><p>那么此时你完全可以引入消息中间件集群，把允许异步化的每秒 500 次请求写入 MQ，然后基于 MQ 做一个削峰填谷。</p><p>比如就以平稳的 100/s 的速度消费出来，然后落入数据库中即可，此时就会大幅度降低数据库的写入压力。</p><p>此时，架构图变成了下面这样：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/MOwlO0INfQquiaCoVZfsYr7nAVKnvhdibibUUbpBAIVD4EPS1ttpib8xDZZsx5m1wFBmSxUGAhchLdUibxmk90ibqwOA/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p><p>大家看上面的架构图，首先消息中间件系统本身也是为高并发而生，所以通常单机都是支撑几万甚至十万级的并发请求的。  </p><p>所以，它本身也跟缓存系统一样，可以用很少的资源支撑很高的并发请求，用它来支撑部分允许异步化的高并发写入是没问题的，比使用数据库直接支撑那部分高并发请求要减少很多的机器使用量。</p><p>而且经过消息中间件的削峰填谷之后，比如就用稳定的 100/s 的速度写数据库，那么数据库层面接收的写请求压力，不就成了 500/s + 100/s  = 600/s 了么？</p><p>大家看看，是不是发现减轻了数据库的压力？到目前为止，通过下面的手段，我们已经可以让系统架构尽可能用最小的机器资源抗住了最大的请求压力，减轻了数据库的负担：</p><ul><li><p>系统集群化。</p></li><li><p>数据库层面的分库分表+读写分离。</p></li><li><p>针对读多写少的请求，引入缓存集群。</p></li><li><p>针对高写入的压力，引入消息中间件集群。</p></li></ul><p>初步来说，简单的一个高并发系统的阐述是说完了。但是，故事到这里还远远没有结束。</p><p>现在能 Hold 住高并发面试题了吗？</p><p>看完了这篇文章，你觉得自己能回答好面试里的高并发问题了吗？</p><p>很遗憾，答案是不能。而且我觉得单单凭借几篇文章是绝对不可能真的让你完全回答好这个问题的，这里有很多原因在里面。</p><p>首先，高并发这个话题本身是非常复杂的，远远不是一些文章可以说的清楚的，它的本质就在于，真实的支撑复杂业务场景的高并发系统架构其实是非常复杂的。</p><p>比如说每秒百万并发的中间件系统、每日百亿请求的网关系统、瞬时每秒几十万请求的秒杀大促系统、支撑几亿用户的大规模高并发电商平台架构，等等。</p><p>为了支撑高并发请求，在系统架构的设计时，会结合具体的业务场景和特点，设计出各种复杂的架构，这需要大量底层技术支撑，需要精妙的架构和机制设计的能力。</p><p>最终，各种复杂系统呈现出来的架构复杂度会远远超出大部分没接触过的同学的想象。</p><p>但是那么复杂的系统架构，通过一些文章是很难说的清楚里面的各种细节以及落地生产的过程的。</p><p>其次，高并发这话题本身包含的内容也远远不止本文说的这么几个 topic：分库分表、缓存、消息。</p><p>一个完整而复杂的高并发系统架构中，一定会包含：</p><ul><li><p>各种复杂的自研基础架构系统。</p></li><li><p>各种精妙的架构设计（比如热点缓存架构设计、多优先级高吞吐 MQ 架构设计、系统全链路并发性能优化设计，等等）。</p></li><li><p>还有各种复杂系统组合而成的高并发架构整体技术方案。</p></li><li><p>还有 NoSQL（Elasticsearch 等）/负载均衡/Web 服务器等相关技术。</p></li></ul><p>所以大家切记要对技术保持敬畏之心，这些东西都很难通过一些文章来表述清楚。</p><p>最后，真正在生产落地的时候，高并发场景下你的系统会出现大量的技术问题。</p><p>比如说消息中间件吞吐量上不去需要优化、磁盘写压力过大性能太差、内存消耗过大容易撑爆、分库分表中间件不知道为什么丢了数据，等等吧。</p><p>诸如此类的问题非常多，这些也不可能通过文章给全部说清楚。</p><p>本文能带给你什么启发？</p><p>其实本文的定位，就是对高并发这个面试 topic 做一个扫盲，因为我发现大部分来问我这个问题的同学，连本文阐述的最最基本的高并发架构演进思路可能都没理解。</p><p>当然，也是因为毕竟没真的做过高并发系统，没相关经验，确实很难理解好这个问题。</p><p>所以本文就是让很多没接触过的同学有一个初步的感知，这个高并发到底是怎么回事儿，到底对系统哪里有压力，要在系统架构里引入什么东西，才可以比较好的支撑住较高的并发压力。</p><p>而且你可以顺着本文的思路继续思考下去，结合你自己熟悉和知道的一些技术继续思考。</p><p>比如说，你熟悉 Elasticsearch 技术，那么你就可以思考，在高并发的架构之下，是不是可以通过分布式架构的 ES 技术支撑高并发的搜索？</p><p>上面所说，权当抛砖引玉。大家自己平时一定要多思考，多画图，盘点自己手头系统的请求压力。</p><p>计算一下分散到各个中间件层面的请求压力，到底应该如何利用最少的机器资源最好的支撑更高的并发请求。</p><p>这才是一个好的高并发架构设计思路。</p><p>如果起到这个效果，本文就成功了。剩下的，还是建议各位同学，对高并发这个话题，结合自己手头负责的系统多做思考。</p><p>比如当前业务场景下，你的系统有多大的请求压力？如果请求压力增长 10 倍，你的架构如何支撑？如果请求压力增长 100 倍，你的架构如何支撑？如果请求压力增长 1000 倍，你的架构如何支撑？</p><p>平时一定多给自己设置一些技术挑战，敦促自己去思考自己的系统，最好多做写架构上的演练、落地和实践，实际操作一下，才有更好的感知。</p><p>然后在面试的时候，起码自己做过一定深度的思考，结合自己负责的系统做过一些实践，可以跟面试官有一个较为清晰和系统的阐述。</p><p>虽然大部分同学可能没机会经历那种真正大规模超高并发的系统架构的设计，但是本文如果能让大家平时对自己的项目多一些思考。在面试的时候，有一些系统性的思路和阐述，那么也就达到本文的目的了。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;作者：__中华石杉&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;_出处：转载自微信公众号：石杉的架构笔记（ID：shishan100）&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/poRrtaqBJjgfj8ZOUxcD-A&quot;
      
    
    </summary>
    
      <category term="架构" scheme="http://zhangyu33.com/categories/architecture/"/>
    
    
      <category term="架构" scheme="http://zhangyu33.com/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>记一次Kubernetes/Docker网络排障</title>
    <link href="http://zhangyu33.com/2019/01/23/%E8%AE%B0%E4%B8%80%E6%AC%A1KubernetesDocker%E7%BD%91%E7%BB%9C%E6%8E%92%E9%9A%9C/"/>
    <id>http://zhangyu33.com/2019/01/23/记一次KubernetesDocker网络排障/</id>
    <published>2019-01-22T16:00:00.000Z</published>
    <updated>2019-01-23T06:22:38.179Z</updated>
    
    <content type="html"><![CDATA[<p>酷 壳</p><p><a href="https://coolshell.cn/articles/18654.html" target="_blank" rel="noopener">https://coolshell.cn/articles/18654.html</a> </p><blockquote><h1 id="记一次Kubernetes-Docker网络排障"><a href="#记一次Kubernetes-Docker网络排障" class="headerlink" title="记一次Kubernetes/Docker网络排障"></a>记一次Kubernetes/Docker网络排障</h1><p>昨天周五晚上，临下班的时候，用户给我们报了一个比较怪异的Kubernetes集群下的网络不能正常访问的问题，让我们帮助查看一下，我们从下午5点半左右一直跟进到晚上十点左右，在远程不能访问用户机器只能远程遥控用户的情况找到了的问题。这个问题比较有意思，我个人觉得其中的调查用到的的命令以及排障的一些方法可以分享一下，所以写下了这篇文章。</p><h4 id="问题的症状"><a href="#问题的症状" class="headerlink" title="问题的症状"></a>问题的症状</h4><p>用户直接在微信里说，他们发现在Kuberbnetes下的某个pod被重启了几百次甚至上千次，于是开启调查这个pod，发现上面的服务时而能够访问，时而不能访问，也就是有一定概率不能访问，不知道是什么原因。而且并不是所有的pod出问题，而只是特定的一两个pod出了网络访问的问题。用户说这个pod运行着Java程序，为了排除是Java的问题，用户用 <code>docker exec -it</code> 命令直接到容器内启了一个 Python的 SimpleHttpServer来测试发现也是一样的问题。</p><p>我们大概知道用户的集群是这样的版本，Kuberbnetes 是1.7，网络用的是flannel的gw模式，Docker版本未知，操作系统CentOS 7.4，直接在物理机上跑docker，物理的配置很高，512GB内存，若干CPU核，上面运行着几百个Docker容器。</p><h4 id="问题的排查"><a href="#问题的排查" class="headerlink" title="问题的排查"></a>问题的排查</h4><h5 id="问题初查"><a href="#问题初查" class="headerlink" title="问题初查"></a>问题初查</h5><p>首先，我们排除了flannel的问题，因为整个集群的网络通信都正常，只有特定的某一两个pod有问题。而用 <code>telnet ip port</code> 的命令手工测试网络连接时有很大的概率出现 <code>connection refused</code> 错误，大约 1/4的概率，而3/4的情况下是可以正常连接的。</p><p>当时，我们让用户抓个包看看，然后，用户抓到了有问题的TCP连接是收到了 <code>SYN</code> 后，立即返回了 <code>RST, ACK</code></p><p><img src="https://coolshell.cn/wp-content/uploads/2018/12/tcpdump.png" alt=""></p><p>我问一下用户这两个IP所在的位置，知道了，<code>10.233.14.129</code> 是 <code>docker0</code>，<code>10.233.14.145</code> 是容器内的IP。所以，这基本上可以排除了所有和kubernets或是flannel的问题，这就是本地的Docker上的网络的问题。</p><p>对于这样被直接 Reset 的情况，在 <code>telnet</code> 上会显示 <code>connection refused</code> 的错误信息，对于我个人的经验，这种 <code>SYN</code>完直接返回 <code>RST, ACK</code>的情况只会有三种情况：</p><ol><li>TCP链接不能建立，不能建立连接的原因基本上是标识一条TCP链接的那五元组不能完成，绝大多数情况都是服务端没有相关的端口号。</li><li>TCP链接建错误，有可能是因为修改了一些TCP参数，尤其是那些默认是关闭的参数，因为这些参数会导致TCP协议不完整。</li><li>有防火墙iptables的设置，其中有 <code>REJECT</code> 规则。</li></ol><p>因为当时还在开车，在等红灯的时候，我感觉到有点像 NAT 的网络中服务端开启了 <code>tcp_tw_recycle</code> 和 <code>tcp_tw_reuse</code> 的症况（详细参看《<a href="https://coolshell.cn/articles/11564.html" target="_blank" rel="noopener">TCP的那些事（上）</a>》），所以，让用户查看了一上TCP参数，发现用户一个TCP的参数都没有改，全是默认的，于是我们排除了TCP参数的问题。</p><p>然后，我也不觉得容器内还会设置上iptables，而且如果有那就是100%的问题，不会时好时坏。所以，我怀疑容器内的端口号没有侦听上，但是马上又好了，这可能会是应用的问题。于是我让用户那边看一下，应用的日志，并用 <code>kublet describe</code>看一下运行的情况，并把宿主机的 iptables 看一下。</p><p>然而，我们发现并没有任何的问题。这时，<strong>我们失去了所有的调查线索，感觉不能继续下去了……</strong></p><h5 id="重新梳理"><a href="#重新梳理" class="headerlink" title="重新梳理"></a>重新梳理</h5><p>这个时候，回到家，大家吃完饭，和用户通了一个电话，把所有的细节再重新梳理了一遍，这个时候，用户提供了一个比较关键的信息—— “<strong>抓包这个事，在 <code>docker0</code> 上可以抓到，然而到了容器内抓不到容器返回 <code>RST, ACK</code></strong> ” ！然而，根据我的知识，我知道在 <code>docker0</code> 和容器内的 <code>veth</code> 网卡上，中间再也没有什么网络设备了（参看《<a href="https://coolshell.cn/articles/17029.html" target="_blank" rel="noopener">Docker基础技术：LINUX NAMESPACE（下）</a>》）!</p><p>于是这个事把我们逼到了最后一种情况 —— IP地址冲突了！</p><p>Linux下看IP地址冲突还不是一件比较简单事的，而在用户的生产环境下没有办法安装一些其它的命令，所以只能用已有的命令，这个时候，我们发现用户的机器上有 <code>arping</code> 于是我们用这个命令来检测有没有冲突的IP地址。使用了下面的命令：</p><p><code>$ arping -D -I docker0 -c 2 10.233.14.145</code></p><p><code>$</code> <code>echo</code> <code>$?</code></p><p>根据文档，<code>-D</code> 参数是检测IP地址冲突模式，如果这个命令的退状态是 <code>0</code> 那么就有冲突。结果返回了 <code>1</code> 。而且，我们用 <code>arping</code> IP的时候，没有发现不同的mac地址。 <strong>这个时候，似乎问题的线索又断了</strong>。</p><p>因为客户那边还在处理一些别的事情，所以，我们在时断时续的情况下工作，而还一些工作都需要用户完成，所以，进展有点缓慢，但是也给我们一些时间思考问题。</p><h5 id="柳暗花明"><a href="#柳暗花明" class="headerlink" title="柳暗花明"></a>柳暗花明</h5><p>现在我们知道，IP冲突的可能性是非常大的，但是我们找不出来是和谁的IP冲突了。而且，我们知道只要把这台机器重启一下，问题一定就解决掉了，但是我们觉得这并不是解决问题的方式，因为重启机器可以暂时的解决掉到这个问题，而如果我们不知道这个问题怎么发生的，那么未来这个问题还会再来。而重启线上机器这个成本太高了。</p><p>于是，我们的好奇心驱使我们继续调查。我让用户 <code>kubectl delete</code> 其中两个有问题的pod，因为本来就服务不断重启，所以，删掉也没有什么问题。删掉这两个pod后（一个是IP为 <code>10.233.14.145</code> 另一个是 <code>10.233.14.137</code>），我们发现，kubernetes在其它机器上重新启动了这两个服务的新的实例。然而，<strong>在问题机器上，这两个IP地址居然还可以ping得通</strong>。</p><p>好了，IP地址冲突的问题可以确认了。因为<code>10.233.14.xxx</code> 这个网段是 docker 的，所以，这个IP地址一定是在这台机器上。所以，我们想看看所有的 network namespace 下的 veth 网卡上的IP。</p><p>在这个事上，我们费了点时间，因为对相关的命令也 很熟悉，所以花了点时间Google，以及看相关的man。</p><ul><li>首先，我们到 <code>/var/run/netns</code>目录下查看系统的network namespace，发现什么也没有。</li><li>然后，我们到 <code>/var/run/docker/netns</code> 目录下查看Docker的namespace，发现有好些。</li><li>于是，我们用指定位置的方式查看Docker的network namespace里的IP地址</li></ul><p>这里要动用 <code>nsenter</code> 命令，这个命令可以进入到namespace里执行一些命令。比如</p><p><code>$ nsenter --net=``/var/run/docker/netns/421bdb2accf1</code> <code>ifconfig</code> <code>-a</code></p><p>上述的命令，到 <code>var/run/docker/netns/421bdb2accf1</code> 这个network namespace里执行了 <code>ifconfig -a</code> 命令。于是我们可以用下面 命令来遍历所有的network namespace。</p><p>1</p><p><code>$</code> <code>ls</code> <code>/var/run/docker/netns</code> <code>|</code> <code>xargs</code> <code>-I {} nsenter --net=``/var/run/docker/netns/``{} ip addr</code></p><p>然后，我们发现了比较诡异的事情。</p><ul><li><code>10.233.14.145</code> 我们查到了这个IP，说明，docker的namespace下还有这个IP。</li><li><code>10.233.14.137</code>，这个IP没有在docker的network namespace下查到。</li></ul><p>有namespace leaking？于是我上网查了一下，发现了一个docker的bug – 在docker remove/stop 一个容器的时候，没有清除相应的network namespace，这个问题被报告到了 <a href="https://github.com/moby/moby/issues/31597" target="_blank" rel="noopener">Issue#31597</a> 然后被fix在了 <a href="https://github.com/moby/moby/pull/31996" target="_blank" rel="noopener">PR#31996</a>，并Merge到了 Docker的 17.05版中。而用户的版本是 17.09，应该包含了这个fix。不应该是这个问题，感觉又走不下去了。</p><p>不过， <code>10.233.14.137</code> 这个IP可以ping得通，说明这个IP一定被绑在某个网卡，而且被隐藏到了某个network namespace下。</p><p>到这里，要查看所有network namespace，只有最后一条路了，那就是到 <code>/proc/</code> 目录下，把所有的pid下的 <code>/proc/&lt;pid&gt;/ns</code> 目录给穷举出来。好在这里有一个比较方便的命令可以干这个事 ： <code>lsns</code></p><p>于是我写下了如下的命令：</p><p>1</p><p><code>$ lsns -t net |</code> <code>awk</code> <code>‘{print $4}&#39; |</code> <code>xargs</code> <code>-t -I {} nsenter -t {}&amp;nbsp;-n ip addr |</code> <code>grep</code> <code>-C 4</code> <code>&quot;10.233.14.137&quot;</code></p><p>解释一下。</p><ul><li><code>lsns -t net</code> 列出所有开了network namespace的进程，其第4列是进程PID</li><li>把所有开过network namespace的进程PID拿出来，转给 <code>xargs</code> 命令</li><li>由 <code>xargs</code> 命令把这些PID 依次传给 <code>nsenter</code> 命令，<ul><li><code>xargs -t</code> 的意思是会把相关的执行命令打出来，这样我知道是那个PID。</li><li><code>xargs -I {}</code>  是声明一个占位符来替换相关的PID</li></ul></li></ul><p>最后，我们发现，虽然在 <code>/var/run/docker/netns</code> 下没有找到 <code>10.233.14.137</code> ，但是在 <code>lsns</code> 中找到了三个进程，他们都用了<code>10.233.14.137</code> 这个IP（冲突了这么多），<strong>而且他们的MAC地址全是一样的！</strong>（怪不得arping找不到）。通过<code>ps</code> 命令，可以查到这三个进程，有两个是java的，还有一个是<code>/pause</code> （这个应该是kubernetes的沙盒）。</p><p>我们继续乘胜追击，穷追猛打，用<code>pstree</code>命令把整个进程树打出来。发现上述的三个进程的父进程都在多个同样叫 <code>docker-contiane</code> 的进程下！</p><p><strong>这明显还是docker的，但是在<code>docker ps</code> 中却找不道相应的容器，什么鬼！快崩溃了……</strong></p><p>继续看进程树，发现，这些 <code>docker-containe</code> 的进程的父进程不在 <code>dockerd</code> 下面，而是在 <code>systemd</code> 这个超级父进程PID 1下，我靠！进而发现了一堆这样的野进程（这种野进程或是僵尸进程对系统是有害的，至少也是会让系统进入亚健康的状态，因为他们还在占着资源）。</p><p><code>docker-contiane</code> 应该是 <code>dockerd</code> 的子进程，被挂到了 <code>pid 1</code> 只有一个原因，那就是父进程“飞”掉了，只能找 pid 1 当养父。这说明，这台机器上出现了比较严重的 <code>dockerd</code> 进程退出的问题，而且是非常规的，因为 <code>systemd</code> 之所以要成为 pid 1，其就是要监管所有进程的子子孙孙，居然也没有管理好，说明是个非常规的问题。（注，关于 systemd，请参看《<a href="https://coolshell.cn/articles/17998.html" target="_blank" rel="noopener">Linux PID 1 和 Systemd</a> 》，关于父子进程的事，请参看《Unix高级环境编程》一书）</p><p>接下来就要看看 <code>systemd</code> 为 <code>dockerd</code> 记录的日志了…… （然而日志只有3天的了，这3天<code>dockerd</code>没有任何异常）</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>通过这个调查，可以总结一下，</p><p>1） 对于问题调查，需要比较扎实的基础知识，知道问题的成因和范围。</p><p>2）如果走不下去了，要重新梳理一下，回头仔细看一下一些蛛丝马迹，认真推敲每一个细节。</p><p>3） 各种诊断工具要比较熟悉，这会让你事半功倍。</p><p>4）系统维护和做清洁比较类似，需要经常看看系统中是否有一些僵尸进程或是一些垃圾东西，这些东西要及时清理掉。</p><p>最后，多说一下，很多人都说，<strong>Docker适合放在物理机内运行，这并不完全对，因为他们只考虑到了性能成本，没有考虑到运维成本，在这样512GB中启动几百个容器的玩法，其实并不好，因为这本质上是个大单体，因为你一旦要重启某些关键进程或是机器，你的影响面是巨大的</strong>。</p><p>———————— 更新 2018/12/10 —————————</p><h4 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h4><p>这两天在自己的环境下测试了一下，发现，只要是通过 <code>systemctl start/stop docker</code> 这样的命令来启停 Docker， 是可以把所有的进程和资源全部干掉的。这个是没有什么问题的。我唯一能重现用户问题的的操作就是直接 <code>kill -9 &lt;dockerd pid&gt;</code> 但是这个事用户应该不会干。而 Docker 如果有 crash 事件时，Systemd 是可以通过 <code>journalctl -u docker</code> 这样的命令查看相关的系统日志的。</p><p>于是，我找用户了解一下他们在Docker在启停时的问题，用户说，<strong>他们的执行 <code>systemctl stop docker</code> 这个命令的时候，发现这个命令不响应了，有可能就直接按了 <code>Ctrl +C</code> 了</strong>！</p><p>这个应该就是导致大量的 <code>docker-containe</code> 进程挂到 <code>PID 1</code> 下的原因了。前面说过，用户的一台物理机上运行着上百个容器，所以，那个进程树也是非常庞大的，我想，停服的时候，系统一定是要遍历所有的docker子进程来一个一个发退出信号的，这个过程可能会非常的长。导致操作员以为命令假死，而直接按了 <code>Ctrl + C</code> ，最后导致很多容器进程并没有终止……</p><h4 id="其它事宜"><a href="#其它事宜" class="headerlink" title="其它事宜"></a>其它事宜</h4><p>有同学问，为什么我在这个文章里写的是 <code>docker-containe</code> 而不是 <code>containd</code> 进程？这是因为被 <code>pstree</code> 给截断了，用 <code>ps</code> 命令可以看全，只是进程名的名字有一个 <code>docker-</code>的前缀。</p><p>下面是这两种不同安装包的进程树的差别（其中 <code>sleep</code> 是我用 <code>buybox</code> 镜像启动的）</p><p>CentOS 系统安装包</p><p><code>systemd───dockerd─┬─docker-contained─┬─3*[docker-contained-shim─┬─``sleep``]</code></p><p><code>│                 │                    └─9*[{docker-containe}]]</code></p><p><code>│                 ├─docker-contained-shim─┬─``sleep</code></p><p><code>│                 │                 └─10*[{docker-containe}]</code></p><p><code>│                 └─14*[{docker-contained-shim}]</code></p><p><code>└─17*[{dockerd}]</code></p><p>Docker 官方安装包</p><p><code>systemd───dockerd─┬─containerd─┬─3*[containerd-shim─┬─``sleep``]</code></p><p><code>│            │                 └─9*[{containerd-shim}]</code></p><p><code>│            ├─2*[containerd-shim─┬─``sleep``]</code></p><p><code>│            │                    └─9*[{containerd-shim}]]</code></p><p><code>│            └─11*[{containerd}]</code></p><p><code>└─10*[{dockerd}]</code></p><p>顺便说一下，自从 Docker 1.11版以后，Docker进程组模型就改成上面这个样子了.</p><ul><li><code>dockerd</code> 是 Docker Engine守护进程，直接面向操作用户。<code>dockerd</code> 启动时会启动 <code>containerd</code> 子进程，他们之前通过RPC进行通信。</li><li><code>containerd</code> 是<code>dockerd</code>和<code>runc</code>之间的一个中间交流组件。他与 <code>dockerd</code> 的解耦是为了让Docker变得更为的中立，而支持OCI 的标准 。</li><li><code>containerd-shim</code>  是用来真正运行的容器的，每启动一个容器都会起一个新的shim进程， 它主要通过指定的三个参数：容器id，boundle目录（containerd的对应某个容器生成的目录，一般位于：<code>/var/run/docker/libcontainerd/containerID</code>）， 和运行命令（默认为 <code>runc</code>）来创建一个容器。</li><li><code>docker-proxy</code> 你有可能还会在新版本的Docker中见到这个进程，这个进程是用户级的代理路由。只要你用 <code>ps -elf</code> 这样的命令把其命令行打出来，你就可以看到其就是做端口映射的。如果你不想要这个代理的话，你可以在 <code>dockerd</code> 启动命令行参数上加上：  <code>--userland-proxy=false</code> 这个参数。</li></ul><p>更多的细节，大家可以自行Google。这里推荐两篇文章：</p><ul><li><a href="https://hackernoon.com/docker-containerd-standalone-runtimes-heres-what-you-should-know-b834ef155426" target="_blank" rel="noopener">Docker, Containerd &amp; Standalone Runtimes — Here’s What You Should Know</a></li><li><a href="http://alexander.holbreich.org/docker-components-explained/" target="_blank" rel="noopener">Docker components explained</a></li></ul><p>（全文完）</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;酷 壳&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://coolshell.cn/articles/18654.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://coolshell.cn/articles/18654.html&lt;/a&gt;
      
    
    </summary>
    
      <category term="docker" scheme="http://zhangyu33.com/categories/docker/"/>
    
    
      <category term="docker" scheme="http://zhangyu33.com/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>网站访问速度慢</title>
    <link href="http://zhangyu33.com/2018/12/26/%E7%BD%91%E7%AB%99%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6%E6%85%A2/"/>
    <id>http://zhangyu33.com/2018/12/26/网站访问速度慢/</id>
    <published>2018-12-25T16:00:00.000Z</published>
    <updated>2018-12-26T03:15:41.472Z</updated>
    
    <content type="html"><![CDATA[<p>网站访问速度慢</p><p><a href="https://www.ssforce.cn/archives/362" target="_blank" rel="noopener">https://www.ssforce.cn/archives/362</a></p><p>a&gt; 访问者自己硬件设备（硬盘、CPU、网口、运营商带宽）资源不足</p><p>b&gt; 服务器硬件设备（硬盘、CPU、网口、运营商带宽）资源不足</p><p>c&gt; 图片未做优化太大、太多导致资源加载太多而慢</p><p>d&gt; 应用程序代码质量差导致性能消耗大、响应速度慢</p><p>e&gt; 页面设计不合理，导致资源整合过多（图片、css、js、前后端请求等）</p><p>f&gt; 其它DNS、安全入侵等问题</p><p>通常解决掉a b c可以帮我们解决80%的问题只需要花费20%的精力，d e f可以帮我们解决掉剩下的20%问题但需要花费80%的精力。</p><p><img src="https://raw.githubusercontent.com/mayou33/other/master/%E7%BD%91%E7%AB%99%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6%E6%85%A2.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;网站访问速度慢&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.ssforce.cn/archives/362&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.ssforce.cn/archives/362&lt;/a&gt;&lt;/p&gt;
&lt;
      
    
    </summary>
    
      <category term="web" scheme="http://zhangyu33.com/categories/web/"/>
    
    
      <category term="web" scheme="http://zhangyu33.com/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>浅谈TLS1.3</title>
    <link href="http://zhangyu33.com/2018/12/26/%E6%B5%85%E8%B0%88TLS1.3/"/>
    <id>http://zhangyu33.com/2018/12/26/浅谈TLS1.3/</id>
    <published>2018-12-25T16:00:00.000Z</published>
    <updated>2018-12-26T03:09:34.530Z</updated>
    
    <content type="html"><![CDATA[<p> 小米运维<br><a href="https://mp.weixin.qq.com/s/uNKrLV4taafS0AluSBUznw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/uNKrLV4taafS0AluSBUznw</a> </p><p>  <strong>TLS简介</strong></p><p> 按照维基百科的定义，TLS 是一种用于为计算机网络通信提供安全性的密码协议，其前身安全套接层（SSL）想必很多人都听说过。TLS 被广泛应用于基于 IP 的网络协议，如 HTTP、SMTP、FTP 等。最近几年内，Let’s Encrypt 提供的免费证书服务、浏览器只对 HTTPS 站点启用 HTTP/2 和把未使用 HTTPS 而要求输入密码的网站标记为不安全等因素强力推动了 HTTPS 的部署，国际上 HTTPS 的部署率现已超过 50%。在各种因素的推动下，国内站点和应用也在大力推广 TLS 等密码协议的使用。</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/Re4KW51oYRpfwee8BkZnflunRvfWAycY1hhnHltT8Z0lw235avib3baOZZicUvfhoZoXFFY2uYL6NVJwUzPcHNjw/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p><p> Figure 1: 数据来自谷歌 Transparency Report，2018年9月14日获取</p><p> <strong> TLS 1.3的优势</strong></p><p> <strong>安全保护</strong></p><p> TLS 1.3 移除了很多过时的密码学原型和功能（例如压缩、重协商），强制要求完美前向安全。TLS 1.2 支持了很多加密算法（包括 3DES、静态 DH 等），这导致了 FREAK、Logjam、Sweet32 等攻击的出现。TLS 1.3 缩紧了对加密原型的限制，避免了因服务器启用不安全的算法导致协议的安全性受到影响。在这方面的简化也使得运维和开发者配置 TLS 变得更容易，不再容易误用不安全的配置。</p><p> TLS 1.3 之前，整个握手环节都是没有加密保护的，这泄漏了很多信息，包括客户端和服务器的身份。TLS 1.3 对握手的绝大部分信息进行了加密，这保护了用户隐私，也在一定程度上防止了协议僵化问题。</p><p> <strong>性能提升</strong></p><p> 虽然电脑越变越快，但在互联网上传输数据耗费的时间依然受限于光速，所以两个节点间来回传输一次的时间（RTT）成为了限制协议性能的因素之一。TLS 1.3 只需要一个 RTT 就能完成握手，相比 TLS 1.2 省去了一个 RTT。并且 TLS 1.3 支持 “0-RTT” 模式，在该模式下客户端可以在握手的同时发送数据，极大地加快了页面的加载速度。TLS 1.3 还增加了 ChaCha20/Poly1305 支持，在不支持 AES 硬件指令的老设备上能提升加、解密性能。</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/Re4KW51oYRpfwee8BkZnflunRvfWAycYjx1icDTU5eT9xhB8KvUK0GjibmHoFqyLvfGZfsearE7H5OtC94wV1CXQ/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/Re4KW51oYRpfwee8BkZnflunRvfWAycYE5oLTsPBS1fefianWRPAatYaBDgY8088AO9XyHiamwtvVsQSS6KYlECA/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p><p> <strong> TLS 1.3的部署</strong></p><p> Tengine 2.2.2 / nginx 1.13.0 提供了 TLS 1.3 支持，和 OpenSSL 1.1.1 配合即可将网站升级到 TLS 1.3。在配置文件里将 TLSv1.3 加到 ssl_protocols 中就可以启用 TLS 1.3 支持了。Qualys 的 SSL 服务器测试[1]是很方便的 TLS 配置测试工具，可以很方便地检测公网站点的 TLS 配置及其安全性。</p><p> <strong>协议僵化问题</strong></p><p> 当一个互联网协议长时间不发生变化时，基于该协议开发的设备就可能无视其预留的变通手段而对其特性作出超出标准的假设，这就是协议僵化现象。在 TLS 1.3 的完善过程中，新的协议因协议僵化问题而不得不模拟老协议的一些行为，这大大拖慢了 TLS 1.3 标准化的进度。尽管在制定 TLS 1.3 标准时工作组针对很多实际测试时出现的问题进行了处理，但我们部署到线上环境还是需要注意可能出现的兼容性问题。</p><p> <strong> TLS 1.3发展时间线</strong></p><ul><li><p>2017年4月25日，nginx 1.13.0 发布，增加了 TLS 1.3 支持。</p></li><li><p>2018年3月21日，IESG 批准了 TLS 1.3 草案。</p></li><li><p>2018年4月17日，Chrome 66 默认开启了对 TLS 1.3 草案的支持。</p></li><li><p>2018年5月9日，Firefox 60 默认开启了对 TLS 1.3 草案的支持。</p></li><li><p>2018年8月10日，IETF 发布了 TLS 1.3 标准。</p></li><li><p>2018年9月11日，OpenSSL 1.1.1 (LTS) 版本发布，提供 TLS 1.3 支持。TLS 1.3 超过 TLS 1.0 成为 Cloudflare 上使用率排名第二的 TLS 版本。</p></li><li><p>2018年10月16日，Chrome 70 支持 TLS 1.3 正式标准。</p></li><li><p>2018年10月23日，Firefox 63 支持 TLS 1.3 正式标准。</p></li></ul><p>  <strong>参考资料</strong></p><p> [1]<a href="https://www.ssllabs.com/ssltest/" target="_blank" rel="noopener">https://www.ssllabs.com/ssltest/</a></p><p> [2]<a href="https://tools.ietf.org/html/rfc8446" target="_blank" rel="noopener">https://tools.ietf.org/html/rfc8446</a></p><p> [3]<a href="https://en.wikipedia.org/wiki/Transport\_Layer\_Security" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Transport\_Layer\_Security</a></p><p> [4]<a href="https://blog.mozilla.org/security/2018/08/13/tls-1-3-published-in-firefox-today/" target="_blank" rel="noopener">https://blog.mozilla.org/security/2018/08/13/tls-1-3-published-in-firefox-today/</a></p><p> [5]<a href="https://ietf.org/blog/tls13/" target="_blank" rel="noopener">https://ietf.org/blog/tls13/</a></p><p> [6]<a href="https://kinsta.com/blog/tls-1-3/" target="_blank" rel="noopener">https://kinsta.com/blog/tls-1-3/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; 小米运维&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/uNKrLV4taafS0AluSBUznw&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s/uNKrLV4taa
      
    
    </summary>
    
      <category term="web" scheme="http://zhangyu33.com/categories/web/"/>
    
    
      <category term="web" scheme="http://zhangyu33.com/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>谈运维转型期的感悟和分享</title>
    <link href="http://zhangyu33.com/2018/12/26/%E8%B0%88%E8%BF%90%E7%BB%B4%E8%BD%AC%E5%9E%8B%E6%9C%9F%E7%9A%84%E6%84%9F%E6%82%9F%E5%92%8C%E5%88%86%E4%BA%AB/"/>
    <id>http://zhangyu33.com/2018/12/26/谈运维转型期的感悟和分享/</id>
    <published>2018-12-25T16:00:00.000Z</published>
    <updated>2018-12-26T02:01:44.595Z</updated>
    
    <content type="html"><![CDATA[<p> <a href="https://www.ssforce.cn/archives/314" target="_blank" rel="noopener">https://www.ssforce.cn/archives/314</a></p><p>结论：要么成为20%的Ops，要么职能尽量更前置、更顶端</p><p>最初研发兼任运维职能，而后发现运维需要专业化分工，遂拆分独立工种。</p><p>拆分发展期间各方技术&amp;理念不断进化，但运维实质上一直处于被动，成为优质的“背锅侠”，其属性在独立工种阶段难以扭转，这是因为在这期间运维所起到的价值并非由运维自身所决定，而是由整个软件交付体系&amp;生命周期、产品市场运营体系、甚至公司层面所决定。</p><p>在一家公司业务快速扩张过程中，上业务、抢市场这无可厚非，但很可悲的是一方面位于技术体系末端的运维往往眼睛很难看到技术、业务的前头，另一方面，作为优质的“兜底”牺牲自身发展成全业务也是天生其“使命”。</p><p>但自然生存法则不会考虑这些，只认结果，所以大部分Ops如果不能成为20%（跑的更快前置于技术&amp;业务、提升价值&amp;定位），其实结果一定是悲剧的。</p><p>现在无论是谁发起DevOps还是OpsDev，那都是因为运维的职能无法从更宏观角度去满足技术、业务发展的要求，原本对称的社会的供需关系失衡而已，但不管你承认与否，这就是强迫被迫转型而已，只不过有了更好的由头。</p><p>退一步，无论跑的再快快到前置在技术&amp;业务前；积极运作转型，提升运营价值、拔高定位，又如何？况且在一个复杂的技术体系和业务迭代动态过程中，能否做到这点也是个疑问。</p><p>所以，如果作为运维你现在无法抉择，未来是选择技术继续攻坚还是选择管理。没关系，在职能选择上：尽量选择一个更前置、更顶端的职能。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; &lt;a href=&quot;https://www.ssforce.cn/archives/314&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.ssforce.cn/archives/314&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;结论：要么成为20%的O
      
    
    </summary>
    
      <category term="运维" scheme="http://zhangyu33.com/categories/ops/"/>
    
    
      <category term="运维" scheme="http://zhangyu33.com/tags/%E8%BF%90%E7%BB%B4/"/>
    
  </entry>
  
  <entry>
    <title>被抛弃的tcp_recycle</title>
    <link href="http://zhangyu33.com/2018/12/05/%E8%A2%AB%E6%8A%9B%E5%BC%83%E7%9A%84tcp_recycle/"/>
    <id>http://zhangyu33.com/2018/12/05/被抛弃的tcp_recycle/</id>
    <published>2018-12-04T16:00:00.000Z</published>
    <updated>2018-12-05T06:15:29.262Z</updated>
    
    <content type="html"><![CDATA[<p>原创： SRE 小米运维<br><a href="https://mp.weixin.qq.com/s/uwykopNnkcRL5JXTVufyBw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/uwykopNnkcRL5JXTVufyBw</a></p><p> 1</p><p> 背景</p><p> 最近准备搭建一个新的kubernetes集群，将内核从3.18更新到了4.14版本，并执行一些常规的优化操作。在执行sysctl -p操作时突然报错如下：</p><pre><code>sysctl: cannot stat /proc/sys/net/ipv4/tcp_tw_recycle: No such file or directory</code></pre><p> 2</p><p> 问题原因</p><p> Linux 从4.12内核版本开始移除了 tcp_tw_recycle 配置。</p><p> 参考：[1]_tcp:remove tcp_tw_recycle 4396e460_</p><p> 移除sysctl.conf中关于net.ipv4.tcp_tw_recycle的配置内容，再次尝试sysctl -p就不再提示报错了。</p><p> 3</p><p> 深入解析</p><p> tcp_tw_recycle通常会和tcp_tw_reuse参数一起使用，用于解决服务器TIME_WAIT状态连接过多的问题。</p><p> 3.1</p><p> <strong>TIME_WAIT状态出现原因与查看</strong></p><p> 让我们回顾一下四次挥手的流程：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_jpg/Re4KW51oYRqZFnOjFRDiaOHz3WztCtNDncIialDaHtqKfRIy8I2KibjuZMwT6SKr13T2QIGpbCQ78rIK9LaooJiagw/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p><p> TIME_WAIT永远是出现在主动发送断开连接请求的一方(下文中我们称之为客户)，划重点：这一点面试的时候经常会被问到。  </p><p> 客户在收到服务器端发送的FIN(表示”我们也要断开连接了”)后发送ACK报文，并且进入TIME_WAIT状态，等待2MSL(MaximumSegmentLifetime 最大报文生存时间)。对于Linux，字段为TCP_TIMEWAIT_LEN硬编码为30秒，对于windows为2分钟(可自行调整)。</p><p> 为什么客户端不直接进入CLOSED状态，而是要在TIME_WAIT等待那么久呢，基于如下考虑：</p><p> 1.确保远程端处于关闭状态。也就是说需要确保客户端发出的最后一个ACK报文能够到达服务器。由于网络不可靠，有可能最后一个ACK报文丢失，如果服务器没有收到客户端的ACK，则会重新发送FIN报文，客户端就可以在2MSL时间段内收到这个这个重发的报文，并且重发ACK报文。但如果客户端跳过TIME_WAIT阶段进入了CLOSED，服务端始终无法得到响应，就会处于LAST-ACK状态，此时假如客户端发起了一个新连接，则会以失败告终。</p><p> 异常流程如下：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/Re4KW51oYRqZFnOjFRDiaOHz3WztCtNDnektVT22fqXfgIXK9H6ZJpyC3gHGG2RTd98JLefRCicRX4Ucb5n8YAFQ/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p><p> 2.防止上一次连接中的包，迷路后重新出现，影响新连接(经过2MSL,上一次连接中所有的重复包都会消失)，这一点和为啥要执行三次握手而不是两次的原因是一样的。</p><p> 异常流程如下：</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/Re4KW51oYRqZFnOjFRDiaOHz3WztCtNDn06zNjGmAGkn2S1HS3iabJVy8gZGu6gMogsh83KnN1vjmWwvF7rEI0oA/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p><p> 查看方式有两种：</p><p> （1）ss -tan state time-wait|wc -l</p><p> （2）netstat -n | awk ‘/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}’</p><p> 3.2</p><p> <strong>TIME_WAIT的危害</strong></p><p> 对于一个处理大量连接的处理器TIME_WAIT是有危害的，表现如下：  </p><p> 1.占用连接资源</p><p> TIME_WAIT占用的1分钟时间内，相同四元组(源地址，源端口，目标地址，目标端口)的连接无法创建，通常一个ip可以开启的端口为net.ipv4.ip_local_port_range指定的32768-61000，如果TIME_WAIT状态过多，会导致无法创建新连接。</p><p> 2.占用内存资源</p><p> 这个占用资源并不是很多，可以不用担心。</p><p> 3.3</p><p> <strong>TIME_WAIT的解决</strong></p><p> 可以考虑如下方式：  </p><p> 1.修改为长连接，代价较大，长连接对服务器性能有影响。</p><p> 2.增加可用端口范围(修改net.ipv4.ip_local_port_range); 增加服务端口，比如采用80，81等多个端口提供服务; 增加客户端ip(适用于负载均衡，比如nginx，采用多个ip连接后端服务器); 增加服务端ip; 这些方式治标不治本，只能缓解问题。</p><p> 3.将net.ipv4.tcp_max_tw_buckets设置为很小的值(默认是18000). 当TIME_WAIT连接数量达到给定的值时，所有的TIME_WAIT连接会被立刻清除，并打印警告信息。但这种粗暴的清理掉所有的连接，意味着有些连接并没有成功等待2MSL，就会造成通讯异常。</p><p> 4.修改TCP_TIMEWAIT_LEN值，减少等待时间，但这个需要修改内核并重新编译。</p><p> 5.打开tcp_tw_recycle和tcp_timestamps选项。</p><p> 6.打开tcp_tw_reuse和tcp_timestamps选项。</p><p> 3.4</p><p> <strong>net.ipv4.tcp_tw_{reuse,recycle}</strong></p><p> 需要明确两个点：  </p><p> 解决方式已经给出，那我们需要了解一下net.ipv4.tcp_tw_reuse和net.ipv4.tcp_tw_recycle有啥区别</p><p> 1.两个选项都需要打开对TCP时间戳的支持，即net.ipv4.tcp_timestamps=1(默认即为1)。</p><p> RFC 1323中实现了TCP拓展规范，以便保证网络繁忙的情况下的高可用。并定义了一个新的TCP选项-两个四字节的timestamp字段，第一个是TCP发送方的当前时钟时间戳，第二个是从远程主机接收到的最新时间戳。</p><p> 2.两个选项默认都是关闭状态，即等于0。</p><p> 3.4.1 - net.ipv4.tcp_tw_reuse：更安全的设置</p><p> 将处于TIME_WAIT状态的socket用于新的TCP连接，影响连出的连接。</p><p> [2]<em>kernel sysctl 官方指南</em>中是这么写的：</p><p> Allow to reuse TIME-WAIT sockets for new connections when it is safe from protocol viewpoint. Default value is 0.</p><p> It should not be changed without advice/request of technical experts.</p><p> 协议安全主要指的是两点：</p><p> 1.只适用于客户端(连接发起方)</p><p> <strong>net/ipv4/inet_hashtables.c</strong></p><pre><code>static int __inet_check_established(struct inet_timewait_death_row *death_row,                    struct sock *sk, __u16 lport,                    struct inet_timewait_sock **twp){    /* ……省略…… */    sk_nulls_for_each(sk2, node, &amp;head-chain) {            if (sk2-sk_hash != hash)                        continue;                                    if (likely(INET_MATCH(sk2, net, acookie,                    saddr, daddr, ports, dif))) {                        if (sk2-sk_state == TCP_TIME_WAIT) {                            tw = inet_twsk(sk2);                            if (twsk_unique(sk, sk2, twp))                                break;            }            goto not_unique;        }    }    /* ……省略…… */}</code></pre><p> 2.TIME_WAIT创建时间超过1秒才可以被复用</p><p> <strong>net/ipv4/tcp_ipv4.c</strong></p><pre><code>int tcp_twsk_unique(struct sock *sk, struct sock *sktw, void *twp){    /* ……省略…… */    if (tcptw-tw_ts_recent_stamp &amp;&amp;        (!twp || (sock_net(sk)-ipv4.sysctl_tcp_tw_reuse &amp;&amp;         get_seconds() - tcptw-tw_ts_recent_stamp  1))) {         /* ……省略…… */         return 1;    }    return 0;}</code></pre><p> 满足以上两个条件才会被认为是”safe from protocol viewpoint”的状况。启用net.ipv4.tcp_tw_reuse后，如果新的时间戳比之前存储的时间戳更大，那么Linux将会从TIME-WAIT状态的存活连接中选取一个，重新分配给新的连接出去的的TCP连接，这种情况下，TIME-WAIT的连接相当于只需要1秒就可以被复用了。</p><p> 重新回顾为什么要引入TIME-WAIT：</p><p> 第一个作用就是避免新连接接收到重复的数据包，由于使用了时间戳，重复的数据包会因为时间戳过期被丢弃。</p><p> 第二个作用是确保远端不是处于LAST-ACK状态，如果ACK包丢失，远端没有成功获取到最后一个ACK包，则会重发FIN包。直到：</p><p> 1.放弃(连接断开)</p><p> 2.收到ACK包</p><p> 3.收到RST包</p><p> 如果FIN包被及时接收到，并且本地端仍然是TIME-WAIT状态，那ACK包会被发送，此时就是正常的四次挥手流程。</p><p> 如果TIME-WAIT的条目已经被新连接所复用，则新连接的SYN包会被忽略掉，并且会收到FIN包的重传，本地会回复一个RST包(因为此时本地连接为SYN-SENT状态)，这会让远程端跳出LAST-ACK状态，最初的SYN包也会在1秒后重新发送，然后完成连接的建立，整个过程不会中断，只是有轻微的延迟。流程如下:</p><p> <img src="http://img01.store.sogou.com/net/a/04/link?appid=100520029&amp;url=https://mmbiz.qpic.cn/mmbiz_png/Re4KW51oYRqZFnOjFRDiaOHz3WztCtNDnXqUciblrAiaWZeVicfHRNNGJ5cW2YnP9GFxH1vFPjl0PUu6YhJcG2mpmg/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p><p> 需要注意，连接被复用后，TWrecycled计数器会增加(/proc/net/netstat中TWrecycled值)</p><p> 3.4.2 - net.ipv4.tcp_tw_recycle：更激进的设置</p><p> 启用TIME_WAIT 状态的sockets的快速回收，影响所有连入和连出的连接</p><p> [3]<em>kernel sysctl 官方指南 </em>是这么写的</p><p> Enable fast recycling TIME-WAIT sockets. Default value is 0. It should not be changed without advice/request of technical experts.</p><p> 这次表述的更加模糊，继续翻看源码：</p><p> <strong>net/ipv4/tcp_input.c</strong></p><p> int tcp_conn_request(struct request_sock_ops <em>rsk_ops,<br>             const struct tcp_request_sock_ops </em>af_ops,<br>             struct sock *sk, struct sk_buff *skb)<br> {<br>   /* ……省略…… <em>/  if (!want_cookie &amp;&amp; !isn) { /\</em> ……省略…… */<br>  if (net-ipv4.tcp_death_row.sysctl_tw_recycle) {<br>          bool strict;</p><p> dst = af_ops-route_req(sk, &amp;fl, req, &amp;strict); if (dst &amp;&amp; strict &amp;&amp;<br>               !tcp_peer_is_proven(req, dst, true,<br>                       tmp_opt.saw_tstamp)) {<br>               NET_INC_STATS(sock_net(sk), LINUX_MIB_PAWSPASSIVEREJECTED);<br>               goto drop_and_release;<br>        }<br>      }<br>  /* ……省略…… <em>/ isn = af_ops-init_seq(skb, &amp;tcp_rsk(req)-ts_off);<br>    }/\</em> ……省略…… */  </p><p> drop_and_release:<br>             dst_release(dst);<br>        drop_and_free:<br>             reqsk_free(req);<br>        drop:<br>             tcp_listendrop(sk);<br>             return  0;<br> }</p><p> 简单来说就是，Linux会丢弃所有来自远端的timestramp时间戳小于上次记录的时间戳(由同一个远端发送的)的任何数据包。也就是说要使用该选项，则必须保证数据包的时间戳是单调递增的。</p><p> 问题在于，此处的时间戳并不是我们通常意义上面的绝对时间，而是一个相对时间。很多情况下，我们是没法保证时间戳单调递增的，比如使用了nat，lvs等情况。</p><p> 而这也是很多优化文章中并没有提及的一点，大部分文章都是简单的推荐将net.ipv4.tcp_tw_recycle设置为1，却忽略了该选项的局限性，最终造成严重的后果(比如我们之前就遇到过部署在nat后端的业务网站有的用户访问没有问题，但有的用户就是打不开网页)。</p><p> 3.5</p><p> <strong>被抛弃的tcp_tw_recycle</strong></p><p> 如果说之前内核中tcp_tw_recycle仅仅不适用于nat和lvs环境，那么从4.10内核开始，官方修改了时间戳的生成机制。</p><p> 参考：[4] <em>tcp: randomize tcp timestamp offsets for each connection 95a22ca</em></p><p> 在这种情况下，无论任何时候，tcp_tw_recycle都不应该开启。故被抛弃也是理所应当的了。</p><p> 4</p><p> 总结</p><ul><li><p>tcp_tw_recycle 选项在4.10内核之前还只是不适用于NAT/LB的情况(其他情况下，我们也非常不推荐开启该选项)，但4.10内核后彻底没有了用武之地，并且在4.12内核中被移除.</p></li><li><p>tcp_tw_reuse 选项仍然可用。在服务器上面，启用该选项对于连入的TCP连接来说不起作用，但是对于客户端(比如服务器上面某个服务以客户端形式运行，比如nginx反向代理)等是一个可以考虑的方案。</p></li><li><p>修改TCP_TIMEWAIT_LEN是非常不建议的行为。</p></li></ul><p> 5<br> 参考链接</p><p> [1]<a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=4396e46187ca5070219b81773c4e65088dac50cc" target="_blank" rel="noopener">https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=4396e46187ca5070219b81773c4e65088dac50cc</a></p><p> [2]<a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/networking/ip-sysctl.txt?h=v4.11#n648" target="_blank" rel="noopener">https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/networking/ip-sysctl.txt?h=v4.11#n648</a></p><p> [3]<a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/networking/ip-sysctl.txt?h=v4.11#n643" target="_blank" rel="noopener">https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/networking/ip-sysctl.txt?h=v4.11#n643</a></p><p> [4]<a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=95a22caee396cef0bb2ca8fafdd82966a49367bb" target="_blank" rel="noopener">https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=95a22caee396cef0bb2ca8fafdd82966a49367bb</a>  </p><p> [5]Coping with the TCP TIME-WAIT state on busy Linux servers：<a href="https://vincent.bernat.ch/en/blog/2014-tcp-time-wait-state-linux" target="_blank" rel="noopener">https://vincent.bernat.ch/en/blog/2014-tcp-time-wait-state-linux</a></p><p> [6]net.ipv4.tcp_tw_recycle は廃止されました ― その危険性を理解する：<a href="https://qiita.com/tmshn/items/b49f1b51bfc472968b30" target="_blank" rel="noopener">https://qiita.com/tmshn/items/b49f1b51bfc472968b30</a></p><p> [7]tcp_tw_reuse、tcp_tw_recycle 使用场景及注意事项：<a href="https://www.cnblogs.com/lulu/p/4149312.html" target="_blank" rel="noopener">https://www.cnblogs.com/lulu/p/4149312.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;原创： SRE 小米运维&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/uwykopNnkcRL5JXTVufyBw&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s/uwy
      
    
    </summary>
    
      <category term="内核" scheme="http://zhangyu33.com/categories/%E5%86%85%E6%A0%B8/"/>
    
    
      <category term="内核" scheme="http://zhangyu33.com/tags/%E5%86%85%E6%A0%B8/"/>
    
  </entry>
  
  <entry>
    <title>PythonWeb开发和Django入门必读</title>
    <link href="http://zhangyu33.com/2018/12/03/PythonWeb%E5%BC%80%E5%8F%91%E5%92%8CDjango%E5%85%A5%E9%97%A8%E5%BF%85%E8%AF%BB/"/>
    <id>http://zhangyu33.com/2018/12/03/PythonWeb开发和Django入门必读/</id>
    <published>2018-12-02T16:00:00.000Z</published>
    <updated>2018-12-03T02:04:36.294Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Python-Web开发和Django入门必读"><a href="#Python-Web开发和Django入门必读" class="headerlink" title="Python Web开发和Django入门必读"></a>Python Web开发和Django入门必读</h2><p> 转载<br> 微信公众号【Python与Django大咖之路】<br><a href="https://mp.weixin.qq.com/s/x2lM26rrPiUTLYxXI_3PgQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/x2lM26rrPiUTLYxXI_3PgQ</a>)</p><p> <strong>Python与Django开发学习之路</strong>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483656&amp;idx=1&amp;sn=cff82f3e5761b96245658e70be75a3d6&amp;chksm=a73c6130904be8268c21f1747831292a43ce4a58e1d478e4bae039ce764bf0641db5335c5f93&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">网络应用开发为什么我们要学Django?</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483716&amp;idx=1&amp;sn=74916d348ef604013b2fd7700f273a25&amp;chksm=a73c617c904be86a5370b9163a39a9fa41c984ae79f42375ea774dc1c7036854b0a10d4b3cd0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">学好Python Web开发和Django能拿高工资吗?</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483679&amp;idx=1&amp;sn=63edf853c7b4833431fc104b71b502a2&amp;chksm=a73c6127904be831725f47d371816ad5259a0c93df9a98562514d73124deb7940714fe832565&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">如何对付学习Django过程中所遇到的挫败感?</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483978&amp;idx=1&amp;sn=3f4e975d7bf127750b6ffa1e2e229ebb&amp;chksm=a73c6272904beb645e6e4fffa2a259409c82c7d876a6c19124b4f791ed05b142100f461b969f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django常见错误总结: 细数我们一起走过的大坑</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247484113&amp;idx=1&amp;sn=c5f278922ee17a57ea39da63d7244bae&amp;chksm=a73c62e9904bebffd26f4597d719ae4ee1aea6b03c7a19c4ed391247c8c29f29b5638d599a5c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">什么人适合学习Django, 如何学习以及需要学习到什么程度可以找到工作?</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483901&amp;idx=1&amp;sn=d8a9ed6978edc4cf5c7d3c289a3eec85&amp;chksm=a73c61c5904be8d376e9dfb33df75a7c8a0f14bdc0ec90eb4d890e293af152020b26a9344b93&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">django的优缺点总结 - Python Web开发面试必备</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483862&amp;idx=1&amp;sn=01b34b6fe4fb78c50710de32267e37ca&amp;chksm=a73c61ee904be8f82d68a8d491dbfe570c43d58cf7c0ee0133b06c4798053bfcbdc9b6fad8ac&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">你应该使用的10个流行的Django第三方包</a></p><p> <strong>一文看到Python原创系列</strong></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483689&amp;idx=1&amp;sn=3c6e345f0dc083450a034a292abcdcba&amp;chksm=a73c6111904be8070fda0c5e64f9263193936aa9e80da13f0f8d77ad6559b431b4d576c0095c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">一文看懂Python面向对象编程(Python学习与新手入门必看)-原创</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483768&amp;idx=1&amp;sn=f7be1e186e74bc27eaf46d1d933fdf09&amp;chksm=a73c6140904be856a69f4276abbd9fa03052c7f83140be483f9a059368c420714734d77b8089&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">一文看懂Python对文件和文件夹的操作, 含shutil和glob模板 - 原创</a></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483821&amp;idx=1&amp;sn=0a6b10cb79e3723b133a51736ff15ae7&amp;chksm=a73c6195904be883228b286f5468e94fdeb9de05452e0210c26c0489d59082f251e2967884dd&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">一文看懂Python Web开发常见数据库MangoDB, Memcached和Redis</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247484141&amp;idx=1&amp;sn=4a640751190159558bdb7db6d5b3d529&amp;chksm=a73c62d5904bebc3a780224a2f6f1033a6ef8c1568f3a36585961d4d1fc3d3a942d31aa2e7fe&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">一文看懂Python字典类型数据常见操作及排序</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247484084&amp;idx=1&amp;sn=573989b9526aef01a3d515ab09afe86a&amp;chksm=a73c628c904beb9a39adef9b95a1ce6560245b7f4e2a39207a55abc1a293935be203a35bcb13&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">一文看懂Python多进程与多线程编程(工作学习面试必读)</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247484053&amp;idx=1&amp;sn=549909ee117ced2eda685cb2c22ca670&amp;chksm=a73c62ad904bebbb8d15834e6a679634df78708e54cc852e989629ddc644f9aa50900e179c1d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">一文看懂Python及Django不同类型数据的json序列化(面试工作必读)</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247484010&amp;idx=1&amp;sn=0973fb062415823ed80473efaa277133&amp;chksm=a73c6252904beb44b31dbca849efb5b15f503265022b6697abe0fb81cb88473982ad4b7cba82&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">一文看懂Python列表表达式及高阶函数如lambda, zip, enumerate, map和filter方法</a></p><p> <strong>Django Web开发核心基础知识</strong></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483665&amp;idx=1&amp;sn=19875184517f6513e53bec3b91c10202&amp;chksm=a73c6129904be83f13ff0501c1159b4e3b776f086613ce4e3fdff2b525aa361cee819f5ebd77&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django网站开发四件套是如何遵循MVC软件设计模式的?</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483679&amp;idx=2&amp;sn=9e3db4167e408a2a0c3a1037c4f7266a&amp;chksm=a73c6127904be831aee7abe13980fbea5e2d611ceb48e346dc0fc083c0a8725b52ebb3b8106f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础核心技术介绍(1): Model模型的介绍与设计</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483716&amp;idx=2&amp;sn=2c0ac2f977c063c67503a9ff3f8d4d0c&amp;chksm=a73c617c904be86a16e7389c3d66760b86e06dd2f5f2f0f0ef6007b38d32647d8700e2a0a48a&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础核心技术介绍(2): URL的设计与配置</a></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483764&amp;idx=1&amp;sn=f0756dbb9887a05280e6464194477e1d&amp;chksm=a73c614c904be85a8380a0d93155a5f70b9cdecf716f452ff9274a9ebeac1c194001beed7b23&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础核心技术介绍(3): View视图详解与通用视图</a></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483780&amp;idx=1&amp;sn=8d8e19c5d21efe986eaa62dce8f78e67&amp;chksm=a73c61bc904be8aa62f8933ab711ce35fed85dd99be7cee5f4c622599dcdee48305c26f9b5b0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础核心技术介绍(4): Template模板的编写及过滤器</a></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483813&amp;idx=1&amp;sn=bda48ff63fd4cc3b2cc0de408e7a1fa1&amp;chksm=a73c619d904be88b13d9c27bc4afb5ca45c76473c5d56cf3b5a0f7f9cf7a57775168ff6150f1&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础核心结束介绍(5): Forms表单的使用与设计</a></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483893&amp;idx=1&amp;sn=3554413878374aaf95631093d5849cb2&amp;chksm=a73c61cd904be8db56032d32654aca4374fb403e95d949f52a9a3ee57718a9e8641536c15206&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础(6): 模型Models高级进阶必读。</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483911&amp;idx=1&amp;sn=cb66b1179996ca1107af279cf40eb5ff&amp;chksm=a73c623f904beb29ebd1c4934ac1cc94e936b6615ed9dd9e258fa1d92d0c04b08c765c6b5d86&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础(7): cookie和session应用场景及如何使用</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483914&amp;idx=1&amp;sn=368657c4efc342d7d8e26a23f8209eb0&amp;chksm=a73c6232904beb249bd3705fdd09176b97fac5f49f152f846d5d10a3dac34e9ae88614f4e43d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础(8): 缓存Cache应用场景及工作原理，Cache设置及如何使用</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483923&amp;idx=1&amp;sn=7b350213d01de2b29005bed5e78941fb&amp;chksm=a73c622b904beb3d5ae0fe0abdd6f585ba23be0cc943a1594e446343e1aa0235441627ab1dfa&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础(9): 表单Forms的高级使用技巧</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483931&amp;idx=1&amp;sn=dcedf1b71eea1bcedab37fc6321caffd&amp;chksm=a73c6223904beb35a0994c7f4e85582074c17543bafb2c837e5af5f6c043f873d2b7fbd9dbea&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础(10): URL重定向的HttpResponseDirect, redirect和reverse的用法</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483938&amp;idx=1&amp;sn=0ac10883d95da506d3e780c6154c4ec7&amp;chksm=a73c621a904beb0cfc9e03b0ace4547405c4520bb0e0b00279237cfb5a7526c2ec4e4474a3cc&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础(11): 表单集合Formset的高级用法</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483945&amp;idx=1&amp;sn=f6f62eb51b4c95024cd6a23190e25893&amp;chksm=a73c6211904beb07dee79af98780387c46a4cb72f4363c5f2797ffefc39e1ea548c8ee047ad7&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础(12): Request对象详解及开发显示用户IP地址和浏览器APP</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483949&amp;idx=1&amp;sn=bc4c8929d5f8e99a769c63f2208ed6eb&amp;chksm=a73c6215904beb033f3277e3d1a98aaeece313792649cf96eea77cb1ee3d06bb493d06bc0c99&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础(13): 深夜放干货。QuerySet特性及高级使用技巧，如何减少数据库的访问，节省内存，提升网站性能。</a></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483974&amp;idx=1&amp;sn=986b0534fbb9f10452ff77770d196a95&amp;chksm=a73c627e904beb68e8f562a498fa5da88bac00d2d6bbcba6fc81be90f0b48a58bc1b10619cf6&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础(14): 通过next参数实现登录后跳转回到前一页的3种方法</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247484039&amp;idx=1&amp;sn=b8eb3a88bed07320a24f3a1bd7c8f369&amp;chksm=a73c62bf904beba97215cfd1a22891c412c715de3478980562226beeccddc0aa0e746315e1b8&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础(15): 模板过滤器(filter)的工作原理及如何自定义模板过滤器</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247484044&amp;idx=1&amp;sn=e200dca29baadfd55a80cbf10e5342d9&amp;chksm=a73c62b4904beba2cf7290f9d5f7a72c6157c05aa2e7abaa554b7f620c7549963ecea9c04636&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础(16): 模板标签(tags)的分类及如何自定义模板标签</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247484102&amp;idx=1&amp;sn=7bd1df46dee7ba89c2c13716449a6221&amp;chksm=a73c62fe904bebe8ae74ac967cb1f9d039abd9eba3b95ccdf2585de4ee5ad3134a30e6ed429f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础(17): 如何上传处理文件及Ajax文件上传示范(附GitHub源码)</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247484108&amp;idx=1&amp;sn=778143f345cb77c647f43cd7d90778ad&amp;chksm=a73c62f4904bebe23412cf002d27a2dd71034031fd32da36a2eb4a2e565feeb54c445eb88110&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础(18): 实现文件下载的3种方法及文件私有化</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247484126&amp;idx=1&amp;sn=db9e171b03c52aa6bad941ce84caf39c&amp;chksm=a73c62e6904bebf0aac2fd0f994bd5fc19b563a3e9dc1b9774b5b8bd2dd36d655aebda11a496&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础(19): Django Admin管理后台详解(上)</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247484136&amp;idx=1&amp;sn=b3f983f56a8d6fe94b3c137db5b9a209&amp;chksm=a73c62d0904bebc6709eacdcdff45bf5b1934036b9b884b8cbbe172c608c0f18336ae1e658a3&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django基础(20): Django admin管理后台详解(中)如何自定义list_display和list_filter</a>  </p><p> <strong>Django Web开发实战案例</strong></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483696&amp;idx=1&amp;sn=6c01e4f01dd274b05a0887a1ff04ad8a&amp;chksm=a73c6108904be81e369adea15cfec39ced7cac33e4c68564477b2755c7fb0b11c7419b2a28eb&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django 2.0 项目实战(1): 扩展Django自带User模型，实现用户注册与登录</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483709&amp;idx=1&amp;sn=a8fc48ab7b1c699a7fdef0bac6d3e69e&amp;chksm=a73c6105904be813db038f203e7a8800ad6bbe32d2bb3243cf8a6d72c10f0419e63c2dc58e6f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django 2.0 项目实战(2): 编辑用户个人资料，扩展Django后台UserAdmin</a></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483739&amp;idx=2&amp;sn=f1081873d87fe2de1a925ffeeb21686a&amp;chksm=a73c6163904be87570e6564769e2b8565a896b37c8964999304c43df151216e3c3e6f551623f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django 2.0项目实战(3): 密码重置与退出登录</a></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483759&amp;idx=1&amp;sn=ab30c1d66016306d05ab5caa8829794a&amp;chksm=a73c6157904be8419bff48476b0f37b6ed90244cfeb5f07595ac7d1ddd0bfc314e0523364153&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django 2.0 项目实战: 图片上传与显示</a></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483763&amp;idx=1&amp;sn=14719cba324b3990ce0ed02366bf45a9&amp;chksm=a73c614b904be85d91868a47d133a72f96d690bd8f6e866b49aa75f34d3fc17401c29cae30fd&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django 2.0 项目实战: PDF文件页面提取</a></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483772&amp;idx=1&amp;sn=e80169eda0b9a1919b6351c40a49fd70&amp;chksm=a73c6144904be852b223ea196e6b8650e257519d4b7c7797e0c17858704e5f3e94244d858e09&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django 2.0 项目实战: PDF文件合并</a></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483791&amp;idx=1&amp;sn=9ca6cc22476d2ede5cc320fd1b7f6525&amp;chksm=a73c61b7904be8a181297546dd7565a8e5b001f5a43c8cc544f4564c2634920642a3a0f6607c&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django 2.0 项目实战：输出树形分类目录</a></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483796&amp;idx=1&amp;sn=f9dd96a08e632553c53849dcb2cd26ef&amp;chksm=a73c61ac904be8ba6d4dc6e2c7552199fe1329c44c98df4603265059dd1dd4b718ec55576ede&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django 2.0 项目实战: 网页计数器统计浏览次数</a></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483810&amp;idx=1&amp;sn=d554570c8bd12560ec669aa67c0ee21a&amp;chksm=a73c619a904be88c197d6eac09466bc7ab214a57e26b11bb09da9a33fa1cef349277448c8325&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django 2.0 项目实战:  利用AJAX实现博文实时搜索</a></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483703&amp;idx=1&amp;sn=7d5573c4176147510ee433cbdeddde89&amp;chksm=a73c610f904be8194c597dc75a2bbd544c4ea230f84c92994de8239171cbefca4901e7ef2be7&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django 1.X和2.0下利用自带分页Paginator类实现分页功能</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483827&amp;idx=1&amp;sn=ba2e487b4721400577e6050dba1885b3&amp;chksm=a73c618b904be89d8fa9e6988755340d124af46182360b440641df83291c62f3dfd99c748f90&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django实战: 利用Ajax生成联动下拉菜单</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483833&amp;idx=1&amp;sn=b75c1c2adfbafbb1356f8a078218c206&amp;chksm=a73c6181904be897b32c043920b0407053789ac73ddcc65fcdfb161351fac30ac265a6193cbb&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">世界那么大，我想去看看。Django仿制微信朋友圈九宫格相册(1)</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483841&amp;idx=1&amp;sn=cac2440f92404724a563c1e8f3991816&amp;chksm=a73c61f9904be8efb84bea87dcd75baf538617da1d9fb6cd65c1a7df12ed9f4bc21a9deae75a&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">世界那么大，我想去看看。Django仿制微信朋友圈九宫格相册(2)</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483857&amp;idx=1&amp;sn=848e9778942008b5f2a170d44d28bc62&amp;chksm=a73c61e9904be8ffa7facea412fffc94e4e6372c702f1cf0cda8d65cd1e0c66ffb23f914998d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">django-allauth教程(1): 安装，用户注册，登录，邮箱验证和密码重置(更新)</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483857&amp;idx=2&amp;sn=85588634313b194d256888016ff501bc&amp;chksm=a73c61e9904be8ff644466e393889d868512f085ff5a8283a56f1ff7aea80b4aeb694e264745&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">django-allauth教程(2): 用户个人资料UserProfile扩展与编辑</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483871&amp;idx=1&amp;sn=a2043390f34a84d91875a9a20b06de9e&amp;chksm=a73c61e7904be8f14dedd23d49465adb4d126c4f1d367cd01eecab9020c9fc46be51dcca0db9&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">django-allauth教程(3): 第三方账户授权登录(以百度账号为例)</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483880&amp;idx=1&amp;sn=fa0c382260bbfdf49604f020db3fb054&amp;chksm=a73c61d0904be8c6700d7990d6f092178e2e4626673efec4e45c13770208f603c71231971226&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">django-allauth教程(4): 美化模板，自定义邮件和消息内容</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483919&amp;idx=1&amp;sn=92b03ee62de5d59d730847a40204c536&amp;chksm=a73c6237904beb219eeead51d36d0bf8c47497055db2983e7e4de382a5b5c306d345693ee5a3&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django+jQuery cropper实现用户头像裁剪, 预览和上传[原创]</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483959&amp;idx=1&amp;sn=f48efbb42b3f67c7ac01beb3f81545db&amp;chksm=a73c620f904beb1922ba1dd00ee15871d4ffdcd762861091af5f83e3b1f90391447463b12727&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django实战教程: 开发餐厅在线点评网站(1)</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483968&amp;idx=1&amp;sn=be82552e1d1641c3aa69c3fb9b39a542&amp;chksm=a73c6278904beb6ed786e5394f831bebfa75c909ed6f0ed7ca9a4a235024309c9f047f403b4d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django实战教程: 开发餐厅在线点评网站(2)</a></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483987&amp;idx=1&amp;sn=1e3fe837a73b1bdfa8bac9f4043c2e90&amp;chksm=a73c626b904beb7d2844c497f88b1107bf9642d05f9017562cb7ca8aa69ded9e1bcf5bedec1b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django实战教程: 开发企业级应用智能文档管理系统smartdoc(1)</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483999&amp;idx=1&amp;sn=f58503f4fe983f5a09ee736551c5b502&amp;chksm=a73c6267904beb71f13259603c63d902a40471a5fe38a768d1be96beb4623f086cff10b4c960&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django实战教程: 开发企业级应用智能文档管理系统smartdoc(2)之权限管理</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247484006&amp;idx=1&amp;sn=c37fbfbd12ab2d420334b6e3c5bd82e9&amp;chksm=a73c625e904beb481902266835eae575bd3d7b466690413d374cb5db16943e5cd0a5f971ea62&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django实战教程: 开发企业级应用智能文档管理系统smartdoc(3)附GitHub代码地址</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247484026&amp;idx=1&amp;sn=3f320aa57ac00c3fef4ea249228ccf6f&amp;chksm=a73c6242904beb545006e523208638051c79ea2e4bb6504e7a019761f8dd2bfc9269d12324ca&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django实战专题: 开发专业博客(1)之内容管理后台开发</a></p><p> <strong>Django Web开发学习笔记</strong></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483689&amp;idx=2&amp;sn=1b71deb02467bd5751f379e828cbe0bd&amp;chksm=a73c6111904be807e86c8754702f30b2dc43bdcddef4504aa51527d4155b3de2a2df79368228&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">浅谈Django Model创建对象的save与create方法</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483906&amp;idx=1&amp;sn=f126a28ba646dfaa936156bf9dc939a2&amp;chksm=a73c623a904beb2ce0c1e8878da48c03653dc75f7a4b92fdbb2c17de54a3999cafc9765c400a&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django模板设置全局变量(默认变量)</a></p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483897&amp;idx=1&amp;sn=69765d08f1de3e73a22589ef75f6d4a9&amp;chksm=a73c61c1904be8d7c212571cfeb466972c27af4adc411d4c344292e8d3a49b7544488c21f803&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django常用命令django-admin.py和manage.py用法详解</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483887&amp;idx=2&amp;sn=3d8531c15ffda4faa32bde775bfd61fb&amp;chksm=a73c61d7904be8c1621603284549aa7eca6e144d8603e6759172d6b5a6b92a0bf6e08ab2d672&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django自定义图片和文件上传路径(upload_to)的2种方式</a>  </p><p> <a href="http://mp.weixin.qq.com/s?__biz=MjM5OTMyODA4Nw==&amp;mid=2247483887&amp;idx=1&amp;sn=7d6f041ba6e223fd696da58b131ea8af&amp;chksm=a73c61d7904be8c1e55415cdebe453e8cfd3455a1b32c71494c225de4e8edd2baf4ebeb11612&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Django ContentTypes框架详解及使用场景介绍</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Python-Web开发和Django入门必读&quot;&gt;&lt;a href=&quot;#Python-Web开发和Django入门必读&quot; class=&quot;headerlink&quot; title=&quot;Python Web开发和Django入门必读&quot;&gt;&lt;/a&gt;Python Web开发和Djan
      
    
    </summary>
    
      <category term="Django" scheme="http://zhangyu33.com/categories/Django/"/>
    
    
      <category term="Django" scheme="http://zhangyu33.com/tags/Django/"/>
    
  </entry>
  
  <entry>
    <title>负载均衡获得真实源IP的6种方法</title>
    <link href="http://zhangyu33.com/2018/11/27/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E8%8E%B7%E5%BE%97%E7%9C%9F%E5%AE%9E%E6%BA%90IP%E7%9A%846%E7%A7%8D%E6%96%B9%E6%B3%95/"/>
    <id>http://zhangyu33.com/2018/11/27/负载均衡获得真实源IP的6种方法/</id>
    <published>2018-11-26T16:00:00.000Z</published>
    <updated>2018-12-26T02:02:22.286Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/qi1msOaElMDk8Ugc87KGLg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/qi1msOaElMDk8Ugc87KGLg</a> </p><p>原创： 小慢哥 小慢哥Linux运维</p><hr><h2 id="获得真实IP的6种方法"><a href="#获得真实IP的6种方法" class="headerlink" title="获得真实IP的6种方法"></a>获得真实IP的6种方法</h2><p> 当数据包从负载均衡器往后端转发时候，真实源IP可在L3、L4、L7实现，并且分别有2种方法可以获得真实IP，因此共有6种方法:</p><p> <strong>保持L3层源IP不变，根据连接次数可以分为</strong></p><ul><li><p>一次连接模式，如lvs</p></li><li><p>二次连接模式，如haproxy的透明模式</p></li></ul><p> <strong>在L4层数据里，添加源IP信息，有2种模式</strong></p><ul><li><p>在4层的option字段里增加源IP信息，比如tcp option、udp option</p></li><li><p>在4层末尾和7层开头之间，增加proxy protocol信息</p></li></ul><p> <strong>在L7层数据里，增加源IP信息，有2种模式</strong></p><ul><li><p>协议自带，例如HTTP的X-FORWARD-FOR</p></li><li><p>业务程序自行实现</p></li></ul><h2 id="一次连接与二次连接"><a href="#一次连接与二次连接" class="headerlink" title="一次连接与二次连接"></a>一次连接与二次连接</h2><p> 一次连接：负载均衡器对数据包仅做转发，而不对后端重新发起三次握手</p><p> 二次连接：和一次连接相对应，在tcp转发时候，对后端重新进行了三次握手。上面所讲的L4和L7方法的负载均衡，都是二次连接</p><p> 可以通过对比源端口是否有改变来简单判断是一次连接还是二次连接，端口没改变，可以理解为一次连接，有改变就是二次连接</p><h2 id="方法1-L3的一次连接模式"><a href="#方法1-L3的一次连接模式" class="headerlink" title="方法1: L3的一次连接模式"></a>方法1: L3的一次连接模式</h2><p> 介绍：是指在网络层不对源IP做修改，直接将数据包转发给后端，当后端接收到数据的时候，源IP就是真实IP。</p><p> 实现：LVS-DR、LVS-NAT、LVS-TUNNEL模式。其中LVS-TUNNEL比较特别，是在原有数据包的开头封装了IP头，当后端收到数据的时候，将封装的IP头进行解封装，获得的就是原有数据包。</p><p> 优点：逻辑简单，当负载均衡器故障切换的时候，从客户端到后端的tcp连接不会中断</p><p> 缺点：对网络架构有要求，比如DR模式，要求后端配VIP，并且回包要能直接回到客户机；NAT模式，要求回包经过负载均衡器；TUNNEL模式要求后端支持IPIP隧道</p><h2 id="方法2-L3的二次连接模式"><a href="#方法2-L3的二次连接模式" class="headerlink" title="方法2: L3的二次连接模式"></a>方法2: L3的二次连接模式</h2><p> 介绍：是指负载均衡器和后端重新进行三次握手，但保持数据包的源IP为真实IP。</p><p> 实现：haproxy（开启tproxy透明代理模式）+ iptables（fwmark打标记）+ 策略路由这3者组合才能实现</p><p> 优点：可以实现L7层（如HTTP/HTTPS）的负载均衡，而一次连接主要实现L4层的负载均衡</p><p> 缺点：配置最复杂，同时要求回包经过负载均衡器</p><h2 id="方法3-L4的toa模式"><a href="#方法3-L4的toa模式" class="headerlink" title="方法3: L4的toa模式"></a>方法3: L4的toa模式</h2><p> 介绍：在4层的option字段里增加源IP信息，比如在tcp option里增加源IP信息（称为toa）、udp option里增加源IP信息（称为uoa）</p><p> 实现：负载均衡器配置lvs-fullnat（只支持toa），iqiyi/dpvs（支持toa和uoa）；后端要加载toa、uoa模块，这个模块的作用是替换了后端应用程序获取IP的系统接口的钩子</p><p> 优点：对网络架构要求低</p><p> 缺点：lvs-fullnat需要编译内核，且只支持rhel/centos 6的内核，另外多年未更新；iqiyi/dpvs功能强大，但需要dpdk的支持；后端都需要加载toa/uoa模块，且只支持linux系统。</p><h2 id="方法4-L4的proxy-protocol模式"><a href="#方法4-L4的proxy-protocol模式" class="headerlink" title="方法4: L4的proxy protocol模式"></a>方法4: L4的proxy protocol模式</h2><p> 介绍：在L7层开头增加proxy protocol数据（该协议是haproxy发明），目前有v1（明文）和v2（二进制）版本</p><p> 实现：负载均衡器和后端同时开启proxy protocol，haproxy和nginx均支持，不过haproxy的配置颗粒度更小，另外nginx转发数据时候只支持v1</p><p> 优点：对网络架构要求低，只要程序支持即可，因此理论上没有操作系统限制</p><p> 缺点：目前支持proxy protocol的程序较少，且两端只能都开启或者都不开启该协议，不能一端开一端不开</p><h2 id="方法5-L7协议自带，例如HTTP的X-FORWARD-FOR"><a href="#方法5-L7协议自带，例如HTTP的X-FORWARD-FOR" class="headerlink" title="方法5: L7协议自带，例如HTTP的X-FORWARD-FOR"></a>方法5: L7协议自带，例如HTTP的X-FORWARD-FOR</h2><p> 介绍：最常见的方法，协议自带源IP信息，或者可定制插入</p><p> 实现：例如HTTP协议有X-FORWARD-FOR，也可以自己将源IP插入到HTTP头部信息里</p><p> 优点：对网络架构要求低，配置简便</p><p> 缺点：容易被伪造</p><h2 id="方法6-L7层业务程序自行实现"><a href="#方法6-L7层业务程序自行实现" class="headerlink" title="方法6: L7层业务程序自行实现"></a>方法6: L7层业务程序自行实现</h2><p> 介绍：最好的方法，就是业务方自行实现</p><p> 实现：业务自行实现，例如在client端插入源IP信息，带到server端</p><p> 优点：对网络架构无要求，只要网络可通即可，只要安全做好，不容易被伪造</p><p> 缺点：业务方要有一定开发能力</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p> 如果能做到无状态，不需要真实源IP，是最好的。因为这样对底层架构没有要求，底层架构就可以做的更高级更弹性。</p><p> 如果一定要获得真实源IP，推荐方案的顺序就是倒推，从L7到L3，即首选方法6，如果不行再选用方法5，以此类推到方法1</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/qi1msOaElMDk8Ugc87KGLg&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s/qi1msOaElMDk8Ugc87K
      
    
    </summary>
    
      <category term="负载均衡" scheme="http://zhangyu33.com/categories/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    
    
      <category term="负载均衡" scheme="http://zhangyu33.com/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    
  </entry>
  
  <entry>
    <title>浅谈大型互联网企业入侵检测及防护策略</title>
    <link href="http://zhangyu33.com/2018/11/23/%E6%B5%85%E8%B0%88%E5%A4%A7%E5%9E%8B%E4%BA%92%E8%81%94%E7%BD%91%E4%BC%81%E4%B8%9A%E5%85%A5%E4%BE%B5%E6%A3%80%E6%B5%8B%E5%8F%8A%E9%98%B2%E6%8A%A4%E7%AD%96%E7%95%A5/"/>
    <id>http://zhangyu33.com/2018/11/23/浅谈大型互联网企业入侵检测及防护策略/</id>
    <published>2018-11-22T16:00:00.000Z</published>
    <updated>2018-11-23T08:44:43.020Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://tech.meituan.com/Intrusion_Detection_Security_Meituan.html" target="_blank" rel="noopener">https://tech.meituan.com/Intrusion_Detection_Security_Meituan.html</a></p><p> 弼政 ·2018-11-08 20:00</p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p> 如何知道自己所在的企业是否被入侵了？是没人来“黑”，还是因自身感知能力不足，暂时还无法发现？其实，入侵检测是每一个大型互联网企业都要面对的严峻挑战。价值越高的公司，面临入侵的威胁也越大，即便是Yahoo这样的互联网鼻祖，在落幕（被收购）时仍遭遇全量数据失窃的事情。安全无小事，一旦互联网公司被成功“入侵”，其后果将不堪想象。</p><p> <img src="https://tech.meituan.com/img/Intrusion_Detection/1.jpg" alt=""></p><p> 基于“攻防对抗”的考量，本文不会提及具体的入侵检测模型、算法和策略，那些希望直接照搬“入侵策略”的同学可能会感到失望。但是我们会将一部分运营思路分享出来，请各位同行指点，如能对后来者起到帮助的作用，那就更好了，也欢迎大家跟我们交流探讨。</p><h2 id="入侵的定义"><a href="#入侵的定义" class="headerlink" title="入侵的定义"></a>入侵的定义</h2><p> 典型的入侵场景：</p><p>  黑客在很远的地方，通过网络远程控制目标的笔记本电脑/手机/服务器/网络设备，进而随意地读取目标的隐私数据，又或者使用目标系统上的功能，包括但不限于使用手机的麦克风监听目标，使用摄像头偷窥监控目标，使用目标设备的计算能力挖矿，使用目标设备的网络能力发动DDoS攻击等等。亦或是破解了一个服务的密码，进去查看敏感资料、控制门禁/红绿灯。以上这些都属于经典的入侵场景。</p><p> 我们可以给入侵下一个定义：就是黑客在未经授权的情况下，控制、使用我方资源（包括但不限于读写数据、执行命令、控制资源等）达到各种目的。从广义上讲，黑客利用SQL注入漏洞窃取数据，或者拿到了目标域名在ISP中的帐号密码，以篡改DNS指向一个黑页，又或者找到了目标的社交帐号，在微博/QQ/邮箱上，对虚拟资产进行非授权的控制，都属于入侵的范畴。</p><h2 id="针对企业的入侵检测"><a href="#针对企业的入侵检测" class="headerlink" title="针对企业的入侵检测"></a>针对企业的入侵检测</h2><p> 企业入侵检测的范围，多数情况下比较狭义：一般特指黑客对PC、系统、服务器、网络（包括办公网、生产网）控制的行为。</p><p> 黑客对PC、服务器等主机资产的控制，最常见的方法是通过Shell去执行指令，获得Shell的这个动作叫做GetShell。</p><p> 比如通过Web服务的上传漏洞，拿到WebShell，或者利用RCE漏洞直接执行命令/代码（RCE环境变相的提供了一个Shell）。另外，通过某种方式先植入“木马后门”，后续直接利用木马集成的SHELL功能对目标远程控制，这个也比较典型。</p><p> 因此，入侵检测可以重点关注GetShell这个动作，以及GetShell成功之后的恶意行为（为了扩大战果，黑客多半会利用Shell进行探测、翻找窃取、横向移动攻击其它内部目标，这些区别于好人的特性也可以作为重要的特征）。</p><p> 有一些同行（包括商业产品），喜欢报告GetShell之前的一些“外部扫描、攻击探测和尝试行为”，并美其名曰“态势感知”，告诉企业有人正在“试图攻击”。在笔者看来，实战价值并不大。包括美团在内的很多企业，基本上无时无刻都在遭受“不明身份”的攻击，知道了有人在“尝试”攻击，如果并不能有效地去行动，无法有效地对行动进行告警，除了耗费心力之外，并没有太大的实际价值。</p><p> 当我们习惯“攻击”是常态之后，就会在这样的常态下去解决问题，可以使用什么加固策略，哪些可以实现常态化的运营，如果有什么策略无法常态化运营，比如需要很多人加班临时突击守着，那这个策略多半在不久之后就会逐渐消逝掉。跟我们做不做这个策略，并没有本质上的区别。</p><p> 类似于SQL注入、XSS等一些不直接GetShell的Web攻击，暂时不在狭义的“入侵检测”考虑范围，建议可以划入“漏洞”、“威胁感知”等领域，另行再做探讨。当然，利用SQL注入、XSS等入口，进行了GetShell操作的，我们仍抓GetShell这个关键点，不必在乎漏洞入口在何处。</p><h2 id="“入侵”和“内鬼”"><a href="#“入侵”和“内鬼”" class="headerlink" title="“入侵”和“内鬼”"></a>“入侵”和“内鬼”</h2><p> 与入侵接近的一种场景是“内鬼”。入侵本身是手段，GetShell只是起点，黑客GetShell的目标是为了之后对资源的控制和数据的窃取。而“内鬼”天然拥有合法的权限，可以合法接触敏感资产，但是基于工作以外的目的，他们对这些资源进行非法的处置，包括拷贝副本、转移外泄、篡改数据牟利等。</p><p> <img src="https://tech.meituan.com/img/Intrusion_Detection/2.jpg" alt=""></p><p> 内鬼的行为不在“入侵检测”的范畴，一般从内部风险控制的视角进行管理和审计，比如职责分离、双人审计等。也有数据防泄密产品（DLP）对其进行辅助，这里不展开细说。</p><p> 有时候，黑客知道员工A有权限接触目标资产，便定向攻击A，再利用A的权限把数据窃取走，也定性为“入侵”。毕竟A不是主观恶意的“内鬼”。如果不能在黑客攻击A的那一刻捕获，或者无法区分黑客控制的A窃取数据和正常员工A的访问数据，那这个入侵检测也是失败的。</p><h2 id="入侵检测的本质"><a href="#入侵检测的本质" class="headerlink" title="入侵检测的本质"></a>入侵检测的本质</h2><p> 前文已经讲过，入侵就是黑客可以不经过我们的同意，来操作我们的资产，在手段上并没有任何的限制。那么如何找出入侵行为和合法正常行为的区别，将其跟合法行为进行分开，就是“入侵发现”。在算法模型上，这算是一个标记问题（入侵、非入侵）。</p><p> 可惜的是，入侵这种动作的“黑”样本特别稀少，想通过大量的带标签的数据，有监督的训练入侵检测模型，找出入侵的规律比较难。因此，入侵检测策略开发人员，往往需要投入大量的时间，去提炼更精准的表达模型，或者花更多的精力去构造“类似入侵”的模拟数据。</p><p> 一个经典的例子是，为了检测出WebShell，安全从业人员可以去GitHub上搜索一些公开的WebShell样本，数量大约不到1000个。而对于机器学习动辄百万级的训练需求，这些数据远远不够。况且GitHub上的这些样本集，从技术手法上来看，有单一技术手法生成的大量类似样本，也有一些对抗的手法样本缺失。因此，这样的训练，试图让AI去通过“大量的样本”掌握WebShell的特征并区分出它们，原则上不太可能完美地去实现。</p><p> 此时，针对已知样本做技术分类，提炼更精准的表达模型，被称为传统的特征工程。而传统的特征工程往往被视为效率低下的重复劳动，但效果往往比较稳定，毕竟加一个技术特征就可以稳定发现一类WebShell。而构造大量的恶意样本，虽然有机器学习、AI等光环加持，但在实际环境中往往难以获得成功：自动生成的样本很难描述WebShell本来的含义，多半描述的是自动生成的算法特征。</p><p> 另一个方面，入侵的区别是看行为本身是否“授权”，而授权与否本身是没有任何显著的区分特征的。因此，做入侵对抗的时候，如果能够通过某种加固，将合法的访问收敛到有限的通道，并且给该通道做出强有力的区分，也就能大大的降低入侵检测的成本。例如，对访问来源进行严格的认证，无论是自然人，还是程序API，都要求持有合法票据，而派发票据时，针对不同情况做多纬度的认证和授权，再用IAM针对这些票据记录和监控它们可以访问的范围，还能产生更底层的Log做异常访问模型感知。</p><p> 这个全生命周期的风控模型，也是Google的BeyondCorp无边界网络得以实施的前提和基础。</p><p> 因此，入侵检测的主要思路也就有2种：</p><ul><li>根据黑特征进行模式匹配（例如WebShell关键字匹配）。</li><li><p>根据业务历史行为（生成基线模型），对入侵行为做异常对比（非白既黑），如果业务的历史行为不够收敛，就用加固的手段对其进行收敛，再挑出不合规的小众异常行为。</p><h2 id="入侵检测与攻击向量"><a href="#入侵检测与攻击向量" class="headerlink" title="入侵检测与攻击向量"></a>入侵检测与攻击向量</h2><p>根据目标不同，可能暴露给黑客的攻击面会不同，黑客可能采用的入侵手法也就完全不同。比如，入侵我们的PC/笔记本电脑，还有入侵部署在机房/云上的服务器，攻击和防御的方法都有挺大的区别。</p><p>针对一个明确的“目标”，它被访问的渠道可能是有限集，被攻击的必经路径也有限。“攻击方法”+“目标的攻击面”的组合，被称为“攻击向量”。</p><p>因此，谈入侵检测模型效果时，需要先明确攻击向量，针对不同的攻击路径，采集对应的日志（数据），才可能做对应的检测模型。比如，基于SSH登录后的Shell命令数据集，是不能用于检测WebShell的行为。而基于网络流量采集的数据，也不可能感知黑客是否在SSH后的Shell环境中执行了什么命令。</p><p>基于此，如果有企业不提具体的场景，就说做好了APT感知模型，显然就是在“吹嘘”了。</p><p>所以，入侵检测得先把各类攻击向量罗列出来，每一个细分场景分别采集数据（HIDS+NIDS+WAF+RASP+应用层日志+系统日志+PC……），再结合公司的实际数据特性，作出适应公司实际情况的对应检测模型。不同公司的技术栈、数据规模、暴露的攻击面，都会对模型产生重大的影响。比如很多安全工作者特别擅长PHP下的WebShell检测，但是到了一个Java系的公司……</p><h2 id="常见的入侵手法与应对"><a href="#常见的入侵手法与应对" class="headerlink" title="常见的入侵手法与应对"></a>常见的入侵手法与应对</h2><p>如果对黑客的常见入侵手法理解不足，就很难有的放矢，有时候甚至会陷入“政治正确”的陷阱里。比如渗透测试团队说，我们做了A动作，你们竟然没有发现，所以你们不行。而实际情况是，该场景可能不是一个完备的入侵链条，就算不发现该动作，对入侵检测效果可能也没有什么影响。每一个攻击向量对公司造成的危害，发生的概率如何进行排序，解决它耗费的成本和带来的收益如何，都需要有专业经验来做支撑与决策。</p><p><img src="https://tech.meituan.com/img/Intrusion_Detection/3.jpg" alt=""></p><p>现在简单介绍一下，黑客入侵教程里的经典流程（完整过程可以参考杀伤链模型）：</p><p>入侵一个目标之前，黑客对该目标可能还不够了解，所以第一件事往往是“踩点”，也就是搜集信息，加深了解。比如，黑客需要知道，目标有哪些资产（域名、IP、服务），它们各自的状态如何，是否存在已知的漏洞，管理他们的人有谁（以及如何合法的管理的），存在哪些已知的泄漏信息（比如社工库里的密码等）……</p><p>一旦踩点完成，熟练的黑客就会针对各种资产的特性，酝酿和逐个验证“攻击向量”的可行性，下文列举了常见的攻击方式和防御建议。</p><h3 id="高危服务入侵"><a href="#高危服务入侵" class="headerlink" title="高危服务入侵"></a>高危服务入侵</h3><p>所有的公共服务都是“高危服务”，因为该协议或者实现该协议的开源组件，可能存在已知的攻击方法（高级的攻击者甚至拥有对应的0day），只要你的价值足够高，黑客有足够的动力和资源去挖掘，那么当你把高危服务开启到互联网，面向所有人都打开的那一刻，就相当于为黑客打开了“大门”。</p><p>比如SSH、RDP这些运维管理相关的服务，是设计给管理员用的，只要知道密码/秘钥，任何人都能登录到服务器端，进而完成入侵。而黑客可能通过猜解密码（结合社工库的信息泄露、网盘检索或者暴力破解），获得凭据。事实上这类攻击由于过于常见，黑客早就做成了全自动化的全互联网扫描的蠕虫类工具，云上购买的一个主机如果设置了一个弱口令，往往在几分钟内就会感染蠕虫病毒，就是因为这类自动化的攻击者实在是太多了。</p><p>或许，你的密码设置得非常强壮，但是这并不是你可以把该服务继续暴露在互联网的理由，我们应该把这些端口限制好，只允许自己的IP（或者内部的堡垒主机）访问，彻底断掉黑客通过它入侵我们的可能。</p><p>与此类似的，MySQL、Redis、FTP、SMTP、MSSQL、Rsync等等，凡是自己用来管理服务器或者数据库、文件的服务，都不应该针对互联网无限制的开放。否则，蠕虫化的攻击工具会在短短几分钟内攻破我们的服务，甚至直接加密我们的数据，甚至要求我们支付比特币，进行敲诈勒索。</p><p>还有一些高危服务存在RCE漏洞（远程命令执行），只要端口开放，黑客就能利用现成的exploit，直接GetShell，完成入侵。</p><p><strong>防御建议</strong>： 针对每一个高危服务做入侵检测的成本较高，因为高危服务的具体所指非常的多，不一定存在通用的特征。所以，通过加固方式，收敛攻击入口性价比更高。禁止所有高危端口对互联网开放可能，这样能够减少90%以上的入侵概率。</p><h3 id="Web入侵"><a href="#Web入侵" class="headerlink" title="Web入侵"></a>Web入侵</h3><p>随着高危端口的加固，黑客知识库里的攻击手法很多都会失效了。但是Web服务是现代互联网公司的主要服务形式，不可能都关掉。于是，基于PHP、Java、ASP、ASP.NET、Node、C写的CGI等等动态的Web服务漏洞，就变成了黑客入侵的最主要入口。</p><p>比如，利用上传功能直接上传一个WebShell，利用文件包含功能，直接引用执行一个远程的WebShell（或者代码），然后利用代码执行的功能，直接当作Shell的入口执行任意命令，解析一些图片、视频的服务，上传一个恶意的样本，触发解析库的漏洞……</p><p>Web服务下的应用安全是一个专门的领域（道哥还专门写了本《白帽子讲Web安全》），具体的攻防场景和对抗已经发展得非常成熟了。当然，由于它们都是由Web服务做为入口，所以入侵行为也会存在某种意义上的共性。相对而言，我们比较容易能够找到黑客GetShell和正常业务行为的一些区别。</p><p>针对Web服务的入侵痕迹检测，可以考虑采集WAF日志、Access Log、Auditd记录的系统调用，或者Shell指令，以及网络层面Response相关的数据，提炼出被攻击成功的特征，建议我们将主要的精力放在这些方面。</p><h3 id="0day入侵"><a href="#0day入侵" class="headerlink" title="0day入侵"></a>0day入侵</h3><p>通过泄漏的工具包来看，早些年NSA是拥有直接攻击Apache、Nginx这些服务的0day武器的。这意味着对手很可能完全不用在乎我们的代码和服务写成什么样，拿0day一打，神不知鬼不觉就GetShell了。</p><p>但是对于入侵检测而言，这并不可怕：因为无论对手利用什么漏洞当入口，它所使用的Shellcode和之后的行为本身依然有共性。Apache存在0day漏洞被攻击，还是一个PHP页面存在低级的代码漏洞被利用，从入侵的行为上来看，说不定是完全一样的，入侵检测模型还可以通用。</p><p>所以，把精力聚焦在有黑客GetShell入口和之后的行为上，可能比关注漏洞入口更有价值。当然，具体的漏洞利用还是要实际跟进，然后验证其行为是否符合预期。</p><h3 id="办公终端入侵"><a href="#办公终端入侵" class="headerlink" title="办公终端入侵"></a>办公终端入侵</h3><p>绝大多数APT报告里，黑客是先对人（办公终端）下手，比如发个邮件，哄骗我们打开后，控制我们的PC，再进行长期的观察/翻阅，拿到我们的合法凭据后，再到内网漫游。所以这些报告，多数集中在描述黑客用的木马行为以及家族代码相似度上。而反APT的产品、解决方案，多数也是在办公终端的系统调用层面，用类似的方法，检验“免杀木马”的行为。</p><p>因此，EDR类的产品+邮件安全网关+办公网出口的行为审计+APT产品的沙箱等，联合起来，可以采集到对应的数据，并作出相似的入侵检测感知模型。而最重要的一点，是黑客喜欢关注内部的重要基础设施，包括但不限于AD域控、邮件服务器、密码管理系统、权限管理系统等，一旦拿下，就相当于成为了内网的“上帝”，可以为所欲为。所以对公司来说，重要基础设施要有针对性的攻防加固讨论，微软针对AD的攻防甚至还发过专门的加固白皮书。</p><h2 id="入侵检测基本原则"><a href="#入侵检测基本原则" class="headerlink" title="入侵检测基本原则"></a>入侵检测基本原则</h2><p>不能把每一条告警都彻底跟进的模型，等同于无效模型。入侵发生后，再辩解之前其实有告警，只是太多了没跟过来/没查彻底，这是“马后炮”，等同于不具备发现能力，所以对于日均告警成千上万的产品，安全运营人员往往表示很无奈。</p><p>我们必须屏蔽一些重复发生的相似告警，以集中精力把每一个告警都闭环掉。这会产生白名单，也就是漏报，因此模型的漏报是不可避免的。</p><p>由于任何模型都会存在漏报，所以我们必须在多个纬度上做多个模型，形成关联和纵深。假设WebShell静态文本分析被黑客变形绕过了，在RASP（运行时环境）的恶意调用还可以进行监控，这样可以选择接受单个模型的漏报，但在整体上仍然具备发现能力。</p><p>既然每一个单一场景的模型都有误报漏报，我们做什么场景，不做什么场景，就需要考虑“性价比”。比如某些变形的WebShell可以写成跟业务代码非常相似，人的肉眼几乎无法识别，再追求一定要在文本分析上进行对抗，就是性价比很差的决策。如果通过RASP的检测方案，其性价比更高一些，也更具可行性一些。</p><p>我们不太容易知道黑客所有的攻击手法，也不太可能针对每一种手法都建设策略（考虑到资源总是稀缺的）。所以针对重点业务，需要可以通过加固的方式（还需要常态化监控加固的有效性），让黑客能攻击的路径极度收敛，仅在关键环节进行对抗。起码能针对核心业务具备兜底的保护能力。</p><p>基于上述几个原则，我们可以知道一个事实，或许我们永远不可能在单点上做到100%发现入侵，但是我们可以通过一些组合方式，让攻击者很难绕过所有的点。</p><p>当老板或者蓝军挑战，某个单点的检测能力有缺失时，如果为了“政治正确”，在这个单点上进行无止境的投入，试图把单点做到100%能发现的能力，很多时候可能只是在试图制造一个“永动机”，纯粹浪费人力、资源，而不产生实际的收益。将节省下来的资源，高性价比的布置更多的纵深防御链条，效果显然会更好。</p><h2 id="入侵检测产品的主流形态"><a href="#入侵检测产品的主流形态" class="headerlink" title="入侵检测产品的主流形态"></a>入侵检测产品的主流形态</h2><p>入侵检测终究是要基于数据去建模，比如针对WebShell的检测，首先要识别Web目录，再对Web目录下的文件进行文本分析，这需要做一个采集器。基于Shell命令的入侵检测模型，需要获取所有Shell命令，这可能要Hook系统调用或者劫持Shell。基于网络IP信誉、流量payload进行检测，或者基于邮件网关对内容的检查，可能要植入网络边界中，对流量进行旁路采集。</p><p>也有一些集大成者，基于多个Sensor，将各方日志进行采集后，汇总在一个SOC或者SIEM，再交由大数据平台进行综合分析。因此，业界的入侵检测相关的产品大致上就分成了以下的形态：</p></li><li><p>主机Agent类：黑客攻击了主机后，在主机上进行的动作，可能会产生日志、进程、命令、网络等痕迹，那么在主机上部署一个采集器（也内含一部分检测规则），就叫做基于主机的入侵检测系统，简称HIDS。</p><ul><li>典型的产品：OSSEC、青藤云、安骑士、安全狗，Google最近也发布了一个Alpha版本的类似产品 Cloud Security Command Center。当然，一些APT厂商，往往也有在主机上的Sensor/Agent，比如FireEye等。</li></ul></li><li><p>网络检测类：由于多数攻击向量是会通过网络对目标投放一些payload，或者控制目标的协议本身具备强特征，因此在网络层面具备识别的优势。</p><ul><li>典型的产品：Snort到商业的各种NIDS/NIPS，对应到APT级别，则还有类似于FireEye的NX之类的产品。</li></ul></li><li><p>日志集中存储分析类：这一类产品允许主机、网络设备、应用都输出各自的日志，集中到一个统一的后台，在这个后台，对各类日志进行综合的分析，判断是否可以关联的把一个入侵行为的多个路径刻画出来。例如A主机的的Web访问日志里显示遭到了扫描和攻击尝试，继而主机层面多了一个陌生的进程和网络连接，最后A主机对内网其它主机进行了横向渗透尝试。</p><ul><li>典型的产品：LogRhythm、Splunk等SIEM类产品。</li></ul></li><li><p>APT沙箱：沙箱类产品更接近于一个云端版的高级杀毒软件，通过模拟执行观测行为，以对抗未知样本弱特征的特点。只不过它需要一个模拟运行的过程，性能开销较大，早期被认为是“性价比不高”的解决方案，但由于恶意文件在行为上的隐藏要难于特征上的对抗，因此现在也成为了APT产品的核心组件。通过网络流量、终端采集、服务器可疑样本提取、邮件附件提炼等拿到的未知样本，都可以提交到沙箱里跑一下行为，判断是否恶意。</p><ul><li>典型产品：FireEye、Palo Alto、Symantec、微步。</li></ul></li><li><p>终端入侵检测产品：移动端目前还没有实际的产品，也不太有必要。PC端首先必备的是杀毒软件，如果能够检测到恶意程序，一定程度上能够避免入侵。但是如果碰到免杀的高级0day和木马，杀毒软件可能会被绕过。借鉴服务器上HIDS的思路，也诞生了EDR的概念，主机除了有本地逻辑之外，更重要的是会采集更多的数据到后端，在后端进行综合分析和联动。也有人说下一代杀毒软件里都会带上EDR的能力，只不过目前销售还是分开在卖。</p><ul><li>典型产品：杀毒软件有Bit9、SEP、赛门铁克、卡巴斯基、McAfee ；EDR产品不枚举了，腾讯的iOA、阿里的阿里郎，一定程度上都是可以充当类似的角色；</li></ul><h2 id="入侵检测效果评价指标"><a href="#入侵检测效果评价指标" class="headerlink" title="入侵检测效果评价指标"></a>入侵检测效果评价指标</h2><p>首先，主动发现的入侵案例/所有入侵 = 主动发现率。这个指标一定是最直观的。比较麻烦的是分母，很多真实发生的入侵，如果外部不反馈，我们又没检测到，它就不会出现在分母里，所以有效发现率总是虚高的，谁能保证当前所有的入侵都发现了呢？（但是实际上，只要入侵次数足够多，不管是SRC收到的情报，还是“暗网”上报出来的一个大新闻，把客观上已经知悉的入侵列入分母，总还是能计算出一个主动发现率的。）</p><p>另外，真实的入侵其实是一个低频行为，大型的互联网企业如果一年到头成百上千的被入侵，肯定也不正常。因此，如果很久没出现真实入侵案例，这个指标长期不变化，也无法刻画入侵检测能力是否在提升。</p><p>所以，我们一般还会引入两个指标来观测：</p></li><li><p>蓝军对抗主动发现率</p></li><li><p>已知场景覆盖率</p><p>蓝军主动高频对抗和演习，可以弥补真实入侵事件低频的不足，但是由于蓝军掌握的攻击手法往往也是有限的，他们多次演习后，手法和场景可能会被罗列完毕。假设某一个场景建设方尚未补齐能力，蓝军同样的姿势演习100遍，增加100个未发现的演习案例，对建设方而言并没有更多的帮助。所以，把已知攻击手法的建成覆盖率拿出来，也是一个比较好的评价指标。</p><p>入侵检测团队把精力聚焦在已知攻击手法的优先级评估和快速覆盖上，对建设到什么程度是满足需要的，要有自己的专业判断（参考入侵检测原则里的“性价比”原则）。</p><p>而宣布建成了一个场景的入侵发现能力，是要有基本的验收原则的：</p></li><li><p>该场景日均工单 &lt; X单，峰值 &lt; Y单；当前所有场景日平均&lt;XX，峰值 &lt;YY，超出该指标的策略不予接收，因为过多的告警会导致有效信息被淹没，反而导致此前具备的能力被干扰，不如视为该场景尚未具备对抗能力。</p></li><li>同一个事件只告警首次，多次出现自动聚合。</li><li>具备误报自学习能力。</li><li>告警具备可读性（有清晰的风险阐述、关键信息、处理指引、辅助信息或者索引，便于定性），不鼓励Key-Value模式的告警，建议使用自然语言描述核心逻辑和响应流程。</li><li>有清晰的说明文档，自测报告（就像交付了一个研发产品，产品文档和自测过程是质量的保障）。</li><li>有蓝军针对该场景实战验收报告。</li><li><p>不建议调用微信、短信等接口发告警（告警和事件的区别是，事件可以闭环，告警只是提醒），统一的告警事件框架可以有效的管理事件确保闭环，还能提供长期的基础运营数据，比如止损效率、误报量/率。</p><p>策略人员的文档应当说明当前模型对哪些情况具备感知能力，哪些前提下会无法告警（考验一个人对该场景和自己模型的理解能力）。通过前述判断，可以对策略的成熟度形成自评分，0-100自由大致估算。单个场景往往很难达到100分，但那并没有关系，因为从80分提升到100分的边际成本可能变的很高。不建议追求极致，而是全盘审视，是否快速投入到下一个场景中去。</p><p>如果某个不到满分的场景经常出现真实对抗，又没有交叉的其它策略进行弥补，那自评结论可能需要重审并提高验收的标准。至少解决工作中实际遇到的Case要优先考虑。</p><h2 id="影响入侵检测的关键要素"><a href="#影响入侵检测的关键要素" class="headerlink" title="影响入侵检测的关键要素"></a>影响入侵检测的关键要素</h2><p>讨论影响入侵检测的要素时，我们可以简单看看，曾经发生过哪些错误导致防守方不能主动发现入侵：</p></li><li><p>依赖的数据丢失，比如HIDS在当事机器上，没部署安装/Agent挂了/数据上报过程丢失了/Bug了，或者后台传输链条中丢失数据。</p></li><li>策略脚本Bug，没启动（事实上我们已经失去了这个策略感知能力了）。</li><li>还没建设对应的策略（很多时候入侵发生了才发现这个场景我们还没来得及建设对应的策略）。</li><li>策略的灵敏度/成熟度不够（比如扫描的阈值没达到，WebShell用了变形的对抗手法）。</li><li>模型依赖的部分基础数据错误，做出了错误的判断。</li><li><p>成功告警了，但是负责应急同学错误的判断/没有跟进/辅助信息不足以定性，没有行动起来。</p><p>所以实际上，要让一个入侵事件被捕获，我们需要入侵检测系统长时间、高质量、高可用的运行。这是一件非常专业的工作，超出了绝大多数安全工程师能力和意愿的范畴。所以建议指派专门的运营人员对以下目标负责：</p></li><li><p>数据采集的完整性（全链路的对账）。</p></li><li>每一个策略时刻工作正常（自动化拨测监控）。</li><li>基础数据的准确性。</li><li><p>工单运营支撑平台及追溯辅助工具的便捷性。</p><p>可能有些同学会想，影响入侵检测的关键要素，难道不是模型的有效性么？怎么全是这些乱七八糟的东西？</p><p>实际上，大型互联网企业的入侵检测系统日均数据量可能到达数百T，甚至更多。涉及到数十个业务模块，成百上千台机器。从数字规模上来说，不亚于一些中小型企业的整个数据中心。这样复杂的一个系统，要长期维持在高可用标准，本身就需要有SRE、QA等辅助角色的专业化支持。如果仅依靠个别安全工程师，很难让其研究安全攻防的时候，又兼顾到基础数据质量、服务的可用性和稳定性、发布时候的变更规范性、各类运营指标和运维故障的及时响应。最终的结果就是能力范围内可以发现的入侵，总是有各种意外“恰好”发现不了。</p><p>所以，笔者认为，以多数安全团队运营质量之差，其实根本轮不到拼策略（技术）。当然，一旦有资源投入去跟进这些辅助工作之后，入侵检测就真的需要拼策略了。</p><p>此时，攻击手法有那么多，凭什么先选择这个场景建设？凭什么认为建设到某程度就足够满足当下的需要了？凭什么选择发现某些样本，而放弃另一些样本的对抗？</p><p>这些看似主观性的东西，非常考验专业判断力。而且在领导面前很容易背上“责任心不足”的帽子，比如为困难找借口而不是为目标找方法，这个手法黑客攻击了好多次，凭什么不解决，那个手法凭什么说在视野范围内，但是要明年再解决？</p><h2 id="如何发现APT？"><a href="#如何发现APT？" class="headerlink" title="如何发现APT？"></a>如何发现APT？</h2><p>所谓APT，就是高级持续威胁。既然是高级的，就意味着木马很大可能是免杀的（不能靠杀毒软件或者普通的特征发现），利用的漏洞也是高级的（加固到牙齿可能也挡不住敌人进来的步伐），攻击手法同样很高级（攻击场景可能我们都没有见过）。</p><p>所以，实际上APT的意思，就约等于同于不能被发现的入侵。然而，业界总还有APT检测产品，解决方案的厂商在混饭吃，他们是怎么做的呢？</p></li><li><p>木马免杀的，他们用沙箱+人工分析，哪怕效率低一些，还是试图做出定性，并快速的把IOC（威胁情报）同步给其它客户，发现1例，全球客户都具备同样的感知能力。</p></li><li><p>流量加密变形对抗的，他们用异常检测的模型，把一些不认识的可疑的IP关系、payload给识别出来。当然，识别出来之后，也要运营人员跟进得仔细，才能定性。</p></li><li><p>攻击手法高级的，他们还是会假定黑客就用鱼叉、水坑之类的已知手法去执行，然后在邮箱附件、PC终端等环节采集日志，对用户行为进行分析，UEBA试图寻找出用户异于平常的动作。</p></li></ul><p> 那么，我们呢？笔者也没有什么好的办法，可以发现传说中的“免杀”的木马，但是我们可以针对已知的黑客攻击框架（比如Metasploit、Cobalt Strike）生成的样本、行为进行一些特征的提取。我们可以假设已经有黑客控制了某一台机器，但是它试图进行横向扩散的时候，我们有一些模型可以识别这个主机的横向移动行为。</p><p> 笔者认为，世界上不存在100%能发现APT的方法。但是我们可以等待实施APT的团队犯错，只要我们的纵深足够的多，信息足够不对称，想要完全不触碰我们所有的铃铛，绝对存在一定的困难。</p><p> 甚至，攻击者如果需要小心翼翼的避开所有的检测逻辑，可能也会给对手一种心理上的震慑，这种震慑可能会延缓对手接近目标的速度，拉长时间。而在这个时间里，只要他犯错，就轮到我们出场了。</p><p> 前面所有的高标准，包括高覆盖、低误报，强制每一个告警跟进到底，“掘地三尺”的态度，都是在等待这一刻。抓到一个值得敬佩的对手，那种成就感，还是很值得回味的。</p><p> 所以，希望所有从事入侵检测的安全同行们都能坚持住，即使听过无数次“狼来了”，下一次看到告警，依然可以用最高的敬畏心去迎接对手（告警虐我千百遍，我待告警如初恋）。</p><h2 id="AI在入侵检测领域的正确姿势"><a href="#AI在入侵检测领域的正确姿势" class="headerlink" title="AI在入侵检测领域的正确姿势"></a>AI在入侵检测领域的正确姿势</h2><p> 最近这两年，如果不谈AI的话，貌似故事就不会完整。只不过，随着AI概念的火爆，很多人已经把传统的数据挖掘、统计分析等思想，比如分类、预测、聚类、关联之类的算法，都一律套在AI的帽子里。</p><p> <img src="https://tech.meituan.com/img/Intrusion_Detection/4.jpg" alt=""></p><p> 其实AI是一种现代的方法，在很多地方有非常实际的产出了。以WebShell的文本分析为例，我们可能需要花很长很长的时间，才能把上千个样本里隐含的几十种样本技术类型拆分开，又花更长的时间去一一建设模型（是的，在这样的场景下，特征工程真的是一个需要更长时间的工作）。</p><p> 而使用AI，做好数据打标的工作，训练、调参，很快就能拿到一个实验室环境不那么过拟合的模型出来，迅速投产到生产环境上。熟练一点可能1-2个月就能做完了。</p><p> 在这种场景下，AI这种现代的方法，的确能极大地提高效率。但问题是，前文也提到过了，黑客的攻击黑样本、WebShell的样本，往往极其稀缺，它不可能是完备的能够描述黑客入侵的完整特征的。因此，AI产出的结果，无论是误报率还是漏报率，都会受训练方法和输入样本的影响较大，我们可以借助AI，但绝对不能完全交给AI。</p><p> 安全领域一个比较常见的现象是，将场景转变成标记问题，要难过于通过数学模型把标记的解给求出来。此时往往需要安全专家先行，算法专家再跟上，而不能直接让算法专家“孤军奋战”。</p><p> 针对一个具体的攻击场景，怎么样采集对应的入侵数据，思考这个入侵动作和正常行为的区别，这个特征的提取过程，往往决定了模型最终的效果。特征决定了效果的上限，而算法模型只能决定了有多接近这个上限。</p><p> 此前，笔者曾见过一个案例，AI团队产出了一个实验室环境效果极佳，误报率达到1/1000000的WebShell模型，但是投放到生产环境里初期日均告警6000单，完全无法运营，同时还存在不少漏报的情况。这些情况随着安全团队和AI工程师共同的努力，后来逐渐地解决。但是并未能成功的取代原有的特征工程模型。</p><p> 目前业界有许多产品、文章在实践AI，但遗憾的是，这些文章和产品大多“浅尝辄止”，没有在真实的环境中实践运营效果。一旦我们用前面的标准去要求它，就会发现，AI虽然是个好东西，但是绝对只是个“半成品”。真正的运营，往往需要传统的特征工程和AI并行，也需要持续地进行迭代。</p><p> 未来必然是AI的天下，但是有多少智能，前面可能就要铺垫多少人工。愿与同行们一起在这个路上继续探索下去，多多交流分享。</p><h2 id="关于美团安全"><a href="#关于美团安全" class="headerlink" title="关于美团安全"></a>关于美团安全</h2><p> 美团安全部的大多数核心开发人员，拥有多年互联网以及安全领域实践经验，很多同学参与过大型互联网公司的安全体系建设，其中也不乏全球化安全运营人才，具备百万级IDC规模攻防对抗的经验。安全部也不乏CVE“挖掘圣手”，有受邀在Black Hat等国际顶级会议发言的讲者，当然还有很多漂亮的运营妹子。</p><p> 目前，美团安全部涉及的技术包括渗透测试、Web防护、二进制安全、内核安全、分布式开发、大数据分析、安全算法等等，同时还有全球合规与隐私保护等策略制定。我们正在建设一套百万级IDC规模、数十万终端接入的移动办公网络自适应安全体系，这套体系构建于零信任架构之上，横跨多种云基础设施，包括网络层、虚拟化/容器层、Server 软件层（内核态/用户态）、语言虚拟机层(JVM/JS V8)、Web应用层、数据访问层等，并能够基于大数据+机器学习技术构建全自动的安全事件感知系统，努力打造成业界最前沿的内置式安全架构和纵深防御体系。</p><p> 随着美团的高速发展，业务复杂度不断提升，安全部门面临更多的机遇和挑战。我们希望将更多代表业界最佳实践的安全项目落地，同时为更多的安全从业者提供一个广阔的发展平台，并提供更多在安全新兴领域不断探索的机会。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://tech.meituan.com/Intrusion_Detection_Security_Meituan.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://tech.meituan.com/Intr
      
    
    </summary>
    
      <category term="安全" scheme="http://zhangyu33.com/categories/%E5%AE%89%E5%85%A8/"/>
    
    
      <category term="安全" scheme="http://zhangyu33.com/tags/%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>新一代数据库TiDB在美团的实践</title>
    <link href="http://zhangyu33.com/2018/11/23/%E6%96%B0%E4%B8%80%E4%BB%A3%E6%95%B0%E6%8D%AE%E5%BA%93TiDB%E5%9C%A8%E7%BE%8E%E5%9B%A2%E7%9A%84%E5%AE%9E%E8%B7%B5/"/>
    <id>http://zhangyu33.com/2018/11/23/新一代数据库TiDB在美团的实践/</id>
    <published>2018-11-22T16:00:00.000Z</published>
    <updated>2018-11-23T08:15:11.520Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://tech.meituan.com/MySQL_PingCAP_Practice.html" target="_blank" rel="noopener">https://tech.meituan.com/MySQL_PingCAP_Practice.html</a></p><p> 应钢 李坤 昌俊 ·2018-11-22 20:00</p><h1 id="1-背景和现状"><a href="#1-背景和现状" class="headerlink" title="1. 背景和现状"></a>1. 背景和现状</h1><p> 近几年，基于MySQL构建的传统关系型数据库服务，已经很难支撑美团业务的爆发式增长，这就促使我们去探索更合理的数据存储方案和实践新的运维方式。而随着分布式数据库大放异彩，美团DBA团队联合基础架构存储团队，于 2018 年初启动了分布式数据库项目。</p><p> <img src="https://tech.meituan.com/img/MySQL_PingCAP_Practice/01.png" alt=""></p><p> 图 1 美团点评产品展示图</p><p> 在立项之初，我们进行了大量解决方案的对比，深入了解了业界的 scale-out（横向扩展）、scale-up（纵向扩展）等解决方案。但考虑到技术架构的前瞻性、发展潜力、社区活跃度以及服务本身与 MySQL 的兼容性，我们最终敲定了基于 <a href="https://www.pingcap.com/" target="_blank" rel="noopener">TiDB</a> 数据库进行二次开发的整体方案，并与 PingCAP 官方和开源社区进行深入合作的开发模式。</p><p> 美团业务线众多，我们根据业务特点及重要程度逐步推进上线，到截稿为止，已经上线了 10 个集群，近 200 个物理节点，大部分是 OLTP 类型的应用，除了上线初期遇到了一些小问题，目前均已稳定运行。初期上线的集群，已经分别服务于配送、出行、闪付、酒旅等业务。虽然 TiDB 的架构分层相对比较清晰，服务也是比较平稳和流畅，但在美团当前的数据量规模和已有稳定的存储体系的基础上，推广新的存储服务体系，需要对周边工具和系统进行一系列改造和适配，从初期探索到整合落地，仍然还需要走很远的路。下面将从以下几个方面分别进行介绍：</p><ul><li>从 0 到 1 的突破，重点考虑做哪些事情。</li><li>如何规划实施不同业务场景的接入和已有业务的迁移。</li><li>上线后遇到的一些典型问题介绍。</li><li><p>后续规划和对未来的展望。</p><h1 id="2-前期调研测试"><a href="#2-前期调研测试" class="headerlink" title="2. 前期调研测试"></a>2. 前期调研测试</h1><h2 id="2-1-对-TiDB-的定位"><a href="#2-1-对-TiDB-的定位" class="headerlink" title="2.1 对 TiDB 的定位"></a>2.1 对 TiDB 的定位</h2><p>我们对于 TiDB 的定位，前期在于重点解决 MySQL 的单机性能和容量无法线性和灵活扩展的问题，与 MySQL 形成互补。业界分布式方案很多，我们为何选择了 TiDB 呢？考虑到公司业务规模的快速增长，以及公司内关系数据库以 MySQL 为主的现状，因此我们在调研阶段，对以下技术特性进行了重点考虑：</p></li><li><p>协议兼容 MySQL：这个是必要项。</p></li><li>可在线扩展：数据通常要有分片，分片要支持分裂和自动迁移，并且迁移过程要尽量对业务无感知。</li><li>强一致的分布式事务：事务可以跨分片、跨节点执行，并且强一致。</li><li>支持二级索引：为兼容 MySQL 的业务，这个是必须的。</li><li>性能：MySQL 的业务特性，高并发的 OLTP 性能必须满足。</li><li>跨机房服务：需要保证任何一个机房宕机，服务能自动切换。</li><li><p>跨机房双写：支持跨机房双写是数据库领域一大难题，是我们对分布式数据库的一个重要期待，也是美团下一阶段重要的需求。</p><p>业界的一些传统方案虽然支持分片，但无法自动分裂、迁移，不支持分布式事务，还有一些在传统 MySQL 上开发一致性协议的方案，但它无法实现线性扩展，最终我们选择了与我们的需求最为接近的 TiDB。与 MySQL 语法和特性高度兼容，具有灵活的在线扩容缩容特性，支持 ACID 的强一致性事务，可以跨机房部署实现跨机房容灾，支持多节点写入，对业务又能像单机 MySQL 一样使用。</p><h2 id="2-2-测试"><a href="#2-2-测试" class="headerlink" title="2.2 测试"></a>2.2 测试</h2><p>针对官方声称的以上优点，我们进行了大量的研究、测试和验证。</p><p>首先，我们需要知道扩容、Region 分裂转移的细节、Schema 到 KV 的映射、分布式事务的实现原理。而 TiDB 的方案，参考了较多的 Google 论文，我们进行了阅读，这有助于我们理解 TiDB 的存储结构、事务算法、安全性等，包括：</p></li><li><p>Spanner: Google’s Globally-Distributed Database</p></li><li>Large-scale Incremental Processing Using Distributed Transactions and Notifications</li><li>In Search of an Understandable Consensus Algorithm</li><li><p>Online, Asynchronous Schema Change in F1</p><p>我们也进行了常规的性能和功能测试，用来与 MySQL 的指标进行对比，其中一个比较特别的测试，是证明 3 副本跨机房部署，确实能保证每个机房分布一个副本，从而保证任何一个机房宕机不会导致丢失超过半数副本。我们从以下几个点进行了测试：</p></li><li><p>Raft 扩容时是否支持 Learner 节点，从而保证单机房宕机不会丢失 2/3 的副本。</p></li><li>TiKV 上的标签优先级是否可靠，保证当机房的机器不平均时，能否保证每个机房的副本数依然是绝对平均的。</li><li>实际测试，单机房宕机，TiDB 在高并发下，QPS、响应时间、报错数量，以及最终数据是否有丢失。</li><li><p>手动 Balance 一个 Region 到其他机房，是否会自动回来。</p><p>从测试结果来看，一切都符合我们的预期。</p><h1 id="3-存储生态建设"><a href="#3-存储生态建设" class="headerlink" title="3. 存储生态建设"></a>3. 存储生态建设</h1><p>美团的产品线丰富，业务体量也比较大，业务对在线存储的服务质量要求也非常高。因此，从早期做好服务体系的规划非常重要。下面从业务接入层、监控报警、服务部署等维度，来分别介绍一下我们所做的工作。</p><h2 id="3-1-业务接入层"><a href="#3-1-业务接入层" class="headerlink" title="3.1 业务接入层"></a>3.1 业务接入层</h2><p>当前 MySQL 的业务接入方式主要有两种，DNS 接入和 Zebra 客户端接入。在前期调研阶段，我们选择了 DNS + 负载均衡组件的接入方式，TiDB-Server 节点宕机，15s 可以被负载均衡识别到，简单且有效。业务架构如下图所示：</p><p><img src="https://tech.meituan.com/img/MySQL_PingCAP_Practice/02.png" alt=""></p></li></ul><p> 图 2 业务架构图</p><p> 后面，我们会逐渐过渡到当前大量使用的 Zebra 接入方式来访问 TiDB，从而保持与访问 MySQL 的方式一致，一方面减少业务改造的成本，另一方面尽量实现从 MySQL 到 TiDB 的透明迁移。</p><h2 id="3-2-监控报警"><a href="#3-2-监控报警" class="headerlink" title="3.2 监控报警"></a>3.2 监控报警</h2><p> 美团目前使用 Mt-Falcon 平台负责监控报警，通过在 Mt-Falcon 上配置不同的插件，可以实现对多种组件的自定义监控。另外也会结合 Puppet 识别不同用户的权限、文件的下发。只要我们编写好插件脚本、需要的文件，装机和权限控制就可以完成了。监控架构如下图所示：</p><p> <img src="https://tech.meituan.com/img/MySQL_PingCAP_Practice/03.png" alt=""></p><p> 图 3 监控架构图</p><p> 而 TiDB 有丰富的监控指标，使用流行的 Prometheus + Grafana，一套集群有 700+ 的 Metric。从官方的架构图可以看出，每个组件会推送自己的 Metric 给 PushGateWay，Prometheus 会直接到 PushGateWay 去抓数据。</p><p> 由于我们需要组件收敛，原生的 TiDB 每个集群一套 Prometheus 的方式不利于监控的汇总、分析、配置，而报警已经在 Mt-Falcon 上实现的比较好了，在 AlertManager 上再造一个也没有必要。因此我们需要想办法把监控和报警汇总到 Mt-Falcon 上面，包括如下几种方式：</p><ul><li>方案一：修改源代码，将 Metric 直接推送到 Falcon，由于 Metric 散落在代码的不同位置，而且 TiDB 代码迭代太快，把精力消耗在不停调整监控埋点上不太合适。</li><li>方案二：在 PushGateWay 是汇总后的，可以直接抓取，但 PushGateWay 是个单点，不好维护。</li><li><p>方案三：通过各个组件（TiDB、PD、TiKV）的本地 API 直接抓取，优点是组件宕机不会影响其他组件，实现也比较简单。</p><p>我们最终选择了方案三。该方案的难点是需要把 Prometheus 的数据格式转化为 Mt-Falcon 可识别的格式，因为 Prometheus 支持 Counter、Gauge、Histogram、Summary 四种数据类型，而 Mt-Falcon 只支持基本的 Counter 和 Gauge，同时 Mt-Falcon 的计算表达式比较少，因此需要在监控脚本中进行转换和计算。</p><h2 id="3-3-批量部署"><a href="#3-3-批量部署" class="headerlink" title="3.3 批量部署"></a>3.3 批量部署</h2><p>TiDB 使用 Ansible 实现自动化部署。迭代快，是 TiDB 的一个特点，有问题能快速进行解决，但也造成 Ansible 工程、TiDB 版本更新过快，我们对 Ansible 的改动，也只会增加新的代码，不会改动已有的代码。因此线上可能同时需要部署、维护多个版本的集群。如果每个集群一个 Ansible 目录，造成空间的浪费。</p><p>我们采用的维护方式是，在中控机中，每个版本一个 Ansible 目录，每个版本中通过不同 inventory 文件来维护。这里需要跟 PingCAP 提出的是，Ansible 只考虑了单集群部署，大量部署会有些麻烦，像一些依赖的配置文件，都不能根据集群单独配置（咨询官方得知，PingCAP 目前正在基于 Cloud TiDB 打造一站式 HTAP 平台，会提供批量部署、多租户等功能，后续会比较好地解决这个问题）。</p><h2 id="3-4-自动化运维平台"><a href="#3-4-自动化运维平台" class="headerlink" title="3.4 自动化运维平台"></a>3.4 自动化运维平台</h2><p>随着线上集群数量的增加，打造运维平台提上了日程，而美团对 TiDB 和 MySQL 的使用方式基本相同，因此 MySQL 平台上具有的大部分组件，TiDB 平台也需要建设。典型的底层组件和方案：SQL 审核模块、DTS、数据备份方案等。自动化运维平台展示如下图所示：</p><p><img src="https://tech.meituan.com/img/MySQL_PingCAP_Practice/04.png" alt=""></p></li></ul><p> 图 4 自动化运维平台展示图</p><h2 id="3-5-上下游异构数据同步"><a href="#3-5-上下游异构数据同步" class="headerlink" title="3.5 上下游异构数据同步"></a>3.5 上下游异构数据同步</h2><p> TiDB 是在线存储体系中的一环，它同时也需要融入到公司现有的数据流中，因此需要一些工具来做衔接。PingCAP 官方标配了相关的组件。</p><p> 公司目前 MySQL 和 Hive 结合的比较重，而 TiDB 要代替 MySQL 的部分功能，需要解决 2 个问题：</p><ul><li>MySQL to TiDB<ul><li>MySQL 到 TiDB 的迁移，需要解决数据迁移以及增量的实时同步，也就是 DTS，Mydumper + Loader 解决存量数据的同步，官方提供了 DM 工具可以很好的解决增量同步问题。</li><li>MySQL 大量使用了自增 ID 作为主键。分库分表 MySQL 合并到 TiDB 时，需要解决自增 ID 冲突的问题。这个通过在 TiDB 端去掉自增 ID 建立自己的唯一主键来解决。新版 DM 也提供分表合并过程主键自动处理的功能。</li></ul></li><li><p>Hive to TiDB &amp; TiDB to Hive</p><ul><li>Hive to TiDB 比较好解决，这体现了 TiDB 和 MySQL 高度兼容的好处，insert 语句可以不用调整，基于 Hive to MySQL 简单改造即可。</li><li>TiDB to Hive 则需要基于官方 Pump + Drainer 组件，Drainer 可以消费到 Kafka、MySQL、TiDB，我们初步考虑用图 5 中的方案通过使用 Drainer 的 Kafka 输出模式同步到 Hive。</li></ul><p><img src="https://tech.meituan.com/img/MySQL_PingCAP_Practice/05.png" alt=""></p></li></ul><p> 图 5 TiDB to Hive 方案图</p><h1 id="4-线上使用磨合"><a href="#4-线上使用磨合" class="headerlink" title="4. 线上使用磨合"></a>4. 线上使用磨合</h1><p> 对于初期上线的业务，我们比较谨慎，基本的原则是：离线业务 - 非核心业务 -\ 核心业务。TiDB 已经发布两年多，且前期经历了大量的测试，我们也深入了解了其它公司的测试和使用情况，可以预期的是 TiDB 上线会比较稳定，但依然遇到了一些小问题。总体来看，在安全性、数据一致性等关键点上没有出现问题。其他一些性能抖动问题，参数调优的问题，也都得到了快速妥善的解决。这里给 PingCAP 的同学点个大大的赞，问题响应速度非常快，与我们美团内部研发的合作也非常融洽。</p><h2 id="4-1-写入量大、读-QPS-高的离线业务"><a href="#4-1-写入量大、读-QPS-高的离线业务" class="headerlink" title="4.1 写入量大、读 QPS 高的离线业务"></a>4.1 写入量大、读 QPS 高的离线业务</h2><p> 我们上线的最大的一个业务，每天有数百 G 的写入量，在前期，我们也遇到了较多的问题。</p><p> 业务场景：</p><ul><li>稳定的写入，每个事务操作 100~200 行不等，每秒 6W 的数据写入。</li><li>每天的写入量超过 500G，以后会逐步提量到每天 3T。</li><li>每 15 分钟的定时读 Job，5000 QPS（高频量小）。</li><li><p>不定时的查询（低频量大）。</p><p>之前使用 MySQL 作为存储，但 MySQL 到达了容量和性能瓶颈，而业务的容量未来会 10 倍的增长。初期调研测试了 ClickHouse，满足了容量的需求，测试发现运行低频 SQL 没有问题，但高频 SQL 的大并发查询无法满足需求，只在 ClickHouse 跑全量的低频 SQL 又会 overkill，最终选择使用 TiDB。</p><p>测试期间模拟写入了一天的真实数据，非常稳定，高频低频两种查询也都满足需求，定向优化后 OLAP 的 SQL 比 MySQL 性能提高四倍。但上线后，陆续发现了一些问题，典型的如下：</p><h3 id="4-1-1-TiKV-发生-Write-Stall"><a href="#4-1-1-TiKV-发生-Write-Stall" class="headerlink" title="4.1.1 TiKV 发生 Write Stall"></a>4.1.1 TiKV 发生 Write Stall</h3><p>TiKV 底层有 2 个 RocksDB 作为存储。新写的数据写入 L0 层，当 RocksDB 的 L0 层数量达到一定数量，就会发生减速，更高则发生 Stall，用来自我保护。TiKV 的默认配置：</p></li><li><p>level0-slowdown-writes-trigger = 20</p></li><li><p>level0-stop-writes-trigger = 36</p><p>遇到过的，发生 L0 文件过多可能的原因有 2 个：</p></li><li><p>写入量大，Compact 完不成。</p></li><li><p>Snapshot 一直创建不完，导致堆积的副本一下释放，RocksDB-Raft 创建大量的 L0 文件，监控展示如下图所示：</p><p><img src="https://tech.meituan.com/img/MySQL_PingCAP_Practice/06.png" alt=""><br>图 6 TiKV 发生 Write Stall 监控展示图</p><p>我们通过以下措施，解决了 Write Stall 的问题：</p></li><li><p>减缓 Raft Log Compact 频率（增大 raft-log-gc-size-limit、raft-log-gc-count-limit）</p></li><li>加快 Snapshot 速度（整体性能、包括硬件性能）</li><li>max-sub-compactions 调整为 3</li><li>max-background-jobs 调整为 12</li><li><p>level 0 的 3 个 Trigger 调整为 16、32、64</p><h3 id="4-1-2-Delete-大量数据，GC-跟不上"><a href="#4-1-2-Delete-大量数据，GC-跟不上" class="headerlink" title="4.1.2 Delete 大量数据，GC 跟不上"></a>4.1.2 Delete 大量数据，GC 跟不上</h3><p>现在 TiDB 的 GC 对于每个 kv-instance 是单线程的，当业务删除数据的量非常大时，会导致 GC 速度较慢，很可能 GC 的速度跟不上写入。</p><p>目前可以通过增多 TiKV 个数来解决，长期需要靠 GC 改为多线程执行，官方对此已经实现，即将发布。</p><h3 id="4-1-3-Insert-响应时间越来越慢"><a href="#4-1-3-Insert-响应时间越来越慢" class="headerlink" title="4.1.3 Insert 响应时间越来越慢"></a>4.1.3 Insert 响应时间越来越慢</h3><p>业务上线初期，insert 的响应时间 80 线（Duration 80 By Instance）在 20ms 左右，随着运行时间增加，发现响应时间逐步增加到 200ms+。期间排查了多种可能原因，定位在由于 Region 数量快速上涨，Raftstore 里面要做的事情变多了，而它又是单线程工作，每个 Region 定期都要 heartbeat，带来了性能消耗。tikv-raft propose wait duration 指标持续增长。</p><p>解决问题的办法：</p></li><li><p>临时解决。</p></li><li><p>增加 Heartbeat 的周期，从 1s 改为 2s，效果比较明显，监控展示如下图所示：</p><p><img src="https://tech.meituan.com/img/MySQL_PingCAP_Practice/07.png" alt=""></p></li></ul><p> 图 7 insert 响应时间优化前后对比图</p><ul><li>彻底解决。</li><li>需要减少 Region 个数，Merge 掉空 Region，官方在 2.1 版本中已经实现了 Region Merge 功能，我们在升级到 2.1 后，得到了彻底解决。</li><li><p>另外，等待 Raftstore 改为多线程，能进一步优化。（官方回复相关开发已基本接近尾声，将于 2.1 的下一个版本发布。）</p><h3 id="4-1-4-Truncate-Table-空间无法完全回收"><a href="#4-1-4-Truncate-Table-空间无法完全回收" class="headerlink" title="4.1.4 Truncate Table 空间无法完全回收"></a>4.1.4 Truncate Table 空间无法完全回收</h3><p>DBA Truncate 一张大表后，发现 2 个现象，一是空间回收较慢，二是最终也没有完全回收。</p></li><li><p>由于底层 RocksDB 的机制，很多数据落在 Level 6 上，有可能清不掉。这个需要打开 cdynamic-level-bytes 会优化 Compaction 的策略，提高 Compact 回收空间的速度。</p></li><li>由于 Truncate 使用 delete_files_in_range 接口，发给 TiKV 去删 SST 文件，这里只删除不相交的部分，而之前判断是否相交的粒度是 Region，因此导致了大量 SST 无法及时删除掉。</li><li>考虑 Region 独立 SST 可以解决交叉问题，但是随之带来的是磁盘占用问题和 Split 延时问题。</li><li>考虑使用 RocksDB 的 DeleteRange 接口，但需要等该接口稳定。</li><li><p>目前最新的 2.1 版本优化为直接使用 DeleteFilesInRange 接口删除整个表占用的空间，然后清理少量残留数据，目前已经解决。</p><h3 id="4-1-5-开启-Region-Merge-功能"><a href="#4-1-5-开启-Region-Merge-功能" class="headerlink" title="4.1.5 开启 Region Merge 功能"></a>4.1.5 开启 Region Merge 功能</h3><p>为了解决 region 过多的问题，我们在升级 2.1 版本后，开启了 region merge 功能，但是 TiDB 的响应时间 80 线（Duration 80 By Instance）依然没有恢复到当初，保持在 50ms 左右，排查发现 KV 层返回的响应时间还很快，和最初接近，那么就定位了问题出现在 TiDB 层。研发人员和 PingCAP 定位在产生执行计划时行为和 2.0 版本不一致了，目前已经优化。</p><h2 id="4-2-在线-OLTP，对响应时间敏感的业务"><a href="#4-2-在线-OLTP，对响应时间敏感的业务" class="headerlink" title="4.2 在线 OLTP，对响应时间敏感的业务"></a>4.2 在线 OLTP，对响应时间敏感的业务</h2><p>除了分析查询量大的离线业务场景，美团还有很多分库分表的场景，虽然业界有很多分库分表的方案，解决了单机性能、存储瓶颈，但是对于业务还是有些不友好的地方：</p></li><li><p>业务无法友好的执行分布式事务。</p></li><li>跨库的查询，需要在中间层上组合，是比较重的方案。</li><li>单库如果容量不足，需要再次拆分，无论怎样做，都很痛苦。</li><li><p>业务需要关注数据分布的规则，即使用了中间层，业务心里还是没底。</p><p>因此很多分库分表的业务，以及即将无法在单机承载而正在设计分库分表方案的业务，主动找到了我们，这和我们对于 TiDB 的定位是相符的。这些业务的特点是 SQL 语句小而频繁，对一致性要求高，通常部分数据有时间属性。在测试及上线后也遇到了一些问题，不过目前基本都有了解决办法。</p><h3 id="4-2-1-SQL-执行超时后，JDBC-报错"><a href="#4-2-1-SQL-执行超时后，JDBC-报错" class="headerlink" title="4.2.1 SQL 执行超时后，JDBC 报错"></a>4.2.1 SQL 执行超时后，JDBC 报错</h3><p>业务偶尔报出 privilege check fail。</p><p>是由于业务在 JDBC 设置了 QueryTimeout，SQL 运行超过这个时间，会发行一个 <code>kill query</code> 命令，而 TiDB 执行这个命令需要 Super 权限，业务是没有权限的。其实 kill 自己的查询，并不需要额外的权限，目前已经解决了这个问题：<br><a href="https://github.com/pingcap/tidb/pull/7003" target="_blank" rel="noopener">https://github.com/pingcap/tidb/pull/7003</a>，不再需要 Super 权限，已在 2.0.5 上线。</p><h3 id="4-2-2-执行计划偶尔不准"><a href="#4-2-2-执行计划偶尔不准" class="headerlink" title="4.2.2 执行计划偶尔不准"></a>4.2.2 执行计划偶尔不准</h3><p>TiDB 的物理优化阶段需要依靠统计信息。在 2.0 版本统计信息的收集从手动执行，优化为在达到一定条件时可以自动触发：</p></li><li><p>数据修改比例达到 tidb_auto_analyze_ratio。</p></li><li><p>表一分钟没有变更（目前版本已经去掉这个条件）。</p><p>但是在没有达到这些条件之前统计信息是不准的，这样就会导致物理优化出现偏差，在测试阶段（2.0 版本）就出现了这样一个案例：业务数据是有时间属性的，业务的查询有 2 个条件，比如：时间+商家 ID，但每天上午统计信息可能不准，当天的数据已经有了，但统计信息认为没有。这时优化器就会建议使用时间列的索引，但实际上商家 ID 列的索引更优化。这个问题可以通过增加 Hint 解决。</p><p>在 2.1 版本对统计信息和执行计划的计算做了大量的优化，也稳定了基于 Query Feedback 更新统计信息，也用于更新直方图和 Count-Min Sketch，非常期待 2.1 的 GA。</p><h1 id="5-总结展望"><a href="#5-总结展望" class="headerlink" title="5. 总结展望"></a>5. 总结展望</h1><p>经过前期的测试、各方的沟通协调，以及近半年对 TiDB 的使用，我们看好 TiDB 的发展，也对未来基于 TiDB 的合作充满信心。</p><p>接下来，我们会加速推进 TiDB 在更多业务系统中的使用，同时也将 TiDB 纳入了美团新一代数据库的战略选型中。当前，我们已经全职投入了 3 位 DBA 同学和多位存储计算专家，从底层的存储，中间层的计算，业务层的接入，再到存储方案的选型和布道，进行全方位和更深入的合作。</p><p>长期来看，结合美团不断增长的业务规模，我们将与 PingCAP 官方合作打造更强大的生态体系：</p></li><li><p>Titan：Titan 是 TiDB 下一步比较大的动作，也是我们非常期待的下一代存储引擎，它对大 Value 支持会更友好，将解决我们单行大小受限，单机 TiKV 最大支持存储容量的问题，大大提升大规模部署的性价比。</p></li><li>Cloud TiDB （Based on Docker &amp; K8s）：云计算大势所趋，PingCAP 在这块也布局比较早，今年 8 月份开源了 TiDB Operator，Cloud TiDB 不仅实现了数据库的高度自动化运维，而且基于 Docker 硬件隔离，实现了数据库比较完美的多租户架构。我们和官方同学沟通，目前他们的私有云方案在国内也有重要体量的 POC，这也是美团看重的一个方向。</li><li><p>TiDB HTAP Platform：PingCAP 在原有 TiDB Server 计算引擎的基础上，还构建 TiSpark 计算引擎，和他们官方沟通，他们在研发了一个基于列的存储引擎，这样就形成了下层行、列两个存储引擎、上层两个计算引擎的完整混合数据库（HTAP），这个架构不仅大大的节省了核心业务数据在整个公司业务周期里的副本数量，还通过收敛技术栈，节省了大量的人力成本、技术成本、机器成本，同时还解决了困扰多年的 OLAP 的实效性。后面我们也会考虑将一些有实时、准实时的分析查询系统接入 TiDB。</p><p><img src="https://tech.meituan.com/img/MySQL_PingCAP_Practice/08.png" alt=""></p></li></ul><p> 图 8 TiDB HTAP Platform 整体架构图</p><ul><li><p>后续的物理备份方案，跨机房多写等也是我们接下来逐步推进的场景，总之，我们坚信未来 TiDB 在美团的使用场景会越来越多，发展也会越来越好。</p><p>目前，TiDB 在业务层面、技术合作层面都已经在美团扬帆起航，美团点评将携手 PingCAP 开启新一代数据库深度实践、探索之旅。后续，还有美团点评架构存储团队针对 TiDB 源码研究和改进的系列文章，敬请期待。</p><h2 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h2><p>应钢，美团点评研究员，数据库专家。曾就职于百度、新浪、去哪儿网等，10年数据库自动化运维开发、数据库性能优化、大规模数据库集群技术保障和架构优化经验。精通主流的SQL与NoSQL系统，现专注于公司业务在NewSQL领域的创新和落地。</p><p>李坤，2018年初加入美团，美团点评数据库专家，多年基于MySQL、Hbase、Oracle的架构设计和维护、自动化开发经验，目前主要负责分布式数据库Blade的推动和落地，以及平台和周边组件的建设</p><p>昌俊，美团点评数据库专家，曾就职于BOCO、去哪儿网，6年MySQL DBA从业经历，积累了丰富的数据库架构设计和性能优化、自动化开发经验。目前专注于TiDB在美团点评业务场景的改造和落地。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://tech.meituan.com/MySQL_PingCAP_Practice.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://tech.meituan.com/MySQL_PingCAP_Prac
      
    
    </summary>
    
      <category term="mysql" scheme="http://zhangyu33.com/categories/mysql/"/>
    
    
      <category term="mysql" scheme="http://zhangyu33.com/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>一篇非常棒的职业规划文章</title>
    <link href="http://zhangyu33.com/2018/11/07/%E4%B8%80%E7%AF%87%E9%9D%9E%E5%B8%B8%E6%A3%92%E7%9A%84%E8%81%8C%E4%B8%9A%E8%A7%84%E5%88%92%E6%96%87%E7%AB%A0/"/>
    <id>http://zhangyu33.com/2018/11/07/一篇非常棒的职业规划文章/</id>
    <published>2018-11-06T16:00:00.000Z</published>
    <updated>2018-11-07T09:13:38.296Z</updated>
    
    <content type="html"><![CDATA[<p>一篇非常棒的职业规划文章</p><p><img src="https://raw.githubusercontent.com/mayou33/other/master/%E4%B8%80%E7%AF%87%E9%9D%9E%E5%B8%B8%E6%A3%92%E7%9A%84%E8%81%8C%E4%B8%9A%E8%A7%84%E5%88%92%E6%96%87%E7%AB%A0.jpg" alt="职业规划"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;一篇非常棒的职业规划文章&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/mayou33/other/master/%E4%B8%80%E7%AF%87%E9%9D%9E%E5%B8%B8%E6%A3%92%E7%9A%
      
    
    </summary>
    
      <category term="胡说八道" scheme="http://zhangyu33.com/categories/%E8%83%A1%E8%AF%B4%E5%85%AB%E9%81%93/"/>
    
    
      <category term="胡说八道" scheme="http://zhangyu33.com/tags/%E8%83%A1%E8%AF%B4%E5%85%AB%E9%81%93/"/>
    
  </entry>
  
  <entry>
    <title>给1到10年运维人的修仙指南</title>
    <link href="http://zhangyu33.com/2018/10/24/%E7%BB%991%E5%88%B010%E5%B9%B4%E8%BF%90%E7%BB%B4%E4%BA%BA%E7%9A%84%E4%BF%AE%E4%BB%99%E6%8C%87%E5%8D%97/"/>
    <id>http://zhangyu33.com/2018/10/24/给1到10年运维人的修仙指南/</id>
    <published>2018-10-23T16:00:00.000Z</published>
    <updated>2018-10-24T10:13:30.338Z</updated>
    
    <content type="html"><![CDATA[<p>(<a href="https://dbaplus.cn/news-149-2242-1.html" target="_blank" rel="noopener">https://dbaplus.cn/news-149-2242-1.html</a>)</p><blockquote><p>今天跟大家分享一下运维人的职业生涯发展和相应的软硬技能提升，议题分为两个部分，第一是运维工程师成长的烦恼，第二是怎么走好自己的运维之路。</p><p><strong>一、运维工程师成长的烦恼</strong></p><p>第一部分里，根据我自己长时间的工作经验，把运维工程师按照工龄做了一些年限上的划分，比如任职三年、五年、八年……处于不同阶段，运维人也呈现出相当不同的状态。  </p><p>1-3年：有技术的逗逼</p><p><strong>（1）随性工程师</strong></p><p>在工作时间内，一般是比较随性的工程师，做一天和尚撞一天钟，我也亲身经历过此阶段。这时候还没有什么责任心，不会有过多的想法，只负责去执行，而不做过多的思考。与工作时间内的“被动思维”呼应的是，下班之后夜生活比较丰富，撩妹、抖音、打游戏等。</p><p><strong>（2）做技术容易“管中窥豹”</strong></p><p>什么概念呢？一到三年的运维人大部分靠度娘，例如Nginx配置最大连接数只知道上网获取65535相关的配置，但是配置背后的原因和原理，他们不知道也不甚关心。至于各种一些文章里的配图，更不会做深入研究。</p><p><strong>（3）工作态度积极，冲劲足</strong></p><p>我曾接带过一个实习运维工程师：3月份入职，9月份离职。初来乍到特别散漫，做事只应付我们的基本期待。后来接受了一些思想指导，小伙子工作突然很有冲劲；他所做的事情，包括日报、周报内容的撰写，表现得判若两人。2015年4月份的22个工作日，他加班22天，天天至凌晨两三点。期间技能也得到了极大提升：比如让他测试集群的性能，积极去做之外，也会认真思考为什么去做这件事情；对新技术进行研究，思考怎么样把它快速地掌握。</p><p><strong>（4）事务型人才</strong></p><p>最后，我把各个行业的小朋友都称为事务型人才，顾名思义，只需要把事情做好，达到公司的业务目的即可。“顾头不顾尾”也是一种常态，我指导过一名90后的运维工程师，他做代码发布，只管发上去，无视后期事态，比如是否发布成功、业务是否可以访问等。</p><p>3-5年专业资深人士</p><p><strong>（1）技术提升</strong></p><p>技术的确得到一定的提升，这是生存规律。初入公司，一张白纸，为了掌握了解公司的业务，你会去学习，否则就只能被淘汰。</p><p><strong>（2）“跳槽”惯性</strong></p><p>技术提高以后，会陷入“跳槽”惯性。上面提到的2015年3月份到我这边的运维工程师，刚入职时转正5K，9月份离职去大麦网以后薪资一下到13K，的确这时候跳槽提升得很快。但是容易迷茫，如果频繁跳槽，发现好像跳到这家公司和那家去差不多，到底应该怎样去做，就不明晰了。这时候，我们运维的技术方向就发生变化了，基础架构运维和开发型运维开始分化，其中DevOps会更多一些，一些运维工程师会产生迷茫，到底是去做什么。我所认识的一些人做到五年左右，基础架构运维的事情还没有非常深入的时候，就去做了DevOps，发现原有的开源组件并不能用得很好，给公司以及个人的发展带来了一定的风险。</p><p><strong>（3）技术能力与高薪预期的“错位”</strong></p><p>技术能力提升减缓与高薪预期的“错位”，这一阶段的中级运维或高级运维都容易自傲。我面试的运维人有跟我同龄的，还有比我大的，他们中有些人技术知识还停留在五年前，却因为自己从事这方面有一定时间了，产生高薪的期望。这就造成错位，高薪期待和实际能力不匹配。    </p><p><strong>（4）事务型和思考型人才</strong></p><p>3-5年运维人属于事务型和思考型人才，身为中级或再高一级的运维工程师，大部分人还是处于被领导的状态。有经验和学习能力加持，他们会思考什么是该掌握的东西，不过思考的强度往往还不够。</p><p><strong>（5）缺乏总结跟复盘</strong></p><p>最后，缺乏总结跟复盘。我相信运维人面对新的技术，或者做一些测试的时候，都会做笔记。那为什么还缺乏总结？很多时候笔记就只是一本笔记，并没有回翻笔记来复习，更不会及时更新笔记内容和分类。</p><p>5-8年：运维经理，至少运维主管</p><p>5-8年的运维人基本上是运维经理，至少是运维主管。但是，很多运维工程师是凭着技术能力和工作年限成为运维经理的，这中间要面对一个从技术到管理的跳跃，所以存在较多问题等待适应和解决。</p><p><strong>（1）找不到自己的定位</strong></p><p>升任到运维经理后，很多事情还是自己承担，导致团队里的其他兄弟分担任务很少，进步很慢，长远来看也不利于整个团队的发展。</p><p><strong>（2）团队意识薄弱</strong></p><p>不会带团队，不懂得利用团队的力量来满足公司的业务需要，还是做原来的角色。</p><p><strong>（3）对管理角色的认知出现偏差</strong></p><p>身份转变来得突然，面对新角色不适应，比如开始摆架子，趾高气昂，指使别人做这个做那个。另外，不习惯处理管理类事务，比如某一公司的业务在机房的哥们先是运维工程师，被提到了IT主管。每天都要做报表，他会觉得太烦了，宁可不做，想回去继续做一个运维工程师。</p><p><strong>（4）思考与事务占比相对来说会更均衡</strong></p><p>做了运维经理以后，你更多的时候要思考的是怎么让自己的运维更加有效率，怎么让公司形成这种标准化、规范化的运维体系以及运维技术体系。所以这时候，作为一个领导者，可能既要处理团队里疑难的技术问题，同时还要去规范运维体系。</p><p><strong>（5）运维技术容易达到瓶颈期</strong></p><p>公司里面处理线上事务特别多的时候，对于一个运维经理来讲，时间、精力用来补足管理，很少能进行技术知识的更新，所以技术知识往往就会停留在那个阶段。但是在做技术的圈子里有个特别好玩的现象，底下的普通员工如果要服你，就要看你的技术能力是否够强。技术能力不强，即使你的管理能力很强，下面的兄弟也不认你。</p><p>我遇上好多这样的情况。有一位运维工程师朋友认为自己经理的技术能力不强，瞎指挥。但纵然这位经理技不如人，他可以把一些任务安排有时间节点地完成，而且保证一定的质量，这就是懂得管理。而我认识的这个朋友，虽然他也做了八九年了，却始终是一个普通的基层技术人员，做不上管理岗。</p><p>8-10年：运维总监/运维架构师</p><p>8-10年的运维人，已达运维总监/运维架构师层次。这时候技术经验和管理经验都已经非常丰富，加上做了运维总监或运维架构师，他们都有比较好的职业习惯。</p><p><strong>（1）知识陈旧</strong></p><p>因为他们不再做一线的运维了，问题交给团队的人处理，自己只会给一个思路。比如说：不管做DBA还是做运维的，他们对听过的名词都熟得不能再熟，但就是做不到毫秒级的故障切换。不久有人来问我，你们是怎么能做到毫秒级故障切换的？我回答说我们对于技术的领域是一直更新的，Failover用的最多的还是Keepalived，Keepalived官方已经给了答案。另外做技术是我的兴趣，做管理是我的工作。</p><p><strong>（2）学习能力下降</strong></p><p>能做到运维总监或运维架构师，年龄绝对不会特别小，一般都在33到35岁之间。这时候，家庭、团队、公司都有很多事情会分散精力，相比而言学习能力会有所下降。 我在没有孩子之前，一周至少有三个晚上可以腾出来三个小时学习。现在，常常被两个孩子缠着玩，等他们睡着以后发现剩下的一个小时或半个小时压根儿就不够，加上早起，精神上会很累。</p><p><strong>（3）新事务接受能力下降</strong></p><p>比如做数据仓库和区块链这些比较火的技术，没法让一帮三十几岁的人去搞技术攻关，攻不了，精力也不够。</p><p><strong>（4）不懂的东西会越来越多</strong></p><p>现在的新技术非常多，如果你不保持更新自己的知识体系，就会发现跟不上行业的发展节奏。</p><p><strong>（5）对于事情目的、目标不明确</strong></p><p>很多人对于运维这件事只管做，但为什么做、到底要做成什么样子的，并不在乎。比如做故障切换的时候，我们是要求十毫秒必须发现问题，两毫秒以内故障切换。但很多公司并没有这个要求，只要出了故障切过去就行，至于你的业务中断多少时间可能都不会去思考。</p><p>以上是我根据实际工作经验，对不同阶段运维工程师的特征做的一些总结。我还是希望更多的运维工程师可以走好自己的职业生涯，因此有了下面的一些建议。</p><p><strong>二、怎么走好自己的运维之路</strong></p><p>先分享一下我最近面试新人时的一些经验。我面试时不会问过多问题，我就问应聘者：你会不会安装操作系统？</p><p>这个问题看似简单，其实不那么容易回答。应聘者没有一个人说得上来，为什么我的操作系统安装到服务器上，服务器可以正常运行，也没有一个人说得上来。</p><p>我又问，你能在任何一个服务器上安装操作系统吗？他们回答是“能”。这就是不善于去深入挖掘，是比较肤浅的。</p><p>再比如做配置的时候，很多人会选择输入网上的资料，我们操作系统里面配置/etc/security/limits.conf时，有人会将nofile配置为65535。我问他们，你为什么不配一个65536呢？他说不允许。我就笑了，说明很多人不会仔细地深究这个65535到底能配还是不能配，能不能比这个大，大多少倍，这些都没有人去思考。</p><p>所以，面试结束我都会告诉他们说，能够深入，你才会有价值。</p><p>对于刚入职场的人而言，五年以内的发展多凭借硬实力；而五年之后，运维软实力才决定他能走多远。</p><p>1、打磨硬实力</p><p><strong>（1）官方文档</strong></p><p>红帽招人面试时会问一个问题，当运维的环境出现故障，你首先从哪里查找资料解决问题？如果回答，我先从红帽的官方文档上找，然后再去处理思路，你已经把一只脚踏入红帽了；如果说你先通过谷歌搜索，还能继续往下聊一会儿，但如果你说先通过百度搜索，下面就已经不用再进行了。这些都是红帽相关负责人告诉我的。</p><p><strong>（2）及时跟上时下比较火的技术</strong></p><p>现在很多人学运维，只把技术停留在落后的架构上，然后根据百度上查找到的资料使用起来，而且没办法做到更深入的使用。对于优化也仅仅停留在稍微修改就可以的程度，不会做更深入的研究。</p><p><strong>（3）多关注技术公众号</strong></p><p>我关注了二十多个技术类的公众号，不为别的，就是为了能及时了解新技术，提升自己的见识。</p><p><strong>（4）给自己投资技术类书籍</strong></p><p>我有一个观点，给自己家庭买东西的时候，要舍得花钱；给自己手底下兄弟谋福利的时候，眼睛眨都不要眨；给自己的大脑做投资的时候，也是如此。看书就是一项对自己有益的投资，以下是我看过后觉得不错的书，推荐给大家：</p><ul><li><p>《亿级流量网站架构核心技术》</p></li><li><p>《Linux性能优化》</p></li><li><p>《Linux防火墙第四版》</p></li><li><p>《海量运维运营规划之道》</p></li><li><p>《精通Nginx第二版》</p></li><li><p>《MySQL运维内参》</p></li><li><p>《高性能MySQL第三版》</p></li></ul><p><strong>（5）实验</strong></p><p>因为技术对我而言是一种兴趣爱好，虽然精力上分不开那么多，但每当出来一些新软件或新版本，我都会去摸一摸，看看根据自己以前的技术知识能不能把它运作起来，同时摸索是否有更好的新用法。</p><p>2、提升软实力</p><p>我现在对部门所有运维工程师的软实力提升，要求非常高，比硬实力要高得多。</p><p><strong>（1）沟通能力</strong></p><p><strong>面试沟通：</strong>我面试的时候，发现有些人沟通能力太差，坐了一会儿就开始紧张，紧张得手都不知道该往哪放了。虽然我已经尽可能地让他在轻松的环境里面试，以最轻松的话题谈起再逐渐进入主题，但他还是紧张得不知所措。</p><p>不过，沟通能力不代表口若悬河，应该具备一些关键要素，交流时讲清楚做了什么事、为什么做这个事、有多少种方法去做，这才是沟通能力。</p><p><strong>上下级沟通：</strong>做管理的时候会发现，领导者最希望听到下属的反馈。当我向下安排任务时，我希望他们过一会儿会来找我，了解做这件事的目的、怎么规避风险、有没有其他应急预案等。如果不沟通的话，上下级很容易会产生这样的问题：比如说我安排的配置要求很高，但他们并不知道我所希望达到的程度，自以为已经配置得很好了，到了交付成果的时候才发现效果不够好。如此反复，领导者只能不时盯紧手下人的任务进程。</p><p>我们建立呼叫中心的时候，招来了一个管人力资源的人，他入职第一周下午下班后给我和公司所有高管发了周报，汇报项目的完成进度、完成结果、由谁负责、为何延期等，写得非常详细。当时所有人的反应都是，这个人一定要好好留着。所以说，通过写周报，就体现了他的价值。推荐看看《不懂汇报工作，还敢拼职场》这本书。</p><p><strong>（2）时间管理能力（碎片时间）</strong></p><p>大家在不加班的情况下，下班后手机一般都是用来干什么的呢？我的习惯是如果坐地铁，会利用这个时间看看文档、PDF等。</p><p>非常值得一提的是去年给我们公司做培训的一位讲师，他的碎片时间管理极为优秀。比如这会儿在我们的峰会现场，会有10分钟的短歇时间，他可以在这10分钟里写一份PPT为明天的演讲做准备，但一般人都会在做完今天这场分享之后再去做下一场的PPT。所以说，懂得利用碎片时间是很重要的。</p><p><strong>（3）方法论</strong></p><p>作为技术人员经常会用到的方法论是什么？</p><ul><li><p>SWOT</p></li><li><p>6W2H</p></li><li><p>PDCA</p></li><li><p>鱼骨图：人、机、法、料、环</p></li><li><p>任务分解法</p></li><li><p>SMART原则：具体、可衡量、可实现、时效性、相关性</p></li><li><p>思维导图</p></li></ul><p>SWOT原则可用于分析你自己的优势和劣势。当你去新的一家公司工作，挑战、机遇各是什么？所以我面试的时候常会问两个问题，你认识你自己吗？有些人想过，有些人没想过，我会再细化，你自己的优势是什么？劣势是什么？</p><p>PDCA原则其实就是帮助我们在做事情前做好计划，做完了再去检查，检查之后发现有没有改进，或者有偏差的地方通过纠偏，通过不断的PDCA原则越做越好。很多时候，如果想做好，PDCA原则是一定要有的。推荐看看《管理管到位就这几招》这本书。</p><p>鱼骨图、任务分解法、思维导图，这三个是我做任何事情都会用到。如果用鱼骨图做不成功，反过头来，把做不成功的原因定位，做好方案，再根据思维导图做这个任务；你的执行计划是什么，执行计划做出来，接着任务分解：什么时间，做什么事情，你需要什么配合。</p><p><strong>（4）工具</strong></p><p>以下这些工具也是技术人员经常需要用到的：</p><ul><li><p>Xmind：用于做思维导图；</p></li><li><p>JIRA：通过JIRA管理项目，根据项目的进度来评估团队每个人每周工作是否饱和。如果谁这周空着，我就让他做学习、提升或优化；</p></li><li><p>Confluence：在这个系统里做文档管理。</p></li></ul><p><strong>（5）项目管理能力以及事件回顾、复盘能力</strong></p><p>最后，项目管理能力以及事件回顾、复盘能力也同样是需要提升的软实力，推荐看看《复盘：对过去的事情做思维演练》这本书。</p><p>Q &amp; A</p><p><strong>Q1：</strong>我是做系统安全运维的，目前我所了解的安全事件一般都是因用户泄露引起的，想问一下，您对现阶段运维安全结合的方向有什么指导吗？</p><p><strong>A1：</strong>我聊一下我的感受：运维如果是面向安全的话，我都不知道怎么去面对。为什么？因为运维在做一些开源组件配置的时候，很多时候安全问题本身是可以避免的。像之前网上看到的NTP、DNS的域名反射攻击，还有数据泄露，这些其实在我看来都不是一个应该发生的问题。因为作为一个运维，他的职责，第一个是稳定，第二个是安全，我们讨论的安全问题80%就是运维引起的，为什么呢？因为不去把配置思考，默认把配置全部建立到公共的IP上，你的数据就是直接暴露的。</p><p>我认为，如果安全方面你把这些开源组件用好，更直接一点，如果这个开源组件里有参数是指定的IP，你只要把这个IP指向内网IP，然后让端口指向内网，你的安全运维80%就做到了。</p><p><strong>Q2：</strong>我是一名运维开发，想咨询一下，您怎么看待运维跟运维开发的关系？</p><p><strong>A2：</strong>只有当你对你所负责业务的基础组建深入了解并能用得好的时候，足够的运维开发你才会得心应手。比如我们公司从运维到现在没有做过一个运维开发，但是在做运维的过程中，我们会做简单的运维开发，做一个平台实现很多的功能。</p><p>为什么不招运维开发？因为当时还没有构建完善的运维体系。只有当建立符合标准化、规范化的运维规则、制度、流程之后，我才会用运维开发。比如现在我已经有了标准化、规范化的东西，那就需要招运维开发帮我实现相应的平台，来更加高效地实现运维的目标。</p><p>所以，运维开发，我个人建议你要么去做监控，要么你想负责所有的开源组件更好地做好运维工作的话，先把运维的基础东西夯实了，然后再去做运维的架构。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;(&lt;a href=&quot;https://dbaplus.cn/news-149-2242-1.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://dbaplus.cn/news-149-2242-1.html&lt;/a&gt;)&lt;/p&gt;
&lt;block
      
    
    </summary>
    
      <category term="运维" scheme="http://zhangyu33.com/categories/ops/"/>
    
    
      <category term="运维" scheme="http://zhangyu33.com/tags/%E8%BF%90%E7%BB%B4/"/>
    
  </entry>
  
</feed>
