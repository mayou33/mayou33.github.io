<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>张天师</title>
  
  
  <link href="http://zhangyu.info/atom.xml" rel="self"/>
  
  <link href="http://zhangyu.info/"/>
  <updated>2022-11-02T15:09:38.165Z</updated>
  <id>http://zhangyu.info/</id>
  
  <author>
    <name>张天师</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>OKR之剑·理念篇01：OKR带给我们的改变我们的改变</title>
    <link href="http://zhangyu.info/2022/11/02/OKR%E4%B9%8B%E5%89%91%C2%B7%E7%90%86%E5%BF%B5%E7%AF%8701-OKR%E5%B8%A6%E7%BB%99%E6%88%91%E4%BB%AC%E7%9A%84%E6%94%B9%E5%8F%98%E6%88%91%E4%BB%AC%E7%9A%84%E6%94%B9%E5%8F%98/"/>
    <id>http://zhangyu.info/2022/11/02/OKR%E4%B9%8B%E5%89%91%C2%B7%E7%90%86%E5%BF%B5%E7%AF%8701-OKR%E5%B8%A6%E7%BB%99%E6%88%91%E4%BB%AC%E7%9A%84%E6%94%B9%E5%8F%98%E6%88%91%E4%BB%AC%E7%9A%84%E6%94%B9%E5%8F%98/</id>
    <published>2022-11-01T16:00:00.000Z</published>
    <updated>2022-11-02T15:09:38.165Z</updated>
    
    <content type="html"><![CDATA[<p>平台产品研发团队 vivo互联网技术 2022-11-02</p><p><a href="https://mp.weixin.qq.com/s/NLxg-4JUx-F-0NwPfO1qIw">https://mp.weixin.qq.com/s/NLxg-4JUx-F-0NwPfO1qIw</a></p><p>[OKR之剑（理念篇）01—— OKR带给我们的改变_<a href="https://blog.csdn.net/m0_56069948/article/details/126869001">虚幻私塾】的博客-CSDN博客_okr总是变化</a></p><blockquote><blockquote><p>作者：vivo互联网平台产品研发团队</p></blockquote><h1 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h1><p>OKR即目标与关键成果法，起源于英特尔，在谷歌发扬光大。近几年在国内比较火，很多企业都相继引入了OKR的管理方式，小到2-3人的小微初创公司，大到十几万名员工的大型企业，都因此而受益。vivo互联网团队经过三年的积极实践，证实这一目标管理工具对于业务和人员发展有非常强大的推动作用。</p><p>“众多企业争相追捧的OKR，到底是何方神圣？我可以用么？”</p><p>从各个渠道了解到OKR对企业有正向作用的你，一定也有这样的疑问。那么此小节，我们先简单解答下这个问题，同时也论述下本系列文章的核心理念，让你充满信心的深入学习OKR以及本系列文章的实践经验。</p><p>通俗来讲，OKR就是一套科学的目标管理工具和方法，它的特点在于重视员工内在动机，激发员工内在潜能，提升员工工作热情。与其他目标管理方法不同的是，OKR弱化了目标管理和绩效考核的关系，通过鼓励员工主动制定更有挑战性的目标，鼓励目标的开放透明，团队精诚合作对齐一致，最终达成大团队的目标。</p><p>本系列文章是基于我们团队中的具体OKR实践，讲述我们如何理解和运用OKR，以及在OKR运用过程中如何践行“团队管理”这一学问，并且在文章中分享我们的团队管理的心得和理念。我们认为OKR与管理的有机结合，归根结底还是对管理的理解要一致，正如德鲁克之言：“<strong>企业需要的管理原则，就是让个人充分发挥特长，凝聚共同的愿景和一致的努力方向，建立团队合作，调和个人目标和共同福祉</strong>”，这其中又包含了两个要点：</p><p><strong>1.目标一致，是战略目标达成的关键</strong></p><p>在信息不透明的情况下，员工和企业计划和战略没有对齐，团队之间规划和方向没有对齐，相互之间目标不一致，怎么可能协作顺畅？特别是当员工只专注个人成就，团队只在乎局部胜利，而非企业整体目标，这对于企业发展来说是非常致命的。</p><p><strong>2.管理之责，在于充分发挥员工才能</strong></p><p>经营企业其实就是经营人，团队管理也是一样。人尽其才，才尽其用，是企业管理的目标之一。OKR让员工自己制定挑战性任务，并在目标达成的推进过程中突破自我局限，收获成长和成就感。在目标制定阶段，员工可以切实的感受到是在掌控工作，而不是被支配。在目标执行过程中，员工可以获得实实在在的能力提升、成就感和相应的影响力，进而有更强的动力去挑战下一阶段的目标，以此进入良性循环。最终OKR高效激发了员工潜能，并逐步释放整个团队的潜力。</p><p>在本系列文章中，我们采用场景化方式进行讲述，让你能够在碎片化的时间里了解我们的执行细节，并从中有所收获，解除OKR实践和团队管理上的困惑。</p><h1 id="二、我们为何引入OKR？"><a href="#二、我们为何引入OKR？" class="headerlink" title="二、我们为何引入OKR？"></a>二、我们为何引入OKR？</h1><p>通过前面介绍，相信你对OKR已经有了一个初步的印象。本小节主要介绍我们是怎样的一个团队，并让大家更加清楚我们是在什么样的背景下开始接触并践行OKR的。</p><p>我们团队于2015年成立，最初只有几个人，主要负责业务方向是垂直电商。最开始的电商研发小队，接到这个时间紧任务重的从0到1的建设任务，也是鸭梨山大。好在团队梯队比较健全，有深耕互联网多年的老司机，有初出茅庐的应届大学生，在互帮互学的氛围引领下，逢山开路遇水架桥，逐渐在一片混沌的情况下开辟了新气象。最终我们把国内电商这块硬骨头啃了下来，收获了业务团队的信任和兄弟团队的称赞。</p><p>在这种团队风貌的影响下，越来越多的业务交接过来，小队也逐渐变成了小组，变成了大组，直至成长为如今的平台产品研发中心，负责整个vivo互联网平台类方向的研发工作。在这风云变幻的8年里，我们见证了互联网的飞速发展，也经历了组织架构调整，业务调整，团队合并，我们改变了很多，但始终保持着那份初心。</p><p>一路走来我们收获了非常多的荣誉，同时也遇到了相当多的困难，特别是在团队规模持续扩大的情况下，我们的团队管理面临着巨大的挑战：</p><p><strong>1.团队目标对不齐，项目协作总困难</strong></p><p>这是在当时非常常见的问题，多发生在上下游有依赖的项目中。比如某一个项目，同时有多个团队在支撑，而这些团队都有各自的产品规划和目标。这就导致在项目版本中，经常出现A团队觉得有个需求非常重要紧急，需要B团队配合，却发现B团队因为要执行自己的计划而出现资源冲突。</p><p><strong>2.角色视角有偏差，Roadmap拍脑袋</strong></p><p>即使在同一个项目团队，也会存在因为角色的不同而在一些事情上出现分歧，一个产品从研发的视角来看要让其稳定高性能的运行，此时他就会想着做对外接口的性能优化；从产品经理的视角来看就想让产品具备更完备的功能，不停的增加新功能。</p><p>因为资源的有限，是先进行接口性能优化还是开发产品新功能呢？两拨人争执不下，每个人都说自己的优先级高，这个时候我们怎么做决策呢？</p><p><strong>3.版本人力空转，资源协调不及时</strong></p><p>我们的团队负责的项目很多，大的项目十几人参与，小的项目一个人负责几个，出现“旱的旱死，涝的涝死”的情况再正常不过了，有些项目这段时间特别的忙，版本的排期都是根据最终交付时间进行倒排，而此时此刻另外一些项目却只有零星的小需求，不慌不忙。</p><p><strong>4.学习进取成空谈，完成任务是唯一</strong></p><p>为了打造一支学习型的团队，公司专门建设了一个线上学习平台，上面有各种类别的学习视频，并且规定每个员工每年必须参与学习多长时间，即使这样效果也不甚理想，每年到年底的时候很多人都需要进行冲刺，毕竟学习是痛苦的，让大家快乐的学习貌似变成了一件不可能的事情。</p><p><strong>5.绩效考核遭质疑，什么样才算是优秀？</strong></p><p>一个高绩效员工所产出的创新效果数倍于一个能力中等的人，同时优秀人才创造的出色成果还能感染激励更多的出色人才，可见优秀的人是多么的重要。</p><p>那么如何识别优秀的人才呢？以前我们用环评+自评+KPI三套组合拳的方式来评定优秀，导致员工比较质疑这个结果的公平性，因为环评+自评本身非常主观，并且KPI又不够透明，管理者总是需要直面这样的挑战：为什么这个人表现平平，绩效比我好？</p><p>上面列举了我们团队之前趟过的一些坑，其实说到底还是怎么管理团队的问题，包括如何调动员工积极性，如何发挥每个人的主观能动性，这也是我们一直在思考的方向。在16年，我们就已经逐渐意识到，原有的类KPI的绩效考核方法对于研发岗位变得不适用了。随后我们去寻找新的管理办法，调研了主流的管理方式，发现它们都与vivo互联网的文化和团队实际情况无法完美契合。</p><p>向外求无果的情况下，我们开始摸索新的管理理念来打造高绩效团队，同时积极寻找更加优秀的管理工具，期望能够将沉淀下来的经验更好地落地和推广。19年的夏天，部门开始学习、引入OKR管理工具。在学习OKR了相关理论书籍后，我们惊奇的发现原来一直苦苦找寻的，能解决我们痛点的工具，就这样出现了我们的面前，直叹相见恨晚。</p><h1 id="三、OKR带给我们的改变"><a href="#三、OKR带给我们的改变" class="headerlink" title="三、OKR带给我们的改变"></a>三、OKR带给我们的改变</h1><p>我们团队的愿景：持续成长为行业一流的技术团队，并打造出了一支自组织、高绩效的标杆团队。目前由三大互联网服务端研发团队组成，人员规模在两百人左右，业务整体可以划分三个方向（三驾马车）：平台产品，营销产品，创新产品。三大业务方向相辅相成，都有着各自的责任和使命。</p><p><strong>平台产品</strong>主要包括业务平台与效率中台两大模块，完善沉淀，稳定支撑业务发展的项目。</p><p><strong>营销产品</strong>主要包括线上营销与线下营销两个模块，主要是能力组合复用，助力营销变革。</p><p><strong>创新产品</strong>主要包括管理创新与技术创新两个模块，创新产品主要是源于业务，发掘新的可能。</p><p>无论团队人员规模还是业务复杂度，都不难看出，对于团队成员以及业务的管理面临着不小的挑战。从19年正式引入OKR起，为了应对不断变化的业务，以及不断调整的组织结构，在团队和业务发展中，我们不断实践和优化符合我们团队特色的管理方式，集百家之长，成一家之言，逐渐沉淀出一套逻辑清晰的管理理念。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/b761540df78dc20204c2d1eb91cfc975.png"></p><p>引入OKR三年多来，让我们一直坚持的“面向未来的组织”的管理理念遍地开花，给我们团队带来了方方面面的改变。团队的凝聚力、氛围以及生产力得到了极大提升，以下是我们认为比较重要的改变。</p><h2 id="3-1专注团队最重要目标"><a href="#3-1专注团队最重要目标" class="headerlink" title="3.1专注团队最重要目标"></a>3.1专注团队最重要目标</h2><blockquote><p>人生之要事在于确立伟大的目标与实现这目标的决心。——歌德</p></blockquote><p>首先，我们需要制定出好的目标，需要足够“伟大”，同时又要让所有人都能够有参与感。在引入OKR后，我们的目标是通过自上而下+自下而上双向产生。在公司确定年度规划和战略目标后，我们会根据自身业务和团队的特点，制定具有挑战性的目标以支撑战略的落地；接着团队成员主动去思考，制定出衡量实现此目标的关键结果，以此解决目标的制定与目标的执行割裂的问题，让团队成员都有参与感，自主感。</p><p>其次我们会为每条关键结果指定负责人，通常是由提出人负责，当然也可以协商由其他人负责。在负责人owner制度下，可以更好的发挥主观能动性，从心理学角度激发完成承诺的欲望。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/f4297458cc2da95c41e87590b4bd35f8.png"></p><p>最后使用在线的OKR管理工具来保证目标的透明性和公开性，通过每周OKR tips来提醒员工持续专注于自己的OKR目标，通过两周一次的OKR庆功会来持续激励和反馈困难。多措并举之下，团队成员自始至终都专注于最重要的目标。</p><h2 id="3-2聚焦价值挑战不可能"><a href="#3-2聚焦价值挑战不可能" class="headerlink" title="3.2聚焦价值挑战不可能"></a>3.2聚焦价值挑战不可能</h2><p>有的人可能会讲定目标那还不简单，但是我们认为，目标不能太多，需要集中优势兵力解决核心问题，让组织保持专注。资源是有限的，为了保证组织的专注，目标的制定必须要聚焦价值。这样事情就变得简单多了，当我们进行两个人目标PK的时候，就比较张三的目标与李四的目标的价值，每个人对自己提出的目标进行价值论证，同时论证的过程也逼迫着我们深入思考，思考我们的目标对用户的价值，对产品的价值，对组织的价值，然后大家一起评估，最终确定我们这个季度的目标。</p><p>这个时候有人就会反驳说，难道没有引入OKR，你们就不思考价值？目标的制定肯定会思考，参考上一节，没有引入OKR的时候，目标是少数人在制定，大部分是自己说服自己，而引入OKR之后，目标是大家一起制定的，那么这个时候就需要每个人都要对目标进行思考。如果你想要自己的目标脱颖而出，那你就要把你的目标的商业价值说的非常清楚，比如为产品提高百分之多少的日活，带来多少收入，节省多少开支。</p><p>目标制定聚焦于价值，也逐步改变了我们绩效评估的方式。以往我们绩效评估，看的是员工在一个绩效周期业务版本、上司任务的产出，员工被动接受任务；随着我们对目标价值的追求，绩效评估也变得更为简单，考察员工在绩效周期内带来的价值即可，员工主动挖掘任务，解决团队最核心的问题。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/440938b36da10fcb10e1d2f3a15638e6.png"></p><h2 id="3-3团队高效协作"><a href="#3-3团队高效协作" class="headerlink" title="3.3团队高效协作"></a>3.3团队高效协作</h2><p>季度初设定了有挑战的目标，那么如何在季度末保证目标的关键结果达成呢？制定目标容易，难的是目标的达成。从一个创意到可运行的产品或服务、再到让客户认可价值，然后客户开始使用，到最终愿意为之付费，整个过程的每个环节难度都在增大，每个环节都需要我们组建合适的团队来完成。</p><p>从前文中关于我们中心的介绍可看出，团队负责的业务形态不同，每个业务的优先级、重要性也不同，每个项目运行的周期都呈现出忙闲交替的现象，作为管理者通过什么手段来合理的调度人力资源？一个KR负责人评估当前KR完成需要的人力不足时该怎么办？一个团队战斗力爆表的成员，完成了自己负责的KR外还想做更多的事情怎么办？</p><p>针对上面的现象，我们建设了伙力平台：一个用于管理人力池、招募人才和认领任务的系统。我们期望能够通过这个平台解决上面的问题时，而此时面临的最大的问题，就是如何保证员工认领任务的积极性。对于普通员工来说，需要走出舒适圈，面对不了解的需求，不熟悉的伙伴，本身就是一件非常具有挑战的事情，如果没有一个好的团队氛围，必然会导致意愿下降，没有人参与，没有人发布，恶性循环，最终流于形式。</p><p>得益于OKR的目标公开透明，和层层分解的思路，员工对组织目标有更加清晰的认知，对于共同目标的达成有更强的意愿。只有大团队的胜利，才能证明小团队的努力是有价值的，才能证明个人的努力是成功的。在这样共赢的氛围下，强化了人与人的信任和协作，弱化了内耗和竞争，伙力平台的能力得到了最大程度的发挥。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/583f1b325028a4b43288273a91491b5a.png"></p><p>从伙力平台上线到现在一年多的时间里，一共发布了35个任务，共有72个同事申请，实现了408个人日的火力输出，不仅帮助我们协调了项目间的人力，更促进了团队共同成长，让优秀的人脱颖而出。不断的成功和胜利，让员工更加相信组织，相信队友，带来良性循环，实现了我们集中力量办大事的愿景。</p><h2 id="3-4浓厚的学习氛围"><a href="#3-4浓厚的学习氛围" class="headerlink" title="3.4浓厚的学习氛围"></a>3.4浓厚的学习氛围</h2><p>为了践行我们的核心价值观（学习是我们公司的核心价值观之一），为了更好的解决业务发展中的技术难题，同时也为了员工的自我成长，我们很有必要去营造一个浓厚的学习氛围。</p><p>作为一个管理者，建设一个学习型的团队是其工作内容的一部分，针对研发团队如何建设呢？通常的做法是：指定一个负责人，让其组织团队的成员轮流在固定的时间固定的场所给大家分享他的知识和经验，比如读书笔记，设计的方案，线上遇到的问题……。既然有现成的模型可以照搬，那对于我们这样执行力强的团队来说，说干就干，于是我们制定了一个规则：每周四晚上七点半大家轮流进行分享。一周一次，轮流分享，团队的人也比较多，一年下来一个人也分享不了几次，从明面上看，这个任务完成的难度不是很大，负责人也是拍着那坚实的胸脯信心满满。</p><p>半年后的一天负责人突然说：不行了，分享搞不下去了，首先是没有子弹了（没有可以分享的内容了），库存已搬空；其实是参与学习的人也没激情了，很多时候参加的人数都少于5个人，既没有想分享的人，也没有想学习的人。问了下不参加的理由，有要紧急发版的，有要配合测试的，都有各自的说法。</p><p>如何解决没有子弹的问题？我们决定换一种分享模式试试，于是我们又组织了读书会，大家一段时间内一起阅读同一本书，一个月分享一次读书心得，分享的形式就是口述，这非常轻量化了，我们想这样大家应该能坚持下去吧。事实证明我们还是太天真，这次比上次的分享会坚持的时间还要短，就搞了几期然后就悄无声息的结束了。</p><p>在我们遇到OKR之后，形势反转了，我们把“营造快乐进取的学习型团队氛围”作为一个目标来跟踪，每个季度制定不同的KR来支撑O的达成。在这种方式下，我们将原来的指派式转变为主动报名，同时OKR的目标牵引又能够让负责人专注于目标的执行和达成，学习的氛围发生了180°的大逆转，教与学变成了水到渠成的事情，很多新的思路和创意也在碰撞中产生。快闪分享、技术沙龙、源码领读、算法专题、读书会、好文分享等是中心内技术学习的专题活动，形式多样丰富，为中心内成员搭建学习交流平台。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/555f9be2e785a058dac1316474a51e57.png"></p><p>（读书会分享：《价值》读书心得）</p><h2 id="3-5持续的内部创新"><a href="#3-5持续的内部创新" class="headerlink" title="3.5持续的内部创新"></a>3.5持续的内部创新</h2><p>当今世界，新技术、新产品、新服务、新模式层出不穷，传统商业模式面临颠覆性的挑战，创新是企业的灵魂，创新是企业发展的不竭动力，对于手机行业公司来说，创新将显得更为重要。对我们团队而言创新主要体现在新能力和新项目的孵化。</p><p>我们首先是通过OKR的目标牵引和激励策略，来培育创新土壤，鼓励创新。众所周知，一个创意从诞生到落地，最大到难关是开始行动，99%的创意在行动之前就被自我扼杀了。所以我们需要建立鼓励创新、包容失败的氛围，降低员工踏出第一步的难度。</p><p>其次是聚焦创新目标，跟踪创新过程。通过持续的激励，让员工能够有足够的动力去长期投入创新目标的完成；通过阶段性的对齐，让团队能够了解目前的进展和瓶颈，利用群体智慧来共同解决困难。以此来呵护创新萌芽的成长壮大。</p><p>最后是关注创新结果，保持正向激励。因为创新这一目标，本身就是极具挑战和不确定性的，因此总结和复盘时，我们并不追求此OKR的完成度，而是以目标是否有价值、是否具备挑战性、员工是否付出足够的努力为衡量标准，即使最终这个KR没有完成，也并不影响到员工的绩效考核。在这样的理念下，保证了创新氛围的可信和持续，让创新变成一件水到渠成的事情。</p><p>三年来，在围绕着创新制定目标的牵引下，中心已经成功孵化出了6个组件和12个服务，在公司内部累计已经超过千余个系统使用，并且我们也在开源上面做探索，让这些组件和服务能为更多的人服务。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/360f8628e9997941686bbc0e7a82cb17.png"></p><p>通过OKR实践，我们扭转了曾经“畏惧犯错，不敢失败，不敢试错”的氛围，打造“乐于创新，敢于突破，勇于挑战”的文化。</p><h2 id="3-6-员工生产力提升"><a href="#3-6-员工生产力提升" class="headerlink" title="3.6 员工生产力提升"></a>3.6 员工生产力提升</h2><p>员工生产力的提升可以说是执行OKR科学管理的必然结果。OKR执行的一个特点：自下而上，即自主，是内在动机的一个基本心理需求。OKR理念强调在目标设定时，要有相当一部分目标是员工自己提出来的，而不是上级指派的。只有这样，员工才会感知到目标是自己的目标，不是他人强加给自己的目标，从而显著增强对目标的承诺感，最终带来员工生产力的提升。</p><p>海外商城的建设就是一个很好的案例。最初海外只有印度市场提出建设官方商城的需求，我们只需将内销商城系统复制一套，并部署到印度当地即可，这种方法简单高效，但是我们并未止步于此，当时我们预见到，海外其它市场需求也必将接踵而至，为了能够快速应对未来全球化业务的发展，我们做了充分的竞品分析、技术调研、架构设计、脑暴碰撞，经过一段时间的摸索和打磨，我们打造出了一套通用的全球化解决方案，包括多语言文案系统、多时区通用组件、多国家隔离框架、多机房域名部署方案等等，一套系统可满足多地区多品牌的需求，极大地提升了人效，在业务需求真正到来之时，可最快7天部署一套新商城。这些能力较好的支撑了商城当前业务的发展需要，同时赋能其它外销业务解决相关难题，多语言平台还一举获得公司级设计驱动奖。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/babd2223d926143ebfe0957ed6910080.png"></p><p>海外能力的建设，从设想到确立目标到落地，是员工自发自主自下而上去完成的，科技时代需要技术创新力，知识工作者需要突破既有经验和惯性束缚，OKR科学的管理机制给与了员工更大的发挥空间，生产力提升水到渠成。</p><h1 id="四、小结"><a href="#四、小结" class="headerlink" title="四、小结"></a>四、小结</h1><p>本章给大家讲述了我们在引入OKR之后发生的六点明显变化，这些变化既是因也是果，它们互相形成了一个良性循环的飞轮，朝着我们的愿景：“持续成长为行业一流的技术团队，并打造出了一支自组织、高绩效的标杆团队”不断前进。</p><p>如果你也想让你的团队有所改变，想更深入的了解OKR是怎么样一步一步的改变我们的，想进一步了解我们执行OKR的核心理念，想了解我们团队有哪些管理理念，那么这就是一本专门为你所写的系列文章。希望我们的团队一路走过来的经验，能为你打开一扇窗，让你有所启发，对你的团队管理有所帮助。</p><p>后续我们将会就以下话题和大家一起分享：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/594fd81198ad489a6443a714d1213152.png"></p><p>OKR给我们带来了很多改变，你们团队有引入OKR吗？为什么要引入OKR？它又给你们带来哪些改变呢？</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;平台产品研发团队 vivo互联网技术 2022-11-02&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/NLxg-4JUx-F-0NwPfO1qIw&quot;&gt;https://mp.weixin.qq.com/s/NLxg-4JUx-F-0</summary>
      
    
    
    
    <category term="OKR" scheme="http://zhangyu.info/categories/OKR/"/>
    
    
    <category term="OKR" scheme="http://zhangyu.info/tags/OKR/"/>
    
  </entry>
  
  <entry>
    <title>redis的大Key对持久化有什么影响</title>
    <link href="http://zhangyu.info/2022/10/26/redis%E7%9A%84%E5%A4%A7Key%E5%AF%B9%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%89%E4%BB%80%E4%B9%88%E5%BD%B1%E5%93%8D/"/>
    <id>http://zhangyu.info/2022/10/26/redis%E7%9A%84%E5%A4%A7Key%E5%AF%B9%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%89%E4%BB%80%E4%B9%88%E5%BD%B1%E5%93%8D/</id>
    <published>2022-10-25T16:00:00.000Z</published>
    <updated>2022-10-26T14:59:49.350Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/qq_34827674/article/details/126829220">https://blog.csdn.net/qq_34827674/article/details/126829220</a></p><p><a href="https://blog.csdn.net/qq_34827674/article/details/126829220">Redis 的大 Key 对持久化有什么影响？_小林coding的博客-CSDN博客_大key对redis的影响</a></p><blockquote><p>Redis 的持久化方式有两种：AOF 日志和 RDB <a href="https://so.csdn.net/so/search?q=%E5%BF%AB%E7%85%A7&spm=1001.2101.3001.7020">快照</a>。</p><p>所以接下来，针对这两种持久化方式具体分析分析。</p><h2 id="大-Key-对-AOF-日志的影响"><a href="#大-Key-对-AOF-日志的影响" class="headerlink" title="大 Key 对 AOF 日志的影响"></a>大 Key 对 AOF 日志的影响</h2><blockquote><p>先说说 AOF 日志三种写回磁盘的策略</p></blockquote><p>Redis 提供了 3 种 AOF 日志写回硬盘的策略，分别是：</p><ul><li>  Always，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；</li><li>  Everysec，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；</li><li>  No，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。</li></ul><p>这三种策略只是在控制 fsync() 函数的调用时机。</p><p>当应用程序向文件写入数据时，内核通常先将数据复制到内核缓冲区中，然后排入队列，然后由内核决定何时写入硬盘。</p><p><img src="https://img-blog.csdnimg.cn/def7d5328829470c9f3cfd15bbcc6814.png"></p><p>如果想要应用程序向文件写入数据后，能立马将数据同步到硬盘，就可以调用 fsync() 函数，这样内核就会将内核缓冲区的数据直接写入到硬盘，等到硬盘写操作完成后，该函数才会返回。</p><ul><li>  Always 策略就是每次写入 AOF 文件数据后，就执行 fsync() 函数；</li><li>  Everysec 策略就会创建一个异步任务来执行 fsync() 函数；</li><li>  No 策略就是永不执行 fsync() 函数;</li></ul><blockquote><p>分别说说这三种策略，在持久化大 Key 的时候，会影响什么？</p></blockquote><p>在使用 Always 策略的时候，主线程在执行完命令后，会把数据写入到 AOF 日志文件，然后会调用 fsync() 函数，将内核缓冲区的数据直接写入到硬盘，等到硬盘写操作完成后，该函数才会返回。</p><p><strong>当使用 Always 策略的时候，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的</strong>。</p><p>当使用 Everysec 策略的时候，由于是异步执行 fsync() 函数，所以大 Key 持久化的过程（数据同步磁盘）不会影响主线程。</p><p>当使用 No 策略的时候，由于永不执行 fsync() 函数，所以大 Key 持久化的过程不会影响主线程。</p><h2 id="大-Key-对-AOF-重写和-RDB-的影响"><a href="#大-Key-对-AOF-重写和-RDB-的影响" class="headerlink" title="大 Key 对 AOF 重写和 RDB 的影响"></a>大 Key 对 AOF 重写和 RDB 的影响</h2><p>当 AOF 日志写入了很多的大 Key，AOF 日志文件的大小会很大，那么很快就会触发 <strong>AOF 重写机制</strong>。</p><p>AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 <code>fork()</code> 函数创建一个子进程来处理任务。</p><p>在创建子进程的过程中，操作系统会把父进程的「<a href="https://so.csdn.net/so/search?q=%E9%A1%B5%E8%A1%A8&spm=1001.2101.3001.7020">页表</a>」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。</p><p><img src="https://img-blog.csdnimg.cn/06657cb93ffa4a24b8fc5b3069cb29bf.png"><br>这样一来，子进程就共享了父进程的物理内存数据了，这样能够节约物理内存资源，页表对应的页表项的属性会标记该物理内存的权限为<strong>只读</strong>。</p><p>随着 Redis 存在越来越多的大 Key，那么 Redis 就会占用很多内存，对应的页表就会越大。</p><p>在通过 <code>fork()</code> 函数创建子进程的时候，虽然不会复制父进程的物理内存，但是<strong>内核会把父进程的页表复制一份给子进程，如果页表很大，那么这个复制过程是会很耗时的，那么在执行 fork 函数的时候就会发生阻塞现象</strong>。</p><p>而且，fork 函数是由 Redis 主线程调用的，如果 fork 函数发生阻塞，那么意味着就会阻塞 Redis 主线程。由于 Redis 执行命令是在主线程处理的，所以当 Redis 主线程发生阻塞，就无法处理后续客户端发来的命令。</p><p>我们可以执行 <code>info</code> 命令获取到 latest_fork_usec 指标，表示 Redis 最近一次 fork 操作耗时。</p><pre><code># 最近一次 fork 操作耗时latest_fork_usec:315</code></pre><p>如果 fork 耗时很大，比如超过1秒，则需要做出优化调整：</p><ul><li>  单个实例的内存占用控制在 10 GB 以下，这样 fork 函数就能很快返回。</li><li>  如果 Redis 只是当作纯缓存使用，不关心 Redis 数据安全性问题，可以考虑关闭 AOF 和 AOF 重写，这样就不会调用 fork 函数了。</li><li>  在主从架构中，要适当调大 repl-backlog-size，避免因为 repl_backlog_buffer 不够大，导致主节点频繁地使用全量同步的方式，全量同步的时候，是会创建 RDB 文件的，也就是会调用 fork 函数。</li></ul><blockquote><p>那什么时候会发生物理内存的复制呢？</p></blockquote><p>当父进程或者子进程在向共享内存发起写操作时，CPU 就会触发<strong>缺页中断</strong>，这个缺页中断是由于违反权限导致的，然后操作系统会在「缺页异常处理函数」里进行物理内存的复制，并重新设置其内存映射关系，将父子进程的内存读写权限设置为可读写，最后才会对内存进行写操作，这个过程被称为「**写时复制(Copy On Write)**」。</p><p><img src="https://img-blog.csdnimg.cn/451024fe10374431aff6f93a8fed4638.png"></p><p>写时复制顾名思义，在发生写操作的时候，操作系统才会去复制物理内存，这样是为了防止 fork 创建子进程时，由于物理内存数据的复制时间过长而导致父进程长时间阻塞的问题。</p><p>如果创建完子进程后，<strong>父进程对共享内存中的大 Key 进行了修改，那么内核就会发生写时复制，会把物理内存复制一份，由于大 Key 占用的物理内存是比较大的，那么在复制物理内存这一过程中，也是比较耗时的，于是父进程（主线程）就会发生阻塞</strong>。</p><p>所以，有两个阶段会导致阻塞父进程：</p><ul><li>  创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；</li><li>  创建完子进程后，如果子进程或者父进程修改了共享数据，就会发生写时复制，这期间会拷贝物理内存，如果内存越大，自然阻塞的时间也越长；</li></ul><p>这里额外提一下， 如果 <strong>Linux 开启了内存大页，会影响 Redis 的性能的</strong>。</p><p>Linux 内核从 2.6.38 开始支持内存大页机制，该机制支持 2MB 大小的内存页分配，而常规的内存页分配是按 4KB 的粒度来执行的。</p><p>如果采用了内存大页，那么即使客户端请求只修改 100B 的数据，在发生写时复制后，Redis 也需要拷贝 2MB 的大页。相反，如果是常规内存页机制，只用拷贝 4KB。</p><p>两者相比，你可以看到，每次写命令引起的<strong>复制内存页单位放大了 512 倍，会拖慢写操作的执行时间，最终导致 Redis 性能变慢</strong>。</p><p>那该怎么办呢？很简单，关闭内存大页（默认是关闭的）。</p><p>禁用方法如下：</p><pre><code>echo never &gt;  /sys/kernel/mm/transparent_hugepage/enabled</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>当 AOF 写回策略配置了 Always 策略，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的。</p><p>AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 <code>fork()</code> 函数创建一个子进程来处理任务。会有两个阶段会导致阻塞父进程（主线程）：</p><ul><li>  创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；</li><li>  创建完子进程后，如果父进程修改了共享数据中的大 Key，就会发生写时复制，这期间会拷贝物理内存，由于大 Key 占用的物理内存会很大，那么在复制物理内存这一过程，就会比较耗时，所以有可能会阻塞父进程。</li></ul><p>大 key 除了会影响持久化之外，还会有以下的影响。</p><ul><li><p>  客户端超时阻塞。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</p></li><li><p>  引发网络阻塞。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</p></li><li><p>  阻塞工作线程。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</p></li><li><p>  内存分布不均。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。</p></li></ul><p>如何避免大 Key 呢？</p><p>最好在设计阶段，就把大 key 拆分成一个一个小 key。或者，定时检查 Redis 是否存在大 key ，如果该大 key 是可以删除的，不要使用 DEL 命令删除，因为该命令删除过程会阻塞主线程，而是用 unlink 命令（Redis 4.0+）删除大 key，因为该命令的删除过程是异步的，不会阻塞主线程。</p><p>完！</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/qq_34827674/article/details/126829220&quot;&gt;https://blog.csdn.net/qq_34827674/article/details/126829220&lt;/a&gt;&lt;/p&gt;</summary>
      
    
    
    
    <category term="redis" scheme="http://zhangyu.info/categories/redis/"/>
    
    
    <category term="redis" scheme="http://zhangyu.info/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis的常见使用场景</title>
    <link href="http://zhangyu.info/2022/10/26/redis%E7%9A%84%E5%B8%B8%E8%A7%81%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/"/>
    <id>http://zhangyu.info/2022/10/26/redis%E7%9A%84%E5%B8%B8%E8%A7%81%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/</id>
    <published>2022-10-25T16:00:00.000Z</published>
    <updated>2022-10-26T15:19:01.932Z</updated>
    
    <content type="html"><![CDATA[<p> <a href="https://blog.csdn.net/Number_oneEngineer/article/details/123229706">https://blog.csdn.net/Number_oneEngineer/article/details/123229706</a><br><a href="https://blog.csdn.net/agonie201218/article/details/123640871">https://blog.csdn.net/agonie201218/article/details/123640871</a></p><blockquote><h2 id="1-缓存"><a href="#1-缓存" class="headerlink" title="1. 缓存"></a>1. 缓存</h2><p>作为<code>Key-Value</code>形态的内存数据库，Redis 最先会被想到的应用场景便是作为数据缓存。而使用 Redis 缓存数据非常简单，只需要通过<code>string</code>类型将序列化后的对象存起来即可，不过也有一些需要注意的地方：</p><ul><li><p>  必须保证不同对象的 key 不会重复，并且使 key 尽量短，一般使用类名（表名）加主键拼接而成。</p></li><li><p>  选择一个优秀的序列化方式也很重要，目的是提高序列化的效率和减少内存占用。</p></li><li><p>缓存内容与数据库的一致性，这里一般有两种做法：</p><ol><li> 只在数据库查询后将对象放入缓存，如果对象发生了修改或删除操作，直接清除对应缓存（或设为过期）。</li><li> 在数据库新增和查询后将对象放入缓存，修改后更新缓存，删除后清除对应缓存（或设为过期）。</li></ol></li></ul><p>String类型</p><p>例如：热点数据缓存（例如报表、明星出轨），对象缓存、全页缓存、可以提升热点数据的访问数据。</p><h2 id="2-数据共享分布式"><a href="#2-数据共享分布式" class="headerlink" title="2. 数据共享分布式"></a>2. 数据共享分布式</h2><p>String 类型，因为 Redis 是分布式的独立服务，可以在多个应用之间共享</p><p>例如：分布式Session</p><pre><code>&lt;dependency&gt;  &lt;groupId&gt;org.springframework.session&lt;/groupId&gt;  &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; &lt;/dependency&gt;</code></pre><h2 id="3、分布式锁"><a href="#3、分布式锁" class="headerlink" title="3、分布式锁"></a>3、分布式锁</h2><p>如今都是分布式的环境下java自带的单体锁已经不适用的。在 Redis 2.6.12 版本开始，<code>string</code>的<code>set</code>命令增加了一些参数：</p><ul><li><p>  <code>EX</code>：设置键的过期时间（单位为秒）</p></li><li><p>  <code>PX</code>：设置键的过期时间（单位为毫秒）</p></li><li><p>  <code>NX</code> ：只在键不存在时，才对键进行设置操作。 <code>SET key value NX</code> 效果等同于 <code>SETNX key value</code> 。</p></li><li><p>  <code>XX</code> ：只在键已经存在时，才对键进行设置操作。</p></li></ul><p>由于这个操作是原子性的，可以简单地以此实现一个分布式的锁，例如：</p><pre><code>　　set lock_key locked NX EX 1 </code></pre><p>如果这个操作返回<code>false</code>，说明 key 的添加不成功，也就是当前有人在占用这把锁。而如果返回<code>true</code>，则说明得了锁，便可以继续进行操作，并且在操作后通过<code>del</code>命令释放掉锁。并且即使程序因为某些原因并没有释放锁，由于设置了过期时间，该锁也会在 1 秒后自动释放，不会影响到其他程序的运行。<br>　　<br>推荐使用 redisson 第三方库实现分布式锁。<br>参考 <a href="https://blog.csdn.net/agonie201218/article/details/122084140">java分布式锁终极解决方案之 redisson</a><br>String 类型setnx方法，只有不存在时才能添加成功，返回true</p><pre><code>public static boolean getLock(String key) &#123;    Long flag = jedis.setnx(key, &quot;1&quot;);    if (flag == 1) &#123;        jedis.expire(key, 10);    &#125;    return flag == 1;&#125;public static void releaseLock(String key) &#123;    jedis.del(key);&#125;</code></pre><h2 id="4、全局ID"><a href="#4、全局ID" class="headerlink" title="4、全局ID"></a>4、全局ID</h2><p>int类型，incrby，利用原子性</p><p><code>incrby userid 1000</code></p><p>分库分表的场景，一次性拿一段</p><h2 id="5、计数器"><a href="#5、计数器" class="headerlink" title="5、计数器"></a>5、计数器</h2><p>int类型，incr方法</p><p>例如：文章的阅读量、微博点赞数、允许一定的延迟，先写入Redis再定时同步到数据库</p><p>计数功能应该是最适合 Redis 的使用场景之一了，因为它高频率读写的特征可以完全发挥 Redis 作为内存数据库的高效。在 Redis 的<a href="https://so.csdn.net/so/search?q=%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84&spm=1001.2101.3001.7020">数据结构</a>中，<code>string</code>、<code>hash</code>和<code>sorted set</code>都提供了<code>incr</code>方法用于原子性的自增操作，下面举例说明一下它们各自的使用场景：</p><ul><li>  如果应用需要显示每天的注册用户数，便可以使用<code>string</code>作为计数器，设定一个名为<code>REGISTERED_COUNT_TODAY</code>的 key，并在初始化时给它设置一个到凌晨 0 点的过期时间，每当用户注册成功后便使用<code>incr</code>命令使该 key 增长 1，同时当每天凌晨 0 点后，这个计数器都会因为 key 过期使值清零。</li><li>  每条微博都有点赞数、评论数、转发数和浏览数四条属性，这时用<code>hash</code>进行计数会更好，将该计数器的 key 设为<code>weibo:weibo_id</code>，<code>hash</code>的 field 为<code>like_number</code>、<code>comment_number</code>、<code>forward_number</code>和<code>view_number</code>，在对应操作后通过<code>hincrby</code>使<code>hash 中</code>的 field 自增。</li><li>  如果应用有一个发帖排行榜的功能，便选择<code>sorted set</code>吧，将集合的 key 设为<code>POST_RANK</code>。当用户发帖后，使用<code>zincrby</code>将该用户 id 的 score 增长 1。<code>sorted set</code>会重新进行排序，用户所在排行榜的位置也就会得到实时的更新。</li></ul><h2 id="6、限流"><a href="#6、限流" class="headerlink" title="6、限流"></a>6、限流</h2><p>int类型，incr方法</p><p>以访问者的ip和其他信息作为key，访问一次增加一次计数，超过次数则返回false</p><h2 id="7、位统计"><a href="#7、位统计" class="headerlink" title="7、位统计"></a>7、位统计</h2><p>String类型的bitcount（1.6.6的bitmap数据结构介绍）</p><p>字符是以8位二进制存储的</p><pre><code>set k1 asetbit k1 6 1setbit k1 7 0get k1 /* 6 7 代表的a的二进制位的修改a 对应的ASCII码是97，转换为二进制数据是01100001b 对应的ASCII码是98，转换为二进制数据是01100010因为bit非常节省空间（1 MB=8388608 bit），可以用来做大数据量的统计。*/</code></pre><p>例如：在线用户统计，留存用户统计</p><pre><code>setbit onlineusers 01 setbit onlineusers 11 setbit onlineusers 20</code></pre><p>支持按位与、按位或等等操作</p><pre><code>BITOPANDdestkeykey[key...] ，对一个或多个 key 求逻辑并，并将结果保存到 destkey 。       BITOPORdestkeykey[key...] ，对一个或多个 key 求逻辑或，并将结果保存到 destkey 。 BITOPXORdestkeykey[key...] ，对一个或多个 key 求逻辑异或，并将结果保存到 destkey 。 BITOPNOTdestkeykey ，对给定 key 求逻辑非，并将结果保存到 destkey 。</code></pre><p>计算出7天都在线的用户</p><pre><code>BITOP &quot;AND&quot; &quot;7_days_both_online_users&quot; &quot;day_1_online_users&quot; &quot;day_2_online_users&quot; ...  &quot;day_7_online_users&quot;</code></pre><p>参考 <a href="https://blog.csdn.net/agonie201218/article/details/107161106">使用Redis的bitmaps统计用户留存率、活跃用户</a></p><p><a href="https://blog.csdn.net/agonie201218/article/details/108988577">用户日活月活怎么统计 - Redis HyperLogLog 详解</a></p><h2 id="8-时间轴（Timeline）"><a href="#8-时间轴（Timeline）" class="headerlink" title="8. 时间轴（Timeline）"></a>8. 时间轴（Timeline）</h2><p> <code>list</code>作为双向链表，不光可以作为队列使用。如果将它用作栈便可以成为一个公用的时间轴。当用户发完微博后，都通过<code>lpush</code>将它存放在一个 key 为<code>LATEST_WEIBO</code>的<code>list</code>中，之后便可以通过<code>lrange</code>取出当前最新的微博。</p><h2 id="9-消息队列"><a href="#9-消息队列" class="headerlink" title="9. 消息队列"></a>9. 消息队列</h2><p>Redis 中<code>list</code>的数据结构实现是双向链表，所以可以非常便捷的应用于消息队列（生产者 / 消费者模型）。消息的生产者只需要通过<code>lpush</code>将消息放入 list，消费者便可以通过<code>rpop</code>取出该消息，并且可以保证消息的有序性。如果需要实现带有优先级的消息队列也可以选择<code>sorted set</code>。而<code>pub/sub</code>功能也可以用作发布者 / 订阅者模型的消息。无论使用何种方式，由于 Redis 拥有持久化功能，也不需要担心由于服务器故障导致消息丢失的情况。</p><p>List提供了两个阻塞的弹出操作：blpop/brpop，可以设置超时时间</p><ul><li>  blpop：blpop key1 timeout 移除并获取列表的第一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。</li><li>  brpop：brpop key1 timeout 移除并获取列表的最后一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。</li></ul><p>上面的操作。其实就是java的阻塞队列。学习的东西越多。学习成本越低</p><ul><li>  队列：先进先除：rpush blpop，左头右尾，右边进入队列，左边出队列</li><li>  栈：先进后出：rpush brpop</li></ul><h3 id="10、抽奖"><a href="#10、抽奖" class="headerlink" title="10、抽奖"></a>10、抽奖</h3><p>利用set结构的无序性,通过 Spop（ Redis Spop 命令用于移除<a href="https://so.csdn.net/so/search?q=%E9%9B%86%E5%90%88&spm=1001.2101.3001.7020">集合</a>中的指定 key 的一个或多个随机元素，移除后会返回移除的元素。 ） 随机获得值</p><pre><code>redis&gt; SADD myset &quot;one&quot;(integer) 1redis&gt; SADD myset &quot;two&quot;(integer) 1redis&gt; SADD myset &quot;three&quot;(integer) 1redis&gt; SPOP myset&quot;one&quot;redis&gt; SMEMBERS myset1) &quot;three&quot;2) &quot;two&quot;redis&gt; SADD myset &quot;four&quot;(integer) 1redis&gt; SADD myset &quot;five&quot;(integer) 1redis&gt; SPOP myset 31) &quot;five&quot;2) &quot;four&quot;3) &quot;two&quot;redis&gt; SMEMBERS myset1) &quot;three&quot;redis&gt; </code></pre><h2 id="11、点赞、签到、打卡"><a href="#11、点赞、签到、打卡" class="headerlink" title="11、点赞、签到、打卡"></a>11、点赞、签到、打卡</h2><p><img src="https://img-blog.csdnimg.cn/img_convert/201157552a906cdee10942c9e3acc2c3.png" alt="图片"></p><p>假如上面的微博ID是t1001，用户ID是u3001</p><p>用 like:t1001 来维护 t1001 这条微博的所有点赞用户</p><ul><li>  点赞了这条微博：sadd like:t1001 u3001</li><li>  取消点赞：srem like:t1001 u3001</li><li>  是否点赞：sismember like:t1001 u3001</li><li>  点赞的所有用户：smembers like:t1001</li><li>  点赞数：scard like:t1001</li></ul><p>是不是比数据库简单多了。</p><h2 id="12-商品标签"><a href="#12-商品标签" class="headerlink" title="12 商品标签"></a>12 商品标签</h2><p><img src="https://img-blog.csdnimg.cn/img_convert/c3af93df9d330c0c490667e497a6846e.png" alt="图片"></p><p>老规矩，用 tags:i5001 来维护商品所有的标签。</p><ul><li>  sadd tags:i5001 画面清晰细腻</li><li>  sadd tags:i5001 真彩清晰显示屏</li><li>  sadd tags:i5001 流程至极</li></ul><h3 id="13、好友关系、用户关注、推荐模型"><a href="#13、好友关系、用户关注、推荐模型" class="headerlink" title="13、好友关系、用户关注、推荐模型"></a>13、好友关系、用户关注、推荐模型</h3><p>这个场景最开始是是一篇介绍微博 Redis 应用的 PPT 中看到的，其中提到微博的 Redis 主要是用在在计数和好友关系两方面上，当时对好友关系方面的用法不太了解，后来看到《Redis 设计与实现》中介绍到作者最开始去使用 Redis 便是希望能通过<code>set</code>解决传统数据库无法快速计算集合中交集这个功能。后来联想到微博当前的业务场景，确实能够以这种方式实现，所以姑且猜测一下：</p><p>对于一个用户 A，将它的关注和粉丝的用户 id 都存放在两个 set 中：</p><ul><li><p>  <code>A:follow</code>：存放 A 所有关注的用户 id</p></li><li><p><code>A:follower</code>：存放 A 所有粉丝的用户 id</p><p>  那么通过<code>sinter</code>命令便可以根据<code>A:follow</code>和<code>A:follower</code>的交集得到与 A 互相关注的用户。当 A 进入另一个用户 B 的主页后，<code>A:follow</code>和<code>B:follow</code>的交集便是 A 和 B 的共同专注，<code>A:follow</code>和<code>B:follower</code>的交集便是 A 关注的人也关注了 B。</p></li></ul><h3 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h3><p>follow 关注 fans 粉丝</p><p>相互关注：</p><ul><li>  sadd 1:follow 2</li><li>  sadd 2:fans 1</li><li>  sadd 1:fans 2</li><li>  sadd 2:follow 1</li></ul><p>我关注的人也关注了他(取交集)：</p><ul><li>  sinter 1:follow 2:fans</li></ul><p>可能认识的人：</p><ul><li>  用户1可能认识的人(差集)：sdiff 2:follow 1:follow</li><li>  用户2可能认识的人：sdiff 1:follow 2:follow</li></ul><h2 id="14-排行榜"><a href="#14-排行榜" class="headerlink" title="14 .排行榜"></a>14 .排行榜</h2><p>使用<code>sorted set</code>(有序set)和一个计算热度的算法便可以轻松打造一个热度排行榜，<code>zrevrangebyscore</code>可以得到以分数倒序排列的序列，<code>zrank</code>可以得到一个成员在该排行榜的位置（是分数正序排列时的位置，如果要获取倒序排列时的位置需要用<code>zcard</code>-<code>zrank</code>）。</p><p>id 为6001 的新闻点击数加1：</p><pre><code>zincrby hotNews:20190926 1 n6001</code></pre><p>获取今天点击最多的15条：</p><pre><code>zrevrange hotNews:20190926 0 15 withscores</code></pre><h3 id="15-倒排索引"><a href="#15-倒排索引" class="headerlink" title="15 .倒排索引"></a>15 .倒排索引</h3><p>倒排索引是构造搜索功能的最常见方式，在 Redis 中也可以通过<code>set</code>进行建立倒排索引，这里以简单的拼音 + 前缀搜索城市功能举例：</p><p>假设一个城市<code>北京</code>，通过拼音词库将<code>北京</code>转为<code>beijing</code>，再通过前缀分词将这两个词分为若干个前缀索引，有：<code>北</code>、<code>北京</code>、<code>b</code>、<code>be</code>…<code>beijin</code>和<code>beijing</code>。将这些索引分别作为<code>set</code>的 key（例如:<code>index:北</code>）并存储<code>北京</code>的 id，倒排索引便建立好了。接下来只需要在搜索时通过关键词取出对应的<code>set</code>并得到其中的 id 即可。</p><h2 id="16-显示最新的项目列表"><a href="#16-显示最新的项目列表" class="headerlink" title="16 .显示最新的项目列表"></a><strong>16 .显示最新的项目列表</strong></h2><p>比如说，我们的一个Web应用想要列出用户贴出的最新20条评论。在最新的评论边上我们有一个“显示全部”的链接，点击后就可以获得更多的评论。</p><p>每次新评论发表时，我们会将它的ID添加到一个Redis列表。可以限定列表的长度为5000</p><p>LPUSH latest.comments</p><p>在Redis中我们的最新ID使用了常驻缓存，这是一直更新的。但是我们做了限制不能超过5000个ID，因此我们的获取ID函数会一直询问Redis。只有在超出了这个范围的时候，才需要去访问数据库。</p><h1 id="17、购物车"><a href="#17、购物车" class="headerlink" title="17、购物车"></a>17、购物车</h1><p>String 或hash。所有String可以做的hash都可以做</p><p><img src="https://img-blog.csdnimg.cn/bf8b92966ab448d88c48f0b45a262e0c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5oiR5Lus5LiA6LW35Y675aSn5Y6C,size_9,color_FFFFFF,t_70,g_se,x_16" alt="图片"></p><ul><li>  key：用户id；field：商品id；value：商品数量。</li><li>  +1：hincr。-1：hdecr。删除：hdel。全选：hgetall。商品数：hlen。</li></ul><h1 id="18、商品筛选"><a href="#18、商品筛选" class="headerlink" title="18、商品筛选"></a>18、商品筛选</h1><pre><code>// 获取差集sdiff set1 set2// 获取交集（intersection ）sinter set1 set2// 获取并集sunion set1 set2</code></pre><p><img src="https://img-blog.csdnimg.cn/d8db8ebb604848bca9646dac0a21859c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5oiR5Lus5LiA6LW35Y675aSn5Y6C,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><p>假如：iPhone11 上市了</p><pre><code>sadd brand:apple iPhone11sadd brand:ios iPhone11sad screensize:6.0-6.24 iPhone11sad screentype:lcd iPhone 11</code></pre><p>赛选商品，苹果的、ios的、屏幕在6.0-6.24之间的，屏幕材质是LCD屏幕</p><pre><code>sinter brand:apple brand:ios screensize:6.0-6.24 screentype:lcd</code></pre><h1 id="19、排行榜"><a href="#19、排行榜" class="headerlink" title="19、排行榜"></a>19、排行榜</h1><p>id 为6001 的新闻点击数加1：</p><blockquote><p>zincrby hotNews:20190926 1 n6001</p></blockquote><p>获取今天点击最多的15条：</p><blockquote><p>zrevrange hotNews:20190926 0 15 withscores</p></blockquote><p><img src="https://img-blog.csdnimg.cn/e61eb794e182400da1aa9f84b00e7800.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5oiR5Lus5LiA6LW35Y675aSn5Y6C,size_7,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; &lt;a href=&quot;https://blog.csdn.net/Number_oneEngineer/article/details/123229706&quot;&gt;https://blog.csdn.net/Number_oneEngineer/article/details/12</summary>
      
    
    
    
    <category term="redis" scheme="http://zhangyu.info/categories/redis/"/>
    
    
    <category term="redis" scheme="http://zhangyu.info/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>云原生微服务最佳实践</title>
    <link href="http://zhangyu.info/2022/05/28/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
    <id>http://zhangyu.info/2022/05/28/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</id>
    <published>2022-05-27T16:00:00.000Z</published>
    <updated>2022-05-28T06:20:51.855Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://developer.aliyun.com/article/891714?spm=5176.21213303.J_6704733920.7.22db53c9yXA1Zr&amp;scm=20140722.S_community@@%E6%96%87%E7%AB%A0@@891714._.ID_community@@%E6%96%87%E7%AB%A0@@891714-RL_%E4%BA%91%E5%8E%9F%E7%94%9F%E6%9E%B6%E6%9E%84%E4%B8%8B%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%80%89%E5%9E%8B%E5%92%8C%E6%BC%94%E8%BF%9B-LOC_main-OR_ser-V_2-P0_0">https://developer.aliyun.com/article/891714?spm=5176.21213303.J_6704733920.7.22db53c9yXA1Zr&amp;scm=20140722.S_community%40%40%E6%96%87%E7%AB%A0%40%40891714._.ID_community%40%40%E6%96%87%E7%AB%A0%40%40891714-RL_%E4%BA%91%E5%8E%9F%E7%94%9F%E6%9E%B6%E6%9E%84%E4%B8%8B%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%80%89%E5%9E%8B%E5%92%8C%E6%BC%94%E8%BF%9B-LOC_main-OR_ser-V_2-P0_0</a></p><p>作者：彦林<br>本文整理自阿里云智能高级技术专家彦林的线上直播分享《云原生微服务最佳实践》。视频回放地址：<a href="https://yqh.aliyun.com/live/detail/28454">https://yqh.aliyun.com/live/detail/28454</a></p><p><a href="https://developer.aliyun.com/article/891714?spm=5176.21213303.J_6704733920.7.22db53c9yXA1Zr&scm=20140722.S_community@@%E6%96%87%E7%AB%A0@@891714._.ID_community@@%E6%96%87%E7%AB%A0@@891714-RL_%E4%BA%91%E5%8E%9F%E7%94%9F%E6%9E%B6%E6%9E%84%E4%B8%8B%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%80%89%E5%9E%8B%E5%92%8C%E6%BC%94%E8%BF%9B-LOC_main-OR_ser-V_2-P0_0">云原生架构下的微服务选型和演进-阿里云开发者社区</a></p><blockquote><p>随着云原生的演进，微服务作为主流应用架构被广泛使用，其落地的难题逐步从如何建好延伸到如何用好。今天跟各位小伙伴分享一下我在微服务领域 10 余年的实践经验，如何以更高效的姿势把微服务这件事做扎实。</p><h2 id="阿里微服务发展历程"><a href="#阿里微服务发展历程" class="headerlink" title="阿里微服务发展历程"></a>阿里微服务发展历程</h2><h3 id="微服务-1-0-（1w-实例-微服务拆分-同城容灾）"><a href="#微服务-1-0-（1w-实例-微服务拆分-同城容灾）" class="headerlink" title="微服务 1.0 （1w 实例/微服务拆分/同城容灾）"></a>微服务 1.0 （1w 实例/微服务拆分/同城容灾）</h3><p>2008 年随着阿里业务规模不断增大，单体胖应用+硬负载的架构逐渐暴露性能瓶颈；随着研发人员逐步增多，协调效率也逐步下降，不能满足日益复杂的业务挑战，因此急需技术升级解决这些问题。<br> <img src="https://ucc.alicdn.com/pic/developer-ecology/755e59619c8c46f19ca8886caf9b725b.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650460882673-b82ca6e7-297e-42a4-817d-badbf61b1604.png?x-oss-process=image/resize,w_1165,limit_0"> </p><p>在当时 SOA 架构非常流行，也就成为我们技术演进的主要方向，当时有两种解决方案，一个是 Server Based 的解决方案，这种模式侵入小、方便集中管控，但是这种中心化方案会带来成本高、稳定性风险高、扩展性差；一个是 Client Based 的解决方案，这种模式去中心化，扩展性强，成本低，但是会带来一定侵入性，比较难以管理；当然很多人会问为什么不直接用 DNS 呢？主要是 DNS 不能满足 IDC 内部服务发现实时性，服务列表更新不能及时通知下有业务会导致业务流量损失。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650461250591-19bfb292-1d8d-4f87-918c-9629d5fc7cbd.png?x-oss-process=image/resize,w_1177,limit_0"> </p><p>在评估两种方案利弊之后，我们在网关这种需要集中管理安全和简单路由场景采用了 Server Based 的方案，基于 Nginx 演进出了阿里 Tengine 网关技术体系，从入口处解决安全、高可用、简单路由能力；在 IDC 内部采用了 Client Base 模式，孵化出 HSF/Dubbo+Nacos 技术体系，支撑了业务微服务拆分。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650461729968-5cb9547c-cd5d-4b9f-9399-364b98176bc1.png?x-oss-process=image/resize,w_1188,limit_0"> </p><p>随着第一代微服务架构落地，由于引入注册中心带来了稳定性风险，注册中心挂会导致调用链路全部中断；业务集中发布的时候注册中心压力会比较大。</p><p> <img src="https://ucc.alicdn.com/pic/developer-ecology/25993cdf295a410fa086fb6ff888c54a.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650508584813-db5f3b84-d992-4d65-8ecd-9c681bdcafd8.png?x-oss-process=image/resize,w_1114,limit_0"> </p><p>针对可用性问题我们提供了推空保护能力，即使注册中心挂也不会影响业务正常运行；为了提供更好性能我们提供了全异步架构；为了支持同城容灾我们提供了 AP 一致性协议，具体协议可以参考《Nacos 架构与原理》电子书。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650508698563-3d6d07b7-6003-449f-97aa-3313a3748faa.png?x-oss-process=image/resize,w_937,limit_0"> </p><p>随着阿里微服务 1.0 架构落地，帮助业务完成微服务拆分，解决了扩展性和协同效率问题，同时支撑了阿里同城容灾能力。对于正在做微服务的小伙伴可能问阿里如何做微服务架构演进的：</p><p><strong>前后端分离是第一步</strong>，因为前端变化多，变化快，后端相对变化小，演进慢，因此需要解耦发展，让前端更快的适应市场变化，以便在竞争中保持先机；</p><p><strong>后端无状态改造是第二步，</strong>把内存状态外置到 Redis，把持久化状态外置到 Mysql，这样业务就可以随意进行切分；</p><p><strong>第三步是模块化拆分，</strong>这块是最考验架构师的，因为拆分一个是按照业务属性拆分，一个是按照应用复杂度进行拆分，这个是一个相对动态过程，建议拆分模块后 2-3 人负责一个模块，拆到太细会有比较高的运维成本，拆的太粗又会带来研发协同问题，阿里内部也经历过合久必分，分久必合的几波震荡，最终走到相对稳态。这里值得一提就是 HSF/Dubbo 的一个优势，因为早期采用 SOA 架构思想设计，一个接口就是一个服务，这样其实非常方便服务的拆分和合并，当然同时带来一个问题是对注册中心性能压力比较大，这是一个架构选择和平衡问题。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650462151116-d659464c-9abf-47c1-aea3-ada1738d921e.png?x-oss-process=image/resize,w_1178,limit_0"> </p><h3 id="微服务-2-0（10w-实例-业务中台-异地多活）"><a href="#微服务-2-0（10w-实例-业务中台-异地多活）" class="headerlink" title="微服务 2.0（10w 实例/业务中台/异地多活）"></a>微服务 2.0（10w 实例/业务中台/异地多活）</h3><p>微服务 1.0 架构帮助阿里极大缓解性能和效率问题，但是由于阿里双十一的成功，技术上面临一个洪峰的技术挑战，我们必须在用户体验、资源成本、高可用之间做一个平衡。这个阶段我们最大的挑战是扩展性和稳定性，扩展性是要支撑业务 10w+实例扩容，但是单地资源有限，双十一商家投入的资金越来越大，导致我们双十一当天也不能出严重问题，不然损失非常大，因此对业务稳定性提出非常高的要求。<br> <img src="https://ucc.alicdn.com/pic/developer-ecology/caa299c0e6e84c40ad3a9c70f56303a9.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650462646607-791462f4-595f-4dfd-b16b-457a33ff0972.png?x-oss-process=image/resize,w_937,limit_0"> </p><p>因此阿里演进到微服务 2.0 支撑了异地多活的高可用体系，让阿里业务可以按照 IDC 级别水平扩展，新的机房，新的技术体系都可以在单元中进行验证，也加速了阿里技术体系演进速度。<br> <img src="https://ucc.alicdn.com/pic/developer-ecology/80e28a96536640fea086b733e79b0e69.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650463572269-62635384-a842-42d6-b7b6-5e948f9a57ae.png?x-oss-process=image/resize,w_1188,limit_0"> </p><p>在此期间 Nacos Server 间水平通知压力巨大，业务发布窗口容易把网卡打满，频繁推送会消耗业务大量内存和 CPU，进而影响业务的稳定性。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650508924614-ec9806bf-df64-4e93-b898-48c2350b3e01.png?x-oss-process=image/resize,w_937,limit_0"> </p><p>针对上述问题，我们在 Nacos Server 间做了聚合推送，将一定时间窗的变更合并聚合推送，推送过程中做了压缩推送，从而解决了上述问题。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650508934970-0f10fd5f-038f-4d64-9baa-a1178df0b7a7.png?x-oss-process=image/resize,w_937,limit_0"> </p><p>在微服务解决扩展性和高可用的同时，业务系统变多，重复建设，业务孤岛也越来越多，协同效率也越来越低，因此阿里业务在这个时候推出了业务中台能力，将扁平的微服务抽象分层，将基础服务抽象为中台服务解决上述问题，业务分层后支撑了阿里业务高速增长，也加速了技术架构统一。 <img src="https://ucc.alicdn.com/pic/developer-ecology/a772d2e42c8e4db6bb050c6679da3997.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650463819661-fc69a6f1-fb7e-4b4d-b1c2-f00659a3e49a.png?x-oss-process=image/resize,w_1160,limit_0"> </p><h3 id="微服务-3-0（100w-实例-业务域拆分-云原生）"><a href="#微服务-3-0（100w-实例-业务域拆分-云原生）" class="headerlink" title="微服务 3.0（100w 实例/业务域拆分/云原生）"></a>微服务 3.0（100w 实例/业务域拆分/云原生）</h3><p>微服务 2.0 架构支撑了阿里双十一的技术奇迹，阿里也陆续开启业务扩张，构建更完整的互联网版图。在这个阶段阿里收购了比较多的公司，技术体系不统一如何形成合力；从线上走到线下后，线下系统对系统稳定性要求更高；云计算发展，如何利用好云的弹性做双十一，这个阶段我们也推出了微服务的云产品，期望通过云产品支撑阿里双十一。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650464151858-72dfe7f9-b5bc-42b7-827b-553bdbf9ce89.png?x-oss-process=image/resize,w_937,limit_0"> </p><p>业务域切分比较容易，切完之后如何更好的互联互通是一个关键，因此我们内部推出了 Nacos-sync 和云原生网关两个产品。Nacos-sync 适合业务流量超大，协议一致场景。云原生网关适合网络不通，协议不同，跨 Region 等场景。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650465807802-a2d8f5f6-79a3-4597-b79d-e7f4cadafba9.png?x-oss-process=image/resize,w_1128,limit_0"> </p><p>即使从顶层做了业务域拆分，但是最大的电商集群往百万实例演进过程中对注册中心的压力越来越大，我们把聚合窗口时间不断拉长，推送慢了会导致业务发布时间变长，推送快了会对业务消耗较大，因此陷入了两难境地。</p><p> <img src="https://ucc.alicdn.com/pic/developer-ecology/c32c246c55d2432cb4885199b476ebc4.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650509243198-6fe13d99-5b6d-4e41-9bde-cfc8a59d45ab.png?x-oss-process=image/resize,w_937,limit_0"> </p><p>这个阶段我们进行问题的分解，首先根据服务列表大小做了一个切分，服务列表多的可以推送慢一些问题也不大，服务列表小的需要及时推送，因此我们优化了聚合推送逻辑，根据服务列表大小做了分级推送。还有一个优化思路是变更只有几个列表变化，因此我们提供了增量推送能力，大幅降低服务变更推送数据量。<br> <img src="https://ucc.alicdn.com/pic/developer-ecology/f8db6f13fb54416091568489a31be669.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650509262172-e9fa62ae-463d-425b-9933-806d2a6e4e2d.png?x-oss-process=image/resize,w_1087,limit_0"> </p><p>通过微服务 3.0 架构演进很好的解决了跨域互通和平滑上云的问题，新业务可以先上云，或者部分业务上云，通过网关做云上云下互通等问题，同时支撑了百万实例微服务架构演进。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650465843769-f8d72e1a-68f4-4da3-8f5b-a52690bbf47e.png?x-oss-process=image/resize,w_1158,limit_0"> </p><p> <img src="https://ucc.alicdn.com/pic/developer-ecology/ca0536204d5c4512baa2b0a37345c6fc.gif" alt="image.gif" title="image.gif"> 期望通过我分享阿里微服务发展历程给大家做微服务架构演进提供一些思路和启发。</p><h3 id="云原生微服务趋势"><a href="#云原生微服务趋势" class="headerlink" title="云原生微服务趋势"></a>云原生微服务趋势</h3><p>随着云原生技术演进，容器以不可变基础设施为理念，解决运维标准和资源利用率问题；微服务以可变运行时为理念，解决研发效率问题，提升系统整体扩展性和高可用。经常有人问我，为什么有了容器的服务发现机制，还需要微服务的注册中心呢？从架构上首先是分层的，小的时候确实也看不到明显区别，大一些就会发现问题，如阿里中心最大微服务集群，底层是多个 Kubernetes 集群，防止一个 Kubernetes 出问题影响全局，底层 Kubernetes 也可以水平扩展，如果依赖了 Kubernetes 的服务发现机制，跨 Kubernetes 服务发现就成了第一个问题。当然底层是一个 Kubernetes 上面也可以是多个微服务环境，微服务可以按照业务域切分。两层可以做解耦，自由环境组合。还有就是阿里微服务体系积累了推空保护、服务治理完整体系，而 Kubernetes 的 CoreDNS 将服务发现强制拉到业务调用链路，每次调用都会做域名解析，因此 CoreDNS 挂的时候业务全部中断。</p><p>对于阿里整体正在从百万实例往千万实例的规模演进，这部分也是阿里微服务 4.0 的内容，这部分给大部分公司的借鉴意义有限，因此不做展开。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650466402749-bdc504d9-a794-418a-b894-e6fbab042065.png?x-oss-process=image/resize,w_937,limit_0"> </p><h2 id="微服务最佳实践"><a href="#微服务最佳实践" class="headerlink" title="微服务最佳实践"></a>微服务最佳实践</h2><p>阿里微服务体系经过 10 余年的发展，目前已经通过开源被广泛使用，通过阿里云支撑了成千上万家企业做数字化升级。借此机会把我们的最佳实践总结分享给大家，期望都对大家用好微服务有所帮助。</p><h3 id="阿里微服务体系简介"><a href="#阿里微服务体系简介" class="headerlink" title="阿里微服务体系简介"></a>阿里微服务体系简介</h3><p>通过 MSE + ACK 能够完成第一步云原生技术升级，释放云弹性红利，释放研发效率红利，可以通过可观测和高可用进一步用好微服务体系。</p><p> <img src="https://ucc.alicdn.com/pic/developer-ecology/fba1762c8d8741fb995606b1d9165143.gif" alt="image.gif" title="image.gif"><img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467432533-a4f4ad8f-3655-4d9c-8d73-4e1ebb10d8a9.png?x-oss-process=image/resize,w_1148,limit_0"> </p><h3 id="微服务最佳实践-1"><a href="#微服务最佳实践-1" class="headerlink" title="微服务最佳实践"></a>微服务最佳实践</h3><p>通过注册&amp;配置中心完成微服务拆分；通过网关统一入口，从入口处解决安全和高可用问题；最后通过服务治理提升用户微服务的问题。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467575338-9a9707a4-40a6-4bbf-9daa-368e995787ae.png?x-oss-process=image/resize,w_961,limit_0"> </p><h3 id="网关最佳实践"><a href="#网关最佳实践" class="headerlink" title="网关最佳实践"></a>网关最佳实践</h3><p>云原生网关作为下一代网关，提供高集成、高可用、高性能、安全的一站式网关解决方案。</p><ul><li>  <strong>统一接入</strong>：将流量网关、 微服务网关、 WAF 三合一大幅降低资源和运维成本，需要强调的是云原生网关集成 WAF 的方案有非常好的性能优势，WAF 做为控制面下发防护规则到云原生网关，流量直接在云原生网关清洗完毕直接路由到后端机器，RT 短，运维成本低。</li><li>  <strong>统一入口安全防线：</strong>自动更新证书防过期，支持 JWT/OAuth2/OIDC/IDaaS 认证机制，支持黑白名单机制。</li><li>  <strong>统一东西南北流量</strong>：统一解决跨域互通问题，包括跨网络域，跨业务域，跨地域，跨安全域等。</li><li>  <strong>统一服务发现机制：</strong>支持 Nacos/Kubernetes/DNS/ 固定 IP 多种服务发现方式。</li><li>  <strong>统一观测平台：</strong>从入口做好 tracing 埋点全链路诊断，丰富业务大盘和告警模板大幅降低网关运维成本。</li><li>  <strong>统一服务治理：</strong>从入口做限流、降级、熔断等高可用能力，提供全链路灰度方案控制变更风险。<strong>统一性能优化：</strong>采用硬件加速性能提升 80%，Ingress 场景比 Nginx 性能高 90%，参数调优+模块优化提升 40%。</li></ul><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467595709-6a151762-5c02-4d8b-90a6-8a289b90aeba.png?x-oss-process=image/resize,w_1151,limit_0"> </p><p>云原生网关支持 WASM 扩展网关自定义功能，并且通过插件市场提供丰富的插件能力。 <img src="https://ucc.alicdn.com/pic/developer-ecology/4c2169fee946427991df5e136e9d481a.gif" alt="image.gif" title="image.gif"> </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650468450175-eff9c375-9488-4000-820d-fed14a1c3e49.png?x-oss-process=image/resize,w_937,limit_0"> </p><h3 id="服务治理最佳实践"><a href="#服务治理最佳实践" class="headerlink" title="服务治理最佳实践"></a>服务治理最佳实践</h3><p>提供零业务侵入，开发，测试，运维全覆盖服务治理能力，提升系统高可用。如发布阶段即使注册中心是毫秒级推送也会有延迟，这个期间就会导致流量损失，因此我们提供了无损上下线能力解决这个痛点。本月我们将服务治理能力通过 OpenSergo 开源，欢迎各位小伙伴参与共建！  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467610712-ac9fe081-caa4-4fa7-aa61-cabf61532870.png?x-oss-process=image/resize,w_1161,limit_0"> </p><h3 id="日常环境隔离最佳实践"><a href="#日常环境隔离最佳实践" class="headerlink" title="日常环境隔离最佳实践"></a>日常环境隔离最佳实践</h3><p>共享一套环境联调开发相互影响，所有环境都独立联调机器成本太高，这个是一个矛盾，我们通过全链路打标能力将流量隔离，让大家可以在一套环境隔离多个逻辑联调环境，巧妙的解决这个问题。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467627252-58a7dbaa-86ef-45a1-81ff-8d3a43e43af2.png?x-oss-process=image/resize,w_1144,limit_0"> </p><h3 id="配置管理最佳实践"><a href="#配置管理最佳实践" class="headerlink" title="配置管理最佳实践"></a>配置管理最佳实践</h3><p>随着应用规模变大，到每个机器去修改配置运维成本太高，因此需要配置中心统一维护应用配置，将静态业务动态化，动态修改业务运行时行为，提升应用运行时灵活性。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467667752-93728a9e-18e2-41aa-8e60-b421c77fee36.png?x-oss-process=image/resize,w_1164,limit_0"> </p><h3 id="服务网格最佳实践"><a href="#服务网格最佳实践" class="headerlink" title="服务网格最佳实践"></a>服务网格最佳实践</h3><p>对于多语言开发有诉求和对服务网关感兴趣的小伙伴可以通过 MSE+ASM 快速构建服务网格解决方案，完成服务互通，快速体验新的技术。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467681962-8065a419-aa38-4cab-b693-af8e5734d2bd.png?x-oss-process=image/resize,w_1147,limit_0"> </p><h3 id="微服务高可用最佳实践"><a href="#微服务高可用最佳实践" class="headerlink" title="微服务高可用最佳实践"></a>微服务高可用最佳实践</h3><p>随着业务复杂度变高，业务峰值不可测，面对失败的设计和微服务高可用工具使用就非常重要，可以通过 Sentinel 完成限流、降级、熔断的保护，可以通过 PTS 完成压测，可以通过混沌工程完成破坏性测试，从体整体提升系统高可用。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467697257-018ce835-63b2-4909-a051-256c61514a0b.png?x-oss-process=image/resize,w_1150,limit_0"> </p><h3 id="注册中心平滑迁移实践"><a href="#注册中心平滑迁移实践" class="headerlink" title="注册中心平滑迁移实践"></a>注册中心平滑迁移实践</h3><p>目前大规模场景推荐双注册，如 1w 实例以上，这样发布周期长，稳定性更高一些。如果不到 1w 实例可以通过 Nacos-sync 同步完成注册中心平滑前一，这样通用型强一些。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467714583-9e9eae9a-32d5-4258-9424-a014718acbec.png?x-oss-process=image/resize,w_1186,limit_0"> </p><h3 id="网关平衡迁移实践"><a href="#网关平衡迁移实践" class="headerlink" title="网关平衡迁移实践"></a>网关平衡迁移实践</h3><p>由于前面云原生网关三合一和性能优势，大家可以通过入口 DNS 灰度切换到云原生网关。  </p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467728539-22275719-f7b8-43ab-af41-e47adc147c78.png?x-oss-process=image/resize,w_1144,limit_0"> </p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="微服务标杆客户"><a href="#微服务标杆客户" class="headerlink" title="微服务标杆客户"></a>微服务标杆客户</h2><p>用户上云中有两类典型客户，一类是传统的单体胖应用客户，一类是已经采用了微服务需要用好微服务的用户，我们通过两个标杆客户分享一下。</p><h3 id="斯凯奇微服务＋业务中台实践"><a href="#斯凯奇微服务＋业务中台实践" class="headerlink" title="斯凯奇微服务＋业务中台实践"></a>斯凯奇微服务＋业务中台实践</h3><p>斯凯奇 2021 年找到我们做数字化升级时间非常紧急，需要双十一前 3 个月左右要完成数字化升级，采用 MSE 微服务+中台解决方案，斯凯奇借助云原生网关完成了东西南北流量的统一控制，借助南北向云原生网关完成安全认证和入口限流，从入口做好流量防护；借助东西向网关完成了多个业务域的互通，新老系统的互通，1 个月左右完成了整个系统的搭建，1 个月左右完成了整个系统压测和高可用验证，并且最终大促业务非常成功，助力斯凯奇双十一 12 亿营收规模。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467744650-35f4135b-1fe3-49a0-801e-dcfd3c275490.png?x-oss-process=image/resize,w_1166,limit_0"> </p><h3 id="来电微服务全链路灰度最佳实践"><a href="#来电微服务全链路灰度最佳实践" class="headerlink" title="来电微服务全链路灰度最佳实践"></a>来电微服务全链路灰度最佳实践</h3><h4 id="来电的技术挑战"><a href="#来电的技术挑战" class="headerlink" title="来电的技术挑战"></a><strong>来电的技术挑战</strong></h4><p>来电科技的业务场景丰富且系统众多，在技术架构上已完成容器化以及微服务化改造，微服务框架使用的是 Spring Cloud 与 Dubbo。随着近年来的高速发展，充电宝设备节点以及业务量都在快速增加，系统的稳定性面临几点挑战:</p><p>1.在系统服务的发布过程中如何避免业务流量的损失；2.系统缺少简单有效的灰度能力，每次系统发布都存在一定的稳定性风险。MSE 微服务治理提供了开箱即用且无侵入的线上发布稳定性解决方案以及全链路灰度解决方案，帮助来电科技消除发布风险、提升线上稳定性。</p><h4 id="来电全链路灰度最佳实践"><a href="#来电全链路灰度最佳实践" class="headerlink" title="来电全链路灰度最佳实践"></a><strong>来电全链路灰度最佳实践</strong></h4><p>1.来电科技选用 MSE 微服务治理专业版来实现无侵入微服务治理能力，无缝支持市面上近 5 年所有的 Spring Cloud 和 Dubbo 的版本，不用改一行代码，不需要改变业务的现有架构就可以使用，没有绑定。</p><p>2.MSE 微服务治理专业版提供了全链路灰度解决方案帮助来电科技快速落地可灰度、可观测、可回滚的安全生产三板斧能力，满足业务高速发展情况下快速迭代和小心验证的诉求；</p><p>3.MSE 微服务治理的无损上下线能力，对系统服务的全流程进行防护，通过服务预热、无损下线、与 Kubernetes 微服务生命周期对齐、延迟发布等一系列能力，保证在服务冷启动或销毁过程中，业务连续无损。</p><p>4.MSE 微服务治理的离群实例摘除能力，可以做到让服务消费者自动检测其所调用提供者实例的可用性并进行实时的权重动态调整，以保证服务调用的成功率，从而提升业务稳定性和服务质量。</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650467760065-7aab61b1-4829-4de9-9f6b-8ab9ce978922.png?x-oss-process=image/resize,w_1160,limit_0"> </p><h2 id="阿里云微服务生态与规划"><a href="#阿里云微服务生态与规划" class="headerlink" title="阿里云微服务生态与规划"></a>阿里云微服务生态与规划</h2><p>阿里开源微服务会贴着服务治理帮助开发者用户微服务，云产品做好产品集成提升大家的使用体验。</p><p>ACK+MSE = 云原生架构升级解决方案</p><p>ASM+MSE = 服务网格解决方案</p><p>AHAS + MSE = 微服务高可用解决方案</p><p>ARMS + MSE = 微服务可观测解决方案</p><p>EDAS + MSE = APaaS解决方案</p><p>SAE + MSE = 微服务 Serverless 解决方案</p><p>WAF + 云盾 + IDaaS + MSE = 微服务安全解决方案</p><p> <img src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/9687/1650511793071-9ba68377-ae2e-4b3c-b9a0-fb0e2dd07360.png?x-oss-process=image/resize,w_977,limit_0"></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://developer.aliyun.com/article/891714?spm=5176.21213303.J_6704733920.7.22db53c9yXA1Zr&amp;amp;scm=20140722.S_community@@%E6%96</summary>
      
    
    
    
    <category term="微服务" scheme="http://zhangyu.info/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
    <category term="微服务" scheme="http://zhangyu.info/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>微服务之间的最佳调用方式</title>
    <link href="http://zhangyu.info/2022/05/28/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B9%8B%E9%97%B4%E7%9A%84%E6%9C%80%E4%BD%B3%E8%B0%83%E7%94%A8%E6%96%B9%E5%BC%8F/"/>
    <id>http://zhangyu.info/2022/05/28/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B9%8B%E9%97%B4%E7%9A%84%E6%9C%80%E4%BD%B3%E8%B0%83%E7%94%A8%E6%96%B9%E5%BC%8F/</id>
    <published>2022-05-27T16:00:00.000Z</published>
    <updated>2022-05-28T06:23:50.040Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/weixin_38748858/article/details/101062272">https://blog.csdn.net/weixin_38748858/article/details/101062272</a></p><p><a href="https://blog.csdn.net/weixin_38748858/article/details/101062272">微服务之间的最佳调用方式_倚天码农的博客-CSDN博客_微服务调用</a></p><blockquote><p>在微服务架构中，需要调用很多服务才能完成一项功能。服务之间如何互相调用就变成微服务架构中的一个关键问题。服务调用有两种方式，一种是RPC方式，另一种是事件驱动（Event-driven）方式，也就是发消息方式。消息方式是松耦合方式，比紧耦合的RPC方式要优越，但RPC方式如果用在适合的场景也有它的一席之地.</p><p><strong>耦合的种类：</strong><br>我们总在谈耦合，那么耦合到底意味着什么呢？</p><ol><li> 时间耦合：客户端和服务端必须同时上线才能工作。发消息时，接受消息队列必须运行，但后台处理程序暂时不工作也不影响。</li><li> 容量耦合：客户端和服务端的处理容量必须匹配。发消息时，如果后台处理能力不足也不要紧，消息队列会起到缓冲的作用。</li><li> 接口耦合：RPC调用有函数标签，而消息队列只是一个消息。例如买了商品之后要调用发货服务，如果是发消息，那么就只需发送一个商品被买消息。</li><li> 发送方式耦合：RPC是点对点方式，需要知道对方是谁，它的好处是能够传回返回值。消息既可以点对点，也可以用广播的方式，这样减少了耦合，但也使返回值比较困难。</li></ol><p>下面我们来逐一分析这些耦合的影响。 第一，时间耦合，对于多数应用来讲，你希望能马上得到回答，因此即使使用消息队列，后台也需要一直工作。第二，容量耦合，如果你对回复有时间要求，那么消息队列的缓冲功能作用不大，因为你希望及时响应。真正需要的是自动伸缩（Auto-scaling），它能自动调整服务端处理能力去匹配请求数量。第三和第四，接口耦合和发送方式耦合，这两个确实是RPC方式的软肋。</p><h3 id="事件驱动（Event-Driven）方式："><a href="#事件驱动（Event-Driven）方式：" class="headerlink" title="事件驱动（Event-Driven）方式："></a>事件驱动（Event-Driven）方式：</h3><p>Martin Fowler把事件驱动分成四种方式(<a href="https://martinfowler.com/articles/201701-event-driven.html">What do you mean by “Event-Driven”</a>)，简化之后本质上只有两种方式。 一种就是我们熟悉的的事件通知（Event Notification），另一种是事件溯源（Event Sourcing）。事件通知就是微服务之间不直接调用，而是通过发消息来进行合作。事件溯源有点像记账，它把所有的事件都记录下来，作为永久存储层，再在它的基础之上构建应用程序。实际上从应用的角度来讲，它们并不应该分属一类，它们的用途完全不同。事件通知是微服务的调用（或集成）方式，应该和RPC分在一起。事件溯源是一种存储数据的方式，应该和数据库分在一起。</p><h4 id="事件通知（Event-Notification）方式："><a href="#事件通知（Event-Notification）方式：" class="headerlink" title="事件通知（Event Notification）方式："></a>事件通知（Event Notification）方式：</h4><p>让我们用具体的例子来看一下。在下面的例子中，有三个微服务，“Order Service”， “Customer Service” 和“Product Service”.</p><p><img src="https://img-blog.csdnimg.cn/20190920153708185.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODc0ODg1OA==,size_16,color_FFFFFF,t_70" alt="file"></p><p><a href="https://www.infoq.com/presentations/aggregates-modular-microservices/">图片来源</a></p><p>先说读数据，假设要创建一个“Order”，在这个过程中需要读取“Customer”的数据和“Product”数据。如果用事件通知的方式就只能在“Order Service”本地也创建只读“Customer”和“Product”表，并把数据用消息的方式同步过来。</p><p>再说写数据，如果在创建一个“Order”时需要创建一个新的“Customer”或要修改“Customer”的信息，那么可以在界面上跳转到用户创建页面，然后在“Customer Service”创建用户之后再发”用户已创建“的消息，“Order Service”接到消息，更新本地“Customer”表。</p><p>这并不是一个很好的使用事件驱动的例子，因为事件驱动的优点就是不同的程序之间可以独立运行，没有绑定关系。但现在“Order Service”需要等待“Customer Service”创建完了之后才能继续运行，来完成整个创建“Order”的工作。主要是因为“Order”和“Customer”本身从逻辑上来讲就是紧耦合关系，没有“Customer”你是不能创建“Order”的。</p><p>在这种紧耦合的情况下，也可以使用RPC。你可以建立一个更高层级的管理程序来管理这些微服务之间的调用，这样“Order Service”就不必直接调用“Customer Service”了。当然它从本质上来讲并没有解除耦合，只是把耦合转移到了上一层，但至少现在“order Service”和“Customer Service”可以互不影响了。之所以不能根除这种紧耦合关系是因为它们在业务上是紧耦合的。</p><p>再举一个购物的例子。用户选好商品之后进行“Checkout”，生成“Order”，然后需要“payment”，再从“Inventory”取货，最后由“Shipment”发货，它们每一个都是微服务。这个例子用RPC方式和事件通知方式都可以完成。当用RPC方式时，由“Order”服务调用其他几个服务来完成整个功能。用事件通知方式时，“Checkout”服务完成之后发送“Order Placed”消息，“Payment”服务收到消息，接收用户付款，发送“Payment received”消息。“Inventory”服务收到消息，从仓库里取货，并发送“Goods fetched”消息。“Shipment”服务得到消息，发送货物，并发送“Goods shipped”消息。</p><p><img src="https://img-blog.csdnimg.cn/20190920153708514.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODc0ODg1OA==,size_16,color_FFFFFF,t_70" alt="file"></p><p><a href="https://blog.bernd-ruecker.com/the-microservice-workflow-automation-cheat-sheet-fc0a80dc25aa">图片来源</a></p><p>对这个例子来讲，使用事件驱动是一个不错的选择，因为每个服务发消息之后它不需要任何反馈，这个消息由下一个模块接收来完成下一步动作，时间上的要求也比上一个要宽松。用事件驱动的好处是降低了耦合度，坏处是你现在不能在程序里找到整个购物过程的步骤。如果一个业务逻辑有它自己相对固定的流程和步骤，那么使用RPC或业务流程管理（BPM）能够更方便地管理这些流程。在这种情况下选哪种方案呢？在我看来好处和坏处是大致相当的。从技术上来讲要选事件驱动，从业务上来讲要选RPC。不过现在越来越多的人采用事件通知作为微服务的集成方式，它似乎已经成了微服务之间的标椎调用方式。</p><h4 id="事件溯源-Event-Sourcing-："><a href="#事件溯源-Event-Sourcing-：" class="headerlink" title="事件溯源(Event Sourcing)："></a>事件溯源(Event Sourcing)：</h4><p>这是一种具有颠覆性质的的设计，它把系统中所有的数据都以事件（Event）的方式记录下来，它的持久存储叫Event Store， 一般是建立在数据库或消息队列（例如Kafka）基础之上，并提供了对事件进行操作的接口，例如事件的读写和查询。事件溯源是由领域驱动设计(<a href="https://dddcommunity.org/book/evans_2003/">Domain-Driven Design</a>)提出来的。DDD中有一个很重要的概念，有界上下文（<a href="https://martinfowler.com/bliki/BoundedContext.html">Bounded Context</a>），可以用有界上下文来划分微服务，每个有界上下文都可以是一个微服务。 下面是有界上下文的示例。下图中有两个服务“Sales”和“Support”。有界上下文的一个关键是如何处理共享成员， 在图中是“Customer”和“Product”。在不同的有界上下文中，共享成员的含义、用法以及他们的对象属性都会有些不同，DDD建议这些共享成员在各自的有界上下文中都分别建自己的类（包括数据库表），而不是共享。可以通过数据同步的手段来保持数据的一致性。下面还会详细讲解。</p><p><img src="https://img-blog.csdnimg.cn/201909201537097.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODc0ODg1OA==,size_16,color_FFFFFF,t_70" alt="file"><br><a href="https://martinfowler.com/bliki/BoundedContext.html">图片来源</a></p><p>事件溯源是微服务的一种存储方式，它是微服务的内部实现细节。因此你可以决定哪些微服务采用事件溯源方式，哪些不采用，而不必所有的服务都变成事件溯源的。 通常整个应用程序只有一个Event Store， 不同的微服务都通过向Event Store发送和接受消息而互相通信。Event Store内部可以分成不同的stream（相当于消息队列中的Topic）， 供不同的微服务中的领域实体（Domain Entity）使用。</p><p>事件溯源的一个短板是数据查询，它有两种方式来解决。第一种是直接对stream进行查询，这只适合stream比较小并且查询比较简单的情况。查询复杂的话，就要采用第二种方式，那就是建立一个只读数据库，把需要的数据放在库中进行查询。数据库中的数据通过监听Event Store中相关的事件来更新。</p><p>数据库存储方式只能保存当前状态，而事件溯源则存储了所有的历史状态，因而能根据需要回放到历史上任何一点的状态，具有很大优势。但它也不是一点问题都没有。第一，它的程序比较复杂，因为事件是一等公民，你必须把业务逻辑按照事件的方式整理出来，然后用事件来驱动程序。第二，如果你要想修改事件或事件的格式就比较麻烦，因为旧的事件已经存储在Event Store里了（事件就像日志，是只读的），没有办法再改。</p><p>由于事件溯源和事件通知表面上看起来很像，不少人都搞不清楚它们的区别。事件通知只是微服务的集成方式，程序内部是不使用事件溯源的，内部实现仍然是传统的数据库方式。只有当要与其他微服务集成时才会发消息。而在事件溯源中，事件是一等公民，可以不要数据库，全部数据都是按照事件的方式存储的。</p><p>虽然事件溯源的践行者有不同的意见，但有不少人都认为事件溯源不是微服务的集成方式，而是微服务的一种内部实现方式。因此，在一个系统中，可以某些微服务用事件溯源，另外一些微服务用数据库。当你要集成这些微服务时，你可以用事件通知的方式。注意现在有两种不同的事件需要区分开，一种是微服务的内部事件，是颗粒度比较细的，这种事件只发送到这个微服务的stream中，只被事件溯源使用。另一种是其他微服务也关心的，是颗粒度比较粗的，这种事件会放到另外一个或几个stream中，被多个微服务使用，是用来做服务之间集成的。这样做的好处是限制了事件的作用范围，减少了不相关事件对程序的干扰。详见”<a href="https://www.innoq.com/en/blog/domain-events-versus-event-sourcing/">Domain Events vs. Event Sourcing</a>“.</p><p>事件溯源出现已经很长时间了，虽然热度一直在上升（尤其是这两年），但总的来说非常缓慢，谈论的人不少，但生产环境使用的不多。究其原因就是应为它对现在的体系结构颠覆太大，需要更改数据存储结构和程序的工作方式，还是有一定风险的。另外，微服务已经形成了一整套体系，从程序部署，服务发现与注册，到监控，服务韧性（Service Resilience），它们基本上都是针对RPC的，虽然也支持消息，但成熟度就差多了，因此有不少工作还是要自己来做。有意思的是Kafka一直在推动它作为事件驱动的工具，也取得了很大的成功。但它却没有得到事件溯源圈内的认可（详见<a href="https://stackoverflow.com/a/49868866">这里</a>）。<br>多数事件溯源都使用一个叫<a href="https://eventstore.org/">evenstore</a>的开源Event Store，或是基于某个数据库的Event Store，只有比较少的人用Kafka做Event Store。 但如果用Kafka实现事件通知就一点问题都没有。总的来说，对大多数公司来讲事件溯源是有一定挑战的，应用时需要找到合适的场景。如果你要尝试的话，可以先拿一个微服务试水。</p><p>虽然现在事件驱动还有些生涩，但从长远来讲，还是很看好它的。像其他全新的技术一样，事件溯源需要大规模的适用场景来推动。例如容器技术就是因为微服务的流行和推动，才走向主流。事件溯源以前的适用场景只限于记账和源代码库，局限性较大。区块链可能会成为它的下一个机遇，因为它用的也是事件溯源技术。另外AI今后会渗入到具体程序中，使程序具有学习功能。而RPC模式注定没有自适应功能。事件驱动本身就具有对事件进行反应的能力，这是自我学习的基础。因此，这项技术长远来讲定会大放异彩，但短期内（3-5年）大概不会成为主流。</p><h3 id="RPC方式："><a href="#RPC方式：" class="headerlink" title="RPC方式："></a>RPC方式：</h3><p>RPC的方式就是远程函数调用，像RESTFul，gRPC, DUBBO 都是这种方式。它一般是同步的，可以马上得到结果。在实际中，大多数应用都要求立刻得到结果，这时同步方式更有优势，代码也更简单。</p><h4 id="服务网关（API-Gateway）"><a href="#服务网关（API-Gateway）" class="headerlink" title="服务网关（API Gateway）:"></a>服务网关（API Gateway）:</h4><p>熟悉微服务的人可能都知道服务网关（API Gateway）。当UI需要调用很多微服务时，它需要了解每个服务的接口，这个工作量很大。于是就用服务网关创建了一个Facade，把几个微服务封装起来，这样UI就只调用服务网关就可以了，不需要去对付每一个微服务。下面是API Gateway示例图：</p><p><img src="https://img-blog.csdnimg.cn/20190920153709420.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODc0ODg1OA==,size_16,color_FFFFFF,t_70" alt="file"></p><p><a href="https://microservices.io/patterns/apigateway.html">图片来源</a></p><p>服务网关（API Gateway）不是为了解决微服务之间调用的紧耦合问题，它主要是为了简化客户端的工作。其实它还可以用来降低函数之间的耦合度。 有了API Gateway之后，一旦服务接口修改，你可能只需要修改API Gateway， 而不必修改每个调用这个函数的客户端，这样就减少了程序的耦合性。</p><h4 id="服务调用："><a href="#服务调用：" class="headerlink" title="服务调用："></a>服务调用：</h4><p>可以借鉴API Gateway的思路来减少RPC调用的耦合度，例如把多个微服务组织起来形成一个完整功能的服务组合，并对外提供统一的服务接口。这种想法跟上面的API Gateway有些相似，都是把服务集中起来提供粗颗粒（Coarse Granular）服务，而不是细颗粒的服务（Fine Granular）。但这样建立的服务组合可能只适合一个程序使用，没有多少共享价值。因此如果有合适的场景就采用，否侧也不必强求。虽然我们不能降低RPC服务之间的耦合度，却可以减少这种紧耦合带来的影响。</p><h3 id="降低紧耦合的影响："><a href="#降低紧耦合的影响：" class="headerlink" title="降低紧耦合的影响："></a>降低紧耦合的影响：</h3><p>什么是紧耦合的主要问题呢？就是客户端和服务端的升级不同步。服务端总是先升级，客户端可能有很多，如果要求它们同时升级是不现实的。它们有各自的部署时间表，一般都会选择在下一次部署时顺带升级。</p><p>一般有两个办法可以解决这个问题：</p><ol><li> 同时支持多个版本：这个工作量比较大，因此大多数公司都不会采用这种方式。</li><li> 服务端向后兼容：这是更通用的方式。例如你要加一个新功能或有些客户要求给原来的函数增加一个新的参数，但别的客户不需要这个参数。这时你只好新建一个函数，跟原来的功能差不多，只是多了一个参数。这样新旧客户的需求都能满足。它的好处是向后兼容（当然这取决于你使用的协议）。它的坏处是当以后新的客户来了，看到两个差不多的函数就糊涂了，不知道该用那个。而且时间越长越严重，你的服务端可能功能增加的不多，但相似的函数却越来越多，无法选择。</li></ol><p>它的解决办法就是使用一个支持向后兼容的RPC协议，现在最好的就是Protobuf gRPC，尤其是在向后兼容上。它给每个服务定义了一个接口，这个接口是与编程语言无关的中性接口，然后你可以用工具生成各个语言的实现代码，供不同语言使用。函数定义的变量都有编号，变量可以是可选类型的，这样就比较好地解决了函数兼容的问题。就用上面的例子，当你要增加一个可选参数时，你就定义一个新的可选变量。由于它是可选的，原来的客户端不需要提供这个参数，因此不需要修改程序。而新的客户端可以提供这个参数。你只要在服务端能同时处理这两种情况就行了。这样服务端并没有增加新的函数，但用户的新需求满足了，而且还是向后兼容的。</p><h3 id="微服务的数量有没有上限？"><a href="#微服务的数量有没有上限？" class="headerlink" title="微服务的数量有没有上限？"></a>微服务的数量有没有上限？</h3><p>总的来说微服务的数量不要太多，不然会有比较重的运维负担。有一点需要明确的是微服务的流行不是因为技术上的创新，而是为了满足管理上的需要。单体程序大了之后，各个模块的部署时间要求不同，对服务器的优化要求也不同，而且团队人数众多，很难协调管理。把程序拆分成微服务之后，每个团队负责几个服务，就容易管理了，而且每个团队也可以按照自己的节奏进行创新，但它给运维带来了巨大的麻烦。所以在微服务刚出来时，我一直觉得它是一个退步，弊大于利。但由于管理上的问题没有其他解决方案，只有硬着头皮上了。值得庆幸的是微服务带来的麻烦都是可解的。直到后来，微服务建立了全套的自动化体系，从程序集成到部署，从全链路跟踪到日志，以及服务检测，服务发现和注册，这样才把微服务的工作量降了下来。虽然微服务在技术上一无是处，但它的流行还是大大推动了容器技术，服务网格（Service Mesh）和全链路跟踪等新技术的发展。不过它本身在技术上还是没有发现任何优势。。直到有一天，我意识到单体程序其实性能调试是很困难的（很难分离出瓶颈点），而微服务配置了全链路跟踪之后，能很快找到症结所在。看来微服务从技术来讲也不全是缺点，总算也有好的地方。但微服务的颗粒度不宜过细，否则工作量还是太大。</p><p>一般规模的公司十几个或几十个微服务都是可以承受的，但如果有几百个甚至上千个，那么绝不是一般公司可以管理的。尽管现有的工具已经很齐全了，而且与微服务有关的整个流程也已经基本上全部自动化了，但它还是会增加很多工作。Martin Fowler几年以前建议先从单体程序开始（详见 <a href="https://martinfowler.com/bliki/MonolithFirst.html">MonolithFirst</a>），然后再逐步把功能拆分出去，变成一个个的微服务。但是后来有人反对这个建议，他也有些松口了。如果单体程序不是太大，这是个好主意。可以用数据额库表的数量来衡量程序的大小，我见过大的单体程序有几百张表，这就太多了，很难管理。正常情况下，一个微服务可以有两、三张表到五、六张表，一般不超过十张表。但如果要减少微服务数量的话，可以把这个标准放宽到不要超过二十张表。用这个做为大致的指标来创建微程序，如果使用一段时间之后还是觉得太大了，那么再逐渐拆分。当然，按照这个标准建立的服务更像是服务组合，而不是单个的微服务。不过它会为你减少工作量。只要不影响业务部门的创新进度，这是一个不错的方案。</p><p>到底应不应该选择微服务呢？如果单体程序已经没法管理了，那么你别无选择。如果没有管理上的问题，那么微服务带给你的只有问题和麻烦。其实，一般公司都没有太多选择，只能采用微服务，不过你可以选择建立比较少的微服务。如果还是没法决定，有一个折中的方案，“内部微服务设计”。</p><h4 id="内部微服务设计："><a href="#内部微服务设计：" class="headerlink" title="内部微服务设计："></a>内部微服务设计：</h4><p>这种设计表面上看起来是一个单体程序，它只有一个源代码存储仓库，一个数据库，一个部署，但在程序内部可以按照微服务的思想来进行设计。它可以分成多个模块，每个模块是一个微服务，可以由不同的团队管理。</p><p><img src="https://img-blog.csdnimg.cn/20190920153709762.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODc0ODg1OA==,size_16,color_FFFFFF,t_70" alt="file"></p><p><a href="https://docs.microsoft.com/en-us/dotnet/architecture/microservices/architect-microservice-container-applications/identify-microservice-domain-model-boundaries">图片来源</a></p><p>用这张图做例子。这个图里的每个圆角方块大致是一个微服务，但我们可以把它作为一个单体程序来设计，内部有五个微服务。每个模块都有自己的数据库表，它们都在一个数据库中，但模块之间不能跨数据库访问（不要建立模块之间数据库表的外键）。“User”（在Conference Management模块中）是一个共享的类，但在不同的模块中的名字不同，含义和用法也不同，成员也不一样（例如，在“Customer Service”里叫“Customer”）。DDD（Domain-Driven Design）建议不要共享这个类，而是在每一个有界上下文（模块）中都建一个新类，并拥有新的名字。虽然它们的数据库中的数据应该大致相同，但DDD建议每一个有界上下文中都建一个新表，它们之间再进行数据同步。</p><p>这个所谓的“内部微服务设计”其实就是DDD，但当时还没有微服务，因此外表看起来是单体程序，但内部已经是微服务的设计了。它的书在2003就出版了，当时就很有名。但它更偏重于业务逻辑的设计，践行起来也比较困难，因此大家谈论得很多，真正用的较少。直到十年之后，微服务出来之后，人们发现它其实内部就是微服务，而且微服务的设计需要用它的思想来指导，于是就又重新焕发了青春，而且这次更猛，已经到了每个谈论微服务的人都不得不谈论DDD的地步。不过一本软件书籍，在十年之后还能指导新技术的设计，非常令人钦佩。</p><p>这样设计的好处是它是一个单体程序，省去了多个微服务带来的部署、运维的麻烦。但它内部是按微服务设计的，如果以后要拆分成微服务会比较容易。至于什么时候拆分不是一个技术问题。如果负责这个单体程序的各个团队之间不能在部署时间表，服务器优化等方面达成一致，那么就需要拆分了。当然你也要应对随之而来的各种运维麻烦。内部微服务设计是一个折中的方案，如果你想试水微服务，但又不愿意冒太大风险时，这是一个不错的选择。<br>微服务的数据库设计也有很多内容，包括如何把服务从单体程序一步步里拆分出来请参见<a href="https://blog.csdn.net/weixin_38748858/article/details/102634941">“微服务的数据库设计”</a>.</p><h4 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h4><p>微服务之间的调用有两种方式，RPC和事件驱动。事件驱动是更好的方式，因为它是松耦合的。但如果业务逻辑是紧耦合的，RPC方式也是可行的（它的好处是代码更简单），而且你还可以通过选取合适的协议（Protobuf gRPC）来降低这种紧耦合带来的危害。由于事件溯源和事件通知的相似性，很多人把两者弄混了，但它们实际上是完全不同的东西。微服务的数量不宜太多，可以先创建比较大的微服务（更像是服务组合）。如果你还是不能确定是否采用微服务架构，可以先从“内部微服务设计”开始，再逐渐拆分。</p><h4 id="索引："><a href="#索引：" class="headerlink" title="索引："></a>索引：</h4><p>[1] <a href="https://martinfowler.com/articles/201701-event-driven.html">What do you mean by “Event-Driven”</a></p><p>[2] <a href="https://dddcommunity.org/book/evans_2003/">Domain-Driven Design</a></p><p>[3] <a href="https://martinfowler.com/bliki/BoundedContext.html">BoundedContext</a></p><p>[4] <a href="https://www.innoq.com/en/blog/domain-events-versus-event-sourcing/">Domain Events vs. Event Sourcing</a></p><p>[5] <a href="https://stackoverflow.com/a/49868866">Using Kafka as a (CQRS) Eventstore. Good idea</a></p><p>[6] <a href="https://eventstore.org/">Evenstore</a></p><p>[7] <a href="https://martinfowler.com/bliki/MonolithFirst.html">MonolithFirst</a></p><p>[8] <a href="https://blog.csdn.net/weixin_38748858/article/details/102634941">微服务的数据库设计</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/weixin_38748858/article/details/101062272&quot;&gt;https://blog.csdn.net/weixin_38748858/article/details/101062272</summary>
      
    
    
    
    <category term="微服务" scheme="http://zhangyu.info/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
    <category term="微服务" scheme="http://zhangyu.info/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>解决gateway使用nacos重启报503ServiceUnavailable问题</title>
    <link href="http://zhangyu.info/2022/05/01/%E8%A7%A3%E5%86%B3gateway%E4%BD%BF%E7%94%A8nacos%E9%87%8D%E5%90%AF%E6%8A%A5503ServiceUnavailable%E9%97%AE%E9%A2%98/"/>
    <id>http://zhangyu.info/2022/05/01/%E8%A7%A3%E5%86%B3gateway%E4%BD%BF%E7%94%A8nacos%E9%87%8D%E5%90%AF%E6%8A%A5503ServiceUnavailable%E9%97%AE%E9%A2%98/</id>
    <published>2022-04-30T16:00:00.000Z</published>
    <updated>2022-05-01T06:10:29.038Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.jianshu.com/p/70f4c2ce6ac8">https://www.jianshu.com/p/70f4c2ce6ac8</a></p><blockquote><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>项目使用spring cloud gateway作为网关，nacos作为微服务注册中心，项目搭建好后正常访问都没问题，但是有个很烦人的小瑕疵：</p><ul><li>  当某个微服务重启后，通过网关调用这个服务时有时会出现<code>503 Service Unavailable(服务不可用)</code>的错误，但过了一会儿又可以访问了，这个等待时间有时很长有时很短，甚至有时候还不会出现</li><li>  导致每次重启某个项目都要顺便启动gateway项目才能保证立即可以访问，时间长了感觉好累，想彻底研究下为什么，并彻底解决</li></ul><p><em>接下来介绍我在解决整个过程的思路，如果没兴趣，可以直接跳到最后的最终解决方案</em></p><h2 id="gateway感知其它服务上下线"><a href="#gateway感知其它服务上下线" class="headerlink" title="gateway感知其它服务上下线"></a>gateway感知其它服务上下线</h2><p>首先在某个微服务上下线时，gateway的控制台可以立即看到有对应的输出</p><p><img src="https://upload-images.jianshu.io/upload_images/9112801-0168be1734dd7bf4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/793"></p><p>某服务下线gateway输出</p><p><img src="https://upload-images.jianshu.io/upload_images/9112801-6a09eaf1f1b91bee.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/761"></p><p>某服务上线gateway输出</p><p>这说明nacos提供了这种监听功能，在注册中心服务列表发生时可以第一时间通知客户端，而在我们的依赖<code>spring-cloud-starter-alibaba-nacos-discovery</code>中显然已经帮我们实现了这个监听</p><p>所以也就说明gateway是可以立即感知其它服务的上下线事件，但问题是明明感知到某个服务的上线，那为什么会出现<code>503 Service Unavailable</code>的错误，而且上面的输出有时出现了很久，但调用依然是<code>503 Service Unavailable</code>，对应的某服务明明下线，这是应该是<code>503 Service Unavailable</code>状态，可有时确会有一定时间的<code>500</code>错误</p><h2 id="ribbon"><a href="#ribbon" class="headerlink" title="ribbon"></a>ribbon</h2><p>为了调查事情的真相，我打开了gateway的debug日志模式，找到了503的罪魁祸首  </p><p><img src="https://upload-images.jianshu.io/upload_images/9112801-e761406118f10444.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1079"></p><p>503的控制台输出</p><p>在503错误输出前，有一行这样的日志<code>Zone aware logic disabled or there is only one zone</code>，而报这个信息的包就是ribbon-loadbalancer，也就是gateway默认所使用的负载均衡器</p><p>我的gateway配置文件路由方面设置如下</p><pre><code>routes:        - id: auth          uri: lb://demo-auth          predicates:            - Path=/auth/**          filters:            - StripPrefix=1</code></pre><p>其中在uri这一行，使用了lb:// ,代表使用了gateway的ribbon负载均衡功能，官方文档说明如下<br><strong>Note that this example also demonstrates (optional) Spring Cloud Netflix Ribbon load-balancing (defined the lb prefix on the destination URI)</strong></p><p>ribbon再调用时首先会获取所有服务列表(ip和端口信息)，然后根据负载均衡策略调用其中一个服务，选择服务的代码如下</p><pre><code>package com.netflix.loadbalancer;public class ZoneAwareLoadBalancer&lt;T extends Server&gt; extends DynamicServerListLoadBalancer&lt;T&gt; &#123;    // 选择服务的方法    public Server chooseServer(Object key) &#123;            if (!ENABLED.get() || getLoadBalancerStats().getAvailableZones().size() &lt;= 1) &#123;                logger.debug(&quot;Zone aware logic disabled or there is only one zone&quot;);                return super.chooseServer(key);            &#125;    ...     </code></pre><p>这就是上面的<code>Zone aware logic..</code>这行日志的出处，经调试发现在<code>getLoadBalancerStats().getAvailableZones()</code>这一步返回的服务是空列表，说明这里没有存储任何服务信息，所以才导致最终的<code>503 Service Unavailable</code><br>继续跟进去看<code>getAvailableZones</code>的代码，如下</p><pre><code>public class LoadBalancerStats implements IClientConfigAware &#123;    // 一个缓存所有服务的map    volatile Map&lt;String, List&lt;? extends Server&gt;&gt; upServerListZoneMap = new ConcurrentHashMap&lt;String, List&lt;? extends Server&gt;&gt;();    // 获取可用服务keys    public Set&lt;String&gt; getAvailableZones() &#123;        return upServerListZoneMap.keySet();    &#125;</code></pre><p>可以看到ribbon是在LoadBalancerStats中维护了一个map来缓存所有可用服务，而问题的原因也大概明了了：<strong>gateway获取到了服务变更事件，但并没有及时更新ribbon的服务列表缓存</strong></p><h2 id="ribbon的刷新缓存机制"><a href="#ribbon的刷新缓存机制" class="headerlink" title="ribbon的刷新缓存机制"></a>ribbon的刷新缓存机制</h2><p>现在的实际情况是：gateway获取到了服务变更事件，但并没有马上更新ribbon的服务列表缓存，但过一段时间可以访问说明缓存又刷新了，那么接下来就要找到ribbon的缓存怎么刷新的，进而进一步分析为什么没有及时刷新</p><p>在LoadBalancerStats查找到更新缓存的方法是<code>updateZoneServerMapping</code></p><pre><code>public class LoadBalancerStats implements IClientConfigAware &#123;    // 一个缓存所有服务的map    volatile Map&lt;String, List&lt;? extends Server&gt;&gt; upServerListZoneMap = new ConcurrentHashMap&lt;String, List&lt;? extends Server&gt;&gt;();    // 更新缓存    public void updateZoneServerMapping(Map&lt;String, List&lt;Server&gt;&gt; map) &#123;        upServerListZoneMap = new ConcurrentHashMap&lt;String, List&lt;? extends Server&gt;&gt;(map);        // make sure ZoneStats object exist for available zones for monitoring purpose        for (String zone: map.keySet()) &#123;            getZoneStats(zone);        &#125;    &#125;</code></pre><p>那么接下来看看这个方法的调用链，调用链有点长，最终找到了<code>DynamicServerListLoadBalancer</code>下的<code>updateListOfServers</code>方法，首先看<code>DynamicServerListLoadBalancer</code>翻译过来”动态服务列表负载均衡器”，说明它有动态获取服务列表的功能，那我们的bug它肯定难辞其咎，而<code>updateListOfServers</code>就是它刷新缓存的手段，那么就看看这个所谓的”动态服务列表负载均衡器”是如何使用<code>updateListOfServers</code>动态刷新缓存的</p><pre><code>public class DynamicServerListLoadBalancer&lt;T extends Server&gt; extends BaseLoadBalancer &#123;    // 封装成一个回调    protected final ServerListUpdater.UpdateAction updateAction = new ServerListUpdater.UpdateAction() &#123;        @Override        public void doUpdate() &#123;            updateListOfServers();        &#125;    &#125;;    // 初始化    public DynamicServerListLoadBalancer(IClientConfig clientConfig, IRule rule, IPing ping,                                         ServerList&lt;T&gt; serverList, ServerListFilter&lt;T&gt; filter,                                         ServerListUpdater serverListUpdater) &#123;        ...        this.serverListUpdater = serverListUpdater; // serverListUpdate赋值        ...        // 初始化时刷新服务        restOfInit(clientConfig);    &#125;    void restOfInit(IClientConfig clientConfig) &#123;        ...        // 开启动态刷新缓存        enableAndInitLearnNewServersFeature();        // 首先刷新一遍缓存        updateListOfServers();        ...    &#125;    // 开启动态刷新缓存    public void enableAndInitLearnNewServersFeature() &#123;        // 把更新的方法传递给serverListUpdater        serverListUpdater.start(updateAction);    &#125;</code></pre><p>可以看到初始化DynamicServerListLoadBalancer时，首先updateListOfServers获取了一次服务列表并缓存，这只能保证项目启动获取一次服务列表，而真正的动态更新实现是把updateListOfServers方法传递给内部<code>serverListUpdater.start</code>方法，serverListUpdater翻译过来就是“服务列表更新器”，所以再理一下思路：</p><p>DynamicServerListLoadBalancer只所以敢自称“动态服务列表负载均衡器”，是因为它内部有个serverListUpdater(“服务列表更新器”)，也就是<code>serverListUpdater.start</code>才是真正为ribbon提供动态更新服务列表的方法，也就是罪魁祸首</p><p>那么就看看<code>ServerListUpdater</code>到底是怎么实现的动态更新，首先<code>ServerListUpdater</code>是一个接口，它的实现也只有一个PollingServerListUpdater，那么肯定是它了，看一下它的<code>start</code>方法实现</p><pre><code>public class PollingServerListUpdater implements ServerListUpdater &#123;    @Override    public synchronized void start(final UpdateAction updateAction) &#123;        if (isActive.compareAndSet(false, true)) &#123;            // 定义一个runable，运行doUpdate放            final Runnable wrapperRunnable = new Runnable() &#123;                @Override                public void run() &#123;                    ....                    try &#123;                        updateAction.doUpdate(); // 执行更新服务列表方法                        lastUpdated = System.currentTimeMillis();                    &#125; catch (Exception e) &#123;                        logger.warn(&quot;Failed one update cycle&quot;, e);                    &#125;                &#125;            &#125;;            // 定时执行            scheduledFuture = getRefreshExecutor().scheduleWithFixedDelay(                    wrapperRunnable,                    initialDelayMs,                    refreshIntervalMs, // 默认30 * 1000                    TimeUnit.MILLISECONDS            );        &#125; else &#123;            logger.info(&quot;Already active, no-op&quot;);        &#125;    &#125;</code></pre><p>至此真相大白了，原来ribbon默认更新服务列表依靠的是<strong>定时任务</strong>，而且默认30秒一次，<strong>也就是说假如某个服务重启了，gateway的nacos客户端也感知到了，但是ribbon内部极端情况需要30秒才会重新获取服务列表</strong>，这也就解释了为什么会有那么长时间的<code>503 Service Unavailable</code>问题</p><p>而且因为定时任务，所以等待时间是0-30秒不等，有可能你刚重启完就获取了正常调用没问题，也有可能刚重启完时刚获取完一次，结果就得等30秒才能访问到新的节点</p><h2 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h2><p>问题的原因找到了，接下来就是解决了，最简单暴力的方式莫过于修改定时任务的间隔时间，默认30秒，可以改成10秒，5秒，1秒，只要你机器配置够牛逼</p><p>但是有没有更优雅的解决方案，我们的gateway明明已经感知到服务的变化，如果通知ribbon直接更新，问题不就完美解决了吗，这种思路定时任务都可以去掉了，性能还优化了</p><p>具体解决步骤如下</p><ul><li>  写一个新的更新器，替换掉默认的PollingServerListUpdater更新器</li><li>  更新器可以监听nacos的服务更新</li><li>  收到服务更新事件时，调用doUpdate方法更新ribbon缓存</li></ul><p>接下来一步步解决</p><p>首先看上面DynamicServerListLoadBalancer的代码，发现更新器是构造方法传入的，所以要找到构造方法的调用并替换成自己信息的更新器</p><p>在DynamicServerListLoadBalancer构造方法上打了个断点，看看它是如何被初始化的(<strong>并不是gateway启动就会初始化，而是首次调用某个服务，给对应的服务创建一个LoadBalancer，有点懒加载的意思</strong>)  </p><p><img src="https://upload-images.jianshu.io/upload_images/9112801-31bc7100ad4ad37f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1061"></p><p>构造方法断点</p><p><img src="https://upload-images.jianshu.io/upload_images/9112801-44f34f0c171f43c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200"></p><p>debugger</p><p>看一下debugger的函数调用，发现一个<code>doCreateBean&gt;&gt;&gt;createBeanInstance</code>的调用，其中createBeanInstance执行到如下地方  </p><p><img src="https://upload-images.jianshu.io/upload_images/9112801-7f8a73918993940e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/873"></p><p>createBeanInstance</p><p>熟悉spring源码的朋友应该看得出来DynamicServerListLoadBalancer是spring容器负责创建的，而且是FactoryBean模式。</p><p>这个bean的定义在spring-cloud-netflix-ribbon依赖中的RibbonClientConfiguration类</p><pre><code>package org.springframework.cloud.netflix.ribbon;@Configuration(proxyBeanMethods = false)@EnableConfigurationProperties@Import(&#123; HttpClientConfiguration.class, OkHttpRibbonConfiguration.class,        RestClientRibbonConfiguration.class, HttpClientRibbonConfiguration.class &#125;)public class RibbonClientConfiguration &#123;    ...    @Bean    @ConditionalOnMissingBean    public ServerListUpdater ribbonServerListUpdater(IClientConfig config) &#123;        return new PollingServerListUpdater(config);    &#125;    ...&#125;</code></pre><p>也就是通过我们熟知的@Configuration+@Bean模式创建的PollingServerListUpdater更新器，而且加了个注解<code>@ConditionalOnMissingBean</code></p><p>也就是说我们自己实现一个ServerListUpdater更新器，并加入spring容器，就可以代替PollingServerListUpdater成为ribbon的更新器</p><h2 id="最终解决方案"><a href="#最终解决方案" class="headerlink" title="最终解决方案"></a>最终解决方案</h2><p>我们的更新器是要订阅nacos的，收到事件做update处理，为了避免ribbon和nacos耦合抽象一个监听器再用nacos实现</p><h5 id="1-抽象监听器"><a href="#1-抽象监听器" class="headerlink" title="1.抽象监听器"></a>1.抽象监听器</h5><pre><code>/** * @Author pq * @Date 2022/4/26 17:19 * @Description 抽象监听器 */public interface ServerListListener &#123;    /**     * 监听     * @param serviceId 服务名     * @param eventHandler 回调     */    void listen(String serviceId, ServerEventHandler eventHandler);    @FunctionalInterface    interface ServerEventHandler &#123;        void update();    &#125;&#125;</code></pre><h5 id="自定义ServerListUpdater"><a href="#自定义ServerListUpdater" class="headerlink" title="自定义ServerListUpdater"></a>自定义ServerListUpdater</h5><pre><code>public class NotificationServerListUpdater implements ServerListUpdater &#123;    private static final Logger logger = LoggerFactory.getLogger(NotificationServerListUpdater.class);    private final ServerListListener listener;    public NotificationServerListUpdater(ServerListListener listener) &#123;        this.listener = listener;    &#125;    /**     * 开始运行     * @param updateAction     */    @Override    public void start(UpdateAction updateAction) &#123;        // 创建监听        String clientName = getClientName(updateAction);        listener.listen(clientName, ()-&gt; &#123;            logger.info(&quot;&#123;&#125; 服务变化, 主动刷新服务列表缓存&quot;, clientName);            // 回调直接更新            updateAction.doUpdate();        &#125;);    &#125;    /**     * 通过updateAction获取服务名，这种方法比较粗暴     * @param updateAction     * @return     */    private String getClientName(UpdateAction updateAction) &#123;        try &#123;            Class&lt;?&gt; bc = updateAction.getClass();            Field field = bc.getDeclaredField(&quot;this$0&quot;);            field.setAccessible(true);            BaseLoadBalancer baseLoadBalancer = (BaseLoadBalancer) field.get(updateAction);            return baseLoadBalancer.getClientConfig().getClientName();        &#125; catch (Exception e) &#123;            e.printStackTrace();            throw new IllegalStateException(e);        &#125;    &#125;</code></pre><h5 id="实现ServerListListener监控nacos并注入bean容器"><a href="#实现ServerListListener监控nacos并注入bean容器" class="headerlink" title="实现ServerListListener监控nacos并注入bean容器"></a>实现ServerListListener监控nacos并注入bean容器</h5><pre><code>@Slf4j@Componentpublic class NacosServerListListener implements ServerListListener &#123;    @Autowired    private NacosServiceManager nacosServiceManager;    private NamingService namingService;    @Autowired    private NacosDiscoveryProperties properties;    @PostConstruct    public void init() &#123;        namingService =  nacosServiceManager.getNamingService(properties.getNacosProperties());    &#125;    /**     * 创建监听器     */    @Override    public void listen(String serviceId, ServerEventHandler eventHandler) &#123;        try &#123;            namingService.subscribe(serviceId, event -&gt; &#123;                if (event instanceof NamingEvent) &#123;                    NamingEvent namingEvent = (NamingEvent) event;//                    log.info(&quot;服务名：&quot; + namingEvent.getServiceName());//                    log.info(&quot;实例：&quot; + namingEvent.getInstances());                    // 实际更新                    eventHandler.update();                &#125;            &#125;);        &#125; catch (NacosException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;</code></pre><h5 id="把自定义Updater注入bean"><a href="#把自定义Updater注入bean" class="headerlink" title="把自定义Updater注入bean"></a>把自定义Updater注入bean</h5><pre><code>@Configuration@ConditionalOnRibbonNacospublic class RibbonConfig &#123;    @Bean    public ServerListUpdater ribbonServerListUpdater(NacosServerListListener listener) &#123;        return new NotificationServerListUpdater(listener);    &#125;&#125;</code></pre><p>到此，大工告成，效果是gateway访问的某微服务停止后，调用马上503，启动后，马上可以调用</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本来想解决这个问题首先想到的是nacos或ribbon肯定留了扩展，比如说改了配置就可以平滑感知服务下线，但结果看了文档和源码，并没有发现对应的扩展点，所以只能大动干戈来解决问题，其实很多地方都觉得很粗暴，比如获取clientName，但也实在找不到更好的方案，如果谁知道，麻烦评论告诉我一下</p><p>实际上我的项目更新器还保留了定时任务刷新的逻辑，一来刚接触cloud对自己的修改自信不足，二来发现nacos的通知都是udp的通知方式，可能不可靠，不知道是否多余</p><p>nacos的监听主要使用namingService的subscribe方法，里面还有坑，还有一层缓存，以后细讲</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/70f4c2ce6ac8&quot;&gt;https://www.jianshu.com/p/70f4c2ce6ac8&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;h2 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述</summary>
      
    
    
    
    <category term="nacos" scheme="http://zhangyu.info/categories/nacos/"/>
    
    
    <category term="nacos" scheme="http://zhangyu.info/tags/nacos/"/>
    
  </entry>
  
  <entry>
    <title>从监控到可观测性，设计思想、技术选型、职责分工都有哪些变化</title>
    <link href="http://zhangyu.info/2022/05/01/%E4%BB%8E%E7%9B%91%E6%8E%A7%E5%88%B0%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7%EF%BC%8C%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%E3%80%81%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%E3%80%81%E8%81%8C%E8%B4%A3%E5%88%86%E5%B7%A5%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%E5%8F%98%E5%8C%96/"/>
    <id>http://zhangyu.info/2022/05/01/%E4%BB%8E%E7%9B%91%E6%8E%A7%E5%88%B0%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7%EF%BC%8C%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%E3%80%81%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%E3%80%81%E8%81%8C%E8%B4%A3%E5%88%86%E5%B7%A5%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%E5%8F%98%E5%8C%96/</id>
    <published>2022-04-30T16:00:00.000Z</published>
    <updated>2022-05-01T13:57:37.956Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.51cto.com/article/707455.html">https://www.51cto.com/article/707455.html</a></p><p><a href="https://www.51cto.com/article/707455.html">从监控到可观测性，设计思想、技术选型、职责分工都有哪些变化-51CTO.COM</a></p><blockquote><p>随着大量云原生技术的应用，IT系统日益复杂，主动感知、预测故障并迅速定位、排障的难度变得越来越大，传统监控方式已无法跟上需求，由此应运而生的可观测性，被视为未来云环境生产部署不可或缺的技术支撑。</p><p>目前大多数传统企业对可观测性仍处于初步了解阶段，不少互联网公司在可观测性建设上也是起步不久。因此，围绕“从监控到可观测性应如何转变与升级”这一话题，本期dbaplus话题接力专栏，特别采访到知乎全链路可观测系统和接入层网络负责人-熊豹、虎牙直播SRE平台研发团队负责人-匡凌轩、好大夫基础架构部高级工程师-方勇三位老师，希望能通过他们在可观测性领域的研究心得和实践经验，帮助广大技术从业者准确认识可观测性、给企业搭建适配自身发展的可观测体系提供建议和启发。</p><h3 id="Q1监控与可观测性是什么关系？有什么区别？可否从两者的关注点、应用场景、作用、局限性等方面进行解析？"><a href="#Q1监控与可观测性是什么关系？有什么区别？可否从两者的关注点、应用场景、作用、局限性等方面进行解析？" class="headerlink" title="Q1监控与可观测性是什么关系？有什么区别？可否从两者的关注点、应用场景、作用、局限性等方面进行解析？"></a>Q1监控与可观测性是什么关系？有什么区别？可否从两者的关注点、应用场景、作用、局限性等方面进行解析？</h3><h4 id="熊豹"><a href="#熊豹" class="headerlink" title="熊豹"></a>熊豹</h4><h4 id="“正在发生什么-与-为什么会这样”"><a href="#“正在发生什么-与-为什么会这样”" class="headerlink" title="“正在发生什么 与 为什么会这样”"></a>“正在发生什么 与 为什么会这样”</h4><p>监控是常见的运维手段，一般是指以观测系统的外部资源使用情况和接口表现来推测系统运行状态，即感知到“正在发生什么”。</p><p>可观测性是一种属性，是指在可以感知系统当前运行状态的性质，提升系统的可被观测的性质有助于我们了解“正在发生什么”以及“为什么会这样”。</p><p>云原生架构在业内逐步落地，给稳定性建设带来了更多新的挑战：迭代发布更迅速、业务系统更庞大、网络链路更复杂、运行环境更动态。在这样的混沌系统中仅仅只是知道问题发生是不够的，在这样纷繁复杂的环境下赤手空拳的我们很难去进行问题的追踪和溯源。我们要依托分层、多维度的观测数据来构建更立体和智能的诊断系统，以更多样的视角来观察和解读系统。</p><h4 id="匡凌轩"><a href="#匡凌轩" class="headerlink" title="匡凌轩"></a>匡凌轩</h4><h4 id="“可观测性更多是对业务应用系统自身的要求”"><a href="#“可观测性更多是对业务应用系统自身的要求”" class="headerlink" title="“可观测性更多是对业务应用系统自身的要求”"></a>“可观测性更多是对业务应用系统自身的要求”</h4><p>我认为监控是可观测性能力的一部分，初期监控主要是外部对业务应用系统的主动行为，运维是传统监控的使用主体，如：通过业务进程状态、系统资源等监控数据的分析和告警来发现问题。而现在可观测性更多是对业务应用系统自身的要求，如何设计去暴露出更多可被观测的应用运行时的数据，并为这些数据之间建立关联，如：微服务框架在请求处理和RPC调用时提供一些AOP扩展的设计，可以更方便地对请求进行Metric度量和Trace追踪，以及异常情况的上下文关联。</p><h4 id="方勇"><a href="#方勇" class="headerlink" title="方勇"></a>方勇</h4><h4 id="“从局部到全局可用性视角的延伸”"><a href="#“从局部到全局可用性视角的延伸”" class="headerlink" title="“从局部到全局可用性视角的延伸”"></a>“从局部到全局可用性视角的延伸”</h4><p>两者的关系：监控和可观测性都旨在辅助建设高可用的服务，缩短故障处理时长，两者往往是密切协作的，界限相对模糊。</p><p>两者的区别：监控往往关注告警触发的瞬时状态，一般围绕告警事件展开，涉及从告警事件的产生到应急响应等一系列动作。关注的视角一般是局部可用性，关注每个具体的监控项，如CPU负载、剩余内存等。监控是个老生常谈的话题，最常见的场景是系统资源监控、进程或服务状态的粗粒度监控。对定制化的业务指标监控不太友好，另外传统的监控体系对云原生的支持、对微服务体系监控的支持也不太友好。</p><p>可观测性可以看作是监控的一种延续，涉及面较广，包括全链路分析（APM）、业务服务质量（SLA）、业务容量等，聚焦服务的整体可用性。关注的视角一般是全局可用性，会忽略不影响服务质量的一些指标，如CPU负载高，服务整体时延波动不大就会忽略这个CPU负载指标。</p><p>可观测性的应用场景一般与业务能力相绑定，通过可视化聚合展示影响SLA的相关指标（SLI），再配合监控告警，通过可观测性看板下钻分析异常根因。另外可观测性打通Metrics/Traces/Logs后可主动识别出服务的潜在风险，能先于用户发现问题。</p><p>可观测性也有所局限，由于需要收集业务数据，对业务具有一定的侵入性，加上打造可视化平台投入成本较高。另外可观测性整体处于初期阶段，很多工具链还不太完善，价值预期其实是被高估了。</p><p>Q2从监控到可观测性都有哪些变化？对运维、开发、架构师等岗位人员分别提出了怎样的新要求？</p><h4 id="熊豹-1"><a href="#熊豹-1" class="headerlink" title="熊豹"></a>熊豹</h4><h4 id="“要把可观测性理念贯穿到架构和程序设计中”"><a href="#“要把可观测性理念贯穿到架构和程序设计中”" class="headerlink" title="“要把可观测性理念贯穿到架构和程序设计中”"></a>“要把可观测性理念贯穿到架构和程序设计中”</h4><p>目标不一样了，除了要知道“正在发生什么”，还要尝试解释“为什么会这样”。我们需要把可观测性的理念贯穿到架构和程序设计中，而不是到事发或事后再来补救。我们需要有意识地设计一些机制来观察业务指标的关联变化、系统架构的数据漏斗模型、程序内逻辑分支的运行开销、外部资源依赖的健康状态，还要暴露程序内的一些资源并发度、池的填充率和命中率、运行时的状态等情况，当运行错误时也要在错误信息中携带足量的上下文信息。</p><p>运维同学要为可观测场景提供更坚实的工具基础，在上述庞大的数据压力下，保障和解决数据存储和查询的性能、资源开销、集群的拓展性和稳定性等问题。</p><h4 id="匡凌轩-1"><a href="#匡凌轩-1" class="headerlink" title="匡凌轩"></a>匡凌轩</h4><h4 id="“从被动监控向主动发现与定位问题的转变”"><a href="#“从被动监控向主动发现与定位问题的转变”" class="headerlink" title="“从被动监控向主动发现与定位问题的转变”"></a>“从被动监控向主动发现与定位问题的转变”</h4><p>我认为最大的变化是应用系统自身角色的转变，从被动监控转向主动发现与定位问题，在设计应用系统架构之初就需要考虑到系统自身的可观测性建设。运维、开发、架构师都是各环节设计的参与者，在协作方式也有一定的改变：</p><ul><li>  运维：深入熟悉产品业务和应用服务，定义并关联业务指标、应用服务指标、系统资源指标等。</li><li>  开发：在框架层设计和实现对分布式应用服务运行时的Metric、Trace、Log数据采集。</li><li>  架构师：业务应用系统和可观测性系统的整体架构设计，需要关注无侵入式采集上报、多维度量聚合、错误寻根分析、整体海量数据处理和存储等。</li></ul><p>总体来说，需要各角色有更多跨技术领域的知识储备、业务思维和模型抽象能力。</p><h4 id="方勇-1"><a href="#方勇-1" class="headerlink" title="方勇"></a>方勇</h4><h4 id="“职责分工、认知意识、排障效率的转变和升级”"><a href="#“职责分工、认知意识、排障效率的转变和升级”" class="headerlink" title="“职责分工、认知意识、排障效率的转变和升级”"></a>“职责分工、认知意识、排障效率的转变和升级”</h4><p>个人认为主要变化有以下几个方面：</p><ul><li>  职责分工的转变，研发关注服务质量后，部分职责从运维侧开始迁移到研发侧。研发上线后不再当甩手掌柜，开始对自己的服务负责。</li><li>  认知意识的提高，从被动响应告警到主动提升服务质量。</li><li>  排障效率的提升，从原先的黑盒排障模式逐渐朝可视化发展。</li></ul><p>对不同岗位人员也有新的要求：</p><ul><li>  运维，需要摆脱传统监控的意识枷锁，拥抱云原生监控体系，同时和其他岗位人员达成共识，共建高可用服务。</li><li>  开发，接棒部分运维职责，聚焦服务可用性，需要有MDD（Metrics-Driven Developmen）的思想，建设具有高韧性的服务。</li><li>  架构师，在架构设计的过程中需要暴露可观测性的指标，同时需要提升数据分析的能力，建模分析Metrics/Traces/Logs数据，识别服务中潜在的风险。围绕可观测性打造相应的工具链及服务治理平台。</li></ul><h3 id="Q3可观测性的核心方法论-关键技术有哪些？"><a href="#Q3可观测性的核心方法论-关键技术有哪些？" class="headerlink" title="Q3可观测性的核心方法论/关键技术有哪些？"></a>Q3可观测性的核心方法论/关键技术有哪些？</h3><h4 id="熊豹-2"><a href="#熊豹-2" class="headerlink" title="熊豹"></a>熊豹</h4><h4 id="“数据的采集、存储、分析是核心关注点”"><a href="#“数据的采集、存储、分析是核心关注点”" class="headerlink" title="“数据的采集、存储、分析是核心关注点”"></a>“数据的采集、存储、分析是核心关注点”</h4><p>可观测性建设的核心关注点还是在数据的采集、存储、分析环节。</p><p>数据采集的覆盖可以以多种角度来看：可尝试梳理完整的数据链路，来覆盖从终端发起、网关、业务、基础设施中间的每一层组件；可以不同的观测视角进行覆盖，比如Metrics、Traces、Logs、Exception Collection、Profiler、Debuger、Changelog等类别的数据或能力都已建设齐备；可以多种维度来观察系统，比如业务维度、资源瓶颈、关联组件等维度进行覆盖的建设。</p><p>数据存储环节要关注多种类型数据的存储和查询系统选型。最为常见的是Metrics、Traces、Logs相关的存储系统，这三者都有非常广泛的基础软件选型。其中相对棘手的是指标维度爆炸、日志和Trace存储成本及性能相关的问题，一般需要搭配预聚合、前采样和后采样、存储分级等策略来解决。</p><p>数据分析环节要关联不同数据源的元信息，糅合以多维视角来构建查询界面。同时，我们也要关注如何在海量的原始数据中找到一些突出和异常的数据，一般需要建设一些流式检测和聚类分析的能力。</p><h4 id="匡凌轩-2"><a href="#匡凌轩-2" class="headerlink" title="匡凌轩"></a>匡凌轩</h4><h4 id="“采集数据，建立关联，设计模型”"><a href="#“采集数据，建立关联，设计模型”" class="headerlink" title="“采集数据，建立关联，设计模型”"></a>“采集数据，建立关联，设计模型”</h4><p>可观测性的核心思考：需要采集什么数据、如何建立关联、如何设计模型，我们以应用服务场景为例：</p><ul><li>  采集：请求量、耗时、错误和容量等，以及线程池、队列、连接池等资源指标。</li><li>  关联：纵向关联请求上下游链路和调用栈，横向关联请求和处理请求所消耗的应用资源。</li><li>  模型：数据采集和关联、异常定义和分析、全链路错误寻根三方面统一的模型化设计。</li></ul><p>以上可指导我们针对不同的业务应用系统进行合理抽象，建设更标准的可观测性能力。</p><h4 id="方勇-2"><a href="#方勇-2" class="headerlink" title="方勇"></a>方勇</h4><h4 id="“MDD思想主张指标驱动开发”"><a href="#“MDD思想主张指标驱动开发”" class="headerlink" title="“MDD思想主张指标驱动开发”"></a>“MDD思想主张指标驱动开发”</h4><p><strong>常用方法论：</strong></p><p>1、SLI选择：</p><ul><li>  参考Google VALET（Volume、Available、Latency、Error、Ticket）模型。</li><li>  Netflix的USE方法，USE是Utilization（使用率）、Saturation（饱和度）、Error（错误）。</li><li>  Weave Cloud的RED方法，Request-Rate（每秒接收的请求数）/Request-Errors（每秒失败的请求数）/Request-Duration（每个请求所花费的时间，用时间间隔表示）。</li></ul><p>2、MDD（Metrics-Driven Development）思想：MDD主张整个应用开发过程由指标驱动，通过实时指标来驱动快速、精确和细粒度的软件迭代。指标驱动开发的理念，不但可以让程序员实时感知生产状态，及时定位并终结问题，还可以帮助产品经理和运维人员一起关注相关的业务指标。</p><p><strong>关键技术：</strong></p><p>1、数据收集：如果是基于Prometheus生态，有丰富的Exporte可用，还可以自研相应的Exporter。如果基于文件日志收集，可考虑Flume、Fluentd等等。</p><p>2、数据分析：可基于Clickhouse SQL分析提炼日志指标，如果是Prometheus体系，也有丰富的PromQL可用来分析相关指标。针对Traces、Logs分析一般采用自研分析引擎，并与Metrics打通。</p><p>3、数据存储：Prometheus本身就是一款很好的时序数据库，但不支持分布式存储。一般采用远程存储引擎搭配使用，常用Clickhouse、InfluxDB等。Traces和Logs一般可采用Elasticsearch存储。</p><p>4、数据展示：数据最终呈现形式，需要契合可视化设计规划，支持上卷/下钻。大部分需求可采用Grafana呈现，Grafana提供了丰富的插件，支持丰富的数据库类型，也可基于Echarts自研。如果托管公有云，可充分利用公有云自有的体系，不过有些需要单独付费。</p><h3 id="Q4如何将Metrics、Traces、Logs三者打通并发挥最大价值？"><a href="#Q4如何将Metrics、Traces、Logs三者打通并发挥最大价值？" class="headerlink" title="Q4如何将Metrics、Traces、Logs三者打通并发挥最大价值？"></a>Q4如何将Metrics、Traces、Logs三者打通并发挥最大价值？</h3><h4 id="熊豹-3"><a href="#熊豹-3" class="headerlink" title="熊豹"></a>熊豹</h4><h4 id="“基于时间范围内的统计关系或Label和TraceID关联”"><a href="#“基于时间范围内的统计关系或Label和TraceID关联”" class="headerlink" title="“基于时间范围内的统计关系或Label和TraceID关联”"></a>“基于时间范围内的统计关系或Label和TraceID关联”</h4><p>我们已知的有两类方式：</p><p>1、基于时间范围内的统计关系：一般的使用习惯是在Metric异常的时间区间里去找到对应时间区间出现异常行为的Traces和Logs，这种方式会依赖对Traces和Logs的聚类分析能力。</p><p>2、基于Label和TraceID关联：基于OpenTelemetry Collector可观测数据采集的框架，我们可以以插件的形式、以Trace Span元数据Label来生成访问指标，也同时将TraceID携带记录到日志的元信息中，这样就能以同样的TraceID或Label维度进行关联查看了。另外当前Prometheus实现了一个exemplar特性可以将Metric与TraceID关联存储，这个设计也挺有意思的。</p><h4 id="匡凌轩-3"><a href="#匡凌轩-3" class="headerlink" title="匡凌轩"></a>匡凌轩</h4><h4 id="“全链路错误寻根是三者打通的最大价值”"><a href="#“全链路错误寻根是三者打通的最大价值”" class="headerlink" title="“全链路错误寻根是三者打通的最大价值”"></a>“全链路错误寻根是三者打通的最大价值”</h4><p>三者打通最大的价值是能做到全链路错误寻根，即从发现请求Metric指标异常，通过指标关联分析，并逐层下钻到明细Trace追踪和具体Error Log，全流程自动化从宏观到明细的错误发现和根因定位。</p><p>虎牙为三者统一设计了应用监控模型，包括应用服务的透明零成本SDK接入，三者数据自动采集和关联，以及在虎牙大型分布式系统充分实践的全链路错误寻根算法。就整体实践经验来说，最终业务价值在于帮助研发和运维提高了应用服务的排障和治理效率。</p><h4 id="方勇-3"><a href="#方勇-3" class="headerlink" title="方勇"></a>方勇</h4><h4 id="“打通后可立体、全息分析整个服务的可用性”"><a href="#“打通后可立体、全息分析整个服务的可用性”" class="headerlink" title="“打通后可立体、全息分析整个服务的可用性”"></a>“打通后可立体、全息分析整个服务的可用性”</h4><p>从投入成本（CapEx）、运维成本（OpEx）、响应能力（Reaction）、查问题的有效程度（Investigation）几个方面分析。Metrics、Logs、Traces具有以下特征：</p><p><img src="https://s5.51cto.com/oss/202204/26/794bc0a70ed8e615f8524332b2b26c8a70383d.jpg"></p><p>Logs和Traces一般采用trace_id打通，trace_id一般在端入口生成，贯穿整个请求的生命周期，业务记录Logs的时候可记录当前的trace_id，这样Logs和Traces就能打通了。</p><p>与Metrics打通一般是采用标签Tags模式，如某个服务servername产生的metrics可与Traces中的servername关联。</p><p>打通后可以服务名的维度，立体、全息分析整个服务的可用性。</p><h3 id="Q5可观测性工具如何选型？有通用的标准吗？"><a href="#Q5可观测性工具如何选型？有通用的标准吗？" class="headerlink" title="Q5可观测性工具如何选型？有通用的标准吗？"></a>Q5可观测性工具如何选型？有通用的标准吗？</h3><h4 id="熊豹-4"><a href="#熊豹-4" class="headerlink" title="熊豹"></a>熊豹</h4><h4 id="“高可用、可伸缩、降成本、易运维”"><a href="#“高可用、可伸缩、降成本、易运维”" class="headerlink" title="“高可用、可伸缩、降成本、易运维”"></a>“高可用、可伸缩、降成本、易运维”</h4><p>我们关注可观测工具系统的这些特性：</p><ul><li>  高可用：可观测系统作为稳定性的守卫者，本身要求更高的可靠性。</li><li>  可伸缩：我们关注存储写入和查询能力的可拓展性，以支持更大的数据量级。</li><li>  降成本：观测类数据会随着时间的推移逐渐失去价值，历史数据最好能低成本地失效或能对存储介质进行降级。</li><li>  易运维：拥有一定的自动化能力或者本身架构足够简单。</li></ul><h4 id="匡凌轩-4"><a href="#匡凌轩-4" class="headerlink" title="匡凌轩"></a>匡凌轩</h4><h4 id="“是否基于业界标准且方便扩展”"><a href="#“是否基于业界标准且方便扩展”" class="headerlink" title="“是否基于业界标准且方便扩展”"></a>“是否基于业界标准且方便扩展”</h4><p>虎牙主要是基于OpenTracing标准进行的深度自研和扩展，通过业界标准来做会有充分的开源代码和社区支持，可以节省很多基础代码的工作，让我们更关注自身的业务系统特性和模型设计。现在OpenTelemetry对Metrics、Traces、Logs三者提供了统一标准，开源社区热度也比较大，是个值得去研究和实践的方向。</p><p>可观测性工具选型建议可考虑两个方面：</p><ol><li> 是否基于业界标准，有更多社区和厂商支持。</li><li> 是否方便扩展，更容易把共性和个性结合，最终在此基础上建设符合自身业务特性的可观测性系统。</li></ol><h4 id="方勇-4"><a href="#方勇-4" class="headerlink" title="方勇"></a>方勇</h4><h4 id="“根据已有技术栈按需选择，不必盲从主流”"><a href="#“根据已有技术栈按需选择，不必盲从主流”" class="headerlink" title="“根据已有技术栈按需选择，不必盲从主流”"></a>“根据已有技术栈按需选择，不必盲从主流”</h4><p>可观测性分析整个技术栈可参考如下图：</p><p><img src="https://s7.51cto.com/oss/202204/26/79797fd850c3ff8d3dd2788ad4febc3662052a.jpg"></p><p>工具选型：</p><ul><li>  Metrics：常用Zabbix、Nagios、Prometheus，及相关高可用部署方案如Prometheus-operator、Thanos。</li><li>  Logging：ELK Stack、Fluentd、Loki等。</li><li>  Traceing：常用Jaeger、SkyWalking、Pinpoint、Zipkin、Spring Cloud Sleuth等。</li><li>  可视化：Grafana。</li></ul><p>其实技术选型没什么特定的标准，每个企业不同阶段可能有不同的选择，适合自己的才是最好的，这里总结几点心得：</p><ul><li>  控制成本预算，企业一般需要从自身的发展阶段实际情况考虑，不必一上来就整全链路可观测性，也许初期只用传统的Zabbix就满足需求了。理性按需选择，大可不必盲从主流。</li><li>  拥抱开源，初期一般采用开源产品，开箱即用，搭顺风车。另外，选型时还需要考虑周边生态的丰富度。</li><li>  根据团队技术栈选择，中间件、业务服务、云原生、物理机监控等选型都要贴合团队已有的技术栈。</li></ul></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://www.51cto.com/article/707455.html&quot;&gt;https://www.51cto.com/article/707455.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.51cto.com/a</summary>
      
    
    
    
    <category term="监控" scheme="http://zhangyu.info/categories/%E7%9B%91%E6%8E%A7/"/>
    
    
    <category term="监控" scheme="http://zhangyu.info/tags/%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot性能太差,教你几招轻松搞定</title>
    <link href="http://zhangyu.info/2022/04/30/SpringBoot%E6%80%A7%E8%83%BD%E5%A4%AA%E5%B7%AE,%E6%95%99%E4%BD%A0%E5%87%A0%E6%8B%9B%E8%BD%BB%E6%9D%BE%E6%90%9E%E5%AE%9A/"/>
    <id>http://zhangyu.info/2022/04/30/SpringBoot%E6%80%A7%E8%83%BD%E5%A4%AA%E5%B7%AE,%E6%95%99%E4%BD%A0%E5%87%A0%E6%8B%9B%E8%BD%BB%E6%9D%BE%E6%90%9E%E5%AE%9A/</id>
    <published>2022-04-29T16:00:00.000Z</published>
    <updated>2022-04-30T10:42:45.102Z</updated>
    
    <content type="html"><![CDATA[<p>SpringBoot性能太差,教你几招轻松搞定 </p><p>Java派 2022-04-30 09:27</p><p><a href="https://mp.weixin.qq.com/s/lreQia3XL5cl0XKrN47KCA">https://mp.weixin.qq.com/s/lreQia3XL5cl0XKrN47KCA</a></p><p><a href="https://mp.weixin.qq.com/s/lreQia3XL5cl0XKrN47KCA">Spring Boot性能太差，教你几招轻松搞定</a></p><blockquote><p><strong>目录</strong></p><ul><li><p>  异步执行</p></li><li><p>  增加内嵌 Tomcat 的最大连接数</p></li><li><p>  使用 @ComponentScan()</p></li><li><p>  默认 Tomcat 容器改为 Undertow</p></li><li><p>  使用 BufferedWriter 进行缓冲</p></li><li><p>  Deferred 方式实现异步调用</p></li><li><p>  异步调用可以使用 AsyncHandlerInterceptor 进行拦截</p></li></ul><p><strong>异步执行</strong></p><p>实现方式二种：</p><ul><li><p>  使用异步注解 @aysnc、启动类：添加 @EnableAsync 注解</p></li><li><p>  JDK 8 本身有一个非常好用的 Future 类——CompletableFuture</p></li></ul></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">@AllArgsConstructor</span><br><span class="line">public class AskThread implements Runnable&#123;</span><br><span class="line">    private CompletableFuture&lt;Integer&gt; re &#x3D; null;</span><br><span class="line">    public void run() &#123;</span><br><span class="line">        int myRe &#x3D; 0;</span><br><span class="line">        try &#123;</span><br><span class="line">            myRe &#x3D; re.get() * re.get();</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(myRe);</span><br><span class="line">    &#125;</span><br><span class="line">    public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">        final CompletableFuture&lt;Integer&gt; future &#x3D; new CompletableFuture&lt;&gt;();</span><br><span class="line">        new Thread(new AskThread(future)).start();</span><br><span class="line">        &#x2F;&#x2F;模拟长时间的计算过程</span><br><span class="line">        Thread.sleep(1000);</span><br><span class="line">        &#x2F;&#x2F;告知完成结果</span><br><span class="line">        future.complete(60);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>在该示例中，启动一个线程，此时 AskThread 对象还没有拿到它需要的数据，执行到  myRe = re.get() * re.get() 会阻塞。</p><p>我们用休眠 1 秒来模拟一个长时间的计算过程，并将计算结果告诉 future 执行结果，AskThread 线程将会继续执行。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public class Calc &#123;</span><br><span class="line">    public static Integer calc(Integer para) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            &#x2F;&#x2F;模拟一个长时间的执行</span><br><span class="line">            Thread.sleep(1000);</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        return para * para;</span><br><span class="line">    &#125;</span><br><span class="line">    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;</span><br><span class="line">        final CompletableFuture&lt;Void&gt; future &#x3D; CompletableFuture.supplyAsync(() -&gt; calc(50))</span><br><span class="line">                .thenApply((i) -&gt; Integer.toString(i))</span><br><span class="line">                .thenApply((str) -&gt; &quot;\&quot;&quot; + str + &quot;\&quot;&quot;)</span><br><span class="line">                .thenAccept(System.out::println);</span><br><span class="line">        future.get();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>CompletableFuture.supplyAsync 方法构造一个 CompletableFuture 实例，在 supplyAsync() 方法中，它会在一个新线程中，执行传入的参数。</p><p>在这里它会执行 calc() 方法，这个方法可能是比较慢的，但这并不影响 CompletableFuture 实例的构造速度，supplyAsync() 会立即返回。</p><p>而返回的 CompletableFuture 实例就可以作为这次调用的契约，在将来任何场合，用于获得最终的计算结果。</p><p>supplyAsync 用于提供返回值的情况，CompletableFuture 还有一个不需要返回值的异步调用方法 runAsync(Runnable runnable)，一般我们在优化 Controller 时，使用这个方法比较多。</p><p>这两个方法如果在不指定线程池的情况下，都是在 ForkJoinPool.common 线程池中执行，而这个线程池中的所有线程都是 Daemon（守护）线程，所以，当主线程结束时，这些线程无论执行完毕都会退出系统。</p><p>核心代码：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CompletableFuture.runAsync(() -&gt;</span><br><span class="line">   this.afterBetProcessor(betRequest,betDetailResult,appUser,id)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><blockquote><p>异步调用使用 Callable 来实现：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">@RestController  </span><br><span class="line">public class HelloController &#123;</span><br><span class="line">    private static final Logger logger &#x3D; LoggerFactory.getLogger(HelloController.class);</span><br><span class="line">    @Autowired  </span><br><span class="line">    private HelloService hello;</span><br><span class="line">    @GetMapping(&quot;&#x2F;helloworld&quot;)</span><br><span class="line">    public String helloWorldController() &#123;</span><br><span class="line">        return hello.sayHello();</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 异步调用restful</span><br><span class="line">     * 当controller返回值是Callable的时候，springmvc就会启动一个线程将Callable交给TaskExecutor去处理</span><br><span class="line">     * 然后DispatcherServlet还有所有的spring拦截器都退出主线程，然后把response保持打开的状态</span><br><span class="line">     * 当Callable执行结束之后，springmvc就会重新启动分配一个request请求，然后DispatcherServlet就重新</span><br><span class="line">     * 调用和处理Callable异步执行的返回结果， 然后返回视图</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;  </span><br><span class="line">    @GetMapping(&quot;&#x2F;hello&quot;)</span><br><span class="line">    public Callable&lt;String&gt; helloController() &#123;</span><br><span class="line">        logger.info(Thread.currentThread().getName() + &quot; 进入helloController方法&quot;);</span><br><span class="line">        Callable&lt;String&gt; callable &#x3D; new Callable&lt;String&gt;() &#123;</span><br><span class="line">            @Override  </span><br><span class="line">            public String call() throws Exception &#123;</span><br><span class="line">                logger.info(Thread.currentThread().getName() + &quot; 进入call方法&quot;);</span><br><span class="line">                String say &#x3D; hello.sayHello();</span><br><span class="line">                logger.info(Thread.currentThread().getName() + &quot; 从helloService方法返回&quot;);</span><br><span class="line">                return say;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        logger.info(Thread.currentThread().getName() + &quot; 从helloController方法返回&quot;);</span><br><span class="line">        return callable;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>异步调用的方式 WebAsyncTask：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">@RestController  </span><br><span class="line">public class HelloController &#123;</span><br><span class="line">    private static final Logger logger &#x3D; LoggerFactory.getLogger(HelloController.class);</span><br><span class="line">    @Autowired  </span><br><span class="line">    private HelloService hello;</span><br><span class="line">        &#x2F;**</span><br><span class="line">     * 带超时时间的异步请求 通过WebAsyncTask自定义客户端超时间</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;  </span><br><span class="line">    @GetMapping(&quot;&#x2F;world&quot;)</span><br><span class="line">    public WebAsyncTask&lt;String&gt; worldController() &#123;</span><br><span class="line">        logger.info(Thread.currentThread().getName() + &quot; 进入helloController方法&quot;);</span><br><span class="line">        &#x2F;&#x2F; 3s钟没返回，则认为超时</span><br><span class="line">        WebAsyncTask&lt;String&gt; webAsyncTask &#x3D; new WebAsyncTask&lt;&gt;(3000, new Callable&lt;String&gt;() &#123;</span><br><span class="line">            @Override  </span><br><span class="line">            public String call() throws Exception &#123;</span><br><span class="line">                logger.info(Thread.currentThread().getName() + &quot; 进入call方法&quot;);</span><br><span class="line">                String say &#x3D; hello.sayHello();</span><br><span class="line">                logger.info(Thread.currentThread().getName() + &quot; 从helloService方法返回&quot;);</span><br><span class="line">                return say;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        logger.info(Thread.currentThread().getName() + &quot; 从helloController方法返回&quot;);</span><br><span class="line">        webAsyncTask.onCompletion(new Runnable() &#123;</span><br><span class="line">            @Override  </span><br><span class="line">            public void run() &#123;</span><br><span class="line">                logger.info(Thread.currentThread().getName() + &quot; 执行完毕&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        webAsyncTask.onTimeout(new Callable&lt;String&gt;() &#123;</span><br><span class="line"></span><br><span class="line">            @Override  </span><br><span class="line">            public String call() throws Exception &#123;</span><br><span class="line">                logger.info(Thread.currentThread().getName() + &quot; onTimeout&quot;);</span><br><span class="line">                &#x2F;&#x2F; 超时的时候，直接抛异常，让外层统一处理超时异常</span><br><span class="line">                throw new TimeoutException(&quot;调用超时&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        return webAsyncTask;</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 异步调用，异常处理，详细的处理流程见MyExceptionHandler类</span><br><span class="line">     *</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;  </span><br><span class="line">    @GetMapping(&quot;&#x2F;exception&quot;)</span><br><span class="line">    public WebAsyncTask&lt;String&gt; exceptionController() &#123;</span><br><span class="line">        logger.info(Thread.currentThread().getName() + &quot; 进入helloController方法&quot;);</span><br><span class="line">        Callable&lt;String&gt; callable &#x3D; new Callable&lt;String&gt;() &#123;</span><br><span class="line"></span><br><span class="line">            @Override  </span><br><span class="line">            public String call() throws Exception &#123;</span><br><span class="line">                logger.info(Thread.currentThread().getName() + &quot; 进入call方法&quot;);</span><br><span class="line">                throw new TimeoutException(&quot;调用超时!&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        logger.info(Thread.currentThread().getName() + &quot; 从helloController方法返回&quot;);</span><br><span class="line">        return new WebAsyncTask&lt;&gt;(20000, callable);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p><strong>增加内嵌 Tomcat 的最大连接数</strong></p><h6 id=""><a href="#" class="headerlink" title=""></a></h6><h6 id="代码如下："><a href="#代码如下：" class="headerlink" title="代码如下："></a>代码如下：</h6></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">public class TomcatConfig &#123;</span><br><span class="line">    @Bean</span><br><span class="line">    public ConfigurableServletWebServerFactory webServerFactory() &#123;</span><br><span class="line">        TomcatServletWebServerFactory tomcatFactory &#x3D; new TomcatServletWebServerFactory();</span><br><span class="line">        tomcatFactory.addConnectorCustomizers(new MyTomcatConnectorCustomizer());</span><br><span class="line">        tomcatFactory.setPort(8005);</span><br><span class="line">        tomcatFactory.setContextPath(&quot;&#x2F;api-g&quot;);</span><br><span class="line">        return tomcatFactory;</span><br><span class="line">    &#125;</span><br><span class="line">    class MyTomcatConnectorCustomizer implements TomcatConnectorCustomizer &#123;</span><br><span class="line">        public void customize(Connector connector) &#123;</span><br><span class="line">            Http11NioProtocol protocol &#x3D; (Http11NioProtocol) connector.getProtocolHandler();</span><br><span class="line">            &#x2F;&#x2F;设置最大连接数</span><br><span class="line">            protocol.setMaxConnections(20000);</span><br><span class="line">            &#x2F;&#x2F;设置最大线程数</span><br><span class="line">            protocol.setMaxThreads(2000);</span><br><span class="line">            protocol.setConnectionTimeout(30000);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><h6 id="-1"><a href="#-1" class="headerlink" title=""></a></h6><p><strong>使用 @ComponentScan()</strong></p><h6 id="-2"><a href="#-2" class="headerlink" title=""></a></h6><h6 id="使用-ComponentScan-定位扫包比-SpringBootApplication-扫包更快。"><a href="#使用-ComponentScan-定位扫包比-SpringBootApplication-扫包更快。" class="headerlink" title="使用 @ComponentScan() 定位扫包比 @SpringBootApplication 扫包更快。"></a>使用 @ComponentScan() 定位扫包比 @SpringBootApplication 扫包更快。</h6><h6 id="-3"><a href="#-3" class="headerlink" title=""></a></h6><p><strong>默认 Tomcat 容器改为 Undertow</strong></p><h6 id="-4"><a href="#-4" class="headerlink" title=""></a></h6><h6 id="默认-Tomcat-容器改为-Undertow（Jboss-下的服务器，Tomcat-吞吐量-5000，Undertow-吞吐量-8000）"><a href="#默认-Tomcat-容器改为-Undertow（Jboss-下的服务器，Tomcat-吞吐量-5000，Undertow-吞吐量-8000）" class="headerlink" title="默认 Tomcat 容器改为 Undertow（Jboss 下的服务器，Tomcat 吞吐量 5000，Undertow 吞吐量 8000）"></a>默认 Tomcat 容器改为 Undertow（Jboss 下的服务器，Tomcat 吞吐量 5000，Undertow 吞吐量 8000）</h6></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;exclusions&gt;</span><br><span class="line">  &lt;exclusion&gt;</span><br><span class="line">     &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">     &lt;artifactId&gt;spring-boot-starter-tomcat&lt;&#x2F;artifactId&gt;</span><br><span class="line">  &lt;&#x2F;exclusion&gt;</span><br><span class="line">&lt;&#x2F;exclusions&gt;</span><br></pre></td></tr></table></figure><blockquote><p>改为：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;spring-boot-starter-undertow&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure><blockquote><p><strong>使用 BufferedWriter 进行缓冲</strong></p><p>这里不给大家举例，可自行尝试。</p><p><strong>Deferred 方式实现异步调用</strong></p><h6 id="代码如下：-1"><a href="#代码如下：-1" class="headerlink" title="代码如下："></a>代码如下：</h6></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">public class AsyncDeferredController &#123;</span><br><span class="line">    private final Logger logger &#x3D; LoggerFactory.getLogger(this.getClass());</span><br><span class="line">    private final LongTimeTask taskService;</span><br><span class="line">    @Autowired</span><br><span class="line">    public AsyncDeferredController(LongTimeTask taskService) &#123;</span><br><span class="line">        this.taskService &#x3D; taskService;</span><br><span class="line">    &#125;</span><br><span class="line">    @GetMapping(&quot;&#x2F;deferred&quot;)</span><br><span class="line">    public DeferredResult&lt;String&gt; executeSlowTask() &#123;</span><br><span class="line">        logger.info(Thread.currentThread().getName() + &quot;进入executeSlowTask方法&quot;);</span><br><span class="line">        DeferredResult&lt;String&gt; deferredResult &#x3D; new DeferredResult&lt;&gt;();</span><br><span class="line">        &#x2F;&#x2F; 调用长时间执行任务</span><br><span class="line">        taskService.execute(deferredResult);</span><br><span class="line">        &#x2F;&#x2F; 当长时间任务中使用deferred.setResult(&quot;world&quot;);这个方法时，会从长时间任务中返回，继续controller里面的流程</span><br><span class="line">        logger.info(Thread.currentThread().getName() + &quot;从executeSlowTask方法返回&quot;);</span><br><span class="line">        &#x2F;&#x2F; 超时的回调方法</span><br><span class="line">        deferredResult.onTimeout(new Runnable()&#123;</span><br><span class="line">   @Override</span><br><span class="line">   public void run() &#123;</span><br><span class="line">    logger.info(Thread.currentThread().getName() + &quot; onTimeout&quot;);</span><br><span class="line">    &#x2F;&#x2F; 返回超时信息</span><br><span class="line">    deferredResult.setErrorResult(&quot;time out!&quot;);</span><br><span class="line">   &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">        &#x2F;&#x2F; 处理完成的回调方法，无论是超时还是处理成功，都会进入这个回调方法</span><br><span class="line">        deferredResult.onCompletion(new Runnable()&#123;</span><br><span class="line">   @Override</span><br><span class="line">   public void run() &#123;</span><br><span class="line">    logger.info(Thread.currentThread().getName() + &quot; onCompletion&quot;);</span><br><span class="line">   &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">        return deferredResult;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><h6 id="-5"><a href="#-5" class="headerlink" title=""></a></h6><p><strong>异步调用可以使用 AsyncHandlerInterceptor 进行拦截</strong></p><h6 id="-6"><a href="#-6" class="headerlink" title=""></a></h6><h6 id="代码如下：-2"><a href="#代码如下：-2" class="headerlink" title="代码如下："></a>代码如下：</h6></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">@Component</span><br><span class="line">public class MyAsyncHandlerInterceptor implements AsyncHandlerInterceptor &#123;</span><br><span class="line"> private static final Logger logger &#x3D; LoggerFactory.getLogger(MyAsyncHandlerInterceptor.class);</span><br><span class="line"> @Override</span><br><span class="line"> public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)</span><br><span class="line">   throws Exception &#123;</span><br><span class="line">  return true;</span><br><span class="line"> &#125;</span><br><span class="line"> @Override</span><br><span class="line"> public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler,</span><br><span class="line">   ModelAndView modelAndView) throws Exception &#123;</span><br><span class="line">&#x2F;&#x2F; HandlerMethod handlerMethod &#x3D; (HandlerMethod) handler;</span><br><span class="line">  logger.info(Thread.currentThread().getName()+ &quot;服务调用完成，返回结果给客户端&quot;);</span><br><span class="line"> &#125;</span><br><span class="line"> @Override</span><br><span class="line"> public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex)</span><br><span class="line">   throws Exception &#123;</span><br><span class="line">  if(null !&#x3D; ex)&#123;</span><br><span class="line">   System.out.println(&quot;发生异常:&quot;+ex.getMessage());</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> @Override</span><br><span class="line"> public void afterConcurrentHandlingStarted(HttpServletRequest request, HttpServletResponse response, Object handler)</span><br><span class="line">   throws Exception &#123;</span><br><span class="line">  &#x2F;&#x2F; 拦截之后，重新写回数据，将原来的hello world换成如下字符串</span><br><span class="line">  String resp &#x3D; &quot;my name is chhliu!&quot;;</span><br><span class="line">  response.setContentLength(resp.length());</span><br><span class="line">  response.getOutputStream().write(resp.getBytes());</span><br><span class="line">  logger.info(Thread.currentThread().getName() + &quot; 进入afterConcurrentHandlingStarted方法&quot;);</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;SpringBoot性能太差,教你几招轻松搞定 &lt;/p&gt;
&lt;p&gt;Java派 2022-04-30 09:27&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/lreQia3XL5cl0XKrN47KCA&quot;&gt;https://mp.weix</summary>
      
    
    
    
    <category term="SpringBoot" scheme="http://zhangyu.info/categories/SpringBoot/"/>
    
    
    <category term="SpringBoot" scheme="http://zhangyu.info/tags/SpringBoot/"/>
    
  </entry>
  
  <entry>
    <title>API网关的功能用途及实现方式</title>
    <link href="http://zhangyu.info/2022/04/30/API%E7%BD%91%E5%85%B3%E7%9A%84%E5%8A%9F%E8%83%BD%E7%94%A8%E9%80%94%E5%8F%8A%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/"/>
    <id>http://zhangyu.info/2022/04/30/API%E7%BD%91%E5%85%B3%E7%9A%84%E5%8A%9F%E8%83%BD%E7%94%A8%E9%80%94%E5%8F%8A%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/</id>
    <published>2022-04-29T16:00:00.000Z</published>
    <updated>2022-04-30T08:52:54.499Z</updated>
    
    <content type="html"><![CDATA[<p>API网关的功能用途及实现方式 - 东风微鸣技术博客<br><a href="https://ewhisper.cn/posts/52291/">https://ewhisper.cn/posts/52291/</a></p><blockquote><h2 id="1-API-网关诞生背景"><a href="#1-API-网关诞生背景" class="headerlink" title="1. API 网关诞生背景"></a>1. API 网关诞生背景</h2><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>API 经济生态链已经在全球范围覆盖， 绝大多数企业都已经走在数字化转型的道路上，API 成为企业连接业务的核心载体， 并产生巨大的盈利空间。快速增长的 API 规模以及调用量，使得企业 IT 在架构上、模式上面临着更多的挑战。</p><h3 id="API-是什么"><a href="#API-是什么" class="headerlink" title="API 是什么"></a>API 是什么</h3><p>API 网关是一个服务器，是系统的唯一入口。从面向对象设计的角度看，它与外观模式类似。API 网关封装了系统内部架构，为每个客户端提供一个定制的 API。它可能还具有其它职责，如身份验证、监控、负载均衡、缓存、请求分片与管理、静态响应处理。API 网关方式的核心要点是，所有的客户端和消费端都通过统一的网关接入微服务，在网关层处理所有的非业务功能。通常，网关也是提供 REST/HTTP 的访问 API。服务端通过 API-GW 注册和管理服务。</p><h4 id="1-API-开放数量不断增加"><a href="#1-API-开放数量不断增加" class="headerlink" title="1. API 开放数量不断增加"></a>1. API 开放数量不断增加</h4><p>毋庸置疑，随着企业的数据化进展，微服务改造，不同领域的 API 层出不穷，早在 2014 年 ProgrammableWeb 便预测 API 矢量可达到 100,000 到 200,000，并会不断增长。API 开发数量的增加给边缘系统带来机会，也随即演变了 API 网关的出现。大规模的 API 管理系统成为核心的发展趋势。</p><p><a href="https://pic-cdn.ewhisper.cn/img/2021/08/25/56946b95ef344c0b542764b063961940-total-number-of-APis-growth-of-the-API-industry.png" title="The API Economy Disruption and the Business of APIs，Nordic APIs"><img src="https://pic-cdn.ewhisper.cn/img/2021/08/25/56946b95ef344c0b542764b063961940-total-number-of-APis-growth-of-the-API-industry.png" alt="The API Economy Disruption and the Business of APIs，Nordic APIs"></a></p><p><a href="https://pic-cdn.ewhisper.cn/img/2021/08/25/56946b95ef344c0b542764b063961940-total-number-of-APis-growth-of-the-API-industry.png" title="The API Economy Disruption and the Business of APIs，Nordic APIs">The API Economy Disruption and the Business of APIs，Nordic APIs</a></p><h4 id="2-API-服务平台多样化"><a href="#2-API-服务平台多样化" class="headerlink" title="2. API 服务平台多样化"></a>2. API 服务平台多样化</h4><p>最初的 API 主要针对不同单体应用的网络单元之间信息交互，现已演变到服务间快速通讯。随着人工智能 EI，IOT 的不断演进，依赖 API 的平台不断更新，如 Web，Mobile，终端等，未来将会出现更多的服务体系。包括不限于：</p><ul><li>  浏览器</li><li>  IOS</li><li>  Android</li><li>  macOS</li><li>  Windows</li><li>  Linux</li><li>  IOT</li><li>  其他移动端</li><li>  小程序</li><li>  终端设备（如智慧零售、工业的终端等）</li><li>  …</li></ul><p><a href="https://pic-cdn.ewhisper.cn/img/2021/08/25/7a9615fedf5505fd3fc6094d38af448d-20210825104220.png"><img src="https://pic-cdn.ewhisper.cn/img/2021/08/25/7a9615fedf5505fd3fc6094d38af448d-20210825104220.png"></a></p><h4 id="3-逐步替换原有企业的服务模式，API-即商品"><a href="#3-逐步替换原有企业的服务模式，API-即商品" class="headerlink" title="3. 逐步替换原有企业的服务模式，API 即商品"></a>3. 逐步替换原有企业的服务模式，API 即商品</h4><p>卖计算，卖软件，卖能力，最终的企业的销售模式会逐步转变，能力变现，释放数据价值，依托不同的 API 管理平台创造新的盈利。</p><h3 id="API-网关诞生背景"><a href="#API-网关诞生背景" class="headerlink" title="API 网关诞生背景"></a>API 网关诞生背景</h3><p>随着 API 的整体趋势发展，每个时期都面临着不同的挑战，架构也随之变化，具体如下图：</p><ol><li> 1960-1980：阿帕网、ATTP、TCP</li><li> 1980-1990：点对点</li><li> 1990-2000：消息中间件、ESB（企业服务总线，Enterprise service bus），SOA（面向服务的架构）</li><li> 2000 至今：Integration as a service，RESTful services，API 管理，云上编排</li></ol><p><a href="https://pic-cdn.ewhisper.cn/img/2021/08/25/e8fdff5629ec5d463b570ddeb01e8bb5-API-Infographic-Final.webp" title="API economy From systems to business services"><img src="https://pic-cdn.ewhisper.cn/img/2021/08/25/e8fdff5629ec5d463b570ddeb01e8bb5-API-Infographic-Final.webp" alt="API economy From systems to business services"></a></p><p><a href="https://pic-cdn.ewhisper.cn/img/2021/08/25/e8fdff5629ec5d463b570ddeb01e8bb5-API-Infographic-Final.webp" title="API economy From systems to business services">API economy From systems to business services</a></p><p>从最原始的“传输协议通讯” -&gt; “简单的接口集成” -&gt; “消息中间件” -&gt; “标准 REST”， 可以看到 API 的发展更趋向于简洁， 集成，规范化， 这也促使更多的系统边界组件不断涌现，在承载了万亿级的 API 经济的背景下， API 网关应运而生。</p><p>如果没有合适的 API 管理工具， API 经济不可能顺利开展。 同时提出了对于 API 管理系统的生命周期定义： planning（规划）, design（设计）， implementation（实施）， publication（发布），operation（运维）, consumption（消费）, maintenance（维护） and retirement of APIs（下架）</p><p>如果没有合适的 API 管理工具， API 经济不可能顺利开展。 同时提出了对于 API 管理系统的生命周期定义： planning（规划）, design（设计）， implementation（实施）， publication（发布），operation（运维）, consumption（消费）, maintenance（维护） and retirement of APIs（下架）</p><p>– <em>Magic Quadrant for Full Life Cycle API Management，Gartner, 2016-10-27</em></p><h2 id="2-API-网关核心功能"><a href="#2-API-网关核心功能" class="headerlink" title="2. API 网关核心功能"></a>2. API 网关核心功能</h2><ul><li>API 生命周期管理<ul><li>  planning（规划）</li><li>  design（设计）</li><li>  implementation（实施）</li><li>  publication（发布）</li><li>  operation（运维）</li><li>  consumption（消费）</li><li>  maintenance（维护）</li><li>  retirement（下架）</li></ul></li><li>API 网关基础功能<ul><li>  认证</li><li>  鉴权</li><li>  服务发现和集成</li><li>  负载均衡</li><li>  日志</li><li>  链路追踪</li><li>  监控</li><li>  重试</li><li>  限流</li><li>  QoS</li><li>  熔断器</li><li>  映射</li><li>  缓存</li><li>  Header、query 字符串 等 转义</li><li>  API 文档</li><li>  API 测试</li><li>  SDK 生成</li></ul></li><li>  API 多版本、多环境管理</li><li>  插件</li><li>  API 集中式 metrics、logging、tracing 管理</li><li>安全<ul><li>  HTTPS</li><li>  IP 黑白名单</li></ul></li><li>高可用<ul><li>  可热重启</li></ul></li><li>  高性能</li><li>可扩展性<ul><li>  无状态横向扩展</li></ul></li></ul><h2 id="3-API-网关的用途"><a href="#3-API-网关的用途" class="headerlink" title="3. API 网关的用途"></a>3. API 网关的用途</h2><h3 id="OpenAPI"><a href="#OpenAPI" class="headerlink" title="OpenAPI"></a>OpenAPI</h3><p>企业需要将自身数据、能力等作为开发平台向外开放，通常会以 rest 的方式向外提供。最好的例子就是淘宝开放平台、腾讯公司的 QQ 开发平台、微信开放平台。</p><p>Open API 开放平台必然涉及到客户应用的接入、API 权限的管理、调用次数管理等，必然会有一个统一的入口进行管理，这正是 API 网关可以发挥作用的时候。</p><h3 id="微服务网关"><a href="#微服务网关" class="headerlink" title="微服务网关"></a>微服务网关</h3><p>在微服务架构中，有一个组件可以说是必不可少的，那就是微服务网关，微服务网关处理了负载均衡，缓存，路由，访问控制，服务代理，监控，日志等。</p><p>API 网关在微服务架构中正是以微服务网关的身份存在。</p><h3 id="API-中台"><a href="#API-中台" class="headerlink" title="API 中台"></a>API 中台</h3><p>上述的微服务架构对企业来说有可能实施上是困难的，企业有很多遗留系统，要全部抽取为微服务改动太大，对企业来说成本太高。</p><p>但是由于不同系统间存在大量的 API 服务互相调用，因此需要对系统间服务调用进行管理，清晰地看到各系统调用关系，对系统间调用进行监控等。</p><p>API 网关可以解决这些问题，我们可以认为如果没有大规模的实施微服务架构，那么对企业来说微服务网关就是企业的 API 中台。</p><h2 id="4-API-网关的价值"><a href="#4-API-网关的价值" class="headerlink" title="4. API 网关的价值"></a>4. API 网关的价值</h2><p>通过 API 网关，可以封装后端各种服务，以 API 的形式，提供给各方使用。API 网关产品的优势总结如下：</p><ul><li>  API 全生命周期管理：协助开发者轻松完成 API 的创建、维护、发布、监控等整个生命周期的管理。</li><li>  丰富的服务治理能力：支持 API 限流，参数校验，元数据维护，SDK 生成，批量操作等能力，协助开发者高效管理服务。</li><li>  可观察性：通过 API 网关，支持对调用次数，前后端错误次数等丰富监控指标的可视和告警能力；通过全面的监控告警，保证用户服务的可用性。</li><li>  可运营性：支持 企业 OpenAPI 定价，账单等运营功能</li><li>  服务安全：通过接入多种认证方式，确保用户 API 的访问安全性；通过严格的流量控制，避免用户服务的过载。</li><li>  前后端业务解耦</li><li>  多类型后端打通</li></ul><h2 id="5-API-网关的实现方式"><a href="#5-API-网关的实现方式" class="headerlink" title="5. API 网关的实现方式"></a>5. API 网关的实现方式</h2><h3 id="主流-API-网关"><a href="#主流-API-网关" class="headerlink" title="主流 API 网关"></a>主流 API 网关</h3><ul><li>  Istio</li><li>  Linkerd</li><li>  NGINX 及其商业版</li><li>  KONG</li><li>  Traefik</li><li>  APISIX</li><li>  RedHat 3scale</li><li>  Netflix Zuul</li><li>  Spring Cloud Gateway</li><li>  Amazon API Gateway</li><li>  阿里云 API 网关</li><li>  腾讯云 API 网关</li><li>  MuleSoft</li></ul><h3 id="OpenAPI-1"><a href="#OpenAPI-1" class="headerlink" title="OpenAPI"></a>OpenAPI</h3><p>对于定位 OpenAPI 平台的 API 网关，目前只能选择专业的 API 网关作为解决方案。</p><h3 id="微服务网关-1"><a href="#微服务网关-1" class="headerlink" title="微服务网关"></a>微服务网关</h3><p>对于定位为「微服务网关」的 API 网关，业务有多种实现方式：</p><h4 id="Service-Mesh"><a href="#Service-Mesh" class="headerlink" title="Service Mesh"></a>Service Mesh</h4><p>典型的如 Istio，架构如下：</p><p><a href="https://pic-cdn.ewhisper.cn/img/2021/08/25/942a1801e1aa084b7301e0afedcb05d2-service_mesh_5.png"><img src="https://pic-cdn.ewhisper.cn/img/2021/08/25/942a1801e1aa084b7301e0afedcb05d2-service_mesh_5.png"></a><br><a href="https://pic-cdn.ewhisper.cn/img/2021/08/25/7a65f5e28f37fa8cb670d84618bb113d-service_mesh_2.png"><img src="https://pic-cdn.ewhisper.cn/img/2021/08/25/7a65f5e28f37fa8cb670d84618bb113d-service_mesh_2.png"></a></p><h4 id="通用反向代理"><a href="#通用反向代理" class="headerlink" title="通用反向代理"></a>通用反向代理<a href="https://ewhisper.cn/posts/52291/#%E9%80%9A%E7%94%A8%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86"></a></h4><p>基于 NGINX 或 NGINX + LUA + OpenResty 的实现。典型如：</p><ul><li><a href="https://www.nginx.com/">Nginx 及其 商业版</a><ul><li>  NGINX Controller（API 管理、App 交付）</li><li>  NGINX Plus（API Gateway，负载均衡，仪表板）</li><li>  NGINX Ingress Controller</li><li>  NGINX Service Mesh</li></ul></li><li>  <a href="https://github.com/Kong/kong">KONG</a></li><li>  <a href="https://doc.traefik.io/traefik/">Traefik</a></li><li>  <a href="https://www.redhat.com/en/technologies/jboss-middleware/3scale">3scale</a></li></ul><h4 id="API-网关框架"><a href="#API-网关框架" class="headerlink" title="API 网关框架"></a>API 网关框架</h4><ul><li>  <a href="https://github.com/Netflix/zuul">Netflix Zuul</a>，zuul 是 spring cloud 的一个推荐组件</li><li>  <a href="https://spring.io/projects/spring-cloud-gateway">Spring Cloud Gateway</a></li></ul><h4 id="公有云解决方案"><a href="#公有云解决方案" class="headerlink" title="公有云解决方案"></a>公有云解决方案</h4><p>其实公有云的解决方案也是基于以上方案的定制化开发并产品化后发布到公有云上，主流的也是基于：NGINX + LUA + OpenResty 的实现</p><ul><li>  <a href="https://aws.amazon.com/cn/api-gateway/">Amazon API Gateway</a></li><li>  <a href="https://www.aliyun.com/product/apigateway/">阿里云 API 网关</a></li><li>  <a href="https://cloud.tencent.com/product/apigateway">腾讯云 API 网关</a></li></ul><h4 id="其他方案"><a href="#其他方案" class="headerlink" title="其他方案"></a>其他方案</h4><ul><li>  基于 Netty、非阻塞 IO 模型。</li><li>  基于 Node.js 的方案。这种方案是应用了 Node.js 的非阻塞的特性。</li><li>  基于 Java，如 <a href="https://docs.mulesoft.com/general/">MuleSoft</a></li></ul></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;API网关的功能用途及实现方式 - 东风微鸣技术博客&lt;br&gt;&lt;a href=&quot;https://ewhisper.cn/posts/52291/&quot;&gt;https://ewhisper.cn/posts/52291/&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;h2 id=&quot;1-</summary>
      
    
    
    
    <category term="API网关" scheme="http://zhangyu.info/categories/API%E7%BD%91%E5%85%B3/"/>
    
    
    <category term="API网关" scheme="http://zhangyu.info/tags/API%E7%BD%91%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>基于容器的PaaS混合云的几种形式</title>
    <link href="http://zhangyu.info/2022/04/30/%E5%9F%BA%E4%BA%8E%E5%AE%B9%E5%99%A8%E7%9A%84PaaS%E6%B7%B7%E5%90%88%E4%BA%91%E7%9A%84%E5%87%A0%E7%A7%8D%E5%BD%A2%E5%BC%8F/"/>
    <id>http://zhangyu.info/2022/04/30/%E5%9F%BA%E4%BA%8E%E5%AE%B9%E5%99%A8%E7%9A%84PaaS%E6%B7%B7%E5%90%88%E4%BA%91%E7%9A%84%E5%87%A0%E7%A7%8D%E5%BD%A2%E5%BC%8F/</id>
    <published>2022-04-29T16:00:00.000Z</published>
    <updated>2022-04-30T09:25:35.098Z</updated>
    
    <content type="html"><![CDATA[<p> 基于容器的 PaaS 混合云的几种形式 - 东风微鸣技术博客<br><a href="https://ewhisper.cn/posts/57201/">https://ewhisper.cn/posts/57201/</a>) </p><blockquote><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>这是 Gartner 的一个图，提供了全球的基于容器的 PaaS 公有云、混合云服务的梳理展示：<br><a href="https://pic-cdn.ewhisper.cn/img/2021/09/17/a11d88b4ce770c547025af0bee5102bb-v2-c3e894db6f71442f6f959b09f8ed5cc1_b.jpeg"><img src="https://pic-cdn.ewhisper.cn/img/2021/09/17/a11d88b4ce770c547025af0bee5102bb-v2-c3e894db6f71442f6f959b09f8ed5cc1_b.jpeg"></a></p><p>这里提供一个其他的视角：<br>中国市场，基于容器的 PaaS 混合云（公有云 + 私有云）的相关厂商及产品。</p><p>❗️ 注意：</p><p>文章目前还是初版，只是厂商和产品的一个简单罗列，后面会进一步细化。<br>另外由于作者认知所限，无法罗列所有相关厂商和产品。请见谅。</p><h2 id="软件-容器平台"><a href="#软件-容器平台" class="headerlink" title="软件 - 容器平台"></a>软件 - 容器平台</h2><p>指的是通过售卖软件形式提供的容器平台（可能的售卖方式包括: 买断 + 维保；订阅），供应商不提供算力。<br>这里的「容器平台」指的是：基于 Kubernetes 的容器平台，有的容器平台会提供更丰富的功能，如：镜像仓库，监控，日志，Tracing，DevOps，微服务治理，ServiceMesh、Servless 等</p><ol><li> RedHat - OpenShift Container Platform</li><li> Rancher - RKE</li><li> 青云 - Kubesphere</li><li> 时速云 - TCS（TenxCloud Container Service）</li><li> 灵雀云 - ACP（Alauda Container Platform）</li><li> 博云 - BeyondContainer</li><li> DaoCLoud - DaoCloud Enterprise</li><li> 腾讯 - TKE Enterprise（基于灵雀云）</li><li> VMware - VSphere 7+</li></ol><h2 id="软件-多云容器管理平台"><a href="#软件-多云容器管理平台" class="headerlink" title="软件 - 多云容器管理平台"></a>软件 - 多云容器管理平台</h2><p>指的是通过售卖软件形式提供的多云容器管理平台（可能的售卖方式包括: 买断 + 维保；订阅），供应商不提供算力。<br>这里的「多云容器管理平台」指的是：基于 Kubernetes 的容器平台，或基于 Kubernetes 联邦（如华为 MCP），或基于自研多集群能力（如 Rancher），实现对异构、公有云及私有云的 Kubernetes 集群的纳管、甚至安装、运维、统一监控等能力。</p><p>❗️ 注意：</p><p>这类「多云容器管理平台」虽然可以纳管异构 Kubernetes 集群，但是某些高级功能，只有使用供应商推荐的 Kubernetes 产品才能使用。<br>如：Rancher 的安装、监控、日志等高级功能；RedHat 的安装、安全策略、GitOps 等功能</p><h3 id="优劣"><a href="#优劣" class="headerlink" title="优劣"></a>优劣</h3><p>优势：</p><ul><li>  灵活</li><li>  适用于：全内网环境（对于安全级别要求高的如金融行业会非常关注）</li></ul><p>劣势：</p><ul><li>  购买方需要提供硬件</li><li>  需要安装搭建，无法开箱即用</li></ul><h3 id="供应商及产品"><a href="#供应商及产品" class="headerlink" title="供应商及产品"></a>供应商及产品</h3><ol><li> Rancher - Rancher</li><li> 华为 - MCP（多云容器平台）</li><li> DaoCloud - DaoCloud Service Platform</li><li> RedHat - ACM（Advanced Cluster Management for Kubernetes）</li><li> 青云 - Kubesphere（<a href="https://kubesphere.com.cn/docs/multicluster-management/">Kubesphere 3.0 以后支持多集群管理</a>）</li><li> VMware - Tanzu</li></ol><h2 id="托管-公有云托管-K8S-集群"><a href="#托管-公有云托管-K8S-集群" class="headerlink" title="托管 - 公有云托管 K8S 集群"></a>托管 - 公有云托管 K8S 集群</h2><p>指的是公有云提供的 K8S 集群，提供公有云算力，也提供托管 Kubernetes 服务。计费方式为：按量计费或包年包月等。</p><p>✍️ 备注：</p><p>暂不包括公有云实例服务及 Servless 服务。</p><ol><li> Amazon - EKS（Elastic Kubernetes Service）</li><li> 阿里 - ACK（Alibaba Cloud Container Service for Kubernetes）</li><li> 腾讯 - TKE（Tencent Kubernetes Engine）</li><li> 微软 - AKS（Azure Kubernetes Service）</li><li> 华为 - CCE（云容器引擎）</li><li> 青云 - QKE（KubeSphere on QingCloud）</li></ol><h2 id="软件-公有云-K8S-集群产品私有化输出"><a href="#软件-公有云-K8S-集群产品私有化输出" class="headerlink" title="软件 - 公有云 K8S 集群产品私有化输出"></a>软件 - 公有云 K8S 集群产品私有化输出</h2><p>指的是通过售卖软件形式提供的和公有云架构类似的「公有云 K8S 集群产品私有化输出」（可能的售卖方式包括: 买断 + 维保；订阅），供应商不提供算力。</p><ol><li> 华为 - CCE（云容器引擎）</li><li> 阿里 - 阿里飞天专有云敏捷版</li><li> 腾讯 - TCS（Tencent Cloud-Native Suite）</li></ol><h2 id="托管-公有云多云容器管理平台"><a href="#托管-公有云多云容器管理平台" class="headerlink" title="托管 - 公有云多云容器管理平台"></a>托管 - 公有云多云容器管理平台</h2><p>指的是公有云提供的 多云容器管理平台，提供公有云算力，也提供管理 Kubernetes 服务。计费方式为：按量计费或包年包月等。<br>但是有个前提：如果是私有云 Kubernetes 集群或其他公有云提供商的 Kubernetes 集群，必须通过专线或互联网等形式与供应商网络联通。</p><h3 id="优劣-1"><a href="#优劣-1" class="headerlink" title="优劣"></a>优劣</h3><p>优势：</p><ul><li>  标准化产品，灵活性欠缺</li><li>  适用于：互联网环境</li><li>  按需付费</li><li>  开箱即用</li></ul><p>劣势：</p><ul><li>  无法纳管 没有互联网或连接公有云专线的 Kubernetes 集群</li><li>  安全性担忧</li><li>  <strong>对于被纳管集群的要求较多</strong>（如：EKS Anywhere 目前仅支持两种特定 Kubernetes 集群的纳管）</li></ul><h3 id="供应商及产品-1"><a href="#供应商及产品-1" class="headerlink" title="供应商及产品"></a>供应商及产品</h3><ol><li> 华为 - MCP（多云容器平台）</li><li> 腾讯 - <a href="https://mp.weixin.qq.com/s/aERPT13Rs_xgAnrOz2mmvg">TKE Everywhere</a>（❗️ 注意：这个和其他 2 家的 Anywhere 还不太一样，云上云下是 <strong>一个</strong> 集群，云下的 Node 由云上的 Master 纳管。本质上是一个边缘容器管理方案。而且还在内测中。）</li><li> Amazon - <a href="https://aws.amazon.com/cn/eks/eks-anywhere/">EKS Anywhere</a></li><li> 阿里云 - <a href="https://www.aliyun.com/product/kubernetes">AKS Anywhere</a></li></ol><p>🧠 <strong>思考：2 家 xxx Anywhere 具体是啥做法？</strong></p><p>2 家的 Anywhere 做法是极为一致的。本质上就是「公有云私有化，线上线下我全都要」。优势是：（兼听则明啊，经过实战检验才知道效果如何…）</p><ul><li>一致体验<ul><li>  统一集群管理</li><li>  统一资源调度</li><li>  统一数据容灾</li><li>  统一应用交付</li></ul></li><li>  弹性算力</li><li>能力下沉<ul><li>  云原生可观测</li><li>  安全防护能力</li><li>  中间件</li><li>  数据库</li><li>  数据分析</li><li>  AI</li></ul></li><li>  简化容灾</li></ul><p>以阿里云为例：<br>阿里云推出了一云多形态的部署架构，提供中心云、本地云、边缘云、云盒等多种部署形态，ACKAnywhere 的全面升级意味着公共云能力向本地化进一步延伸，客户在自建的数据中心内也能体验到低成本、低延迟、本地化的公共云产品。<br>随着云计算的普及和云原生技术的发展，容器服务已成为各大公司上云用云的必备基础设施。…此次升级的 ACK Anywhere 拥有「一致体验、弹性算力、能力下沉、简化容灾」四大核心能力，使企业在任何业务场景下使用容器服务时，都能实现「统一集群管理、统一资源调度、统一数据容灾和统一应用交付」。<br>得益于阿里云公共云丰富的产品能力，ACK Anywhere 可将成熟的云原生可观测、安全防护能力部署到用户环境，更可以将云端先进的中间件、数据分析和 AI 能力下沉到本地，满足客户对于产品丰富度以及数据管控的需求，加速业务创新。</p><p>业务连续性是现代企业 IT 架构关注的重点，ACK Anywhere 内建的备份中心，实现了备份、容灾、迁移一体化；支持 Kubernetes 集群配置与数据卷的备份恢复。结合阿里云丰富的业务多活容灾经验，帮助企业全面提升系统稳定性和业务连续性。</p><p>❗️ 注意：</p><p>由于上面所说的原因：「对于被纳管集群的要求较多」，所以这类产品往往也会推荐用户安装自己提供的 Kubernetes 产品，如：华为的 CCE，腾讯的 TKE 开源版，或 Amazon EKS Anywhere 的 <a href="https://aws.amazon.com/cn/eks/eks-distro/">EKS Distro</a> 产品，或阿里云的 ACK Distro。</p><h2 id="其他玩家"><a href="#其他玩家" class="headerlink" title="其他玩家"></a>其他玩家</h2><ol><li> 京东云</li><li> UCloud</li><li> 百度云</li><li> 金山云</li></ol></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; 基于容器的 PaaS 混合云的几种形式 - 东风微鸣技术博客&lt;br&gt;&lt;a href=&quot;https://ewhisper.cn/posts/57201/&quot;&gt;https://ewhisper.cn/posts/57201/&lt;/a&gt;) &lt;/p&gt;
&lt;blockquote&gt;
&lt;h2</summary>
      
    
    
    
    <category term="PaaS" scheme="http://zhangyu.info/categories/PaaS/"/>
    
    
    <category term="PaaS" scheme="http://zhangyu.info/tags/PaaS/"/>
    
  </entry>
  
  <entry>
    <title>打破Dockershim移除焦虑,且看Rancher如何应对</title>
    <link href="http://zhangyu.info/2022/04/30/%E6%89%93%E7%A0%B4Dockershim%E7%A7%BB%E9%99%A4%E7%84%A6%E8%99%91,%E4%B8%94%E7%9C%8BRancher%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9/"/>
    <id>http://zhangyu.info/2022/04/30/%E6%89%93%E7%A0%B4Dockershim%E7%A7%BB%E9%99%A4%E7%84%A6%E8%99%91,%E4%B8%94%E7%9C%8BRancher%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9/</id>
    <published>2022-04-29T16:00:00.000Z</published>
    <updated>2022-04-30T14:43:29.818Z</updated>
    
    <content type="html"><![CDATA[<p>打破 Dockershim 移除焦虑，且看 Rancher 如何应对<br><a href="https://mp.weixin.qq.com/s/swhQtu0pb_1AwQtMfTyd9Q">https://mp.weixin.qq.com/s/swhQtu0pb_1AwQtMfTyd9Q</a></p><blockquote><p><strong>前 言</strong></p><p>早在 2020 年 12 月，Kubernetes 就宣布将要弃用 Dockershim（<a href="https://kubernetes.io/blog/2020/12/02/dont-panic-kubernetes-and-docker/%EF%BC%89%E3%80%82%E5%9C%A8">https://kubernetes.io/blog/2020/12/02/dont-panic-kubernetes-and-docker/）。在</a> Kubernetes 中，Dockershim 是一个适配器组件，Dockershim 适配器允许 Kubelet 与 Docker 交互，就好像 Docker 是一个与 CRI 兼容的运行时一样。</p><p>Kubernetes 即将发布的 v1.24 版本最主要的变化就是删除了 Dockershim（<a href="https://github.com/kubernetes/enhancements/issues/2221%EF%BC%89%E3%80%82%E4%B9%9F%E5%B0%B1%E6%98%AF%E8%AF%B4%EF%BC%8CKubernetes">https://github.com/kubernetes/enhancements/issues/2221）。也就是说，Kubernetes</a> v1.24 无法再通过 in-tree 的形式来支持 Docker 作为它的 CRI 运行时。</p><p>随着 Kubernetes 的发展， 虽然 Docker 日渐式微，但还是有大量用户群体离不开 Docker，或者说暂时无法切换到 containerd 或 CRI-O 作为它的 CRI 运行时。 Rancher 为了满足继续使用 Docker 作为 CRI 运行时的需求，通过 RKE 集群支持外部 Dockershim 继续使用 Docker 作为 CRI 运行时。</p><p>虽然 Rancher 最新的 v2.6.4 目前还不支持 Kubernetes v1.24，但早在 Kubernetes v1.21 中就采用了 Mirantis 和 Docker 宣布的上游开源社区外部 Dockershim （该项目称为 cri-dockerd：<a href="https://github.com/kubernetes/enhancements/issues/2221%EF%BC%89%E6%9D%A5%E7%A1%AE%E4%BF%9D">https://github.com/kubernetes/enhancements/issues/2221）来确保</a> RKE 集群可以继续使用 Docker。换句话说，你可以像之前一样继续基于 Docker Engine 构建 Kubernetes，唯一的区别就是 Dockershim 由内置方案变成了外部方案。</p><p>要启用外部 Dockershim，只需要在 RKE 配置中设置以下选项：</p><pre><code>enable_cri_dockerd: true    </code></pre><p>由于外部 Dockershim 的支持是从 RKE 创建的 Kubernetes 1.21 及以上的版本中开始支持，所以我们需要通过 RKE 创建一个 Kubernetes 1.21 及以上的 Kubernetes 版本才能支持这种方案。  </p><p>下面将演示如何在 RKE 创建的 Kubernetes 集群中启用外部 Dockershim。</p><p><strong>通过 RKE CLI 创建集群</strong></p><p>说明：</p><ul><li><p>  RKE 的安装及使用，请参考官方文档（<a href="http://docs.rancher.cn/rke%EF%BC%89%EF%BC%8C">http://docs.rancher.cn/rke），</a> 这里不再详细说明。</p></li><li><p>  本次 demo 使用的 RKE 版本为 `v1.3.9`。</p></li></ul><p><strong>配置RKE cluster.yml 文件</strong></p><p>在 RKE 的集群配置文件 cluster.yml 中通过增加  enable_cri_dockerd: true  选项来启用外部 Dockershim 支持。本例使用最精简文件示例，如需个性化设置，请根据需求调整选项：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">~$ cat cluster.yml</span><br><span class="line">nodes:</span><br><span class="line">  - address: 192.168.205.19</span><br><span class="line">    user: ubuntu</span><br><span class="line">    role:</span><br><span class="line">      - controlplane</span><br><span class="line">      - etcd</span><br><span class="line">      - worker</span><br><span class="line">enable_cri_dockerd: true</span><br></pre></td></tr></table></figure><blockquote><p><strong>通过 RKE 创建 Kubernetes 集群</strong></p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">~$ rke up</span><br><span class="line">INFO[0000] Running RKE version: v1.3.9</span><br><span class="line">INFO[0000] Initiating Kubernetes cluster</span><br><span class="line">INFO[0000] cri-dockerd is enabled for cluster version [v1.22.7-rancher1-2]</span><br><span class="line">INFO[0000] [certificates] GenerateServingCertificate is disabled, checking if there are unused Kubelet certificates</span><br><span class="line">INFO[0000] [certificates] Generating admin certificates and kubeconfig</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">INFO[1130] [ingress] ingress controller nginx deployed successfully</span><br><span class="line">INFO[1130] [addons] Setting up user addons</span><br><span class="line">INFO[1130] [addons] no user addons defined</span><br><span class="line">INFO[1130] Finished building Kubernetes cluster successfully</span><br></pre></td></tr></table></figure><blockquote><p><strong>确认启用 cri-dockerd</strong>  </p><p>集群创建成功后，连接到下游集群的主机查看进程，可以发现增加了一个 cri-dockerd 的进程：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@dev-1:~# ps -ef | grep cri-dockerd</span><br><span class="line">root     26211 25813  3 11:26 ?        00:04:13 &#x2F;opt&#x2F;rke-tools&#x2F;bin&#x2F;cri-dockerd --network-plugin&#x3D;cni --cni-conf-dir&#x3D;&#x2F;etc&#x2F;cni&#x2F;net.d --cni-bin-dir&#x3D;&#x2F;opt&#x2F;cni&#x2F;bin --pod-infra-container-image&#x3D;rancher&#x2F;mirrored-pause:3.6</span><br></pre></td></tr></table></figure><blockquote><p>Cri-dockerd 其实就是从被移除的 Dockershim 中，独立出来的一个项目。为 Docker Engine 提供了一个垫片（shim），可以通过 Kubernetes CRI 控制 Docker。这意味着你可以像以前一样继续基于 Docker Engine 构建 Kubernetes，只需从内置的 Dockershim 切换到外部的 Dockershim 即可。</p><p>接下来，我们再观察 Kubelet 的参数变化：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@dev-1:~# docker inspect kubelet</span><br><span class="line">            &quot;Entrypoint&quot;: [</span><br><span class="line">                ...</span><br><span class="line">                &quot;--container-runtime&#x3D;remote&quot;,</span><br><span class="line">                &quot;--container-runtime-endpoint&#x3D;&#x2F;var&#x2F;run&#x2F;Dockershim.sock&quot;,</span><br><span class="line">                ...</span><br><span class="line">            ],</span><br></pre></td></tr></table></figure><blockquote><p>可以看到，增加 enable_cri_dockerd: true 参数启动的 Kubernetes 集群增加了 --container-runtime=remote 和 --container-runtime-endpoint=/var/run/Dockershim.sock 两个 Kubelet 参数。通过这两个 Kubelet 参数可以设置 Kubernetes 集群利用外部 Dockershim 继续使用 Docker 作为 CRI 运行时。 </p><p><strong>通过 Rancher 创建 RKE 集群</strong></p><p>如果你是 Rancher 的长期用户，你肯定会知道从 Rancher UI 上创建的自定义集群就是通过 RKE 来去实现的。只不过通过 Rancher UI 创建的 RKE 集群可以省去配置 RKE cluster.yml 的烦恼，只需要从 UI 上做一些简单的配置即可。</p><p>本节，将给大家介绍如何通过 Rancher 创建 RKE 集群并启用外部 Dockershim 支持。</p><p><strong>安装 Rancher</strong></p><p>Rancher 的安装及使用，请参考官方文档，这里不再详细说明。因为 RKE 创建的Kubernetes 1.21 及以上的版本中才开始支持外部 Dockershim，并且只有 Rancher v2.6.x 才支持 Kubernetes 1.21 或以上版本。所以，我们本次示例选择 Rancher 2.6.4 作为 demo 环境。</p><p><strong>创建自定义集群</strong></p><p><img src="https://img01.sogoucdn.com/net/a/04/link?appid=100520033&url=https://mmbiz.qpic.cn/sz_mmbiz_png/0peJZSmaUqUcbsgHAnQdTkKXk0ia0N2YXLIvXEYiay5f0XPpZu0HkC4yLr2o5YNNkst1LEFcGVXTTDlPwZxERb6A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p><strong>通过 Edit as YAML 来设置 enable_cri_dockerd 参数值为 true</strong></p><p><img src="https://img01.sogoucdn.com/net/a/04/link?appid=100520033&url=https://mmbiz.qpic.cn/sz_mmbiz_png/0peJZSmaUqUcbsgHAnQdTkKXk0ia0N2YX91OOE4jouqebegsnhCHQfs8NgpzvFkiaUhIkKjEDHLd9adrDggiaerpA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>将 enable_cri_dockerd 的值修改为  true ，保存并创建集群</p><p><img src="https://img01.sogoucdn.com/net/a/04/link?appid=100520033&url=https://mmbiz.qpic.cn/sz_mmbiz_png/0peJZSmaUqUcbsgHAnQdTkKXk0ia0N2YXfrcnGKZCTFOE9nKk3AV0Fib9Fb6Z4clKC3uTibBXyu4JMcqvaWvIszhw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p><strong>确认启用 cri-dockerd</strong></p><p>可以参考上面“通过 RKE CLI 创建集群”章节的步骤去检查下游集群是否成功启用了 cri-docker，为了节省篇幅，这里就不重复说明。</p><p><strong>常见问题</strong></p><p><strong>问：如果要获得 Rancher 对上游 Dockershim 的支持，需要升级 Rancher 吗？</strong></p><p>答：对于 RKE，Dockershim 的上游支持从 Kubernetes 1.21 开始。你需要使用支持 RKE 1.21 的 Rancher 版本。详情请参见我们的支持矩阵。</p><p><strong>问：我目前的 RKE 使用 Kubernetes 1.20。为了避免出现不再支持 Dockershim 的情况，我是否需要尽早将 RKE 升级到 Kubernetes 1.21？</strong></p><p>答：在使用 Kubernetes 1.20 的 RKE 中，Dockershim 版本依然可用，而且在下一个发行版发行之前不会被弃用。有关时间线的更多信息，请参见 [Kubernetes Dockershim 弃用相关的常见问题](<a href="https://kubernetes.io/blog/2020/12/02/Dockershim-faq/#when-will-Dockershim-be-removed)%E3%80%82Kubernetes">https://kubernetes.io/blog/2020/12/02/Dockershim-faq/#when-will-Dockershim-be-removed)。Kubernetes</a> 会发出将会弃用 Dockershim 的警告，而 Rancher 在 RKE 中已经用 Kubernetes 1.21 缓解了这个问题。你可以按照计划正常升级到 1.21。</p><p><strong>问：如果不想再依赖 Dockershim，还有什么选择？</strong></p><p>答：你可以为 Kubernetes 使用不需要 Dockershim 支持的运行时，如 Containerd。RKE2 和 K3s 就是其中的两个选项。</p><p><strong>问：如果目前使用 RKE1，但想切换到 RKE2，可以怎样进行迁移？</strong></p><p>答：你可以构建一个新集群，然后将工作负载迁移到使用 Containerd 的新 RKE2 集群。Rancher 也在探索就地升级路径的可能性。</p><p><strong>问：如果已经通过 RKE 创建了 Kubernetes v1.21 以上的集群，当我切换到外部 Dockershim 时，是否会对集群有影响？</strong></p><p>答：没影响，因为容器运行时没有变化，Dockershim 只是由内置方案变成了外部方案。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;打破 Dockershim 移除焦虑，且看 Rancher 如何应对&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/swhQtu0pb_1AwQtMfTyd9Q&quot;&gt;https://mp.weixin.qq.com/s/swhQtu0pb_1A</summary>
      
    
    
    
    <category term="k8s" scheme="http://zhangyu.info/categories/k8s/"/>
    
    
    <category term="k8s" scheme="http://zhangyu.info/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>API网关为K8s容器应用集群提供强大的接入能力</title>
    <link href="http://zhangyu.info/2022/04/30/API%E7%BD%91%E5%85%B3%E4%B8%BAK8s%E5%AE%B9%E5%99%A8%E5%BA%94%E7%94%A8%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BE%9B%E5%BC%BA%E5%A4%A7%E7%9A%84%E6%8E%A5%E5%85%A5%E8%83%BD%E5%8A%9B/"/>
    <id>http://zhangyu.info/2022/04/30/API%E7%BD%91%E5%85%B3%E4%B8%BAK8s%E5%AE%B9%E5%99%A8%E5%BA%94%E7%94%A8%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BE%9B%E5%BC%BA%E5%A4%A7%E7%9A%84%E6%8E%A5%E5%85%A5%E8%83%BD%E5%8A%9B/</id>
    <published>2022-04-29T16:00:00.000Z</published>
    <updated>2022-04-30T07:58:02.175Z</updated>
    
    <content type="html"><![CDATA[<p>API网关为K8s容器应用集群提供强大的接入能力<br><a href="https://help.aliyun.com/document_detail/71623.html">https://help.aliyun.com/document_detail/71623.html</a></p><blockquote><h2 id="1-Kubernetes-集群介绍"><a href="#1-Kubernetes-集群介绍" class="headerlink" title="1. Kubernetes 集群介绍"></a>1. Kubernetes 集群介绍</h2><p>Kubernetes（k8s）作为自动化容器操作的开源平台已经名声大噪，目前已经成为容器玩家主流选择。Kubernetes在容器技术的基础上，增加调度和节点集群间扩展能力，可以非常轻松地让你快速建立一个企业级容器应用集群，这个集群主要拥有以下能力：</p><ul><li><p>  自动化容器的部署和复制</p></li><li><p>  随时扩展或收缩容器规模</p></li><li><p>  将容器组织成组，并且提供容器间的负载均衡</p></li><li><p>  很容易地升级应用程序容器的新版本</p></li><li><p>  提供容器弹性，如果容器失效就替换它</p></li></ul><p>下面是一个典型的Kubernetes架构图：</p><p><img src="http://help-docs-aliyun.aliyuncs.com/assets/pic/71623/cn_zh/1525425558172/d56441427680948fb56a00af57bda690.png"></p><h2 id="2-API网关作为Kubernetes集群的接入层架构"><a href="#2-API网关作为Kubernetes集群的接入层架构" class="headerlink" title="2. API网关作为Kubernetes集群的接入层架构"></a>2. API网关作为Kubernetes集群的接入层架构</h2><p>我们可以看到Kubernetes集群是有足够理由作为应用服务的首选，但是Kubernetes集群没有足够的接入能力，特别在大型应用中，它是不能够直接对用户提供服务的，否则会有非常大的安全风险。而API网关作为成熟的云产品，已经集成了非常丰富的接入能力，把API网关放在Kubernetes集群前面作为应用集群的接入服务使用，将大大提高Kubernetes集群的服务能力，可以作为标准的大型互联网应用的标准架构。下面是使用阿里云架构图：</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/4354359951/p96242.png"></p><p><strong>是否启用Ingress Control？</strong></p><p>从架构图中我们可以看到，API网关作为Kubernetes集群的桥头堡，负责处理所有客户端的接入及安全工作，API网关和Kubernetes集群中Ingress Control的内网SLB或者服务的内网SLB进行通信。具体什么时候用Ingress Control呢？如果Kubernetes集群内只有一个服务，网关直接和此服务关联的内网SLB进行通信最高效。如果Kubernetes集群内有多个服务，如果使用服务的内网SLB对网关提供服务，将会生成很多SLB，资源管理起来会比较麻烦，此时我们可以使用Ingress Control做Kubernetes中服务发现与七层代理工作，API网关的所有请求发送到Ingress Control关联的内网SLB上，由Ingress Control将请求分发到Kubernetes集群内的容器内，这样我们也只需要一个内网SLB就能将Kubernetes集群内的所有服务暴露出去了。</p><h2 id="3-API网关接入能力"><a href="#3-API网关接入能力" class="headerlink" title="3. API网关接入能力"></a>3. API网关接入能力</h2><p>读者要问了，接入了API网关具体能为整个架构带来哪些好处呢？下面我们列一下这种架构中，API网关具体能给整个应用带来什么价值。</p><p>1.API网关允许客户端和API网关使用多种协议进行通信，其中包括：</p><pre><code>* HTTP  * HTTP2  * WebScoket</code></pre><p>2.API网关使用多种方法保证和客户端之间的通信安全：</p><pre><code>* 允许定义API和APP之间的授权关系，只有授权的APP允许调用；* 全链路通信都使用签名验证机制，包括客户端和API网关之间的通信和API网关和后端服务之间的通信，保证请求在整个链路上不会被篡改；* 支持用户使用自己的SSL证书进行HTTPS通信；* 支持OPENID CONNECT；</code></pre><p>3.API网关具备iOS/Android/Java三种SDK的自动生成能力，并且具备API调用文档自动生成能力；</p><p>4.API网关支持入参混排能力，请求中的参数可以映射到后端请求中的任何位置；</p><p>5.API网关提供参数清洗能力，用户定义API的时候可以指定参数的类型，正则等规则，API网关会帮用户确认传输给后端服务的请求是符合规则的数据；</p><p>6.API网关支持流量控制能力，支持的维度为用户/APP/API；</p><p>7.API网关提供双向通信的能力；</p><p>8.API网关提供基于请求数/错误数/应答超时时间/流量监控报警能力，所有的报警信息会使用短信或者邮件在一分钟内发出；</p><p>9.API网关已经和阿里云的SLS产品打通，用户可以将所有请求日志自动上传到用户自己的SLS中，后继好对访问日志进行统计分析；</p><p>10.API网关支持Mock模式，在联调中这个能力非常方便；</p><p>11.API网关支持用户配置调用方的IP白名单和黑名单； 12.API网关结合阿里云的云市场，为Provider提供向API使用者收费的能力。</p><p>阿里云的API网关是一个上线数年的成熟云产品，在稳定性和性能方面，经过了时间和阿里云的工程师的不断打磨，有高性能需求的用户尽管放马过来。</p><h2 id="4-在阿里云快速配置Kubernetes集群和API网关"><a href="#4-在阿里云快速配置Kubernetes集群和API网关" class="headerlink" title="4. 在阿里云快速配置Kubernetes集群和API网关"></a>4. 在阿里云快速配置Kubernetes集群和API网关</h2><p>阿里云支持快速创建Kubernetes集群，同一个Region内的Kubernetes集群和API网关的集成也非常简单，下面我们来一步一步地在阿里云中配置出本文第二节中架构设计。第二节中的架构设计中，API网关和Kubernetes有两种结合的模式，一种是API网关将请求发送到Ingress Control前的SLB，由Ingress Control将请求路由到Kubernetes对应的节点中，第二种是API网关直接将请求发送到Kubernetes中服务前的SLB，由SLB直接将请求转发到Kubernetes中服务对应的节点中。第一种模式只需要Ingress Control前有一个SLB就可以了，由Ingress Contro做服务发现与路由，第二种模式每个服务前都需要申请一个SLB，适合并发量大的场景。</p><h2 id="4-1-Ingress-Control模式的配置方式"><a href="#4-1-Ingress-Control模式的配置方式" class="headerlink" title="4.1 Ingress Control模式的配置方式"></a>4.1 Ingress Control模式的配置方式</h2><h2 id="4-1-1-创建带有Ingress-Control组件的Kubernetes集群"><a href="#4-1-1-创建带有Ingress-Control组件的Kubernetes集群" class="headerlink" title="4.1.1 创建带有Ingress Control组件的Kubernetes集群"></a>4.1.1 创建带有Ingress Control组件的Kubernetes集群</h2><p>首先我们来通过控制台创建一个具备Ingress Control组件的Kubernetes集群。</p><p>1.进入Kubernetes集群管理控制台界面：<a href="https://cs.console.aliyun.com/#/k8s/cluster/list">https://cs.console.aliyun.com/#/k8s/cluster/list</a></p><p>2.点击左上角“创建Kubernetes集群”按钮，进入</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/4354359951/p96396.png"></p><p>3.在创建Kubernetes集群页面选择不同规格的，具体创建选项和常规创建参数一致，在组件配置子页面，需要注意勾选创建Ingress组件：</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/4354359951/p96275.png"></p><p>4.创建成功后可以在Kubernetes列表页面看到刚才创建的集群。</p><h2 id="4-1-2-在Kubernetes集群内创建一个多容器的服务"><a href="#4-1-2-在Kubernetes集群内创建一个多容器的服务" class="headerlink" title="4.1.2 在Kubernetes集群内创建一个多容器的服务"></a>4.1.2 在Kubernetes集群内创建一个多容器的服务</h2><p>现在集群有了，我们需要在集群内创建一个服务，这个服务由2个容器组成，每个容器都由最新的Tomcat镜像生成。容器的端口是8080，Ingress Control提供服务的端口是80。</p><p>1.进入Kubernetes集群管理控制台界面：<a href="https://cs.console.aliyun.com/#/k8s/cluster/list">https://cs.console.aliyun.com/#/k8s/cluster/list</a></p><p>2.进入Kubernetes集群的控制台页面后，点击左边菜单栏的“应用”菜单下的“无状态”按钮，进入应用列表页面后，点击右上角的“使用模板创建”按钮进入创建页面：</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/4354359951/p96278.png"></p><p>3.进入创建页面后，点击使用文本创建按钮，输入下面的资源编排文本点击上传按钮进行创建：</p><pre><code>apiVersion: apps/v1 kind: Deploymentmetadata:  name: tomcat-demo  labels:    app: tomcatspec:  replicas: 2  selector:    matchLabels:      app: tomcat  template:    metadata:      labels:        app: tomcat    spec:      containers:      - name: tomcat        image: tomcat:latest        ports:        - containerPort: 8080---apiVersion: v1kind: Servicemetadata:  name: tomcat-servicespec:  ports:  - port: 80    protocol: TCP    targetPort: 8080  selector:    app: tomcat  sessionAffinity: None  type: NodePort</code></pre><p>对这段编排模板创建文本做下解释：使用最新的Tomcat镜像创建两个容器的意思，容器的服务端口是8080，并且创建一个命名为tomcat-service的服务，对外服务的端口为80，映射到容器8080的端口；</p><p>好了，目前为止，我们已经创建了一个Kubernetes集群，并且在这个集群下面创建了两个容器，每个容器上面跑着一个最新的Tomcat。这两个容器组成一个无状态应用，并且组成了一个命名为tomcat-service的服务。我们可以进入无状态应用详情页面看到整个应用的运行情况。目前我们的API网关没有办法访问到这个服务，需要我们在Ingress Control上建立一条到这个服务的路由才能把全链路打通</p><h2 id="4-1-3-在Ingress-Control上给服务加上路由"><a href="#4-1-3-在Ingress-Control上给服务加上路由" class="headerlink" title="4.1.3 在Ingress Control上给服务加上路由"></a>4.1.3 在Ingress Control上给服务加上路由</h2><p>现在我们有应用了，还需要在Ingress Control上为这个应用建立一个服务，然后在服务上建立一条路由，这样API网关将请求发送给Ingress Control时，Ingress Control会根据配置的路由信息将请求代理到对应的应用节点上。</p><p>1.在容器服务控制台上点击“路由与负载均衡”菜单下的“服务”按钮，点击右上角的“创建”按钮；</p><p>2.在创建路由页面填写服务对应的域名，所监听的端口等：</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/5354359951/p96324.png"></p><h2 id="4-1-4-在API网关对Ingress-Control的内网SLB授权"><a href="#4-1-4-在API网关对Ingress-Control的内网SLB授权" class="headerlink" title="4.1.4 在API网关对Ingress Control的内网SLB授权"></a>4.1.4 在API网关对Ingress Control的内网SLB授权</h2><p>API网关如果要访问Ingress Control的内网SLB，需要增加VPC网络的授权，首先我们需要准备VPC的标识和内网SLB的实例ID，我们可以在SLB控制台获取。</p><p>1.在Kubernetes管理控制台的“服务于负载均衡”菜单下点击“服务”菜单，进入服务管理页面后，选择命名空间为”所有命名空间”后可以在列表中看到Ingress Control的内网SLB地址：</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/5354359951/p96341.png"></p><p>2.登录SLB控制台（<a href="https://slb.console.aliyun.com/%EF%BC%89%EF%BC%8C%E6%89%BE%E5%88%B0%E5%88%9A%E6%89%8D%E5%88%9B%E5%BB%BAKubernetes%E6%9C%8D%E5%8A%A1%E6%97%B6%E8%87%AA%E5%8A%A8%E5%88%9B%E5%BB%BA%E7%9A%84VPC%EF%BC%8C%E7%82%B9%E5%87%BB%E8%BF%9B%E5%8E%BB%E6%9F%A5%E7%9C%8B%E8%AF%A6%E6%83%85%EF%BC%8C%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E5%9C%A8%E8%BF%99%E4%B8%AA%E9%A1%B5%E9%9D%A2%E7%9C%8B%E5%88%B0VPC%E7%9A%84%E6%A0%87%E8%AF%86%EF%BC%9A">https://slb.console.aliyun.com/），找到刚才创建Kubernetes服务时自动创建的VPC，点击进去查看详情，我们可以在这个页面看到VPC的标识：</a></p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/5354359951/p96332.png"></p><p>好了，目前我们已经获取到了VPC的ID和SLB的实例ID,下面我们来创建API网关的授权：</p><p>3.进入API网关授权页面：<a href="https://apigateway.console.aliyun.com/#/cn-beijing/vpcAccess/list">https://apigateway.console.aliyun.com/#/cn-beijing/vpcAccess/list</a> ，点击右上角的创建授权按钮，弹出创建VPC授权的小页面，将刚才查询到的VPC标识和SLB实例ID填入到对应的内容中：</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/5354359951/p96333.png"></p><p>点击确认按钮后，授权关系就创建好了，需要记住刚才填写的授权名称。</p><h2 id="4-1-5-创建API"><a href="#4-1-5-创建API" class="headerlink" title="4.1.5 创建API"></a>4.1.5 创建API</h2><p>在API网关控制台创建API的时候，后端服务这块，有两点需要注意的：</p><p>1.我们需要填写刚才创建的VPC授权名称；</p><p>2.在创建API页面的常量参数添加一个名字为host，位置header的参数，参数值设置为4.1.3节中设置的路由中填写的域名。</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/5354359951/p96380.png"></p><h2 id="4-1-6-调用测试"><a href="#4-1-6-调用测试" class="headerlink" title="4.1.6 调用测试"></a>4.1.6 调用测试</h2><p>API建立好了以后，我们把API发布到线上就可以使用API网关的测试工具进行测试，看看能否将请求发送到刚才创建的Kubernetes集群中去。 我们进入刚才创建好的API的详情页面，点击左侧菜单中的调试API，进入调试页面。在调试页面填写好相应的参数，点击“发起请求”按钮。</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/5354359951/p96378.png"></p><p>我们可以看到，请求发送到了Kubernetes的集群中的容器中，并且收到了容器中tomcate的404的应答（因为没有配置对应的页面）。</p><h2 id="4-2-Kubernetes服务内网SLB结合模式的配置方式"><a href="#4-2-Kubernetes服务内网SLB结合模式的配置方式" class="headerlink" title="4.2 Kubernetes服务内网SLB结合模式的配置方式"></a>4.2 Kubernetes服务内网SLB结合模式的配置方式</h2><p>通过Kubernetes服务的SLB结合API网关与Kubernetes的模式的配置方式与前一节中通过Ingress Control结合模式的配置方式有两点不同：1.申请Kubernetes中的容器服务时，需要指定生成内网SLB，2.找到这个SLB的VPC ID与SLB ID，使用这两个ID到API网关去进行授权即可。上一节中描述的创建Kubernetes集群的步骤，本节不再冗余描述。本节主要描述创建携带内网SLB的Kubernetes服务，并且找到这个内网SLB的IP地址。在找到SLB的IP地址后，具体授权方法和4.1.4中描述的一致，本节也不再重复描述。</p><h2 id="4-2-1-生成携带内网SLB的Kubernetes服务"><a href="#4-2-1-生成携带内网SLB的Kubernetes服务" class="headerlink" title="4.2.1 生成携带内网SLB的Kubernetes服务"></a>4.2.1 生成携带内网SLB的Kubernetes服务</h2><p>在4.1.1操作之后，我们有了一个Kubernetes集群，现在我们通过资源编排文本在这个集群中创建带有内网SLB的服务。我们注意下，本段资源编排代码和4.1.2中的资源编排代码不同的是，我们把最后一行的Type变成了LoadBalancer，并且指定了这个SLBLoadBalancer为内网：</p><pre><code>apiVersion: apps/v1 kind: Deploymentmetadata:  name: tomcat-demo  labels:    app: tomcatspec:  replicas: 2  selector:    matchLabels:      app: tomcat  template:    metadata:      labels:        app: tomcat    spec:      containers:      - name: tomcat        image: tomcat:latest        ports:        - containerPort: 8080---apiVersion: v1kind: Servicemetadata:  name: tomcat-service  annotations:    service.beta.kubernetes.io/alicloud-loadbalancer-address-type: intranetspec:  ports:  - port: 80    targetPort: 8080    protocol: TCP  selector:    app: tomcat  type: LoadBalancer</code></pre><p>对这段编排模板创建文本做下解释：使用最新的Tomcat镜像创建两个容器的意思，容器的服务端口是8080，并且创建一个命名为tomcat-service的服务，这个服务前有一个内网SLB，对外服务的端口为80，映射到容器8080的端口。</p><h2 id="4-2-2-在Kubernetes控制台找到服务的内网SLB地址"><a href="#4-2-2-在Kubernetes控制台找到服务的内网SLB地址" class="headerlink" title="4.2.2 在Kubernetes控制台找到服务的内网SLB地址"></a>4.2.2 在Kubernetes控制台找到服务的内网SLB地址</h2><p>现在我们成功创建了一个携带内网SLB的服务，我们可以在Kubernetes控制台的“路由与负载均衡”菜单的“服务”子页面找到这个内网SLB的内网IP：</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/5354359951/p96549.png"></p><p>找到内网SLB之后，就可以像4.1.4中一样，去SLB的控制台找到这个SLB的VPC ID和SLB ID，并且使用这个SLB的VPC ID和SLB ID到API网关去授权了。</p><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5 总结"></a>5 总结</h2><p>让我们总结一下本文的内容，在前三节中，我们描述了Kubernetes集群和API网关的各项能力，并且画出了结合他俩作为后端应用服务生产的架构图。我们结合API网关+Kubernetes集群的架构，让系统具备了动态伸缩，动态路由，支持多协议接入，SDK自动生成，双向通信等各项能力，成为可用性更高，更灵活，更可靠的一套架构。</p><h2 id="5-1-配置总结"><a href="#5-1-配置总结" class="headerlink" title="5.1 配置总结"></a>5.1 配置总结</h2><p>在最后一节，我们描述了在阿里云的公有云如何创建一整套API网关加Kubernetes的流程，关键点在于Kubernetes集群通过Ingress Control组件服务发现，在API网关对Ingress Control组件的内网SLB进行授权后，将所有请求发送到SLB上。下面我们再总结一下通过Ingress结合API网关与Kubernetes的步骤：</p><ol><li><p> 创建一个带有Ingress Control组件的Kubernetes的集群；</p></li><li><p> 使用资源编排命令，在Kubernetes集群中创建两个运行这最新版本的Tomcat的容器，并且基于这两个容器创建对应的服务；</p></li><li><p> 在控制台上给Ingress Control加上一条服务路由；</p></li><li><p> 到SLB控制台找到Ingress Control内网SLB的实例ID，在API网关创建一个VPC授权；</p></li><li><p> 在API网关创建API，后端服务使用刚才创建的VPC授权，并且设定一个名为host的参数，参数值使用Ingress Control服务路由设置的域名。API的请求将发送到Kubernetes集群的Ingress Control的SLB上，由Ingress Control将请求路由到容器内部的Tomcat服务上。</p></li></ol><p>在高并发场景或者只有一个服务的场景，我们可以跳过Ingress Control，直接在服务前面架设一个内网SLB，并且将这个内网SLB授权给API网关，供API网关进行访问。</p><h2 id="5-2-Ingress-Control和SLB两种方案对比"><a href="#5-2-Ingress-Control和SLB两种方案对比" class="headerlink" title="5.2 Ingress Control和SLB两种方案对比"></a>5.2 Ingress Control和SLB两种方案对比</h2><p>1. 使用SLB+Ingress Control。Ingress Control可以做Kubernetes集群的服务发现和七层代理工作，如果Kubernetes集群中有多个服务，可以统一使用Ingress Control进行路由，同时只需要一个内网SLB就可以对外暴露多个服务。便于运维管理和Kubernetes集群的服务扩充。推荐使用此种方式。</p><p>2. 直接使用SLB。如果集群中某个服务的业务压力很大，可以考虑为此服务单独建立一个SLB，API网关直接连接此SLB，从而达到更高的通信效率。此种方式的弊端也比较明显，如果Kubernetes集群内有多个服务，需要为每个服务配置一个SLB，因此给运维管理带来较大工作量。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;API网关为K8s容器应用集群提供强大的接入能力&lt;br&gt;&lt;a href=&quot;https://help.aliyun.com/document_detail/71623.html&quot;&gt;https://help.aliyun.com/document_detail/71623.ht</summary>
      
    
    
    
    <category term="API网关" scheme="http://zhangyu.info/categories/API%E7%BD%91%E5%85%B3/"/>
    
    
    <category term="API网关" scheme="http://zhangyu.info/tags/API%E7%BD%91%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>云原生环境下的日志采集、存储、分析实践</title>
    <link href="http://zhangyu.info/2022/04/30/%E4%BA%91%E5%8E%9F%E7%94%9F%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%9A%84%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86-%E5%AD%98%E5%82%A8-%E5%88%86%E6%9E%90%E5%AE%9E%E8%B7%B5/"/>
    <id>http://zhangyu.info/2022/04/30/%E4%BA%91%E5%8E%9F%E7%94%9F%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%9A%84%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86-%E5%AD%98%E5%82%A8-%E5%88%86%E6%9E%90%E5%AE%9E%E8%B7%B5/</id>
    <published>2022-04-29T16:00:00.000Z</published>
    <updated>2022-04-30T09:51:45.713Z</updated>
    
    <content type="html"><![CDATA[<p> 以下文章来源于火山引擎开发者社区<br>作者：刘卯银｜火山引擎日志系统架构师</p><p>云原生环境下的日志采集、存储、分析实践<br><a href="https://mp.weixin.qq.com/s/L2bPGFL2cNamaFrxeyU48Q">https://mp.weixin.qq.com/s/L2bPGFL2cNamaFrxeyU48Q</a></p><blockquote><p>谈到日志系统，首先要从日志说起，日志在 IT 系统里无处不在，也是 IT系统大数据的关键来源。日志的种类和样式非常多，以在线教育系统为例，日志包括客户端日志、服务端日志。服务端日志又包括业务的运行/运维日志以及业务使用的云产品产生的日志。要管理诸多类型的日志，就需要一套统一的日志系统，对日志进行采集、加工、存储、查询、分析、可视化、告警以及消费投递，将日志的生命周期进行闭环。</p><p>Kubernetes 下日志采集的开源自建方案</p><p><strong>开源自建</strong></p><p>火山引擎早期为了快速上线业务，各团队基于开源项目搭建了自己的日志系统，以满足基本的日志查询需求，例如使用典型的开源日志平台 <strong>Filebeat+Logstash+ES+Kibana</strong> 的方案。但是在使用过程中，我们发现了开源日志系统的不足：</p><ul><li><p>  各业务模块自己搭建日志系统，造成重复建设。</p></li><li><p>  以 ES 为中心的日志架构可以利用 ES 查询便利的优势，但是资源开销大、成本高。而且 ES 与 Kibana 在界面上强绑定，不利于功能扩展。</p></li><li><p>  开源方案一般采用单机 yaml 做采集配置，当节点数很多的时候，配置非常繁琐。</p></li><li><p>  开源系统的采集配置难以管理，数据源也比较单一。</p></li></ul><p><img src="https://mmbiz.qpic.cn/mmbiz_png/fgbJnuXT4EqeiaZn0NZBVcfngVp083FmjVjJ2EheTOKXIWcL2QCrDNF5t1ujPv14aWR6ytFwRdS7iaEnkbImdZ2w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p><strong>Kubernetes 下的日志采集</strong></p><p>Kubernetes 下如何采集日志呢？官方推荐了四种日志采集方案：</p><ul><li><p>  DaemonSet：在每台宿主机上搭建一个 DaemonSet 容器来部署 Agent。业务容器将容器标准输出存储到宿主机上的文件，Agent 采集对应宿主机上的文件。</p></li><li><p>  Streaming Sidecar：有一些业务系统的日志不是标准输出，而是文件输出。Streaming Sidecar 的方式可以把这些文件输出通过 Sidecar 容器转换成容器的标准输出，然后采集。</p></li><li><p>  Sidecar Logging Agent：业务 Pod 内单独部署 Agent 的 Sidecar 容器。这种方式的资源隔离性强。</p></li><li><p>  API/SDK：直接在容器内使用 API 或 SDK 接口将日志采集到后端。</p></li></ul><p>以上前三种采集方案都只支持采集容器的标准输出，第四种方案需要改造业务代码，这几种方式对采集容器文件都不友好。但用户对于日志文件有分类的需求，标准输出将所有日志混在一起，不利于用户进行分类。如果用户要把所有日志都转到标准输出上，还需要开发或者配置，难以推广。因此 Kubernetes 官方推荐的方案无法完全满足用户需求，给我们的实际使用带来了很多不便。</p><p><strong>自建日志采集系统的困境与挑战</strong></p><p>云原生场景下<strong>日志种类多、数量多、动态非永久</strong>，开源系统在采集云原生日志时面临诸多困难，主要包括以下问题：</p><p><strong>一、采集难</strong></p><ul><li><p>  <strong>配置复杂</strong>：系统规模越来越大，节点数越来越多，每个节点的配置都不一样，手工配置很容易出错，系统的变更变得非常困难。</p></li><li><p>  <strong>需求不满足</strong>：开源系统无法完全满足实际场景的用户需求，例如不具备多行日志采集、完整正则匹配、过滤、时间解析等功能，容器文件的采集也比较困难。</p></li><li><p>  <strong>运维难度高</strong>：大规模场景下大量 Agent 的升级是个挑战，系统无法实时监控 Agent 的状态，当Agent 状态异常时也没有故障告警。</p></li></ul><p><strong>二、产品化能力不足</strong></p><ul><li><p>  <strong>可用性低</strong>：因为缺少流控，突发的业务容易使后端系统过载，业务之间容易相互影响。</p></li><li><p>  <strong>资源使用效率低</strong>：如果配置的资源是固定的，在突发场景下容易造成性能不足的问题；但如果配置的资源过多，普通场景下资源利用率就会很低；不同的组件配置不均衡还会导致性能瓶颈浪费资源。ES 的原始数据和索引使用相同的资源配置，也会导致高成本。</p></li><li><p>  <strong>功能不足</strong>：比如 ES 的投递和消费能力弱、分析能力固化、没有告警能力、可视化能力有限。</p></li></ul><p>火山引擎统一日志平台 TLS  </p><p>在遇到这些问题以后，我们研发了一套统一的日志管理平台——**火山引擎日志服务（Tinder Log Service，简称为 TLS)**。TLS 的整体架构如下：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/fgbJnuXT4EqeiaZn0NZBVcfngVp083FmjYA33Zyhiav3lzlJhTQemLCOh6K6cfWrQ2xIh0h7ibdBH5JV63wKUOQOw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>面对各种日志源，TLS 通过自研的 LogCollector/SDK/API，可支持专有协议、 OpenTelemetry 和 Kafka 协议上传日志。支持多种类型的终端、多种开发语言以及开源生态标准协议。</p><p>采集到的日志首先会存入<strong>高速缓冲集群</strong>，削峰填谷，随后日志会匀速流入<strong>存储集群</strong>，根据用户配置再流转到<strong>数据加工集群</strong>进行日志加工，或者到<strong>索引集群</strong>建立索引。建立索引后用户可以进行实时查询和分析。TLS 提供标准的 Lucene 查询语法、SQL 92 分析语法、可视化仪表盘以及丰富的监控告警能力。</p><p>当日志存储达到一定周期，不再需要实时分析之后，用户可以把日志投递到成本更低的火山引擎对象存储服务中，或者通过 Kafka 协议投递到其他云产品。如果用户有更高阶的分析需求，TLS 也支持把日志消费到实时计算、流式计算或离线计算进行更深入的分析。</p><p>TLS 的系统设计遵循<strong>高可用、高性能、分层设计</strong>的原则。</p><ul><li><p>  <strong>高可用</strong>：通过存算分离，所有服务都是无状态的，故障快速恢复。</p></li><li><p>  <strong>高性能</strong>：所有集群都可横向扩展，没有热点。</p></li><li><p>  <strong>分层设计</strong>：各模块之间低耦合，模块之间定义标准接口，组件可替换。</p></li></ul><p>以上就是火山引擎自研的日志存储平台 TLS 的系统架构，下面将详细介绍 TLS 相较于开源系统做的优化。</p><p><strong>系统优化</strong></p><p><strong>中心化白屏化的配置管理</strong></p><p>当日志系统中采集 Agent 数量较多时，不再适合在每台机器上手工配置，因此我们开发了中心化、白屏化的配置管理功能，支持动态下发采集配置，并支持查看 Agent 运行状态监控、支持客户端自动升级。</p><p>中心化配置的实现流程如下：</p><ol><li><p> 客户端主动向服务端发起心跳，携带自身版本信息。</p></li><li><p> 服务端收到心跳，检查版本。</p></li><li><p> 服务端判断是否需要下发配置信息给客户端。</p></li><li><p> 客户端收到配置信息，热加载到本地配置，以新的配置进行采集。</p></li></ol><p><img src="https://mmbiz.qpic.cn/mmbiz_png/fgbJnuXT4EqeiaZn0NZBVcfngVp083FmjqSrAjh32gBkHzHr4KHbRSSCDGPZXJbW1SibapEZmrKRVxWkS4TEB45w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>中心化配置管理的优势在于：</p><ul><li><p>  可靠：中心化管理，配置不丢失，白屏化配置不容易出错。</p></li><li><p>  高效：各种环境下所有的配置都是统一处理，无论 LogCollector 部署在移动端、容器还是物理机上，用户都可以在服务端相同的界面上配置，配置以机器组为单位批量下发，快速高效。</p></li><li><p>  轻松运维：用户可以在服务端查看客户端的运行状态，对客户端的异常发出告警。通过中心化配置，TLS 可以向客户端推送最新版本，自动升级。</p></li></ul><p><strong>CRD 云原生配置方式</strong></p><p>中心化、白屏化的配置方式是适合运维人员的配置方式。在开发测试自动化的场景下，最优的方式是 CRD。传统的方式通过 API 接口去做采集配置，用户通常需要写数千行代码来实现。TLS 提供了云原生 CRD 的方式来进行配置，用户只需要在 yaml 文件里配置要采集的容器、容器内的日志路径以及采集规则即可完成采集配置。因为不再需要编写代码，CRD 方式大幅提高了日志接入效率。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/fgbJnuXT4EqeiaZn0NZBVcfngVp083FmjYP0hTUYJJwLgzT60iasNJwsicvYG5Jj6eqXbTcInZ3XFDjGEaUDibZSyw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>CRD 的配置流程如下：</p><ol><li><p> 使用 Kubectl 命令创建 TLS LogConfig CRD；</p></li><li><p> TLS Controller 监听到 CRD 配置更新；</p></li><li><p> TLS Controller 根据 CRD 配置向 TLS Server 发送命令，创建 topic、创建机器组，创建日志采集配置；</p></li><li><p> LogCollector 定期请求 TLS Server，获取新的采集配置并进行热加载；</p></li><li><p> LogCollector 根据采集配置采集各个容器上的标准输出或文本日志；</p></li><li><p> LogCollector 将采集到的日志发送给 TLS Server。</p></li></ol><p><strong>适合大规模、多租户场景的客户端</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/fgbJnuXT4EqeiaZn0NZBVcfngVp083FmjEB0Hw5nv6B6SibRJVfvjQhHrSEkUWKcueLCwZLRvbTiaJMHaDnOB1HOw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>开源日志采集客户端一般只支持一个 Output，多个 Input 采用相同的 Pipeline，相互影响。为了适应大规模、多租户场景，火山引擎自研了日志采集的客户端 LogCollector。LogCollector 对不同的 Input 采用不同的 Pipeline 做资源隔离，减少多租户之间的相互影响。一个 LogCollector 支持多个 Output，可以根据不同的 Output 单独做租户鉴权。同时我们还在 LogCollector 内实现了自适应反压机制，如果服务端忙碌，LogCollector 会自动延迟退避，服务端空闲时再发送，减少算力负担。</p><p><strong>产品优化</strong></p><p><strong>可用性提升</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/fgbJnuXT4EqeiaZn0NZBVcfngVp083Fmjic1FUdj20kJXxkxgzQCQt19sJekvm0ficRQh14rny7h8KQVNYZ4IFLQg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>在可用性方面，TLS 支持多级全局流控，能杜绝因业务突发导致的故障扩散问题。</p><ul><li><p>  在日志采集到高速缓冲集群时，按照用户的 Shard 数控制写入高速缓冲区的流量。</p></li><li><p>  当数据从高速缓冲区流向存储集群时，按存储集群控制单个存储集群的流量。</p></li><li><p>  从存储集群到索引集群，按索引集群控制单个索引集群的写入流控以及查询分析并发数。</p></li></ul><p><strong>效率提升</strong></p><p><strong>索引和原始数据分离</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/fgbJnuXT4EqeiaZn0NZBVcfngVp083FmjZWzzN512awjorhGKgnDNk5YJujrX5DpKfEibfUnOaO0j7NO0PcAVayA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>ES 的索引和数据存在一起，我们在设计过程发现索引和原始数据分离会更优，主要表现在：</p><ul><li><p>  提升数据流动性：存储集群支持批量消费接口，消费数据不经过索引集群。相对于从索引集群先查询后消费的模式，直接从存储集群消费性能更高，有效提升数据流动性。</p></li><li><p>  降低成本：索引和存储可以采用不同成本的存储，整体的存储成本就会降低。用户可以随时按需创建索引，进一步降低索引成本。</p></li><li><p>  提升可用性：索引可以异步创建，流量突发时创建索引慢不会影响存储写入速率。</p></li></ul><p><strong>索引管理和调度</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/fgbJnuXT4EqeiaZn0NZBVcfngVp083FmjomGWwa6uDIge2s5E3JSUYvXtpjyfNFgMgRNNsA3fcGdjC6D1PcCmicA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>索引的流量是不可预测的，因此我们在效率方面的另一个优化是支持索引的管理和调度，实现弹性伸缩，从而提升可用性，解决规模问题。我们的解决方案是在多个索引集群之间做数据流动，基于负载、资源、容量自动迁移索引，支持动态跨集群在线迁移索引，平衡索引集群负载。  </p><p><strong>功能优化</strong></p><ul><li>  <strong>消费投递</strong>：在消费投递方面我们支持了丰富的消费投递接口，包括：</li></ul><ul><li><p>  消费者</p></li><li><p>  消费组</p></li><li><p>  Kafka 协议：通过 Kafka 协议进行标准协议的消费；</p></li><li><p>  S3 协议：支持通过 S3 对象存储的协议把日志投递到对象存储。</p></li></ul><p><img src="https://mmbiz.qpic.cn/mmbiz_png/fgbJnuXT4EqeiaZn0NZBVcfngVp083Fmj0sTazoYHCq7VCMRTENlib89eGtJxdu3bXmBh871Gb0mAGicrxy9iaxTJw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><ul><li><p>  <strong>查询分析</strong>：支持先查询过滤后分析，减少分析数据量提高性能。分析支持标准的 SQL 92，分析结果支持图表可视化。</p></li><li><p>  <strong>日志告警</strong>：通过实时监控日志，基于用户配置的监控规则组合以及告警触发条件，满足条件就可以通过短信、邮件、飞书等方式发送告警给用户或用户组。</p></li><li><p>  <strong>可视化仪表盘</strong>：TLS 提供多种可视化仪表盘，实现实时监测，且仪表盘可以关联告警。</p></li></ul><p>TLS 实践案例</p><p>接下来为大家介绍两个 TLS 的典型案例。</p><p><strong>火山引擎内部业务及运维日志采集</strong></p><p>TLS 目前支撑了火山引擎全国多个 Region 运维日志的采集分析。日志类型包括业务的文件日志、容器标准输出。业务分别部署在内网、外网以及混合云，日志都通过 TLS 平台统一做采集和分析。</p><p>相较于前期各业务模块自己搭建日志系统，采用 TLS 获得了如下收益：</p><ul><li><p>  经济高效：资源利用率由之前的 20% 提升到现在的 **80%**，大幅降低资源成本；</p></li><li><p>  可用性较高：多级流控加缓存，抗突发能力强，即使在索引系统故障的时候也不会影响原始数据的流量；</p></li><li><p>  轻松运维：TLS 的统一运维提升了运维人员的能力，少量运维人员即可完成整个系统的运维。</p></li><li><p>  快速接入：TLS 可以在一小时内完成一个新业务的采集、查询、分析、消费的快速接入。</p></li></ul><p><strong>某教育行业头部客户日志采集</strong></p><p>该客户的系统业务主要采集的日志包括：</p><ul><li><p>  文件日志</p></li><li><p>  App 日志</p></li><li><p>  Kubernetes 集群后端业务的日志</p></li><li><p>  用户行为日志</p></li></ul><p>TLS 把这几个平台的日志统一采集到云端，进行实时查询分析以及进行告警。客户自建有大数据分析平台，TLS 可将日志数据通过消费的方式流转到该平台进行在线、离线等更高阶的大数据分析。对于时间长的历史数据，则投递到对象存储进行归档，从而降低整个系统的成本。</p><p>用户的管理员可在 TLS 上统一查看所有平台的各种日志，整个系统的建设和运维成本也降低了。TLS 使用标准接口，可以兼容云上自建的分析平台，用户在快速上线的同时也能保证系统的高度兼容。</p><p>展望未来</p><p>未来，TLS 平台会不断进行更深层次的优化：</p><ul><li><p>  云产品的一键日志采集</p></li><li><p>  搜索引擎的深度优化</p></li><li><p>  数据清洗和加工的函数式接口</p></li><li><p>  集成更多第三方平台，火山引擎云产品深度融合</p></li></ul><p><strong>Q&amp;A</strong></p><p><strong>Q：中心化配置，各个业务的日志采集配置是 OP 负责还是 RD 负责？</strong><br><strong>A</strong>：日志采集的中心化配置是 Web 方式，配置非常简单，无论是 RD 或是 OP 负责都可以。火山引擎上 Web 配置由 OP 来负责，容器自动化采集是用 CRD 的方式，一般是 RD 负责。</p><p><strong>Q：采集端 Agent 的使用资源可以限制吗？是否会影响业务的资源使用？</strong><br><strong>A</strong>：CPU 占用量、内存占用量这些是可以配置的，不会影响业务的资源使用。</p><p><strong>Q：CRD 和中心化配置不会冲突吗？</strong><br><strong>A</strong>：通常情况下不会冲突。CRD 有特定的命名规则，只要 Web 配置和 CRD 配置的名字不冲突就不会报错。如果名字冲突，配置会失败，改名字后重试即可。</p><p><strong>Q：Node 节点宕机是否会丢日志？</strong><br><strong>A</strong>：不会。LogCollector 有 Checkpoint，Checkpoint 会定期更新。如果节点宕机没有更新 Checkpoint，日志会从上次 Checkpoint 点重新采集，所以是不会丢的。</p><p><strong>Q：日志采集的延迟情况如何？</strong><br><strong>A</strong>：一般在秒级延迟，后端业务忙的时候可能是几秒到十几秒的延迟。</p><p><strong>Q：Kafka 协议是如何暴露的？通过实现 Kafka Server 吗？</strong><br><strong>A</strong>：我们是在服务端实现的 Kafka 协议。用户以 Kafka 的协议方式接入，鉴权也是以 Kafka 的鉴权协议来做的。用户看到的其实就是一个 Kafka。这样可以对用户做到透明。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; 以下文章来源于火山引擎开发者社区&lt;br&gt;作者：刘卯银｜火山引擎日志系统架构师&lt;/p&gt;
&lt;p&gt;云原生环境下的日志采集、存储、分析实践&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/L2bPGFL2cNamaFrxeyU48Q&quot;&gt;https:/</summary>
      
    
    
    
    <category term="日志" scheme="http://zhangyu.info/categories/%E6%97%A5%E5%BF%97/"/>
    
    
    <category term="日志" scheme="http://zhangyu.info/tags/%E6%97%A5%E5%BF%97/"/>
    
  </entry>
  
  <entry>
    <title>公有云降本增效最佳实践</title>
    <link href="http://zhangyu.info/2022/04/30/%E5%85%AC%E6%9C%89%E4%BA%91%E9%99%8D%E6%9C%AC%E5%A2%9E%E6%95%88%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
    <id>http://zhangyu.info/2022/04/30/%E5%85%AC%E6%9C%89%E4%BA%91%E9%99%8D%E6%9C%AC%E5%A2%9E%E6%95%88%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</id>
    <published>2022-04-29T16:00:00.000Z</published>
    <updated>2022-04-30T07:57:55.662Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://ewhisper.cn/posts/59535/">https://ewhisper.cn/posts/59535/</a></p><blockquote><h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><h3 id="整体"><a href="#整体" class="headerlink" title="整体"></a>整体</h3><h4 id="首选公有云服务而非自建"><a href="#首选公有云服务而非自建" class="headerlink" title="首选公有云服务而非自建"></a>首选公有云服务而非自建</h4><p>公有云除了提供 IaaS（计算、存储、网络等）外，也会提供 PaaS（微服务、中间件、数据库、大数据、开发套件等）和 SaaS 服务。</p><p>在公有云提供的服务（如 MySQL 数据库）可以满足需求的前提下，建议首选公有云上的 MySQL 数据库服务，而非自建。</p><p>理由简单说明如下：</p><p>对比项</p><p>成本</p><p>性能</p><p>伸缩性</p><p>维护方</p><p>可靠性</p><p>监控</p><p>易用性</p><p>自建</p><p>高</p><p>低</p><p>弱</p><p>我方</p><p>低</p><p>无</p><p>难</p><p>云上服务</p><p>中</p><p>高</p><p>高</p><p>云提供商</p><p>高</p><p>有</p><p>易用</p><ul><li><strong>成本</strong>：<ul><li>  自建，需要人员维护和优化的成本，需要自行考虑高可靠（可能需要购买多台服务器）和高性能（可能需要购买高性能存储），使得成本偏高。</li><li>  云上服务，通过规模效应、资源池化、参数调优等实现成本相对不高。</li></ul></li><li><strong>性能</strong>：<ul><li>  自建，不一定知道所有的参数优化项，也不一定同价位能买到专用的高性能硬件。</li><li>  云上服务，性能明码标价，按需选择适合自己的性能配置。</li></ul></li><li><strong>伸缩性</strong><ul><li>  自建，伸缩较麻烦，要不手动，要不通过 历经检验的 DevOps 脚本，伸缩性弱。</li><li>  云上服务，很多 PaaS 类服务可以一键升配。</li></ul></li><li><strong>维护方</strong><ul><li>  自建，我方自行兜底</li><li>  云上服务，云提供商提供 SLA 兜底。</li></ul></li><li><strong>可靠性</strong><ul><li>  自建，不一定能实现该组件的集群模式或高可用模式的全部最佳实践。</li><li>  云上服务，会做好网络高可用（甚至是跨 AZ 的高可用）、存储多副本、计算跨物理服务器 / 机架 /AZ 甚至 region、服务监控及自愈、备份等多种措施保障可靠性。</li></ul></li><li><strong>监控</strong>：<ul><li>  自建，要不没监控，要不监控需要从头（采集端）到尾（告警通知）实现一遍</li><li>  云上服务，监控具备，且和公有云监控无缝对接。</li></ul></li><li><strong>易用性</strong>：<ul><li>  自建：一般没有 Web 界面，需要通过线下或流程平台或 CLI 来申请和操作</li><li>  云上服务：有易用的 web 界面，可以在 web 界面上完成大部分功能。</li></ul></li></ul><p>比如云数据库：</p><ul><li>运维架构：<ul><li>  存储的数据规模及后期扩展，采用的高可用架构；</li><li>  异常切换</li></ul></li><li>硬件及基础环境部署<ul><li>  选择什么配置的服务器，服务器型号及对应磁盘阵列；</li><li>  操作系统环境及内核设置；</li></ul></li><li>数据库安装及优化<ul><li>  数据库版本安装部署及配置；</li><li>  数据库配置参数调优；</li></ul></li><li>SQL 语句优化；<ul><li>  慢查询，对 SQL 语句及索引做优化</li></ul></li><li>数据库日常备份及恢复。<ul><li>  备份；</li><li>  热备还是冷备？物理备份还是逻辑备份？</li><li>  备份策略、周期、频率</li></ul></li></ul><p>使用云数据库，这些步骤云数据库都帮你做了。其他 PaaS（中间件、大数据、微服务、DevOps 等）也类似。</p><h4 id="做好安全防护"><a href="#做好安全防护" class="headerlink" title="做好安全防护"></a>做好安全防护</h4><p>公有云最大的风险就是数据泄露。所以一定要做好安全防护。这个安全防护是多方面的。详细见 <a href="https://ewhisper.cn/posts/59535/#%E5%AE%89%E5%85%A8">安全</a> 部分。</p><h4 id="云的优势是「分布式」"><a href="#云的优势是「分布式」" class="headerlink" title="云的优势是「分布式」"></a>云的优势是「分布式」</h4><p>如果对比单台服务器，可能云主机的性能差一些。「分布式」是云计算的最大优势。在实践中，不要只追求单台机器的性能，而是要通过分布式的设计思想来保障业务的高性能。最佳实践推荐，服务器标配 4C8G，低配也可以采用 2C4G 的配置。通过分布式充分压榨了单台服务器的资源，从而最大限度地保障了最终的低成本。<br>所以，在云上，一般情况下应用服务器的选择条件是：更多的低配的云服务胜于更少的高配的云服务器。<br>所以，在云上，对于数据库来说，如果数据量非常大，也推荐使用「分布式数据库」，而非在云上自建 Oracle。</p><h4 id="云的优势是「弹性」"><a href="#云的优势是「弹性」" class="headerlink" title="云的优势是「弹性」"></a>云的优势是「弹性」</h4><p>所以，在云上，不要按照业务峰值购买全量的资源，而是推荐：</p><ul><li>  买满足日常需求的资源</li><li>  高峰时，再提前购买一些弹性的资源，弹性扩容。</li></ul><p>另外，不仅仅是服务器资源，对于网络也适用，如果您的系统经常搞活动，网络负载差距很大，那么推荐：「大带宽按量付费」而不是「固定带宽固定计费」。</p><h4 id="动静分离"><a href="#动静分离" class="headerlink" title="动静分离"></a>动静分离</h4><p>静态：放 CDN + 对象存储上，或者放 NGINX 服务器上也好，不要直接用应用服务器（如 tomcat 或 nodejs）来处理静态资源。（浪费，术业有专攻）<br>动态：典型架构是 LB - NGINX - 应用服务器 - redis - 数据库。</p><h4 id="上云前做好业务量的评估"><a href="#上云前做好业务量的评估" class="headerlink" title="上云前做好业务量的评估"></a>上云前做好业务量的评估</h4><p>上云前做好业务量的评估，为云上的资源规划做好资源预算。<br>可以通过：</p><ul><li>  压测</li><li>  已有监控数据分析</li></ul><p>等方式评估业务量。</p><p>常用的业务量指标如下：</p><p>指标</p><p>计算周期</p><p>指标含义</p><p>PV</p><p>天</p><p>Page View。指 B/S 架构中的 Web 类业务一天内页面的访问次数，每打开或刷新一次页面，算一个 PV。</p><p>UV</p><p>天</p><p>UV 是 Unique Visitor 的简写。指 B/S 架构中 Web 类业务一天内访问站点的用户数（以 cookie 为依据）</p><p>IP</p><p>天</p><p>B/S 架构中 Web 类业务一天内有多少个独立的 IP 浏览了页面，即统计不同的 IP 浏览用户数量。</p><p>用户数</p><p>–</p><p>业务系统的注册用户数</p><p>活跃用户数</p><p>天</p><p>注册用户数中，一天中实际使用了业务系统的用户数量，跟 UV 的概念一样</p><p>在线用户数</p><p>天</p><p>一天的活跃用户数中，用户同时在一定的时间段内在线的数量</p><p>并发用户数</p><p>–</p><p>指在线用户数基础上，某一时刻同时指向服务器发送请求的用户数</p><p>具体的性能监控指标如何和业务指标进行转换就先略过了。</p><h4 id="推荐几个公有云云产品"><a href="#推荐几个公有云云产品" class="headerlink" title="推荐几个公有云云产品"></a>推荐几个公有云云产品</h4><p>这些公有云产品是基本上都会用到的，历经检验，且比较实用的产品。</p><ol><li> 云服务器</li><li> 关系型数据库</li><li> 负载均衡</li><li> 对象存储</li><li> VPC（Virtual Private Cloud）：专有网络</li><li> CDN</li><li> Redis</li><li> 安全类的基本产品（如：安全组、ACL、漏扫、WAF、DDoS 防护等）</li></ol><h3 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h3><h4 id="云服务器配置以中低配为主"><a href="#云服务器配置以中低配为主" class="headerlink" title="云服务器配置以中低配为主"></a>云服务器配置以中低配为主</h4><p>云服务器一般用于承载应用，推荐以更多台数的中低配为主，避免资源的浪费。<br>建议一般配置不要超过：16C32G，主流配置为：</p><ul><li>  4C8G 甚至更低</li><li>  8C16G</li></ul><h4 id="推荐使用容器服务"><a href="#推荐使用容器服务" class="headerlink" title="推荐使用容器服务"></a>推荐使用容器服务</h4><p>容器服务有诸多优势，推荐无状态应用使用容器服务。</p><ul><li>  资源粒度更细，细粒度到: 0.1C, 内存 MB。</li><li>  自动扩缩容更方便</li><li>  扩容后 pod 自动加入负载均衡</li><li>  …</li></ul><h4 id="按需购买"><a href="#按需购买" class="headerlink" title="按需购买"></a>按需购买</h4><p>在云上，不要按照业务峰值购买全量的资源，而是推荐：买满足日常需求的资源</p><h4 id="弹性扩容"><a href="#弹性扩容" class="headerlink" title="弹性扩容"></a>弹性扩容</h4><p>在云上，如果需要搞活动，再通过「容器」或「API + 镜像 + 快照」批量购买、弹性扩容。</p><p>比如在某手机的秒杀活动中，会瞬间开启 200 台机器且持续 2H 来应对，IT 资源花费 600 元人民币：</p><ol><li> 搭建好环境，制作好镜像；</li><li> 活动前通过 API 秒开 200 台服务器来应对活动；</li><li> 活动结束后，通过 API 瞬间释放资源</li></ol><p>这在传统架构中，根本不可想象。比如传统架构，搞「双十一」，都要提前一个月准备 IT 资源。</p><p>另外上面的场景也可以利用 「弹性伸缩服务」或「容器 HPA」来动态调整。</p><h4 id="使用-Ansible-等-DevOps-工具"><a href="#使用-Ansible-等-DevOps-工具" class="headerlink" title="使用 Ansible 等 DevOps 工具"></a>使用 Ansible 等 DevOps 工具</h4><p>既然云的优势是「分布式」，资源多，那么 Ansible 这种批量的 DevOps 工具是必不可少的，可以大幅度提升效率。<br>具体应用，可以通过 Ansible，定制对应的 Playbook，自动化批量安装和运维。</p><h4 id="通过镜像提升云端部署效率"><a href="#通过镜像提升云端部署效率" class="headerlink" title="通过镜像提升云端部署效率"></a>通过镜像提升云端部署效率</h4><p>先开通一台云服务器，并对这台云服务器做运维规范方面的系统调优、安全加固等措施。然后把这台云服务器做成一个基础镜像，批量开通 其他同样环境的服务器，可以大大提升部署效率。</p><h3 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h3><h4 id="域名备案要先行"><a href="#域名备案要先行" class="headerlink" title="域名备案要先行"></a>域名备案要先行</h4><p>上云的最后一步，是要将域名的 IP 解析到 负载均衡 公网 IP 上。但需要提前在共有云上对域名进行备案，如果到最后域名解析到公有云上后才发现域名被拉黑，业务访问被拒绝，这将会变得非常麻烦。因此需要提前通过公有云进行域名备案，或者已经在其他供应商进行备案，那么需要将域名备案转接入公有云。</p><h4 id="推荐必备-CN-域名"><a href="#推荐必备-CN-域名" class="headerlink" title="推荐必备 .CN 域名"></a>推荐必备 .CN 域名</h4><p>近期国际形势愈演愈烈，中美摩擦进一步升级，形势紧张。要做最坏的打算：美国可能会断掉您的 .COM 域名的解析。<br>另外国家最近有指引，不要使用外国管控的根域名作为基础设施的一级域名。<br>.cn 是国家根域，.com.cn、[net.cn]、[org.cn] 等这些都是可以的。</p><h4 id="严禁每台服务器都能访问公网"><a href="#严禁每台服务器都能访问公网" class="headerlink" title="严禁每台服务器都能访问公网"></a>严禁每台服务器都能访问公网</h4><p>出于安全（受攻击面太大）和成本（公网 IP 都是钱）的考虑。<br>而且没必要，如果是业务访问，入向通过负载均衡进来，出向通过 NAT 网关出去。<br>如果是运维，推荐通过 VPN + 跳板机（中小企业）或专线 + 堡垒机（大企业）来实现运维管理。</p><h4 id="如果需要出公网，建议使用-NAT-网关而非在某台机器绑定公网-IP"><a href="#如果需要出公网，建议使用-NAT-网关而非在某台机器绑定公网-IP" class="headerlink" title="如果需要出公网，建议使用 NAT 网关而非在某台机器绑定公网 IP"></a>如果需要出公网，建议使用 NAT 网关而非在某台机器绑定公网 IP</h4><p>原因：可靠性更高，更安全。</p><h4 id="利用低成本高负载的按量带宽"><a href="#利用低成本高负载的按量带宽" class="headerlink" title="利用低成本高负载的按量带宽"></a>利用低成本高负载的按量带宽</h4><p>对于中小规模企业，如果您的系统经常搞活动，网络负载差距很大，那么推荐：「大带宽按量付费」而不是「固定带宽固定计费」，比如：「1Gbps 峰值带宽按量计费」对比「100Mbps 固定带宽」：</p><ul><li>  费用可能更低</li><li>  带宽更大，活动期间可能会超过 100Mbps，那这时候固定带宽就会影响用户体验，而 1Gbps 峰值带宽是完全可以支撑的住的。</li></ul><p>以某客户上云前后为例，在 IDC 机房，200Mbps 的独享电信带宽，一年的成本大概是 1Mbps/100 元 / 月 x 12 个月 x 200 = 24 万。而在云端，采用 1Gbps 峰值的 BGP 多线 SLB 带宽，在带宽质量上面提升了几个量级。另外，带宽费用采用按量付费，大大降低了维护成本。</p><h4 id="推荐使用云上软负载均衡"><a href="#推荐使用云上软负载均衡" class="headerlink" title="推荐使用云上软负载均衡"></a>推荐使用云上软负载均衡</h4><p>推荐使用公有云提供的负载均衡，可以作为反向代理，防止客户端直连云服务器带来的安全和稳定性风险。</p><p>加入 负载均衡 可以保障架构灵活扩展性：加入 负载均衡 后，架构变得更加灵活。典型场景是将所有域名先绑定到 负载均衡 上，然后转到后端 Nginx，通过 Nginx 做虚拟主机等七层更灵活的控制。</p><h4 id="高并发情况下，推荐使用-4-层负载均衡"><a href="#高并发情况下，推荐使用-4-层负载均衡" class="headerlink" title="高并发情况下，推荐使用 4 层负载均衡"></a>高并发情况下，推荐使用 4 层负载均衡</h4><p>采用 4 层 负载均衡 保障性能：在实践中，面对高并发性能的场景时，发现 7 层的负载均衡，相比 4 层的负载均衡，在性能上面有很大差距。7 层负载均衡只能达到万级别并发，而 4 层的负载均衡能达到几十万级，甚至上百万级的并发量。所以在电商等网站应用中，对于 负载均衡，优先选择 TCP 层。四层 LB 能扛得住 10w-50w 的并发。</p><h4 id="DNS-记录调整要注意"><a href="#DNS-记录调整要注意" class="headerlink" title="DNS 记录调整要注意"></a>DNS 记录调整要注意</h4><p>用户的 DNS TTL 我们是无法控制的，如果调整了某域名的 DNS 记录，可能某些用户已生效，某些用户没有生效。<br>针对这种情况，需要在原有 IP 上做 302 重定向跳转，将依旧访问原 IP 的客户引流到新 IP 上，这将大大提高用户的访问体验。</p><h4 id="大型企业-DNS-负载均衡实践"><a href="#大型企业-DNS-负载均衡实践" class="headerlink" title="大型企业 - DNS 负载均衡实践"></a>大型企业 - DNS 负载均衡实践</h4><p>大规模应用。当后端有一两百台云服务器，而一台负载均衡 性能有限时，可以采用多个 负载均衡，前边通过 DNS 负载均衡。典型如：淘宝、阿里云官网。</p><p>DNS 有个最大的问题，就是 本地 DNS 缓存。</p><ol><li> 可以让 DNS TTL 生效快一点；</li><li> DNS 配置的是负载均衡 IP，而不是云服务器的 IP。</li><li> 如果还是有部分用户出问题，指导用户清理 DNS 缓存，或强制绑定本机 host 指向域名解析。</li></ol><p>智能解析 – 跨地域分布式架构中必不可少。根据 ClientIP，选择返回对应地域、运营商的 IP。</p><h5 id="运营商线路解析"><a href="#运营商线路解析" class="headerlink" title="运营商线路解析"></a>运营商线路解析</h5><p>如：DNS 记录：</p><ul><li>  默认线路：电信服务器 IP</li><li>  网通：网通 IP</li><li>  移动：移动 IP</li><li>  教育网：教育网 IP</li><li>  海外：海外 IP</li></ul><p>如果有 BGP 线路，那就更简单了：</p><ul><li>  默认线路：负载均衡的公网 IP</li></ul><h5 id="地域线路解析"><a href="#地域线路解析" class="headerlink" title="地域线路解析"></a>地域线路解析</h5><p>如：用户请求访问域名，DNS 自动判断访问者 IP 是「上海联通」还是「北京联通」，然后智能返回设置的对应的「上海联通」和「北京联通」的服务器 IP 地址完成域名解析。</p><p>海外：可以选择「海外、海外大洲、海外（国家 / 地区）」来细分解析。</p><p>如:</p><ul><li>  海外 - 亚洲地区 - 新加坡线路：指向新加坡服务器的 IP</li><li>  海外 - 北美洲 - 美国线路：指向美国服务器的 IP</li><li>  海外 - 欧洲 - 德国线路：指向德国服务器的 IP</li><li>  默认线路：指向新加坡服务器的 IP</li></ul><h4 id="CDN-就是智能解析的最佳实践"><a href="#CDN-就是智能解析的最佳实践" class="headerlink" title="CDN 就是智能解析的最佳实践"></a>CDN 就是智能解析的最佳实践</h4><h3 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h3><h4 id="云上善用「对象存储服务」"><a href="#云上善用「对象存储服务」" class="headerlink" title="云上善用「对象存储服务」"></a>云上善用「对象存储服务」</h4><p>云上建议尽量不要使用类 NAS 的共享文件存储服务，而应该使用 <strong>对象存储服务</strong> 来替代。<br>在传统环境，NAS 的典型使用场景如下：</p><ul><li><p><strong>负载均衡</strong>：使用 LB + 多台 云服务器（如：Web 服务器）部署的业务。多台 云服务器 需要访问同一个存储空间，以便多台 云服务器 共享数据。</p><ul><li>  <strong>替代方案</strong>：直接使用普通云数据盘，通过 DevOps 等工具实现批量部署及数据一致。</li></ul></li><li><p><strong>代码共享</strong>：多台 云服务器 应用，部署的代码一致。将代码放在同一个存储空间，提供给多台 云服务器 同时访问。代码集中管理。</p><ul><li>  <strong>替代方案</strong>：代码放在代码仓库中集中管理。</li></ul></li><li><p><strong>日志共享</strong>：多台 云服务器 应用，需要将日志写入到同一个存储空间，以便做集中的日志数据处理和分析</p><ul><li>  <strong>替代方案</strong>：日志定期存储到对象存储中，可以根据策略、冷热数据的实际情况选择分别存储到「标准对象存储」、「低频对象存储」和「归档存储」中进一步压缩成本；或直接使用云上的「日志服务」。</li></ul></li><li><p><strong>企业办公文件共享场景</strong>：企业有公共的文件需要共享给多组业务使用，需要集中的共享存储来存放数据。</p><ul><li>  <strong>替代方案</strong>：使用对象存储来替代。</li></ul></li><li><p><strong>容器服务的场景</strong>：部署的容器服务需要共享访问某个文件数据源，特别是在资源编排的容器服务。对应的容器可能会在不同的服务器中进行服务漂移，所以文件共享访问尤为重要。</p><ul><li>  <strong>替代方案</strong>：这种场景确实需要用到云上文件系统服务。</li></ul></li><li><p><strong>备份的场景</strong>：用户希望将数据备份到云上，可以通过挂载文件系统来存储数据备份。</p><ul><li>  <strong>替代方案</strong>：备份到对象存储的「归档存储」中，进一步降低成本。</li></ul></li></ul><h4 id="错误用法：NGINX-做公网转发到对象存储"><a href="#错误用法：NGINX-做公网转发到对象存储" class="headerlink" title="错误用法：NGINX 做公网转发到对象存储"></a>错误用法：NGINX 做公网转发到对象存储</h4><p>在某个客户场景中，静态资源放到 对象存储 中，前端对静态资源的请求通过 Nginx 反向代理转发给 对象存储。但这种做法，在云端架构上是不推荐的，因为它会带来几个问题：</p><ul><li>  访问静态资源的流量走 云服务器 的带宽流量，特别是中大型的 Web 应用中。流量走 云服务器 的带宽，很可能出现性能瓶颈。</li><li>  Nginx 是通过公网将请求反向代理转发给 对象存储 的，所以在网络传输上会影响速度性能。</li><li>  通过 Nginx 反向代理，不仅增加运维成本，还要维护 Nginx 配置文件等。</li></ul><p>所以，添加 Nginx 做反向代理是多此一举。云端不推荐这么做。该客户这么用，主要原因是业务代码侧，静态资源的请求，都是通过目录划分。如果将静态资源单独放在二级域名，跨域等问题代码侧没很好地解决，从而产生这种不伦不类的架构。最终在业务代码侧进行了优化调整，对 对象存储 静态资源的使用规范如下：</p><ul><li>  业务侧使用单独的二级域名来管理静态资源（如：&lt;<a href="http://pic-cdn.ewhisper.cn/">pic-cdn.ewhisper.cn</a>&gt;)，静态资源统一放在 对象存储 中；</li><li>  静态资源的二级域名直接将 CNAME 绑定在 对象存储 的 URL 地址上（访问量很少的情况下），这样就直接跳过「使用 Nginx 做反向代理」这个冗余的步骤了</li><li>如果想要进一步提升 对象存储 中存放的静态资源的访问速度，可以无缝接入 CDN。 CDN 的回源请求，会直接通过内网回源请求 对象存储 中的源数据。相比 Nginx 反向代理走公网请求 对象存储，速度和效率会提升得更高，价格特定情况下也会更划算。<ul><li>  👉 <a href="https://ewhisper.cn/posts/59535/#%E5%85%B8%E5%9E%8B%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%EF%BC%9ACDN-%20%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8">典型使用场景：CDN 对象存储</a></li></ul></li></ul><h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h3><h4 id="数据库推荐云服务-且必须有高可用保障"><a href="#数据库推荐云服务-且必须有高可用保障" class="headerlink" title="数据库推荐云服务 且必须有高可用保障"></a>数据库推荐云服务 且必须有高可用保障</h4><p>数据库不推荐自建，推荐直接使用云提供商的相关数据库服务，且推荐必备高可用保障，如集群模式或多副本，以及数据备份。<br>数据库优先采用云提供商的相关数据库服务 ，低成本高效率：如果在云上购买云服务器自建 MySQL 主从部署并维护的模式，使得后期的维护管理成本很大。即我们要监控及维护主从状态，并且在出现问题时需要及时处理，保障业务对数据库读写的连续性。在采用云提供商的相关数据库服务 后，这些问题都可以自动化解决。即对数据库主从的监控、备份、后期维护、故障切换等，都是全自动。</p><h4 id="对于可靠性要求特别高的-DB，可以选择跨-AZ-高可用的集群方案"><a href="#对于可靠性要求特别高的-DB，可以选择跨-AZ-高可用的集群方案" class="headerlink" title="对于可靠性要求特别高的 DB，可以选择跨 AZ 高可用的集群方案"></a>对于可靠性要求特别高的 DB，可以选择跨 AZ 高可用的集群方案</h4><p>对于可靠性要求特别高的 DB，可以选择跨 AZ 高可用的集群方案。比如：Redis、MongoDB、MySQL 都有类似的跨 AZ 高可用的集群方案提供。</p><h4 id="按需选择合适的数据库"><a href="#按需选择合适的数据库" class="headerlink" title="按需选择合适的数据库"></a>按需选择合适的数据库</h4><p>数据库多种多样，根据自己的实际需求进行选择，以下列出部分：</p><ul><li>关系型数据库<ul><li>  MySQL</li><li>  SQL Server</li><li>  Postgresql</li><li>  MariaDB</li><li>  分布式数据库（如 OceanBase 或 TDSQL 等）</li></ul></li><li>非关系型：内存数据库<ul><li>  Redis</li><li>  Memcache</li></ul></li><li>  文档数据库：MongoDB</li><li>列数据库<ul><li>  HBase 等</li></ul></li><li>时序数据库<ul><li>  InfluxDB</li><li>  TSDB</li></ul></li></ul><h3 id="CDN"><a href="#CDN" class="headerlink" title="CDN"></a>CDN</h3><h4 id="典型使用场景：CDN-对象存储"><a href="#典型使用场景：CDN-对象存储" class="headerlink" title="典型使用场景：CDN + 对象存储"></a>典型使用场景：CDN + 对象存储</h4><ul><li>  <strong>数据分发</strong>：适用于搭建下载行为较多的 APP、音视频平台、网站等，用户可结合 CDN + 对象存储 的能力，将静态内容（包括音视频、图片等文件）托管在对象存储中，并将热点文件提前下发至 CDN 边缘节点，降低下载访问延迟</li><li>  <strong>网站托管</strong>：适用于官方网站等偏静态的站点，将网站的静态资源快速托管存储在对象存储中，同时通过 CDN + 对象存储 分发，通过 CDN 配置的域名作为静态网站访客的访问地址入口，快速建好一个网站</li></ul><h3 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h3><h4 id="必须设置强密码"><a href="#必须设置强密码" class="headerlink" title="必须设置强密码"></a>必须设置强密码</h4><p>典型如：MongoDB、Redis、ES，默认无密码或弱密码，已经发生过多轮、大规模的数据泄露事件，所以针对这些服务，一定要设置强密码。<br>至于云服务器、云账户、关系型数据库等，更是要保障强密码或者更强力的安全措施。</p><h4 id="客户端访问必须-HTTPS"><a href="#客户端访问必须-HTTPS" class="headerlink" title="客户端访问必须 HTTPS"></a>客户端访问必须 HTTPS</h4><p>这个就不多说了。</p><ul><li>  给域名申请证书，放在 Nginx 或 LB 上 管理。</li><li>  业务侧，保留 HTTP 80 端口，做 80 -&gt; 443 的重定向。LB 上 80 和 443 端口监听都要开启。</li></ul><h4 id="一定要配置安全组和-ACL"><a href="#一定要配置安全组和-ACL" class="headerlink" title="一定要配置安全组和 ACL"></a>一定要配置安全组和 ACL</h4><p>最基本的安全防护</p><h4 id="不要-root-直连"><a href="#不要-root-直连" class="headerlink" title="不要 root 直连"></a>不要 root 直连</h4><p>不要 root 直连，用普通用户，登陆过去按需 sudo 切换到 root</p><h4 id="建议暴露公网的-SSH-端口不要用-22"><a href="#建议暴露公网的-SSH-端口不要用-22" class="headerlink" title="建议暴露公网的 SSH 端口不要用 22"></a>建议暴露公网的 SSH 端口不要用 22</h4><p>建议不要用默认的 22 端口，防止被扫描。另外还有建议用证书认证等方式，就不一一赘述了。</p><h4 id="免费安全产品别忘领"><a href="#免费安全产品别忘领" class="headerlink" title="免费安全产品别忘领"></a>免费安全产品别忘领</h4><p>如每开通一台云服务器，都会赠送一些免费额度的「DDoS 防护和主机安全防护」。有基本的防护，会比裸奔安全很多。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://ewhisper.cn/posts/59535/&quot;&gt;https://ewhisper.cn/posts/59535/&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;h2 id=&quot;最佳实践&quot;&gt;&lt;a href=&quot;#最佳实践&quot; class=&quot;hea</summary>
      
    
    
    
    <category term="公有云" scheme="http://zhangyu.info/categories/%E5%85%AC%E6%9C%89%E4%BA%91/"/>
    
    
    <category term="公有云" scheme="http://zhangyu.info/tags/%E5%85%AC%E6%9C%89%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>为什么互联网大厂一边大规模裁员又一边招聘</title>
    <link href="http://zhangyu.info/2022/04/23/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BA%92%E8%81%94%E7%BD%91%E5%A4%A7%E5%8E%82%E4%B8%80%E8%BE%B9%E5%A4%A7%E8%A7%84%E6%A8%A1%E8%A3%81%E5%91%98%E5%8F%88%E4%B8%80%E8%BE%B9%E6%8B%9B%E8%81%98/"/>
    <id>http://zhangyu.info/2022/04/23/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BA%92%E8%81%94%E7%BD%91%E5%A4%A7%E5%8E%82%E4%B8%80%E8%BE%B9%E5%A4%A7%E8%A7%84%E6%A8%A1%E8%A3%81%E5%91%98%E5%8F%88%E4%B8%80%E8%BE%B9%E6%8B%9B%E8%81%98/</id>
    <published>2022-04-22T16:00:00.000Z</published>
    <updated>2022-06-09T04:56:47.045Z</updated>
    
    <content type="html"><![CDATA[<p>作者：东岳老师</p><p><a href="https://www.zhihu.com/people/tian-tian-quan-75-47">https://www.zhihu.com/people/tian-tian-quan-75-47</a></p><blockquote><p>真实在大厂工作过，十几年的互联网老兵告诉你事实。</p><p>大厂里面有很多的业务线，也有很多的部门，每个部门负责的都不一样，阿里不是只做淘宝，腾讯也不是只做微信，一个大厂有数百条业务线，有的赚钱，有的赔钱。但是通常赔钱的最多。</p><p>通常大厂是这样玩的:</p><p>上层领导看中了一个方向，比如说游戏是赚钱的，于是就大量开始招聘游戏岗位。</p><p>公司往这方面投钱，比如说一年投入1000万，然后制定一个目标，实现三年盈利。通过招聘，你顺利进入了他们的游戏业务线，成为大厂员工。</p><p>光环加顶，有些刚进入大厂的员工觉以为祖坟冒青烟了，但也可能冒黑烟。</p><p>因为公司业务线刚开辟，所以就大量招人，高层来赌这个业务三年后一定盈利。把人力，金钱，物力投入进去。至于高层哪来的那么大自信赌成功，说真的，他们也都是懵逼状态。</p><p><strong>高层之间也内卷，总裁副总裁一大批，负责的业务都不同。</strong></p><p>我在某厂做总监时，经常跟一些总裁开会讨论方案，他们真的啥也不懂。因为这群人年龄太大了，很多都是投资人，根本不懂互联网，都是瞎指挥。</p><p>懂互联网的也是极个别人，总裁眼里只有钱。其他都没有。各种不着调的想法每次和他们开完会恨不能摔门而去。</p><p>但你还得执行他们不靠谱的想法，谁让咱们是打工人。就算方案是屎也得给老板做出臭豆腐的口感。实现不了怎么办，假装很努力的加班啊，得让老板看到咱很努力的干啊。</p><p>高层画大饼不要紧，咱也得吃饭啊。</p><p>高层天天开会，传达给中层的就TM一句话，今年我们要实现十个亿的目标!</p><p>卧槽，毛线都没有呢，那怎么办，上有政策下有对策，中层也有办法，你们知道中层每天都在干什么吗，天天写PPT!天天给高层做实现十个亿目标的汇报，一次一次被打回重改，直到改到高层认为PPT可以真的能实现十个亿目标位置。</p><p>PPT是个好东西，不仅能造车，还能造梦!</p><p>很遗憾的是，高层和中层一本正经的搞了PPT很长时间，大家一致认为从PPT上面已经证明能够实现十个亿的目标。</p><p>但多数业务实际根本不可能像预想的那样盈利，PPT终究是PPT，当不能盈利时，这条业务线就会被砍掉，你经常发现大厂裁员是整条业务线从上到下全部被裁掉就是这个问题。</p><p>老板层总是有各种想法，每年都要想我要做什么，总之都是为了赚钱。</p><p>有的老板都是拍脑门，反正人家有钱，玩得起。瞎折腾怕什么，万一折腾成功了呢。就像有个人说的那样，梦想总是有的，万一实现了呢。</p><p>把钱往里面一投资，找一堆写手，做几篇新闻，搞几个概念，开始忽悠了。全都给我上，产品，技术，运营，招起来!上层要干什么事情呢，上层要拿着PPT去资本市场忽悠钱。</p><p>有一次和某个总裁喝酒，无意之间他说了一句话，我们不这样的话，股票就会跌的，我们只有这样做股票才能涨。</p><p>我忽然恍然大悟，其实他们根本不是做互联网的，他们就是一群在股市圈钱的人。是的，只要折腾起来，股民才会不断的被割韭菜。原来赔掉的钱可以通过股市赚回来!资本市场才是真正赚钱的地方。</p><p>互联网从诞生开始，就是靠资本一轮一轮融资的吹起来的，互联网公司本质就是投资公司，而高层就是投资人，靠着一个一个的故事融钱，用钱赚钱，而至于这个业务，他们并不关心能不能做成。他们只关心手里的股票能不能升值。</p><p>但是问题是，你不可能所有开辟的业务线都赔钱吧，股东也不是傻子啊，靠股市画大饼早晚会被做空。所以他们总得有点赚钱的业务啊。</p><p>十条业务线九条可能都赔钱，但有一条业务线赚钱就成功。公司高层都是赌徒心理，因为他们也没办法判断哪个业务能成功。多生几个孩子，总有一个孩子能成器吧。</p><p>不成器的孩子怎么办，放弃吧。然后继续生孩子，继续招人。大厂靠着自己的招牌不用担心招不到人，反正人人都想进大厂。</p><p>就算全都裁掉，照样能够招到。就算赔掉一个亿对大厂来说只不过是交学费而已。毕竟人家赚一个亿也就是小目标。</p><p>那问题在于，为什么他们不用原有的团队做呢，因为原有团队在高层看来就是败军之将，给你三年时间都没搞成你在高层眼里已经没有价值，不裁你才怪呢。老板看你不顺眼，他们眼中只有一个单词：loser!</p><p><strong>这类新闻屡见不鲜:</strong></p><p>字节跳动方面，本地生活和房产业务受到影响。去年10月，字节跳动本地生活被曝出从22个城市撤退，仅保留了北京、上海等几个城市。</p><p>字节跳动HR相关负责人回应媒体称，裁员信息属实，系公司正常业务调整。</p><p>大部分的公司都是公司业务正常调整，简单来说就是，这孩子不成器，赶出家门。</p><p><strong>那你说，我这条业务线搞成了，那总不会被裁吧。</strong></p><p>呵呵，你想的天真了，一条业务线搞成了照样裁掉一半，这叫<strong>组织人员优化</strong>，本身做这条业务线就需要大量人参与进来，就像你建一座桥，建设时候需要几千人，建完了只需要几十人维护就可以了。</p><p>那你说，我只要努力就不会被裁吧，呵呵，裁掉你和你努力不努力无关系，什么末尾淘汰制只不过是裁你的理由，制定一个规则，让员工内卷，因为员工内卷对企业最有好处。</p><p><strong>只有裁员，才能让员工感到危机。</strong></p><p>你虽然花费了大量时间精力，什么996啊，公司是不会看在眼里的，公司只看你成本太高了。</p><p>三十五岁为什么会被裁，你知道，你在一家公司干十年你的薪资得有多高，不给你加薪资你不满意，给你加薪资老板不满意，反正有的是人干活，这么高薪资不需要你了，就裁掉了。</p><p><strong>与你能力无关系。只和你成本有关系。</strong></p><p>在大厂的业务线，中层压力最大，因为裁员先把中层干掉。中层在公司的定位就是背锅的，中层一般都是总监或者级别副总裁级，负责承上启下，只要业务快玩完了，为了给公司交代，稳定军心，高层首先要把中层拿来祭旗了。</p><p>中层天天要逼着底层加班，也并不是真的很忙，因为他要做给高层看，让高层觉得他很努力，一定能成功。但是中层消息也很灵敏，见势不妙，没等裁员就脚底抹油提前跑路了。</p><p>跑之前中层这群老油条们还得给底层没有经验的职场小白PUA，兄弟们，挺住，困难只是暂时的。只要团结一心，一定可以的！</p><p>你会说中层难道不想要补偿吗？呵呵，你太小看中层了，在业务没有倒闭前另谋其主，还TM能吹牛皮一把说这业务做的很成功。</p><p>你看，离开我就倒闭了吧。真要耗到业务干倒闭了拿那个裁员补偿，对他们来说找工作都不好找。中层早就提前谋划好了出路，重要的人该走的都走光了。</p><p>多说句中层的话题，中层之间也经常在一起喝酒，不同的业务线之间也会互相交流经验，我参加过很多聚餐，喝酒前大家牛皮吹一波，我们做的是十个亿的大项目，这算什么，我们做的是一百亿的大项目。</p><p>你们说的都不是什么，我们定下目标一千亿。酒过三巡，真情流露，大家互相安慰，兄弟，早撤吧，我看透了，这活没希望。</p><p>等你有一天做了中层，就知道中层才是互联网公司最苦逼的，上面领导骂你，底下员工骂你，回家老婆骂你，辞职不敢，没有一边讨好。多少底层想要往上爬到中层，等你爬上去，就知道这哪是人生巅峰，是TM火山口!</p><p>上也上不去，下也下不来。每件事处理起来都是贼烫手。做中层久了就知道，有些事不能硬撑，关键时候跑路才是上上策，孙子兵法得作为案头书天天阅读，不然你怎么在这么复杂的环境中生存下去。</p><p>这就是你看到的类似新闻:</p><p><strong>某某大厂某事业部负责人离职，加入某某公司。</strong></p><p>但你看到这种消息后一般还不到裁员时候，因为裁员需要一个过程。</p><p>三个月后，轮到HR上场了，HR会在一夜之间发个通告，因某某原因，公司无法经营，宣布裁员，底层员工被打的措手不及!</p><p>前一天还在加班到凌晨十二点，这时候你忽然看到HR也在加班，你心里想，嗯，公司又开始招人了。</p><p>公司肯定发展越来越好了。其实人家加班是制定裁员名单呢，今天一上班就被告知裁员。没等你反应过来，整个部门都没有了。</p><p>HR才是互联网公司效率最高的职位!昨天，还许诺你加薪，今天你一脸懵逼的发呆，看着同事一个一个打包离开。</p><p>HR就告诉你一句话，今天必须走。按劳动合同，给你n+1补偿。其实发布裁员公告之前，所有准备都已经提前三个月准备好了。连给你n+1的钱都准备好了。</p><p>有的大厂裁员也很有情怀，临走还发给职场小白一个毕业证，<strong>同学!恭喜你在某厂顺利毕业了!</strong></p><p>呵呵，有的应届生刚入职第一天就毕业了，这速度真TM的快啊!给我的50万年薪呢？这么快就没了?咱好歹号称是大厂啊，别这样糊弄人行不？</p><p>这时候你看到的新闻就是:</p><p>某厂内部员工在某APP传闻裁员，整个事业部都被裁撤，未经官方证实。</p><p>于是一轮从招聘到裁员的过程就结束了，宣布一条不靠谱的业务线彻底消失，老板的大饼没有画成。</p><p>从项目立项，到招人，到投资扩建，到疯狂炒概念，再到负责人离职，内部传出裁员，公司证实属实。</p><p>众位朋友，等你经历互联网十年你就知道这种招聘裁员戏天天上演。只是大部分都没有爆出来而已。因为很多业务线都不起眼，还没有人知道就已经消亡了。</p><p>然后公司继续开辟新业务线，继续靠着大厂这个招牌白嫖打工者的青春，反正你不来是有别人来，我反正是给钱的，你不做还有别人做。真招不到人就开始画大饼，给应届生开高薪。</p><p>一毕业就来个年薪五十万，卧槽，我这工作十几年的都没一个应届生薪资高，你招他来做什么？</p><p>后来我明白，很多人都是凑数的。裁员的时候容易点。要招我这种老油条，连签合同我都得看三遍，敢裁我，分分钟给你讲劳动法。别TM忽悠我，罗翔的刑法讲义我天天看。</p><p>应届生就容易多了，签合同都不看一眼，裁你时候给你一个绩效不合格，他们还觉得自己没有尽全力，对不起公司。也不用n+1补偿，因为连n都没有。看起来薪资那么高，其实用工成本真的很廉价。很多都是做给外界看的。</p><p>其实很多人，不过是陪着高层赌未来，高层赌不对没关系，可以继续赌，毕竟人家不会担心自己被裁掉。本身高层眼里也没有员工，只有利益，员工自己堵不对，只能被裁了。</p><p>老板赌上的是钱，员工陪赌的是未来。老板赌输了钱，大不了再赌一把，员工赌没了未来，就真的啥也没有了。有的员工连命都赔赌进去了。</p><p>所谓某些互联网大厂，也不过是披着一层炫酷的外衣，进去也是996的工作。因为你得陪着老板赌这种不靠谱的未来。</p><p>只是，你人生需要做的是淡定！看庭前花开花落，云卷云舒，莫纠结！很多事情，对打工人来说都很无奈，最后苦的还是打工人。</p><p>你方唱罢我登场，今天他被裁，明天你被裁，也只是打工人的命运。与你能力高低真没关系。如果有关系，那你不过是个背锅侠而已。裁你，也只是杀鸡给猴看。</p><p>领导说，我们给社会每年输送一千人才。呵呵，确实是这样，陪你玩几年，你赚的盆满钵满，我们成了人才。两全其美，何乐不为呢。</p><p>我TM混了互联网十五年不是做人才就是走在做人才的路上!</p><p>青春就那么几年，你从小到大都是很优秀，拿着985的学历拼进大厂，恋爱都不敢谈，每天996的为公司奋斗，养着房东，养着这个城市，养着身体几十万亿的细胞。</p><p>不到三十岁的小伙子头发秃顶，肾虚无力，腰间盘突出，赌上了自己一切，用自己拼搏卷走了无数人，梦想有一天出人头地，你做好了最优秀的自己，无一刻休息，只为了明天更好，最后结局被裁了。最后如梦初醒，才知道自己是小丑。</p><p>真实，上面的话都不敢说，我敢说只因为我不在大厂干了，也不想再进去。就算封杀我也无所谓。我坚决反对拿员工前途做赌注的公司!</p><p>我要说这些话，也希望企业裁员慎重考虑!同时也希望企业不要盲目的招聘，因为真的很多同学因为你们的招聘赌上了未来。我不怕得罪那么多的大厂，我只希望彼此都真诚些，大家都是为了更好的未来。</p><p>我没有针对任何大厂，我只说一种现象，希望我写这些不会被封掉。</p><p>人生苦短，善待自己!</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;作者：东岳老师&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/people/tian-tian-quan-75-47&quot;&gt;https://www.zhihu.com/people/tian-tian-quan-75-47&lt;/a&gt;&lt;/p&gt;
&lt;blo</summary>
      
    
    
    
    <category term="我假装讲-你假装看" scheme="http://zhangyu.info/categories/%E6%88%91%E5%81%87%E8%A3%85%E8%AE%B2-%E4%BD%A0%E5%81%87%E8%A3%85%E7%9C%8B/"/>
    
    
    <category term="我假装讲-你假装看" scheme="http://zhangyu.info/tags/%E6%88%91%E5%81%87%E8%A3%85%E8%AE%B2-%E4%BD%A0%E5%81%87%E8%A3%85%E7%9C%8B/"/>
    
  </entry>
  
  <entry>
    <title>Linux的CPU上下文切换深入探讨</title>
    <link href="http://zhangyu.info/2022/04/23/Linux%E7%9A%84CPU%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%E6%B7%B1%E5%85%A5%E6%8E%A2%E8%AE%A8/"/>
    <id>http://zhangyu.info/2022/04/23/Linux%E7%9A%84CPU%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%E6%B7%B1%E5%85%A5%E6%8E%A2%E8%AE%A8/</id>
    <published>2022-04-22T16:00:00.000Z</published>
    <updated>2022-04-23T15:03:30.595Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/3fJvAjgPmi6N8XUQ4QII4w">https://mp.weixin.qq.com/s/3fJvAjgPmi6N8XUQ4QII4w</a></p><blockquote><p><em>链接：<a href="https://medium.com/geekculture/linux-cpu-context-switch-deep-dive-764bfdae4f01">https://medium.com/geekculture/linux-cpu-context-switch-deep-dive-764bfdae4f01</a></em></p></blockquote><blockquote><p>我们都知道 Linux 是一个多任务操作系统，它支持的任务同时运行的数量远远大于 CPU 的数量。当然，这些任务实际上并不是同时运行的（Single CPU），而是因为系统在短时间内将 CPU 轮流分配给任务，造成了多个任务同时运行的假象。</p><h2 id="CPU-上下文（CPU-Context）"><a href="#CPU-上下文（CPU-Context）" class="headerlink" title="CPU 上下文（CPU Context）"></a>CPU 上下文（CPU Context）</h2><p>在每个任务运行之前，CPU 需要知道在哪里加载和启动任务。这意味着系统需要提前帮助设置 CPU <strong>寄存器</strong>和<strong>程序计数器</strong>。</p><p>CPU 寄存器是内置于 CPU 中的小型但速度极快的内存。程序计数器用于存储 CPU 正在执行的或下一条要执行指令的位置。</p><p>它们都是 CPU 在运行任何任务之前必须依赖的依赖环境，因此也被称为 “CPU 上下文”。如下图所示：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/QFzRdz9libEa4QiaK9HAa6licygbok94QEpljrPgEZa2rHcgdQc0BG8icMAkOabSYqPjVaP9ulIZNKZ9RAwm7j26Fg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>知道了 CPU 上下文是什么，我想你理解 <strong>CPU 上下文切换</strong>就很容易了。“CPU上下文切换”指的是先保存上一个任务的 CPU 上下文（CPU寄存器和程序计数器），然后将新任务的上下文加载到这些寄存器和程序计数器中，最后跳转到程序计数器。</p><p>这些保存的上下文存储在系统内核中，并在重新安排任务执行时再次加载。这确保了任务的原始状态不受影响，并且任务似乎在持续运行。</p><h2 id="CPU-上下文切换的类型"><a href="#CPU-上下文切换的类型" class="headerlink" title="CPU 上下文切换的类型"></a>CPU 上下文切换的类型</h2><p>你可能会说 CPU 上下文切换无非就是更新 CPU 寄存器和程序计数器值，而这些寄存器是为了快速运行任务而设计的，那为什么会影响 CPU 性能呢？</p><p>在回答这个问题之前，请问，你有没有想过这些“任务”是什么？你可能会说一个任务就是一个<strong>进程</strong>或者一个<strong>线程</strong>。是的，进程和线程正是最常见的任务，但除此之外，还有其他类型的任务。</p><p>别忘了<strong>硬件中断</strong>也是一个常见的任务，硬件触发信号，会引起中断处理程序的调用。</p><p>因此，CPU 上下文切换至少有三种不同的类型：</p><ul><li><p>  进程上下文切换</p></li><li><p>  线程上下文切换</p></li><li><p>  中断上下文切换</p></li></ul><p>让我们一一来看看。</p><h2 id="进程上下文切换"><a href="#进程上下文切换" class="headerlink" title="进程上下文切换"></a>进程上下文切换</h2><p>Linux 按照特权级别将进程的运行空间划分为内核空间和用户空间，分别对应下图中 <code>Ring 0</code> 和 <code>Ring 3</code> 的 CPU 特权级别的 。</p><ul><li><p>  <strong>内核空间</strong>（<code>Ring 0</code>）拥有最高权限，可以直接访问所有资源</p></li><li><p>  <strong>用户空间</strong>（<code>Ring 3</code>）只能访问受限资源，不能直接访问内存等硬件设备。它必须通过<strong>系统调用</strong>被<strong>陷入（trapped）</strong>内核中才能访问这些特权资源。</p></li></ul><p><img src="https://mmbiz.qpic.cn/mmbiz_png/QFzRdz9libEa4QiaK9HAa6licygbok94QEpMSWZMNUExiaibUIoicUEeT7jdF4d59q7lJQicHQ6Xhe3kbicscVKu3GRBKg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>从另一个角度看，一个进程既可以在用户空间也可以在内核空间运行。当一个进程在<strong>用户空间</strong>运行时，称为该进程的<strong>用户态</strong>，当它落入<strong>内核空间</strong>时，称为该进程的<strong>内核态</strong>。</p><p>从<strong>用户态</strong>到<strong>内核态</strong>的转换需要通过<strong>系统调用</strong>来完成。例如，当我们查看一个文件的内容时，我们需要以下系统调用：</p><ul><li><p>  <code>open()</code>：打开文件</p></li><li><p>  <code>read()</code>：读取文件的内容</p></li><li><p>  <code>write()</code>：将文件的内容写入到输出文件（包括标准输出）</p></li><li><p>  <code>close()</code>：关闭文件</p></li></ul><p>那么在上述系统调用过程中是否会发生 CPU 上下文切换呢？当然是的。</p><p>这需要先保存 CPU 寄存器中原来的用户态指令的位置。接下来，为了执行内核态的代码，需要将 CPU 寄存器更新到内核态指令的新位置。最后是跳转到内核态运行内核任务。</p><p>那么系统调用结束后，CPU 寄存器需要<strong>恢复</strong>原来保存的用户状态，然后切换到用户空间继续运行进程。</p><blockquote><p>因此，在一次系统调用的过程中，实际上有两次 CPU 上下文切换。</p></blockquote><p>但需要指出的是，系统调用进程不会涉及进程切换，也不会涉及虚拟内存等系统资源切换。这与我们通常所说的“进程上下文切换”不同。进程上下文切换是指从一个进程切换到另一个进程，而系统调用期间始终运行同一个进程</p><p>系统调用过程通常被称为<strong>特权模式切换</strong>，而不是<strong>上下文切换</strong>。但实际上，在系统调用过程中，CPU 的上下文切换也是不可避免的。</p><h3 id="进程上下文切换-vs-系统调用"><a href="#进程上下文切换-vs-系统调用" class="headerlink" title="进程上下文切换 vs 系统调用"></a>进程上下文切换 vs 系统调用</h3><p>那么进程上下文切换和系统调用有什么区别呢？首先，进程是由内核管理的，进程切换只能发生在内核态。因此，进程上下文不仅包括<strong>虚拟内存</strong>、<strong>栈</strong>和<strong>全局变量</strong>等用户空间资源，还包括<strong>内核栈</strong>和<strong>寄存器</strong>等内核空间的状态。</p><p>所以<strong>进程上下文切换</strong>比<strong>系统调用</strong>要多出一步：</p><blockquote><p>在保存当前进程的内核状态和 CPU 寄存器之前，需要保存进程的虚拟内存、栈等；并加载下一个进程的内核状态。</p></blockquote><p>根据 Tsuna 的测试报告，每次上下文切换需要几十纳秒至微秒的 CPU 时间。这个时间是相当可观的，尤其是在大量进程上下文切换的情况下，很容易导致 CPU 花费大量时间来保存和恢复寄存器、内核栈、虚拟内存等资源。这正是我们在上一篇文章中谈到的，一个导致平均负载上升的重要因素。</p><p>那么，该进程何时会被调度/切换到在 CPU 上运行？其实有很多场景，下面我为大家总结一下：</p><ul><li><p>  当一个进程的 CPU 时间片用完时，它会被系统<strong>挂起</strong>，并切换到其他等待 CPU 运行的进程。</p></li><li><p>  当系统资源不足（如内存不足）时，直到资源充足之前，进程无法运行。此时进程也会被<strong>挂起</strong>，系统会调度其他进程运行。</p></li><li><p>  当一个进程通过 <code>sleep</code> 函数自动<strong>挂起自己</strong>时，自然会被重新调度。</p></li><li><p>  当优先级较高的进程运行时，为了保证高优先级进程的运行，当前进程会被高优先级进程<strong>挂起运行</strong>。</p></li><li><p>  当发生硬件中断时，CPU 上的进程会被<strong>中断挂起</strong>，转而执行内核中的中断服务程序。</p></li></ul><p>了解这些场景是非常有必要的，因为一旦上下文切换出现性能问题，它们就是幕后杀手。</p><h2 id="线程上下文切换"><a href="#线程上下文切换" class="headerlink" title="线程上下文切换"></a>线程上下文切换</h2><p>线程和进程最大的区别在于，线程是<strong>任务调度</strong>的基本单位，而进程是<strong>资源获取</strong>的基本单位。</p><p>说白了，内核中所谓的任务调度，实际的调度对象是线程；而进程只为线程提供虚拟内存和全局变量等资源。所以，对于线程和进程，我们可以这样理解：</p><ul><li><p>  当一个进程只有一个线程时，可以认为一个进程等于一个线程</p></li><li><p>  当一个进程有多个线程时，这些线程共享相同的资源，例如虚拟内存和全局变量。</p></li><li><p>  此外，线程也有自己的私有数据，比如栈和寄存器，在上下文切换时也需要保存。</p></li></ul><p>这样，线程的上下文切换其实可以分为两种情况：</p><ul><li><p>  首先，前后两个线程属于不同的进程。此时，由于资源不共享，切换过程与进程上下文切换相同。</p></li><li><p>  其次，前后两个线程属于同一个进程。此时，由于虚拟内存是共享的，所以切换时虚拟内存的资源保持不变，只需要切换线程的私有数据、寄存器等未共享的数据。</p></li></ul><p>显然，同一个进程内的线程切换比切换多个进程消耗的资源要少。这也是多线程替代多进程的优势。</p><h2 id="中断上下文切换"><a href="#中断上下文切换" class="headerlink" title="中断上下文切换"></a>中断上下文切换</h2><p>除了前面两种上下文切换之外，还有另外一种场景也输出 CPU 上下文切换的，那就是<strong>中断</strong>。</p><p>为了快速响应事件，硬件中断会中断正常的调度和执行过程，进而调用<strong>中断处理程序</strong>。</p><p>在中断其他进程时，需要保存进程的当前状态，以便中断后进程仍能从原始状态恢复。</p><p>与进程上下文不同，中断上下文切换不涉及进程的用户态。因此，即使中断进程中断了处于用户态的进程，也不需要保存和恢复进程的虚拟内存、全局变量等用户态资源。</p><p>另外，和进程上下文切换一样，中断上下文切换也会消耗 CPU。过多的切换次数会消耗大量的 CPU 资源，甚至严重降低系统的整体性能。因此，当您发现中断过多时，需要注意排查它是否会对您的系统造成严重的性能问题。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>综上所述，无论哪种场景导致上下文切换，你都应该知道：</p><p>CPU 上下文切换是保证 Linux 系统正常运行的核心功能之一，一般不需要我们特别关注。</p><p>但是过多的上下文切换会消耗 CPU 的时间来保存和恢复寄存器、内核栈、虚拟内存等数据，从而缩短进程的实际运行时间，导致系统整体性能显着下降。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/3fJvAjgPmi6N8XUQ4QII4w&quot;&gt;https://mp.weixin.qq.com/s/3fJvAjgPmi6N8XUQ4QII4w&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em</summary>
      
    
    
    
    <category term="linux" scheme="http://zhangyu.info/categories/linux/"/>
    
    
    <category term="linux" scheme="http://zhangyu.info/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>微服务架构及设计模式</title>
    <link href="http://zhangyu.info/2022/04/23/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E5%8F%8A%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    <id>http://zhangyu.info/2022/04/23/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E5%8F%8A%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</id>
    <published>2022-04-22T16:00:00.000Z</published>
    <updated>2022-04-23T14:12:56.733Z</updated>
    
    <content type="html"><![CDATA[<p> <a href="https://colstuwjx.github.io/2020/01/%E7%BF%BB%E8%AF%91-%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E5%8F%8A%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">https://colstuwjx.github.io/2020/01/%E7%BF%BB%E8%AF%91-%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E5%8F%8A%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</a></p><p>原文：<a href="https://medium.com/@madhukaudantha/microservice-architecture-and-design-patterns-for-microservices-e0e5013fd58a">https://medium.com/@madhukaudantha/microservice-architecture-and-design-patterns-for-microservices-e0e5013fd58a</a></p><blockquote><p>本文介绍了主流常见的微服务模式。</p><p>微服务能够对企业产生积极影响。因此，了解如何处理微服务架构（MSA）以及一些微服务设计模式，一个微服务架构的一些通用目标或者设计原则是很有价值的。下面是在微服务架构方案中值得考虑的四个目标[1]。</p><p>1、缩减成本：MSA将会降低设计、实现和维护IT服务的总体成本</p><p>2、加快发布速度：MSA将会加快服务从想法到部署的落地速度</p><p>3、增强弹性：MSA将会提升我们服务网络的弹性</p><p>4、开启可见性：MSA支持为服务和网络提供更好的可见性</p><p>你需要了解建设微服务架构背后的几个设计原则：</p><ul><li>  可扩展性</li><li>  可用性</li><li>  韧性</li><li>  灵活性</li><li>  独立自主性，自治性</li><li>  去中心化治理</li><li>  故障隔离</li><li>  自动装配</li><li>  通过 DevOps 持续交付</li></ul><p>听取上述原则，在你实施的解决方案或系统付诸实践的同时，这也会带来一些挑战和问题。这些问题在许多解决方案中也很常见。使用正确及匹配的设计模式可以克服这些问题。微服务有一些设计模式，这可以大体分为五类。每类都包含许多具体的设计模式。下图展示了这些设计模式。</p><p><img src="https://colstuwjx.github.io/images/2019/Dec/design-patterns.png" alt="Design Patterns for Microservices"></p><p><em>图1 微服务设计模式</em></p><h2 id="分解模式"><a href="#分解模式" class="headerlink" title="分解模式"></a>分解模式</h2><h3 id="按业务功能进行分解"><a href="#按业务功能进行分解" class="headerlink" title="按业务功能进行分解"></a>按业务功能进行分解</h3><p>说白了，微服务就是要应用单一职责原则，把服务改造成松耦合式的。它可以按照业务功能进行分解。定义和业务功能相对应的服务。业务功能是一个来自业务架构建模 [2] 的概念。它是一个企业为了创造价值而要去做的某些事情。一个业务功能往往对应于一个业务对象，比如：</p><ul><li>  订单管理负责订单</li><li>  客户管理则是负责客户</li></ul><h3 id="按问题子域进行分解"><a href="#按问题子域进行分解" class="headerlink" title="按问题子域进行分解"></a>按问题子域进行分解</h3><p>按照业务功能来分解一个应用程序可能会是一个不错的开始，但是你终将会遇到所谓的“神类”，它很难再被分解。这些类将在多个服务之间都是通用的。可以定义一些和领域驱动设计（DDD）里面的子域相对应的服务。DDD 把应用程序的问题空间 —— 也即是业务 —— 称之为域。一个域由多个子域组成。每个子域对应业务的各个不同部分。</p><p>子域可以分为如下几类：</p><ul><li><p>  核心 —— 业务的核心竞争力以及应用程序最有价值的部分</p></li><li><p>  支撑 —— 和业务有关但并不是一个核心竞争力。这些可以在内部实现也可以外包</p></li><li><p>  通用 —— 不特定于业务，而且在理想情况下可以使用现成的软件实现</p></li></ul><p>一个订单管理的子域包括：</p><ul><li><p>  产品目录服务</p></li><li><p>  库存管理服务</p></li><li><p>  订单管理服务</p></li><li><p>  配送管理服务</p></li></ul><h3 id="按事务-两阶段提交（2pc）模式进行分解"><a href="#按事务-两阶段提交（2pc）模式进行分解" class="headerlink" title="按事务/两阶段提交（2pc）模式进行分解"></a>按事务/两阶段提交（2pc）模式进行分解</h3><p>你可以通过事务分解服务。然后，这样一来系统里将会存在多个事务。事务处理协调器[3]是分布式事务处理的重要参与者之一。分布式事务包括两个步骤：</p><ul><li><p>  准备阶段 —— 在这个阶段，事务的所有参与者都准备提交并通知协调员他们已准备好完成事务</p></li><li><p>  提交或回滚阶段 —— 在这个阶段，事务协调器向所有参与者发出提交或回滚命令</p></li></ul><p>2PC 的问题在于，和单个微服务的运行时间相比，它显得相当慢。即便这些微服务跑在相同的网络里，它们之间的事务协调也确实会减慢系统速度，因此这种方法通常不适用于高负载情况。</p><h3 id="绞杀者模式（Strangler-Pattern）"><a href="#绞杀者模式（Strangler-Pattern）" class="headerlink" title="绞杀者模式（Strangler Pattern）"></a>绞杀者模式（Strangler Pattern）</h3><p>上面三种，我们看到的这几个设计模式都是用来分解绿场（Greenfield）的应用程序，但是往往我们所做的工作中有 80％ 是针对灰场（brownfield）应用程序，它们是一些大型的单体应用程序（历史遗留的代码库）。绞杀者模式可以解决这类问题。它会创建两个单独的应用程序，它们并排跑在同一个 URI 空间里。随着时间的流逝，直到最后，新重构的应用程序会“干掉”或替换原有的应用程序，此时就可以关掉那个老的单体应用程序。绞杀应用程序的步骤分别是转换，共存和消除[4]：</p><ul><li><p>  转换（Transform） —— 使用现代方法创建一个并行的全新站点。</p></li><li><p>  共存（Coexist） —— 让现有站点保留一段时间。把针对现有站点的访问重定向到新站点，以便逐步实现所需功能。</p></li><li><p>  消除（Eliminate） —— 从现有站点中删除旧功能。</p></li></ul><h3 id="隔舱模式（Bulkhead-Pattern）"><a href="#隔舱模式（Bulkhead-Pattern）" class="headerlink" title="隔舱模式（Bulkhead Pattern）"></a>隔舱模式（Bulkhead Pattern）</h3><p>让一个应用程序的元素和池子相对隔离，这样一来，其他应用程序将可以继续正常工作。这种模式被称为“隔舱”，因为它类似于船体的分段分区。根据使用者负载和可用性要求，将服务实例分成不同的组。这种设计有助于隔离故障，并允许用户即使在故障期间仍可为某些使用者维持服务。</p><h3 id="边车模式"><a href="#边车模式" class="headerlink" title="边车模式"></a>边车模式</h3><p>该模式将一个应用程序的组件部署到一个单独的处理器容器里以提供隔离和封装。它还允许应用程序由异构的组件和技术组成。这种模式被称为边车模式（Sidecar），因为它类似于连接到摩托车的侧边车。在该模式中，侧边车会附加到父应用程序，并为该应用程序提供功能支持。Sidecar 还与父应用程序共享相同的生命周期，并与父应用程序一起创建和退出。Sidecar 模式有时也称为 sidekick 模式，这是我们在文章中列出的最后一个分解模式。</p><h2 id="集成模式"><a href="#集成模式" class="headerlink" title="集成模式"></a>集成模式</h2><h3 id="API-网关模式"><a href="#API-网关模式" class="headerlink" title="API 网关模式"></a>API 网关模式</h3><p>当一个应用程序被分解成多个较小的微服务时，这里会出现一些需要解决的问题：</p><ul><li><p>  存在不同渠道对多个微服务的多次调用</p></li><li><p>  需要处理不同类型的协议</p></li><li><p>  不同的消费者可能需要不同的响应格式</p></li></ul><p>API 网关有助于解决微服务实现引发的诸多问题，而不仅限于上述提到的这些。</p><ul><li><p>  API 网关是任何微服务调用的单一入口点</p></li><li><p>  它可以用作将请求路由到相关微服务的代理服务</p></li><li><p>  它可以汇总结果并发送回消费者</p></li><li><p>  该解决方案可以为每种特定类型的客户端创建一个细粒度的 API</p></li><li><p>  它还可以转换协议请求并做出响应</p></li><li><p>  它也可以承担微服务的身份验证/授权的责任。</p></li></ul><h3 id="聚合器模式（Aggregator-Pattern）"><a href="#聚合器模式（Aggregator-Pattern）" class="headerlink" title="聚合器模式（Aggregator Pattern）"></a>聚合器模式（Aggregator Pattern）</h3><p>将业务功能分解成几个较小的逻辑代码段后就有必要考虑如何协同每个服务返回的数据。不能把这个职责留给消费者。</p><p>聚合器模式有助于解决这个问题。<strong>它讨论了如何聚合来自不同服务的数据，然后将最终响应发送给消费者。</strong>这里有两种实现方式[6]：</p><p>1、一个组合微服务将调用所有必需的微服务，合并数据，然后在发送回数据之前对其进行转换合成</p><p>2、一个 API 网关还可以将请求划分成多个微服务，然后在将数据发送给使用者之前汇总数据</p><p>如果要应用一些业务逻辑的话，建议选择一个组合式的微服务。除此之外，API 网关作为这个问题的解决方案已经是既定的事实标准。</p><h3 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h3><p>针对 API 网关，我们只是借助它来对外公开我们的微服务。引入 API 网关后，我们得以获得一些像安全性和对 API 进行分类这样的 API 层面功能。在这个例子里，API 网关有三个 API 模块：</p><p>1、移动端 API，它实现了 FTGO 移动客户端的 API 2、浏览器端 API，它实现了在浏览器里运行的 JavaScript 应用程序的 API 3、公共API，它实现了一些第三方开发人员需要的 API</p><h3 id="网关路由模式"><a href="#网关路由模式" class="headerlink" title="网关路由模式"></a>网关路由模式</h3><p>API 网关负责路由请求。一个 API 网关通过将请求路由到相应的服务来实现一些 API 操作。当 API 网关接收到请求时，它会查询一个路由映射，该路由映射指定了将请求路由到哪个服务。一个路由映射可以将一个 HTTP 方法和路径映射到服务的 HTTP URL。这种做法和像 NGINX 这样的 Web 服务器提供的反向代理功能一样。</p><h3 id="链式微服务模式（Chained-Microservice-Pattern）"><a href="#链式微服务模式（Chained-Microservice-Pattern）" class="headerlink" title="链式微服务模式（Chained Microservice Pattern）"></a>链式微服务模式（Chained Microservice Pattern）</h3><p>单个服务或者微服务将会有多级依赖，举个例子：Sale 的微服务依赖 Product 微服务和 Order 微服务。链式微服务设计模式将帮助你提供合并后的请求结果。microservice-1 接收到请求后，该请求随后与 microservice-2 进行通信，还有可能正在和 microservice-3 通信。所有这些服务都是同步调用。</p><h3 id="分支模式"><a href="#分支模式" class="headerlink" title="分支模式"></a>分支模式</h3><p>一个微服务可能需要从包括其他微服务在内的多个来源获取数据。分支微服务模式是聚合器和链式设计模式的混合，并允许来自两个或多个微服务的同时请求/响应处理。调用的微服务可以是一个微服务链。分支模式还可用于根据你的业务需求调用不同的微服务链或单个链。</p><h3 id="客户端UI组合模式"><a href="#客户端UI组合模式" class="headerlink" title="客户端UI组合模式"></a>客户端UI组合模式</h3><p>通过分解业务功能/子域来开发服务时，负责用户体验的服务必须从多个微服务中提取数据。在一个单体世界里，过去只有一个从 UI 到后端服务的调用，它会检索所有数据然后刷新/提交 UI 页面。但是，现在不一样了。对于微服务而言，我们必须把 UI 设计成一个具有屏幕/页面的多个板块/区域的框架。每个板块都将调用一个单独的后端微服务以提取数据。诸如 AngularJS 和 ReactJS 之类的框架可以帮助我们轻松地实现这一点。这些屏幕称为单页应用程序（SPA）。每个团队都开发一个客户端 UI 组件，比如一个 AngularJS 指令，该组件实现其服务的页面/屏幕区域。UI 团队负责通过组合多个特定服务的 UI 组件来实现构建页面/屏幕的页面框架。</p><h2 id="数据库模式"><a href="#数据库模式" class="headerlink" title="数据库模式"></a>数据库模式</h2><p>给微服务定义数据库架构时，我们需要考虑以下几点：</p><p>1、服务必须是松耦合的。这样它们可以独立开发，部署和扩展</p><p>2、业务事务可能会强制跨越多个服务的不变量</p><p>3、一些业务事务需要查询多个服务的数据</p><p>4、为了可扩展性考虑，数据库有时候必须是可复制和共享的</p><p>5、不同服务存在不同的数据存储要求</p><h3 id="每个服务一套数据库"><a href="#每个服务一套数据库" class="headerlink" title="每个服务一套数据库"></a>每个服务一套数据库</h3><p>为了解决上述问题，必须为每个微服务设计一个数据库。它必须仅专用于该服务。应当只能通过微服务的 API 访问它。其他服务无法直接访问它。比如，针对关系型数据库，我们可以采用每个服务使用单独的专用表（private-tables-per-service），每个服务单独的数据库模式（schema-per-service）或每个服务单独的数据库服务器（database-server-per-service）。</p><h3 id="服务之间共享数据库"><a href="#服务之间共享数据库" class="headerlink" title="服务之间共享数据库"></a>服务之间共享数据库</h3><p>我们已经说过，在微服务里，为每个服务分配一套单独的数据库是理想方案。采用共享数据库在微服务里属于反模式。但是，如果应用程序是一个单体应用而且试图拆分成微服务，那么反正规化就不那么容易了。在后面的阶段里，我们可以转到每个服务一套数据库的模式，直到我们完全做到了这一点。服务之间共享数据库并不理想，但是对于上述情况，它是一个切实可行的解决方案。大多数人认为这是微服务的反模式，但是对于灰场应用程序，这是将应用程序分解成更小逻辑部分的一个很好的开始。值得一提的是，这不应当应用于绿场应用程序。</p><h3 id="命令和查询职责分离-CQRS"><a href="#命令和查询职责分离-CQRS" class="headerlink" title="命令和查询职责分离 (CQRS)"></a>命令和查询职责分离 (CQRS)</h3><p>一旦实现了每个服务分配单独一套数据库（database-per-service），自然就会产生查询需求，这需要联合来自多个服务的数据。然而这是不可能的。CQRS 建议将应用程序分成两部分 —— 命令端和查询端。</p><ul><li><p>  命令端处理创建，更新和删除请求</p></li><li><p>  查询端通过使用物化视图来处理查询部分</p></li></ul><p>这通常会搭配事件驱动模式（event sourcing pattern）一起使用，一旦有任何数据更改便会创建对应的事件。通过订阅事件流，我们便可以让物化视图保持更新。</p><h3 id="事件驱动"><a href="#事件驱动" class="headerlink" title="事件驱动"></a>事件驱动</h3><p>绝大多数应用程序需要用到数据，典型的做法就是应用程序要维护当前状态。例如，在传统的创建，读取，更新和删除（CRUD）模型中，典型的数据流程是从存储中读取数据。它也包含了经常使用事务导致锁定数据的限制。</p><p>事件驱动模式[7]定义了一种方法，用于处理由一系列事件驱动的数据操作，每个事件都记录在一个 append-only 的存储中。应用程序代码向事件存储发送一系列事件，这些事件命令式的描述了对数据执行的每个操作，它们会被持久化到事件存储。每个事件代表一组数据更改（例如，AddedItemToOrder）。</p><p>这些事件将保留在充当记录系统的一个事件存储里。事件存储发布的事件的典型用途是在应用程序触发的一些动作更改实体时维护这些实体的物化视图，以及与外部系统集成。例如，一个系统可以维护一个用于填充 UI 部分所有客户订单的物化视图。当应用程序添加新订单，添加或删除订单中的项目以及添加运输信息时，描述这些更改的事件将会得到处理并用于更新物化视图。下图展示了该模式的一个概览。</p><p><img src="https://colstuwjx.github.io/images/2019/Dec/event-sourcing.png" alt="Event Sourcing Pattern"></p><p><em>图2 事件驱动模式[8]</em></p><h2 id="Saga模式"><a href="#Saga模式" class="headerlink" title="Saga模式"></a>Saga模式</h2><p>当每个服务都有它们自己的数据库，并且一个业务事务跨越多个服务时，我们该如何确保各个服务之间的数据一致性呢？ 每个请求都有一个补偿请求，它会在请求失败时执行。这可以通过两种方式实现：</p><ul><li>  编舞（Choreography） —— 在没有中央协调的情况下，每个服务都会生成并侦听另一个服务的事件，并决定是否应该采取措施。编舞是一种指定两个或多个参与方的方案。任何一方都无法控制对方的流程，或者对这些流程有任何可见性，无法协调他们的活动和流程以共享信息和值。当需要跨控制/可见性域进行协调时，请使用编舞的方式。参考一个简单场景，你可以把编舞看作和网络协议类似。它规定了各方之间可接受的请求和响应模式。</li></ul><p><img src="https://colstuwjx.github.io/images/2019/Dec/saga-pattern.png" alt="sage pattern"></p><p><em>图3 Saga模式 —— 编舞</em></p><ul><li>  编排（Orchestration） —— 一个编排器（对象）会负责 saga 的决策和业务逻辑排序。此时你可以控制流程中的所有参与者。当它们全部处于一个控制域时，你可以控制该活动的流程。当然，这通常是你被指派到一个拥有控制权的组织里制定业务流程。</li></ul><p><img src="https://colstuwjx.github.io/images/2019/Dec/saga-pattern-orchestration.png" alt="saga-pattern-orchestration"></p><p><em>图4 Saga模式 —— 编排</em></p><h2 id="可观测性模式"><a href="#可观测性模式" class="headerlink" title="可观测性模式"></a>可观测性模式</h2><h3 id="日志聚合"><a href="#日志聚合" class="headerlink" title="日志聚合"></a>日志聚合</h3><p>考虑一个应用程序包含多个服务的用例。请求通常跨越多个服务实例。每个服务实例均采用标准格式生成日志文件。我们需要一个集中式的日志记录服务，该服务可以汇总每个服务实例的日志。用户可以搜索和分析日志。他们可以配置在某些消息出现在日志中时触发告警。例如，PCF 就有日志聚合器，它在应用侧从 PCF 平台的每个组件（router、controller、diego等）收集日志。AWS Cloud Watch 也是这样做的。</p><h3 id="性能指标"><a href="#性能指标" class="headerlink" title="性能指标"></a>性能指标</h3><p>当服务组合由于引入了微服务架构而增加时，保持对事务的监控就变得尤为关键了，如此一来就可以监控这些模式，而当有问题发生时便会发送告警。</p><p>此外，需要一个度量服务来收集有关单个操作的统计信息。它应当聚合一个应用服务的指标数据，它会用来报告和告警。这里有两种用于汇总指标的模型：</p><ul><li>  推送 —— 服务将指标推送到指标服务，例如 NewRelic，AppDynamics</li><li>  提取 —— 指标服务从服务中提取指标，例如 Prometheus</li></ul><h3 id="分布式链路追踪"><a href="#分布式链路追踪" class="headerlink" title="分布式链路追踪"></a>分布式链路追踪</h3><p>在微服务架构里，请求通常跨越多个服务。每个服务通过跨越多个服务执行一个或多个操作来处理请求。在排障时，有一个 Trace ID 是很有帮助的，我们可以端对端地跟踪一个请求。</p><p>解决方案便是引入一个事务ID。可以采用如下方式：</p><ul><li>  为每个外部请求分配一个唯一的外部请求ID</li><li>  将外部请求ID传递给处理该请求链路的所有服务</li><li>  在所有日志消息中加入该外部请求ID</li></ul><h3 id="健康检查"><a href="#健康检查" class="headerlink" title="健康检查"></a>健康检查</h3><p>实施微服务架构后，服务可能会出现启动了但是无法处理事务的情况。每个服务都需要有一个可用于检查应用程序运行状况的 API 端点，例如 /health。该 API 应该检查主机的状态，与其他服务/基础设施的连接以及任何其他特定的逻辑。</p><h2 id="横切关注点模式（Cross-Cutting-Concern-Patterns）"><a href="#横切关注点模式（Cross-Cutting-Concern-Patterns）" class="headerlink" title="横切关注点模式（Cross-Cutting Concern Patterns）"></a>横切关注点模式（Cross-Cutting Concern Patterns）</h2><h3 id="外部配置"><a href="#外部配置" class="headerlink" title="外部配置"></a>外部配置</h3><p>一个服务通常还会调用其他服务和数据库。对于dev，QA，UAT，Prod等每个环境而言，API 端点的 URL 或某些配置属性可能会有所不同。这些属性中的任何一个更改都可能需要重新构建和重新部署服务。</p><p>为避免代码修改，可以使用配置。把所有配置放到外面，包括端点 URL 和证书。应用程序应该在启动时或运行时加载它们。这些可以在启动时由应用程序访问，也可以在不重新启动服务器的情况下进行刷新。</p><h3 id="服务发现模式"><a href="#服务发现模式" class="headerlink" title="服务发现模式"></a>服务发现模式</h3><p>在微服务出现时，我们需要在调用服务方面解决一些问题。</p><p>借助容器技术，IP地址可以动态地分配给服务实例。每次地址更改时，消费端服务都会中断并且需要手动更改。</p><p>对于消费端服务来说，它们必须记住每个上游服务的 URL ，这就变成紧耦合了。</p><p>为此，需要创建一个服务注册中心，该注册表将保留每个生产者服务的元数据和每个服务的配置。服务实例在启动时应当注册到注册中心，而在关闭时应当注销。服务发现有两种类型：</p><ul><li>  客户端：例如：Netflix Eureka</li><li>  服务端：例如：AWS ALB</li></ul><p><img src="https://colstuwjx.github.io/images/2019/Dec/service-discovery.png" alt="service-discovery"></p><p><em>图5 服务发现[9]</em></p><h3 id="熔断器模式"><a href="#熔断器模式" class="headerlink" title="熔断器模式"></a>熔断器模式</h3><p>一个服务通常会通过调用其他服务来检索数据，而这时候下游服务可能已经挂了。这样的话，有两个问题：首先，请求将继续抵达挂了的服务，耗尽网络资源，并且降低性能。其次，用户体验将是糟糕且不可预测的。</p><p>消费端服务应通过代理来调用远程服务，该代理的表现和一个电流断路器类似。当连续的故障数超过阈值时，断路器将跳闸，并且在超时期间内，所有调用远程服务的尝试都会立即失败。超时到期后，断路器将允许有限数量的测试请求通过。如果这些请求成功，断路器则将恢复正常运行。否则，如果发生故障的话，超时时间则将再次重新开始计算。如果某些操作失败概率很高的话，采取此模式有助于防止应用程序在故障发生后仍然不断尝试调用远程服务或访问共享资源。</p><p><img src="https://colstuwjx.github.io/images/2019/Dec/circuit-breaker.png" alt="circuit-breaker"></p><p><em>图6 熔断器模式[10]</em></p><h3 id="蓝绿部署模式"><a href="#蓝绿部署模式" class="headerlink" title="蓝绿部署模式"></a>蓝绿部署模式</h3><p>使用微服务架构时，一个应用可以被拆分成许多个微服务。如果我们采用停止所有服务然后再部署改进版本的方式的话，宕机时间将是非常可观的，并且会影响业务。同样，回滚也将是一场噩梦。 蓝绿部署模式可以避免这种情况。</p><p>实施蓝绿部署策略可以用来减少或消除宕机。它通过运行两个相同的生产环境，Blue 和Green 来实现这一目标。 假设 Green 是现有的活动实例，Blue 是该应用程序的新版本。在任何时候，只有一个环境处于活动状态，该活动环境为所有生产流量提供服务。所有云平台均提供了用于实施蓝绿部署的选项。</p><p><img src="https://colstuwjx.github.io/images/2019/Dec/blue-green-deployment-pattern.png" alt="blue-green-deployment-pattern"></p><p><em>图7 蓝绿部署模式</em></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>[1] “Microservice Architecture: Aligning Principles, Practices, and Culture” Book by Irakli Nadareishvili, Matt McLarty, and Michael Amundsen</p><p>[2] <a href="https://microservices.io/patterns/decomposition/decompose-by-business-capability.html">https://microservices.io/patterns/decomposition/decompose-by-business-capability.html</a></p><p>[3] <a href="https://www.baeldung.com/transactions-across-microservices">https://www.baeldung.com/transactions-across-microservices</a></p><p>[4] <a href="https://developer.ibm.com/articles/cl-strangler-application-pattern-microservices-apps-trs/">https://developer.ibm.com/articles/cl-strangler-application-pattern-microservices-apps-trs/</a></p><p>[5] <a href="https://docs.microsoft.com/en-us/azure/architecture/patterns/bulkhead">https://docs.microsoft.com/en-us/azure/architecture/patterns/bulkhead</a></p><p>[6] <a href="https://dzone.com/articles/design-patterns-for-microservices">https://dzone.com/articles/design-patterns-for-microservices</a></p><p>[7] <a href="https://docs.microsoft.com/en-us/azure/architecture/patterns/cqrs#event-sourcing-and-cqrs">https://docs.microsoft.com/en-us/azure/architecture/patterns/cqrs#event-sourcing-and-cqrs</a></p><p>[8] <a href="https://docs.microsoft.com/en-us/azure/architecture/patterns/event-sourcing">https://docs.microsoft.com/en-us/azure/architecture/patterns/event-sourcing</a></p><p>[9] <a href="https://www.dineshonjava.com/microservices-with-spring-boot/">https://www.dineshonjava.com/microservices-with-spring-boot/</a></p><p>[10] <a href="https://docs.microsoft.com/en-us/azure/architecture/patterns/circuit-breaker">https://docs.microsoft.com/en-us/azure/architecture/patterns/circuit-breaker</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; &lt;a href=&quot;https://colstuwjx.github.io/2020/01/%E7%BF%BB%E8%AF%91-%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E5%8F%8A%E8%AE%BE%E8%AE%A1</summary>
      
    
    
    
    <category term="架构" scheme="http://zhangyu.info/categories/%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="架构" scheme="http://zhangyu.info/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>打造一套客户端功能最全的APM监控系统</title>
    <link href="http://zhangyu.info/2022/04/23/%E6%89%93%E9%80%A0%E4%B8%80%E5%A5%97%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%8A%9F%E8%83%BD%E6%9C%80%E5%85%A8%E7%9A%84APM%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"/>
    <id>http://zhangyu.info/2022/04/23/%E6%89%93%E9%80%A0%E4%B8%80%E5%A5%97%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%8A%9F%E8%83%BD%E6%9C%80%E5%85%A8%E7%9A%84APM%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/</id>
    <published>2022-04-22T16:00:00.000Z</published>
    <updated>2022-04-23T14:24:50.485Z</updated>
    
    <content type="html"><![CDATA[<blockquote><h1 id="打造一套客户端功能最全的-APM-监控系统"><a href="#打造一套客户端功能最全的-APM-监控系统" class="headerlink" title="打造一套客户端功能最全的 APM 监控系统"></a><a href="https://segmentfault.com/a/1190000040277799">打造一套客户端功能最全的 APM 监控系统</a></h1><p> <strong>杭城小刘</strong> 发布于 2021-07-02</p><blockquote><p>APM 是 Application Performance Monitoring 的缩写，监视和管理软件应用程序的性能和可用性。应用性能管理对一个应用的持续稳定运行至关重要。所以这篇文章就从一个 iOS App 的性能管理的纬度谈谈如何精确监控以及数据如何上报等技术点</p></blockquote><p>App 的性能问题是影响用户体验的重要因素之一。性能问题主要包含：Crash、网络请求错误或者超时、UI 响应速度慢、主线程卡顿、CPU 和内存使用率高、耗电量大等等。大多数的问题原因在于开发者错误地使用了线程锁、系统函数、编程规范问题、数据结构等等。解决问题的关键在于尽早的发现和定位问题。</p><p>本篇文章着重总结了 APM 的原因以及如何收集数据。APM 数据收集后结合数据上报机制，按照一定策略上传数据到服务端。服务端消费这些信息并产出报告。请结合<a href="https://link.segmentfault.com/?enc=3WWrfendOrHHUYaFUFmEWQ==.gXyR2KjStFj13n8ud2G51sMBu7j/K1MBzaJfRUnJZV1p11+6W2vj1HjCb0fDrYc3Kao0BOufcvbrp+SvLAUkl0nxS4839kyL6sa8Y1fPC9gGbVJXVBqa4xwWlJl+Gmla">姊妹篇</a>， 总结了如何打造一款灵活可配置、功能强大的数据上报组件。</p><h2 id="一、卡顿监控"><a href="#一、卡顿监控" class="headerlink" title="一、卡顿监控"></a>一、卡顿监控</h2><p>卡顿问题，就是在主线程上无法响应用户交互的问题。影响着用户的直接体验，所以针对 App 的卡顿监控是 APM 里面重要的一环。</p><p>FPS（frame per second）每秒钟的帧刷新次数，iPhone 手机以 60 为最佳，iPad 某些型号是 120，也是作为卡顿监控的一项参考参数，为什么说是参考参数？因为它不准确。先说说怎么获取到 FPS。CADisplayLink 是一个系统定时器，会以帧刷新频率一样的速率来刷新视图。 <code>[CADisplayLink displayLinkWithTarget:self selector:@selector(###:)]</code>。至于为什么不准我们来看看下面的示例代码</p><p>_displayLink = [CADisplayLink displayLinkWithTarget:self selector:@selector(p_displayLinkTick:)];<br>[_displayLink setPaused:YES];<br>[_displayLink addToRunLoop:[NSRunLoop currentRunLoop] forMode:NSRunLoopCommonModes];</p><p>代码所示，CADisplayLink 对象是被添加到指定的 RunLoop 的某个 Mode 下。所以还是 CPU 层面的操作，卡顿的体验是整个图像渲染的结果：CPU + GPU。请继续往下看</p><h3 id="1-屏幕绘制原理"><a href="#1-屏幕绘制原理" class="headerlink" title="1. 屏幕绘制原理"></a>1. 屏幕绘制原理</h3><p><img src="https://segmentfault.com/img/bVbIOee"></p><p>讲讲老式的 CRT 显示器的原理。 CRT 电子枪按照上面方式，从上到下一行行扫描，扫面完成后显示器就呈现一帧画面，随后电子枪回到初始位置继续下一次扫描。为了把显示器的显示过程和系统的视频控制器进行同步，显示器（或者其他硬件）会用硬件时钟产生一系列的定时信号。当电子枪换到新的一行，准备进行扫描时，显示器会发出一个水平同步信号（horizonal synchronization），简称 HSync；当一帧画面绘制完成后，电子枪恢复到原位，准备画下一帧前，显示器会发出一个垂直同步信号（Vertical synchronization），简称 VSync。显示器通常以固定的频率进行刷新，这个固定的刷新频率就是 VSync 信号产生的频率。虽然现在的显示器基本都是液晶显示屏，但是原理保持不变。</p><p><img src="https://segmentfault.com/img/bVbIOej"></p><p>通常，屏幕上一张画面的显示是由 CPU、GPU 和显示器是按照上图的方式协同工作的。CPU 根据工程师写的代码计算好需要现实的内容（比如视图创建、布局计算、图片解码、文本绘制等），然后把计算结果提交到 GPU，GPU 负责图层合成、纹理渲染，随后 GPU 将渲染结果提交到帧缓冲区。随后视频控制器会按照 VSync 信号逐行读取帧缓冲区的数据，经过数模转换传递给显示器显示。</p><p>在帧缓冲区只有一个的情况下，帧缓冲区的读取和刷新都存在效率问题，为了解决效率问题，显示系统会引入2个缓冲区，即双缓冲机制。在这种情况下，GPU 会预先渲染好一帧放入帧缓冲区，让视频控制器来读取，当下一帧渲染好后，GPU 直接把视频控制器的指针指向第二个缓冲区。提升了效率。</p><p>目前来看，双缓冲区提高了效率，但是带来了新的问题：当视频控制器还未读取完成时，即屏幕内容显示了部分，GPU 将新渲染好的一帧提交到另一个帧缓冲区并把视频控制器的指针指向新的帧缓冲区，视频控制器就会把新的一帧数据的下半段显示到屏幕上，造成画面撕裂的情况。</p><p>为了解决这个问题，GPU 通常有一个机制叫垂直同步信号（V-Sync），当开启垂直同步信号后，GPU 会等到视频控制器发送 V-Sync 信号后，才进行新的一帧的渲染和帧缓冲区的更新。这样的几个机制解决了画面撕裂的情况，也增加了画面流畅度。但需要更多的计算资源</p><p><img src="https://segmentfault.com/img/bVbIOes"></p><p>答疑</p><p>可能有些人会看到「当开启垂直同步信号后，GPU 会等到视频控制器发送 V-Sync 信号后，才进行新的一帧的渲染和帧缓冲区的更新」这里会想，GPU 收到 V-Sync 才进行新的一帧渲染和帧缓冲区的更新，那是不是双缓冲区就失去意义了？</p><p>设想一个显示器显示第一帧图像和第二帧图像的过程。首先在双缓冲区的情况下，GPU 首先渲染好一帧图像存入到帧缓冲区，然后让视频控制器的指针直接直接这个缓冲区，显示第一帧图像。第一帧图像的内容显示完成后，视频控制器发送 V-Sync 信号，GPU 收到 V-Sync 信号后渲染第二帧图像并将视频控制器的指针指向第二个帧缓冲区。</p><p><strong>看上去第二帧图像是在等第一帧显示后的视频控制器发送 V-Sync 信号。是吗？真是这样的吗？ 😭 想啥呢，当然不是。 🐷 不然双缓冲区就没有存在的意义了</strong></p><p>揭秘。请看下图</p><p><img src="https://segmentfault.com/img/bVbIOeK"></p><p>当第一次 V-Sync 信号到来时，先渲染好一帧图像放到帧缓冲区，但是不展示，当收到第二个 V-Sync 信号后读取第一次渲染好的结果（视频控制器的指针指向第一个帧缓冲区），并同时渲染新的一帧图像并将结果存入第二个帧缓冲区，等收到第三个 V-Sync 信号后，读取第二个帧缓冲区的内容（视频控制器的指针指向第二个帧缓冲区），并开始第三帧图像的渲染并送入第一个帧缓冲区，依次不断循环往复。</p><p>请查看资料，需要梯子：<a href="https://link.segmentfault.com/?enc=n8yMZ8IDSwKEkHK7UX9mew==.rwyqrHqcabnVtvC7qgQO21Sfn3W4WPZ1Y6CbA1wv6wtXtqZAywcg1uD9Y1SmX4ad3KutIqneRAmcP4CSbb1NbQ==">Multiple buffering</a></p><h3 id="2-卡顿产生的原因"><a href="#2-卡顿产生的原因" class="headerlink" title="2. 卡顿产生的原因"></a>2. 卡顿产生的原因</h3><p><img src="https://segmentfault.com/img/bVbIOeO"></p><p>VSync 信号到来后，系统图形服务会通过 CADisplayLink 等机制通知 App，App 主线程开始在 CPU 中计算显示内容（视图创建、布局计算、图片解码、文本绘制等）。然后将计算的内容提交到 GPU，GPU 经过图层的变换、合成、渲染，随后 GPU 把渲染结果提交到帧缓冲区，等待下一次 VSync 信号到来再显示之前渲染好的结果。在垂直同步机制的情况下，如果在一个 VSync 时间周期内，CPU 或者 GPU 没有完成内容的提交，就会造成该帧的丢弃，等待下一次机会再显示，这时候屏幕上还是之前渲染的图像，所以这就是 CPU、GPU 层面界面卡顿的原因。</p><p>目前 iOS 设备有双缓存机制，也有三缓冲机制，Android 现在主流是三缓冲机制，在早期是单缓冲机制。<br><a href="https://link.segmentfault.com/?enc=yWtB/pBzC6C53LUBI/MRaA==.dtIZUu+rgO4kc9Kz1OM6fhoRFMNyKY+BUURmK4zHfeQpy9fES4w1t64pP1D3wATKgkkXQunwc71gQBONJgOH45koMcsMRQ5sc8dxbSdg81kFE0AkmutjrwopIhyMnJxE">iOS 三缓冲机制例子</a></p><p>CPU 和 GPU 资源消耗原因很多，比如对象的频繁创建、属性调整、文件读取、视图层级的调整、布局的计算（AutoLayout 视图个数多了就是线性方程求解难度变大）、图片解码（大图的读取优化）、图像绘制、文本渲染、数据库读取（多读还是多写乐观锁、悲观锁的场景）、锁的使用（举例：自旋锁使用不当会浪费 CPU）等方面。开发者根据自身经验寻找最优解（这里不是本文重点）。</p><h3 id="3-APM-如何监控卡顿并上报"><a href="#3-APM-如何监控卡顿并上报" class="headerlink" title="3. APM 如何监控卡顿并上报"></a>3. APM 如何监控卡顿并上报</h3><p>CADisplayLink 肯定不用了，这个 FPS 仅作为参考。一般来讲，卡顿的监测有2种方案：<strong>监听 RunLoop 状态回调、子线程 ping 主线程</strong></p><h4 id="3-1-RunLoop-状态监听的方式"><a href="#3-1-RunLoop-状态监听的方式" class="headerlink" title="3.1 RunLoop 状态监听的方式"></a>3.1 RunLoop 状态监听的方式</h4><p>RunLoop 负责监听输入源进行调度处理。比如网络、输入设备、周期性或者延迟事件、异步回调等。RunLoop 会接收2种类型的输入源：一种是来自另一个线程或者来自不同应用的异步消息（source0事件）、另一种是来自预定或者重复间隔的事件。</p><p>RunLoop 状态如下图<br><img src="https://segmentfault.com/img/bVbIOe3"></p><p>第一步：通知 Observers，RunLoop 要开始进入 loop，紧接着进入 loop</p><p>if (currentMode-&gt;_observerMask &amp; kCFRunLoopEntry )<br>    // 通知 Observers: RunLoop 即将进入 loop<br>    __CFRunLoopDoObservers(rl, currentMode, kCFRunLoopEntry);<br>// 进入loop<br>result = __CFRunLoopRun(rl, currentMode, seconds, returnAfterSourceHandled, previousMode);</p><p>第二步：开启 do while 循环保活线程，通知 Observers，RunLoop 触发 Timer 回调、Source0 回调，接着执行被加入的 block</p><p> if (rlm-&gt;_observerMask &amp; kCFRunLoopBeforeTimers)<br>    //  通知 Observers: RunLoop 即将触发 Timer 回调<br>    __CFRunLoopDoObservers(rl, rlm, kCFRunLoopBeforeTimers);<br>if (rlm-&gt;_observerMask &amp; kCFRunLoopBeforeSources)<br>    //  通知 Observers: RunLoop 即将触发 Source 回调<br>    __CFRunLoopDoObservers(rl, rlm, kCFRunLoopBeforeSources);<br>// 执行被加入的block<br>__CFRunLoopDoBlocks(rl, rlm);</p><p>第三步：RunLoop 在触发 Source0 回调后，如果 Source1 是 ready 状态，就会跳转到 handle_msg 去处理消息。</p><p>//  如果有 Source1 (基于port) 处于 ready 状态，直接处理这个 Source1 然后跳转去处理消息<br>if (MACH_PORT_NULL != dispatchPort &amp;&amp; !didDispatchPortLastTime) {<br>#if DEPLOYMENT_TARGET_MACOSX || DEPLOYMENT_TARGET_EMBEDDED || DEPLOYMENT_TARGET_EMBEDDED_MINI<br>    msg = (mach_msg_header_t *)msg_buffer;</p><pre><code>if (\_\_CFRunLoopServiceMachPort(dispatchPort, &amp;msg, sizeof(msg\_buffer), &amp;livePort, 0, &amp;voucherState, NULL)) &#123;    goto handle\_msg;&#125;</code></pre><p>#elif DEPLOYMENT_TARGET_WINDOWS<br>    if (__CFRunLoopWaitForMultipleObjects(NULL, &amp;dispatchPort, 0, 0, &amp;livePort, NULL)) {<br>        goto handle_msg;<br>    }<br>#endif<br>}</p><p>第四步：回调触发后，通知 Observers 即将进入休眠状态</p><p>Boolean poll = sourceHandledThisLoop || (0ULL == timeout_context-&gt;termTSR);<br>// 通知 Observers: RunLoop 的线程即将进入休眠(sleep)<br>if (!poll &amp;&amp; (rlm-&gt;_observerMask &amp; kCFRunLoopBeforeWaiting)) __CFRunLoopDoObservers(rl, rlm, kCFRunLoopBeforeWaiting);<br>    __CFRunLoopSetSleeping(rl);</p><p>第五步：进入休眠后，会等待 mach_port 消息，以便再次唤醒。只有以下4种情况才可以被再次唤醒。</p><ul><li><p>  基于 port 的 source 事件</p></li><li><p>  Timer 时间到</p></li><li><p>  RunLoop 超时</p></li><li><p>被调用者唤醒</p><p>  do {</p><pre><code>if (kCFUseCollectableAllocator) &#123;    // objc\_clear\_stack(0);    // &lt;rdar://problem/16393959&gt;    memset(msg\_buffer, 0, sizeof(msg\_buffer));&#125;msg = (mach\_msg\_header\_t \*)msg\_buffer;\_\_CFRunLoopServiceMachPort(waitSet, &amp;msg, sizeof(msg\_buffer), &amp;livePort, poll ? 0 : TIMEOUT\_INFINITY, &amp;voucherState, &amp;voucherCopy);if (modeQueuePort != MACH\_PORT\_NULL &amp;&amp; livePort == modeQueuePort) &#123;    // Drain the internal queue. If one of the callout blocks sets the timerFired flag, break out and service the timer.    while (\_dispatch\_runloop\_root\_queue\_perform\_4CF(rlm-&gt;\_queue));    if (rlm-&gt;\_timerFired) &#123;        // Leave livePort as the queue port, and service timers below        rlm-&gt;\_timerFired = false;        break;    &#125; else &#123;        if (msg &amp;&amp; msg != (mach\_msg\_header\_t \*)msg\_buffer) free(msg);    &#125;&#125; else &#123;    // Go ahead and leave the inner loop.    break;&#125;</code></pre><p>  } while (1);</p></li></ul><p>第六步：唤醒时通知 Observer，RunLoop 的线程刚刚被唤醒了</p><p>// 通知 Observers: RunLoop 的线程刚刚被唤醒了<br>if (!poll &amp;&amp; (rlm-&gt;_observerMask &amp; kCFRunLoopAfterWaiting)) __CFRunLoopDoObservers(rl, rlm, kCFRunLoopAfterWaiting);<br>    // 处理消息<br>    handle_msg:;<br>    __CFRunLoopSetIgnoreWakeUps(rl);</p><p>第七步：RunLoop 唤醒后，处理唤醒时收到的消息</p><ul><li><p>  如果是 Timer 时间到，则触发 Timer 的回调</p></li><li><p>  如果是 dispatch，则执行 block</p></li><li><p>如果是 source1 事件，则处理这个事件</p><p>  #if USE_MK_TIMER_TOO</p><pre><code>    // 如果一个 Timer 到时间了，触发这个Timer的回调    else if (rlm-&gt;\_timerPort != MACH\_PORT\_NULL &amp;&amp; livePort == rlm-&gt;\_timerPort) &#123;        CFRUNLOOP\_WAKEUP\_FOR\_TIMER();        // On Windows, we have observed an issue where the timer port is set before the time which we requested it to be set. For example, we set the fire time to be TSR 167646765860, but it is actually observed firing at TSR 167646764145, which is 1715 ticks early. The result is that, when \_\_CFRunLoopDoTimers checks to see if any of the run loop timers should be firing, it appears to be &#39;too early&#39; for the next timer, and no timers are handled.        // In this case, the timer port has been automatically reset (since it was returned from MsgWaitForMultipleObjectsEx), and if we do not re-arm it, then no timers will ever be serviced again unless something adjusts the timer list (e.g. adding or removing timers). The fix for the issue is to reset the timer here if CFRunLoopDoTimers did not handle a timer itself. 9308754        if (!\_\_CFRunLoopDoTimers(rl, rlm, mach\_absolute\_time())) &#123;            // Re-arm the next timer            \_\_CFArmNextTimerInMode(rlm, rl);        &#125;    &#125;</code></pre><p>  #endif</p><pre><code>    //  如果有dispatch到main\_queue的block，执行block    else if (livePort == dispatchPort) &#123;        CFRUNLOOP\_WAKEUP\_FOR\_DISPATCH();        \_\_CFRunLoopModeUnlock(rlm);        \_\_CFRunLoopUnlock(rl);        \_CFSetTSD(\_\_CFTSDKeyIsInGCDMainQ, (void \*)6, NULL);</code></pre><p>  #if DEPLOYMENT_TARGET_WINDOWS</p><pre><code>        void \*msg = 0;</code></pre><p>  #endif</p><pre><code>        \_\_CFRUNLOOP\_IS\_SERVICING\_THE\_MAIN\_DISPATCH\_QUEUE\_\_(msg);        \_CFSetTSD(\_\_CFTSDKeyIsInGCDMainQ, (void \*)0, NULL);        \_\_CFRunLoopLock(rl);        \_\_CFRunLoopModeLock(rlm);        sourceHandledThisLoop = true;        didDispatchPortLastTime = true;    &#125;    // 如果一个 Source1 (基于port) 发出事件了，处理这个事件    else &#123;        CFRUNLOOP\_WAKEUP\_FOR\_SOURCE();        // If we received a voucher from this mach\_msg, then put a copy of the new voucher into TSD. CFMachPortBoost will look in the TSD for the voucher. By using the value in the TSD we tie the CFMachPortBoost to this received mach\_msg explicitly without a chance for anything in between the two pieces of code to set the voucher again.        voucher\_t previousVoucher = \_CFSetTSD(\_\_CFTSDKeyMachMessageHasVoucher, (void \*)voucherCopy, os\_release);        CFRunLoopSourceRef rls = \_\_CFRunLoopModeFindSourceForMachPort(rl, rlm, livePort);        if (rls) &#123;</code></pre><p>  #if DEPLOYMENT_TARGET_MACOSX || DEPLOYMENT_TARGET_EMBEDDED || DEPLOYMENT_TARGET_EMBEDDED_MINI</p><pre><code>    mach\_msg\_header\_t \*reply = NULL;    sourceHandledThisLoop = \_\_CFRunLoopDoSource1(rl, rlm, rls, msg, msg-&gt;msgh\_size, &amp;reply) || sourceHandledThisLoop;    if (NULL != reply) &#123;        (void)mach\_msg(reply, MACH\_SEND\_MSG, reply-&gt;msgh\_size, 0, MACH\_PORT\_NULL, 0, MACH\_PORT\_NULL);        CFAllocatorDeallocate(kCFAllocatorSystemDefault, reply);    &#125;</code></pre><p>  #elif DEPLOYMENT_TARGET_WINDOWS</p><pre><code>            sourceHandledThisLoop = \_\_CFRunLoopDoSource1(rl, rlm, rls) || sourceHandledThisLoop;</code></pre><p>  #endif</p></li></ul><p>第八步：根据当前 RunLoop 状态判断是否需要进入下一个 loop。当被外部强制停止或者 loop 超时，就不继续下一个 loop，否则进入下一个 loop</p><p>if (sourceHandledThisLoop &amp;&amp; stopAfterHandle) {<br>    // 进入loop时参数说处理完事件就返回<br>    retVal = kCFRunLoopRunHandledSource;<br>    } else if (timeout_context-&gt;termTSR &lt; mach_absolute_time()) {<br>        // 超出传入参数标记的超时时间了<br>        retVal = kCFRunLoopRunTimedOut;<br>} else if (__CFRunLoopIsStopped(rl)) {<br>        __CFRunLoopUnsetStopped(rl);<br>    // 被外部调用者强制停止了<br>    retVal = kCFRunLoopRunStopped;<br>} else if (rlm-&gt;_stopped) {<br>    rlm-&gt;_stopped = false;<br>    retVal = kCFRunLoopRunStopped;<br>} else if (__CFRunLoopModeIsEmpty(rl, rlm, previousMode)) {<br>    // source/timer一个都没有<br>    retVal = kCFRunLoopRunFinished;<br>}</p><p>完整且带有注释的 RunLoop 代码见<a href="https://link.segmentfault.com/?enc=4+ujjBH/lrpIClaiO1sgHw==.4NGPkCBCwzwCUKeUI03OiixGhpRfW7dcVkbAqhHmBXStW2/XOQRmaqukaiDaOHawZC/eLpoax5X2hEwn0gX1hDLwEn+JtBNB6BR5NNWgQt+A+gQ+qPNARMoQOkEZxrc2">此处</a>。 Source1 是 RunLoop 用来处理 Mach port 传来的系统事件的，Source0 是用来处理用户事件的。收到 Source1 的系统事件后本质还是调用 Source0 事件的处理函数。</p><p>RunLoop 6个状态</p><p>typedef CF_OPTIONS(CFOptionFlags, CFRunLoopActivity) {<br>    kCFRunLoopEntry ,           // 进入 loop<br>    kCFRunLoopBeforeTimers ,    // 触发 Timer 回调<br>    kCFRunLoopBeforeSources ,   // 触发 Source0 回调<br>    kCFRunLoopBeforeWaiting ,   // 等待 mach_port 消息<br>    kCFRunLoopAfterWaiting ),   // 接收 mach_port 消息<br>    kCFRunLoopExit ,            // 退出 loop<br>    kCFRunLoopAllActivities     // loop 所有状态改变<br>}</p><p>RunLoop 在进入睡眠前的方法执行时间过长而导致无法进入睡眠，或者线程唤醒后接收消息时间过长而无法进入下一步，都会阻塞线程。如果是主线程，则表现为卡顿。</p><p>一旦发现进入睡眠前的 KCFRunLoopBeforeSources 状态，或者唤醒后 KCFRunLoopAfterWaiting，在设置的时间阈值内没有变化，则可判断为卡顿，此时 dump 堆栈信息，还原案发现场，进而解决卡顿问题。</p><p>开启一个子线程，不断进行循环监测是否卡顿了。在 n 次都超过卡顿阈值后则认为卡顿了。卡顿之后进行堆栈 dump 并上报（具有一定的机制，数据处理在下一 part 讲）。</p><p>WatchDog 在不同状态下具有不同的值。</p><ul><li>  启动（Launch）：20s</li><li>  恢复（Resume）：10s</li><li>  挂起（Suspend）：10s</li><li>  退出（Quit）：6s</li><li>  后台（Background）：3min（在 iOS7 之前可以申请 10min；之后改为 3min；可连续申请，最多到 10min）</li></ul><p>卡顿阈值的设置的依据是 WatchDog 的机制。APM 系统里面的阈值需要小于 WatchDog 的值，所以取值范围在 [1, 6] 之间，业界通常选择3秒。</p><p>通过 <code>long dispatch_semaphore_wait(dispatch_semaphore_t dsema, dispatch_time_t timeout)</code> 方法判断是否阻塞主线程，<code>Returns zero on success, or non-zero if the timeout occurred.</code> 返回非0则代表超时阻塞了主线程。</p><p><img src="https://segmentfault.com/img/bVbIOfh"></p><p>可能很多人纳闷 RunLoop 状态那么多，为什么选择 KCFRunLoopBeforeSources 和 KCFRunLoopAfterWaiting？因为大部分卡顿都是在 KCFRunLoopBeforeSources 和 KCFRunLoopAfterWaiting 之间。比如 Source0 类型的 App 内部事件等</p><p>Runloop 检测卡顿流程图如下：</p><p>关键代码如下：</p><p>// 设置Runloop observer的运行环境<br>CFRunLoopObserverContext context = {0, (__bridge void *)self, NULL, NULL};<br>// 创建Runloop observer对象<br>_observer = CFRunLoopObserverCreate(kCFAllocatorDefault,<br>                                    kCFRunLoopAllActivities,<br>                                    YES,<br>                                    0,<br>                                    &amp;runLoopObserverCallBack,<br>                                    &amp;context);<br>// 将新建的observer加入到当前thread的runloop<br>CFRunLoopAddObserver(CFRunLoopGetMain(), _observer, kCFRunLoopCommonModes);<br>// 创建信号<br>_semaphore = dispatch_semaphore_create(0);</p><p>__weak __typeof(self) weakSelf = self;<br>// 在子线程监控时长<br>dispatch_async(dispatch_get_global_queue(0, 0), ^{<br>    __strong __typeof(weakSelf) strongSelf = weakSelf;<br>    if (!strongSelf) {<br>        return;<br>    }<br>    while (YES) {<br>        if (strongSelf.isCancel) {<br>            return;<br>        }<br>        // N次卡顿超过阈值T记录为一次卡顿<br>        long semaphoreWait = dispatch_semaphore_wait(self-&gt;_semaphore, dispatch_time(DISPATCH_TIME_NOW, strongSelf.limitMillisecond * NSEC_PER_MSEC));<br>        if (semaphoreWait != 0) {<br>            if (self-&gt;_activity == kCFRunLoopBeforeSources || self-&gt;_activity == kCFRunLoopAfterWaiting) {<br>                if (++strongSelf.countTime &lt; strongSelf.standstillCount){<br>                    continue;<br>                }<br>                // 堆栈信息 dump 并结合数据上报机制，按照一定策略上传数据到服务器。堆栈 dump 会在下面讲解。数据上报会在 [打造功能强大、灵活可配置的数据上报组件](<a href="https://github.com/FantasticLBP/knowledge-kit/blob/master/Chapter1%20-%20iOS/1.80.md">https://github.com/FantasticLBP/knowledge-kit/blob/master/Chapter1%20-%20iOS/1.80.md</a>) 讲<br>            }<br>        }<br>        strongSelf.countTime = 0;<br>    }<br>});</p><h4 id="3-2-子线程-ping-主线程监听的方式"><a href="#3-2-子线程-ping-主线程监听的方式" class="headerlink" title="3.2 子线程 ping 主线程监听的方式"></a>3.2 子线程 ping 主线程监听的方式</h4><p>开启一个子线程，创建一个初始值为0的信号量、一个初始值为 YES 的布尔值类型标志位。将设置标志位为 NO 的任务派发到主线程中去，子线程休眠阈值时间，时间到后判断标志位是否被主线程成功（值为 NO），如果没成功则认为主线程发生了卡顿情况，此时 dump 堆栈信息并结合数据上报机制，按照一定策略上传数据到服务器。数据上报会在 <a href="https://link.segmentfault.com/?enc=G+IqmQf5jDS7gdx4HQe5Ew==.OVUGL5Uvtof2GzureH523kZYwMTZz2GbPR81pG19p0mRZXIykiXcGms40cL/DGFT5Omf/h7tJnKxxQjnWD3WYM6I3nn0rGiHbnHLVHJ0CirCtL20e85ritrJms7CsJxL">打造功能强大、灵活可配置的数据上报组件</a> 讲</p><p>while (self.isCancelled == NO) {<br>        @autoreleasepool {<br>            __block BOOL isMainThreadNoRespond = YES;<br>            dispatch_semaphore_t semaphore = dispatch_semaphore_create(0);</p><pre><code>        dispatch\_async(dispatch\_get\_main\_queue(), ^&#123;            isMainThreadNoRespond = NO;            dispatch\_semaphore\_signal(semaphore);        &#125;);        \[NSThread sleepForTimeInterval:self.threshold\];        if (isMainThreadNoRespond) &#123;            if (self.handlerBlock) &#123;                self.handlerBlock(); // 外部在 block 内部 dump 堆栈（下面会讲），数据上报            &#125;        &#125;        dispatch\_semaphore\_wait(semaphore, DISPATCH\_TIME\_FOREVER);    &#125;&#125;</code></pre><h3 id="4-堆栈-dump"><a href="#4-堆栈-dump" class="headerlink" title="4. 堆栈 dump"></a>4. 堆栈 dump</h3><p>方法堆栈的获取是一个麻烦事。理一下思路。<code>[NSThread callStackSymbols]</code> 可以获取当前线程的调用栈。但是当监控到卡顿发生，需要拿到主线程的堆栈信息就无能为力了。从任何线程回到主线程这条路走不通。先做个知识回顾。</p><p>在计算机科学中，调用堆栈是一种栈类型的数据结构，用于存储有关计算机程序的线程信息。这种栈也叫做执行堆栈、程序堆栈、控制堆栈、运行时堆栈、机器堆栈等。调用堆栈用于跟踪每个活动的子例程在完成执行后应该返回控制的点。</p><p>维基百科搜索到 “Call Stack” 的一张图和例子，如下<br><img src="https://segmentfault.com/img/bVbIOfu"><br>上图表示为一个栈。分为若干个栈帧（Frame），每个栈帧对应一个函数调用。下面蓝色部分表示 <code>DrawSquare</code> 函数，它在执行的过程中调用了 <code>DrawLine</code> 函数，用绿色部分表示。</p><p>可以看到栈帧由三部分组成：函数参数、返回地址、局部变量。比如在 DrawSquare 内部调用了 DrawLine 函数：第一先把 DrawLine 函数需要的参数入栈；第二把返回地址(控制信息。举例：函数 A 内调用函数 B，调用函数B 的下一行代码的地址就是返回地址)入栈；第三函数内部的局部变量也在该栈中存储。</p><p>栈指针 Stack Pointer 表示当前栈的顶部，大多部分操作系统都是栈向下生长，所以栈指针是最小值。帧指针 Frame Pointer 指向的地址中，存储了上一次 Stack Pointer 的值，也就是返回地址。</p><p>大多数操作系统中，每个栈帧还保存了上一个栈帧的帧指针。因此知道当前栈帧的 Stack Pointer 和 Frame Pointer 就可以不断回溯，递归获取栈底的帧。</p><p>接下来的步骤就是拿到所有线程的 Stack Pointer 和 Frame Pointer。然后不断回溯，还原案发现场。</p><h3 id="5-Mach-Task-知识"><a href="#5-Mach-Task-知识" class="headerlink" title="5. Mach Task 知识"></a>5. Mach Task 知识</h3><p><strong>Mach task:</strong></p><p>App 在运行的时候，会对应一个 Mach Task，而 Task 下可能有多条线程同时执行任务。《OS X and iOS Kernel Programming》 中描述 Mach Task 为：任务（Task）是一种容器对象，虚拟内存空间和其他资源都是通过这个容器对象管理的，这些资源包括设备和其他句柄。简单概括为：Mack task 是一个机器无关的 thread 的执行环境抽象。</p><p>作用： task 可以理解为一个进程，包含它的线程列表。</p><p>结构体：task_threads，将 target_task 任务下的所有线程保存在 act_list 数组中，数组个数为 act_listCnt</p><p>kern_return_t task_threads<br>(<br>  task_t traget_task,<br>  thread_act_array_t *act_list,                     //线程指针列表<br>  mach_msg_type_number_t *act_listCnt  //线程个数<br>)</p><p>thread_info:</p><p>kern_return_t thread_info<br>(<br>  thread_act_t target_act,<br>  thread_flavor_t flavor,<br>  thread_info_t thread_info_out,<br>  mach_msg_type_number_t *thread_info_outCnt<br>);</p><p>如何获取线程的堆栈数据：</p><p>系统方法 <code>kern_return_t task_threads(task_inspect_t target_task, thread_act_array_t *act_list, mach_msg_type_number_t *act_listCnt);</code> 可以获取到所有的线程，不过这种方法获取到的线程信息是最底层的 <strong>mach 线程</strong>。</p><p>对于每个线程，可以用 <code>kern_return_t thread_get_state(thread_act_t target_act, thread_state_flavor_t flavor, thread_state_t old_state, mach_msg_type_number_t *old_stateCnt);</code> 方法获取它的所有信息，信息填充在 <code>_STRUCT_MCONTEXT</code> 类型的参数中，这个方法中有2个参数随着 CPU 架构不同而不同。所以需要定义宏屏蔽不同 CPU 之间的区别。</p><p><code>_STRUCT_MCONTEXT</code> 结构体中，存储了当前线程的 Stack Pointer 和最顶部栈帧的 Frame pointer，进而回溯整个线程调用堆栈。</p><p>但是上述方法拿到的是内核线程，我们需要的信息是 NSThread，所以需要将内核线程转换为 NSThread。</p><p>pthread 的 p 是 <strong>POSIX</strong> 的缩写，表示「可移植操作系统接口」（Portable Operating System Interface）。设计初衷是每个系统都有自己独特的线程模型，且不同系统对于线程操作的 API 都不一样。所以 POSIX 的目的就是提供抽象的 pthread 以及相关 API。这些 API 在不同的操作系统中有不同的实现，但是完成的功能一致。</p><p>Unix 系统提供的 <code>task_threads</code> 和 <code>thread_get_state</code> 操作的都是内核系统，每个内核线程由 thread_t 类型的 id 唯一标识。pthread 的唯一标识是 pthread_t 类型。其中内核线程和 pthread 的转换（即 thread_t 和 pthread_t）很容易，因为 pthread 设计初衷就是「抽象内核线程」。</p><p><code>memorystatus_action_neededpthread_create</code> 方法创建线程的回调函数为 <strong>nsthreadLauncher</strong>。</p><p>static void *nsthreadLauncher(void* thread)<br>{<br>    NSThread *t = (NSThread*)thread;<br>    [nc postNotificationName: NSThreadDidStartNotification object:t userInfo: nil];<br>    [t _setName: [t name]];<br>    [t main];<br>    [NSThread exit];<br>    return NULL;<br>}</p><p>NSThreadDidStartNotification 其实就是字符串 @”_NSThreadDidStartNotification”。</p><p>&lt;NSThread: 0x…&gt;{number = 1, name = main}  </p><p>为了 NSThread 和内核线程对应起来，只能通过 name 一一对应。 pthread 的 API <code>pthread_getname_np</code> 也可获取内核线程名字。np 代表 not POSIX，所以不能跨平台使用。</p><p>思路概括为：将 NSThread 的原始名字存储起来，再将名字改为某个随机数（时间戳），然后遍历内核线程 pthread 的名字，名字匹配则 NSThread 和内核线程对应了起来。找到后将线程的名字还原成原本的名字。对于主线程，由于不能使用 <code>pthread_getname_np</code>，所以在当前代码的 load 方法中获取到 thread_t，然后匹配名字。</p><p>static mach_port_t main_thread_id;  </p><ul><li>(void)load {<br>  main_thread_id = mach_thread_self();<br>}</li></ul><h2 id="二、-App-启动时间监控"><a href="#二、-App-启动时间监控" class="headerlink" title="二、 App 启动时间监控"></a>二、 App 启动时间监控</h2><h3 id="1-App-启动时间的监控"><a href="#1-App-启动时间的监控" class="headerlink" title="1. App 启动时间的监控"></a>1. App 启动时间的监控</h3><p>应用启动时间是影响用户体验的重要因素之一，所以我们需要量化去衡量一个 App 的启动速度到底有多快。启动分为冷启动和热启动。<br><img src="https://segmentfault.com/img/bVbIOfD"></p><p>冷启动：App 尚未运行，必须加载并构建整个应用。完成应用的初始化。冷启动存在较大优化空间。冷启动时间从 <code>application: didFinishLaunchingWithOptions:</code> 方法开始计算，App 一般在这里进行各种 SDK 和 App 的基础初始化工作。</p><p>热启动：应用已经在后台运行（常见场景：比如用户使用 App 过程中点击 Home 键，再打开 App），由于某些事件将应用唤醒到前台，App 会在 <code>applicationWillEnterForeground:</code> 方法接受应用进入前台的事件</p><p>思路比较简单。如下</p><ul><li>  在监控类的 <code>load</code> 方法中先拿到当前的时间值</li><li>  监听 App 启动完成后的通知 <code>UIApplicationDidFinishLaunchingNotification</code></li><li>  收到通知后拿到当前的时间</li><li>  步骤1和3的时间差就是 App 启动时间。</li></ul><p><code>mach_absolute_time</code> 是一个 CPU/总线依赖函数，返回一个 CPU 时钟周期数。系统休眠时不会增加。是一个纳秒级别的数字。获取前后2个纳秒后需要转换到秒。需要基于系统时间的基准，通过 <code>mach_timebase_info</code> 获得。</p><p>mach_timebase_info_data_t g_apmmStartupMonitorTimebaseInfoData = 0;<br>mach_timebase_info(&amp;g_apmmStartupMonitorTimebaseInfoData);<br>uint64_t timelapse = mach_absolute_time() - g_apmmLoadTime;<br>double timeSpan = (timelapse * g_apmmStartupMonitorTimebaseInfoData.numer) / (g_apmmStartupMonitorTimebaseInfoData.denom * 1e9);</p><h3 id="2-线上监控启动时间就好，但是在开发阶段需要对启动时间做优化。"><a href="#2-线上监控启动时间就好，但是在开发阶段需要对启动时间做优化。" class="headerlink" title="2. 线上监控启动时间就好，但是在开发阶段需要对启动时间做优化。"></a>2. 线上监控启动时间就好，但是在开发阶段需要对启动时间做优化。</h3><p>要优化启动时间，就先得知道在启动阶段到底做了什么事情，针对现状作出方案。</p><p>pre-main 阶段定义为 App 开始启动到系统调用 main 函数这个阶段；main 阶段定义为 main 函数入口到主 UI 框架的 viewDidAppear。</p><p>App 启动过程：</p><ul><li>  解析 Info.plist：加载相关信息例如闪屏；沙盒建立、权限检查；</li><li>  Mach-O 加载：如果是胖二进制文件，寻找合适当前 CPU 架构的部分；加载所有依赖的 Mach-O 文件（递归调用 Mach-O 加载的方法）；定义内部、外部指针引用，例如字符串、函数等；加载分类中的方法；c++ 静态对象加载、调用 Objc 的 <code>+load()</code> 函数；执行声明为 __attribute_((constructor)) 的 c 函数；</li><li>  程序执行：调用 main()；调用 UIApplicationMain()；调用 applicationWillFinishLaunching()；</li></ul><p>Pre-Main 阶段<br><img src="https://segmentfault.com/img/bVbIOfI"></p><p>Main 阶段<br><img src="https://segmentfault.com/img/bVbIOfP"></p><h4 id="2-1-加载-Dylib"><a href="#2-1-加载-Dylib" class="headerlink" title="2.1 加载 Dylib"></a>2.1 加载 Dylib</h4><p>每个动态库的加载，dyld 需要</p><ul><li>  分析所依赖的动态库</li><li>  找到动态库的 Mach-O 文件</li><li>  打开文件</li><li>  验证文件</li><li>  在系统核心注册文件签名</li><li>  对动态库的每一个 segment 调用 mmap（）</li></ul><p>优化：</p><ul><li>  减少非系统库的依赖</li><li>  使用静态库而不是动态库</li><li>  合并非系统动态库为一个动态库</li></ul><h4 id="2-2-Rebase-amp-amp-Binding"><a href="#2-2-Rebase-amp-amp-Binding" class="headerlink" title="2.2 Rebase &amp;&amp; Binding"></a>2.2 Rebase &amp;&amp; Binding</h4><p>优化：</p><ul><li>  减少 Objc 类数量，减少 selector 数量，把未使用的类和函数都可以删掉</li><li>  减少 c++ 虚函数数量</li><li>  转而使用 Swift struct（本质就是减少符号的数量）</li></ul><h4 id="2-3-Initializers"><a href="#2-3-Initializers" class="headerlink" title="2.3 Initializers"></a>2.3 Initializers</h4><p>优化：</p><ul><li>  使用 <code>+initialize</code> 代替 <code>+load</code></li><li>  不要使用过 attribute*((constructor)) 将方法显示标记为初始化器，而是让初始化方法调用时才执行。比如使用 dispatch_one、pthread_once() 或 std::once()。也就是第一次使用时才初始化，推迟了一部分工作耗时也尽量不要使用 c++ 的静态对象</li></ul><h4 id="2-4-pre-main-阶段影响因素"><a href="#2-4-pre-main-阶段影响因素" class="headerlink" title="2.4 pre-main 阶段影响因素"></a>2.4 pre-main 阶段影响因素</h4><ul><li>  动态库加载越多，启动越慢。</li><li>  ObjC 类越多，函数越多，启动越慢。</li><li>  可执行文件越大启动越慢。</li><li>  C 的 constructor 函数越多，启动越慢。</li><li>  C++ 静态对象越多，启动越慢。</li><li>  ObjC 的 +load 越多，启动越慢。</li></ul><p>优化手段：</p><ul><li>  减少依赖不必要的库，不管是动态库还是静态库；如果可以的话，把动态库改造成静态库；如果必须依赖动态库，则把多个非系统的动态库合并成一个动态库</li><li>  检查下 framework应当设为optional和required，如果该framework在当前App支持的所有iOS系统版本都存在，那么就设为required，否则就设为optional，因为optional会有些额外的检查</li><li>合并或者删减一些OC类和函数。关于清理项目中没用到的类，使用工具AppCode代码检查功能，查到当前项目中没有用到的类（也可以用根据linkmap文件来分析，但是准确度不算很高）<br>  有一个叫做<a href="https://link.segmentfault.com/?enc=+M8NWNM6ZOB/M1EERBDGkA==.4WCLtil1YWB+tkjAZgL3jaHwEVhfygyzT0Rq6xbaGoM=">FUI</a>的开源项目能很好的分析出不再使用的类，准确率非常高，唯一的问题是它处理不了动态库和静态库里提供的类，也处理不了C++的类模板</li><li>  删减一些无用的静态变量</li><li>  删减没有被调用到或者已经废弃的方法</li><li>  将不必须在 +load 方法中做的事情延迟到 +initialize中，尽量不要用 C++ 虚函数(创建虚函数表有开销)</li><li>类和方法名不要太长：iOS每个类和方法名都在 __cstring 段里都存了相应的字符串值，所以类和方法名的长短也是对可执行文件大小是有影响的<br>  因还是 Object-c 的动态特性，因为需要通过类/方法名反射找到这个类/方法进行调用，Object-c 对象模型会把类/方法名字符串都保存下来；</li><li>  用 dispatch_once() 代替所有的 attribute((constructor)) 函数、C++ 静态对象初始化、ObjC 的 +load 函数；</li><li>在设计师可接受的范围内压缩图片的大小，会有意外收获。<br>  压缩图片为什么能加快启动速度呢？因为启动的时候大大小小的图片加载个十来二十个是很正常的，<br>  图片小了，IO操作量就小了，启动当然就会快了，比较靠谱的压缩算法是 TinyPNG。</li></ul><h4 id="2-5-main-阶段优化"><a href="#2-5-main-阶段优化" class="headerlink" title="2.5 main 阶段优化"></a>2.5 main 阶段优化</h4><ul><li>  减少启动初始化的流程。能懒加载就懒加载，能放后台初始化就放后台初始化，能延迟初始化的就延迟初始化，不要卡主线程的启动时间，已经下线的业务代码直接删除</li><li>  优化代码逻辑。去除一些非必要的逻辑和代码，减小每个流程所消耗的时间</li><li>  启动阶段使用多线程来进行初始化，把 CPU 性能发挥最大</li><li>  使用纯代码而不是 xib 或者 storyboard 来描述 UI，尤其是主 UI 框架，比如 TabBarController。因为 xib 和 storyboard 还是需要解析成代码来渲染页面，多了一步。</li></ul><h3 id="3-启动时间加速"><a href="#3-启动时间加速" class="headerlink" title="3. 启动时间加速"></a>3. 启动时间加速</h3><p>内存缺页异常？在使用中，访问虚拟内存的一个 page 而对应的物理内存缺不存在（没有被加载到物理内存中），则发生缺页异常。影响耗时，在几毫秒之内。</p><p>什么时候发生大量的缺页异常？一个应用程序刚启动的时候。</p><p>启动时所需要的代码分布在 VM 的第一页、第二页、第三页…，这样的情况下启动时间会影响较大，所以解决思路就是将应用程序启动刻所需要的代码（二进制优化一下），统一放到某几页，这样就可以避免内存缺页异常，则优化了 App 启动时间。</p><p>二进制重排提升 App 启动速度是通过「解决内存缺页异常」（内存缺页会有几毫秒的耗时）来提速的。</p><p>一个 App 发生大量「内存缺页」的时机就是 App 刚启动的时候。所以优化手段就是「将影响 App 启动的方法集中处理，放到某一页或者某几页」（虚拟内存中的页）。Xcode 工程允许开发者指定 「Order File」，可以「按照文件中的方法顺序去加载」，可以查看 linkMap 文件（需要在 Xcode 中的 「Buiild Settings」中设置 Order File、Write Link Map Files 参数）。</p><p>其实难点是如何拿到启动时刻所调用的所用方法？代码可能是 Swift、block、c、OC，所以hook 肯定不行、fishhook 也不行，用 clang 插桩可以满足需求。</p><h2 id="三、-CPU-使用率监控"><a href="#三、-CPU-使用率监控" class="headerlink" title="三、 CPU 使用率监控"></a>三、 CPU 使用率监控</h2><h3 id="1-CPU-架构"><a href="#1-CPU-架构" class="headerlink" title="1. CPU 架构"></a>1. CPU 架构</h3><p>CPU（Central Processing Unit）中央处理器，市场上主流的架构有 ARM（arm64）、Intel（x86）、AMD 等。其中 Intel 使用 CISC（Complex Instruction Set Computer），ARM 使用 RISC（Reduced Instruction Set Computer）。区别在于<strong>不同的 CPU 设计理念和方法</strong>。</p><p>早期 CPU 全部是 CISC 架构，设计目的是<strong>用最少的机器语言指令来完成所需的计算任务</strong>。比如对于乘法运算，在 CISC 架构的 CPU 上。一条指令 <code>MUL ADDRA, ADDRB</code> 就可以将内存 ADDRA 和内存 ADDRB 中的数香乘，并将结果存储在 ADDRA 中。做的事情就是：将 ADDRA、ADDRB 中的数据读入到寄存器，相乘的结果写入到内存的操作依赖于 CPU 设计，所以 <strong>CISC 架构会增加 CPU 的复杂性和对 CPU 工艺的要求。</strong></p><p>RISC 架构要求软件来指定各个操作步骤。比如上面的乘法，指令实现为 <code>MOVE A, ADDRA; MOVE B, ADDRB; MUL A, B; STR ADDRA, A;</code>。这种架构可以降低 CPU 的复杂性以及允许在同样的工艺水平下生产出功能更加强大的 CPU，但是对于编译器的设计要求更高。</p><p>目前市场是大部分的 iPhone 都是基于 arm64 架构的。且 arm 架构能耗低。</p><h3 id="2-获取线程信息"><a href="#2-获取线程信息" class="headerlink" title="2. 获取线程信息"></a>2. 获取线程信息</h3><p>讲完了区别来讲下如何做 CPU 使用率的监控</p><ul><li>  开启定时器，按照设定的周期不断执行下面的逻辑</li><li>  获取当前任务 task。从当前 task 中获取所有的线程信息（线程个数、线程数组）</li><li>  遍历所有的线程信息，判断是否有线程的 CPU 使用率超过设置的阈值</li><li>  假如有线程使用率超过阈值，则 dump 堆栈</li><li>  组装数据，上报数据</li></ul><p>线程信息结构体</p><p>struct thread_basic_info {<br>    time_value_t    user_time;      /* user run time（用户运行时长） */<br>    time_value_t    system_time;    /* system run time（系统运行时长） */<br>    integer_t       cpu_usage;      /* scaled cpu usage percentage（CPU使用率，上限1000） */<br>    policy_t        policy;         /* scheduling policy in effect（有效调度策略） */<br>    integer_t       run_state;      /* run state (运行状态，见下) */<br>    integer_t       flags;          /* various flags (各种各样的标记) */<br>    integer_t       suspend_count;  /* suspend count for thread（线程挂起次数） */<br>    integer_t       sleep_time;     /* number of seconds that thread<br>                                     *  has been sleeping（休眠时间） */<br>};</p><p>代码在讲堆栈还原的时候讲过，忘记的看一下上面的分析</p><p>thread_act_array_t threads;<br>mach_msg_type_number_t threadCount = 0;<br>const task_t thisTask = mach_task_self();<br>kern_return_t kr = task_threads(thisTask, &amp;threads, &amp;threadCount);<br>if (kr != KERN_SUCCESS) {<br>    return ;<br>}<br>for (int i = 0; i &lt; threadCount; i++) {<br>    thread_info_data_t threadInfo;<br>    thread_basic_info_t threadBaseInfo;<br>    mach_msg_type_number_t threadInfoCount;</p><pre><code>kern\_return\_t kr = thread\_info((thread\_inspect\_t)threads\[i\], THREAD\_BASIC\_INFO, (thread\_info\_t)threadInfo, &amp;threadInfoCount);if (kr == KERN\_SUCCESS) &#123;    threadBaseInfo = (thread\_basic\_info\_t)threadInfo;    // todo：条件判断，看不明白    if (!(threadBaseInfo-&gt;flags &amp; TH\_FLAGS\_IDLE)) &#123;        integer\_t cpuUsage = threadBaseInfo-&gt;cpu\_usage / 10;        if (cpuUsage &gt; CPUMONITORRATE) &#123;            NSMutableDictionary \*CPUMetaDictionary = \[NSMutableDictionary dictionary\];            NSData \*CPUPayloadData = \[NSData data\];            NSString \*backtraceOfAllThread = \[BacktraceLogger backtraceOfAllThread\];            // 1. 组装卡顿的 Meta 信息            CPUMetaDictionary\[@&quot;MONITOR\_TYPE&quot;\] = APMMonitorCPUType;            // 2. 组装卡顿的 Payload 信息（一个JSON对象，对象的 Key 为约定好的 STACK\_TRACE， value 为 base64 后的堆栈信息）            NSData \*CPUData = \[SAFE\_STRING(backtraceOfAllThread) dataUsingEncoding:NSUTF8StringEncoding\];            NSString \*CPUDataBase64String = \[CPUData base64EncodedStringWithOptions:0\];            NSDictionary \*CPUPayloadDictionary = @&#123;@&quot;STACK\_TRACE&quot;: SAFE\_STRING(CPUDataBase64String)&#125;;            NSError \*error;            // NSJSONWritingOptions 参数一定要传0，因为服务端需要根据 \\n 处理逻辑，传递 0 则生成的 json 串不带 \\n            NSData \*parsedData = \[NSJSONSerialization dataWithJSONObject:CPUPayloadDictionary options:0 error:&amp;error\];            if (error) &#123;                APMMLog(@&quot;%@&quot;, error);                return;            &#125;            CPUPayloadData = \[parsedData copy\];            // 3. 数据上报会在 \[打造功能强大、灵活可配置的数据上报组件\](https://github.com/FantasticLBP/knowledge-kit/blob/master/Chapter1%20-%20iOS/1.80.md) 讲            \[\[HermesClient sharedInstance\] sendWithType:APMMonitorCPUType meta:CPUMetaDictionary payload:CPUPayloadData\];         &#125;    &#125;&#125;</code></pre><p>}</p><h2 id="四、-OOM-问题"><a href="#四、-OOM-问题" class="headerlink" title="四、 OOM 问题"></a>四、 OOM 问题</h2><h3 id="1-基础知识准备"><a href="#1-基础知识准备" class="headerlink" title="1. 基础知识准备"></a>1. 基础知识准备</h3><p>硬盘：也叫做磁盘，用于存储数据。你存储的歌曲、图片、视频都是在硬盘里。</p><p>内存：由于硬盘读取速度较慢，如果 CPU 运行程序期间，所有的数据都直接从硬盘中读取，则非常影响效率。所以 CPU 会将程序运行所需要的数据从硬盘中读取到内存中。然后 CPU 与内存中的数据进行计算、交换。内存是易失性存储器（断电后，数据消失）。内存条区是计算机内部（在主板上）的一些存储器，用来保存 CPU 运算的中间数据和结果。内存是程序与 CPU 之间的桥梁。从硬盘读取出数据或者运行程序提供给 CPU。</p><p><strong>虚拟内存</strong> 是计算机系统内存管理的一种技术。它使得程序认为它拥有连续的可用内存，而实际上，它通常被分割成多个物理内存碎片，可能部分暂时存储在外部磁盘（硬盘）存储器上（当需要使用时则用硬盘中数据交换到内存中）。Windows 系统中称为 “虚拟内存”，Linux/Unix 系统中称为 ”交换空间“。</p><p>iOS 不支持交换空间？不只是 iOS 不支持交换空间，大多数手机系统都不支持。因为移动设备的大量存储器是<strong>闪存</strong>，它的读写速度远远小电脑所使用的硬盘，也就是说手机即使使用了<strong>交换空间</strong>技术，也因为闪存慢的问题，不能提升性能，所以索性就没有交换空间技术。</p><h3 id="2-iOS-内存知识"><a href="#2-iOS-内存知识" class="headerlink" title="2. iOS 内存知识"></a>2. iOS 内存知识</h3><p>内存（RAM）与 CPU 一样都是系统中最稀少的资源，也很容易发生竞争，应用内存与性能直接相关。iOS 没有交换空间作为备选资源，所以内存资源尤为重要。</p><p>什么是 OOM？是 out-of-memory 的缩写，字面意思是超过了内存限制。分为 FOOM（Foreground Out Of Memory，应用在前台运行的过程中崩溃。用户在使用的过程中产生的，这样的崩溃会使得活跃用户流失，业务上是非常不愿意看到的）和 BOOM（Background Out Of Memory，应用在后台运行的过程崩溃）。它是由 iOS 的 <code>Jetsam</code> 机制造成的一种非主流 Crash，它不能通过 Signal 这种监控方案所捕获。</p><p>什么是 Jetsam 机制？Jetsam 机制可以理解为系统为了控制内存资源过度使用而采用的一种管理机制。Jetsam 机制是运行在一个独立的进程中，每个进程都有一个内存阈值，一旦超过这个内存阈值，Jetsam 会立即杀掉这个进程。</p><p>为什么设计 Jetsam 机制？因为设备的内存是有限的，所以内存资源非常重要。系统进程以及其他使用的 App 都会抢占这个资源。由于 iOS 不支持交换空间，一旦触发低内存事件，Jetsam 就会尽可能多的释放 App 所在内存，这样 iOS 系统上出现内存不足时，App 就会被系统杀掉，变现为 crash。</p><p>2种情况触发 OOM：系统由于整体内存使用过高，会基于优先级策略杀死优先级较低的 App；当前 App 达到了 “<strong>highg water mark</strong>“ ，系统也会强杀当前 App（超过系统对当前单个 App 的内存限制值）。</p><p>读了源码（xnu/bsd/kern/kern_memorystatus.c）会发现内存被杀也有2种机制，如下</p><p>highwater 处理 -&gt; 我们的 App 占用内存不能超过单个限制</p><ol><li> 从优先级列表里循环寻找线程</li><li> 判断是否满足 p_memstat_memlimit 的限制条件</li><li> DiagonoseActive、FREEZE 过滤</li><li> 杀进程，成功则 exit，否则循环</li></ol><p>memorystatus_act_aggressive 处理 -&gt; 内存占用高，按照优先级杀死</p><ol><li> 根据 policy 家在 jld_bucket_count，用来判断是否被杀</li><li> 从 JETSAM_PRIORITY_ELEVATED_INACTIVE 开始杀</li><li> Old_bucket_count 和 memorystatus_jld_eval_period_msecs 判断是否开杀</li><li> 根据优先级从低到高开始杀，直到 memorystatus_avail_pages_below_pressure</li></ol><p>内存过大的几种情况</p><ul><li>  App 内存消耗较低，同时其他 App 内存管理也很棒，那么即使切换到其他 App，我们自己的 App 依旧是“活着”的，保留了用户状态。体验好</li><li>  App 内存消耗较低，但其他 App 内存消耗太大（可能是内存管理糟糕，也可能是本身就耗费资源，比如游戏），那么除了在前台的线程，其他 App 都会被系统杀死，回收内存资源，用来给活跃的进程提供内存。</li><li>  App 内存消耗较大，切换到其他 App 后，即使其他 App 向系统申请的内存不大，系统也会因为内存资源紧张，优先把内存消耗大的 App 杀死。表现为用户将 App 退出到后台，过会儿再次打开会发现 App 重新加载启动。</li><li>  App 内存消耗非常大，在前台运行时就被系统杀死，造成闪退。</li></ul><p>App 内存不足时，系统会按照一定策略来腾出更多的空间供使用。比较常见的做法是将一部分优先级低的数据挪到磁盘上，该操作为称为 <strong>page out</strong>。之后再次访问这块数据的时候，系统会负责将它重新搬回到内存中，该操作被称为 <strong>page in</strong>。</p><p>Memory page** 是内存管理中的最小单位，是系统分配的，可能一个 page 持有多个对象，也可能一个大的对象跨越多个 page。通常它是 16KB 大小，且有3种类型的 page。</p><p><img src="https://segmentfault.com/img/bVbIOf9"></p><ul><li><p>Clean Memory<br>  Clean memory 包括3类：可以 <code>page out</code> 的内存、内存映射文件、App 使用到的 framework（每个 framework 都有 _DATA_CONST 段，通常都是 clean 状态，但使用 runtime swizling，那么变为 dirty）。</p><p>  一开始分配的 page 都是干净的（堆里面的对象分配除外），我们 App 数据写入时候变为 dirty。从硬盘读进内存的文件，也是只读的、clean page。<br>  <img src="https://segmentfault.com/img/bVbIOn9"></p></li><li><p>Dirty Memory</p><p>  Dirty memory 包括4类：被 App 写入过数据的内存、所有堆区分配的对象、图像解码缓冲区、framework（framework 都有 _DATA 段和 _DATA_DIRTY 段，它们的内存都是 dirty）。</p><p>  在使用 framework 的过程中会产生 Dirty memory，使用单例或者全局初始化方法有助于帮助减少 Dirty memory（因为单例一旦创建就不销毁，一直在内存中，系统不认为是 Dirty memory）。</p><p>  <img src="https://segmentfault.com/img/bVbIOoc"></p></li><li><p>Compressed Memory</p><p>  由于闪存容量和读写限制，iOS 没有交换空间机制，而是在 iOS7 引入了 <strong>memory compressor</strong>。它是在内存紧张时候能够将最近一段时间未使用过的内存对象，内存压缩器会把对象压缩，释放出更多的 page。在需要时内存压缩器对其解压复用。在节省内存的同时提高了响应速度。</p><p>  比如 App 使用某 Framework，内部有个 NSDictionary 属性存储数据，使用了 3 pages 内存，在近期未被访问的时候 memory compressor 将其压缩为 1 page，再次使用的时候还原为 3 pages。</p></li></ul><p>App 运行内存 = pageNumbers * pageSize。因为 Compressed Memory 属于 Dirty memory。所以 Memory footprint = dirtySize + CompressedSize</p><p>设备不同，内存占用上限不同，App 上限较高，extension 上限较低，超过上限 crash 到 <code>EXC_RESOURCE_EXCEPTION</code>。<br><img src="https://segmentfault.com/img/bVbIOgi"></p><p>接下来谈一下如何获取内存上限，以及如何监控 App 因为占用内存过大而被强杀。</p><h3 id="3-获取内存信息"><a href="#3-获取内存信息" class="headerlink" title="3. 获取内存信息"></a>3. 获取内存信息</h3><h4 id="3-1-通过-JetsamEvent-日志计算内存限制值"><a href="#3-1-通过-JetsamEvent-日志计算内存限制值" class="headerlink" title="3.1 通过 JetsamEvent 日志计算内存限制值"></a>3.1 通过 JetsamEvent 日志计算内存限制值</h4><p>当 App 被 Jetsam 机制杀死时，手机会生成系统日志。查看路径：Settings-Privacy-Analytics &amp; Improvements- Analytics Data（设置-隐私- 分析与改进-分析数据），可以看到 <code>JetsamEvent-2020-03-14-161828.ips</code> 形式的日志，以 JetsamEvent 开头。这些 JetsamEvent 日志都是 iOS 系统内核强杀掉那些优先级不高（idle、frontmost、suspended）且占用内存超过系统内存限制的 App 留下的。</p><p>日志包含了 App 的内存信息。可以查看到 日志最顶部有 <code>pageSize</code> 字段，查找到 per-process-limit，该节点所在结构里的 <code>rpages</code> ，将 rpages * pageSize 即可得到 OOM 的阈值。</p><p>日志中 largestProcess 字段代表 App 名称；reason 字段代表内存原因；states 字段代表奔溃时 App 的状态（ idle、suspended、frontmost…）。</p><p>为了测试数据的准确性，我将测试2台设备（iPhone 6s plus/13.3.1，iPhone 11 Pro/13.3.1）的所有 App 彻底退出，只跑了一个为了测试内存临界值的 Demo App。 循环申请内存，ViewController 代码如下</p><p>- (void)viewDidLoad {<br>    [super viewDidLoad];<br>    NSMutableArray *array = [NSMutableArray array];<br>    for (NSInteger index = 0; index &lt; 10000000; index++) {<br>        UIImageView *imageView = [[UIImageView alloc] initWithFrame:CGRectMake(0, 0, 100, 100)];<br>        UIImage *image = [UIImage imageNamed:@”AppIcon”];<br>        imageView.image = image;<br>        [array addObject:imageView];<br>    }<br>}</p><p>iPhone 6s plus/13.3.1 数据如下：</p><p>{“bug_type”:”298”,”timestamp”:”2020-03-19 17:23:45.94 +0800”,”os_version”:”iPhone OS 13.3.1 (17D50)”,”incident_id”:”DA8AF66D-24E8-458C-8734-981866942168”}<br>{<br>  “crashReporterKey” : “fc9b659ce486df1ed1b8062d5c7c977a7eb8c851”,<br>  “kernel” : “Darwin Kernel Version 19.3.0: Thu Jan  9 21:10:44 PST 2020; root:xnu-6153.82.3~1\/RELEASE_ARM64_S8000”,<br>  “product” : “iPhone8,2”,<br>  “incident” : “DA8AF66D-24E8-458C-8734-981866942168”,<br>  “date” : “2020-03-19 17:23:45.93 +0800”,<br>  “build” : “iPhone OS 13.3.1 (17D50)”,<br>  “timeDelta” : 332,<br>  “memoryStatus” : {<br>  “compressorSize” : 48499,<br>  “compressions” : 7458651,<br>  “decompressions” : 5190200,<br>  “zoneMapCap” : 744407040,<br>  “largestZone” : “APFS_4K_OBJS”,<br>  “largestZoneSize” : 41402368,<br>  “pageSize” : 16384,<br>  “uncompressed” : 104065,<br>  “zoneMapSize” : 141606912,<br>  “memoryPages” : {<br>    “active” : 26214,<br>    “throttled” : 0,<br>    “fileBacked” : 14903,<br>    “wired” : 20019,<br>    “anonymous” : 37140,<br>    “purgeable” : 142,<br>    “inactive” : 23669,<br>    “free” : 2967,<br>    “speculative” : 2160<br>  }<br>},<br>  “largestProcess” : “Test”,<br>  “genCounter” : 0,<br>  “processes” : [<br>  {<br>    “uuid” : “39c5738b-b321-3865-a731-68064c4f7a6f”,<br>    “states” : [<br>      “daemon”,<br>      “idle”<br>    ],<br>    “lifetimeMax” : 188,<br>    “age” : 948223699030,<br>    “purgeable” : 0,<br>    “fds” : 25,<br>    “coalition” : 422,<br>    “rpages” : 177,<br>    “pid” : 282,<br>    “idleDelta” : 824711280,<br>    “name” : “com.apple.Safari.SafeBrowsing.Se”,<br>    “cpuTime” : 10.275422000000001<br>  },<br>  // …<br>  {<br>    “uuid” : “83dbf121-7c0c-3ab5-9b66-77ee926e1561”,<br>    “states” : [<br>      “frontmost”<br>    ],<br>    “killDelta” : 2592,<br>    “genCount” : 0,<br>    “age” : 1531004794,<br>    “purgeable” : 0,<br>    “fds” : 50,<br>    “coalition” : 1047,<br>    “rpages” : 92806,<br>    “reason” : “per-process-limit”,<br>    “pid” : 2384,<br>    “cpuTime” : 59.464373999999999,<br>    “name” : “Test”,<br>    “lifetimeMax” : 92806<br>  },<br>  // …<br> ]<br>}</p><p>iPhone 6s plus/13.3.1 手机 OOM 临界值为：(16384*92806)/(1024*1024)=1450.09375M</p><p>iPhone 11 Pro/13.3.1 数据如下：</p><p>{“bug_type”:”298”,”timestamp”:”2020-03-19 17:30:28.39 +0800”,”os_version”:”iPhone OS 13.3.1 (17D50)”,”incident_id”:”7F111601-BC7A-4BD7-A468-CE3370053057”}<br>{<br>  “crashReporterKey” : “bc2445adc164c399b330f812a48248e029e26276”,<br>  “kernel” : “Darwin Kernel Version 19.3.0: Thu Jan  9 21:11:10 PST 2020; root:xnu-6153.82.3~1\/RELEASE_ARM64_T8030”,<br>  “product” : “iPhone12,3”,<br>  “incident” : “7F111601-BC7A-4BD7-A468-CE3370053057”,<br>  “date” : “2020-03-19 17:30:28.39 +0800”,<br>  “build” : “iPhone OS 13.3.1 (17D50)”,<br>  “timeDelta” : 189,<br>  “memoryStatus” : {<br>  “compressorSize” : 66443,<br>  “compressions” : 25498129,<br>  “decompressions” : 15532621,<br>  “zoneMapCap” : 1395015680,<br>  “largestZone” : “APFS_4K_OBJS”,<br>  “largestZoneSize” : 41222144,<br>  “pageSize” : 16384,<br>  “uncompressed” : 127027,<br>  “zoneMapSize” : 169639936,<br>  “memoryPages” : {<br>    “active” : 58652,<br>    “throttled” : 0,<br>    “fileBacked” : 20291,<br>    “wired” : 45838,<br>    “anonymous” : 96445,<br>    “purgeable” : 4,<br>    “inactive” : 54368,<br>    “free” : 5461,<br>    “speculative” : 3716<br>  }<br>},<br>  “largestProcess” : “杭城小刘”,<br>  “genCounter” : 0,<br>  “processes” : [<br>  {<br>    “uuid” : “2dd5eb1e-fd31-36c2-99d9-bcbff44efbb7”,<br>    “states” : [<br>      “daemon”,<br>      “idle”<br>    ],<br>    “lifetimeMax” : 171,<br>    “age” : 5151034269954,<br>    “purgeable” : 0,<br>    “fds” : 50,<br>    “coalition” : 66,<br>    “rpages” : 164,<br>    “pid” : 11276,<br>    “idleDelta” : 3801132318,<br>    “name” : “wcd”,<br>    “cpuTime” : 3.430787<br>  },<br>  // …<br>  {<br>    “uuid” : “63158edc-915f-3a2b-975c-0e0ac4ed44c0”,<br>    “states” : [<br>      “frontmost”<br>    ],<br>    “killDelta” : 4345,<br>    “genCount” : 0,<br>    “age” : 654480778,<br>    “purgeable” : 0,<br>    “fds” : 50,<br>    “coalition” : 1718,<br>    “rpages” : 134278,<br>    “reason” : “per-process-limit”,<br>    “pid” : 14206,<br>    “cpuTime” : 23.955463999999999,<br>    “name” : “杭城小刘”,<br>    “lifetimeMax” : 134278<br>  },<br>  // …<br> ]<br>}</p><p>iPhone 11 Pro/13.3.1 手机 OOM 临界值为：(16384*134278)/(1024*1024)=2098.09375M</p><p><strong>iOS 系统如何发现 Jetsam ？</strong></p><p>MacOS/iOS 是一个 BSD 衍生而来的系统，其内核是 Mach，但是对于上层暴露的接口一般是基于 BSD 层对 Mach 的包装后的。Mach 是一个微内核的架构，真正的虚拟内存管理也是在其中进行的，BSD 对内存管理提供了上层接口。Jetsam 事件也是由 BSD 产生的。<code>bsd_init</code> 函数是入口，其中基本都是在初始化各个子系统，比如虚拟内存管理等。</p><p>// 1. Initialize the kernel memory allocator, 初始化 BSD 内存 Zone，这个 Zone 是基于 Mach 内核的zone 构建<br>kmeminit();</p><p>// 2. Initialise background freezing, iOS 上独有的特性，内存和进程的休眠的常驻监控线程<br>#if CONFIG_FREEZE<br>#ifndef CONFIG_MEMORYSTATUS<br>    #error “CONFIG_FREEZE defined without matching CONFIG_MEMORYSTATUS”<br>#endif<br>    /* Initialise background freezing */<br>    bsd_init_kprintf(“calling memorystatus_freeze_init\n”);<br>    memorystatus_freeze_init();<br>#endif&gt;</p><p>// 3. iOS 独有，JetSAM（即低内存事件的常驻监控线程）<br>#if CONFIG_MEMORYSTATUS<br>    /* Initialize kernel memory status notifications */<br>    bsd_init_kprintf(“calling memorystatus_init\n”);<br>    memorystatus_init();<br>#endif /* CONFIG_MEMORYSTATUS */</p><p><strong>主要作用就是开启了2个优先级最高的线程，来监控整个系统的内存情况。</strong></p><p>CONFIG_FREEZE 开启时，内核对进程进行冷冻而不是杀死。冷冻功能是由内核中启动一个 <code>memorystatus_freeze_thread</code> 进行，这个进程在收到信号后调用 <code>memorystatus_freeze_top_process</code> 进行冷冻。</p><p>iOS 系统会开启优先级最高的线程 <code>vm_pressure_monitor</code> 来监控系统的内存压力情况，并通过一个堆栈来维护所有 App 进程。iOS 系统还会维护一个内存快照表，用于保存每个进程内存页的消耗情况。有关 Jetsam 也就是 memorystatus 相关的逻辑，可以在 XNU 项目中的 <strong>kern_memorystatus.h</strong> 和 <strong>kern_memorystatus.c</strong> 源码中查看。</p><p>iOS 系统因内存占用过高会强杀 App 前，至少有 6秒钟可以用来做优先级判断，JetsamEvent 日志也是在这6秒内生成的。</p><p>上文提到了 iOS 系统没有交换空间，于是引入了 <strong>MemoryStatus 机制（也称为 Jetsam）</strong>。也就是说在 iOS 系统上释放尽可能多的内存供当前 App 使用。这个机制表现在优先级上，就是先强杀后台应用；如果内存还是不够多，就强杀掉当前应用。在 MacOS 中，MemoryStatus 只会强杀掉标记为空闲退出的进程。</p><p>MemoryStatus 机制会开启一个 memorystatus_jetsam_thread 的线程，它负责强杀 App 和记录日志，不会发送消息，所以内存压力检测线程无法获取到强杀 App 的消息。</p><p>当监控线程发现某 App 有内存压力时，就发出通知，此时有内存的 App 就去执行 <code>didReceiveMemoryWarning</code> 代理方法。在这个时机，我们还有机会做一些内存资源释放的逻辑，也许会避免 App 被系统杀死。</p><p><strong>源码角度查看问题</strong></p><p>iOS 系统内核有一个数组，专门维护线程的优先级。数组的每一项是一个包含进程链表的结构体。结构体如下：</p><p>#define MEMSTAT_BUCKET_COUNT (JETSAM_PRIORITY_MAX + 1)</p><p>typedef struct memstat_bucket {<br>    TAILQ_HEAD(, proc) list;<br>    int count;<br>} memstat_bucket_t;</p><p>memstat_bucket_t memstat_bucket[MEMSTAT_BUCKET_COUNT];</p><p>在 kern_memorystatus.h 中可以看到进行优先级信息</p><p>#define JETSAM_PRIORITY_IDLE_HEAD                -2<br>/* The value -1 is an alias to JETSAM_PRIORITY_DEFAULT */<br>#define JETSAM_PRIORITY_IDLE                      0<br>#define JETSAM_PRIORITY_IDLE_DEFERRED          1 /* Keeping this around till all xnu_quick_tests can be moved away from it.*/<br>#define JETSAM_PRIORITY_AGING_BAND1          JETSAM_PRIORITY_IDLE_DEFERRED<br>#define JETSAM_PRIORITY_BACKGROUND_OPPORTUNISTIC  2<br>#define JETSAM_PRIORITY_AGING_BAND2          JETSAM_PRIORITY_BACKGROUND_OPPORTUNISTIC<br>#define JETSAM_PRIORITY_BACKGROUND                3<br>#define JETSAM_PRIORITY_ELEVATED_INACTIVE      JETSAM_PRIORITY_BACKGROUND<br>#define JETSAM_PRIORITY_MAIL                      4<br>#define JETSAM_PRIORITY_PHONE                     5<br>#define JETSAM_PRIORITY_UI_SUPPORT                8<br>#define JETSAM_PRIORITY_FOREGROUND_SUPPORT        9<br>#define JETSAM_PRIORITY_FOREGROUND               10<br>#define JETSAM_PRIORITY_AUDIO_AND_ACCESSORY      12<br>#define JETSAM_PRIORITY_CONDUCTOR                13<br>#define JETSAM_PRIORITY_HOME                     16<br>#define JETSAM_PRIORITY_EXECUTIVE                17<br>#define JETSAM_PRIORITY_IMPORTANT                18<br>#define JETSAM_PRIORITY_CRITICAL                 19</p><p>#define JETSAM_PRIORITY_MAX                      21</p><p>可以明显的看到，后台 App 优先级 JETSAM_PRIORITY_BACKGROUND 为3，前台 App 优先级 JETSAM_PRIORITY_FOREGROUND 为10。</p><p>优先级规则是：内核线程优先级 &gt; 操作系统优先级 &gt; App 优先级。且前台 App 优先级高于后台运行的 App；当线程的优先级相同时， CPU 占用多的线程的优先级会被降低。</p><p>在 kern_memorystatus.c 中可以看到 OOM 可能的原因：</p><p>/* For logging clarity */<br>static const char *memorystatus_kill_cause_name[] = {<br>    “”                                ,        /* kMemorystatusInvalid                            */<br>    “jettisoned”                    ,        /* kMemorystatusKilled                            */<br>    “highwater”                        ,        /* kMemorystatusKilledHiwat                        */<br>    “vnode-limit”                    ,        /* kMemorystatusKilledVnodes                    */<br>    “vm-pageshortage”                ,        /* kMemorystatusKilledVMPageShortage            */<br>    “proc-thrashing”                ,        /* kMemorystatusKilledProcThrashing                */<br>    “fc-thrashing”                    ,        /* kMemorystatusKilledFCThrashing                */<br>    “per-process-limit”                ,        /* kMemorystatusKilledPerProcessLimit            */<br>    “disk-space-shortage”            ,        /* kMemorystatusKilledDiskSpaceShortage            */<br>    “idle-exit”                        ,        /* kMemorystatusKilledIdleExit                    */<br>    “zone-map-exhaustion”            ,        /* kMemorystatusKilledZoneMapExhaustion            */<br>    “vm-compressor-thrashing”        ,        /* kMemorystatusKilledVMCompressorThrashing        */<br>    “vm-compressor-space-shortage”    ,        /* kMemorystatusKilledVMCompressorSpaceShortage    */<br>};</p><p>查看 memorystatus_init 这个函数中初始化 Jetsam 线程的关键代码</p><p>__private_extern__ void<br>memorystatus_init(void) {<br>    // …<br>  /* Initialize the jetsam_threads state array */<br>    jetsam_threads = kalloc(sizeof(struct jetsam_thread_state) * max_jetsam_threads);</p><pre><code>/\* Initialize all the jetsam threads \*/for (i = 0; i &lt; max\_jetsam\_threads; i++) &#123;    result = kernel\_thread\_start\_priority(memorystatus\_thread, NULL, 95 /\* MAXPRI\_KERNEL \*/, &amp;jetsam\_threads\[i\].thread);    if (result == KERN\_SUCCESS) &#123;        jetsam\_threads\[i\].inited = FALSE;        jetsam\_threads\[i\].index = i;        thread\_deallocate(jetsam\_threads\[i\].thread);    &#125; else &#123;        panic(&quot;Could not create memorystatus\_thread %d&quot;, i);    &#125;&#125;</code></pre><p>}</p><p>/*<br> *    High-level priority assignments<br> *<br> *************************************************************************<br> * 127        Reserved (real-time)<br> *                A<br> *                +<br> *            (32 levels)<br> *                +<br> *                V<br> * 96        Reserved (real-time)<br> * 95        Kernel mode only<br> *                A<br> *                +<br> *            (16 levels)<br> *                +<br> *                V<br> * 80        Kernel mode only<br> * 79        System high priority<br> *                A<br> *                +<br> *            (16 levels)<br> *                +<br> *                V<br> * 64        System high priority<br> * 63        Elevated priorities<br> *                A<br> *                +<br> *            (12 levels)<br> *                +<br> *                V<br> * 52        Elevated priorities<br> * 51        Elevated priorities (incl. BSD +nice)<br> *                A<br> *                +<br> *            (20 levels)<br> *                +<br> *                V<br> * 32        Elevated priorities (incl. BSD +nice)<br> * 31        Default (default base for threads)<br> * 30        Lowered priorities (incl. BSD -nice)<br> *                A<br> *                +<br> *            (20 levels)<br> *                +<br> *                V<br> * 11        Lowered priorities (incl. BSD -nice)<br> * 10        Lowered priorities (aged pri’s)<br> *                A<br> *                +<br> *            (11 levels)<br> *                +<br> *                V<br> * 0        Lowered priorities (aged pri’s / idle)<br> *************************************************************************<br> */</p><p>可以看出：用户态的应用程序的线程不可能高于操作系统和内核。而且，用户态的应用程序间的线程优先级分配也有区别，比如处于前台的应用程序优先级高于处于后台的应用程序优先级。iOS 上应用程序优先级最高的是 SpringBoard；此外线程的优先级不是一成不变的。Mach 会根据线程的利用率和系统整体负载动态调整线程优先级。如果耗费 CPU 太多就降低线程优先级，如果线程过度挨饿，则会提升线程优先级。但是无论怎么变，程序都不能超过其所在线程的优先级区间范围。</p><p>可以看出，系统会根据内核启动参数和设备性能，开启 max_jetsam_threads 个（一般情况为1，特殊情况下可能为3）jetsam 线程，且这些线程的优先级为 95，也就是 MAXPRI_KERNEL（注意这里的 95 是线程的优先级，XNU 的线程优先级区间为：0～127。上文的宏定义是进程优先级，区间为：-2~19）。</p><p>紧接着，分析下 memorystatus_thread 函数，主要负责线程启动的初始化</p><p>static void<br>memorystatus_thread(void *param __unused, wait_result_t wr __unused) {<br>  //…<br>  while (memorystatus_action_needed()) {<br>        boolean_t killed;<br>        int32_t priority;<br>        uint32_t cause;<br>        uint64_t jetsam_reason_code = JETSAM_REASON_INVALID;<br>        os_reason_t jetsam_reason = OS_REASON_NULL;</p><pre><code>    cause = kill\_under\_pressure\_cause;    switch (cause) &#123;        case kMemorystatusKilledFCThrashing:            jetsam\_reason\_code = JETSAM\_REASON\_MEMORY\_FCTHRASHING;            break;        case kMemorystatusKilledVMCompressorThrashing:            jetsam\_reason\_code = JETSAM\_REASON\_MEMORY\_VMCOMPRESSOR\_THRASHING;            break;        case kMemorystatusKilledVMCompressorSpaceShortage:            jetsam\_reason\_code = JETSAM\_REASON\_MEMORY\_VMCOMPRESSOR\_SPACE\_SHORTAGE;            break;        case kMemorystatusKilledZoneMapExhaustion:            jetsam\_reason\_code = JETSAM\_REASON\_ZONE\_MAP\_EXHAUSTION;            break;        case kMemorystatusKilledVMPageShortage:            /\* falls through \*/        default:            jetsam\_reason\_code = JETSAM\_REASON\_MEMORY\_VMPAGESHORTAGE;            cause = kMemorystatusKilledVMPageShortage;            break;    &#125;    /\* Highwater \*/    boolean\_t is\_critical = TRUE;    if (memorystatus\_act\_on\_hiwat\_processes(&amp;errors, &amp;hwm\_kill, &amp;post\_snapshot, &amp;is\_critical)) &#123;        if (is\_critical == FALSE) &#123;            /\*             \* For now, don&#39;t kill any other processes.             \*/            break;        &#125; else &#123;            goto done;        &#125;    &#125;    jetsam\_reason = os\_reason\_create(OS\_REASON\_JETSAM, jetsam\_reason\_code);    if (jetsam\_reason == OS\_REASON\_NULL) &#123;        printf(&quot;memorystatus\_thread: failed to allocate jetsam reason\\n&quot;);    &#125;    if (memorystatus\_act\_aggressive(cause, jetsam\_reason, &amp;jld\_idle\_kills, &amp;corpse\_list\_purged, &amp;post\_snapshot)) &#123;        goto done;    &#125;    /\*     \* memorystatus\_kill\_top\_process() drops a reference,     \* so take another one so we can continue to use this exit reason     \* even after it returns     \*/    os\_reason\_ref(jetsam\_reason);    /\* LRU \*/    killed = memorystatus\_kill\_top\_process(TRUE, sort\_flag, cause, jetsam\_reason, &amp;priority, &amp;errors);    sort\_flag = FALSE;    if (killed) &#123;        if (memorystatus\_post\_snapshot(priority, cause) == TRUE) &#123;                post\_snapshot = TRUE;        &#125;        /\* Jetsam Loop Detection \*/        if (memorystatus\_jld\_enabled == TRUE) &#123;            if ((priority == JETSAM\_PRIORITY\_IDLE) || (priority == system\_procs\_aging\_band) || (priority == applications\_aging\_band)) &#123;                jld\_idle\_kills++;            &#125; else &#123;                /\*                 \* We&#39;ve reached into bands beyond idle deferred.                 \* We make no attempt to monitor them                 \*/            &#125;        &#125;        if ((priority &gt;= JETSAM\_PRIORITY\_UI\_SUPPORT) &amp;&amp; (total\_corpses\_count() &gt; 0) &amp;&amp; (corpse\_list\_purged == FALSE)) &#123;            /\*             \* If we have jetsammed a process in or above JETSAM\_PRIORITY\_UI\_SUPPORT             \* then we attempt to relieve pressure by purging corpse memory.             \*/            task\_purge\_all\_corpses();            corpse\_list\_purged = TRUE;        &#125;        goto done;    &#125;    if (memorystatus\_avail\_pages\_below\_critical()) &#123;        /\*         \* Still under pressure and unable to kill a process - purge corpse memory         \*/        if (total\_corpses\_count() &gt; 0) &#123;            task\_purge\_all\_corpses();            corpse\_list\_purged = TRUE;        &#125;        if (memorystatus\_avail\_pages\_below\_critical()) &#123;            /\*             \* Still under pressure and unable to kill a process - panic             \*/            panic(&quot;memorystatus\_jetsam\_thread: no victim! available pages:%llu\\n&quot;, (uint64\_t)memorystatus\_available\_pages);        &#125;    &#125;</code></pre><p>done:    </p><p>}</p><p>可以看到它开启了一个 循环，memorystatus_action_needed() 来作为循环条件，持续释放内存。</p><p>static boolean_t<br>memorystatus_action_needed(void) {<br>#if CONFIG_EMBEDDED<br>    return (is_reason_thrashing(kill_under_pressure_cause) ||<br>            is_reason_zone_map_exhaustion(kill_under_pressure_cause) ||<br>           memorystatus_available_pages &lt;= memorystatus_available_pages_pressure);<br>#else /* CONFIG_EMBEDDED */<br>    return (is_reason_thrashing(kill_under_pressure_cause) ||<br>            is_reason_zone_map_exhaustion(kill_under_pressure_cause));<br>#endif /* CONFIG_EMBEDDED */<br>}</p><p>它通过 vm_pagepout 发送的内存压力来判断当前内存资源是否紧张。几种情况：频繁的页面换出换进 is_reason_thrashing, Mach Zone 耗尽了 is_reason_zone_map_exhaustion、以及可用的页低于了 memory status_available_pages 这个门槛。</p><p>继续看 memorystatus_thread，会发现内存紧张时，将先触发 High-water 类型的 OOM，也就是说假如某个进程使用过程中超过了其使用内存的最高限制 hight water mark 时会发生 OOM。在 memorystatus_act_on_hiwat_processes() 中，通过 memorystatus_kill_hiwat_proc() 在优先级数组 memstat_bucket 中查找优先级最低的进程，如果进程的内存小于阈值（footprint_in_bytes &lt;= memlimit_in_bytes）则继续寻找次优先级较低的进程，直到找到占用内存超过阈值的进程并杀死。</p><p>通常来说单个 App 很难触碰到 high water mark，如果不能结束任何进程，最终走到 memorystatus_act_aggressive，也就是大多数 OOM 发生的地方。</p><p>static boolean_t<br>memorystatus_act_aggressive(uint32_t cause, os_reason_t jetsam_reason, int *jld_idle_kills, boolean_t *corpse_list_purged, boolean_t *post_snapshot) {<br>    // …<br>  if ( (jld_bucket_count == 0) ||<br>             (jld_now_msecs &gt; (jld_timestamp_msecs + memorystatus_jld_eval_period_msecs))) {</p><pre><code>        /\*          \* Refresh evaluation parameters          \*/        jld\_timestamp\_msecs     = jld\_now\_msecs;        jld\_idle\_kill\_candidates = jld\_bucket\_count;        \*jld\_idle\_kills         = 0;        jld\_eval\_aggressive\_count = 0;        jld\_priority\_band\_max    = JETSAM\_PRIORITY\_UI\_SUPPORT;    &#125;</code></pre><p>  //…<br>}</p><p>上述代码看到，判断要不要真正执行 kill 是根据一定的时间间判断的，条件是 <code>jld_now_msecs &gt; (jld_timestamp_msecs + memorystatus_jld_eval_period_msecs</code>。 也就是在 memorystatus_jld_eval_period_msecs 后才发生条件里面的 kill。</p><p>/* Jetsam Loop Detection */<br>if (max_mem &lt;= (512 * 1024 * 1024)) {<br>    /* 512 MB devices */<br>memorystatus_jld_eval_period_msecs = 8000;    /* 8000 msecs == 8 second window */<br>} else {<br>    /* 1GB and larger devices */<br>memorystatus_jld_eval_period_msecs = 6000;    /* 6000 msecs == 6 second window */<br>}</p><p>其中 memorystatus_jld_eval_period_msecs 取值最小6秒。所以我们可以在6秒内做些处理。</p><h4 id="3-2-开发者们整理所得"><a href="#3-2-开发者们整理所得" class="headerlink" title="3.2 开发者们整理所得"></a>3.2 开发者们整理所得</h4><p><a href="https://link.segmentfault.com/?enc=jXqAlw4S4FOsD7u5160uFA==.Ap2qdKjaM0Mrxz+exry6MgJXIb+6daIX0Uf70MPabekPiXVP9YTyapT4vtBNYne6LbUktczVdsrs9D8E/M5QzaYa1fLm/DrkWOTFgNx1OySq+DkvKpj6QxzOJBIyhLmx">stackoverflow</a> 上有一份数据，整理了各种设备的 OOM 临界值</p><p>device</p><p>crash amount:MB</p><p>total amount:MB</p><p>percentage of total</p><p>iPad1</p><p>127</p><p>256</p><p>49%</p><p>iPad2</p><p>275</p><p>512</p><p>53%</p><p>iPad3</p><p>645</p><p>1024</p><p>62%</p><p>iPad4(iOS 8.1)</p><p>585</p><p>1024</p><p>57%</p><p>Pad Mini 1st Generation</p><p>297</p><p>512</p><p>58%</p><p>iPad Mini retina(iOS 7.1)</p><p>696</p><p>1024</p><p>68%</p><p>iPad Air</p><p>697</p><p>1024</p><p>68%</p><p>iPad Air 2(iOS 10.2.1)</p><p>1383</p><p>2048</p><p>68%</p><p>iPad Pro 9.7”(iOS 10.0.2 (14A456))</p><p>1395</p><p>1971</p><p>71%</p><p>iPad Pro 10.5”(iOS 11 beta4)</p><p>3057</p><p>4000</p><p>76%</p><p>iPad Pro 12.9” (2015)(iOS 11.2.1)</p><p>3058</p><p>3999</p><p>76%</p><p>iPad 10.2(iOS 13.2.3)</p><p>1844</p><p>2998</p><p>62%</p><p>iPod touch 4th gen(iOS 6.1.1)</p><p>130</p><p>256</p><p>51%</p><p>iPod touch 5th gen</p><p>286</p><p>512</p><p>56%</p><p>iPhone4</p><p>325</p><p>512</p><p>63%</p><p>iPhone4s</p><p>286</p><p>512</p><p>56%</p><p>iPhone5</p><p>645</p><p>1024</p><p>62%</p><p>iPhone5s</p><p>646</p><p>1024</p><p>63%</p><p>iPhone6(iOS 8.x)</p><p>645</p><p>1024</p><p>62%</p><p>iPhone6 Plus(iOS 8.x)</p><p>645</p><p>1024</p><p>62%</p><p>iPhone6s(iOS 9.2)</p><p>1396</p><p>2048</p><p>68%</p><p>iPhone6s Plus(iOS 10.2.1)</p><p>1396</p><p>2048</p><p>68%</p><p>iPhoneSE(iOS 9.3)</p><p>1395</p><p>2048</p><p>68%</p><p>iPhone7(iOS 10.2)</p><p>1395</p><p>2048</p><p>68%</p><p>iPhone7 Plus(iOS 10.2.1)</p><p>2040</p><p>3072</p><p>66%</p><p>iPhone8(iOS 12.1)</p><p>1364</p><p>1990</p><p>70%</p><p>iPhoneX(iOS 11.2.1)</p><p>1392</p><p>2785</p><p>50%</p><p>iPhoneXS(iOS 12.1)</p><p>2040</p><p>3754</p><p>54%</p><p>iPhoneXS Max(iOS 12.1)</p><p>2039</p><p>3735</p><p>55%</p><p>iPhoneXR(iOS 12.1)</p><p>1792</p><p>2813</p><p>63%</p><p>iPhone11(iOS 13.1.3)</p><p>2068</p><p>3844</p><p>54%</p><p>iPhone11 Pro Max(iOS 13.2.3)</p><p>2067</p><p>3740</p><p>55%</p><h4 id="3-3-触发当前-App-的-high-water-mark"><a href="#3-3-触发当前-App-的-high-water-mark" class="headerlink" title="3.3 触发当前 App 的 high water mark"></a>3.3 触发当前 App 的 high water mark</h4><p>我们可以写定时器，不断的申请内存，之后再通过 <code>phys_footprint</code> 打印当前占用内存，按道理来说不断申请内存即可触发 Jetsam 机制，强杀 App，那么<strong>最后一次打印的内存占用也就是当前设备的内存上限值</strong>。</p><p>timer = [NSTimer scheduledTimerWithTimeInterval:0.01 target:self selector:@selector(allocateMemory) userInfo:nil repeats:YES];</p><ul><li><p>(void)allocateMemory {<br>  UIImageView *imageView = [[UIImageView alloc] initWithFrame:CGRectMake(0, 0, 100, 100)];<br>  UIImage *image = [UIImage imageNamed:@”AppIcon”];<br>  imageView.image = image;<br>  [array addObject:imageView];</p><p>  memoryLimitSizeMB = [self usedSizeOfMemory];<br>  if (memoryWarningSizeMB &amp;&amp; memoryLimitSizeMB) {</p><pre><code>  NSLog(@&quot;----- memory warnning:%dMB, memory limit:%dMB&quot;, memoryWarningSizeMB, memoryLimitSizeMB);</code></pre><p>  }<br>}</p></li><li><p>(int)usedSizeOfMemory {<br>  task_vm_info_data_t taskInfo;<br>  mach_msg_type_number_t infoCount = TASK_VM_INFO_COUNT;<br>  kern_return_t kernReturn = task_info(mach_task_self(), TASK_VM_INFO, (task_info_t)&amp;taskInfo, &amp;infoCount);</p><p>  if (kernReturn != KERN_SUCCESS) {</p><pre><code>  return 0;</code></pre><p>  }<br>  return (int)(taskInfo.phys_footprint/1024.0/1024.0);<br>}</p></li></ul><h4 id="3-4-适用于-iOS13-系统的获取方式"><a href="#3-4-适用于-iOS13-系统的获取方式" class="headerlink" title="3.4 适用于 iOS13 系统的获取方式"></a>3.4 适用于 iOS13 系统的获取方式</h4><p>iOS13 开始 &lt;os/proc.h&gt; 中 <code>size_t os_proc_available_memory(void);</code> 可以查看当前可用内存。</p><blockquote><p>Return Value</p><p>The number of bytes that the app may allocate before it hits its memory limit. If the calling process isn’t an app, or if the process has already exceeded its memory limit, this function returns <code>0</code>.</p><p>Discussion</p><p>Call this function to determine the amount of memory available to your app. The returned value corresponds to the current memory limit minus the memory footprint of your app at the time of the function call. Your app’s memory footprint consists of the data that you allocated in RAM, and that must stay in RAM (or the equivalent) at all times. Memory limits can change during the app life cycle and don’t necessarily correspond to the amount of physical memory available on the device.</p><p>Use the returned value as advisory information only and don’t cache it. The precise value changes when your app does any work that affects memory, which can happen frequently.</p><p>Although this function lets you determine the amount of memory your app may safely consume, don’t use it to maximize your app’s memory usage. Significant memory use, even when under the current memory limit, affects system performance. For example, when your app consumes all of its available memory, the system may need to terminate other apps and system processes to accommodate your app’s requests. Instead, always consume the smallest amount of memory you need to be responsive to the user’s needs.</p><p>If you need more detailed information about the available memory resources, you can call <code>task_info</code>. However, be aware that <code>task_info</code> is an expensive call, whereas this function is much more efficient.</p></blockquote><p>if (@available(iOS 13.0, *)) {<br>    return os_proc_available_memory() / 1024.0 / 1024.0;<br>}</p><p>App 内存信息的 API 可以在 Mach 层找到，<code>mach_task_basic_info</code> 结构体存储了 Mach task 的内存使用信息，其中 phys_footprint 就是应用使用的物理内存大小，virtual_size 是虚拟内存大小。</p><p>#define MACH_TASK_BASIC_INFO     20         /* always 64-bit basic info */<br>struct mach_task_basic_info {<br>    mach_vm_size_t  virtual_size;       /* virtual memory size (bytes) */<br>    mach_vm_size_t  resident_size;      /* resident memory size (bytes) */<br>    mach_vm_size_t  resident_size_max;  /* maximum resident memory size (bytes) */<br>    time_value_t    user_time;          /* total user run time for<br>                                            terminated threads */<br>    time_value_t    system_time;        /* total system run time for<br>                                            terminated threads */<br>    policy_t        policy;             /* default policy for new threads */<br>    integer_t       suspend_count;      /* suspend count for task */<br>};</p><p>所以获取代码为</p><p>task_vm_info_data_t vmInfo;<br>mach_msg_type_number_t count = TASK_VM_INFO_COUNT;<br>kern_return_t kr = task_info(mach_task_self(), TASK_VM_INFO, (task_info_t)&amp;vmInfo, &amp;count);</p><p>if (kr != KERN_SUCCESS) {<br>    return ;<br>}<br>CGFloat memoryUsed = (CGFloat)(vmInfo.phys_footprint/1024.0/1024.0);</p><p>可能有人好奇不应该是 <code>resident_size</code> 这个字段获取内存的使用情况吗？一开始测试后发现 resident_size 和 Xcode 测量结果差距较大。而使用 phys_footprint 则接近于 Xcode 给出的结果。且可以从 <a href="https://link.segmentfault.com/?enc=JnwZOCCjfSuM+5Ot/DLidg==.cYB5AHuFJs5/6Be4sEnT/CDIRxgf1D0geQbZ5W2vvtXQxvYEPRKMVYgeJt8rGaYhaU+rrfaezYhQI3h+pGMETDhUijv+K1JrciXQb9ArAJQfyT545MlJlPC6OLcyu6GtxVj+tlQVIxC1wNk9sbg6C5Dynbwf7TCURqKmnF39nIk=">WebKit 源码</a>中得到印证。</p><p>所以在 iOS13 上，我们可以通过 <code>os_proc_available_memory</code> 获取到当前可以用内存，通过 <code>phys_footprint</code> 获取到当前 App 占用内存，2者的和也就是当前设备的内存上限，超过即触发 Jetsam 机制。</p><p>- (CGFloat)limitSizeOfMemory {<br>    if (@available(iOS 13.0, *)) {<br>        task_vm_info_data_t taskInfo;<br>        mach_msg_type_number_t infoCount = TASK_VM_INFO_COUNT;<br>        kern_return_t kernReturn = task_info(mach_task_self(), TASK_VM_INFO, (task_info_t)&amp;taskInfo, &amp;infoCount);</p><pre><code>    if (kernReturn != KERN\_SUCCESS) &#123;        return 0;    &#125;    return (CGFloat)((taskInfo.phys\_footprint + os\_proc\_available\_memory()) / (1024.0 \* 1024.0);&#125;return 0;</code></pre><p>}</p><p>当前可以使用内存：1435.936752MB；当前 App 已占用内存：14.5MB，临界值：1435.936752MB + 14.5MB= 1450.436MB， 和 3.1 方法中获取到的内存临界值一样「iPhone 6s plus/13.3.1 手机 OOM 临界值为：(16384*92806)/(1024*1024)=1450.09375M」。</p><h4 id="3-5-通过-XNU-获取内存限制值"><a href="#3-5-通过-XNU-获取内存限制值" class="headerlink" title="3.5 通过 XNU 获取内存限制值"></a>3.5 通过 XNU 获取内存限制值</h4><p>在 XNU 中，有专门用于获取内存上限值的函数和宏，可以通过 <code>memorystatus_priority_entry</code> 这个结构体得到所有进程的优先级和内存限制值。</p><p>typedef struct memorystatus_priority_entry {<br>  pid_t pid;<br>  int32_t priority;<br>  uint64_t user_data;<br>  int32_t limit;<br>  uint32_t state;<br>} memorystatus_priority_entry_t;</p><p>其中，priority 代表进程优先级，limit 代表进程的内存限制值。但是这种方式需要 root 权限，由于没有越狱设备，我没有尝试过。</p><p>相关代码可查阅 <code>kern_memorystatus.h</code> 文件。需要用到函数 <code>int memorystatus_control(uint32_t command, int32_t pid, uint32_t flags, void *buffer, size_t buffersize);</code></p><p>/* Commands */<br>#define MEMORYSTATUS_CMD_GET_PRIORITY_LIST            1<br>#define MEMORYSTATUS_CMD_SET_PRIORITY_PROPERTIES      2<br>#define MEMORYSTATUS_CMD_GET_JETSAM_SNAPSHOT          3<br>#define MEMORYSTATUS_CMD_GET_PRESSURE_STATUS          4<br>#define MEMORYSTATUS_CMD_SET_JETSAM_HIGH_WATER_MARK   5    /* Set active memory limit = inactive memory limit, both non-fatal    */<br>#define MEMORYSTATUS_CMD_SET_JETSAM_TASK_LIMIT          6    /* Set active memory limit = inactive memory limit, both fatal    */<br>#define MEMORYSTATUS_CMD_SET_MEMLIMIT_PROPERTIES      7    /* Set memory limits plus attributes independently            */<br>#define MEMORYSTATUS_CMD_GET_MEMLIMIT_PROPERTIES      8    /* Get memory limits plus attributes                    */<br>#define MEMORYSTATUS_CMD_PRIVILEGED_LISTENER_ENABLE   9    /* Set the task’s status as a privileged listener w.r.t memory notifications  */<br>#define MEMORYSTATUS_CMD_PRIVILEGED_LISTENER_DISABLE  10   /* Reset the task’s status as a privileged listener w.r.t memory notifications  */<br>#define MEMORYSTATUS_CMD_AGGRESSIVE_JETSAM_LENIENT_MODE_ENABLE  11   /* Enable the ‘lenient’ mode for aggressive jetsam. See comments in kern_memorystatus.c near the top. */<br>#define MEMORYSTATUS_CMD_AGGRESSIVE_JETSAM_LENIENT_MODE_DISABLE 12   /* Disable the ‘lenient’ mode for aggressive jetsam. */<br>#define MEMORYSTATUS_CMD_GET_MEMLIMIT_EXCESS          13   /* Compute how much a process’s phys_footprint exceeds inactive memory limit */<br>#define MEMORYSTATUS_CMD_ELEVATED_INACTIVEJETSAMPRIORITY_ENABLE     14 /* Set the inactive jetsam band for a process to JETSAM_PRIORITY_ELEVATED_INACTIVE */<br>#define MEMORYSTATUS_CMD_ELEVATED_INACTIVEJETSAMPRIORITY_DISABLE     15 /* Reset the inactive jetsam band for a process to the default band (0)*/<br>#define MEMORYSTATUS_CMD_SET_PROCESS_IS_MANAGED       16   /* (Re-)Set state on a process that marks it as (un-)managed by a system entity e.g. assertiond */<br>#define MEMORYSTATUS_CMD_GET_PROCESS_IS_MANAGED       17   /* Return the ‘managed’ status of a process */<br>#define MEMORYSTATUS_CMD_SET_PROCESS_IS_FREEZABLE     18   /* Is the process eligible for freezing? Apps and extensions can pass in FALSE to opt out of freezing, i.e.,</p><p>伪代码</p><p>struct memorystatus_priority_entry memStatus[NUM_ENTRIES];<br>size_t count = sizeof(struct memorystatus_priority_entry) * NUM_ENTRIES;<br>int kernResult = memorystatus_control(MEMORYSTATUS_CMD_GET_PRIORITY_LIST, 0, 0, memStatus, count);<br>if (rc &lt; 0) {<br>  NSLog(@”memorystatus_control”);<br>    return ;<br>}</p><p>int entry = 0;<br>for (; rc &gt; 0; rc -= sizeof(struct memorystatus_priority_entry)){<br>  printf (“PID: %5d\tPriority:%2d\tUser Data: %llx\tLimit:%2d\tState:%s\n”,<br>          memstatus[entry].pid,<br>          memstatus[entry].priority,<br>          memstatus[entry].user_data,<br>          memstatus[entry].limit,<br>          state_to_text(memstatus[entry].state));<br>  entry++;<br>}</p><p>for 循环打印出每个进程（也就是 App）的 pid、Priority、User Data、Limit、State 信息。从 log 中找出优先级为10的进程，即我们前台运行的 App。为什么是10？ 因为 <code>#define JETSAM_PRIORITY_FOREGROUND 10</code> 我们的目的就是获取前台 App 的内存上限值。</p><h3 id="4-如何判定发生了-OOM"><a href="#4-如何判定发生了-OOM" class="headerlink" title="4. 如何判定发生了 OOM"></a>4. 如何判定发生了 OOM</h3><p>OOM 导致 crash 前，app 一定会收到低内存警告吗？</p><p>做2组对比实验：</p><p>// 实验1<br>NSMutableArray *array = [NSMutableArray array];<br>for (NSInteger index = 0; index &lt; 10000000; index++) {<br>  NSString *filePath = [[NSBundle mainBundle] pathForResource:@”Info” ofType:@”plist”];<br>  NSData *data = [NSData dataWithContentsOfFile:filePath];<br>  [array addObject:data];<br>}</p><p>// 实验2<br>// ViewController.m</p><ul><li>(void)viewDidLoad {<br>  [super viewDidLoad];<br>  dispatch_async(dispatch_get_global_queue(0, 0), ^{<pre><code>  NSMutableArray \*array = \[NSMutableArray array\];  for (NSInteger index = 0; index &lt; 10000000; index++) &#123;      NSString \*filePath = \[\[NSBundle mainBundle\] pathForResource:@&quot;Info&quot; ofType:@&quot;plist&quot;\];      NSData \*data = \[NSData dataWithContentsOfFile:filePath\];      \[array addObject:data\];  &#125;</code></pre>  });<br>}</li><li>(void)didReceiveMemoryWarning<br>{<br>  NSLog(@”2”);<br>}</li></ul><p>// AppDelegate.m</p><ul><li>(void)applicationDidReceiveMemoryWarning:(UIApplication *)application<br>{<br>  NSLog(@”1”);<br>}</li></ul><p>现象：</p><ol><li> 在 viewDidLoad 也就是主线程中内存消耗过大，系统并不会发出低内存警告，直接 Crash。因为内存增长过快，主线程很忙。</li><li> 多线程的情况下，App 因内存增长过快，会收到低内存警告，AppDelegate 中的<code>applicationDidReceiveMemoryWarning</code> 先执行，随后是当前 VC 的 <code>didReceiveMemoryWarning</code>。</li></ol><p>结论：</p><p><strong>收到低内存警告不一定会 Crash，因为有6秒钟的系统判断时间，6秒内内存下降了则不会 crash。发生 OOM 也不一定会收到低内存警告。</strong></p><h3 id="5-内存信息收集"><a href="#5-内存信息收集" class="headerlink" title="5. 内存信息收集"></a>5. 内存信息收集</h3><p>要想精确的定位问题，就需要 dump 所有对象及其内存信息。当内存接近系统内存上限的时候，收集并记录所需信息，结合一定的数据上报机制，上传到服务器，分析并修复。</p><p>还需要知道每个对象具体是在哪个函数里创建出来的，以便还原“案发现场”。</p><p>源代码（libmalloc/malloc），内存分配函数 malloc 和 calloc 等默认使用 nano_zone，nano_zone 是小于 256B 以下的内存分配，大于 256B 则使用 scalable_zone 来分配。</p><p>主要针对大内存的分配监控。malloc 函数用的是 malloc_zone_malloc, calloc 用的是 malloc_zone_calloc。</p><p>使用 scalable_zone 分配内存的函数都会调用 malloc_logger 函数，因为系统为了有个地方专门统计并管理内存分配情况。这样的设计也满足「收口原则」。</p><p>void *<br>malloc(size_t size) {<br>    void *retval;<br>    retval = malloc_zone_malloc(default_zone, size);<br>    if (retval == NULL) {<br>        errno = ENOMEM;<br>    }<br>    return retval;<br>}</p><p>void *<br>calloc(size_t num_items, size_t size) {<br>    void *retval;<br>    retval = malloc_zone_calloc(default_zone, num_items, size);<br>    if (retval == NULL) {<br>        errno = ENOMEM;<br>    }<br>    return retval;<br>}</p><p>首先来看看这个 <code>default_zone</code> 是什么东西, 代码如下</p><p>typedef struct {<br>    malloc_zone_t malloc_zone;<br>    uint8_t pad[PAGE_MAX_SIZE - sizeof(malloc_zone_t)];<br>} virtual_default_zone_t;</p><p>static virtual_default_zone_t virtual_default_zone<br>__attribute__((section(“__DATA,__v_zone”)))<br>__attribute__((aligned(PAGE_MAX_SIZE))) = {<br>    NULL,<br>    NULL,<br>    default_zone_size,<br>    default_zone_malloc,<br>    default_zone_calloc,<br>    default_zone_valloc,<br>    default_zone_free,<br>    default_zone_realloc,<br>    default_zone_destroy,<br>    DEFAULT_MALLOC_ZONE_STRING,<br>    default_zone_batch_malloc,<br>    default_zone_batch_free,<br>    &amp;default_zone_introspect,<br>    10,<br>    default_zone_memalign,<br>    default_zone_free_definite_size,<br>    default_zone_pressure_relief,<br>    default_zone_malloc_claimed_address,<br>};</p><p>static malloc_zone_t *default_zone = &amp;virtual_default_zone.malloc_zone;</p><p>static void *<br>default_zone_malloc(malloc_zone_t *zone, size_t size) {<br>    zone = runtime_default_zone();</p><pre><code>return zone-&gt;malloc(zone, size);</code></pre><p>}</p><p>MALLOC_ALWAYS_INLINE<br>static inline malloc_zone_t *<br>runtime_default_zone() {<br>    return (lite_zone) ? lite_zone : inline_malloc_default_zone();<br>}</p><p>可以看到 <code>default_zone</code> 通过这种方式来初始化</p><p>static inline malloc_zone_t *<br>inline_malloc_default_zone(void) {<br>    _malloc_initialize_once();<br>    // malloc_report(ASL_LEVEL_INFO, “In inline_malloc_default_zone with %d %d\n”, malloc_num_zones, malloc_has_debug_zone);<br>    return malloc_zones[0];<br>}</p><p><strong>随后的调用如下</strong><br><code>_malloc_initialize</code> -&gt; <code>create_scalable_zone</code> -&gt; <code>create_scalable_szone</code> 最终我们创建了 szone_t 类型的对象，通过类型转换，得到了我们的 default_zone。</p><p>malloc_zone_t *<br>create_scalable_zone(size_t initial_size, unsigned debug_flags) {<br>    return (malloc_zone_t *) create_scalable_szone(initial_size, debug_flags);<br>}</p><p>void *malloc_zone_malloc(malloc_zone_t *zone, size_t size) {<br>  MALLOC_TRACE(TRACE_malloc | DBG_FUNC_START, (uintptr_t)zone, size, 0, 0);<br>  void *ptr;<br>  if (malloc_check_start &amp;&amp; (malloc_check_counter++ &gt;= malloc_check_start)) {<br>    internal_check();<br>  }<br>  if (size &gt; MALLOC_ABSOLUTE_MAX_SIZE) {<br>    return NULL;<br>  }<br>  ptr = zone-&gt;malloc(zone, size);<br>  // 在 zone 分配完内存后就开始使用 malloc_logger 进行进行记录<br>  if (malloc_logger) {<br>    malloc_logger(MALLOC_LOG_TYPE_ALLOCATE | MALLOC_LOG_TYPE_HAS_ZONE, (uintptr_t)zone, (uintptr_t)size, 0, (uintptr_t)ptr, 0);<br>  }<br>  MALLOC_TRACE(TRACE_malloc | DBG_FUNC_END, (uintptr_t)zone, size, (uintptr_t)ptr, 0);<br>  return ptr;<br>}</p><p>其分配实现是 <code>zone-&gt;malloc</code> 根据之前的分析，就是szone_t结构体对象中对应的malloc实现。</p><p>在创建szone之后，做了一系列如下的初始化操作。</p><p>// Initialize the security token.<br>szone-&gt;cookie = (uintptr_t)malloc_entropy[0];</p><p>szone-&gt;basic_zone.version = 12;<br>szone-&gt;basic_zone.size = (void *)szone_size;<br>szone-&gt;basic_zone.malloc = (void *)szone_malloc;<br>szone-&gt;basic_zone.calloc = (void *)szone_calloc;<br>szone-&gt;basic_zone.valloc = (void *)szone_valloc;<br>szone-&gt;basic_zone.free = (void *)szone_free;<br>szone-&gt;basic_zone.realloc = (void *)szone_realloc;<br>szone-&gt;basic_zone.destroy = (void *)szone_destroy;<br>szone-&gt;basic_zone.batch_malloc = (void *)szone_batch_malloc;<br>szone-&gt;basic_zone.batch_free = (void *)szone_batch_free;<br>szone-&gt;basic_zone.introspect = (struct malloc_introspection_t *)&amp;szone_introspect;<br>szone-&gt;basic_zone.memalign = (void *)szone_memalign;<br>szone-&gt;basic_zone.free_definite_size = (void *)szone_free_definite_size;<br>szone-&gt;basic_zone.pressure_relief = (void *)szone_pressure_relief;<br>szone-&gt;basic_zone.claimed_address = (void *)szone_claimed_address;</p><p>其他使用 scalable_zone 分配内存的函数的方法也类似，所以大内存的分配，不管外部函数如何封装，最终都会调用到 malloc_logger 函数。所以我们可以用 fishhook 去 hook 这个函数，然后记录内存分配情况，结合一定的数据上报机制，上传到服务器，分析并修复。</p><p>// For logging VM allocation and deallocation, arg1 here<br>// is the mach_port_name_t of the target task in which the<br>// alloc or dealloc is occurring. For example, for mmap()<br>// that would be mach_task_self(), but for a cross-task-capable<br>// call such as mach_vm_map(), it is the target task.</p><p>typedef void (malloc_logger_t)(uint32_t type, uintptr_t arg1, uintptr_t arg2, uintptr_t arg3, uintptr_t result, uint32_t num_hot_frames_to_skip);</p><p>extern malloc_logger_t *__syscall_logger;</p><p>当 malloc_logger 和 __syscall_logger 函数指针不为空时，malloc/free、vm_allocate/vm_deallocate 等内存分配/释放通过这两个指针通知上层，这也是内存调试工具 malloc stack 的实现原理。有了这两个函数指针，我们很容易记录当前存活对象的内存分配信息（包括分配大小和分配堆栈）。分配堆栈可以用 backtrace 函数捕获，但捕获到的地址是虚拟内存地址，不能从符号表 DSYM 解析符号。所以还要记录每个 image 加载时的偏移 slide，这样 <strong>符号表地址 = 堆栈地址 - slide。</strong></p><p>小 tips：</p><p>ASLR（Address space layout randomization）：常见称呼为位址空间随机载入、位址空间配置随机化、位址空间布局随机化，是一种防止内存损坏漏洞被利用的计算机安全技术，通过随机放置进程关键数据区域的定址空间来放置攻击者能可靠地跳转到内存的特定位置来操作函数。现代作业系统一般都具备该机制。</p><p>函数地址 add: 函数真实的实现地址;</p><p>函数虚拟地址：<code>vm_add</code>;</p><p>ASLR: <code>slide</code> 函数虚拟地址加载到进程内存的随机偏移量，每个 mach-o 的 slide 各不相同。<code>vm_add + slide = add</code>。也就是：<code>*(base +offset)= imp</code>。</p><p>由于腾讯也开源了自己的 OOM 定位方案- <a href="https://link.segmentfault.com/?enc=yKbHc3af98aQlln5PiMykQ==.TLNJTvH5g0hkQIcULZcKaEhuB4PrGx64mTZELylFElD2YaHmAbY9Klysfkjwk8a/">OOMDetector</a> ，有了现成的轮子，那么用好就可以了，所以对于内存的监控思路就是找到系统给 App 的内存上限，然后当接近内存上限值的时候，dump 内存情况，组装基础数据信息成一个合格的上报数据，经过一定的数据上报策略到服务端，服务端消费数据，分析产生报表，客户端工程师根据报表分析问题。不同工程的数据以邮件、短信、企业微信等形式通知到该项目的 owner、开发者。（情况严重的会直接电话给开发者，并给主管跟进每一步的处理结果）。<br>问题分析处理后要么发布新版本，要么 hot fix。</p><h3 id="6-开发阶段针对内存我们能做些什么"><a href="#6-开发阶段针对内存我们能做些什么" class="headerlink" title="6. 开发阶段针对内存我们能做些什么"></a>6. 开发阶段针对内存我们能做些什么</h3><ol><li><p>图片缩放</p><p> WWDC 2018 Session 416 - iOS Memory Deep Dive，处理图片缩放的时候直接使用 UIImage 会在解码时读取文件而占用一部分内存，还会生成中间位图 bitmap 消耗大量内存。而 <strong>ImageIO</strong> 不存在上述2种弊端，只会占用最终图片大小的内存</p><p> 做了2组对比实验：给 App 显示一张图片</p><p> // 方法1: 19.6M<br> UIImage *imageResult = [self scaleImage:[UIImage imageNamed:@”test”]                                                  newSize:CGSizeMake(self.view.frame.size.width, self.view.frame.size.height)];<br> self.imageView.image = imageResult;</p><p> // 方法2: 14M<br> NSData *data = UIImagePNGRepresentation([UIImage imageNamed:@”test”]);<br> UIImage *imageResult = [self scaledImageWithData:data                     withSize:CGSizeMake(self.view.frame.size.width, self.view.frame.size.height) scale:3 orientation:UIImageOrientationUp];<br> self.imageView.image = imageResult;</p><ul><li><p>(UIImage *)scaleImage:(UIImage *)image newSize:(CGSize)newSize<br>{<br>  UIGraphicsBeginImageContextWithOptions(newSize, NO, 0);<br>  [image drawInRect:CGRectMake(0, 0, newSize.width, newSize.height)];<br>  UIImage *newImage = UIGraphicsGetImageFromCurrentImageContext();<br>  UIGraphicsEndImageContext();<br>  return newImage;<br>}</p></li><li><p>(UIImage *)scaledImageWithData:(NSData *)data withSize:(CGSize)size scale:(CGFloat)scale orientation:(UIImageOrientation)orientation<br>{<br>  CGFloat maxPixelSize = MAX(size.width, size.height);<br>  CGImageSourceRef sourceRef = CGImageSourceCreateWithData((__bridge CFDataRef)data, nil);<br>  NSDictionary *options = @{(__bridge id)kCGImageSourceCreateThumbnailFromImageAlways : (__bridge id)kCFBooleanTrue,</p><pre><code>                        (\_\_bridge id)kCGImageSourceThumbnailMaxPixelSize : \[NSNumber numberWithFloat:maxPixelSize\]&#125;;</code></pre><p>  CGImageRef imageRef = CGImageSourceCreateThumbnailAtIndex(sourceRef, 0, (__bridge CFDictionaryRef)options);<br>  UIImage *resultImage = [UIImage imageWithCGImage:imageRef scale:scale orientation:orientation];<br>  CGImageRelease(imageRef);<br>  CFRelease(sourceRef);<br>  return resultImage;<br>}</p></li></ul></li></ol><p>可以看出使用 ImageIO 比使用 UIImage 直接缩放占用内存更低。</p><ol start="2"><li><p>合理使用 autoreleasepool</p><p> 我们知道 autoreleasepool 对象是在 RunLoop 结束时才释放。在 ARC 下，我们如果在不断申请内存，比如各种循环，那么我们就需要手动添加 autoreleasepool，避免短时间内内存猛涨发生 OOM。</p><p> 对比实验</p><p> // 实验1<br> NSMutableArray *array = [NSMutableArray array];<br> for (NSInteger index = 0; index &lt; 10000000; index++) {<br>  NSString *indexStrng = [NSString stringWithFormat:@”%zd”, index];<br>  NSString *resultString = [NSString stringWithFormat:@”%zd-%@”, index, indexStrng];<br>  [array addObject:resultString];<br> }</p><p> // 实验2<br> NSMutableArray *array = [NSMutableArray array];<br> for (NSInteger index = 0; index &lt; 10000000; index++) {<br>  @autoreleasepool {<br>  NSString *indexStrng = [NSString stringWithFormat:@”%zd”, index];<br>  NSString *resultString = [NSString stringWithFormat:@”%zd-%@”, index, indexStrng];<br>  [array addObject:resultString];<br>  }<br> }</p></li></ol><p>实验1消耗内存 739.6M，实验2消耗内存 587M。</p><ol start="3"><li><p> UIGraphicsBeginImageContext 和 UIGraphicsEndImageContext 必须成双出现，不然会造成 context 泄漏。另外 XCode 的 Analyze 也能扫出这类问题。</p></li><li><p> 不管是打开网页，还是执行 js，都应该使用 WKWebView。UIWebView 会占用大量内存，从而导致 App 发生 OOM 的几率增加，而 WKWebView 是一个多进程组件，Network Loading 以及 UI Rendering 在其它进程中执行，比 UIWebView 占用更低的内存开销。</p></li><li><p>在做 SDK 或者 App，如果场景是缓存相关，尽量使用 NSCache 而不是 NSMutableDictionary。它是系统提供的专门处理缓存的类，NSCache 分配的内存是 <code>Purgeable Memory</code>，可以由系统自动释放。NSCache 与 NSPureableData 的结合使用可以让系统根据情况回收内存，也可以在内存清理时移除对象。</p><p> 其他的开发习惯就不一一描述了，良好的开发习惯和代码意识是需要平时注意修炼的。</p></li></ol><h3 id="7-现状及其改进"><a href="#7-现状及其改进" class="headerlink" title="7. 现状及其改进"></a>7. 现状及其改进</h3><p>在使用了一波业界优秀的的内存监控工具后发现了一些问题，比如 <code>MLeaksFinder</code>、<code>OOMDetector</code>、<code>FBRetainCycleDetector</code>等都有一些问题。比如 <code>MLeaksFinder</code> 因为单纯通过 VC 的 push、pop 等检测内存泄露的情况，会存在误报的情况。<code>FBRetainCycleDetector</code> 则因为对象深度优先遍历，会有一些性能问题，影响 App 性能。<code>OOMDetector</code> 因为没有合适的触发时机。</p><p>思路有2种：</p><ul><li>  <code>MLeaksFinder</code> + <code>FBRetainCycleDetector</code> 结合提高准确性</li><li>  借鉴头条的实现方案：基于内存快照技术的线上方案，我们称之为——线上 Memory Graph。（引用如下）</li></ul><blockquote><ul><li>  基于 Objective-C 对象引用关系找循环引用的方案，适用范围比较小，只能处理部分循环引用问题，而内存问题通常是复杂的，类似于内存堆积，Root Leak，C/C++层问题都无法解决。</li><li>  基于分配堆栈信息聚类的方案需要常驻运行，对内存、CPU 等资源存在较大消耗，无法针对有内存问题的用户进行监控，只能广撒网，用户体验影响较大。同时，通过某些比较通用的堆栈分配的内存无法定位出实际的内存使用场景，对于循环引用等常见泄漏也无法分析。</li></ul></blockquote><p>核心原理是： 扫描进程中所有的 Dirty 内存，通过内存节点中保存的其他内存节点的地址值，建立起内存节点之间的引用关系的有向图。</p><p>全部的讲解可以看这里)。对于 Memory Graph 的实现细节感兴趣的可以看这篇<a href="https://link.segmentfault.com/?enc=JCBA55CJcQityylTd2V54w==.YaCpcpVk5R35as3/ROYixsLzKFlCP2yFYxf4IsraLh/EQjp7u9kioXChaJGQzACX">文章</a></p><h2 id="五、-App-网络监控"><a href="#五、-App-网络监控" class="headerlink" title="五、 App 网络监控"></a>五、 App 网络监控</h2><p>移动网络环境一直很复杂，WIFI、2G、3G、4G、5G 等，用户使用 App 的过程中可能在这几种类型之间切换，这也是移动网络和传统网络间的一个区别，被称为「Connection Migration」。此外还存在 DNS 解析缓慢、失败率高、运营商劫持等问题。用户在使用 App 时因为某些原因导致体验很差，要想针对网络情况进行改善，必须有清晰的监控手段。</p><h3 id="1-App-网络请求过程"><a href="#1-App-网络请求过程" class="headerlink" title="1. App 网络请求过程"></a>1. App 网络请求过程</h3><p><img src="https://segmentfault.com/img/bVbIOhA"></p><p>App 发送一次网络请求一般会经历下面几个关键步骤：</p><ul><li><p>DNS 解析</p><p>  Domain Name system，网络域名名称系统，本质上就是将<code>域名</code>和<code>IP 地址</code> 相互映射的一个分布式数据库，使人们更方便的访问互联网。首先会查询本地的 DNS 缓存，查找失败就去 DNS 服务器查询，这其中可能会经过非常多的节点，涉及到<strong>递归查询和迭代查询</strong>的过程。运营商可能不干人事：一种情况就是出现运营商劫持的现象，表现为你在 App 内访问某个网页的时候会看到和内容不相关的广告；另一种可能的情况就是把你的请求丢给非常远的基站去做 DNS 解析，导致我们 App 的 DNS 解析时间较长，App 网络效率低。一般做 HTTPDNS 方案去自行解决 DNS 的问题。</p></li><li><p>TCP 3次握手</p><p>  关于 TCP 握手过程中为什么是3次握手而不是2次、4次，可以查看这篇<a href="https://link.segmentfault.com/?enc=4bf4fIci5+2SfwGhscbC8A==.JejU/qg7VrCdv+zxcQmevbCzhRa1Cmx81mmRYmh1XkWKMZhUAMuy+3VW42U2OI1iy1tkPAqSWzWeVDDOI15+9g==">文章</a>。</p></li><li><p>TLS 握手</p><p>  对于 HTTPS 请求还需要做 TLS 握手，也就是密钥协商的过程。</p></li><li><p>发送请求</p><p>  连接建立好之后就可以发送 request，此时可以记录下 request start 时间</p></li><li><p>等待回应</p><p>  等待服务器返回响应。这个时间主要取决于资源大小，也是网络请求过程中最为耗时的一个阶段。</p></li><li><p>返回响应</p><p>  服务端返回响应给客户端，根据 HTTP header 信息中的状态码判断本次请求是否成功、是否走缓存、是否需要重定向。</p></li></ul><h3 id="2-监控原理"><a href="#2-监控原理" class="headerlink" title="2. 监控原理"></a>2. 监控原理</h3><p>名称</p><p>说明</p><p>NSURLConnection</p><p>已经被废弃。用法简单</p><p>NSURLSession</p><p>iOS7.0 推出，功能更强大</p><p>CFNetwork</p><p>NSURL 的底层，纯 C 实现</p><p>iOS 网络框架层级关系如下：</p><p><img src="https://segmentfault.com/img/bVbIOhF"></p><p>iOS 网络现状是由4层组成的：最底层的 BSD Sockets、SecureTransport；次级底层是 CFNetwork、NSURLSession、NSURLConnection、WebView 是用 Objective-C 实现的，且调用 CFNetwork；应用层框架 AFNetworking 基于 NSURLSession、NSURLConnection 实现。</p><p>目前业界对于网络监控主要有2种：一种是通过 NSURLProtocol 监控、一种是通过 Hook 来监控。下面介绍几种办法来监控网络请求，各有优缺点。</p><h4 id="2-1-方案一：NSURLProtocol-监控-App-网络请求"><a href="#2-1-方案一：NSURLProtocol-监控-App-网络请求" class="headerlink" title="2.1 方案一：NSURLProtocol 监控 App 网络请求"></a>2.1 方案一：NSURLProtocol 监控 App 网络请求</h4><p>NSURLProtocol 作为上层接口，使用较为简单，但 NSURLProtocol 属于 URL Loading System 体系中。应用协议的支持程度有限，支持 FTP、HTTP、HTTPS 等几个应用层协议，对于其他的协议则无法监控，存在一定的局限性。如果监控底层网络库 CFNetwork 则没有这个限制。</p><p>对于 NSURLProtocol 的具体做法在<a href="https://link.segmentfault.com/?enc=32MAqCv5rRh1xG9swBrweQ==.waVikw52hdsc0HH/KXTAhq1AbWxJWzODd9KmUKRpFe0ys3u+yRMdMdKnPLFVrtinIpYrvdbyeC33qKZqTeuJx8TDkWj/hIeStA+z7zej8a/ZVIlwwrLHg+MKzIhLU5BM">这篇文章</a>中讲过，继承抽象类并实现相应的方法，自定义去发起网络请求来实现监控的目的。</p><p>iOS 10 之后，NSURLSessionTaskDelegate 中增加了一个新的代理方法：</p><p>/*<br> * Sent when complete statistics information has been collected for the task.<br> */</p><ul><li>(void)URLSession:(NSURLSession *)session task:(NSURLSessionTask *)task didFinishCollectingMetrics:(NSURLSessionTaskMetrics *)metrics API_AVAILABLE(macosx(10.12), ios(10.0), watchos(3.0), tvos(10.0));</li></ul><p>可以从 <code>NSURLSessionTaskMetrics</code> 中获取到网络情况的各项指标。各项参数如下</p><p>@interface NSURLSessionTaskMetrics : NSObject</p><p>/*<br> * transactionMetrics array contains the metrics collected for every request/response transaction created during the task execution.<br> */<br>@property (copy, readonly) NSArray&lt;NSURLSessionTaskTransactionMetrics *&gt; *transactionMetrics;</p><p>/*<br> * Interval from the task creation time to the task completion time.<br> * Task creation time is the time when the task was instantiated.<br> * Task completion time is the time when the task is about to change its internal state to completed.<br> */<br>@property (copy, readonly) NSDateInterval *taskInterval;</p><p>/*<br> * redirectCount is the number of redirects that were recorded.<br> */<br>@property (assign, readonly) NSUInteger redirectCount;</p><ul><li>(instancetype)init API_DEPRECATED(“Not supported”, macos(10.12,10.15), ios(10.0,13.0), watchos(3.0,6.0), tvos(10.0,13.0));</li></ul><ul><li>(instancetype)new API_DEPRECATED(“Not supported”, macos(10.12,10.15), ios(10.0,13.0), watchos(3.0,6.0), tvos(10.0,13.0));</li></ul><p>@end</p><p>其中：<code>taskInterval</code> 表示任务从创建到完成话费的总时间，任务的创建时间是任务被实例化时的时间，任务完成时间是任务的内部状态将要变为完成的时间；<code>redirectCount</code> 表示被重定向的次数；<code>transactionMetrics</code> 数组包含了任务执行过程中每个请求/响应事务中收集的指标，各项参数如下：</p><pre><code>/* * This class defines the performance metrics collected for a request/response transaction during the task execution. */API_AVAILABLE(macosx(10.12), ios(10.0), watchos(3.0), tvos(10.0))@interface NSURLSessionTaskTransactionMetrics : NSObject/* * Represents the transaction request. 请求事务 */@property (copy, readonly) NSURLRequest *request;/* * Represents the transaction response. Can be nil if error occurred and no response was generated. 响应事务 */@property (nullable, copy, readonly) NSURLResponse *response;/* * For all NSDate metrics below, if that aspect of the task could not be completed, then the corresponding “EndDate” metric will be nil. * For example, if a name lookup was started but the name lookup timed out, failed, or the client canceled the task before the name could be resolved -- then while domainLookupStartDate may be set, domainLookupEndDate will be nil along with all later metrics. *//* * 客户端开始请求的时间，无论是从服务器还是从本地缓存中获取 * fetchStartDate returns the time when the user agent started fetching the resource, whether or not the resource was retrieved from the server or local resources. * * The following metrics will be set to nil, if a persistent connection was used or the resource was retrieved from local resources: * *   domainLookupStartDate *   domainLookupEndDate *   connectStartDate *   connectEndDate *   secureConnectionStartDate *   secureConnectionEndDate */@property (nullable, copy, readonly) NSDate *fetchStartDate;/* * domainLookupStartDate returns the time immediately before the user agent started the name lookup for the resource. DNS 开始解析的时间 */@property (nullable, copy, readonly) NSDate *domainLookupStartDate;/* * domainLookupEndDate returns the time after the name lookup was completed. DNS 解析完成的时间 */@property (nullable, copy, readonly) NSDate *domainLookupEndDate;/* * connectStartDate is the time immediately before the user agent started establishing the connection to the server. * * For example, this would correspond to the time immediately before the user agent started trying to establish the TCP connection. 客户端与服务端开始建立 TCP 连接的时间 */@property (nullable, copy, readonly) NSDate *connectStartDate;/* * If an encrypted connection was used, secureConnectionStartDate is the time immediately before the user agent started the security handshake to secure the current connection. HTTPS 的 TLS 握手开始的时间 * * For example, this would correspond to the time immediately before the user agent started the TLS handshake.  * * If an encrypted connection was not used, this attribute is set to nil. */@property (nullable, copy, readonly) NSDate *secureConnectionStartDate;/* * If an encrypted connection was used, secureConnectionEndDate is the time immediately after the security handshake completed. HTTPS 的 TLS 握手结束的时间 * * If an encrypted connection was not used, this attribute is set to nil. */@property (nullable, copy, readonly) NSDate *secureConnectionEndDate;/* * connectEndDate is the time immediately after the user agent finished establishing the connection to the server, including completion of security-related and other handshakes. 客户端与服务器建立 TCP 连接完成的时间，包括 TLS 握手时间 */@property (nullable, copy, readonly) NSDate *connectEndDate;/* * requestStartDate is the time immediately before the user agent started requesting the source, regardless of whether the resource was retrieved from the server or local resources. 客户端请求开始的时间，可以理解为开始传输 HTTP 请求的 header 的第一个字节时间 * * For example, this would correspond to the time immediately before the user agent sent an HTTP GET request. */@property (nullable, copy, readonly) NSDate *requestStartDate;/* * requestEndDate is the time immediately after the user agent finished requesting the source, regardless of whether the resource was retrieved from the server or local resources. 客户端请求结束的时间，可以理解为 HTTP 请求的最后一个字节传输完成的时间 * * For example, this would correspond to the time immediately after the user agent finished sending the last byte of the request. */@property (nullable, copy, readonly) NSDate *requestEndDate;/* * responseStartDate is the time immediately after the user agent received the first byte of the response from the server or from local resources. 客户端从服务端接收响应的第一个字节的时间 * * For example, this would correspond to the time immediately after the user agent received the first byte of an HTTP response. */@property (nullable, copy, readonly) NSDate *responseStartDate;/* * responseEndDate is the time immediately after the user agent received the last byte of the resource. 客户端从服务端接收到最后一个请求的时间 */@property (nullable, copy, readonly) NSDate *responseEndDate;/* * The network protocol used to fetch the resource, as identified by the ALPN Protocol ID Identification Sequence [RFC7301]. * E.g., h2, http/1.1, spdy/3.1. 网络协议名，比如 http/1.1, spdy/3.1 * * When a proxy is configured AND a tunnel connection is established, then this attribute returns the value for the tunneled protocol. * * For example: * If no proxy were used, and HTTP/2 was negotiated, then h2 would be returned. * If HTTP/1.1 were used to the proxy, and the tunneled connection was HTTP/2, then h2 would be returned. * If HTTP/1.1 were used to the proxy, and there were no tunnel, then http/1.1 would be returned. * */@property (nullable, copy, readonly) NSString *networkProtocolName;/* * This property is set to YES if a proxy connection was used to fetch the resource.    该连接是否使用了代理 */@property (assign, readonly, getter=isProxyConnection) BOOL proxyConnection;/* * This property is set to YES if a persistent connection was used to fetch the resource. 是否复用了现有连接 */@property (assign, readonly, getter=isReusedConnection) BOOL reusedConnection;/* * Indicates whether the resource was loaded, pushed or retrieved from the local cache. 获取资源来源 */@property (assign, readonly) NSURLSessionTaskMetricsResourceFetchType resourceFetchType;/* * countOfRequestHeaderBytesSent is the number of bytes transferred for request header. 请求头的字节数 */@property (readonly) int64_t countOfRequestHeaderBytesSent API_AVAILABLE(macos(10.15), ios(13.0), watchos(6.0), tvos(13.0));/* * countOfRequestBodyBytesSent is the number of bytes transferred for request body. 请求体的字节数 * It includes protocol-specific framing, transfer encoding, and content encoding. */@property (readonly) int64_t countOfRequestBodyBytesSent API_AVAILABLE(macos(10.15), ios(13.0), watchos(6.0), tvos(13.0));/* * countOfRequestBodyBytesBeforeEncoding is the size of upload body data, file, or stream. 上传体数据、文件、流的大小 */@property (readonly) int64_t countOfRequestBodyBytesBeforeEncoding API_AVAILABLE(macos(10.15), ios(13.0), watchos(6.0), tvos(13.0));/* * countOfResponseHeaderBytesReceived is the number of bytes transferred for response header. 响应头的字节数 */@property (readonly) int64_t countOfResponseHeaderBytesReceived API_AVAILABLE(macos(10.15), ios(13.0), watchos(6.0), tvos(13.0));/* * countOfResponseBodyBytesReceived is the number of bytes transferred for response body. 响应体的字节数 * It includes protocol-specific framing, transfer encoding, and content encoding. */@property (readonly) int64_t countOfResponseBodyBytesReceived API_AVAILABLE(macos(10.15), ios(13.0), watchos(6.0), tvos(13.0));/* * countOfResponseBodyBytesAfterDecoding is the size of data delivered to your delegate or completion handler.给代理方法或者完成后处理的回调的数据大小 */@property (readonly) int64_t countOfResponseBodyBytesAfterDecoding API_AVAILABLE(macos(10.15), ios(13.0), watchos(6.0), tvos(13.0));/* * localAddress is the IP address string of the local interface for the connection.  当前连接下的本地接口 IP 地址 * * For multipath protocols, this is the local address of the initial flow. * * If a connection was not used, this attribute is set to nil. */@property (nullable, copy, readonly) NSString *localAddress API_AVAILABLE(macos(10.15), ios(13.0), watchos(6.0), tvos(13.0));/* * localPort is the port number of the local interface for the connection. 当前连接下的本地端口号 * * For multipath protocols, this is the local port of the initial flow. * * If a connection was not used, this attribute is set to nil. */@property (nullable, copy, readonly) NSNumber *localPort API_AVAILABLE(macos(10.15), ios(13.0), watchos(6.0), tvos(13.0));/* * remoteAddress is the IP address string of the remote interface for the connection. 当前连接下的远端 IP 地址 * * For multipath protocols, this is the remote address of the initial flow. * * If a connection was not used, this attribute is set to nil. */@property (nullable, copy, readonly) NSString *remoteAddress API_AVAILABLE(macos(10.15), ios(13.0), watchos(6.0), tvos(13.0));/* * remotePort is the port number of the remote interface for the connection.  当前连接下的远端端口号 * * For multipath protocols, this is the remote port of the initial flow. * * If a connection was not used, this attribute is set to nil. */@property (nullable, copy, readonly) NSNumber *remotePort API_AVAILABLE(macos(10.15), ios(13.0), watchos(6.0), tvos(13.0));/* * negotiatedTLSProtocolVersion is the TLS protocol version negotiated for the connection.  连接协商用的 TLS 协议版本号 * It is a 2-byte sequence in host byte order. * * Please refer to tls_protocol_version_t enum in Security/SecProtocolTypes.h * * If an encrypted connection was not used, this attribute is set to nil. */@property (nullable, copy, readonly) NSNumber *negotiatedTLSProtocolVersion API_AVAILABLE(macos(10.15), ios(13.0), watchos(6.0), tvos(13.0));/* * negotiatedTLSCipherSuite is the TLS cipher suite negotiated for the connection. 连接协商用的 TLS 密码套件 * It is a 2-byte sequence in host byte order. * * Please refer to tls_ciphersuite_t enum in Security/SecProtocolTypes.h * * If an encrypted connection was not used, this attribute is set to nil. */@property (nullable, copy, readonly) NSNumber *negotiatedTLSCipherSuite API_AVAILABLE(macos(10.15), ios(13.0), watchos(6.0), tvos(13.0));/* * Whether the connection is established over a cellular interface. 是否是通过蜂窝网络建立的连接 */@property (readonly, getter=isCellular) BOOL cellular API_AVAILABLE(macos(10.15), ios(13.0), watchos(6.0), tvos(13.0));/* * Whether the connection is established over an expensive interface. 是否通过昂贵的接口建立的连接 */@property (readonly, getter=isExpensive) BOOL expensive API_AVAILABLE(macos(10.15), ios(13.0), watchos(6.0), tvos(13.0));/* * Whether the connection is established over a constrained interface. 是否通过受限接口建立的连接 */@property (readonly, getter=isConstrained) BOOL constrained API_AVAILABLE(macos(10.15), ios(13.0), watchos(6.0), tvos(13.0));/* * Whether a multipath protocol is successfully negotiated for the connection. 是否为了连接成功协商了多路径协议 */@property (readonly, getter=isMultipath) BOOL multipath API_AVAILABLE(macos(10.15), ios(13.0), watchos(6.0), tvos(13.0));- (instancetype)init API_DEPRECATED(&quot;Not supported&quot;, macos(10.12,10.15), ios(10.0,13.0), watchos(3.0,6.0), tvos(10.0,13.0));+ (instancetype)new API_DEPRECATED(&quot;Not supported&quot;, macos(10.12,10.15), ios(10.0,13.0), watchos(3.0,6.0), tvos(10.0,13.0));@end</code></pre><p>网络监控简单代码</p><p>// 监控基础信息<br>@interface  NetworkMonitorBaseDataModel : NSObject<br>// 请求的 URL 地址<br>@property (nonatomic, strong) NSString *requestUrl;<br>//请求头<br>@property (nonatomic, strong) NSArray *requestHeaders;<br>//响应头<br>@property (nonatomic, strong) NSArray *responseHeaders;<br>//GET方法 的请求参数<br>@property (nonatomic, strong) NSString *getRequestParams;<br>//HTTP 方法, 比如 POST<br>@property (nonatomic, strong) NSString *httpMethod;<br>//协议名，如http1.0 / http1.1 / http2.0<br>@property (nonatomic, strong) NSString *httpProtocol;<br>//是否使用代理<br>@property (nonatomic, assign) BOOL useProxy;<br>//DNS解析后的 IP 地址<br>@property (nonatomic, strong) NSString *ip;<br>@end</p><p>// 监控信息模型<br>@interface  NetworkMonitorDataModel : NetworkMonitorBaseDataModel<br>//客户端发起请求的时间<br>@property (nonatomic, assign) UInt64 requestDate;<br>//客户端开始请求到开始dns解析的等待时间,单位ms<br>@property (nonatomic, assign) int waitDNSTime;<br>//DNS 解析耗时<br>@property (nonatomic, assign) int dnsLookupTime;<br>//tcp 三次握手耗时,单位ms<br>@property (nonatomic, assign) int tcpTime;<br>//ssl 握手耗时<br>@property (nonatomic, assign) int sslTime;<br>//一个完整请求的耗时,单位ms<br>@property (nonatomic, assign) int requestTime;<br>//http 响应码<br>@property (nonatomic, assign) NSUInteger httpCode;<br>//发送的字节数<br>@property (nonatomic, assign) UInt64 sendBytes;<br>//接收的字节数<br>@property (nonatomic, assign) UInt64 receiveBytes;</p><p>// 错误信息模型<br>@interface  NetworkMonitorErrorModel : NetworkMonitorBaseDataModel<br>//错误码<br>@property (nonatomic, assign) NSInteger errorCode;<br>//错误次数<br>@property (nonatomic, assign) NSUInteger errCount;<br>//异常名<br>@property (nonatomic, strong) NSString *exceptionName;<br>//异常详情<br>@property (nonatomic, strong) NSString *exceptionDetail;<br>//异常堆栈<br>@property (nonatomic, strong) NSString *stackTrace;<br>@end</p><p>// 继承自 NSURLProtocol 抽象类，实现响应方法，代理网络请求<br>@interface CustomURLProtocol () &lt;NSURLSessionTaskDelegate&gt;</p><p>@property (nonatomic, strong) NSURLSessionDataTask *dataTask;<br>@property (nonatomic, strong) NSOperationQueue *sessionDelegateQueue;<br>@property (nonatomic, strong) NetworkMonitorDataModel *dataModel;<br>@property (nonatomic, strong) NetworkMonitorErrorModel *errModel;</p><p>@end</p><p>//使用NSURLSessionDataTask请求网络</p><ul><li>(void)startLoading {<br>  NSURLSessionConfiguration *configuration = [NSURLSessionConfiguration defaultSessionConfiguration];<pre><code>NSURLSession \*session = \[NSURLSession sessionWithConfiguration:configuration                                                    delegate:self                                               delegateQueue:nil\];</code></pre>  NSURLSession *session = [NSURLSession sessionWithConfiguration:configuration delegate:self delegateQueue:nil];<pre><code>self.sessionDelegateQueue = \[\[NSOperationQueue alloc\] init\];</code></pre>  self.sessionDelegateQueue.maxConcurrentOperationCount = 1;<br>  self.sessionDelegateQueue.name = @”com.networkMonitor.session.queue”;<br>  self.dataTask = [session dataTaskWithRequest:self.request];<br>  [self.dataTask resume];<br>}</li></ul><p>#pragma mark - NSURLSessionTaskDelegate</p><ul><li>(void)URLSession:(NSURLSession *)session task:(NSURLSessionTask *)task didCompleteWithError:(NSError *)error {<br>  if (error) {<pre><code>  \[self.client URLProtocol:self didFailWithError:error\];</code></pre>  } else {<pre><code>  \[self.client URLProtocolDidFinishLoading:self\];</code></pre>  }<br>  if (error) {<pre><code>  NSURLRequest \*request = task.currentRequest;  if (request) &#123;      self.errModel.requestUrl  = request.URL.absoluteString;              self.errModel.httpMethod = request.HTTPMethod;      self.errModel.requestParams = request.URL.query;  &#125;  self.errModel.errorCode = error.code;  self.errModel.exceptionName = error.domain;  self.errModel.exceptionDetail = error.description;// 上传 Network 数据到数据上报组件，数据上报会在 \[打造功能强大、灵活可配置的数据上报组件\](https://github.com/FantasticLBP/knowledge-kit/blob/master/Chapter1%20-%20iOS/1.80.md) 讲</code></pre>  }<br>  self.dataTask = nil;<br>}</li></ul><ul><li><p>(void)URLSession:(NSURLSession *)session task:(NSURLSessionTask *)task didFinishCollectingMetrics:(NSURLSessionTaskMetrics *)metrics {</p><pre><code> if (@available(iOS 10.0, \*) &amp;&amp; \[metrics.transactionMetrics count\] &gt; 0) &#123;  \[metrics.transactionMetrics enumerateObjectsUsingBlock:^(NSURLSessionTaskTransactionMetrics \*\_Nonnull obj, NSUInteger idx, BOOL \*\_Nonnull stop) &#123;      if (obj.resourceFetchType == NSURLSessionTaskMetricsResourceFetchTypeNetworkLoad) &#123;          if (obj.fetchStartDate) &#123;              self.dataModel.requestDate = \[obj.fetchStartDate timeIntervalSince1970\] \* 1000;          &#125;          if (obj.domainLookupStartDate &amp;&amp; obj.domainLookupEndDate) &#123;              self.dataModel. waitDNSTime = ceil(\[obj.domainLookupStartDate timeIntervalSinceDate:obj.fetchStartDate\] \* 1000);              self.dataModel. dnsLookupTime = ceil(\[obj.domainLookupEndDate timeIntervalSinceDate:obj.domainLookupStartDate\] \* 1000);          &#125;          if (obj.connectStartDate) &#123;              if (obj.secureConnectionStartDate) &#123;                  self.dataModel. waitDNSTime = ceil(\[obj.secureConnectionStartDate timeIntervalSinceDate:obj.connectStartDate\] \* 1000);              &#125; else if (obj.connectEndDate) &#123;                  self.dataModel.tcpTime = ceil(\[obj.connectEndDate timeIntervalSinceDate:obj.connectStartDate\] \* 1000);              &#125;          &#125;          if (obj.secureConnectionEndDate &amp;&amp; obj.secureConnectionStartDate) &#123;              self.dataModel.sslTime = ceil(\[obj.secureConnectionEndDate timeIntervalSinceDate:obj.secureConnectionStartDate\] \* 1000);          &#125;          if (obj.fetchStartDate &amp;&amp; obj.responseEndDate) &#123;              self.dataModel.requestTime = ceil(\[obj.responseEndDate timeIntervalSinceDate:obj.fetchStartDate\] \* 1000);          &#125;          self.dataModel.httpProtocol = obj.networkProtocolName;          NSHTTPURLResponse \*response = (NSHTTPURLResponse \*)obj.response;          if (\[response isKindOfClass:NSHTTPURLResponse.class\]) &#123;              self.dataModel.receiveBytes = response.expectedContentLength;          &#125;          if (\[obj respondsToSelector:@selector(\_remoteAddressAndPort)\]) &#123;              self.dataModel.ip = \[obj valueForKey:@&quot;\_remoteAddressAndPort&quot;\];          &#125;          if (\[obj respondsToSelector:@selector(\_requestHeaderBytesSent)\]) &#123;              self.dataModel.sendBytes = \[\[obj valueForKey:@&quot;\_requestHeaderBytesSent&quot;\] unsignedIntegerValue\];          &#125;          if (\[obj respondsToSelector:@selector(\_responseHeaderBytesReceived)\]) &#123;              self.dataModel.receiveBytes = \[\[obj valueForKey:@&quot;\_responseHeaderBytesReceived&quot;\] unsignedIntegerValue\];          &#125;         self.dataModel.requestUrl = \[obj.request.URL absoluteString\];          self.dataModel.httpMethod = obj.request.HTTPMethod;          self.dataModel.useProxy = obj.isProxyConnection;      &#125;  &#125;\];          // 上传 Network 数据到数据上报组件，数据上报会在 \[打造功能强大、灵活可配置的数据上报组件\](https://github.com/FantasticLBP/knowledge-kit/blob/master/Chapter1%20-%20iOS/1.80.md) 讲</code></pre><p>  }<br>}</p></li></ul><h4 id="2-2-方案二：NSURLProtocol-监控-App-网络请求之黑魔法篇"><a href="#2-2-方案二：NSURLProtocol-监控-App-网络请求之黑魔法篇" class="headerlink" title="2.2 方案二：NSURLProtocol 监控 App 网络请求之黑魔法篇"></a>2.2 方案二：NSURLProtocol 监控 App 网络请求之黑魔法篇</h4><p>文章上面 <a href="https://segmentfault.com/a/1190000040277799#network-2.1">2.1</a> 分析到了 NSURLSessionTaskMetrics 由于兼容性问题，对于网络监控来说似乎不太完美，但是自后在搜资料的时候看到了一篇<a href="https://link.segmentfault.com/?enc=lyjF2l1sjWlNLh2nKf0mXw==.2JdFSv7uYQ9qWxE26VJkv7dXHcec4rUBP6BpC/FCKNN/5qdXhE9jLJ3RU0x8KzGA">文章</a>。文章在分析 WebView 的网络监控的时候分析 Webkit 源码的时候发现了下面代码</p><p>#if !HAVE(TIMINGDATAOPTIONS)<br>void setCollectsTimingData()<br>{<br>    static dispatch_once_t onceToken;<br>    dispatch_once(&amp;onceToken, ^{<br>        [NSURLConnection _setCollectsTimingData:YES];<br>        …<br>    });<br>}<br>#endif</p><p>也就是说明 NSURLConnection 本身有一套 <code>TimingData</code> 的收集 API，只是没有暴露给开发者，苹果自己在用而已。在 runtime header 中找到了 NSURLConnection 的 <code>_setCollectsTimingData:</code> 、<code>_timingData</code> 2个 api（iOS8 以后可以使用）。</p><p>NSURLSession 在 iOS9 之前使用 <code>_setCollectsTimingData:</code> 就可以使用 TimingData 了。</p><p>注意：</p><ul><li>  因为是私有 API，所以在使用的时候注意混淆。比如 <code>[[@&quot;_setC&quot; stringByAppendingString:@&quot;ollectsT&quot;] stringByAppendingString:@&quot;imingData:&quot;]</code>。</li><li>  不推荐私有 API，一般做 APM 的属于公共团队，你想想看虽然你做的 SDK 达到网络监控的目的了，但是万一给业务线的 App 上架造成了问题，那就得不偿失了。一般这种投机取巧，不是百分百确定的事情可以在玩具阶段使用。</li></ul><p>@interface _NSURLConnectionProxy : DelegateProxy</p><p>@end</p><p>@implementation _NSURLConnectionProxy</p><ul><li><p>(BOOL)respondsToSelector:(SEL)aSelector<br>{<br>  if ([NSStringFromSelector(aSelector) isEqualToString:@”connectionDidFinishLoading:”]) {</p><pre><code>  return YES;</code></pre><p>  }<br>  return [self.target respondsToSelector:aSelector];<br>}</p></li><li><p>(void)forwardInvocation:(NSInvocation *)invocation<br>{<br>  [super forwardInvocation:invocation];<br>  if ([NSStringFromSelector(invocation.selector) isEqualToString:@”connectionDidFinishLoading:”]) {</p><pre><code>  \_\_unsafe\_unretained NSURLConnection \*conn;  \[invocation getArgument:&amp;conn atIndex:2\];  SEL selector = NSSelectorFromString(\[@&quot;\_timin&quot; stringByAppendingString:@&quot;gData&quot;\]);  NSDictionary \*timingData = \[conn performSelector:selector\];  \[\[NTDataKeeper shareInstance\] trackTimingData:timingData request:conn.currentRequest\];</code></pre><p>  }<br>}</p></li></ul><p>@end</p><p>@implementation NSURLConnection(tracker)</p><ul><li><p>(void)load<br>{<br>  static dispatch_once_t onceToken;<br>  dispatch_once(&amp;onceToken, ^{</p><pre><code>  Class class = \[self class\];  SEL originalSelector = @selector(initWithRequest:delegate:);  SEL swizzledSelector = @selector(swizzledInitWithRequest:delegate:);  Method originalMethod = class\_getInstanceMethod(class, originalSelector);  Method swizzledMethod = class\_getInstanceMethod(class, swizzledSelector);  method\_exchangeImplementations(originalMethod, swizzledMethod);  NSString \*selectorName = \[\[@&quot;\_setC&quot; stringByAppendingString:@&quot;ollectsT&quot;\] stringByAppendingString:@&quot;imingData:&quot;\];  SEL selector = NSSelectorFromString(selectorName);  \[NSURLConnection performSelector:selector withObject:@(YES)\];</code></pre><p>  });<br>}</p></li></ul><ul><li>(instancetype)swizzledInitWithRequest:(NSURLRequest *)request delegate:(id&lt;NSURLConnectionDelegate&gt;)delegate<br>{<br>  if (delegate) {<pre><code>  \_NSURLConnectionProxy \*proxy = \[\[\_NSURLConnectionProxy alloc\] initWithTarget:delegate\];  objc\_setAssociatedObject(delegate ,@&quot;\_NSURLConnectionProxy&quot; ,proxy, OBJC\_ASSOCIATION\_RETAIN\_NONATOMIC);  return \[self swizzledInitWithRequest:request delegate:(id&lt;NSURLConnectionDelegate\&gt;)proxy\];</code></pre>  }else{<pre><code>  return \[self swizzledInitWithRequest:request delegate:delegate\];</code></pre>  }<br>}</li></ul><p>@end</p><h4 id="2-3-方案三：Hook"><a href="#2-3-方案三：Hook" class="headerlink" title="2.3 方案三：Hook"></a>2.3 方案三：Hook</h4><p>iOS 中 hook 技术有2类，一种是 NSProxy，一种是 method swizzling（isa swizzling）</p><h5 id="2-3-1-方法一"><a href="#2-3-1-方法一" class="headerlink" title="2.3.1 方法一"></a>2.3.1 方法一</h5><p>写 SDK 肯定不可能手动侵入业务代码（你没那个权限提交到线上代码 😂），所以不管是 APM 还是无痕埋点都是通过 Hook 的方式。</p><p>面向切面程序设计（Aspect-oriented Programming，AOP）是计算机科学中的一种程序设计范型，将<strong>横切关注点</strong>与业务主体进一步分离，以提高程序代码的模块化程度。在不修改源代码的情况下给程序动态增加功能。其核心思想是将业务逻辑（核心关注点，系统主要功能）与公共功能（横切关注点，比如日志系统）进行分离，降低复杂性，保持系统模块化程度、可维护性、可重用性。常被用在日志系统、性能统计、安全控制、事务处理、异常处理等场景下。</p><p>在 iOS 中 AOP 的实现是基于 Runtime 机制，目前由3种方式：Method Swizzling、NSProxy、FishHook（主要用用于 hook c 代码）。</p><p>文章上面 <a href="https://segmentfault.com/a/1190000040277799#network-2.1">2.1</a> 讨论了满足大多数的需求的场景，NSURLProtocol 监控了 NSURLConnection、NSURLSession 的网络请求，自身代理后可以发起网络请求并得到诸如请求开始时间、请求结束时间、header 信息等，但是无法得到非常详细的网络性能数据，比如 DNS 开始解析时间、DNS 解析用了多久、reponse 开始返回的时间、返回了多久等。 iOS10 之后 NSURLSessionTaskDelegate 增加了一个代理方法 <code>- (void)URLSession:(NSURLSession *)session task:(NSURLSessionTask *)task didFinishCollectingMetrics:(NSURLSessionTaskMetrics *)metrics API_AVAILABLE(macosx(10.12), ios(10.0), watchos(3.0), tvos(10.0));</code>，可以获取到精确的各项网络数据。但是具有兼容性。文章上面 <a href="https://segmentfault.com/a/1190000040277799#network-2.2">2.2</a> 讨论了从 Webkit 源码中得到的信息，通过私有方法 <code>_setCollectsTimingData:</code> 、<code>_timingData</code> 可以获取到 TimingData。</p><p>但是如果需要监全部的网络请求就不能满足需求了，查阅资料后发现了阿里百川有 APM 的解决方案，于是有了方案3，对于网络监控需要做如下的处理</p><p><img src="https://segmentfault.com/img/bVbIOh5"></p><p>可能对于 CFNetwork 比较陌生，可以看一下 CFNetwork 的层级和简单用法<br><img src="https://segmentfault.com/img/bVbIOiA"></p><p>CFNetwork 的基础是 CFSocket 和 CFStream。</p><p>CFSocket：Socket 是网络通信的底层基础，可以让2个 socket 端口互发数据，iOS 中最常用的 socket 抽象是 BSD socket。而 CFSocket 是 BSD socket 的 OC 包装，几乎实现了所有的 BSD 功能，此外加入了 RunLoop。</p><p>CFStream：提供了与设备无关的读写数据方法，使用它可以为内存、文件、网络（使用 socket）的数据建立流，使用 stream 可以不必将所有数据写入到内存中。CFStream 提供 API 对2种 CFType 对象提供抽象：CFReadStream、CFWriteStream。同时也是 CFHTTP、CFFTP 的基础。</p><p>简单 Demo</p><p>- (void)testCFNetwork<br>{<br>    CFURLRef urlRef = CFURLCreateWithString(kCFAllocatorDefault, CFSTR(“<a href="https://httpbin.org/get&quot;">https://httpbin.org/get&quot;</a>), NULL);<br>    CFHTTPMessageRef httpMessageRef = CFHTTPMessageCreateRequest(kCFAllocatorDefault, CFSTR(“GET”), urlRef, kCFHTTPVersion1_1);<br>    CFRelease(urlRef);</p><pre><code>CFReadStreamRef readStream = CFReadStreamCreateForHTTPRequest(kCFAllocatorDefault, httpMessageRef);CFRelease(httpMessageRef);CFReadStreamScheduleWithRunLoop(readStream, CFRunLoopGetCurrent(), kCFRunLoopCommonModes);CFOptionFlags eventFlags = (kCFStreamEventHasBytesAvailable | kCFStreamEventErrorOccurred | kCFStreamEventEndEncountered);CFStreamClientContext context = &#123;    0,    NULL,    NULL,    NULL,   NULL&#125; ;// Assigns a client to a stream, which receives callbacks when certain events occur.CFReadStreamSetClient(readStream, eventFlags, CFNetworkRequestCallback, &amp;context);// Opens a stream for reading.CFReadStreamOpen(readStream);</code></pre><p>}<br>// callback<br>void CFNetworkRequestCallback (CFReadStreamRef _Null_unspecified stream, CFStreamEventType type, void * _Null_unspecified clientCallBackInfo) {<br>    CFMutableDataRef responseBytes = CFDataCreateMutable(kCFAllocatorDefault, 0);<br>    CFIndex numberOfBytesRead = 0;<br>    do {<br>        UInt8 buffer[2014];<br>        numberOfBytesRead = CFReadStreamRead(stream, buffer, sizeof(buffer));<br>        if (numberOfBytesRead &gt; 0) {<br>            CFDataAppendBytes(responseBytes, buffer, numberOfBytesRead);<br>        }<br>    } while (numberOfBytesRead &gt; 0);</p><pre><code>CFHTTPMessageRef response = (CFHTTPMessageRef)CFReadStreamCopyProperty(stream, kCFStreamPropertyHTTPResponseHeader);if (responseBytes) &#123;    if (response) &#123;        CFHTTPMessageSetBody(response, responseBytes);    &#125;    CFRelease(responseBytes);&#125;// close and cleanupCFReadStreamClose(stream);CFReadStreamUnscheduleFromRunLoop(stream, CFRunLoopGetCurrent(), kCFRunLoopCommonModes);CFRelease(stream);// print responseif (response) &#123;    CFDataRef reponseBodyData = CFHTTPMessageCopyBody(response);    CFRelease(response);    printResponseData(reponseBodyData);    CFRelease(reponseBodyData);&#125;</code></pre><p>}</p><p>void printResponseData (CFDataRef responseData) {<br>    CFIndex dataLength = CFDataGetLength(responseData);<br>    UInt8 *bytes = (UInt8 *)malloc(dataLength);<br>    CFDataGetBytes(responseData, CFRangeMake(0, CFDataGetLength(responseData)), bytes);<br>    CFStringRef responseString = CFStringCreateWithBytes(kCFAllocatorDefault, bytes, dataLength, kCFStringEncodingUTF8, TRUE);<br>    CFShow(responseString);<br>    CFRelease(responseString);<br>    free(bytes);<br>}<br>// console<br>{<br>  “args”: {},<br>  “headers”: {<br>    “Host”: “httpbin.org”,<br>    “User-Agent”: “Test/1 CFNetwork/1125.2 Darwin/19.3.0”,<br>    “X-Amzn-Trace-Id”: “Root=1-5e8980d0-581f3f44724c7140614c2564”<br>  },<br>  “origin”: “183.159.122.102”,<br>  “url”: “<a href="https://httpbin.org/get&quot;">https://httpbin.org/get&quot;</a><br>}</p><p>我们知道 NSURLSession、NSURLConnection、CFNetwork 的使用都需要调用一堆方法进行设置然后需要设置代理对象，实现代理方法。所以针对这种情况进行监控首先想到的是使用 runtime hook 掉方法层级。但是针对设置的代理对象的代理方法没办法 hook，因为不知道代理对象是哪个类。所以想办法可以 hook 设置代理对象这个步骤，将代理对象替换成我们设计好的某个类，然后让这个类去实现 NSURLConnection、NSURLSession、CFNetwork 相关的代理方法。然后在这些方法的内部都去调用一下原代理对象的方法实现。所以我们的需求得以满足，我们在相应的方法里面可以拿到监控数据，比如请求开始时间、结束时间、状态码、内容大小等。</p><p>NSURLSession、NSURLConnection hook 如下。</p><p><img src="https://segmentfault.com/img/bVbIOiI"></p><p><img src="https://segmentfault.com/img/bVbIOiT"></p><p>业界有 APM 针对 CFNetwork 的方案，整理描述下：</p><p>CFNetwork 是 c 语言实现的，要对 c 代码进行 hook 需要使用 Dynamic Loader Hook 库 - <a href="https://link.segmentfault.com/?enc=tcKJVyEvs7dexHInMoDCyw==.U6nR6eU3JMfqS5fGvu0zKDtIo2B6MLKTgyx0LvekE3gw4lJm88QrCDo9LH1aCMnC">fishhook</a>。</p><blockquote><p><strong>Dynamic Loader</strong>（dyld）通过更新 <strong>Mach-O</strong> 文件中保存的指针的方法来绑定符号。借用它可以在 <strong>Runtime</strong> 修改 <strong>C</strong> 函数调用的函数指针。<strong>fishhook</strong> 的实现原理：遍历 <code>__DATA segment</code> 里面 <code>__nl_symbol_ptr</code> 、<code>__la_symbol_ptr</code> 两个 section 里面的符号，通过 Indirect Symbol Table、Symbol Table 和 String Table 的配合，找到自己要替换的函数，达到 hook 的目的。</p><p>/* Returns the number of bytes read, or -1 if an error occurs preventing any</p><p>bytes from being read, or 0 if the stream’s end was encountered.</p><p>It is an error to try and read from a stream that hasn’t been opened first.</p><p>This call will block until at least one byte is available; it will NOT block</p><p>until the entire buffer can be filled. To avoid blocking, either poll using</p><p>CFReadStreamHasBytesAvailable() or use the run loop and listen for the</p><p>kCFStreamEventHasBytesAvailable event for notification of data available. */</p><p>CF_EXPORT</p><p>CFIndex CFReadStreamRead(CFReadStreamRef <strong>_Null_unspecified</strong> stream, UInt8 * <strong>_Null_unspecified</strong> buffer, CFIndex bufferLength);</p></blockquote><p>CFNetwork 使用 CFReadStreamRef 来传递数据，使用回调函数的形式来接受服务器的响应。当回调函数受到</p><p>具体步骤及其关键代码如下，以 NSURLConnection 举例</p><ul><li><p>因为要 Hook 挺多地方，所以写一个 method swizzling 的工具类</p><p>  #import &lt;Foundation/Foundation.h&gt;</p><p>  NS_ASSUME_NONNULL_BEGIN</p><p>  @interface NSObject (hook)</p><p>  /**<br>   hook对象方法</p><p>   @param originalSelector 需要hook的原始对象方法<br>   @param swizzledSelector 需要替换的对象方法<br>   */</p><ul><li><p>(void)apm_swizzleMethod:(SEL)originalSelector swizzledSelector:(SEL)swizzledSelector;</p><p>/**<br>hook类方法</p><p>@param originalSelector 需要hook的原始类方法<br>@param swizzledSelector 需要替换的类方法<br>*/</p></li><li><p>(void)apm_swizzleClassMethod:(SEL)originalSelector swizzledSelector:(SEL)swizzledSelector;</p><p>@end</p><p>NS_ASSUME_NONNULL_END</p></li><li><p>(void)apm_swizzleMethod:(SEL)originalSelector swizzledSelector:(SEL)swizzledSelector<br>{<br>  class_swizzleInstanceMethod(self, originalSelector, swizzledSelector);<br>}</p></li><li><p>(void)apm_swizzleClassMethod:(SEL)originalSelector swizzledSelector:(SEL)swizzledSelector<br>{<br>  //类方法实际上是储存在类对象的类(即元类)中，即类方法相当于元类的实例方法,所以只需要把元类传入，其他逻辑和交互实例方法一样。<br>  Class class2 = object_getClass(self);<br>  class_swizzleInstanceMethod(class2, originalSelector, swizzledSelector);<br>}</p><p>void class_swizzleInstanceMethod(Class class, SEL originalSEL, SEL replacementSEL)<br>{<br>  Method originMethod = class_getInstanceMethod(class, originalSEL);<br>  Method replaceMethod = class_getInstanceMethod(class, replacementSEL);</p><p>  if(class_addMethod(class, originalSEL, method_getImplementation(replaceMethod),method_getTypeEncoding(replaceMethod)))<br>  {</p><pre><code>  class\_replaceMethod(class,replacementSEL, method\_getImplementation(originMethod), method\_getTypeEncoding(originMethod));</code></pre><p>  }else {</p><pre><code>  method\_exchangeImplementations(originMethod, replaceMethod);</code></pre><p>  }<br>}</p></li></ul></li><li><p>建立一个继承自 NSProxy 抽象类的类，实现相应方法。</p><p>  #import &lt;Foundation/Foundation.h&gt;</p><p>  NS_ASSUME_NONNULL_BEGIN</p><p>  // 为 NSURLConnection、NSURLSession、CFNetwork 代理设置代理转发<br>  @interface NetworkDelegateProxy : NSProxy</p><ul><li><p>(instancetype)setProxyForObject:(id)originalTarget withNewDelegate:(id)newDelegate;</p><p>@end</p><p>NS_ASSUME_NONNULL_END</p><p>// .m<br>@interface NetworkDelegateProxy () {<br>  id _originalTarget;<br>  id _NewDelegate;<br>}</p><p>@end</p><p>@implementation NetworkDelegateProxy</p><p>#pragma mark - life cycle</p></li><li><p>(instancetype)sharedInstance {<br>  static NetworkDelegateProxy *_sharedInstance = nil;</p><p>  static dispatch_once_t onceToken;</p><p>  dispatch_once(&amp;onceToken, ^{</p><pre><code>  \_sharedInstance = \[NetworkDelegateProxy alloc\];</code></pre><p>  });</p><p>  return _sharedInstance;<br>}</p><p>#pragma mark - public Method</p></li><li><p>(instancetype)setProxyForObject:(id)originalTarget withNewDelegate:(id)newDelegate<br>{<br>  NetworkDelegateProxy *instance = [NetworkDelegateProxy sharedInstance];<br>  instance-&gt;_originalTarget = originalTarget;<br>  instance-&gt;_NewDelegate = newDelegate;<br>  return instance;<br>}</p></li></ul><ul><li><p>(void)forwardInvocation:(NSInvocation *)invocation<br>{<br>  if ([_originalTarget respondsToSelector:invocation.selector]) {</p><pre><code>  \[invocation invokeWithTarget:\_originalTarget\];  \[((NSURLSessionAndConnectionImplementor \*)\_NewDelegate) invoke:invocation\];</code></pre><p>  }<br>}</p></li><li><p>(nullable NSMethodSignature *)methodSignatureForSelector:(SEL)sel<br>{<br>  return [_originalTarget methodSignatureForSelector:sel];<br>}</p><p>@end</p></li></ul></li><li><p>创建一个对象，实现 NSURLConnection、NSURLSession、NSIuputStream 代理方法</p><p>  // NetworkImplementor.m</p><p>  #pragma mark-NSURLConnectionDelegate</p><ul><li><p>(void)connection:(NSURLConnection *)connection didFailWithError:(NSError *)error {<br>  NSLog(@”%s”, __func__);<br>}</p></li><li><p>(nullable NSURLRequest *)connection:(NSURLConnection *)connection willSendRequest:(NSURLRequest *)request redirectResponse:(nullable NSURLResponse *)response {<br>  NSLog(@”%s”, __func__);<br>  return request;<br>}</p><p>#pragma mark-NSURLConnectionDataDelegate</p></li><li><p>(void)connection:(NSURLConnection *)connection didReceiveResponse:(NSURLResponse *)response {<br>  NSLog(@”%s”, __func__);<br>}</p></li><li><p>(void)connection:(NSURLConnection *)connection didReceiveData:(NSData *)data {<br> NSLog(@”%s”, __func__);<br>}</p></li><li><p>(void)connection:(NSURLConnection *)connection   didSendBodyData:(NSInteger)bytesWritten<br>totalBytesWritten:(NSInteger)totalBytesWritten<br>totalBytesExpectedToWrite:(NSInteger)totalBytesExpectedToWrite {<br>  NSLog(@”%s”, __func__);<br>}</p></li><li><p>(void)connectionDidFinishLoading:(NSURLConnection *)connection {<br>  NSLog(@”%s”, __func__);<br>}</p><p>#pragma mark-NSURLConnectionDownloadDelegate</p></li><li><p>(void)connection:(NSURLConnection *)connection didWriteData:(long long)bytesWritten totalBytesWritten:(long long)totalBytesWritten expectedTotalBytes:(long long) expectedTotalBytes {<br>  NSLog(@”%s”, __func__);<br>}</p></li><li><p>(void)connectionDidResumeDownloading:(NSURLConnection *)connection totalBytesWritten:(long long)totalBytesWritten expectedTotalBytes:(long long) expectedTotalBytes {<br>  NSLog(@”%s”, __func__);<br>}</p></li><li><p>(void)connectionDidFinishDownloading:(NSURLConnection *)connection destinationURL:(NSURL *) destinationURL {<br>  NSLog(@”%s”, __func__);<br>}<br>// 根据需求自己去写需要监控的数据项</p></li></ul></li><li><p>给 NSURLConnection 添加 Category，专门设置 hook 代理对象、hook NSURLConnection 对象方法</p><p>  // NSURLConnection+Monitor.m<br>  @implementation NSURLConnection (Monitor)</p><ul><li>(void)load<br>{<br>  static dispatch_once_t onceToken;<br>  dispatch_once(&amp;onceToken, ^{<pre><code>  @autoreleasepool &#123;      \[\[self class\] apm\_swizzleMethod:@selector(apm\_initWithRequest:delegate:) swizzledSelector:@selector(initWithRequest: delegate:)\];  &#125;</code></pre>  });<br>}</li></ul><ul><li><p>(_Nonnull instancetype)apm_initWithRequest:(NSURLRequest *)request delegate:(nullable id)delegate<br>{<br>  /*</p><ol><li><p>在设置 Delegate 的时候替换 delegate。</p></li><li><p>因为要在每个代理方法里面，监控数据，所以需要将代理方法都 hook 下</p></li><li><p>在原代理方法执行的时候，让新的代理对象里面，去执行方法的转发，<br>*/<br>NSString *traceId = @”traceId”;<br>NSMutableURLRequest *rq = [request mutableCopy];<br>NSString *preTraceId = [request.allHTTPHeaderFields valueForKey:@”head_key_traceid”];<br>if (preTraceId) {<br>// 调用 hook 之前的初始化方法，返回 NSURLConnection<br>return [self apm_initWithRequest:rq delegate:delegate];<br>} else {<br>[rq setValue:traceId forHTTPHeaderField:@”head_key_traceid”];</p><p>NSURLSessionAndConnectionImplementor *mockDelegate = [NSURLSessionAndConnectionImplementor new];<br>[self registerDelegateMethod:@”connection:didFailWithError:” originalDelegate:delegate newDelegate:mockDelegate flag:”v@:@@”];</p><p>[self registerDelegateMethod:@”connection:didReceiveResponse:” originalDelegate:delegate newDelegate:mockDelegate flag:”v@:@@”];<br>[self registerDelegateMethod:@”connection:didReceiveData:” originalDelegate:delegate newDelegate:mockDelegate flag:”v@:@@”];<br>[self registerDelegateMethod:@”connection:didFailWithError:” originalDelegate:delegate newDelegate:mockDelegate flag:”v@:@@”];</p><p>[self registerDelegateMethod:@”connectionDidFinishLoading:” originalDelegate:delegate newDelegate:mockDelegate flag:”v@:@”];<br>[self registerDelegateMethod:@”connection:willSendRequest:redirectResponse:” originalDelegate:delegate newDelegate:mockDelegate flag:”@@:@@”];<br>delegate = [NetworkDelegateProxy setProxyForObject:delegate withNewDelegate:mockDelegate];</p><p>// 调用 hook 之前的初始化方法，返回 NSURLConnection<br>return [self apm_initWithRequest:rq delegate:delegate];<br>}<br>}</p></li></ol></li><li><p>(void)registerDelegateMethod:(NSString *)methodName originalDelegate:(id&lt;NSURLConnectionDelegate&gt;)originalDelegate newDelegate:(NSURLSessionAndConnectionImplementor *)newDelegate flag:(const char *)flag<br>{<br>  if ([originalDelegate respondsToSelector:NSSelectorFromString(methodName)]) {</p><pre><code>  IMP originalMethodImp = class\_getMethodImplementation(\[originalDelegate class\], NSSelectorFromString(methodName));  IMP newMethodImp = class\_getMethodImplementation(\[newDelegate class\], NSSelectorFromString(methodName));  if (originalMethodImp != newMethodImp) &#123;      \[newDelegate registerSelector: methodName\];      NSLog(@&quot;&quot;);  &#125;</code></pre><p>  } else {</p><pre><code>  class\_addMethod(\[originalDelegate class\], NSSelectorFromString(methodName), class\_getMethodImplementation(\[newDelegate class\], NSSelectorFromString(methodName)), flag);</code></pre><p>  }<br>}</p><p>@end</p></li></ul></li></ul><p>这样下来就是可以监控到网络信息了，然后将数据交给数据上报 SDK，按照下发的数据上报策略去上报数据。</p><h5 id="2-3-2-方法二"><a href="#2-3-2-方法二" class="headerlink" title="2.3.2 方法二"></a>2.3.2 方法二</h5><p>其实，针对上述的需求还有另一种方法一样可以达到目的，那就是 <strong>isa swizzling</strong>。</p><p>顺道说一句，上面针对 NSURLConnection、NSURLSession、NSInputStream 代理对象的 hook 之后，利用 NSProxy 实现代理对象方法的转发，有另一种方法可以实现，那就是 <strong>isa swizzling</strong>。</p><ul><li><p>Method swizzling 原理</p><p>  struct old_method {</p><pre><code>  SEL method\_name;  char \*method\_types;  IMP method\_imp;</code></pre><p>  };</p></li></ul><p><img src="https://segmentfault.com/img/bVbIOi3"></p><p>method swizzling 改进版如下</p><p>Method originalMethod = class_getInstanceMethod(aClass, aSEL);<br>IMP originalIMP = method_getImplementation(originalMethod);<br>char *cd = method_getTypeEncoding(originalMethod);<br>IMP newIMP = imp_implementationWithBlock(^(id self) {<br>  void (*tmp)(id self, SEL _cmd) = originalIMP;<br>  tmp(self, aSEL);<br>});<br>class_replaceMethod(aClass, aSEL, newIMP, cd);</p><ul><li><p>isa swizzling</p><p>  /// Represents an instance of a class.<br>  struct objc_object {</p><pre><code>  Class \_Nonnull isa  OBJC\_ISA\_AVAILABILITY;</code></pre><p>  };</p><p>  /// A pointer to an instance of a class.<br>  typedef struct objc_object *id;</p></li></ul><p><img src="https://segmentfault.com/img/bVbIOjh"></p><p>我们来分析一下为什么修改 <code>isa</code> 可以实现目的呢？</p><ol><li> 写 APM 监控的人没办法确定业务代码</li><li> 不可能为了方便监控 APM，写某些类，让业务线开发者别使用系统 NSURLSession、NSURLConnection 类</li></ol><p>想想 KVO 的实现原理？结合上面的图</p><ul><li>  创建监控对象子类</li><li>  重写子类中属性的 getter、seeter</li><li>  将监控对象的 isa 指针指向新创建的子类</li><li>  在子类的 getter、setter 中拦截值的变化，通知监控对象值的变化</li><li>  监控完之后将监控对象的 isa 还原回去</li></ul><p>按照这个思路，我们也可以对 NSURLConnection、NSURLSession 的 load 方法中动态创建子类，在子类中重写方法，比如 <code>- (**nullable** **instancetype**)initWithRequest:(NSURLRequest *)request delegate:(**nullable** **id**)delegate startImmediately:(**BOOL**)startImmediately;</code> ，然后将 NSURLSession、NSURLConnection 的 isa 指向动态创建的子类。在这些方法处理完之后还原本身的 isa 指针。</p><p>不过 isa swizzling 针对的还是 method swizzling，代理对象不确定，还是需要 NSProxy 进行动态处理。</p><p>至于如何修改 isa，我写一个简单的 Demo 来模拟 KVO</p><p>- (void)lbpKVO_addObserver:(NSObject *)observer forKeyPath:(NSString *)keyPath options:(NSKeyValueObservingOptions)options context:(nullable void *)context {<br>    //生成自定义的名称<br>    NSString *className = NSStringFromClass(self.class);<br>    NSString *currentClassName = [@”LBPKVONotifying_“ stringByAppendingString:className];<br>    //1. runtime 生成类<br>    Class myclass = objc_allocateClassPair(self.class, [currentClassName UTF8String], 0);<br>    // 生成后不能马上使用，必须先注册<br>    objc_registerClassPair(myclass);</p><pre><code>//2. 重写 setter 方法class\_addMethod(myclass,@selector(say) , (IMP)say, &quot;v@:@&quot;);</code></pre><p>//    class_addMethod(myclass,@selector(setName:) , (IMP)setName, “v@:@”);<br>    //3. 修改 isa<br>    object_setClass(self, myclass);</p><pre><code>//4. 将观察者保存到当前对象里面objc\_setAssociatedObject(self, &quot;observer&quot;, observer, OBJC\_ASSOCIATION\_ASSIGN);//5. 将传递的上下文绑定到当前对象里面objc\_setAssociatedObject(self, &quot;context&quot;, (\_\_bridge id \_Nullable)(context), OBJC\_ASSOCIATION\_RETAIN);</code></pre><p>}</p><p>void say(id self, SEL _cmd)<br>{<br>   // 调用父类方法一<br>    struct objc_super superclass = {self, [self superclass]};<br>    ((void(*)(struct objc_super *,SEL))objc_msgSendSuper)(&amp;superclass,@selector(say));<br>    NSLog(@”%s”, __func__);<br>// 调用父类方法二<br>//    Class class = [self class];<br>//    object_setClass(self, class_getSuperclass(class));<br>//    objc_msgSend(self, @selector(say));<br>}</p><p>void setName (id self, SEL _cmd, NSString *name) {<br>    NSLog(@”come here”);<br>    //先切换到当前类的父类，然后发送消息 setName，然后切换当前子类<br>    //1. 切换到父类<br>    Class class = [self class];<br>    object_setClass(self, class_getSuperclass(class));<br>    //2. 调用父类的 setName 方法<br>    objc_msgSend(self, @selector(setName:), name);</p><pre><code>//3. 调用观察id observer = objc\_getAssociatedObject(self, &quot;observer&quot;);id context = objc\_getAssociatedObject(self, &quot;context&quot;);if (observer) &#123;    objc\_msgSend(observer, @selector(observeValueForKeyPath:ofObject:change:context:), @&quot;name&quot;, self, @&#123;@&quot;new&quot;: name, @&quot;kind&quot;: @1 &#125; , context);&#125;//4. 改回子类object\_setClass(self, class);</code></pre><p>}</p><p>@end</p><h4 id="2-4-方案四：监控-App-常见网络请求"><a href="#2-4-方案四：监控-App-常见网络请求" class="headerlink" title="2.4 方案四：监控 App 常见网络请求"></a>2.4 方案四：监控 App 常见网络请求</h4><p>本着成本的原因，由于现在大多数的项目的网络能力都是通过 <a href="https://link.segmentfault.com/?enc=MYj1ggNH/meF+oxXiYJbZg==.IYz8wJ/KSEXObkRzTOxLYjdN5RNFlQyunNtJO1Se9wGa3x76x0tMSjB/U+kVQy7b">AFNetworking</a> 完成的，所以本文的网络监控可以快速完成。</p><p>AFNetworking 在发起网络的时候会有相应的通知。<code>AFNetworkingTaskDidResumeNotification</code> 和 <code>AFNetworkingTaskDidCompleteNotification</code>。通过监听通知携带的参数获取网络情况信息。</p><p> self.didResumeObserver = [[NSNotificationCenter defaultCenter] addObserverForName:AFNetworkingTaskDidResumeNotification object:nil queue:self.queue usingBlock:^(NSNotification * _Nonnull note) {<br>    // 开始<br>    __strong __typeof(weakSelf)strongSelf = weakSelf;<br>    NSURLSessionTask *task = note.object;<br>    NSString *requestId = [[NSUUID UUID] UUIDString];<br>    task.apm_requestId = requestId;<br>    [strongSelf.networkRecoder recordStartRequestWithRequestID:requestId task:task];<br>}];</p><p>self.didCompleteObserver = [[NSNotificationCenter defaultCenter] addObserverForName:AFNetworkingTaskDidCompleteNotification object:nil queue:self.queue usingBlock:^(NSNotification * _Nonnull note) {</p><pre><code>\_\_strong \_\_typeof(weakSelf)strongSelf = weakSelf;NSError \*error = note.userInfo\[AFNetworkingTaskDidCompleteErrorKey\];NSURLSessionTask \*task = note.object;if (!error) &#123;    // 成功    \[strongSelf.networkRecoder recordFinishRequestWithRequestID:task.apmn\_requestId task:task\];&#125; else &#123;    // 失败    \[strongSelf.networkRecoder recordResponseErrorWithRequestID:task.apmn\_requestId task:task error:error\];&#125;</code></pre><p>}];</p><p>在 networkRecoder 的方法里面去组装数据，交给数据上报组件，等到合适的时机策略去上报。</p><p>因为网络是一个异步的过程，所以当网络请求开始的时候需要为每个网络设置唯一标识，等到网络请求完成后再根据每个请求的标识，判断该网络耗时多久、是否成功等。所以措施是为 <strong>NSURLSessionTask</strong> 添加分类，通过 runtime 增加一个属性，也就是唯一标识。</p><p>这里插一嘴，为 Category 命名、以及内部的属性和方法命名的时候需要注意下。假如不注意会怎么样呢？假如你要为 NSString 类增加身份证号码中间位数隐藏的功能，那么写代码久了的老司机 A，为 NSString 增加了一个方法名，叫做 getMaskedIdCardNumber，但是他的需求是从 [9, 12] 这4位字符串隐藏掉。过了几天同事 B 也遇到了类似的需求，他也是一位老司机，为 NSString 增加了一个也叫 getMaskedIdCardNumber 的方法，但是他的需求是从 [8, 11] 这4位字符串隐藏，但是他引入工程后发现输出并不符合预期，为该方法写的单测没通过，他以为自己写错了截取方法，检查了几遍才发现工程引入了另一个 NSString 分类，里面的方法同名 😂 真坑。</p><p>下面的例子是 SDK，但是日常开发也是一样。</p><ul><li>  Category 类名：建议按照当前 SDK 名称的简写作为前缀，再加下划线，再加当前分类的功能，也就是<code>类名+SDK名称简写_功能名称</code>。比如当前 SDK 叫 JuhuaSuanAPM，那么该 NSURLSessionTask Category 名称就叫做 <code>NSURLSessionTask+JuHuaSuanAPM_NetworkMonitor.h</code></li><li>  Category 属性名：建议按照当前 SDK 名称的简写作为前缀，再加下划线，再加属性名，也就是<code>SDK名称简写_属性名称</code>。比如 JuhuaSuanAPM_requestId`</li><li>  Category 方法名：建议按照当前 SDK 名称的简写作为前缀，再加下划线，再加方法名，也就是<code>SDK名称简写_方法名称</code>。比如 <code>-(BOOL)JuhuaSuanAPM__isGzippedData</code></li></ul><p>例子如下：</p><p>#import &lt;Foundation/Foundation.h&gt;</p><p>@interface NSURLSessionTask (JuhuaSuanAPM_NetworkMonitor)</p><p>@property (nonatomic, copy) NSString* JuhuaSuanAPM_requestId;</p><p>@end</p><p>#import “NSURLSessionTask+JuHuaSuanAPM_NetworkMonitor.h”<br>#import &lt;objc/runtime.h&gt;</p><p>@implementation NSURLSessionTask (JuHuaSuanAPM_NetworkMonitor)</p><ul><li><p>(NSString*)JuhuaSuanAPM_requestId<br>{<br>  return objc_getAssociatedObject(self, _cmd);<br>}</p></li><li><p>(void)setJuhuaSuanAPM_requestId:(NSString*)requestId<br>{<br>  objc_setAssociatedObject(self, @selector(JuhuaSuanAPM_requestId), requestId, OBJC_ASSOCIATION_COPY_NONATOMIC);<br>}<br>@end</p></li></ul><h4 id="2-5-iOS-流量监控"><a href="#2-5-iOS-流量监控" class="headerlink" title="2.5 iOS 流量监控"></a>2.5 iOS 流量监控</h4><h5 id="2-5-1-HTTP-请求、响应数据结构"><a href="#2-5-1-HTTP-请求、响应数据结构" class="headerlink" title="2.5.1 HTTP 请求、响应数据结构"></a>2.5.1 HTTP 请求、响应数据结构</h5><p>HTTP 请求报文结构</p><p><img src="https://segmentfault.com/img/bVbIOjv"></p><p>响应报文的结构<br><img src="https://segmentfault.com/img/bVbIOjA"></p><ol><li> HTTP 报文是格式化的数据块，每条报文由三部分组成：对报文进行描述的起始行、包含属性的首部块、以及可选的包含数据的主体部分。</li><li> 起始行和手部就是由行分隔符的 ASCII 文本，每行都以一个由2个字符组成的行终止序列作为结束（包括一个回车符、一个换行符）</li><li> 实体的主体或者报文的主体是一个可选的数据块。与起始行和首部不同的是，主体中可以包含文本或者二进制数据，也可以为空。</li><li> HTTP 首部（也就是 Headers）总是应该以一个空行结束，即使没有实体部分。浏览器发送了一个空白行来通知服务器，它已经结束了该头信息的发送。</li></ol><p>请求报文的格式</p><p>&lt;method&gt; &lt;request-URI&gt; &lt;version&gt;<br>&lt;headers&gt;</p><p>&lt;entity-body&gt;</p><p>响应报文的格式</p><p><version> <status> <reason-phrase><br><headers></p><entity-body><p>下图是打开 Chrome 查看极课时间网页的请求信息。包括响应行、响应头、响应体等信息。</p><p><img src="https://segmentfault.com/img/bVbIOjS"></p><p>下图是在终端使用 <code>curl</code> 查看一个完整的请求和响应数据<br><img src="https://segmentfault.com/img/bVbIOj9"></p><p>我们都知道在 HTTP 通信中，响应数据会使用 gzip 或其他压缩方式压缩，用 NSURLProtocol 等方案监听，用 NSData 类型去计算分析流量等会造成数据的不精确，因为正常一个 HTTP 响应体的内容是使用 gzip 或其他压缩方式压缩的，所以使用 NSData 会偏大。</p><h5 id="2-5-2-问题"><a href="#2-5-2-问题" class="headerlink" title="2.5.2 问题"></a>2.5.2 问题</h5><ol><li><p>Request 和 Response 不一定成对存在</p><p> 比如网络断开、App 突然 Crash 等，所以 Request 和 Response 监控后不应该记录在一条记录里</p></li><li><p>请求流量计算方式不精确</p><p> 主要原因有：</p><ul><li>  监控技术方案忽略了请求头和请求行部分的数据大小</li><li>  监控技术方案忽略了 Cookie 部分的数据大小</li><li>  监控技术方案在对请求体大小计算的时候直接使用 <code>HTTPBody.length</code>，导致不够精确</li></ul></li><li><p>响应流量计算方式不精确</p><p> 主要原因有：</p><ul><li>  监控技术方案忽略了响应头和响应行部分的数据大小</li><li>  监控技术方案在对 body 部分的字节大小计算，因采用 <code>exceptedContentLength</code> 导致不够准确</li><li>  监控技术方案忽略了响应体使用 gzip 压缩。真正的网络通信过程中，客户端在发起请求的请求头中 <code>Accept-Encoding</code> 字段代表客户端支持的数据压缩方式（表明客户端可以正常使用数据时支持的压缩方法），同样服务端根据客户端想要的压缩方式、服务端当前支持的压缩方式，最后处理数据，在响应头中<code>Content-Encoding</code> 字段表示当前服务器采用了什么压缩方式。</li></ul></li></ol><h5 id="2-5-3-技术实现"><a href="#2-5-3-技术实现" class="headerlink" title="2.5.3 技术实现"></a>2.5.3 技术实现</h5><p>第五部分讲了网络拦截的各种原理和技术方案，这里拿 NSURLProtocol 来说实现流量监控（Hook 的方式）。从上述知道了我们需要什么样的，那么就逐步实现吧。</p><h6 id="2-5-3-1-Request-部分"><a href="#2-5-3-1-Request-部分" class="headerlink" title="2.5.3.1 Request 部分"></a>2.5.3.1 Request 部分</h6><ol><li><p> 先利用网络监控方案将 NSURLProtocol 管理 App 的各种网络请求</p></li><li><p>在各个方法内部记录各项所需参数（NSURLProtocol 不能分析请求握手、挥手等数据大小和时间消耗，不过对于正常情况的接口流量分析足够了，最底层需要 Socket 层）</p><p> @property(nonatomic, strong) NSURLConnection *internalConnection;<br> @property(nonatomic, strong) NSURLResponse *internalResponse;<br> @property(nonatomic, strong) NSMutableData *responseData;<br> @property (nonatomic, strong) NSURLRequest *internalRequest;</p></li></ol><p>- (void)startLoading<br>{<br>    NSMutableURLRequest *mutableRequest = [[self request] mutableCopy];<br>    self.internalConnection = [[NSURLConnection alloc] initWithRequest:mutableRequest delegate:self];<br>    self.internalRequest = self.request;<br>}</p><ul><li><p>(void)connection:(NSURLConnection *)connection didReceiveResponse:(NSURLResponse *)response<br>{<br>  [self.client URLProtocol:self didReceiveResponse:response cacheStoragePolicy:NSURLCacheStorageNotAllowed];<br>  self.internalResponse = response;<br>}</p></li><li><p>(void)connection:(NSURLConnection *)connection didReceiveData:(NSData *)data<br>{<br>  [self.responseData appendData:data];<br>  [self.client URLProtocol:self didLoadData:data];<br>}</p></li></ul><ol start="3"><li><p>Status Line 部分</p><p> NSURLResponse 没有 Status Line 等属性或者接口，HTTP Version 信息也没有，所以要想获取 Status Line 想办法转换到 CFNetwork 层试试看。发现有私有 API 可以实现。</p><p> <strong>思路：将 NSURLResponse 通过 <code>_CFURLResponse</code> 转换为 <code>CFTypeRef</code>，然后再将 <code>CFTypeRef</code> 转换为 <code>CFHTTPMessageRef</code>，再通过 <code>CFHTTPMessageCopyResponseStatusLine</code> 获取 <code>CFHTTPMessageRef</code> 的 Status Line 信息。</strong></p><p> 将读取 Status Line 的功能添加一个 NSURLResponse 的分类。</p><p> // NSURLResponse+apm_FetchStatusLineFromCFNetwork.h<br> #import &lt;Foundation/Foundation.h&gt;</p><p> NS_ASSUME_NONNULL_BEGIN</p><p> @interface NSURLResponse (apm_FetchStatusLineFromCFNetwork)</p><ul><li><p>(NSString *)apm_fetchStatusLineFromCFNetwork;</p><p>@end</p><p>NS_ASSUME_NONNULL_END</p><p>// NSURLResponse+apm_FetchStatusLineFromCFNetwork.m<br>#import “NSURLResponse+apm_FetchStatusLineFromCFNetwork.h”<br>#import &lt;dlfcn.h&gt;</p><p>#define SuppressPerformSelectorLeakWarning(Stuff) \<br>do { \<br>_Pragma(“clang diagnostic push”) \<br>_Pragma(“clang diagnostic ignored \“-Warc-performSelector-leaks\“”) \<br>Stuff; \<br>_Pragma(“clang diagnostic pop”) \<br>} while (0)</p><p>typedef CFHTTPMessageRef (*APMURLResponseFetchHTTPResponse)(CFURLRef response);</p><p>@implementation NSURLResponse (apm_FetchStatusLineFromCFNetwork)</p></li><li><p>(NSString *)apm_fetchStatusLineFromCFNetwork<br>{<br>NSString *statusLine = @””;<br>NSString *funcName = @”CFURLResponseGetHTTPResponse”;<br>APMURLResponseFetchHTTPResponse originalURLResponseFetchHTTPResponse = dlsym(RTLD_DEFAULT, [funcName UTF8String]);</p><p>SEL getSelector = NSSelectorFromString(@”_CFURLResponse”);<br>if ([self respondsToSelector:getSelector] &amp;&amp; NULL != originalURLResponseFetchHTTPResponse) {<br>  CFTypeRef cfResponse;<br>  SuppressPerformSelectorLeakWarning(</p><pre><code>  cfResponse = CFBridgingRetain(\[self performSelector:getSelector\]);</code></pre><p>  );<br>  if (NULL != cfResponse) {</p><pre><code>  CFHTTPMessageRef messageRef = originalURLResponseFetchHTTPResponse(cfResponse);  statusLine = (\_\_bridge\_transfer NSString \*)CFHTTPMessageCopyResponseStatusLine(messageRef);  CFRelease(cfResponse);</code></pre><p>  }<br>}<br>return statusLine;<br>}</p><p>@end</p></li></ul></li><li><p>将获取到的 Status Line 转换为 NSData，再计算大小</p><p> - (NSUInteger)apm_getLineLength {<br> NSString *statusLineString = @””;<br> if ([self isKindOfClass:[NSHTTPURLResponse class]]) {</p><pre><code> NSHTTPURLResponse \*httpResponse = (NSHTTPURLResponse \*)self; statusLineString = \[self apm\_fetchStatusLineFromCFNetwork\];</code></pre><p> }<br> NSData *lineData = [statusLineString dataUsingEncoding:NSUTF8StringEncoding];<br> return lineData.length;<br> }</p></li><li><p>Header 部分</p><p> <code>allHeaderFields</code> 获取到 NSDictionary，然后按照 <code>key: value</code> 拼接成字符串，然后转换成 NSData 计算大小</p><p> 注意：<code>key: value</code> key 后是有空格的，curl 或者 chrome Network 面板可以查看印证下。</p><p> - (NSUInteger)apm_getHeadersLength<br> {<br> NSUInteger headersLength = 0;<br> if ([self isKindOfClass:[NSHTTPURLResponse class]]) {</p><pre><code> NSHTTPURLResponse \*httpResponse = (NSHTTPURLResponse \*)self; NSDictionary \*headerFields = httpResponse.allHeaderFields; NSString \*headerString = @&quot;&quot;; for (NSString \*key in headerFields.allKeys) &#123;     headerString = \[headerStr stringByAppendingString:key\];     headheaderStringerStr = \[headerString stringByAppendingString:@&quot;: &quot;\];     if (\[headerFields objectForKey:key\]) &#123;         headerString = \[headerString stringByAppendingString:headerFields\[key\]\];     &#125;     headerString = \[headerString stringByAppendingString:@&quot;\\n&quot;\]; &#125; NSData \*headerData = \[headerString dataUsingEncoding:NSUTF8StringEncoding\]; headersLength = headerData.length;</code></pre><p> }<br> return headersLength;<br> }</p></li><li><p>Body 部分</p><p> Body 大小的计算不能直接使用 excepectedContentLength，官方文档说明了其不准确性，只可以作为参考。或者 <code>allHeaderFields</code> 中的 <code>Content-Length</code> 值也是不够准确的。</p><blockquote><p>/*!</p><p><strong>@abstract</strong> Returns the expected content length of the receiver.</p><p><strong>@discussion</strong> Some protocol implementations report a content length</p><p>as part of delivering load metadata, but not all protocols</p><p>guarantee the amount of data that will be delivered in actuality.</p><p>Hence, this method returns an expected amount. Clients should use</p><p>this value as an advisory, and should be prepared to deal with</p><p>either more or less data.</p><p><strong>@result</strong> The expected content length of the receiver, or -1 if</p><p>there is no expectation that can be arrived at regarding expected</p><p>content length.</p><p>*/</p><p><strong>@property</strong> (<strong>readonly</strong>) <strong>long</strong> <strong>long</strong> expectedContentLength;</p></blockquote><ul><li><p>  HTTP 1.1 版本规定，如果存在 <code>Transfer-Encoding: chunked</code>，则在 header 中不能有 <code>Content-Length</code>，有也会被忽视。</p></li><li><p>  在 HTTP 1.0及之前版本中，<code>content-length</code> 字段可有可无</p></li><li><p>在 HTTP 1.1及之后版本。如果是 <code>keep alive</code>，则 <code>Content-Length</code> 和 <code>chunked</code> 必然是二选一。若是非<code>keep alive</code>，则和 HTTP 1.0一样。<code>Content-Length</code> 可有可无。</p><p>什么是 <code>Transfer-Encoding: chunked</code></p><p>数据以一系列分块的形式进行发送 <code>Content-Length</code> 首部在这种情况下不被发送. 在每一个分块的开头需要添加当前分块的长度, 以十六进制的形式表示，后面紧跟着 <code>\r\n</code> , 之后是分块本身, 后面也是 <code>\r\n</code> ，终止块是一个常规的分块, 不同之处在于其长度为0.</p><p>我们之前拿 NSMutableData 记录了数据，所以我们可以在 <code>stopLoading</code> 方法中计算出 Body 大小。步骤如下：</p></li><li><p>在 <code>didReceiveData</code> 中不断添加 data</p><p>- (void)connection:(NSURLConnection *)connection didReceiveData:(NSData *)data<br>{<br>  [self.responseData appendData:data];<br>  [self.client URLProtocol:self didLoadData:data];<br>}</p></li></ul></li></ol><ul><li><p>在 <code>stopLoading</code> 方法中拿到 <code>allHeaderFields</code> 字典，获取 <code>Content-Encoding</code> key 的值，如果是 <strong>gzip</strong>，则在 <code>stopLoading</code> 中将 NSData 处理为 gzip 压缩后的数据，再计算大小。（gzip 相关功能可以使用这个<a href="https://link.segmentfault.com/?enc=wIhdNGkCq9yrL31VzIBqyA==.zCMe4OPXbL0XTEsiuqivL7za/Z0ccjxY3A8kt2LI7OCHkRWiBCvTwvl+50VVeo6Q">工具</a>）</p><p>  需要额外计算一个空白行的长度</p><p>  - (void)stopLoadi<br>  {</p><pre><code>  \[self.internalConnection cancel\];  HCTNetworkTrafficModel \*model = \[\[HCTNetworkTrafficModel alloc\] init\];  model.path = self.request.URL.path;  model.host = self.request.URL.host;  model.type = DMNetworkTrafficDataTypeResponse;  model.lineLength = \[self.internalResponse apm\_getStatusLineLength\];  model.headerLength = \[self.internalResponse apm\_getHeadersLength\];  model.emptyLineLength = \[self.internalResponse apm\_getEmptyLineLength\];  if (\[self.dm\_response isKindOfClass:\[NSHTTPURLResponse class\]\]) &#123;      NSHTTPURLResponse \*httpResponse = (NSHTTPURLResponse \*)self.dm\_response;      NSData \*data = self.dm\_data;      if (\[\[httpResponse.allHeaderFields objectForKey:@&quot;Content-Encoding&quot;\] isEqualToString:@&quot;gzip&quot;\]) &#123;          data = \[self.dm\_data gzippedData\];      &#125;      model.bodyLength = data.length;  &#125;  model.length = model.lineLength + model.headerLength + model.bodyLength + model.emptyLineLength;  NSDictionary \*networkTrafficDictionary = \[model convertToDictionary\];  \[\[HermesClient sharedInstance\] sendWithType:APMMonitorNetworkTrafficType meta:networkTrafficDictionary payload:nil\];</code></pre><p>  }</p></li></ul><h6 id="2-5-3-2-Resquest-部分"><a href="#2-5-3-2-Resquest-部分" class="headerlink" title="2.5.3.2 Resquest 部分"></a>2.5.3.2 Resquest 部分</h6><ol><li><p> 先利用网络监控方案将 NSURLProtocol 管理 App 的各种网络请求</p></li><li><p>在各个方法内部记录各项所需参数（NSURLProtocol 不能分析请求握手、挥手等数据大小和时间消耗，不过对于正常情况的接口流量分析足够了，最底层需要 Socket 层）</p><p> @property(nonatomic, strong) NSURLConnection *internalConnection;<br> @property(nonatomic, strong) NSURLResponse *internalResponse;<br> @property(nonatomic, strong) NSMutableData *responseData;<br> @property (nonatomic, strong) NSURLRequest *internalRequest;</p></li></ol><p>- (void)startLoading<br>{<br>    NSMutableURLRequest *mutableRequest = [[self request] mutableCopy];<br>    self.internalConnection = [[NSURLConnection alloc] initWithRequest:mutableRequest delegate:self];<br>    self.internalRequest = self.request;<br>}</p><ul><li><p>(void)connection:(NSURLConnection *)connection didReceiveResponse:(NSURLResponse *)response<br>{<br>  [self.client URLProtocol:self didReceiveResponse:response cacheStoragePolicy:NSURLCacheStorageNotAllowed];<br>  self.internalResponse = response;<br>}</p></li><li><p>(void)connection:(NSURLConnection *)connection didReceiveData:(NSData *)data<br>{<br>  [self.responseData appendData:data];<br>  [self.client URLProtocol:self didLoadData:data];<br>}</p></li></ul><ol start="3"><li><p>Status Line 部分</p><p> 对于 NSURLRequest 没有像 NSURLResponse 一样的方法找到 StatusLine。所以兜底方案是自己根据 Status Line 的结构，自己手动构造一个。结构为：<code>协议版本号+空格+状态码+空格+状态文本+换行</code></p><p> 为 NSURLRequest 添加一个专门获取 Status Line 的分类。</p><p> // NSURLResquest+apm_FetchStatusLineFromCFNetwork.m</p><ul><li>(NSUInteger)apm_fetchStatusLineLength<br>{<br>NSString *statusLineString = [NSString stringWithFormat:@”%@ %@ %@\n”, self.HTTPMethod, self.URL.path, @”HTTP/1.1”];<br>NSData *statusLineData = [statusLineString dataUsingEncoding:NSUTF8StringEncoding];<br>return statusLineData.length;<br>}</li></ul></li><li><p>Header 部分</p><p> 一个 HTTP 请求会先构建判断是否存在缓存，然后进行 DNS 域名解析以获取请求域名的服务器 IP 地址。如果请求协议是 HTTPS，那么还需要建立 TLS 连接。接下来就是利用 IP 地址和服务器建立 TCP 连接。连接建立之后，浏览器端会构建请求行、请求头等信息，并把和该域名相关的 Cookie 等数据附加到请求头中，然后向服务器发送构建的请求信息。</p><p> 所以一个网络监控不考虑 cookie 😂，借用王多鱼的一句话「那不完犊子了吗」。</p><p> 看过一些文章说 NSURLRequest 不能完整获取到请求头信息。其实问题不大， 几个信息获取不完全也没办法。衡量监控方案本身就是看接口在不同版本或者某些情况下数据消耗是否异常，WebView 资源请求是否过大，类似于控制变量法的思想。</p><p> 所以获取到 NSURLRequest 的 <code>allHeaderFields</code> 后，加上 cookie 信息，计算完整的 Header 大小</p><p> // NSURLResquest+apm_FetchHeaderWithCookies.m</p><ul><li><p>(NSUInteger)apm_fetchHeaderLengthWithCookie<br>{<br>  NSDictionary *headerFields = self.allHTTPHeaderFields;<br>  NSDictionary *cookiesHeader = [self apm_fetchCookies];</p><p>  if (cookiesHeader.count) {</p><pre><code>  NSMutableDictionary \*headerDictionaryWithCookies = \[NSMutableDictionary dictionaryWithDictionary:headerFields\];  \[headerDictionaryWithCookies addEntriesFromDictionary:cookiesHeader\];  headerFields = \[headerDictionaryWithCookies copy\];</code></pre><p>  }</p><p>  NSString *headerString = @””;</p><p>  for (NSString *key in headerFields.allKeys) {</p><pre><code>  headerString = \[headerString stringByAppendingString:key\];  headerString = \[headerString stringByAppendingString:@&quot;: &quot;\];  if (\[headerFields objectForKey:key\]) &#123;      headerString = \[headerString stringByAppendingString:headerFields\[key\]\];  &#125;  headerString = \[headerString stringByAppendingString:@&quot;\\n&quot;\];</code></pre><p>  }<br>  NSData *headerData = [headerString dataUsingEncoding:NSUTF8StringEncoding];<br>  headersLength = headerData.length;<br>  return headerString;<br>}</p></li><li><p>(NSDictionary *)apm_fetchCookies<br>{<br>  NSDictionary *cookiesHeaderDictionary;<br>  NSHTTPCookieStorage *cookieStorage = [NSHTTPCookieStorage sharedHTTPCookieStorage];<br>  NSArray&lt;NSHTTPCookie *&gt; *cookies = [cookieStorage cookiesForURL:self.URL];<br>  if (cookies.count) {</p><pre><code>  cookiesHeaderDictionary = \[NSHTTPCookie requestHeaderFieldsWithCookies:cookies\];</code></pre><p>  }<br>  return cookiesHeaderDictionary;<br>}</p></li></ul></li><li><p>Body 部分</p><p> NSURLConnection 的 <code>HTTPBody</code> 有可能获取不到，问题类似于 WebView 上 ajax 等情况。所以可以通过 <code>HTTPBodyStream</code> 读取 stream 来计算 body 大小.</p><p> - (NSUInteger)apm_fetchRequestBody<br> {</p><pre><code> NSDictionary \*headerFields = self.allHTTPHeaderFields; NSUInteger bodyLength = \[self.HTTPBody length\]; if (\[headerFields objectForKey:@&quot;Content-Encoding&quot;\]) &#123;     NSData \*bodyData;     if (self.HTTPBody == nil) &#123;         uint8\_t d\[1024\] = &#123;0&#125;;         NSInputStream \*stream = self.HTTPBodyStream;         NSMutableData \*data = \[\[NSMutableData alloc\] init\];         \[stream open\];         while (\[stream hasBytesAvailable\]) &#123;             NSInteger len = \[stream read:d maxLength:1024\];             if (len &gt; 0 &amp;&amp; stream.streamError == nil) &#123;                 \[data appendBytes:(void \*)d length:len\];             &#125;         &#125;         bodyData = \[data copy\];         \[stream close\];     &#125; else &#123;         bodyData = self.HTTPBody;     &#125;     bodyLength = \[\[bodyData gzippedData\] length\]; &#125; return bodyLength;</code></pre><p> }</p></li><li><p>在 <code>- (NSURLRequest *)connection:(NSURLConnection *)connection willSendRequest:(NSURLRequest *)request redirectResponse:(NSURLResponse *)response</code> 方法中将数据上报会在 <a href="https://link.segmentfault.com/?enc=eA1igiLRIyzxo5vMT8tLmQ==.AHKgASs3qLXjTEPL9wX33oDkOMD1zeDvkG6R9Jp1OXq1zlKsABF2yM0xNspPp96Eq/t1yL+R/k/H7p1hkZh50wttauZx5eHaAgCWyi7opMUOqkwqVl5SGWY4PwJtG5Ys">打造功能强大、灵活可配置的数据上报组件</a> 讲</p><p> -(NSURLRequest *)connection:(NSURLConnection *)connection willSendRequest:(NSURLRequest *)request redirectResponse:(NSURLResponse *)response<br> {</p><pre><code> if (response != nil) &#123;     self.internalResponse = response;     \[self.client URLProtocol:self wasRedirectedToRequest:request redirectResponse:response\]; &#125; HCTNetworkTrafficModel \*model = \[\[HCTNetworkTrafficModel alloc\] init\]; model.path = request.URL.path; model.host = request.URL.host; model.type = DMNetworkTrafficDataTypeRequest; model.lineLength = \[connection.currentRequest dgm\_getLineLength\]; model.headerLength = \[connection.currentRequest dgm\_getHeadersLengthWithCookie\]; model.bodyLength = \[connection.currentRequest dgm\_getBodyLength\]; model.emptyLineLength = \[self.internalResponse apm\_getEmptyLineLength\]; model.length = model.lineLength + model.headerLength + model.bodyLength + model.emptyLineLength; NSDictionary \*networkTrafficDictionary = \[model convertToDictionary\]; \[\[HermesClient sharedInstance\] sendWithType:APMMonitorNetworkTrafficType meta:networkTrafficDictionary payload:nil\]; return request;</code></pre><p> }</p></li></ol><h2 id="六、-电量消耗"><a href="#六、-电量消耗" class="headerlink" title="六、 电量消耗"></a>六、 电量消耗</h2><p>移动设备上电量一直是比较敏感的问题，如果用户在某款 App 的时候发现耗电量严重、手机发热严重，那么用户很大可能会马上卸载这款 App。所以需要在开发阶段关心耗电量问题。</p><p>一般来说遇到耗电量较大，我们立马会想到是不是使用了定位、是不是使用了频繁网络请求、是不是不断循环做某件事情？</p><p>开发阶段基本没啥问题，我们可以结合 <code>Instrucments</code> 里的 <code>Energy Log</code> 工具来定位问题。但是线上问题就需要代码去监控耗电量，可以作为 APM 的能力之一。</p><h3 id="1-如何获取电量"><a href="#1-如何获取电量" class="headerlink" title="1. 如何获取电量"></a>1. 如何获取电量</h3><p>在 iOS 中，<code>IOKit</code> 是一个私有框架，用来获取硬件和设备的详细信息，也是硬件和内核服务通信的底层框架。所以我们可以通过 <code>IOKit</code> 来获取硬件信息，从而获取到电量信息。步骤如下：</p><ul><li>  首先在苹果开放源代码 opensource 中找到 <a href="https://link.segmentfault.com/?enc=b/6fURTOumUTAheQuqpyxw==.dtXSUx10pYnebLQ48O8hnlF0B3mu1BzrOerkThTmYrlnpOwSNKQFCRC847ewVPpe5IgUj5QgS085FsKXyfzn74H35iPkjiQ8aT/fwMuVVp+QOBpakYTdYuZvMsZbG59F/gB5bS8STsX272y03dvAJQ==">IOPowerSources.h</a>、<a href="https://link.segmentfault.com/?enc=JL4sd8PzpJH1P4eo4y6QNQ==.XAH/9UR0Dplko4Zt/s1ZHcsZZOWvPu7K/KAe1o+BdDFcemfyCycdcPwe2G5Hpw9JmvBGhliBSx6fFM5u4ruadbsuWy6Ev0CWwoeUoMTa4EBFjwqYkIdPoZIZkaaNm8gU">IOPSKeys.h</a>。在 Xcode 的 <code>Package Contents</code> 里面找到 <code>IOKit.framework</code>。 路径为 <code>/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS.sdk/System/Library/Frameworks/IOKit.framework</code></li><li>  然后将 IOPowerSources.h、IOPSKeys.h、IOKit.framework 导入项目工程</li><li>  设置 UIDevice 的 batteryMonitoringEnabled 为 true</li><li>  获取到的耗电量精确度为 1%</li></ul><h3 id="2-定位问题"><a href="#2-定位问题" class="headerlink" title="2. 定位问题"></a>2. 定位问题</h3><p>通常我们通过 Instrucments 里的 Energy Log 解决了很多问题后，App 上线了，线上的耗电量解决就需要使用 APM 来解决了。耗电地方可能是二方库、三方库，也可能是某个同事的代码。</p><p>思路是：在检测到耗电后，先找到有问题的线程，然后堆栈 dump，还原案发现场。</p><p>在上面部分我们知道了线程信息的结构， <code>thread_basic_info</code> 中有个记录 CPU 使用率百分比的字段 <code>cpu_usage</code>。所以我们可以通过遍历当前线程，判断哪个线程的 CPU 使用率较高，从而找出有问题的线程。然后再 dump 堆栈，从而定位到发生耗电量的代码。详细请看 <a href="https://segmentfault.com/a/1190000040277799#threadInfo">3.2</a> 部分。</p><p>- (double)fetchBatteryCostUsage<br>{<br>  // returns a blob of power source information in an opaque CFTypeRef<br>    CFTypeRef blob = IOPSCopyPowerSourcesInfo();<br>    // returns a CFArray of power source handles, each of type CFTypeRef<br>    CFArrayRef sources = IOPSCopyPowerSourcesList(blob);<br>    CFDictionaryRef pSource = NULL;<br>    const void *psValue;<br>    // returns the number of values currently in an array<br>    int numOfSources = CFArrayGetCount(sources);<br>    // error in CFArrayGetCount<br>    if (numOfSources == 0) {<br>        NSLog(@”Error in CFArrayGetCount”);<br>        return -1.0f;<br>    }</p><pre><code>// calculating the remaining energyfor (int i=0; i&lt;numOfSources; i++) &#123;    // returns a CFDictionary with readable information about the specific power source    pSource = IOPSGetPowerSourceDescription(blob, CFArrayGetValueAtIndex(sources, i));    if (!pSource) &#123;        NSLog(@&quot;Error in IOPSGetPowerSourceDescription&quot;);        return \-1.0f;    &#125;    psValue = (CFStringRef) CFDictionaryGetValue(pSource, CFSTR(kIOPSNameKey));    int curCapacity = 0;    int maxCapacity = 0;    double percentage;    psValue = CFDictionaryGetValue(pSource, CFSTR(kIOPSCurrentCapacityKey));    CFNumberGetValue((CFNumberRef)psValue, kCFNumberSInt32Type, &amp;curCapacity);    psValue = CFDictionaryGetValue(pSource, CFSTR(kIOPSMaxCapacityKey));    CFNumberGetValue((CFNumberRef)psValue, kCFNumberSInt32Type, &amp;maxCapacity);    percentage = ((double) curCapacity / (double) maxCapacity \* 100.0f);    NSLog(@&quot;curCapacity : %d / maxCapacity: %d , percentage: %.1f &quot;, curCapacity, maxCapacity, percentage);    return percentage;&#125;return \-1.0f;</code></pre><p>}</p><h3 id="3-开发阶段针对电量消耗我们能做什么"><a href="#3-开发阶段针对电量消耗我们能做什么" class="headerlink" title="3. 开发阶段针对电量消耗我们能做什么"></a>3. 开发阶段针对电量消耗我们能做什么</h3><p>CPU 密集运算是耗电量主要原因。所以我们对 CPU 的使用需要精打细算。尽量避免让 CPU 做无用功。对于大量数据的复杂运算，可以借助服务器的能力、GPU 的能力。如果方案设计必须是在 CPU 上完成数据的运算，则可以利用 GCD 技术，使用 <code>dispatch_block_create_with_qos_class(&lt;#dispatch_block_flags_t flags#&gt;, dispatch_qos_class_t qos_class, &lt;#int relative_priority#&gt;, &lt;#^(void)block#&gt;)()</code> 并指定 队列的 qos 为 <code>QOS_CLASS_UTILITY</code>。将任务提交到这个队列的 block 中，在 QOS_CLASS_UTILITY 模式下，系统针对大量数据的计算，做了电量优化</p><p>除了 CPU 大量运算，I/O 操作也是耗电主要原因。业界常见方案都是将「碎片化的数据写入磁盘存储」这个操作延后，先在内存中聚合吗，然后再进行磁盘存储。碎片化数据先聚合，在内存中进行存储的机制，iOS 提供 <code>NSCache</code> 这个对象。</p><p>NSCache 是线程安全的，NSCache 会在达到达预设的缓存空间的条件时清理缓存，此时会触发 <code>- (**void**)cache:(NSCache *)cache willEvictObject:(**id**)obj;</code> 方法回调，在该方法内部对数据进行 I/O 操作，达到将聚合的数据 I/O 延后的目的。I/O 次数少了，对电量的消耗也就减少了。</p><p>NSCache 的使用可以查看 SDWebImage 这个图片加载框架。在图片读取缓存处理时，没直接读取硬盘文件（I/O），而是使用系统的 NSCache。</p><p>- (nullable UIImage *)imageFromMemoryCacheForKey:(nullable NSString *)key {<br>    return [self.memoryCache objectForKey:key];<br>}</p><ul><li><p>(nullable UIImage *)imageFromDiskCacheForKey:(nullable NSString *)key {<br>  UIImage *diskImage = [self diskImageForKey:key];<br>  if (diskImage &amp;&amp; self.config.shouldCacheImagesInMemory) {</p><pre><code>  NSUInteger cost = diskImage.sd\_memoryCost;  \[self.memoryCache setObject:diskImage forKey:key cost:cost\];</code></pre><p>  }</p><p>  return diskImage;<br>}</p></li></ul><p>可以看到主要逻辑是先从磁盘中读取图片，如果配置允许开启内存缓存，则将图片保存到 NSCache 中，使用的时候也是从 NSCache 中读取图片。NSCache 的 <code>totalCostLimit、countLimit</code> 属性，</p><p><code>- (void)setObject:(ObjectType)obj forKey:(KeyType)key cost:(NSUInteger)g;</code> 方法用来设置缓存条件。所以我们写磁盘、内存的文件操作时可以借鉴该策略，以优化耗电量。</p><h2 id="七、-Crash-监控"><a href="#七、-Crash-监控" class="headerlink" title="七、 Crash 监控"></a>七、 Crash 监控</h2><h3 id="1-异常相关知识回顾"><a href="#1-异常相关知识回顾" class="headerlink" title="1. 异常相关知识回顾"></a>1. 异常相关知识回顾</h3><h4 id="1-1-Mach-层对异常的处理"><a href="#1-1-Mach-层对异常的处理" class="headerlink" title="1.1 Mach 层对异常的处理"></a>1.1 Mach 层对异常的处理</h4><p>Mach 在消息传递基础上实现了一套独特的异常处理方法。Mach 异常处理在设计时考虑到：</p><ul><li>  带有一致的语义的单一异常处理设施：Mach 只提供一个异常处理机制用于处理所有类型的异常（包括用户定义的异常、平台无关的异常以及平台特定的异常）。根据异常类型进行分组，具体的平台可以定义具体的子类型。</li><li>  清晰和简洁：异常处理的接口依赖于 Mach 已有的具有良好定义的消息和端口架构，因此非常优雅（不会影响效率）。这就允许调试器和外部处理程序的拓展-甚至在理论上还支持拓展基于网络的异常处理。</li></ul><p>在 Mach 中，异常是通过内核中的基础设施-消息传递机制处理的。一个异常并不比一条消息复杂多少，异常由出错的线程或者任务（通过 msg_send()） 抛出，然后由一个处理程序通过 msg_recv()）捕捉。处理程序可以处理异常，也可以清楚异常（将异常标记为已完成并继续），还可以决定终止线程。</p><p>Mach 的异常处理模型和其他的异常处理模型不同，其他模型的异常处理程序运行在出错的线程上下文中，而 Mach 的异常处理程序在不同的上下文中运行异常处理程序，出错的线程向预先指定好的异常端口发送消息，然后等待应答。每一个任务都可以注册一个异常处理端口，这个异常处理端口会对该任务中的所有线程生效。此外，每个线程都可以通过 <code>thread_set_exception_ports(&lt;#thread_act_t thread#&gt;, &lt;#exception_mask_t exception_mask#&gt;, &lt;#mach_port_t new_port#&gt;, &lt;#exception_behavior_t behavior#&gt;, &lt;#thread_state_flavor_t new_flavor#&gt;)</code> 注册自己的异常处理端口。通常情况下，任务和线程的异常端口都是 NULL，也就是异常不会被处理，而一旦创建异常端口，这些端口就像系统中的其他端口一样，可以转交给其他任务或者其他主机。（有了端口，就可以使用 UDP 协议，通过网络能力让其他的主机上应用程序处理异常）。</p><p>发生异常时，首先尝试将异常抛给线程的异常端口，然后尝试抛给任务的异常端口，最后再抛给主机的异常端口（即主机注册的默认端口）。如果没有一个端口返回 <code>KERN_SUCCESS</code>，那么整个任务将被终止。也就是 Mach 不提供异常处理逻辑，只提供传递异常通知的框架。</p><p>异常首先是由处理器陷阱引发的。为了处理陷阱，每一个现代的内核都会安插陷阱处理程序。这些底层函数是由内核的汇编部分安插的。</p><h4 id="1-2-BSD-层对异常的处理"><a href="#1-2-BSD-层对异常的处理" class="headerlink" title="1.2 BSD 层对异常的处理"></a>1.2 BSD 层对异常的处理</h4><p>BSD 层是用户态主要使用的 XUN 接口，这一层展示了一个符合 POSIX 标准的接口。开发者可以使用 UNIX 系统的一切功能，但不需要了解 Mach 层的细节实现。</p><p>Mach 已经通过异常机制提供了底层的陷进处理，而 BSD 则在异常机制之上构建了信号处理机制。硬件产生的信号被 Mach 层捕捉，然后转换为对应的 UNIX 信号，为了维护一个统一的机制，操作系统和用户产生的信号首先被转换为 Mach 异常，然后再转换为信号。</p><p>Mach 异常都在 host 层被 <code>ux_exception</code> 转换为相应的 unix 信号，并通过 <code>threadsignal</code> 将信号投递到出错的线程。</p><p><img src="https://segmentfault.com/img/bVbIOko"></p><h3 id="2-Crash-收集方式"><a href="#2-Crash-收集方式" class="headerlink" title="2. Crash 收集方式"></a>2. Crash 收集方式</h3><p>iOS 系统自带的 Apples`s Crash Reporter 在设置中记录 Crash 日志，我们先观察下 Crash 日志</p><p>Incident Identifier: 7FA6736D-09E8-47A1-95EC-76C4522BDE1A<br>CrashReporter Key:   4e2d36419259f14413c3229e8b7235bcc74847f3<br>Hardware Model:      iPhone7,1<br>Process:         APMMonitorExample [3608]<br>Path:            /var/containers/Bundle/Application/9518A4F4-59B7-44E9-BDDA-9FBEE8CA18E5/APMMonitorExample.app/APMMonitorExample<br>Identifier:      com.Wacai.APMMonitorExample<br>Version:         1.0 (1)<br>Code Type:       ARM-64<br>Parent Process:  ? [1]</p><p>Date/Time:       2017-01-03 11:43:03.000 +0800<br>OS Version:      iOS 10.2 (14C92)<br>Report Version:  104</p><p>Exception Type:  EXC_CRASH (SIGABRT)<br>Exception Codes: 0x00000000 at 0x0000000000000000<br>Crashed Thread:  0</p><p>Application Specific Information:<br>*** Terminating app due to uncaught exception ‘NSInvalidArgumentException’, reason: ‘-[__NSSingleObjectArrayI objectForKey:]: unrecognized selector sent to instance 0x174015060’</p><p>Thread 0 Crashed:<br>0   CoreFoundation                  0x0000000188f291b8 0x188df9000 + 1245624 (<redacted> + 124)<br>1   libobjc.A.dylib                 0x000000018796055c 0x187958000 + 34140 (objc_exception_throw + 56)<br>2   CoreFoundation                  0x0000000188f30268 0x188df9000 + 1274472 (<redacted> + 140)<br>3   CoreFoundation                  0x0000000188f2d270 0x188df9000 + 1262192 (<redacted> + 916)<br>4   CoreFoundation                  0x0000000188e2680c 0x188df9000 + 186380 (_CF_forwarding_prep_0 + 92)<br>5   APMMonitorExample                0x000000010004c618 0x100044000 + 34328 (-[MakeCrashHandler throwUncaughtNSException] + 80)</p><p>会发现，Crash 日志中 <code>Exception Type</code> 项由2部分组成：Mach 异常 + Unix 信号。</p><p>所以 <code>Exception Type: EXC_CRASH (SIGABRT)</code> 表示：Mach 层发生了 <code>EXC_CRASH</code> 异常，在 host 层被转换为 <code>SIGABRT</code> 信号投递到出错的线程。</p><p><strong>问题：</strong> 捕获 Mach 层异常、注册 Unix 信号处理都可以捕获 Crash，这两种方式如何选择？</p><p><strong>答：</strong> 优选 Mach 层异常拦截。根据上面 1.2 中的描述我们知道 Mach 层异常处理时机更早些，假如 Mach 层异常处理程序让进程退出，这样 Unix 信号永远不会发生了。</p><p>业界关于崩溃日志的收集开源项目很多，著名的有： KSCrash、plcrashreporter，提供一条龙服务的 Bugly、友盟等。我们一般使用开源项目在此基础上开发成符合公司内部需求的 bug 收集工具。一番对比后选择 KSCrash。为什么选择 KSCrash 不在本文重点。</p><p>KSCrash 功能齐全，可以捕获如下类型的 Crash</p><ul><li>  Mach kernel exceptions</li><li>  Fatal signals</li><li>  C++ exceptions</li><li>  Objective-C exceptions</li><li>  Main thread deadlock (experimental)</li><li>  Custom crashes (e.g. from scripting languages)</li></ul><p>所以分析 iOS 端的 Crash 收集方案也就是分析 KSCrash 的 Crash 监控实现原理。</p><h4 id="2-1-Mach-层异常处理"><a href="#2-1-Mach-层异常处理" class="headerlink" title="2.1. Mach 层异常处理"></a>2.1. Mach 层异常处理</h4><p>大体思路是：先创建一个异常处理端口，为该端口申请权限，再设置异常端口、新建一个内核线程，在该线程内循环等待异常。但是为了防止自己注册的 Mach 层异常处理抢占了其他 SDK、或者业务线开发者设置的逻辑，我们需要在最开始保存其他的异常处理端口，等逻辑执行完后将异常处理交给其他的端口内的逻辑处理。收集到 Crash 信息后组装数据，写入 json 文件。</p><p>流程图如下：</p><p><img src="https://segmentfault.com/img/bVbIOku"></p><p>对于 Mach 异常捕获，可以注册一个异常端口，该端口负责对当前任务的所有线程进行监听。</p><p>下面来看看关键代码:</p><p>注册 Mach 层异常监听代码</p><p>static bool installExceptionHandler()<br>{<br>    KSLOG_DEBUG(“Installing mach exception handler.”);</p><pre><code>bool attributes\_created = false;pthread\_attr\_t attr;kern\_return\_t kr;int error;// 拿到当前进程const task\_t thisTask = mach\_task\_self();exception\_mask\_t mask = EXC\_MASK\_BAD\_ACCESS |EXC\_MASK\_BAD\_INSTRUCTION |EXC\_MASK\_ARITHMETIC |EXC\_MASK\_SOFTWARE |EXC\_MASK\_BREAKPOINT;KSLOG\_DEBUG(&quot;Backing up original exception ports.&quot;);// 获取该 Task 上的注册好的异常端口kr = task\_get\_exception\_ports(thisTask,                              mask,                              g\_previousExceptionPorts.masks,                              &amp;g\_previousExceptionPorts.count,                              g\_previousExceptionPorts.ports,                              g\_previousExceptionPorts.behaviors,                              g\_previousExceptionPorts.flavors);// 获取失败走 failed 逻辑if(kr != KERN\_SUCCESS)&#123;    KSLOG\_ERROR(&quot;task\_get\_exception\_ports: %s&quot;, mach\_error\_string(kr));    goto failed;&#125;// KSCrash 的异常为空则走执行逻辑if(g\_exceptionPort == MACH\_PORT\_NULL)&#123;    KSLOG\_DEBUG(&quot;Allocating new port with receive rights.&quot;);    // 申请异常处理端口    kr = mach\_port\_allocate(thisTask,                            MACH\_PORT\_RIGHT\_RECEIVE,                            &amp;g\_exceptionPort);    if(kr != KERN\_SUCCESS)    &#123;        KSLOG\_ERROR(&quot;mach\_port\_allocate: %s&quot;, mach\_error\_string(kr));        goto failed;    &#125;    KSLOG\_DEBUG(&quot;Adding send rights to port.&quot;);    // 为异常处理端口申请权限：MACH\_MSG\_TYPE\_MAKE\_SEND    kr = mach\_port\_insert\_right(thisTask,                                g\_exceptionPort,                                g\_exceptionPort,                                MACH\_MSG\_TYPE\_MAKE\_SEND);    if(kr != KERN\_SUCCESS)    &#123;        KSLOG\_ERROR(&quot;mach\_port\_insert\_right: %s&quot;, mach\_error\_string(kr));        goto failed;    &#125;&#125;KSLOG\_DEBUG(&quot;Installing port as exception handler.&quot;);// 为该 Task 设置异常处理端口kr = task\_set\_exception\_ports(thisTask,                              mask,                              g\_exceptionPort,                              EXCEPTION\_DEFAULT,                              THREAD\_STATE\_NONE);if(kr != KERN\_SUCCESS)&#123;    KSLOG\_ERROR(&quot;task\_set\_exception\_ports: %s&quot;, mach\_error\_string(kr));    goto failed;&#125;KSLOG\_DEBUG(&quot;Creating secondary exception thread (suspended).&quot;);pthread\_attr\_init(&amp;attr);attributes\_created = true;pthread\_attr\_setdetachstate(&amp;attr, PTHREAD\_CREATE\_DETACHED);// 设置监控线程error = pthread\_create(&amp;g\_secondaryPThread,                       &amp;attr,                       &amp;handleExceptions,                       kThreadSecondary);if(error != 0)&#123;    KSLOG\_ERROR(&quot;pthread\_create\_suspended\_np: %s&quot;, strerror(error));    goto failed;&#125;// 转换为 Mach 内核线程g\_secondaryMachThread = pthread\_mach\_thread\_np(g\_secondaryPThread);ksmc\_addReservedThread(g\_secondaryMachThread);KSLOG\_DEBUG(&quot;Creating primary exception thread.&quot;);error = pthread\_create(&amp;g\_primaryPThread,                       &amp;attr,                       &amp;handleExceptions,                       kThreadPrimary);if(error != 0)&#123;    KSLOG\_ERROR(&quot;pthread\_create: %s&quot;, strerror(error));    goto failed;&#125;pthread\_attr\_destroy(&amp;attr);g\_primaryMachThread = pthread\_mach\_thread\_np(g\_primaryPThread);ksmc\_addReservedThread(g\_primaryMachThread);KSLOG\_DEBUG(&quot;Mach exception handler installed.&quot;);return true;</code></pre><p>failed:<br>    KSLOG_DEBUG(“Failed to install mach exception handler.”);<br>    if(attributes_created)<br>    {<br>        pthread_attr_destroy(&amp;attr);<br>    }<br>    // 还原之前的异常注册端口，将控制权还原<br>    uninstallExceptionHandler();<br>    return false;<br>}</p><p>处理异常的逻辑、组装崩溃信息</p><p>/** Our exception handler thread routine.<br> * Wait for an exception message, uninstall our exception port, record the<br> * exception information, and write a report.<br> */<br>static void* handleExceptions(void* const userData)<br>{<br>    MachExceptionMessage exceptionMessage = 0;<br>    MachReplyMessage replyMessage = 0;<br>    char* eventID = g_primaryEventID;</p><pre><code>const char\* threadName = (const char\*) userData;pthread\_setname\_np(threadName);if(threadName == kThreadSecondary)&#123;    KSLOG\_DEBUG(&quot;This is the secondary thread. Suspending.&quot;);    thread\_suspend((thread\_t)ksthread\_self());    eventID = g\_secondaryEventID;&#125;// 循环读取注册好的异常端口信息for(;;)&#123;    KSLOG\_DEBUG(&quot;Waiting for mach exception&quot;);    // Wait for a message.    kern\_return\_t kr = mach\_msg(&amp;exceptionMessage.header,                                MACH\_RCV\_MSG,                                0,                                sizeof(exceptionMessage),                                g\_exceptionPort,                                MACH\_MSG\_TIMEOUT\_NONE,                                MACH\_PORT\_NULL);    // 获取到信息后则代表发生了 Mach 层异常，跳出 for 循环，组装数据    if(kr == KERN\_SUCCESS)    &#123;        break;    &#125;    // Loop and try again on failure.    KSLOG\_ERROR(&quot;mach\_msg: %s&quot;, mach\_error\_string(kr));&#125;KSLOG\_DEBUG(&quot;Trapped mach exception code 0x%x, subcode 0x%x&quot;,            exceptionMessage.code\[0\], exceptionMessage.code\[1\]);if(g\_isEnabled)&#123;    // 挂起所有线程    ksmc\_suspendEnvironment();    g\_isHandlingCrash = true;    // 通知发生了异常    kscm\_notifyFatalExceptionCaptured(true);    KSLOG\_DEBUG(&quot;Exception handler is installed. Continuing exception handling.&quot;);    // Switch to the secondary thread if necessary, or uninstall the handler    // to avoid a death loop.    if(ksthread\_self() == g\_primaryMachThread)    &#123;        KSLOG\_DEBUG(&quot;This is the primary exception thread. Activating secondary thread.&quot;);</code></pre><p>// TODO: This was put here to avoid a freeze. Does secondary thread ever fire?<br>            restoreExceptionPorts();<br>            if(thread_resume(g_secondaryMachThread) != KERN_SUCCESS)<br>            {<br>                KSLOG_DEBUG(“Could not activate secondary thread. Restoring original exception ports.”);<br>            }<br>        }<br>        else<br>        {<br>            KSLOG_DEBUG(“This is the secondary exception thread. Restoring original exception ports.”);<br>//            restoreExceptionPorts();<br>        }</p><pre><code>    // Fill out crash information    // 组装异常所需要的方案现场信息    KSLOG\_DEBUG(&quot;Fetching machine state.&quot;);    KSMC\_NEW\_CONTEXT(machineContext);    KSCrash\_MonitorContext\* crashContext = &amp;g\_monitorContext;    crashContext-&gt;offendingMachineContext = machineContext;    kssc\_initCursor(&amp;g\_stackCursor, NULL, NULL);    if(ksmc\_getContextForThread(exceptionMessage.thread.name, machineContext, true))    &#123;        kssc\_initWithMachineContext(&amp;g\_stackCursor, 100, machineContext);        KSLOG\_TRACE(&quot;Fault address 0x%x, instruction address 0x%x&quot;, kscpu\_faultAddress(machineContext), kscpu\_instructionAddress(machineContext));        if(exceptionMessage.exception == EXC\_BAD\_ACCESS)        &#123;            crashContext-&gt;faultAddress = kscpu\_faultAddress(machineContext);        &#125;        else        &#123;            crashContext-&gt;faultAddress = kscpu\_instructionAddress(machineContext);        &#125;    &#125;    KSLOG\_DEBUG(&quot;Filling out context.&quot;);    crashContext-&gt;crashType = KSCrashMonitorTypeMachException;    crashContext-&gt;eventID = eventID;    crashContext-&gt;registersAreValid = true;    crashContext-&gt;mach.type = exceptionMessage.exception;    crashContext-&gt;mach.code = exceptionMessage.code\[0\];    crashContext-&gt;mach.subcode = exceptionMessage.code\[1\];    if(crashContext-&gt;mach.code == KERN\_PROTECTION\_FAILURE &amp;&amp; crashContext-&gt;isStackOverflow)    &#123;        // A stack overflow should return KERN\_INVALID\_ADDRESS, but        // when a stack blasts through the guard pages at the top of the stack,        // it generates KERN\_PROTECTION\_FAILURE. Correct for this.        crashContext-&gt;mach.code = KERN\_INVALID\_ADDRESS;    &#125;    crashContext-&gt;signal.signum = signalForMachException(crashContext-&gt;mach.type, crashContext-&gt;mach.code);    crashContext-&gt;stackCursor = &amp;g\_stackCursor;    kscm\_handleException(crashContext);    KSLOG\_DEBUG(&quot;Crash handling complete. Restoring original handlers.&quot;);    g\_isHandlingCrash = false;    ksmc\_resumeEnvironment();&#125;KSLOG\_DEBUG(&quot;Replying to mach exception message.&quot;);// Send a reply saying &quot;I didn&#39;t handle this exception&quot;.replyMessage.header = exceptionMessage.header;replyMessage.NDR = exceptionMessage.NDR;replyMessage.returnCode = KERN\_FAILURE;mach\_msg(&amp;replyMessage.header,         MACH\_SEND\_MSG,         sizeof(replyMessage),         0,         MACH\_PORT\_NULL,         MACH\_MSG\_TIMEOUT\_NONE,         MACH\_PORT\_NULL);return NULL;</code></pre><p>}</p><p>还原异常处理端口，转移控制权</p><p>/** Restore the original mach exception ports.<br> */<br>static void restoreExceptionPorts(void)<br>{<br>    KSLOG_DEBUG(“Restoring original exception ports.”);<br>    if(g_previousExceptionPorts.count == 0)<br>    {<br>        KSLOG_DEBUG(“Original exception ports were already restored.”);<br>        return;<br>    }</p><pre><code>const task\_t thisTask = mach\_task\_self();kern\_return\_t kr;// Reinstall old exception ports.// for 循环去除保存好的在 KSCrash 之前注册好的异常端口，将每个端口注册回去for(mach\_msg\_type\_number\_t i = 0; i &lt; g\_previousExceptionPorts.count; i++)&#123;    KSLOG\_TRACE(&quot;Restoring port index %d&quot;, i);    kr = task\_set\_exception\_ports(thisTask,                                  g\_previousExceptionPorts.masks\[i\],                                  g\_previousExceptionPorts.ports\[i\],                                  g\_previousExceptionPorts.behaviors\[i\],                                  g\_previousExceptionPorts.flavors\[i\]);    if(kr != KERN\_SUCCESS)    &#123;        KSLOG\_ERROR(&quot;task\_set\_exception\_ports: %s&quot;,                    mach\_error\_string(kr));    &#125;&#125;KSLOG\_DEBUG(&quot;Exception ports restored.&quot;);g\_previousExceptionPorts.count = 0;</code></pre><p>}</p><h4 id="2-2-Signal-异常处理"><a href="#2-2-Signal-异常处理" class="headerlink" title="2.2. Signal 异常处理"></a>2.2. Signal 异常处理</h4><p>对于 Mach 异常，操作系统会将其转换为对应的 <code>Unix 信号</code>，所以开发者可以通过注册 <code>signanHandler</code> 的方式来处理。</p><p>KSCrash 在这里的处理逻辑如下图：</p><p><img src="https://segmentfault.com/img/bVbIOkv"><br>看一下关键代码:</p><p>设置信号处理函数</p><p>static bool installSignalHandler()<br>{<br>    KSLOG_DEBUG(“Installing signal handler.”);</p><p>#if KSCRASH_HAS_SIGNAL_STACK<br>    // 在堆上分配一块内存，<br>    if(g_signalStack.ss_size == 0)<br>    {<br>        KSLOG_DEBUG(“Allocating signal stack area.”);<br>        g_signalStack.ss_size = SIGSTKSZ;<br>        g_signalStack.ss_sp = malloc(g_signalStack.ss_size);<br>    }<br>    // 信号处理函数的栈挪到堆中，而不和进程共用一块栈区<br>    // sigaltstack() 函数，该函数的第 1 个参数 sigstack 是一个 stack_t 结构的指针，该结构存储了一个“可替换信号栈” 的位置及属性信息。第 2 个参数 old_sigstack 也是一个 stack_t 类型指针，它用来返回上一次建立的“可替换信号栈”的信息(如果有的话)<br>    KSLOG_DEBUG(“Setting signal stack area.”);<br>    // sigaltstack 第一个参数为创建的新的可替换信号栈，第二个参数可以设置为NULL，如果不为NULL的话，将会将旧的可替换信号栈的信息保存在里面。函数成功返回0，失败返回-1.<br>    if(sigaltstack(&amp;g_signalStack, NULL) != 0)<br>    {<br>        KSLOG_ERROR(“signalstack: %s”, strerror(errno));<br>        goto failed;<br>    }<br>#endif</p><pre><code>const int\* fatalSignals = kssignal\_fatalSignals();int fatalSignalsCount = kssignal\_numFatalSignals();if(g\_previousSignalHandlers == NULL)&#123;    KSLOG\_DEBUG(&quot;Allocating memory to store previous signal handlers.&quot;);    g\_previousSignalHandlers = malloc(sizeof(\*g\_previousSignalHandlers)                                      \* (unsigned)fatalSignalsCount);&#125;// 设置信号处理函数 sigaction 的第二个参数，类型为 sigaction 结构体struct sigaction action = &#123;&#123;0&#125;&#125;;// sa\_flags 成员设立 SA\_ONSTACK 标志，该标志告诉内核信号处理函数的栈帧就在“可替换信号栈”上建立。action.sa\_flags = SA\_SIGINFO | SA\_ONSTACK;</code></pre><p>#if KSCRASH_HOST_APPLE &amp;&amp; defined(__LP64__)<br>    action.sa_flags |= SA_64REGSET;<br>#endif<br>    sigemptyset(&amp;action.sa_mask);<br>    action.sa_sigaction = &handleSignal;</p><pre><code>// 遍历需要处理的信号数组for(int i = 0; i &lt; fatalSignalsCount; i++)&#123;    // 将每个信号的处理函数绑定到上面声明的 action 去，另外用 g\_previousSignalHandlers 保存当前信号的处理函数    KSLOG\_DEBUG(&quot;Assigning handler for signal %d&quot;, fatalSignals\[i\]);    if(sigaction(fatalSignals\[i\], &amp;action, &amp;g\_previousSignalHandlers\[i\]) != 0)    &#123;        char sigNameBuff\[30\];        const char\* sigName = kssignal\_signalName(fatalSignals\[i\]);        if(sigName == NULL)        &#123;            snprintf(sigNameBuff, sizeof(sigNameBuff), &quot;%d&quot;, fatalSignals\[i\]);            sigName = sigNameBuff;        &#125;        KSLOG\_ERROR(&quot;sigaction (%s): %s&quot;, sigName, strerror(errno));        // Try to reverse the damage        for(i--;i &gt;= 0; i--)        &#123;            sigaction(fatalSignals\[i\], &amp;g\_previousSignalHandlers\[i\], NULL);        &#125;        goto failed;    &#125;&#125;KSLOG\_DEBUG(&quot;Signal handlers installed.&quot;);return true;</code></pre><p>failed:<br>    KSLOG_DEBUG(“Failed to install signal handlers.”);<br>    return false;<br>}</p><p>信号处理时记录线程等上下文信息</p><p>static void handleSignal(int sigNum, siginfo_t* signalInfo, void* userContext)<br>{<br>    KSLOG_DEBUG(“Trapped signal %d”, sigNum);<br>    if(g_isEnabled)<br>    {<br>        ksmc_suspendEnvironment();<br>        kscm_notifyFatalExceptionCaptured(false);</p><pre><code>    KSLOG\_DEBUG(&quot;Filling out context.&quot;);    KSMC\_NEW\_CONTEXT(machineContext);    ksmc\_getContextForSignal(userContext, machineContext);    kssc\_initWithMachineContext(&amp;g\_stackCursor, 100, machineContext);    // 记录信号处理时的上下文信息    KSCrash\_MonitorContext\* crashContext = &amp;g\_monitorContext;    memset(crashContext, 0, sizeof(\*crashContext));    crashContext-&gt;crashType = KSCrashMonitorTypeSignal;    crashContext-&gt;eventID = g\_eventID;    crashContext-&gt;offendingMachineContext = machineContext;    crashContext-&gt;registersAreValid = true;    crashContext-&gt;faultAddress = (uintptr\_t)signalInfo-&gt;si\_addr;    crashContext-&gt;signal.userContext = userContext;    crashContext-&gt;signal.signum = signalInfo-&gt;si\_signo;    crashContext-&gt;signal.sigcode = signalInfo-&gt;si\_code;    crashContext-&gt;stackCursor = &amp;g\_stackCursor;    kscm\_handleException(crashContext);    ksmc\_resumeEnvironment();&#125;KSLOG\_DEBUG(&quot;Re-raising signal for regular handlers to catch.&quot;);// This is technically not allowed, but it works in OSX and iOS.raise(sigNum);</code></pre><p>}</p><p>KSCrash 信号处理后还原之前的信号处理权限</p><p>static void uninstallSignalHandler(void)<br>{<br>    KSLOG_DEBUG(“Uninstalling signal handlers.”);</p><pre><code>const int\* fatalSignals = kssignal\_fatalSignals();int fatalSignalsCount = kssignal\_numFatalSignals();// 遍历需要处理信号数组，将之前的信号处理函数还原for(int i = 0; i &lt; fatalSignalsCount; i++)&#123;    KSLOG\_DEBUG(&quot;Restoring original handler for signal %d&quot;, fatalSignals\[i\]);    sigaction(fatalSignals\[i\], &amp;g\_previousSignalHandlers\[i\], NULL);&#125;KSLOG\_DEBUG(&quot;Signal handlers uninstalled.&quot;);</code></pre><p>}</p><p>说明：</p><ol><li><p>先从堆上分配一块内存区域，被称为“可替换信号栈”，目的是将信号处理函数的栈干掉，用堆上的内存区域代替，而不和进程共用一块栈区。</p><p> 为什么这么做？一个进程可能有 n 个线程，每个线程都有自己的任务，假如某个线程执行出错，这样就会导致整个进程的崩溃。所以为了信号处理函数正常运行，需要为信号处理函数设置单独的运行空间。另一种情况是递归函数将系统默认的栈空间用尽了，但是信号处理函数使用的栈是它实现在堆中分配的空间，而不是系统默认的栈，所以它仍旧可以正常工作。</p></li><li><p><code>int sigaltstack(const stack_t * __restrict, stack_t * __restrict)</code> 函数的二个参数都是 <code>stack_t</code> 结构的指针，存储了可替换信号栈的信息（栈的起始地址、栈的长度、状态）。第1个参数该结构存储了一个“可替换信号栈” 的位置及属性信息。第 2 个参数用来返回上一次建立的“可替换信号栈”的信息(如果有的话)。</p><p> _STRUCT_SIGALTSTACK<br> {</p><pre><code> void            \*ss\_sp;         /\* signal stack base \*/ \_\_darwin\_size\_t ss\_size;        /\* signal stack length \*/ int             ss\_flags;       /\* SA\_DISABLE and/or SA\_ONSTACK \*/</code></pre><p> };<br> typedef _STRUCT_SIGALTSTACK     stack_t; /* [???] signal stack */</p></li></ol><p>新创建的可替换信号栈，<code>ss_flags</code> 必须设置为 0。系统定义了 <code>SIGSTKSZ</code> 常量，可满足绝大多可替换信号栈的需求。</p><p>/*<br> * Structure used in sigaltstack call.<br> */</p><p>#define SS_ONSTACK      0x0001  /* take signal on signal stack */<br>#define SS_DISABLE      0x0004  /* disable taking signals on alternate stack */<br>#define MINSIGSTKSZ     32768   /* (32K)minimum allowable stack */<br>#define SIGSTKSZ        131072  /* (128K)recommended stack size */</p><p><code>sigaltstack</code> 系统调用通知内核“可替换信号栈”已经建立。</p><p><code>ss_flags</code> 为 <code>SS_ONSTACK</code> 时，表示进程当前正在“可替换信号栈”中执行，如果此时试图去建立一个新的“可替换信号栈”，那么会遇到 <code>EPERM</code> (禁止该动作) 的错误；为 <code>SS_DISABLE</code> 说明当前没有已建立的“可替换信号栈”，禁止建立“可替换信号栈”。</p><ol start="3"><li><p><code>int sigaction(int, const struct sigaction * __restrict, struct sigaction * __restrict);</code></p><p> 第一个函数表示需要处理的信号值，但不能是 <code>SIGKILL</code> 和 <code>SIGSTOP</code> ，这两个信号的处理函数不允许用户重写，因为它们给超级用户提供了终止程序的方法（ <code>SIGKILL</code> and <code>SIGSTOP</code> cannot be caught, blocked, or ignored）；</p><p> 第二个和第三个参数是一个 <code>sigaction</code> 结构体。如果第二个参数不为空则代表将其指向信号处理函数，第三个参数不为空，则将之前的信号处理函数保存到该指针中。如果第二个参数为空，第三个参数不为空，则可以获取当前的信号处理函数。</p><p> /*<br>  * Signal vector “template” used in sigaction call.<br>  */<br> struct  sigaction {</p><pre><code> union \_\_sigaction\_u \_\_sigaction\_u;  /\* signal handler \*/ sigset\_t sa\_mask;               /\* signal mask to apply \*/ int     sa\_flags;               /\* see signal options below \*/</code></pre><p> };</p></li></ol><p><code>sigaction</code> 函数的 <code>sa_flags</code> 参数需要设置 <code>SA_ONSTACK</code> 标志，告诉内核信号处理函数的栈帧就在“可替换信号栈”上建立。</p><h4 id="2-3-C-异常处理"><a href="#2-3-C-异常处理" class="headerlink" title="2.3. C++ 异常处理"></a>2.3. C++ 异常处理</h4><p>c++ 异常处理的实现是依靠了标准库的 <code>std::set_terminate(CPPExceptionTerminate)</code> 函数。</p><p>iOS 工程中某些功能的实现可能使用了C、C++等。假如抛出 C++ 异常，如果该异常可以被转换为 NSException，则走 OC 异常捕获机制，如果不能转换，则继续走 C++ 异常流程，也就是 <code>default_terminate_handler</code>。这个 C++ 异常的默认 terminate 函数内部调用 <code>abort_message</code> 函数，最后触发了一个 <code>abort</code> 调用，系统产生一个 <code>SIGABRT</code> 信号。</p><p>在系统抛出 C++ 异常后，加一层 <code>try...catch...</code> 来判断该异常是否可以转换为 <code>NSException</code>，再重新抛出的C++异常。此时异常的现场堆栈已经消失，所以上层通过捕获 <code>SIGABRT</code> 信号是无法还原发生异常时的场景，即异常堆栈缺失。</p><p>为什么？<code>try...catch...</code> 语句内部会调用 <code>__cxa_rethrow()</code> 抛出异常，<code>__cxa_rethrow()</code> 内部又会调用 <code>unwind</code>，<code>unwind</code> 可以简单理解为函数调用的逆调用，主要用来清理函数调用过程中每个函数生成的局部变量，一直到最外层的 catch 语句所在的函数，并把控制移交给 catch 语句，这就是C++异常的堆栈消失原因。</p><p>static void setEnabled(bool isEnabled) {<br>    if(isEnabled != g_isEnabled)<br>    {<br>        g_isEnabled = isEnabled;<br>        if(isEnabled)<br>        {<br>            initialize();</p><pre><code>        ksid\_generate(g\_eventID);        g\_originalTerminateHandler = std::set\_terminate(CPPExceptionTerminate);    &#125;    else    &#123;        std::set\_terminate(g\_originalTerminateHandler);    &#125;    g\_captureNextStackTrace = isEnabled;&#125;</code></pre><p>}</p><p>static void initialize() {<br>    static bool isInitialized = false;<br>    if(!isInitialized)<br>    {<br>        isInitialized = true;<br>        kssc_initCursor(&amp;g_stackCursor, NULL, NULL);<br>    }<br>}</p><p>void kssc_initCursor(KSStackCursor *cursor,<br>                     void (*resetCursor)(KSStackCursor*),<br>                     bool (*advanceCursor)(KSStackCursor*)) {<br>    cursor-&gt;symbolicate = kssymbolicator_symbolicate;<br>    cursor-&gt;advanceCursor = advanceCursor != NULL ? advanceCursor : g_advanceCursor;<br>    cursor-&gt;resetCursor = resetCursor != NULL ? resetCursor : kssc_resetCursor;<br>    cursor-&gt;resetCursor(cursor);<br>}</p><p>static void CPPExceptionTerminate(void) {<br>    ksmc_suspendEnvironment();<br>    KSLOG_DEBUG(“Trapped c++ exception”);<br>    const char* name = NULL;<br>    std::type_info* tinfo = __cxxabiv1::__cxa_current_exception_type();<br>    if(tinfo != NULL)<br>    {<br>        name = tinfo-&gt;name();<br>    }</p><pre><code>if(name == NULL || strcmp(name, &quot;NSException&quot;) != 0)&#123;    kscm\_notifyFatalExceptionCaptured(false);    KSCrash\_MonitorContext\* crashContext = &amp;g\_monitorContext;    memset(crashContext, 0, sizeof(\*crashContext));    char descriptionBuff\[DESCRIPTION\_BUFFER\_LENGTH\];    const char\* description = descriptionBuff;    descriptionBuff\[0\] = 0;    KSLOG\_DEBUG(&quot;Discovering what kind of exception was thrown.&quot;);    g\_captureNextStackTrace = false;    try    &#123;        throw;    &#125;    catch(std::exception&amp; exc)    &#123;        strncpy(descriptionBuff, exc.what(), sizeof(descriptionBuff));    &#125;</code></pre><p>#define CATCH_VALUE(TYPE, PRINTFTYPE) \<br>catch(TYPE value)\<br>{ \<br>    snprintf(descriptionBuff, sizeof(descriptionBuff), “%” #PRINTFTYPE, value); \<br>}<br>        CATCH_VALUE(char,                 d)<br>        CATCH_VALUE(short,                d)<br>        CATCH_VALUE(int,                  d)<br>        CATCH_VALUE(long,                ld)<br>        CATCH_VALUE(long long,          lld)<br>        CATCH_VALUE(unsigned char,        u)<br>        CATCH_VALUE(unsigned short,       u)<br>        CATCH_VALUE(unsigned int,         u)<br>        CATCH_VALUE(unsigned long,       lu)<br>        CATCH_VALUE(unsigned long long, llu)<br>        CATCH_VALUE(float,                f)<br>        CATCH_VALUE(double,               f)<br>        CATCH_VALUE(long double,         Lf)<br>        CATCH_VALUE(char*,                s)<br>        catch(…)<br>        {<br>            description = NULL;<br>        }<br>        g_captureNextStackTrace = g_isEnabled;</p><pre><code>    // TODO: Should this be done here? Maybe better in the exception handler?    KSMC\_NEW\_CONTEXT(machineContext);    ksmc\_getContextForThread(ksthread\_self(), machineContext, true);    KSLOG\_DEBUG(&quot;Filling out context.&quot;);    crashContext-&gt;crashType = KSCrashMonitorTypeCPPException;    crashContext-&gt;eventID = g\_eventID;    crashContext-&gt;registersAreValid = false;    crashContext-&gt;stackCursor = &amp;g\_stackCursor;    crashContext-&gt;CPPException.name = name;    crashContext-&gt;exceptionName = name;    crashContext-&gt;crashReason = description;    crashContext-&gt;offendingMachineContext = machineContext;    kscm\_handleException(crashContext);&#125;else&#123;    KSLOG\_DEBUG(&quot;Detected NSException. Letting the current NSException handler deal with it.&quot;);&#125;ksmc\_resumeEnvironment();KSLOG\_DEBUG(&quot;Calling original terminate handler.&quot;);g\_originalTerminateHandler();</code></pre><p>}</p><h4 id="2-4-Objective-C-异常处理"><a href="#2-4-Objective-C-异常处理" class="headerlink" title="2.4. Objective-C 异常处理"></a>2.4. Objective-C 异常处理</h4><p>对于 OC 层面的 NSException 异常处理较为容易，可以通过注册 <code>NSUncaughtExceptionHandler</code> 来捕获异常信息，通过 NSException 参数来做 Crash 信息的收集，交给数据上报组件。</p><p>static void setEnabled(bool isEnabled) {<br>    if(isEnabled != g_isEnabled)<br>    {<br>        g_isEnabled = isEnabled;<br>        if(isEnabled)<br>        {<br>            KSLOG_DEBUG(@”Backing up original handler.”);<br>            // 记录之前的 OC 异常处理函数<br>            g_previousUncaughtExceptionHandler = NSGetUncaughtExceptionHandler();</p><pre><code>        KSLOG\_DEBUG(@&quot;Setting new handler.&quot;);        // 设置新的 OC 异常处理函数        NSSetUncaughtExceptionHandler(&amp;handleException);        KSCrash.sharedInstance.uncaughtExceptionHandler = &amp;handleException;    &#125;    else    &#123;        KSLOG\_DEBUG(@&quot;Restoring original handler.&quot;);        NSSetUncaughtExceptionHandler(g\_previousUncaughtExceptionHandler);    &#125;&#125;</code></pre><p>}</p><h4 id="2-5-主线程死锁"><a href="#2-5-主线程死锁" class="headerlink" title="2.5. 主线程死锁"></a>2.5. 主线程死锁</h4><p>主线程死锁的检测和 ANR 的检测有些类似</p><ul><li><p>  创建一个线程，在线程运行方法中用 <code>do...while...</code> 循环处理逻辑，加了 autorelease 避免内存过高</p></li><li><p>有一个 <code>awaitingResponse</code> 属性和 <code>watchdogPulse</code> 方法。watchdogPulse 主要逻辑为设置 <code>awaitingResponse</code> 为 YES，切换到主线程中，设置 <code>awaitingResponse</code> 为 NO，</p><p>  - (void) watchdogPulse<br>  {</p><pre><code>  \_\_block id blockSelf = self;  self.awaitingResponse = YES;  dispatch\_async(dispatch\_get\_main\_queue(), ^                 &#123;                     \[blockSelf watchdogAnswer\];                 &#125;);</code></pre><p>  }</p></li><li><p>线程的执行方法里面不断循环，等待设置的 <code>g_watchdogInterval</code> 后判断 <code>awaitingResponse</code> 的属性值是不是初始状态的值，否则判断为死锁</p><p>  - (void) runMonitor<br>  {</p><pre><code>  BOOL cancelled = NO;  do  &#123;      // Only do a watchdog check if the watchdog interval is &gt; 0.      // If the interval is &lt;= 0, just idle until the user changes it.      @autoreleasepool &#123;          NSTimeInterval sleepInterval = g\_watchdogInterval;          BOOL runWatchdogCheck = sleepInterval &gt; 0;          if(!runWatchdogCheck)          &#123;              sleepInterval = kIdleInterval;          &#125;          \[NSThread sleepForTimeInterval:sleepInterval\];          cancelled = self.monitorThread.isCancelled;          if(!cancelled &amp;&amp; runWatchdogCheck)          &#123;              if(self.awaitingResponse)              &#123;                  \[self handleDeadlock\];              &#125;              else              &#123;                  \[self watchdogPulse\];              &#125;          &#125;      &#125;  &#125; while (!cancelled);</code></pre><p>  }</p></li></ul><h4 id="2-6-Crash-的生成与保存"><a href="#2-6-Crash-的生成与保存" class="headerlink" title="2.6 Crash 的生成与保存"></a>2.6 Crash 的生成与保存</h4><h5 id="2-6-1-Crash-日志的生成逻辑"><a href="#2-6-1-Crash-日志的生成逻辑" class="headerlink" title="2.6.1 Crash 日志的生成逻辑"></a>2.6.1 Crash 日志的生成逻辑</h5><p>上面的部分讲过了 iOS 应用开发中的各种 crash 监控逻辑，接下来就应该分析下 crash 捕获后如何将 crash 信息记录下来，也就是保存到应用沙盒中。</p><p>拿主线程死锁这种 crash 举例子，看看 KSCrash 是如何记录 crash 信息的。</p><p>// KSCrashMonitor_Deadlock.m</p><ul><li><p>(void) handleDeadlock<br>{<br>  ksmc_suspendEnvironment();<br>  kscm_notifyFatalExceptionCaptured(false);</p><p>  KSMC_NEW_CONTEXT(machineContext);<br>  ksmc_getContextForThread(g_mainQueueThread, machineContext, false);<br>  KSStackCursor stackCursor;<br>  kssc_initWithMachineContext(&amp;stackCursor, 100, machineContext);<br>  char eventID[37];<br>  ksid_generate(eventID);</p><p>  KSLOG_DEBUG(@”Filling out context.”);<br>  KSCrash_MonitorContext* crashContext = &amp;g_monitorContext;<br>  memset(crashContext, 0, sizeof(*crashContext));<br>  crashContext-&gt;crashType = KSCrashMonitorTypeMainThreadDeadlock;<br>  crashContext-&gt;eventID = eventID;<br>  crashContext-&gt;registersAreValid = false;<br>  crashContext-&gt;offendingMachineContext = machineContext;<br>  crashContext-&gt;stackCursor = &stackCursor;</p><p>  kscm_handleException(crashContext);<br>  ksmc_resumeEnvironment();</p><p>  KSLOG_DEBUG(@”Calling abort()”);<br>  abort();<br>}</p></li></ul><p>其他几个 crash 也是一样，异常信息经过包装交给 <code>kscm_handleException()</code> 函数处理。可以看到这个函数被其他几种 crash 捕获后所调用。</p><p><img src="https://segmentfault.com/img/bVbIOkD"></p><p>/** Start general exception processing.<br> *<br> * @oaram context Contextual information about the exception.<br> */<br>void kscm_handleException(struct KSCrash_MonitorContext* context)<br>{<br>    context-&gt;requiresAsyncSafety = g_requiresAsyncSafety;<br>    if(g_crashedDuringExceptionHandling)<br>    {<br>        context-&gt;crashedDuringCrashHandling = true;<br>    }<br>    for(int i = 0; i &lt; g_monitorsCount; i++)<br>    {<br>        Monitor* monitor = &amp;g_monitors[i];<br>        // 判断当前的 crash 监控是开启状态<br>        if(isMonitorEnabled(monitor))<br>        {<br>            // 针对每种 crash 类型做一些额外的补充信息<br>            addContextualInfoToEvent(monitor, context);<br>        }<br>    }<br>    // 真正处理 crash 信息，保存 json 格式的 crash 信息<br>    g_onExceptionEvent(context);</p><pre><code>if(g\_handlingFatalException &amp;&amp; !g\_crashedDuringExceptionHandling)&#123;    KSLOG\_DEBUG(&quot;Exception is fatal. Restoring original handlers.&quot;);    kscm\_setActiveMonitors(KSCrashMonitorTypeNone);&#125;</code></pre><p>}</p><p><code>g_onExceptionEvent</code> 是一个 block，声明为 <code>static void (*g_onExceptionEvent)(struct KSCrash_MonitorContext* monitorContext);</code> 在 <code>KSCrashMonitor.c</code> 中被赋值</p><p>void kscm_setEventCallback(void (*onEvent)(struct KSCrash_MonitorContext* monitorContext))<br>{<br>    g_onExceptionEvent = onEvent;<br>}</p><p><code>kscm_setEventCallback()</code> 函数在 <code>KSCrashC.c</code> 文件中被调用</p><p>KSCrashMonitorType kscrash_install(const char* appName, const char* const installPath)<br>{<br>    KSLOG_DEBUG(“Installing crash reporter.”);</p><pre><code>if(g\_installed)&#123;    KSLOG\_DEBUG(&quot;Crash reporter already installed.&quot;);    return g\_monitoring;&#125;g\_installed = 1;char path\[KSFU\_MAX\_PATH\_LENGTH\];snprintf(path, sizeof(path), &quot;%s/Reports&quot;, installPath);ksfu\_makePath(path);kscrs\_initialize(appName, path);snprintf(path, sizeof(path), &quot;%s/Data&quot;, installPath);ksfu\_makePath(path);snprintf(path, sizeof(path), &quot;%s/Data/CrashState.json&quot;, installPath);kscrashstate\_initialize(path);snprintf(g\_consoleLogPath, sizeof(g\_consoleLogPath), &quot;%s/Data/ConsoleLog.txt&quot;, installPath);if(g\_shouldPrintPreviousLog)&#123;    printPreviousLog(g\_consoleLogPath);&#125;kslog\_setLogFilename(g\_consoleLogPath, true);ksccd\_init(60);// 设置 crash 发生时的 callback 函数kscm\_setEventCallback(onCrash);KSCrashMonitorType monitors = kscrash\_setMonitoring(g\_monitoring);KSLOG\_DEBUG(&quot;Installation complete.&quot;);return monitors;</code></pre><p>}</p><p>/** Called when a crash occurs.<br> *<br> * This function gets passed as a callback to a crash handler.<br> */<br>static void onCrash(struct KSCrash_MonitorContext* monitorContext)<br>{<br>    KSLOG_DEBUG(“Updating application state to note crash.”);<br>    kscrashstate_notifyAppCrash();<br>    monitorContext-&gt;consoleLogPath = g_shouldAddConsoleLogToReport ? g_consoleLogPath : NULL;</p><pre><code>// 正在处理 crash 的时候，发生了再次 crashif(monitorContext-&gt;crashedDuringCrashHandling)&#123;    kscrashreport\_writeRecrashReport(monitorContext, g\_lastCrashReportFilePath);&#125;else&#123;    // 1. 先根据当前时间创建新的 crash 的文件路径    char crashReportFilePath\[KSFU\_MAX\_PATH\_LENGTH\];    kscrs\_getNextCrashReportPath(crashReportFilePath);    // 2. 将新生成的文件路径保存到 g\_lastCrashReportFilePath    strncpy(g\_lastCrashReportFilePath, crashReportFilePath, sizeof(g\_lastCrashReportFilePath));    // 3. 将新生成的文件路径传入函数进行 crash 写入    kscrashreport\_writeStandardReport(monitorContext, crashReportFilePath);&#125;</code></pre><p>}</p><p>接下来的函数就是具体的日志写入文件的实现。2个函数做的事情相似，都是格式化为 json 形式并写入文件。区别在于 crash 写入时如果再次发生 crash， 则走简易版的写入逻辑 <code>kscrashreport_writeRecrashReport()</code>，否则走标准的写入逻辑 <code>kscrashreport_writeStandardReport()</code>。</p><p>bool ksfu_openBufferedWriter(KSBufferedWriter* writer, const char* const path, char* writeBuffer, int writeBufferLength)<br>{<br>    writer-&gt;buffer = writeBuffer;<br>    writer-&gt;bufferLength = writeBufferLength;<br>    writer-&gt;position = 0;<br>    /*<br>     open() 的第二个参数描述的是文件操作的权限<br>     #define O_RDONLY        0x0000         open for reading only<br>     #define O_WRONLY        0x0001         open for writing only<br>     #define O_RDWR          0x0002         open for reading and writing<br>     #define O_ACCMODE       0x0003         mask for above mode</p><pre><code> #define O\_CREAT         0x0200         create if nonexistant #define O\_TRUNC         0x0400         truncate to zero length #define O\_EXCL          0x0800         error if already exists 0755：即用户具有读/写/执行权限，组用户和其它用户具有读写权限； 0644：即用户具有读写权限，组用户和其它用户具有只读权限； 成功则返回文件描述符，若出现则返回 -1 \*/writer-&gt;fd = open(path, O\_RDWR | O\_CREAT | O\_EXCL, 0644);if(writer-&gt;fd &lt; 0)&#123;    KSLOG\_ERROR(&quot;Could not open crash report file %s: %s&quot;, path, strerror(errno));    return false;&#125;return true;</code></pre><p>}</p><p>/**<br> * Write a standard crash report to a file.<br> *<br> *  @param monitorContext Contextual information about the crash and environment.<br> *                      The caller must fill this out before passing it in.<br> *<br> *  @param path The file to write to.<br> */<br>void kscrashreport_writeStandardReport(const struct KSCrash_MonitorContext* const monitorContext,<br>                                       const char* path)<br>{<br>        KSLOG_INFO(“Writing crash report to %s”, path);<br>    char writeBuffer[1024];<br>    KSBufferedWriter bufferedWriter;</p><pre><code>if(!ksfu\_openBufferedWriter(&amp;bufferedWriter, path, writeBuffer, sizeof(writeBuffer)))&#123;    return;&#125;ksccd\_freeze();KSJSONEncodeContext jsonContext;jsonContext.userData = &amp;bufferedWriter;KSCrashReportWriter concreteWriter;KSCrashReportWriter\* writer = &amp;concreteWriter;prepareReportWriter(writer, &amp;jsonContext);ksjson\_beginEncode(getJsonContext(writer), true, addJSONData, &amp;bufferedWriter);writer-&gt;beginObject(writer, KSCrashField\_Report);&#123;    writeReportInfo(writer,                    KSCrashField\_Report,                    KSCrashReportType\_Standard,                    monitorContext-&gt;eventID,                    monitorContext-&gt;System.processName);    ksfu\_flushBufferedWriter(&amp;bufferedWriter);    writeBinaryImages(writer, KSCrashField\_BinaryImages);    ksfu\_flushBufferedWriter(&amp;bufferedWriter);    writeProcessState(writer, KSCrashField\_ProcessState, monitorContext);    ksfu\_flushBufferedWriter(&amp;bufferedWriter);    writeSystemInfo(writer, KSCrashField\_System, monitorContext);    ksfu\_flushBufferedWriter(&amp;bufferedWriter);    writer-&gt;beginObject(writer, KSCrashField\_Crash);    &#123;        writeError(writer, KSCrashField\_Error, monitorContext);        ksfu\_flushBufferedWriter(&amp;bufferedWriter);        writeAllThreads(writer,                        KSCrashField\_Threads,                        monitorContext,                        g\_introspectionRules.enabled);        ksfu\_flushBufferedWriter(&amp;bufferedWriter);    &#125;    writer-&gt;endContainer(writer);    if(g\_userInfoJSON != NULL)    &#123;        addJSONElement(writer, KSCrashField\_User, g\_userInfoJSON, false);        ksfu\_flushBufferedWriter(&amp;bufferedWriter);    &#125;    else    &#123;        writer-&gt;beginObject(writer, KSCrashField\_User);    &#125;    if(g\_userSectionWriteCallback != NULL)    &#123;        ksfu\_flushBufferedWriter(&amp;bufferedWriter);        g\_userSectionWriteCallback(writer);    &#125;    writer-&gt;endContainer(writer);    ksfu\_flushBufferedWriter(&amp;bufferedWriter);    writeDebugInfo(writer, KSCrashField\_Debug, monitorContext);&#125;writer-&gt;endContainer(writer);ksjson\_endEncode(getJsonContext(writer));ksfu\_closeBufferedWriter(&amp;bufferedWriter);ksccd\_unfreeze();</code></pre><p>}</p><p>/** Write a minimal crash report to a file.<br> *<br> * @param monitorContext Contextual information about the crash and environment.<br> *                       The caller must fill this out before passing it in.<br> *<br> * @param path The file to write to.<br> */<br>void kscrashreport_writeRecrashReport(const struct KSCrash_MonitorContext* const monitorContext,<br>                                      const char* path)<br>{<br>  char writeBuffer[1024];<br>    KSBufferedWriter bufferedWriter;<br>    static char tempPath[KSFU_MAX_PATH_LENGTH];<br>    // 将传递过来的上份 crash report 文件名路径（/var/mobile/Containers/Data/Application/******/Library/Caches/KSCrash/Test/Reports/Test-report-******.json）修改为去掉 .json ，加上 .old 成为新的文件路径 /var/mobile/Containers/Data/Application/******/Library/Caches/KSCrash/Test/Reports/Test-report-******.old</p><pre><code>strncpy(tempPath, path, sizeof(tempPath) - 10);strncpy(tempPath + strlen(tempPath) - 5, &quot;.old&quot;, 5);KSLOG\_INFO(&quot;Writing recrash report to %s&quot;, path);if(rename(path, tempPath) &lt; 0)&#123;    KSLOG\_ERROR(&quot;Could not rename %s to %s: %s&quot;, path, tempPath, strerror(errno));&#125;// 根据传入路径来打开内存写入需要的文件if(!ksfu\_openBufferedWriter(&amp;bufferedWriter, path, writeBuffer, sizeof(writeBuffer)))&#123;    return;&#125;ksccd\_freeze();// json 解析的 c 代码KSJSONEncodeContext jsonContext;jsonContext.userData = &amp;bufferedWriter;KSCrashReportWriter concreteWriter;KSCrashReportWriter\* writer = &amp;concreteWriter;prepareReportWriter(writer, &amp;jsonContext);ksjson\_beginEncode(getJsonContext(writer), true, addJSONData, &amp;bufferedWriter);writer-&gt;beginObject(writer, KSCrashField\_Report);&#123;    writeRecrash(writer, KSCrashField\_RecrashReport, tempPath);    ksfu\_flushBufferedWriter(&amp;bufferedWriter);    if(remove(tempPath) &lt; 0)    &#123;        KSLOG\_ERROR(&quot;Could not remove %s: %s&quot;, tempPath, strerror(errno));    &#125;    writeReportInfo(writer,                    KSCrashField\_Report,                    KSCrashReportType\_Minimal,                    monitorContext-&gt;eventID,                    monitorContext-&gt;System.processName);    ksfu\_flushBufferedWriter(&amp;bufferedWriter);    writer-&gt;beginObject(writer, KSCrashField\_Crash);    &#123;        writeError(writer, KSCrashField\_Error, monitorContext);        ksfu\_flushBufferedWriter(&amp;bufferedWriter);        int threadIndex = ksmc\_indexOfThread(monitorContext-&gt;offendingMachineContext,                                             ksmc\_getThreadFromContext(monitorContext-&gt;offendingMachineContext));        writeThread(writer,                    KSCrashField\_CrashedThread,                    monitorContext,                    monitorContext-&gt;offendingMachineContext,                    threadIndex,                    false);        ksfu\_flushBufferedWriter(&amp;bufferedWriter);    &#125;    writer-&gt;endContainer(writer);&#125;writer-&gt;endContainer(writer);ksjson\_endEncode(getJsonContext(writer));ksfu\_closeBufferedWriter(&amp;bufferedWriter);ksccd\_unfreeze();</code></pre><p>}</p><h5 id="2-6-2-Crash-日志的读取逻辑"><a href="#2-6-2-Crash-日志的读取逻辑" class="headerlink" title="2.6.2 Crash 日志的读取逻辑"></a>2.6.2 Crash 日志的读取逻辑</h5><p>当前 App 在 Crash 之后，KSCrash 将数据保存到 App 沙盒目录下，App 下次启动后我们读取存储的 crash 文件，然后处理数据并上传。</p><p>App 启动后函数调用：</p><p><code>[KSCrashInstallation sendAllReportsWithCompletion:]</code> -&gt; <code>[KSCrash sendAllReportsWithCompletion:]</code> -&gt; <code>[KSCrash allReports]</code> -&gt; <code>[KSCrash reportWithIntID:]</code> -&gt;<code>[KSCrash loadCrashReportJSONWithID:]</code> -&gt; <code>kscrs_readReport</code></p><p>在 <code>sendAllReportsWithCompletion</code> 里读取沙盒里的Crash 数据。</p><p>// 先通过读取文件夹，遍历文件夹内的文件数量来判断 crash 报告的个数<br>static int getReportCount()<br>{<br>    int count = 0;<br>    DIR* dir = opendir(g_reportsPath);<br>    if(dir == NULL)<br>    {<br>        KSLOG_ERROR(“Could not open directory %s”, g_reportsPath);<br>        goto done;<br>    }<br>    struct dirent* ent;<br>    while((ent = readdir(dir)) != NULL)<br>    {<br>        if(getReportIDFromFilename(ent-&gt;d_name) &gt; 0)<br>        {<br>            count++;<br>        }<br>    }</p><p>done:<br>    if(dir != NULL)<br>    {<br>        closedir(dir);<br>    }<br>    return count;<br>}</p><p>// 通过 crash 文件个数、文件夹信息去遍历，一次获取到文件名（文件名的最后一部分就是 reportID），拿到 reportID 再去读取 crash 报告内的文件内容，写入数组</p><ul><li><p>(NSArray*) allReports<br>{<br>  int reportCount = kscrash_getReportCount();<br>  int64_t reportIDs[reportCount];<br>  reportCount = kscrash_getReportIDs(reportIDs, reportCount);<br>  NSMutableArray* reports = [NSMutableArray arrayWithCapacity:(NSUInteger)reportCount];<br>  for(int i = 0; i &lt; reportCount; i++)<br>  {</p><pre><code>  NSDictionary\* report = \[self reportWithIntID:reportIDs\[i\]\];  if(report != nil)  &#123;      \[reports addObject:report\];  &#125;</code></pre><p>  }</p><p>  return reports;<br>}</p></li></ul><p>//  根据 reportID 找到 crash 信息</p><ul><li><p>(NSDictionary*) reportWithIntID:(int64_t) reportID<br>{<br>  NSData* jsonData = [self loadCrashReportJSONWithID:reportID];<br>  if(jsonData == nil)<br>  {</p><pre><code>  return nil;</code></pre><p>  }</p><p>  NSError* error = nil;<br>  NSMutableDictionary* crashReport = [KSJSONCodec decode:jsonData</p><pre><code>                                             options:KSJSONDecodeOptionIgnoreNullInArray |                                                     KSJSONDecodeOptionIgnoreNullInObject |                                                     KSJSONDecodeOptionKeepPartialObject                                               error:&amp;error\];</code></pre><p>  if(error != nil)<br>  {</p><pre><code>  KSLOG\_ERROR(@&quot;Encountered error loading crash report %&quot; PRIx64 &quot;: %@&quot;, reportID, error);</code></pre><p>  }<br>  if(crashReport == nil)<br>  {</p><pre><code>  KSLOG\_ERROR(@&quot;Could not load crash report&quot;);  return nil;</code></pre><p>  }<br>  [self doctorReport:crashReport];</p><p>  return crashReport;<br>}</p></li></ul><p>//  reportID 读取 crash 内容并转换为 NSData 类型</p><ul><li>(NSData*) loadCrashReportJSONWithID:(int64_t) reportID<br>{<br>  char* report = kscrash_readReport(reportID);<br>  if(report != NULL)<br>  {<pre><code>  return \[NSData dataWithBytesNoCopy:report length:strlen(report) freeWhenDone:YES\];</code></pre>  }<br>  return nil;<br>}</li></ul><p>// reportID 读取 crash 数据到 char 类型<br>char* kscrash_readReport(int64_t reportID)<br>{<br>    if(reportID &lt;= 0)<br>    {<br>        KSLOG_ERROR(“Report ID was %” PRIx64, reportID);<br>        return NULL;<br>    }</p><pre><code>char\* rawReport = kscrs\_readReport(reportID);if(rawReport == NULL)&#123;    KSLOG\_ERROR(&quot;Failed to load report ID %&quot; PRIx64, reportID);    return NULL;&#125;char\* fixedReport = kscrf\_fixupCrashReport(rawReport);if(fixedReport == NULL)&#123;    KSLOG\_ERROR(&quot;Failed to fixup report ID %&quot; PRIx64, reportID);&#125;free(rawReport);return fixedReport;</code></pre><p>}</p><p>// 多线程加锁，通过 reportID 执行 c 函数 getCrashReportPathByID，将路径设置到 path 上。然后执行 ksfu_readEntireFile 读取 crash 信息到 result<br>char* kscrs_readReport(int64_t reportID)<br>{<br>    pthread_mutex_lock(&amp;g_mutex);<br>    char path[KSCRS_MAX_PATH_LENGTH];<br>    getCrashReportPathByID(reportID, path);<br>    char* result;<br>    ksfu_readEntireFile(path, &amp;result, NULL, 2000000);<br>    pthread_mutex_unlock(&amp;g_mutex);<br>    return result;<br>}</p><p>int kscrash_getReportIDs(int64_t* reportIDs, int count)<br>{<br>    return kscrs_getReportIDs(reportIDs, count);<br>}</p><p>int kscrs_getReportIDs(int64_t* reportIDs, int count)<br>{<br>    pthread_mutex_lock(&amp;g_mutex);<br>    count = getReportIDs(reportIDs, count);<br>    pthread_mutex_unlock(&amp;g_mutex);<br>    return count;<br>}<br>// 循环读取文件夹内容，根据 ent-&gt;d_name 调用 getReportIDFromFilename 函数，来获取 reportID，循环内部填充数组<br>static int getReportIDs(int64_t* reportIDs, int count)<br>{<br>    int index = 0;<br>    DIR* dir = opendir(g_reportsPath);<br>    if(dir == NULL)<br>    {<br>        KSLOG_ERROR(“Could not open directory %s”, g_reportsPath);<br>        goto done;<br>    }</p><pre><code>struct dirent\* ent;while((ent = readdir(dir)) != NULL &amp;&amp; index &lt; count)&#123;    int64\_t reportID = getReportIDFromFilename(ent-&gt;d\_name);    if(reportID &gt; 0)    &#123;        reportIDs\[index++\] = reportID;    &#125;&#125;qsort(reportIDs, (unsigned)count, sizeof(reportIDs\[0\]), compareInt64);</code></pre><p>done:<br>    if(dir != NULL)<br>    {<br>        closedir(dir);<br>    }<br>    return index;<br>}</p><p>// sprintf(参数1， 格式2) 函数将格式2的值返回到参数1上，然后执行 sscanf(参数1， 参数2， 参数3)，函数将字符串参数1的内容，按照参数2的格式，写入到参数3上。crash 文件命名为 “App名称-report-reportID.json”<br>static int64_t getReportIDFromFilename(const char* filename)<br>{<br>    char scanFormat[100];<br>    sprintf(scanFormat, “%s-report-%%” PRIx64 “.json”, g_appName);</p><pre><code>int64\_t reportID = 0;sscanf(filename, scanFormat, &amp;reportID);return reportID;</code></pre><p>}</p><p><img src="https://segmentfault.com/img/bVbIOkN"></p><h4 id="2-7-前端-js-相关的-Crash-的监控"><a href="#2-7-前端-js-相关的-Crash-的监控" class="headerlink" title="2.7 前端 js 相关的 Crash 的监控"></a>2.7 前端 js 相关的 Crash 的监控</h4><h5 id="2-7-1-JavascriptCore-异常监控"><a href="#2-7-1-JavascriptCore-异常监控" class="headerlink" title="2.7.1 JavascriptCore 异常监控"></a>2.7.1 JavascriptCore 异常监控</h5><p>这部分简单粗暴，直接通过 JSContext 对象的 exceptionHandler 属性来监控，比如下面的代码</p><p>jsContext.exceptionHandler = ^(JSContext *context, JSValue *exception) {<br>    // 处理 jscore 相关的异常信息<br>};</p><h5 id="2-7-2-h5-页面异常监控"><a href="#2-7-2-h5-页面异常监控" class="headerlink" title="2.7.2 h5 页面异常监控"></a>2.7.2 h5 页面异常监控</h5><p>当 h5 页面内的 Javascript 运行异常时会 window 对象会触发 <code>ErrorEvent</code> 接口的 error 事件，并执行 <code>window.onerror()</code>。</p><p>window.onerror = function (msg, url, lineNumber, columnNumber, error) {<br>   // 处理异常信息<br>};</p><p><img src="https://segmentfault.com/img/bVbIOkO"></p><h5 id="2-7-3-React-Native-异常监控"><a href="#2-7-3-React-Native-异常监控" class="headerlink" title="2.7.3 React Native 异常监控"></a>2.7.3 React Native 异常监控</h5><p>小实验：下图是写了一个 RN Demo 工程，在 Debug Text 控件上加了事件监听代码，内部人为触发 crash</p><p>&lt;Text style={styles.sectionTitle} onPress={()=&gt;{1+qw;}}&gt;Debug&lt;/Text&gt;</p><p>对比组1：</p><p>条件： iOS 项目 debug 模式。在 RN 端增加了异常处理的代码。</p><p>模拟器点击 <code>command + d</code> 调出面板，选择 Debug，打开 Chrome 浏览器， Mac 下快捷键 <code>Command + Option + J</code> 打开调试面板，就可以像调试 React 一样调试 RN 代码了。</p><p>查看到 crash stack 后点击可以跳转到 sourceMap 的地方。</p><p>Tips：RN 项目打 Release 包</p><ul><li><p>  在项目根目录下创建文件夹（ release_iOS），作为资源的输出文件夹</p></li><li><p>在终端切换到工程目录，然后执行下面的代码</p><p>  react-native bundle –entry-file index.js –platform ios –dev false –bundle-output release_ios/main.jsbundle –assets-dest release_iOS –sourcemap-output release_ios/index.ios.map;</p></li><li><p>  将 release_iOS 文件夹内的 <code>.jsbundle</code> 和 <code>assets</code> 文件夹内容拖入到 iOS 工程中即可</p></li></ul><p>对比组2：</p><p>条件：iOS 项目 release 模式。在 RN 端不增加异常处理代码</p><p>操作：运行 iOS 工程，点击按钮模拟 crash</p><p>现象：iOS 项目奔溃。截图以及日志如下</p><p><img src="https://segmentfault.com/img/bVbIOkX"></p><p>2020-06-22 22:26:03.318 [info][tid:main][RCTRootView.m:294] Running application todos ({<br>    initialProps =     {<br>    };<br>    rootTag = 1;<br>})<br>2020-06-22 22:26:03.490 [info][tid:com.facebook.react.JavaScript] Running “todos” with {“rootTag”:1,”initialProps”:{}}<br>2020-06-22 22:27:38.673 [error][tid:com.facebook.react.JavaScript] ReferenceError: Can’t find variable: qw<br>2020-06-22 22:27:38.675 [fatal][tid:com.facebook.react.ExceptionsManagerQueue] Unhandled JS Exception: ReferenceError: Can’t find variable: qw<br>2020-06-22 22:27:38.691300+0800 todos[16790:314161] *** Terminating app due to uncaught exception ‘RCTFatalException: Unhandled JS Exception: ReferenceError: Can’t find variable: qw’, reason: ‘Unhandled JS Exception: ReferenceError: Can’t find variable: qw, stack:<br>onPress@397:1821<br><unknown>@203:3896<br>_performSideEffectsForTransition@210:9689<br>_performSideEffectsForTransition@(null):(null)<br>_receiveSignal@210:8425<br>_receiveSignal@(null):(null)<br>touchableHandleResponderRelease@210:5671<br>touchableHandleResponderRelease@(null):(null)<br>onResponderRelease@203:3006<br>b@97:1125<br>S@97:1268<br>w@97:1322<br>R@97:1617<br>M@97:2401<br>forEach@(null):(null)<br>U@97:2201<br><unknown>@97:13818<br>Pe@97:90199<br>Re@97:13478<br>Ie@97:13664<br>receiveTouches@97:14448<br>value@27:3544<br><unknown>@27:840<br>value@27:2798<br>value@27:812<br>value@(null):(null)<br>‘<br>*** First throw call stack:<br>(<br>    0   CoreFoundation                      0x00007fff23e3cf0e __exceptionPreprocess + 350<br>    1   libobjc.A.dylib                     0x00007fff50ba89b2 objc_exception_throw + 48<br>    2   todos                               0x00000001017b0510 RCTFormatError + 0<br>    3   todos                               0x000000010182d8ca -[RCTExceptionsManager reportFatal:stack:exceptionId:suppressRedBox:] + 503<br>    4   todos                               0x000000010182e34e -[RCTExceptionsManager reportException:] + 1658<br>    5   CoreFoundation                      0x00007fff23e43e8c __invoking___ + 140<br>    6   CoreFoundation                      0x00007fff23e41071 -[NSInvocation invoke] + 321<br>    7   CoreFoundation                      0x00007fff23e41344 -[NSInvocation invokeWithTarget:] + 68<br>    8   todos                               0x00000001017e07fa -[RCTModuleMethod invokeWithBridge:module:arguments:] + 578<br>    9   todos                               0x00000001017e2a84 _ZN8facebook5reactL11invokeInnerEP9RCTBridgeP13RCTModuleDatajRKN5folly7dynamicE + 246<br>    10  todos                               0x00000001017e280c ___ZN8facebook5react15RCTNativeModule6invokeEjON5folly7dynamicEi_block_invoke + 78<br>    11  libdispatch.dylib                   0x00000001025b5f11 _dispatch_call_block_and_release + 12<br>    12  libdispatch.dylib                   0x00000001025b6e8e _dispatch_client_callout + 8<br>    13  libdispatch.dylib                   0x00000001025bd6fd _dispatch_lane_serial_drain + 788<br>    14  libdispatch.dylib                   0x00000001025be28f _dispatch_lane_invoke + 422<br>    15  libdispatch.dylib                   0x00000001025c9b65 _dispatch_workloop_worker_thread + 719<br>    16  libsystem_pthread.dylib             0x00007fff51c08a3d _pthread_wqthread + 290<br>    17  libsystem_pthread.dylib             0x00007fff51c07b77 start_wqthread + 15<br>)<br>libc++abi.dylib: terminating with uncaught exception of type NSException<br>(lldb) </p><p>Tips：如何在 RN release 模式下调试（看到 js 侧的 console 信息）</p><ul><li>  在 <code>AppDelegate.m</code> 中引入 <code>#import &lt;React/RCTLog.h&gt;</code></li><li>  在 <code>- (BOOL)application:(UIApplication *)application didFinishLaunchingWithOptions:(NSDictionary *)launchOptions</code> 中加入 <code>RCTSetLogThreshold(RCTLogLevelTrace);</code></li></ul><p>对比组3：</p><p>条件：iOS 项目 release 模式。在 RN 端增加异常处理代码。</p><p>global.ErrorUtils.setGlobalHandler((e) =&gt; {<br>  console.log(e);<br>  let message = { name: e.name,<br>                message: e.message,<br>                stack: e.stack<br>  };<br>  axios.get(‘<a href="http://192.168.1.100:8888/test.php&#39;">http://192.168.1.100:8888/test.php&#39;</a>, {<br>      params: { ‘message’: JSON.stringify(message) }<br>  }).then(function (response) {<br>          console.log(response)<br>  }).catch(function (error) {<br>  console.log(error)<br>  });<br>}, true)</p><p>操作：运行 iOS 工程，点击按钮模拟 crash。</p><p>现象：iOS 项目不奔溃。日志信息如下，对比 bundle 包中的 js。</p><p><img src="https://segmentfault.com/img/bVbIOk9"></p><p>结论：</p><p>在 RN 项目中，如果发生了 crash 则会在 Native 侧有相应体现。如果 RN 侧写了 crash 捕获的代码，则 Native 侧不会奔溃。如果 RN 侧的 crash 没有捕获，则 Native 直接奔溃。</p><p>RN 项目写了 crash 监控，监控后将堆栈信息打印出来发现对应的 js 信息是经过 webpack 处理的，crash 分析难度很大。所以我们针对 RN 的 crash 需要在 RN 侧写监控代码，监控后需要上报，此外针对监控后的信息需要写专门的 crash 信息还原给你，也就是 sourceMap 解析。</p><h6 id="2-7-3-1-js-逻辑错误"><a href="#2-7-3-1-js-逻辑错误" class="headerlink" title="2.7.3.1 js 逻辑错误"></a>2.7.3.1 js 逻辑错误</h6><p>写过 RN 的人都知道在 DEBUG 模式下 js 代码有问题则会产生红屏，在 RELEASE 模式下则会白屏或者闪退，为了体验和质量把控需要做异常监控。</p><p>在看 RN 源码时候发现了 <code>ErrorUtils</code>，看代码可以设置处理错误信息。</p><p>/**<br> * Copyright (c) Facebook, Inc. and its affiliates.<br> *<br> * This source code is licensed under the MIT license found in the<br> * LICENSE file in the root directory of this source tree.<br> *<br> * @format<br> * @flow strict<br> * @polyfill<br> */</p><p>let _inGuard = 0;</p><p>type ErrorHandler = (error: mixed, isFatal: boolean) =&gt; void;<br>type Fn&lt;Args, Return&gt; = (…Args) =&gt; Return;</p><p>/**<br> * This is the error handler that is called when we encounter an exception<br> * when loading a module. This will report any errors encountered before<br> * ExceptionsManager is configured.<br> */<br>let _globalHandler: ErrorHandler = function onError( e: mixed,<br>  isFatal: boolean, ) {<br>  throw e;<br>};</p><p>/**<br> * The particular require runtime that we are using looks for a global<br> * `ErrorUtils` object and if it exists, then it requires modules with the<br> * error handler specified via ErrorUtils.setGlobalHandler by calling the<br> * require function with applyWithGuard. Since the require module is loaded<br> * before any of the modules, this ErrorUtils must be defined (and the handler<br> * set) globally before requiring anything.<br> */<br>const ErrorUtils = {<br>  setGlobalHandler(fun: ErrorHandler): void {<br>    _globalHandler = fun;<br>  },<br>  getGlobalHandler(): ErrorHandler {<br>    return _globalHandler;<br>  },<br>  reportError(error: mixed): void {<br>    _globalHandler &amp;&amp; _globalHandler(error, false);<br>  },<br>  reportFatalError(error: mixed): void {<br>    // NOTE: This has an untyped call site in Metro.<br>    _globalHandler &amp;&amp; _globalHandler(error, true);<br>  },<br>  applyWithGuard&lt;TArgs: $ReadOnlyArray<mixed>, TOut&gt;(<br>    fun: Fn&lt;TArgs, TOut&gt;,<br>    context?: ?mixed,<br>    args?: ?TArgs,<br>    // Unused, but some code synced from www sets it to null.<br>    unused_onError?: null,<br>    // Some callers pass a name here, which we ignore.<br>    unused_name?: ?string,<br>  ): ?TOut {<br>    try {<br>      _inGuard++;<br>      // $FlowFixMe: TODO T48204745 (1) apply(context, null) is fine. (2) array -&gt; rest array should work<br>      return fun.apply(context, args);<br>    } catch (e) {<br>      ErrorUtils.reportError(e);<br>    } finally {<br>      _inGuard–;<br>    }<br>    return null;<br>  },<br>  applyWithGuardIfNeeded&lt;TArgs: $ReadOnlyArray<mixed>, TOut&gt;(<br>    fun: Fn&lt;TArgs, TOut&gt;,<br>    context?: ?mixed,<br>    args?: ?TArgs,<br>  ): ?TOut {<br>    if (ErrorUtils.inGuard()) {<br>      // $FlowFixMe: TODO T48204745 (1) apply(context, null) is fine. (2) array -&gt; rest array should work<br>      return fun.apply(context, args);<br>    } else {<br>      ErrorUtils.applyWithGuard(fun, context, args);<br>    }<br>    return null;<br>  },<br>  inGuard(): boolean {<br>    return !!_inGuard;<br>  },<br>  guard&lt;TArgs: $ReadOnlyArray<mixed>, TOut&gt;(<br>    fun: Fn&lt;TArgs, TOut&gt;,<br>    name?: ?string,<br>    context?: ?mixed,<br>  ): ?(…TArgs) =&gt; ?TOut {<br>    // TODO: (moti) T48204753 Make sure this warning is never hit and remove it - types<br>    // should be sufficient.<br>    if (typeof fun !== ‘function’) {<br>      console.warn(‘A function must be passed to ErrorUtils.guard, got ‘, fun);<br>      return null;<br>    }<br>    const guardName = name ?? fun.name ?? ‘<generated guard>‘;<br>    function guarded(…args: TArgs): ?TOut {<br>      return ErrorUtils.applyWithGuard(<br>        fun,<br>        context ?? this,<br>        args,<br>        null,<br>        guardName,<br>      );<br>    }</p><pre><code>return guarded;</code></pre><p>  },<br>};</p><p>global.ErrorUtils = ErrorUtils;</p><p>export type ErrorUtilsT = typeof ErrorUtils;</p><p>所以 RN 的异常可以使用 <code>global.ErrorUtils</code> 来设置错误处理。举个例子</p><p>global.ErrorUtils.setGlobalHandler(e =&gt; {<br>   // e.name e.message e.stack<br>}, true);</p><h6 id="2-7-3-2-组件问题"><a href="#2-7-3-2-组件问题" class="headerlink" title="2.7.3.2 组件问题"></a>2.7.3.2 组件问题</h6><p>其实对于 RN 的 crash 处理还有个需要注意的就是 <strong>React Error Boundaries</strong>。<a href="https://link.segmentfault.com/?enc=pryYiUIXt6rDMGiBW9JdrA==.m0P9N0YFY2i5YfbUeQ3tNbz+v2HXBviSU/EGkeGwkl7Fc1Aj96LYcBtAFcW4WJbnHu/Rjtl+A+CX/DLsjgJCAw==">详细资料</a></p><blockquote><p>过去，组件内的 JavaScript 错误会导致 React 的内部状态被破坏，并且在下一次渲染时 <a href="https://link.segmentfault.com/?enc=+LL4iGAJU9MD0cUXcZy1VA==.2F/oGJUCX0ff9hXmb2uYfiOBp8YAXVdK2oHwA1wPhCIo/Xas7UOC6IoywXqhn9EG">产生</a> <a href="https://link.segmentfault.com/?enc=7dOxkzsfnRZKbyVDhQABvw==.3rdyWD6oNR35X8Plfr1hv4kEcLcD9nB7/USWO4ck9QCl2eyv0i5RuSPqmFesUTgV">可能无法追踪的</a> <a href="https://link.segmentfault.com/?enc=j4GzfPPN8psI9QIBipaswA==.foxVhlbMGnly4jHG/uBHeYEQ/j8DTTnrqzGyzMQJcQeWcBwyuNjZaEOVJU8ylyqv">错误</a>。这些错误基本上是由较早的其他代码（非 React 组件代码）错误引起的，但 React 并没有提供一种在组件中优雅处理这些错误的方式，也无法从错误中恢复。</p><p>部分 UI 的 JavaScript 错误不应该导致整个应用崩溃，为了解决这个问题，React 16 引入了一个新的概念 —— 错误边界。</p><p>错误边界是一种 React 组件，这种组件<strong>可以捕获并打印发生在其子组件树任何位置的 JavaScript 错误，并且，它会渲染出备用 UI</strong>，而不是渲染那些崩溃了的子组件树。错误边界在渲染期间、生命周期方法和整个组件树的构造函数中捕获错误。</p></blockquote><p>它能捕获子组件生命周期函数中的异常，包括构造函数（constructor）和 render 函数</p><p>而不能捕获以下异常：</p><ul><li>  Event handlers（事件处理函数）</li><li>  Asynchronous code（异步代码，如setTimeout、promise等）</li><li>  Server side rendering（服务端渲染）</li><li>  Errors thrown in the error boundary itself (rather than its children)（异常边界组件本身抛出的异常）</li></ul><p>所以可以通过异常边界组件捕获组件生命周期内的所有异常然后渲染兜底组件 ，防止 App crash，提高用户体验。也可引导用户反馈问题，方便问题的排查和修复</p><p>至此 RN 的 crash 分为2种，分别是 js 逻辑错误、组件 js 错误，都已经被监控处理了。接下来就看看如何从工程化层面解决这些问题</p><h5 id="2-7-4-RN-Crash-还原"><a href="#2-7-4-RN-Crash-还原" class="headerlink" title="2.7.4 RN Crash 还原"></a>2.7.4 RN Crash 还原</h5><p>SourceMap 文件对于前端日志的解析至关重要，SourceMap 文件中各个参数和如何计算的步骤都在里面有写，可以查看<a href="https://link.segmentfault.com/?enc=lqiIX9uf0T1epu78J0gMgw==.pFeUKkKaFchytJc+k6N9CiVIXf+Zzdo/IXobGvd9lG9/BsxgN/VLg2E8JDIHq5RaxvB9mG4FtsbHKdGuvlcx5aHf52FIeYmsLA0QJeBQG3WdAjdo8ozUy257Y33FfaDk">这篇文章</a>。</p><p>有了 SourceMap 文件，借助于 <a href="https://link.segmentfault.com/?enc=xxCynZ245I7o4l2TUjBHjA==.6aGTndpktKHB4Vx3d8dlszqp+ujJC8og3LAhDdL0c7s=">mozilla</a> 的 <a href="https://link.segmentfault.com/?enc=+gvuXOyReT1RLpCGgzsiqQ==.GgVByZjqibYalVB7iwMXK5MHsJbVAU/d+GeQlMviGFlM1ytvmQeMtU2G0EcmEC+E">source-map</a> 项目，可以很好的还原 RN 的 crash 日志。</p><p>我写了个 NodeJS 脚本，代码如下</p><p>var fs = require(‘fs’);<br>var sourceMap = require(‘source-map’);<br>var arguments = process.argv.splice(2);</p><p>function parseJSError(aLine, aColumn) {<br>    fs.readFile(‘./index.ios.map’, ‘utf8’, function (err, data) {<br>        const whatever =  sourceMap.SourceMapConsumer.with(data, null, consumer =&gt; {<br>            // 读取 crash 日志的行号、列号<br>            let parseData = consumer.originalPositionFor({<br>                line: parseInt(aLine),<br>                column: parseInt(aColumn)<br>            });<br>            // 输出到控制台<br>            console.log(parseData);<br>            // 输出到文件中<br>            fs.writeFileSync(‘./parsed.txt’, JSON.stringify(parseData) + ‘\n’, ‘utf8’, function(err) {<br>                if(err) {<br>                    console.log(err);<br>                }<br>            });<br>        });<br>    });<br>}</p><p>var line = arguments[0];<br>var column = arguments[1];<br>parseJSError(line, column);</p><p>接下来做个实验，还是上述的 todos 项目。</p><ol><li><p>在 Text 的点击事件上模拟 crash</p><p> &lt;Text style={styles.sectionTitle} onPress={()=&gt;{1+qw;}}&gt;Debug&lt;/Text&gt;</p></li><li><p>将 RN 项目打 bundle 包、产出 sourceMap 文件。执行命令,</p><p> react-native bundle –entry-file index.js –platform android –dev false –bundle-output release_ios/main.jsbundle –assets-dest release_iOS –sourcemap-output release_ios/index.android.map;</p></li></ol><p>因为高频使用，所以给 iterm2 增加 alias 别名设置，修改 <code>.zshrc</code> 文件</p><p>alias RNRelease=’react-native bundle –entry-file index.js –platform ios –dev false –bundle-output release_ios/main.jsbundle –assets-dest release_iOS –sourcemap-output release_ios/index.ios.map;’ # RN 打 Release 包</p><ol start="3"><li><p> 将 js bundle 和图片资源拷贝到 Xcode 工程中</p></li><li><p>点击模拟 crash，将日志下面的行号和列号拷贝，在 Node 项目下，执行下面命令</p><p> node index.js 397 1822</p></li><li><p> 拿脚本解析好的行号、列号、文件信息去和源代码文件比较，结果很正确。</p></li></ol><p><img src="https://segmentfault.com/img/bVbIOlg"></p><h5 id="2-7-5-SourceMap-解析系统设计"><a href="#2-7-5-SourceMap-解析系统设计" class="headerlink" title="2.7.5 SourceMap 解析系统设计"></a>2.7.5 SourceMap 解析系统设计</h5><p>目的：通过平台可以将 RN 项目线上 crash 可以还原到具体的文件、代码行数、代码列数。可以看到具体的代码，可以看到 RN stack trace、提供源文件下载功能。</p><ol><li><p>打包系统下管理的服务器：</p><ul><li>  生产环境下打包才生成 source map 文件</li><li>  存储打包前的所有文件（install）</li></ul></li><li><p> 开发产品侧 RN 分析界面。点击收集到的 RN crash，在详情页可以看到具体的文件、代码行数、代码列数。可以看到具体的代码，可以看到 RN stack trace、Native stack trace。（具体技术实现上面讲过了）</p></li><li><p> 由于 souece map 文件较大，RN 解析过长虽然不久，但是是对计算资源的消耗，所以需要设计高效读取方式</p></li><li><p> SourceMap 在 iOS、Android 模式下不一样，所以 SoureceMap 存储需要区分 os。</p></li></ol><h3 id="3-KSCrash-的使用包装"><a href="#3-KSCrash-的使用包装" class="headerlink" title="3. KSCrash 的使用包装"></a>3. KSCrash 的使用包装</h3><p>然后再封装自己的 Crash 处理逻辑。比如要做的事情就是：</p><ul><li><p>继承自 KSCrashInstallation 这个抽象类，设置初始化工作（抽象类比如 NSURLProtocol 必须继承后使用），实现抽象类中的 <code>sink</code> 方法。</p><p>  /**<br>   * Crash system installation which handles backend-specific details.<br>   *<br>   * Only one installation can be installed at a time.<br>   *<br>   * This is an abstract class.<br>   */<br>  @interface KSCrashInstallation : NSObject</p></li></ul><p>#import “APMCrashInstallation.h”<br>#import &lt;KSCrash/KSCrashInstallation+Private.h&gt;<br>#import “APMCrashReporterSink.h”</p><p>@implementation APMCrashInstallation</p><ul><li>(instancetype)sharedInstance {<br>  static APMCrashInstallation *sharedInstance = nil;<br>  static dispatch_once_t onceToken;<br>  dispatch_once(&amp;onceToken, ^{<pre><code>  sharedInstance = \[\[APMCrashInstallation alloc\] init\];</code></pre>  });<br>  return sharedInstance;<br>}</li></ul><ul><li><p>(id)init {<br>  return [super initWithRequiredProperties: nil];<br>}</p></li><li><p>(id<KSCrashReportFilter>)sink {<br>  APMCrashReporterSink *sink = [[APMCrashReporterSink alloc] init];<br>  return [sink defaultCrashReportFilterSetAppleFmt];<br>}</p></li></ul><p>@end</p><ul><li><p><code>sink</code> 方法内部的 <code>APMCrashReporterSink</code> 类，遵循了 <strong>KSCrashReportFilter</strong> 协议，声明了公有方法 <code>defaultCrashReportFilterSetAppleFmt</code></p><p>  // .h<br>  #import &lt;Foundation/Foundation.h&gt;<br>  #import &lt;KSCrash/KSCrashReportFilter.h&gt;</p><p>  @interface APMCrashReporterSink : NSObject&lt;KSCrashReportFilter&gt;</p><ul><li><p>(id <KSCrashReportFilter>) defaultCrashReportFilterSetAppleFmt;</p><p>@end</p><p>// .m<br>#pragma mark - public Method</p></li><li><p>(id <KSCrashReportFilter>) defaultCrashReportFilterSetAppleFmt<br>{<br>  return [KSCrashReportFilterPipeline filterWithFilters:</p><pre><code>      \[APMCrashReportFilterAppleFmt filterWithReportStyle:KSAppleReportStyleSymbolicatedSideBySide\],      self,      nil\];</code></pre><p>}</p></li></ul></li></ul><p>其中 <code>defaultCrashReportFilterSetAppleFmt</code> 方法内部返回了一个 <code>KSCrashReportFilterPipeline</code> 类方法 <code>filterWithFilters</code> 的结果。</p><p><code>APMCrashReportFilterAppleFmt</code> 是一个继承自 <code>KSCrashReportFilterAppleFmt</code> 的类，遵循了 <code>KSCrashReportFilter</code> 协议。协议方法允许开发者处理 Crash 的数据格式。</p><p>/** Filter the specified reports.<br> *<br> * @param reports The reports to process.<br> * @param onCompletion Block to call when processing is complete.<br> */</p><ul><li>(void) filterReports:(NSArray*) reports<pre><code>    onCompletion:(KSCrashReportFilterCompletion) onCompletion;</code></pre></li></ul><p>#import &lt;KSCrash/KSCrashReportFilterAppleFmt.h&gt;</p><p>@interface APMCrashReportFilterAppleFmt : KSCrashReportFilterAppleFmt&lt;KSCrashReportFilter&gt;</p><p>@end</p><p>// .m</p><ul><li>(void) filterReports:(NSArray*)reports onCompletion:(KSCrashReportFilterCompletion)onCompletion<br>{<br>  NSMutableArray* filteredReports = [NSMutableArray arrayWithCapacity:[reports count]];<br>  for(NSDictionary *report in reports){<pre><code>if(\[self majorVersion:report\] == kExpectedMajorVersion)&#123;  id monitorInfo = \[self generateMonitorInfoFromCrashReport:report\];  if(monitorInfo != nil)&#123;    \[filteredReports addObject:monitorInfo\];  &#125;&#125;</code></pre>  }<br>  kscrash_callCompletion(onCompletion, filteredReports, YES, nil);<br>}</li></ul><p>/**<br> @brief 获取Crash JSON中的crash时间、mach name、signal name和apple report<br> */</p><ul><li><p>(NSDictionary *)generateMonitorInfoFromCrashReport:(NSDictionary *)crashReport<br>{<br>  NSDictionary *infoReport = [crashReport objectForKey:@”report”];<br>  // …<br>  id appleReport = [self toAppleFormat:crashReport];</p><p>  NSMutableDictionary *info = [NSMutableDictionary dictionary];<br>  [info setValue:crashTime forKey:@”crashTime”];<br>  [info setValue:appleReport forKey:@”appleReport”];<br>  [info setValue:userException forKey:@”userException”];<br>  [info setValue:userInfo forKey:@”custom”];</p><p>  return [info copy];<br>}</p></li></ul><p>/**<br> * A pipeline of filters. Reports get passed through each subfilter in order.<br> *<br> * Input: Depends on what’s in the pipeline.<br> * Output: Depends on what’s in the pipeline.<br> */<br>@interface KSCrashReportFilterPipeline : NSObject &lt;KSCrashReportFilter&gt;</p><ul><li><p>APM 能力中为 Crash 模块设置一个启动器。启动器内部设置 KSCrash 的初始化工作，以及触发 Crash 时候监控所需数据的组装。比如：SESSION_ID、App 启动时间、App 名称、崩溃时间、App 版本号、当前页面信息等基础信息。</p><p>  /** C Function to call during a crash report to give the callee an opportunity to<br>   * add to the report. NULL = ignore.<br>   *<br>   * WARNING: Only call async-safe functions from this function! DO NOT call<br>   * Objective-C methods!!!<br>   */<br>  @property(atomic,readwrite,assign) KSReportWriteCallback onCrash;</p></li></ul><p>+ (instancetype)sharedInstance<br>{<br>    static APMCrashMonitor *_sharedManager = nil;<br>    static dispatch_once_t onceToken;<br>    dispatch_once(&amp;onceToken, ^{<br>        _sharedManager = [[APMCrashMonitor alloc] init];<br>    });<br>    return _sharedManager;<br>}</p><p>#pragma mark - public Method</p><ul><li>(void)startMonitor<br>{<br>  APMMLog(@”crash monitor started”);</li></ul><p>#ifdef DEBUG<br>    BOOL _trackingCrashOnDebug = [APMMonitorConfig sharedInstance].trackingCrashOnDebug;<br>    if (_trackingCrashOnDebug) {<br>        [self installKSCrash];<br>    }<br>#else<br>    [self installKSCrash];<br>#endif<br>}</p><p>#pragma mark - private method</p><p>static void onCrash(const KSCrashReportWriter* writer)<br>{<br>    NSString *sessionId = [NSString stringWithFormat:@”\“%@\“”, ***]];<br>    writer-&gt;addJSONElement(writer, “SESSION_ID”, [sessionId UTF8String], true);</p><pre><code>NSString \*appLaunchTime = \*\*\*;writer-&gt;addJSONElement(writer, &quot;USER\_APP\_START\_DATE&quot;, \[\[NSString stringWithFormat:@&quot;\\&quot;%@\\&quot;&quot;, appLaunchTime\] UTF8String\], true);// ...</code></pre><p>}</p><ul><li>(void)installKSCrash<br>{<br>  [[APMCrashInstallation sharedInstance] install];<br>  [[APMCrashInstallation sharedInstance] sendAllReportsWithCompletion:nil];<br>  [APMCrashInstallation sharedInstance].onCrash = onCrash;<br>  dispatch_after(dispatch_time(DISPATCH_TIME_NOW, (int64_t)(5.f * NSEC_PER_SEC)), dispatch_get_main_queue(), ^{<pre><code>  \_isCanAddCrashCount = NO;</code></pre>  });<br>}</li></ul><p>在 <code>installKSCrash</code> 方法中调用了 <code>[[APMCrashInstallation sharedInstance] sendAllReportsWithCompletion: nil]</code>，内部实现如下</p><p>- (void) sendAllReportsWithCompletion:(KSCrashReportFilterCompletion) onCompletion<br>{<br>    NSError* error = [self validateProperties];<br>    if(error != nil)<br>    {<br>        if(onCompletion != nil)<br>        {<br>            onCompletion(nil, NO, error);<br>        }<br>        return;<br>    }</p><pre><code>id&lt;KSCrashReportFilter&gt; sink = \[self sink\];if(sink == nil)&#123;    onCompletion(nil, NO, \[NSError errorWithDomain:\[\[self class\] description\]                                              code:0                                       description:@&quot;Sink was nil (subclasses must implement method \\&quot;sink\\&quot;)&quot;\]);    return;&#125;sink = \[KSCrashReportFilterPipeline filterWithFilters:self.prependedFilters, sink, nil\];KSCrash\* handler = \[KSCrash sharedInstance\];handler.sink = sink;\[handler sendAllReportsWithCompletion:onCompletion\];</code></pre><p>}</p><p>方法内部将 <code>KSCrashInstallation</code> 的 <code>sink</code> 赋值给 <code>KSCrash</code> 对象。 内部还是调用了 <code>KSCrash</code> 的 <code>sendAllReportsWithCompletion</code> 方法，实现如下</p><p>- (void) sendAllReportsWithCompletion:(KSCrashReportFilterCompletion) onCompletion<br>{<br>    NSArray* reports = [self allReports];</p><pre><code>KSLOG\_INFO(@&quot;Sending %d crash reports&quot;, \[reports count\]);\[self sendReports:reports     onCompletion:^(NSArray\* filteredReports, BOOL completed, NSError\* error) &#123;     KSLOG\_DEBUG(@&quot;Process finished with completion: %d&quot;, completed);     if(error != nil)     &#123;         KSLOG\_ERROR(@&quot;Failed to send reports: %@&quot;, error);     &#125;     if((self.deleteBehaviorAfterSendAll == KSCDeleteOnSucess &amp;&amp; completed) ||        self.deleteBehaviorAfterSendAll == KSCDeleteAlways)     &#123;         kscrash\_deleteAllReports();     &#125;     kscrash\_callCompletion(onCompletion, filteredReports, completed, error); &#125;\];</code></pre><p>}</p><p>该方法内部调用了对象方法 <code>sendReports: onCompletion:</code>，如下所示</p><p>- (void) sendReports:(NSArray*) reports onCompletion:(KSCrashReportFilterCompletion) onCompletion<br>{<br>    if([reports count] == 0)<br>    {<br>        kscrash_callCompletion(onCompletion, reports, YES, nil);<br>        return;<br>    }</p><pre><code>if(self.sink == nil)&#123;    kscrash\_callCompletion(onCompletion, reports, NO,                             \[NSError errorWithDomain:\[\[self class\] description\]                                                 code:0                                          description:@&quot;No sink set. Crash reports not sent.&quot;\]);    return;&#125;\[self.sink filterReports:reports            onCompletion:^(NSArray\* filteredReports, BOOL completed, NSError\* error) &#123;     kscrash\_callCompletion(onCompletion, filteredReports, completed, error); &#125;\];</code></pre><p>}</p><p>方法内部的 <code>[self.sink filterReports: onCompletion: ]</code> 实现其实就是 <code>APMCrashInstallation</code> 中设置的 <code>sink</code> getter 方法，内部返回了 <code>APMCrashReporterSink</code> 对象的 <code>defaultCrashReportFilterSetAppleFmt</code> 方法的返回值。内部实现如下</p><p>- (id <KSCrashReportFilter>) defaultCrashReportFilterSetAppleFmt<br>{<br>    return [KSCrashReportFilterPipeline filterWithFilters:<br>            [APMCrashReportFilterAppleFmt filterWithReportStyle:KSAppleReportStyleSymbolicatedSideBySide],<br>            self,<br>            nil];<br>}</p><p>可以看到这个函数内部设置了多个 <strong>filters</strong>，其中一个就是 <strong>self</strong>，也就是 <code>APMCrashReporterSink</code> 对象，所以上面的 <code>[self.sink filterReports: onCompletion:]</code> ，也就是调用 <code>APMCrashReporterSink</code> 内的数据处理方法。完了之后通过 <code>kscrash_callCompletion(onCompletion, reports, YES, nil);</code> 告诉 <code>KSCrash</code> 本地保存的 Crash 日志已经处理完毕，可以删除了。</p><p>- (void)filterReports:(NSArray *)reports onCompletion:(KSCrashReportFilterCompletion)onCompletion<br>{<br>    for (NSDictionary *report in reports) {<br>        // 处理 Crash 数据，将数据交给统一的数据上报组件处理…<br>    }<br>    kscrash_callCompletion(onCompletion, reports, YES, nil);<br>}</p><p>至此，概括下 KSCrash 做的事情，提供各种 crash 的监控能力，在 crash 后将进程信息、基本信息、异常信息、线程信息等用 c 高效转换为 json 写入文件，App 下次启动后读取本地的 crash 文件夹中的 crash 日志，让开发者可以自定义 key、value 然后去上报日志到 APM 系统，然后删除本地 crash 文件夹中的日志。</p><h3 id="4-符号化"><a href="#4-符号化" class="headerlink" title="4. 符号化"></a>4. 符号化</h3><p>应用 crash 之后，系统会生成一份崩溃日志，存储在设置中，应用的运行状态、调用堆栈、所处线程等信息会记录在日志中。但是这些日志是地址，并不可读，所以需要进行符号化还原。</p><h4 id="4-1-DSYM-文件"><a href="#4-1-DSYM-文件" class="headerlink" title="4.1 .DSYM 文件"></a>4.1 .DSYM 文件</h4><p><code>.DSYM</code> （debugging symbol）文件是保存十六进制函数地址映射信息的中转文件，调试信息（symbols）都包含在该文件中。Xcode 工程每次编译运行都会生成新的 <code>.DSYM</code> 文���。默认情况下 debug 模式时不生成 <code>.DSYM</code> ，可以在 Build Settings -&gt; Build Options -&gt; Debug Information Format 后将值 <code>DWARF</code> 修改为 <code>DWARF with DSYM File</code>，这样再次编译运行就可以生成 <code>.DSYM</code> 文件。</p><p>所以每次 App 打包的时候都需要保存每个版本的 <code>.DSYM</code> 文件。</p><p><code>.DSYM</code> 文件中包含 DWARF 信息，打开文件的包内容 <code>Test.app.DSYM/Contents/Resources/DWARF/Test</code> 保存的就是 <code>DWARF</code> 文件。</p><p><code>.DSYM</code> 文件是从 Mach-O 文件中抽取调试信息而得到的文件目录，发布的时候为了安全，会把调试信息存储在单独的文件，<code>.DSYM</code> 其实是一个文件目录，结构如下：</p><p><img src="https://segmentfault.com/img/bVbIOlA"></p><h4 id="4-2-DWARF-文件"><a href="#4-2-DWARF-文件" class="headerlink" title="4.2 DWARF 文件"></a>4.2 DWARF 文件</h4><blockquote><p>DWARF is a debugging file format used by many compilers and debuggers to support source level debugging. It addresses the requirements of a number of procedural languages, such as C, C++, and Fortran, and is designed to be extensible to other languages. DWARF is architecture independent and applicable to any processor or operating system. It is widely used on Unix, Linux and other operating systems, as well as in stand-alone environments.</p></blockquote><p><strong>DWARF 是一种调试文件格式，它被许多编译器和调试器所广泛使用以支持源代码级别的调试</strong>。它满足许多过程语言（C、C++、Fortran）的需求，它被设计为支持拓展到其他语言。DWARF 是架构独立的，适用于其他任何的处理器和操作系统。被广泛使用在 Unix、Linux 和其他的操作系统上，以及独立环境上。</p><p>DWARF 全称是 Debugging With Arbitrary Record Formats，是一种使用属性化记录格式的调试文件。</p><p>DWARF 是可执行程序与源代码关系的一个紧凑表示。</p><p>大多数现代编程语言都是块结构：每个实体（一个类、一个函数）被包含在另一个实体中。一个 c 程序，每个文件可能包含多个数据定义、多个变量、多个函数，所以 DWARF 遵循这个模型，也是块结构。DWARF 里基本的描述项是调试信息项 DIE（Debugging Information Entry）。一个 DIE 有一个标签，表示这个 DIE 描述了什么以及一个填入了细节并进一步描述该项的属性列表（类比 html、xml 结构）。一个 DIE（除了最顶层的）被一个父 DIE 包含，可能存在兄弟 DIE 或者子 DIE，属性可能包含各种值：常量（比如一个函数名），变量（比如一个函数的起始地址），或对另一个DIE的引用（比如一个函数的返回值类型）。</p><p>DWARF 文件中的数据如下：</p><p>数据列</p><p>信息说明</p><p>.debug_loc</p><p>在 DW_AT_location 属性中使用的位置列表</p><p>.debug_macinfo</p><p>宏信息</p><p>.debug_pubnames</p><p>全局对象和函数的查找表</p><p>.debug_pubtypes</p><p>全局类型的查找表</p><p>.debug_ranges</p><p>在 DW_AT_ranges 属性中使用的地址范围</p><p>.debug_str</p><p>在 .debug_info 中使用的字符串表</p><p>.debug_types</p><p>类型描述</p><p>常用的标记与属性如下：</p><p>数据列</p><p>信息说明</p><p>DW_TAG_class_type</p><p>表示类名称和类型信息</p><p>DW_TAG_structure_type</p><p>表示结构名称和类型信息</p><p>DW_TAG_union_type</p><p>表示联合名称和类型信息</p><p>DW_TAG_enumeration_type</p><p>表示枚举名称和类型信息</p><p>DW_TAG_typedef</p><p>表示 typedef 的名称和类型信息</p><p>DW_TAG_array_type</p><p>表示数组名称和类型信息</p><p>DW_TAG_subrange_type</p><p>表示数组的大小信息</p><p>DW_TAG_inheritance</p><p>表示继承的类名称和类型信息</p><p>DW_TAG_member</p><p>表示类的成员</p><p>DW_TAG_subprogram</p><p>表示函数的名称信息</p><p>DW_TAG_formal_parameter</p><p>表示函数的参数信息</p><p>DW_TAG_name</p><p>表示名称字符串</p><p>DW_TAG_type</p><p>表示类型信息</p><p>DW_TAG_artifical</p><p>在创建时由编译程序设置</p><p>DW_TAG_sibling</p><p>表示兄弟位置信息</p><p>DW_TAG_data_memver_location</p><p>表示位置信息</p><p>DW_TAG_virtuality</p><p>在虚拟时设置</p><p>简单看一个 DWARF 的例子：将测试工程的 <code>.DSYM</code> 文件夹下的 DWARF 文件用下面命令解析</p><p>dwarfdump -F –debug-info Test.app.DSYM/Contents/Resources/DWARF/Test &gt; debug-info.txt</p><p>打开如下</p><p>Test.app.DSYM/Contents/Resources/DWARF/Test:    file format Mach-O arm64</p><p>.debug_info contents:<br>0x00000000: Compile Unit: length = 0x0000004f version = 0x0004 abbr_offset = 0x0000 addr_size = 0x08 (next unit at 0x00000053)</p><p>0x0000000b: DW_TAG_compile_unit<br>              DW_AT_producer [DW_FORM_strp]    (“Apple clang version 11.0.3 (clang-1103.0.32.62)”)<br>              DW_AT_language [DW_FORM_data2]    (DW_LANG_ObjC)<br>              DW_AT_name [DW_FORM_strp]    (“_Builtin_stddef_max_align_t”)<br>              DW_AT_stmt_list [DW_FORM_sec_offset]    (0x00000000)<br>              DW_AT_comp_dir [DW_FORM_strp]    (“/Users/lbp/Desktop/Test”)<br>              DW_AT_APPLE_major_runtime_vers [DW_FORM_data1]    (0x02)<br>              DW_AT_GNU_dwo_id [DW_FORM_data8]    (0x392b5344d415340c)</p><p>0x00000027:   DW_TAG_module<br>                DW_AT_name [DW_FORM_strp]    (“_Builtin_stddef_max_align_t”)<br>                DW_AT_LLVM_config_macros [DW_FORM_strp]    (“\“-DDEBUG=1\“ \“-DOBJC_OLD_DISPATCH_PROTOTYPES=1\“”)<br>                DW_AT_LLVM_include_path [DW_FORM_strp]    (“/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/11.0.3/include”)<br>                DW_AT_LLVM_isysroot [DW_FORM_strp]    (“/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk”)</p><p>0x00000038:     DW_TAG_typedef<br>                  DW_AT_type [DW_FORM_ref4]    (0x0000004b “long double”)<br>                  DW_AT_name [DW_FORM_strp]    (“max_align_t”)<br>                  DW_AT_decl_file [DW_FORM_data1]    (“/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/11.0.3/include/__stddef_max_align_t.h”)<br>                  DW_AT_decl_line [DW_FORM_data1]    (16)</p><p>0x00000043:     DW_TAG_imported_declaration<br>                  DW_AT_decl_file [DW_FORM_data1]    (“/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/11.0.3/include/__stddef_max_align_t.h”)<br>                  DW_AT_decl_line [DW_FORM_data1]    (27)<br>                  DW_AT_import [DW_FORM_ref_addr]    (0x0000000000000027)</p><p>0x0000004a:     NULL</p><p>0x0000004b:   DW_TAG_base_type<br>                DW_AT_name [DW_FORM_strp]    (“long double”)<br>                DW_AT_encoding [DW_FORM_data1]    (DW_ATE_float)<br>                DW_AT_byte_size [DW_FORM_data1]    (0x08)</p><p>0x00000052:   NULL<br>0x00000053: Compile Unit: length = 0x000183dc version = 0x0004 abbr_offset = 0x0000 addr_size = 0x08 (next unit at 0x00018433)</p><p>0x0000005e: DW_TAG_compile_unit<br>              DW_AT_producer [DW_FORM_strp]    (“Apple clang version 11.0.3 (clang-1103.0.32.62)”)<br>              DW_AT_language [DW_FORM_data2]    (DW_LANG_ObjC)<br>              DW_AT_name [DW_FORM_strp]    (“Darwin”)<br>              DW_AT_stmt_list [DW_FORM_sec_offset]    (0x000000a7)<br>              DW_AT_comp_dir [DW_FORM_strp]    (“/Users/lbp/Desktop/Test”)<br>              DW_AT_APPLE_major_runtime_vers [DW_FORM_data1]    (0x02)<br>              DW_AT_GNU_dwo_id [DW_FORM_data8]    (0xa4a1d339379e18a5)</p><p>0x0000007a:   DW_TAG_module<br>                DW_AT_name [DW_FORM_strp]    (“Darwin”)<br>                DW_AT_LLVM_config_macros [DW_FORM_strp]    (“\“-DDEBUG=1\“ \“-DOBJC_OLD_DISPATCH_PROTOTYPES=1\“”)<br>                DW_AT_LLVM_include_path [DW_FORM_strp]    (“/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include”)<br>                DW_AT_LLVM_isysroot [DW_FORM_strp]    (“/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk”)</p><p>0x0000008b:     DW_TAG_module<br>                  DW_AT_name [DW_FORM_strp]    (“C”)<br>                  DW_AT_LLVM_config_macros [DW_FORM_strp]    (“\“-DDEBUG=1\“ \“-DOBJC_OLD_DISPATCH_PROTOTYPES=1\“”)<br>                  DW_AT_LLVM_include_path [DW_FORM_strp]    (“/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include”)<br>                  DW_AT_LLVM_isysroot [DW_FORM_strp]    (“/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk”)</p><p>0x0000009c:       DW_TAG_module<br>                    DW_AT_name [DW_FORM_strp]    (“fenv”)<br>                    DW_AT_LLVM_config_macros [DW_FORM_strp]    (“\“-DDEBUG=1\“ \“-DOBJC_OLD_DISPATCH_PROTOTYPES=1\“”)<br>                    DW_AT_LLVM_include_path [DW_FORM_strp]    (“/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include”)<br>                    DW_AT_LLVM_isysroot [DW_FORM_strp]    (“/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk”)</p><p>0x000000ad:         DW_TAG_enumeration_type<br>                      DW_AT_type [DW_FORM_ref4]    (0x00017276 “unsigned int”)<br>                      DW_AT_byte_size [DW_FORM_data1]    (0x04)<br>                      DW_AT_decl_file [DW_FORM_data1]    (“/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/fenv.h”)<br>                      DW_AT_decl_line [DW_FORM_data1]    (154)</p><p>0x000000b5:           DW_TAG_enumerator<br>                        DW_AT_name [DW_FORM_strp]    (“__fpcr_trap_invalid”)<br>                        DW_AT_const_value [DW_FORM_udata]    (256)</p><p>0x000000bc:           DW_TAG_enumerator<br>                        DW_AT_name [DW_FORM_strp]    (“__fpcr_trap_divbyzero”)<br>                        DW_AT_const_value [DW_FORM_udata]    (512)</p><p>0x000000c3:           DW_TAG_enumerator<br>                        DW_AT_name [DW_FORM_strp]    (“__fpcr_trap_overflow”)<br>                        DW_AT_const_value [DW_FORM_udata]    (1024)</p><p>0x000000ca:           DW_TAG_enumerator<br>                        DW_AT_name [DW_FORM_strp]    (“__fpcr_trap_underflow”)<br>// ……<br>0x000466ee:   DW_TAG_subprogram<br>                DW_AT_name [DW_FORM_strp]    (“CFBridgingRetain”)<br>                DW_AT_decl_file [DW_FORM_data1]    (“/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSObject.h”)<br>                DW_AT_decl_line [DW_FORM_data1]    (105)<br>                DW_AT_prototyped [DW_FORM_flag_present]    (true)<br>                DW_AT_type [DW_FORM_ref_addr]    (0x0000000000019155 “CFTypeRef”)<br>                DW_AT_inline [DW_FORM_data1]    (DW_INL_inlined)</p><p>0x000466fa:     DW_TAG_formal_parameter<br>                  DW_AT_name [DW_FORM_strp]    (“X”)<br>                  DW_AT_decl_file [DW_FORM_data1]    (“/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/System/Library/Frameworks/Foundation.framework/Headers/NSObject.h”)<br>                  DW_AT_decl_line [DW_FORM_data1]    (105)<br>                  DW_AT_type [DW_FORM_ref4]    (0x00046706 “id”)</p><p>0x00046705:     NULL</p><p>0x00046706:   DW_TAG_typedef<br>                DW_AT_type [DW_FORM_ref4]    (0x00046711 “objc_object*“)<br>                DW_AT_name [DW_FORM_strp]    (“id”)<br>                DW_AT_decl_file [DW_FORM_data1]    (“/Users/lbp/Desktop/Test/Test/NetworkAPM/NSURLResponse+apm_FetchStatusLineFromCFNetwork.m”)<br>                DW_AT_decl_line [DW_FORM_data1]    (44)</p><p>0x00046711:   DW_TAG_pointer_type<br>                DW_AT_type [DW_FORM_ref4]    (0x00046716 “objc_object”)</p><p>0x00046716:   DW_TAG_structure_type<br>                DW_AT_name [DW_FORM_strp]    (“objc_object”)<br>                DW_AT_byte_size [DW_FORM_data1]    (0x00)</p><p>0x0004671c:     DW_TAG_member<br>                  DW_AT_name [DW_FORM_strp]    (“isa”)<br>                  DW_AT_type [DW_FORM_ref4]    (0x00046727 “objc_class*“)<br>                  DW_AT_data_member_location [DW_FORM_data1]    (0x00)<br>// ……</p><p>这里就不粘贴全部内容了（太长了）。可以看到 DIE 包含了函数开始地址、结束地址、函数名、文件名、所在行数，对于给定的地址，找到函数开始地址、结束地址之间包含该地址的 DIE，则可以还原函数名和文件名信息。</p><p>debug_line 可以还原文件行数等信息</p><p>dwarfdump -F –debug-line Test.app.DSYM/Contents/Resources/DWARF/Test &gt; debug-inline.txt</p><p>贴部分信息</p><p>Test.app.DSYM/Contents/Resources/DWARF/Test:    file format Mach-O arm64</p><p>.debug_line contents:<br>debug_line[0x00000000]<br>Line table prologue:<br>    total_length: 0x000000a3<br>         version: 4<br> prologue_length: 0x0000009a<br> min_inst_length: 1<br>max_ops_per_inst: 1<br> default_is_stmt: 1<br>       line_base: -5<br>      line_range: 14<br>     opcode_base: 13<br>standard_opcode_lengths[DW_LNS_copy] = 0<br>standard_opcode_lengths[DW_LNS_advance_pc] = 1<br>standard_opcode_lengths[DW_LNS_advance_line] = 1<br>standard_opcode_lengths[DW_LNS_set_file] = 1<br>standard_opcode_lengths[DW_LNS_set_column] = 1<br>standard_opcode_lengths[DW_LNS_negate_stmt] = 0<br>standard_opcode_lengths[DW_LNS_set_basic_block] = 0<br>standard_opcode_lengths[DW_LNS_const_add_pc] = 0<br>standard_opcode_lengths[DW_LNS_fixed_advance_pc] = 1<br>standard_opcode_lengths[DW_LNS_set_prologue_end] = 0<br>standard_opcode_lengths[DW_LNS_set_epilogue_begin] = 0<br>standard_opcode_lengths[DW_LNS_set_isa] = 1<br>include_directories[  1] = “/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/11.0.3/include”<br>file_names[  1]:<br>           name: “__stddef_max_align_t.h”<br>      dir_index: 1<br>       mod_time: 0x00000000<br>         length: 0x00000000</p><p>Address            Line   Column File   ISA Discriminator Flags</p><hr><p>0x0000000000000000      1      0      1   0             0  is_stmt end_sequence<br>debug_line[0x000000a7]<br>Line table prologue:<br>    total_length: 0x0000230a<br>         version: 4<br> prologue_length: 0x00002301<br> min_inst_length: 1<br>max_ops_per_inst: 1<br> default_is_stmt: 1<br>       line_base: -5<br>      line_range: 14<br>     opcode_base: 13<br>standard_opcode_lengths[DW_LNS_copy] = 0<br>standard_opcode_lengths[DW_LNS_advance_pc] = 1<br>standard_opcode_lengths[DW_LNS_advance_line] = 1<br>standard_opcode_lengths[DW_LNS_set_file] = 1<br>standard_opcode_lengths[DW_LNS_set_column] = 1<br>standard_opcode_lengths[DW_LNS_negate_stmt] = 0<br>standard_opcode_lengths[DW_LNS_set_basic_block] = 0<br>standard_opcode_lengths[DW_LNS_const_add_pc] = 0<br>standard_opcode_lengths[DW_LNS_fixed_advance_pc] = 1<br>standard_opcode_lengths[DW_LNS_set_prologue_end] = 0<br>standard_opcode_lengths[DW_LNS_set_epilogue_begin] = 0<br>standard_opcode_lengths[DW_LNS_set_isa] = 1<br>include_directories[  1] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include”<br>include_directories[  2] = “/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/11.0.3/include”<br>include_directories[  3] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/sys”<br>include_directories[  4] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/mach”<br>include_directories[  5] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/libkern”<br>include_directories[  6] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/architecture”<br>include_directories[  7] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/sys/_types”<br>include_directories[  8] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/_types”<br>include_directories[  9] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/arm”<br>include_directories[ 10] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/sys/_pthread”<br>include_directories[ 11] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/mach/arm”<br>include_directories[ 12] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/libkern/arm”<br>include_directories[ 13] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/uuid”<br>include_directories[ 14] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/netinet”<br>include_directories[ 15] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/netinet6”<br>include_directories[ 16] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/net”<br>include_directories[ 17] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/pthread”<br>include_directories[ 18] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/mach_debug”<br>include_directories[ 19] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/os”<br>include_directories[ 20] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/malloc”<br>include_directories[ 21] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/bsm”<br>include_directories[ 22] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/machine”<br>include_directories[ 23] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/mach/machine”<br>include_directories[ 24] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/secure”<br>include_directories[ 25] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/xlocale”<br>include_directories[ 26] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/arpa”<br>file_names[  1]:<br>           name: “fenv.h”<br>      dir_index: 1<br>       mod_time: 0x00000000<br>         length: 0x00000000<br>file_names[  2]:<br>           name: “stdatomic.h”<br>      dir_index: 2<br>       mod_time: 0x00000000<br>         length: 0x00000000<br>file_names[  3]:<br>           name: “wait.h”<br>      dir_index: 3<br>       mod_time: 0x00000000<br>         length: 0x00000000<br>// ……<br>Address            Line   Column File   ISA Discriminator Flags</p><hr><p>0x000000010000b588     14      0      2   0             0  is_stmt<br>0x000000010000b5b4     16      5      2   0             0  is_stmt prologue_end<br>0x000000010000b5d0     17     11      2   0             0  is_stmt<br>0x000000010000b5d4      0      0      2   0             0<br>0x000000010000b5d8     17      5      2   0             0<br>0x000000010000b5dc     17     11      2   0             0<br>0x000000010000b5e8     18      1      2   0             0  is_stmt<br>0x000000010000b608     20      0      2   0             0  is_stmt<br>0x000000010000b61c     22      5      2   0             0  is_stmt prologue_end<br>0x000000010000b628     23      5      2   0             0  is_stmt<br>0x000000010000b644     24      1      2   0             0  is_stmt<br>0x000000010000b650     15      0      1   0             0  is_stmt<br>0x000000010000b65c     15     41      1   0             0  is_stmt prologue_end<br>0x000000010000b66c     11      0      2   0             0  is_stmt<br>0x000000010000b680     11     17      2   0             0  is_stmt prologue_end<br>0x000000010000b6a4     11     17      2   0             0  is_stmt end_sequence<br>debug_line[0x0000def9]<br>Line table prologue:<br>    total_length: 0x0000015a<br>         version: 4<br> prologue_length: 0x000000eb<br> min_inst_length: 1<br>max_ops_per_inst: 1<br> default_is_stmt: 1<br>       line_base: -5<br>      line_range: 14<br>     opcode_base: 13<br>standard_opcode_lengths[DW_LNS_copy] = 0<br>standard_opcode_lengths[DW_LNS_advance_pc] = 1<br>standard_opcode_lengths[DW_LNS_advance_line] = 1<br>standard_opcode_lengths[DW_LNS_set_file] = 1<br>standard_opcode_lengths[DW_LNS_set_column] = 1<br>standard_opcode_lengths[DW_LNS_negate_stmt] = 0<br>standard_opcode_lengths[DW_LNS_set_basic_block] = 0<br>standard_opcode_lengths[DW_LNS_const_add_pc] = 0<br>standard_opcode_lengths[DW_LNS_fixed_advance_pc] = 1<br>standard_opcode_lengths[DW_LNS_set_prologue_end] = 0<br>standard_opcode_lengths[DW_LNS_set_epilogue_begin] = 0<br>standard_opcode_lengths[DW_LNS_set_isa] = 1<br>include_directories[  1] = “Test”<br>include_directories[  2] = “Test/NetworkAPM”<br>include_directories[  3] = “/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS13.5.sdk/usr/include/objc”<br>file_names[  1]:<br>           name: “AppDelegate.h”<br>      dir_index: 1<br>       mod_time: 0x00000000<br>         length: 0x00000000<br>file_names[  2]:<br>           name: “JMWebResourceURLProtocol.h”<br>      dir_index: 2<br>       mod_time: 0x00000000<br>         length: 0x00000000<br>file_names[  3]:<br>           name: “AppDelegate.m”<br>      dir_index: 1<br>       mod_time: 0x00000000<br>         length: 0x00000000<br>file_names[  4]:<br>           name: “objc.h”<br>      dir_index: 3<br>       mod_time: 0x00000000<br>         length: 0x00000000<br>// ……</p><p>可以看到 debug_line 里包含了每个代码地址对应的行数。上面贴了 AppDelegate 的部分。</p><h4 id="4-3-symbols"><a href="#4-3-symbols" class="headerlink" title="4.3 symbols"></a>4.3 symbols</h4><blockquote><p>在链接中，我们将函数和变量统称为符合（Symbol），函数名或变量名就是符号名（Symbol Name），我们可以将符号看成是链接中的粘合剂，整个链接过程正是基于符号才能正确完成的。</p></blockquote><p>上述文字来自《程序员的自我修养》。所以符号就是函数、变量、类的统称。</p><p>按照类型划分，符号可以分为三类：</p><ul><li>  全局符号：目标文件外可见的符号，可以被其他目标文件所引用，或者需要其他目标文件定义</li><li>  局部符号：只在目标文件内可见的符号，指只在目标文件内可见的函数和变量</li><li>  调试符号：包括行号信息的调试符号信息，行号信息记录了函数和变量对应的文件和文件行号。</li></ul><p><strong>符号表（Symbol Table）</strong>：是内存地址与函数名、文件名、行号的映射表。每个定义的符号都有一个对应的值得，叫做符号值（Symbol Value），对于变量和函数来说，符号值就是地址，符号表组成如下</p><p>&lt;起始地址&gt; &lt;结束地址&gt; &lt;函数&gt; [&lt;文件名：行号&gt;]</p><h4 id="4-4-如何获取地址？"><a href="#4-4-如何获取地址？" class="headerlink" title="4.4 如何获取地址？"></a>4.4 <strong>如何获取地址？</strong></h4><p>image 加载的时候会进行相对基地址进行重定位，并且每次加载的基地址都不一样，函数栈 frame 的地址是重定位后的绝对地址，我们要的是重定位前的相对地址。</p><p>Binary Images</p><p>拿测试工程的 crash 日志举例子，打开贴部分 Binary Images 内容</p><p>// …<br>Binary Images:<br>0x102fe0000 - 0x102ff3fff Test arm64  &lt;37eaa57df2523d95969e47a9a1d69ce5&gt; /var/containers/Bundle/Application/643F0DFE-A710-4136-A278-A89D780B7208/Test.app/Test<br>0x1030e0000 - 0x1030ebfff libobjc-trampolines.dylib arm64  &lt;181f3aa866d93165ac54344385ac6e1d&gt; /usr/lib/libobjc-trampolines.dylib<br>0x103204000 - 0x103267fff dyld arm64  &lt;6f1c86b640a3352a8529bca213946dd5&gt; /usr/lib/dyld<br>0x189a78000 - 0x189a8efff libsystem_trace.dylib arm64  <b7477df8f6ab3b2b9275ad23c6cc0b75> /usr/lib/system/libsystem_trace.dylib<br>// …</p><p>可以看到 Crash 日志的 Binary Images 包含每个 Image 的加载开始地址、结束地址、image 名称、arm 架构、uuid、image 路径。</p><p>crash 日志中的信息</p><p>Last Exception Backtrace:<br>// …<br>5   Test                              0x102fe592c -[ViewController testMonitorCrash] + 22828 (ViewController.mm:58)</p><p>Binary Images:<br>0x102fe0000 - 0x102ff3fff Test arm64  &lt;37eaa57df2523d95969e47a9a1d69ce5&gt; /var/containers/Bundle/Application/643F0DFE-A710-4136-A278-A89D780B7208/Test.app/Test</p><p>所以 frame 5 的相对地址为 <code>0x102fe592c - 0x102fe0000</code> 。再使用 命令可以还原符号信息。</p><p>使用 atos 来解析，<code>0x102fe0000</code> 为 image 加载的开始地址，<code>0x102fe592c</code> 为 frame 需要还原的地址。</p><p>atos -o Test.app.DSYM/Contents/Resources/DWARF/Test-arch arm64 -l 0x102fe0000 0x102fe592c</p><h4 id="4-5-UUID"><a href="#4-5-UUID" class="headerlink" title="4.5 UUID"></a>4.5 UUID</h4><ul><li><p>crash 文件的 UUID</p><p>  grep –after-context=2 “Binary Images:” *.crash</p></li></ul><p>Test  5-28-20, 7-47 PM.crash:Binary Images:<br>Test  5-28-20, 7-47 PM.crash-0x102fe0000 - 0x102ff3fff Test arm64  &lt;37eaa57df2523d95969e47a9a1d69ce5&gt; /var/containers/Bundle/Application/643F0DFE-A710-4136-A278-A89D780B7208/Test.app/Test<br>Test  5-28-20, 7-47 PM.crash-0x1030e0000 - 0x1030ebfff libobjc-trampolines.dylib arm64  &lt;181f3aa866d93165ac54344385ac6e1d&gt; /usr/lib/libobjc-trampolines.dylib<br>–<br>Test.crash:Binary Images:<br>Test.crash-0x102fe0000 - 0x102ff3fff Test arm64  &lt;37eaa57df2523d95969e47a9a1d69ce5&gt; /var/containers/Bundle/Application/643F0DFE-A710-4136-A278-A89D780B7208/Test.app/Test<br>Test.crash-0x1030e0000 - 0x1030ebfff libobjc-trampolines.dylib arm64  &lt;181f3aa866d93165ac54344385ac6e1d&gt; /usr/lib/libobjc-trampolines.dylib</p><p>Test App 的 UUID 为 <code>37eaa57df2523d95969e47a9a1d69ce5</code>.</p><ul><li><p>.DSYM 文件的 UUID</p><p>  dwarfdump –uuid Test.app.DSYM</p></li></ul><p>结果为</p><p>UUID: 37EAA57D-F252-3D95-969E-47A9A1D69CE5 (arm64) Test.app.DSYM/Contents/Resources/DWARF/Test</p><ul><li><p>app 的 UUID</p><p>  dwarfdump –uuid Test.app/Test</p></li></ul><p>结果为</p><p>UUID: 37EAA57D-F252-3D95-969E-47A9A1D69CE5 (arm64) Test.app/Test</p><h4 id="4-6-符号化（解析-Crash-日志）"><a href="#4-6-符号化（解析-Crash-日志）" class="headerlink" title="4.6 符号化（解析 Crash 日志）"></a>4.6 符号化（解析 Crash 日志）</h4><p>上述篇幅分析了如何捕获各种类型的 crash，App 在用户手中我们通过技术手段可以获取 crash 案发现场信息并结合一定的机制去上报，但是这种堆栈是十六进制的地址，无法定位问题，所以需要做符号化处理。</p><p>上面也说明了<a href="https://segmentfault.com/a/1190000040277799#DSYM">.DSYM 文件</a> 的作用，<strong>通过符号地址结合 DSYM 文件来还原文件名、所在行、函数名，这个过程叫符号化</strong>。但是 .DSYM 文件必须和 crash log 文件的 bundle id、version 严格对应。</p><p>获取 Crash 日志可以通过 Xcode -&gt; Window -&gt; Devices and Simulators 选择对应设备，找到 Crash 日志文件，根据时间和 App 名称定位。</p><p>app 和 .DSYM 文件可以通过打包的产物得到，路径为 <code>~/Library/Developer/Xcode/Archives</code>。</p><p>解析方法一般有2种：</p><ul><li><p>使用 <strong>symbolicatecrash</strong></p><p>  symbolicatecrash 是 Xcode 自带的 crash 日志分析工具，先确定所在路径，在终端执行下面的命令</p><p>  find /Applications/Xcode.app -name symbolicatecrash -type f</p></li></ul><p>会返回几个路径，找到 <code>iPhoneSimulator.platform</code> 所在那一行</p><p>/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/Library/PrivateFrameworks/DVTFoundation.framework/symbolicatecrash</p><p>将 symbolicatecrash 拷贝到指定文件夹下（保存了 app、DSYM、crash 文件的文件夹）</p><p>执行命令</p><p>./symbolicatecrash Test.crash Test.DSYM &gt; Test.crash</p><p>第一次做这事儿应该会报错 <code>Error: &quot;DEVELOPER_DIR&quot; is not defined at ./symbolicatecrash line 69.</code>，解决方案：在终端执行下面命令</p><p>export DEVELOPER_DIR=/Applications/Xcode.app/Contents/Developer</p><ul><li><p>使用 atos</p><p>  区别于 symbolicatecrash，atos 较为灵活，只要 <code>.crash</code> 和 <code>.DSYM</code> 或者 <code>.crash</code> 和 <code>.app</code> 文件对应即可。</p><p>  用法如下，-l 最后跟得是符号地址</p><p>  xcrun atos -o Test.app.DSYM/Contents/Resources/DWARF/Test -arch armv7 -l 0x1023c592c</p></li></ul><p>也可以解析 .app 文件（不存在 .DSYM 文件），其中xxx为段地址，xx为偏移地址</p><p>atos -arch architecture -o binary -l xxx xx</p><p>因为我们的 App 可能有很多，每个 App 在用户手中可能是不同的版本，所以在 APM 拦截之后需要符号化的时候需要将 crash 文件和 <code>.DSYM</code> 文件一一对应，才能正确符号化，对应的原则就是 <strong>UUID</strong> 一致。</p><h4 id="4-7-系统库符号化解析"><a href="#4-7-系统库符号化解析" class="headerlink" title="4.7 系统库符号化解析"></a>4.7 系统库符号化解析</h4><p>我们每次真机连接 Xcode 运行程序，会提示等待，其实系统为了堆栈解析，都会把当前版本的系统符号库自动导入到 <code>/Users/你自己的用户名/Library/Developer/Xcode/iOS DeviceSupport</code> 目录下安装了一大堆系统库的符号化文件。你可以访问下面目录看看</p><p>/Users/你自己的用户名/Library/Developer/Xcode/iOS DeviceSupport/</p><p><img src="https://segmentfault.com/img/bVbIOlY"></p><h3 id="5-服务端处理"><a href="#5-服务端处理" class="headerlink" title="5. 服务端处理"></a>5. 服务端处理</h3><h5 id="5-1-ELK-日志系统"><a href="#5-1-ELK-日志系统" class="headerlink" title="5.1 ELK 日志系统"></a>5.1 ELK 日志系统</h5><p>业界设计日志监控系统一般会采用基于 ELK 技术。ELK 是 Elasticsearch、Logstash、Kibana 三个开源框架缩写。Elasticsearch 是一个分布式、通过 Restful 方式进行交互的近实时搜索的平台框架。Logstash 是一个中央数据流引擎，用于从不同目标（文件/数据存储/MQ）收集不同格式的数据，经过过滤后支持输出到不同目的地（文件/MQ/Redis/ElasticsSearch/Kafka）。Kibana 可以将 Elasticserarch 的数据通过友好的页面展示出来，提供可视化分析功能。所以 ELK 可以搭建一个高效、企业级的日志分析系统。</p><p>早期单体应用时代，几乎应用的所有功能都在一台机器上运行，出了问题，运维人员打开终端输入命令直接查看系统日志，进而定位问题、解决问题。随着系统的功能越来越复杂，用户体量越来越大，单体应用几乎很难满足需求，所以技术架构迭代了，通过水平拓展来支持庞大的用户量，将单体应用进行拆分为多个应用，每个应用采用集群方式部署，负载均衡控制调度，假如某个子模块发生问题，去找这台服务器上终端找日志分析吗？显然台落后，所以日志管理平台便应运而生。通过 Logstash 去收集分析每台服务器的日志文件，然后按照定义的正则模版过滤后传输到 Kafka 或 Redis，然后由另一个 Logstash 从 Kafka 或 Redis 上读取日志存储到 ES 中创建索引，最后通过 Kibana 进行可视化分析。此外可以将收集到的数据进行数据分析，做更进一步的维护和决策。</p><p><img src="https://segmentfault.com/img/bVbIOma"></p><p>上图展示了一个 ELK 的日志架构图。简单说明下：</p><ul><li>  Logstash 和 ES 之前存在一个 Kafka 层，因为 Logstash 是架设在数据资源服务器上，将收集到的数据进行实时过滤，过滤需要消耗时间和内存，所以存在 Kafka，起到了数据缓冲存储作用，因为 Kafka 具备非常出色的读写性能。</li><li>  再一步就是 Logstash 从 Kafka 里面进行读取数据，将数据过滤、处理，将结果传输到 ES</li><li>  这个设计不但性能好、耦合低，还具备可拓展性。比如可以从 n 个不同的 Logstash 上读取传输到 n 个 Kafka 上，再由 n 个 Logstash 过滤处理。日志来源可以是 m 个，比如 App 日志、Tomcat 日志、Nginx 日志等等</li></ul><p>下图贴一个 Elasticsearch 社区分享的一个 “Elastic APM 动手实战”<a href="https://link.segmentfault.com/?enc=GlmdPehBhmCplzSNC0/ymQ==.C5++ytucOFOBjcXb+QzqtRBG55cXLxvwvo82vEIrH1aL4Zm4o/dwEaHgQ0LAE6VM">主题</a>的内容截图。</p><p><img src="https://segmentfault.com/img/bVbIOmc"></p><h5 id="5-2-服务侧"><a href="#5-2-服务侧" class="headerlink" title="5.2 服务侧"></a>5.2 服务侧</h5><p>Crash log 统一入库 Kibana 时是没有符号化的，所以需要符号化处理，以方便定位问题、crash 产生报表和后续处理。</p><p><img src="https://segmentfault.com/img/bVbIOmh"></p><p>所以整个流程就是：客户端 APM SDK 收集 crash log -&gt; Kafka 存储 -&gt; Mac 机执行定时任务符号化 -&gt; 数据回传 Kafka -&gt; 产品侧（显示端）对数据进行分类、报表、报警等操作。</p><p>因为公司的产品线有多条，相应的 App 有多个，用户使用的 App 版本也各不相同，所以 crash 日志分析必须要有正确的 .DSYM 文件，那么多 App 的不同版本，自动化就变得非常重要了。</p><p>自动化有2种手段，规模小一点的公司或者图省事，可以在 Xcode中 添加 runScript 脚本代码来自动在 release 模式下上传DSYM）。</p><p>因为我们大前端有一套体系，可以同时管理 iOS SDK、iOS App、Android SDK、Android App、Node、React、React Native 工程项目的初始化、依赖管理、构建（持续集成、Unit Test、Lint、统跳检测）、测试、打包、部署、动态能力（热更新、统跳路由下发）等能力于一身。可以基于各个阶段做能力的插入，所以可以在打包系统中，当调用打包后在打包机上传 <code>.DSYM</code> 文件到七牛云存储（规则可以是以 AppName + Version 为 key，value 为 .DSYM 文件）。</p><p>现在很多架构设计都是微服务，至于为什么选微服务，不在本文范畴。所以 crash 日志的符号化被设计为一个微服务。架构图如下</p><p><img src="https://segmentfault.com/img/bVcKBTl"><br>说明：</p><ul><li>  Symbolication Service 作为整个监控系统的一个组成部分，是专注于 crash report 符号化的微服务。</li><li>  接收来自任务调度框架的包含预处理过的 crash report 和 DSYM index 的请求，从七牛拉取对应的 DSYM，对 crash report 做符号化解析，计算 hash，并将 hash 响应给「数据处理和任务调度框架」。</li><li>  接收来自 APM 管理系统的包含原始 crash report 和 DSYM index 的请求，从七牛拉取对应的 DSYM，对crash report 做符号化解析，并将符号化的 crash report 响应给 APM 管理系统。</li><li>  脚手架 cli 有个能力就是调用打包系统的打包构建能力，会根据项目的特点，选择合适的打包机（打包平台是维护了多个打包任务，不同任务根据特点被派发到不同的打包机上，任务详情页可以看到依赖的下载、编译、运行过程等，打包好的产物包括二进制包、下载二维码等等）</li></ul><p>其中符号化服务是大前端背景下大前端团队的产物，所以是 NodeJS 实现的（单线程，所以为了提高机器利用率，就要开启多进程能力）。iOS 的符号化机器是 双核的 Mac mini，这就需要做实验测评到底需要开启几个 worker 进程做符号化服务。结果是双进程处理 crash log，比单进程效率高近一倍，而四进程比双进程效率提升不明显，符合双核 mac mini 的特点。所以开启两个 worker 进程做符号化处理。</p><p>下图是完整设计图</p><p><img src="https://segmentfault.com/img/bVcKBTm"></p><p>简单说明下，符号化流程是一个主从模式，一台 master 机，多个 slave 机，master 机读取 .DSYM 和 crash 结果的 cache。「数据处理和任务调度框架」调度符号化服务（内部2个 symbolocate worker）同时从七牛云上获取 .DSYM 文件。</p><p>系统架构图如下<br><img src="https://segmentfault.com/img/bVbIOmt"></p><h2 id="八、-APM-小结"><a href="#八、-APM-小结" class="headerlink" title="八、 APM 小结"></a>八、 APM 小结</h2><ol><li><p> 通常来说各个端的监控能力是不太一致的，技术实现细节也不统一。所以在技术方案评审的时候需要将监控能力对齐统一。每个能力在各个端的数据字段必须对齐（字段个数、名称、数据类型和精度），因为 APM 本身是一个闭环，监控了之后需符号化解析、数据整理，进行产品化开发、最后需要监控大盘展示等</p></li><li><p> 一些 crash 或者 ANR 等根据等级需要邮件、短信、企业内容通信工具告知干系人，之后快速发布版本、hot fix 等。</p></li><li><p> 监控的各个能力需要做成可配置，灵活开启关闭。</p></li><li><p> 监控数据需要做内存到文件的写入处理，需要注意策略。监控数据需要存储数据库，数据库大小、设计规则等。存入数据库后如何上报，上报机制等会在另一篇文章讲：<a href="https://link.segmentfault.com/?enc=tHMPJBwKBqGAnYO7hYcQqg==./eOLWZKsqJHhNAhfSn2gbQ2a7WVL9mUUlYeQsXYOSjBISZB2NR17mPajVWwk5TDY5Dn4xXC6MPLu/eK8jzZhnSvMtXciC76PEuTuT2+PpAAYT5v/pm2vmYaTDoGykKi6">打造一个通用、可配置的数据上报 SDK</a></p></li><li><p>尽量在技术评审后，将各端的技术实现写进文档中，同步给相关人员。比如 ANR 的实现</p><p> /*<br> android 端</p><p> 根据设备分级，一般超过 300ms 视为一次卡顿<br> hook 系统 loop，在消息处理前后插桩，用以计算每条消息的时长<br> 开启另外线程 dump 堆栈，处理结束后关闭<br> */<br> new ExceptionProcessor().init(this, new Runnable() {</p><pre><code>         @Override         public void run() &#123;             //监测卡顿             try &#123;                 ProxyPrinter proxyPrinter = new ProxyPrinter(PerformanceMonitor.this);                 Looper.getMainLooper().setMessageLogging(proxyPrinter);                 mWeakPrinter = new WeakReference&lt;ProxyPrinter&gt;(proxyPrinter);             &#125; catch (FileNotFoundException e) &#123;             &#125;         &#125;     &#125;)</code></pre><p> /*<br> iOS 端</p><p> 子线程通过 ping 主线程来确认主线程当前是否卡顿。<br> 卡顿阈值设置为 300ms，超过阈值时认为卡顿。<br> 卡顿时获取主线程的堆栈，并存储上传。<br> */ </p><ul><li>(void) main() {<br>  while (self.cancle == NO) {<pre><code>  self.isMainThreadBlocked = YES;  dispatch\_async(dispatch\_get\_main\_queue(), ^&#123;      self.isMainThreadBlocked = YES;      \[self.semaphore singal\];  &#125;);  \[Thread sleep:300\];  if (self.isMainThreadBlocked) &#123;      \[self handleMainThreadBlock\];  &#125;  \[self.semaphore wait\];</code></pre>  }<br>}</li></ul></li><li><p>整个 APM 的架构图如下</p><p> <img src="https://segmentfault.com/img/bVbIOnN"></p><p> 说明：</p><ul><li>  埋点 SDK，通过 sessionId 来关联日志数据</li></ul></li><li><p> APM 技术方案本身是随着技术手段、分析需求不断调整升级的。上图的几个结构示意图是早期几个版本的，目前使用的是在此基础上进行了升级和结构调整，提几个关键词：Hermes、Flink SQL、InfluxDB。</p></li></ol></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;h1 id=&quot;打造一套客户端功能最全的-APM-监控系统&quot;&gt;&lt;a href=&quot;#打造一套客户端功能最全的-APM-监控系统&quot; class=&quot;headerlink&quot; title=&quot;打造一套客户端功能最全的 APM 监控系统&quot;&gt;&lt;/a&gt;&lt;a href=&quot;h</summary>
      
    
    
    
    <category term="监控" scheme="http://zhangyu.info/categories/%E7%9B%91%E6%8E%A7/"/>
    
    
    <category term="监控" scheme="http://zhangyu.info/tags/%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
  <entry>
    <title>企业完成云转型的成功之道：云成本优化管理</title>
    <link href="http://zhangyu.info/2022/04/23/%E4%BC%81%E4%B8%9A%E5%AE%8C%E6%88%90%E4%BA%91%E8%BD%AC%E5%9E%8B%E7%9A%84%E6%88%90%E5%8A%9F%E4%B9%8B%E9%81%93-%E4%BA%91%E6%88%90%E6%9C%AC%E4%BC%98%E5%8C%96%E7%AE%A1%E7%90%86/"/>
    <id>http://zhangyu.info/2022/04/23/%E4%BC%81%E4%B8%9A%E5%AE%8C%E6%88%90%E4%BA%91%E8%BD%AC%E5%9E%8B%E7%9A%84%E6%88%90%E5%8A%9F%E4%B9%8B%E9%81%93-%E4%BA%91%E6%88%90%E6%9C%AC%E4%BC%98%E5%8C%96%E7%AE%A1%E7%90%86/</id>
    <published>2022-04-22T16:00:00.000Z</published>
    <updated>2022-04-23T14:47:42.471Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/498641381">https://zhuanlan.zhihu.com/p/498641381</a></p><blockquote><p>近年来，各行各业的企业的云采用率迅速增加，预计向云的迁移将继续加速，以实现快速的敏捷性以及以最少的资本支出获得规模和弹性。即用即付定价带来的成本优势也是推动云采用的关键驱动因素之一。</p><p>然而，随着企业将更多的工作负载（业务应用程序和数据）转移到云上，在缺乏明确定义的云成本管理策略的情况下，它们的成本优势会迅速消失。</p><p>为了快速迁移到云计算上，企业通常采用直接迁移策略来迁移云，但会导致与本地部署相同的低效率。这些效率低下的表现形式可能是内存、计算或存储容量过剩。如果在迁移过程中或迁移之后没有针对云计算进行架构和优化，则基本成本要素保持不变，不会提供成本优势，并且在许多情况下会增加成本。</p><p>此外，很多时候会使用旧的预算和预测实践来管理云上的成本。云财务管理必须区别对待，它需要实时跟踪、准确预测，并在发生任何事件时立即采取行动。不能像以前那样将其留作每月或每季度的审查。</p><p>因此，有效的云成本管理是所有云转型过程中的基本要素。</p><p><strong>1、控制云成本 – 框架和策略</strong></p><p>云采用被认为是按使用付费的模式。但是，其提供的所有服务都是收费的，无论它们是否已被充分利用。对云服务的无纪律、不受监管和不受监控的使用会导致云预算激增，企业难以控制其不断增长的云支出。有许多公司在迁移到云时大大超过其本地基础设施成本。</p><p>云成本管理需要从整体角度严格监控和控制云成本。这可以通过定义和实施清晰的云成本管理框架来管理云经济来实现。该框架应允许企业了解和基线化云计算需求，提供对云服务相关支出的可见性、优化使用的能力和工具、实施建议、与利益相关者的成本透明度以及向业务线（LoB）回收成本的机制。</p><p><strong>2、云成本管理框架</strong></p><p>以下是应考虑的云成本管理框架的核心组件。</p><p><strong>1）预算和控制</strong></p><p>定义、分配和管理分配给部门或项目的预算。此功能是计划和控制资源利用率，跟踪预算与实际运行成本并针对变化采取行动。这将为企业提供可预测的成本消耗预算。</p><p><strong>2）基线和优化</strong></p><p>为云计算设定合适的初始规模以基线化成本并定期重复以进一步优化。</p><p><strong>3）监控和分析</strong></p><p>了解使用的云资源，以便对其进行有效管理。应审查当前和过去的消费、非标准、未使用或未优化使用的云服务等详细信息并采取行动。应该对云使用模式和成本趋势进行分析，以便对 LoB 和产品组合进行精细预算和预测。另一个有助于云成本管理的方面是基于事件的干预定义和自动化。</p><p><strong>4）治理和标准化</strong></p><p>每个角色的企业范围内基于策略的访问和权限。标准化云基础设施配置，例如创建已批准的虚拟机配置、内置安全性、网络设置等的预定义模板，开发人员可以配置这些模板以提高生产力和自动化。</p><p>使用元数据设置自动警报机制，当云服务使用量超过预定义级别时通知管理员或通知未使用的资源、未充分利用的资源和自动响应的标签。</p><p>建立与不同环境的运行时间相关的治理（例如，在不使用时可以作为候选关闭的开发/测试环境），定期审查与 CSP 的计费协议，并根据预期的工作负载变化重新协商。</p><p><strong>5）成本透明度</strong></p><p>为不同的 LoB 和部门带来云使用成本的可见性和透明度。使用元数据和资源标签对 LoB 和部门的云使用情况进行跟踪和基于计量的显示和计费。</p><p><strong>3、云成本优化策略</strong></p><p>以下是可用于优化云费用的一些策略和最佳实践：</p><p><strong>1）正确调整内存、计算、存储和其他资源的大小</strong></p><p>很多时候，特别是如果一个企业采用了一种提升和转移的方法来迁移到云，基础设施资源就会被过度配置。由于按使用付费实际上是按订单付费，因此最初正确调整大小并定期进行审查和重新调整大小是必不可少的。这消除了过度配置或次优化使用的机会。</p><p><strong>2）消除未使用的资源和服务</strong></p><p>识别云设置中未使用的资源并删除它们是一项关键策略。这通常发生在为临时目的创建服务器然后被遗忘时。同样，无法删除附加到虚拟机实例的服务——诸如块级存储卷或静态公共 IP 地址之类的服务，过时的快照，即使实例已经终止，仍然会产生成本。</p><p>识别和消除未使用的服务将降低成本。</p><p><strong>3）使用正确的服务和生命周期策略进行存储</strong></p><p>云存储服务的定价因使用模式而异。根据业务需求选择合适的云服务。根据预期的使用模式和延迟要求，使用存储生命周期策略将内容移动到正确的存储桶。</p><p><strong>4）安排可用时间</strong></p><p>设置不同环境的运行时间，尤其是非生产实例。例如，识别不需要全天候运行的虚拟机并设置最具成本效益的动态停止和启动计划。</p><p><strong>5）使用预留实例，现货定价</strong></p><p>估算云服务的计划使用量并购买预留实例。预留实例具有折扣价，可以显著降低成本。这种方法更适合具有长期承诺的和具有相对较低可变性的应用程序的企业。</p><p>但是，如果不能准确地估计，这可能会导致总成本增加（由于使用不足）。为此，对历史使用模式的分析和推断至关重要。同样，使用虚拟机的现货定价可以获得显著的成本效益。这最适合容错和无状态应用程序，例如大数据和分析、高性能和高吞吐量计算、机器学习和人工智能应用程序。</p><p><strong>6）架构优化</strong></p><p>无论云服务提供商如何，为云构建解决方案并选择正确的服务对于从云中获得最大价值至关重要。使用 IaaS 和云原生 PaaS 服务的正确组合可以降低成本，因为它们是基于使用的收费模式。例如，从虚拟机上的数据库迁移到完全托管的弹性数据库即服务。</p><p>此外，建立企业标准并确保在云上加入的所有应用程序都遵循优化的架构。此外，定期评估并避免解决方案中所有成本低效的架构元素，例如，最小化来自云的数据出口。</p><p><strong>7）使用容器</strong></p><p>容器提供了一种在同一虚拟机上以隔离方式运行多个应用程序的轻量级和可移植方式。与传统的虚拟机托管相比，它们能够以更高的单位硬件密度运行应用程序。如果操作正确，这可以降低总体计算成本。此外，容器还具有敏捷性、跨环境简化部署和可移植性的优势。</p><p><strong>8）AI/ML 的训练环境</strong></p><p>在大型数据集上完成 AI/ML 训练需要大量计算，并且重复执行以微调和提高模型的准确性。在公共云上重复执行此操作可能会变得昂贵，尤其是对于大型数据集。其中一种方法是在内部设置 AI/ML 培训基础设施，并在公共云上运行经过培训的模型。这样可以更好地控制与培训相关的成本。</p><p>有些供应商提供专用硬件 (GPU) 和软件的捆绑解决方案，以在本地设置 AI/ML 培训基础设施。关于 AI/ML 培训设置的基础设施位置的决策应在考虑业务需求和成本的情况下整体完成。</p><p><strong>9）使用工具监控使用情况、重新基线并时常调整</strong></p><p>使用工具查看云费用。所有云供应商都提供云原生服务，许多第三方供应商提供解决方案来组织、预算、跟踪、监控、报告和优化云成本。使用资源标记和元数据来查看和跟踪资源，以获得使用情况、成本跟踪和缓解的实时情况。这需要主动管理而不是被动管理，因为每次延误都要花费金钱。</p><p><strong>4、结论</strong></p><p>云成本管理可以将云成本智能嵌入到企业的工作中。这样，云成本管理将成为云转型不可或缺的一部分，实现优化成本的框架应该嵌入到云采用生命周期中。有了适当的防范措施，它将推动一种注重成本的文化，并将成为目标运营模式的重要组成部分。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/498641381&quot;&gt;https://zhuanlan.zhihu.com/p/498641381&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;近年来，各行各业的企业的云采用率迅速增加，预计向云</summary>
      
    
    
    
    <category term="架构" scheme="http://zhangyu.info/categories/%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="架构" scheme="http://zhangyu.info/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>谈谈如何设计好网站的URL</title>
    <link href="http://zhangyu.info/2022/04/12/%E8%B0%88%E8%B0%88%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E5%A5%BD%E7%BD%91%E7%AB%99%E7%9A%84URL/"/>
    <id>http://zhangyu.info/2022/04/12/%E8%B0%88%E8%B0%88%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E5%A5%BD%E7%BD%91%E7%AB%99%E7%9A%84URL/</id>
    <published>2022-04-11T16:00:00.000Z</published>
    <updated>2022-04-12T01:49:09.960Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>来源: IT架构师联盟  </p><blockquote><p>URL设计，这是一个非常重要但是往往容易给忽略的部分，也比较少架构师会去关注或者重视。在整个系统架构中，有时候一个好的URL设计对整个系统会起到一个好的作用。</p></blockquote><p>URI和URL及URN</p><p>URL大家都比较熟悉，其他两个词就比较陌生了。URI、URL和URN是识别、定位和命名互联网上的资源的标准途径。1989年Tim Berners-Lee发明了互联网（World Wide Web）。WWW被认为是全球互连的实际的和抽象的资源的集合–它按需求提供信息实体–通过互联网访问。实际的资源的范围从文件到人，抽象的资源包括数据库查询。</p><p>因为要通过多样的方式识别资源（人的名字可能相同，然而计算机文件只能通过唯一的路径名称组合访问），所以需要标准的识别WWW资源的途径。为了满足这种需要，Tim Berners-Lee引入了标准的识别、定位和命名的途径：URI、URL和URN。</p><ul><li><p>  URI：Uniform Resource Identifier，统一资源标识符</p></li><li><p>  URL：Uniform Resource Locator，统一资源定位符</p></li><li><p>  URN：Uniform Resource Name，统一资源名称</p></li></ul><p>在这个体系中的URI、URL和URN是彼此关联的。URI的范畴位于体系的顶层，URL和URN的范畴位于体系的底层。这种排列显示URL和URN都是URI的子范畴。</p><p><img src="https://nimg.ws.126.net/?url=http://dingyue.ws.126.net/2022/0412/c967c46fj00ra7dat000yd200bt00brg00bt00br.jpg&thumbnail=660x2147483647&quality=80&type=jpg">  </p><p>URI可被视为定位符（URL），名称（URN）或两者兼备。统一资源名（URN）如同一个人的名称，而统一资源定位符（URL）代表一个人的住址。换言之，URN定义某事物的身份，而URL提供查找该事物的方法。</p><p>用于标志唯一书目的ISBN系统是一个典型的URN使用范例。例如，ISBN 0-486-27557-4无二义性地标志出莎士比亚的戏剧《罗密欧与朱丽叶》的某一特定版本。为获得该资源并阅读该书，人们需要它的位置，也就是一个URL地址。在类Unix操作系统中，一个典型的URL地址可能是一个文件目录，例如file:///home/username/RomeoAndJuliet.pdf。该URL标志出存储于本地硬盘中的电子书文件。因此，URL和URN有着互补的作用。</p><p>URL</p><p>URL是Internet上用来描述信息资源的字符串，主要用在各种WWW客户程序和服务器程序上。采用URL可以用一种统一的格式来描述各种信息资源，包括文件、服务器的地址和目录等。</p><p><img src="https://nimg.ws.126.net/?url=http://dingyue.ws.126.net/2022/0412/dda5bb43j00ra7dau000xd200k00074g00it006o.jpg&thumbnail=660x2147483647&quality=80&type=jpg">  </p><p>URL的格式由下列三部分组成：</p><ul><li><p>  协议（或称为服务方式）</p></li><li><p>  存有该资源的主机IP地址（有时也包括端口号）</p></li><li><p>  主机资源的具体地址。如目录和文件名等</p></li></ul><p>第一部分和第二部分之间用”：//”符号隔开，第二部分和第三部分用”/”符号隔开。第一部分和第二部分是不可缺少的，第三部分有时可以省略。</p><p>目前最大的缺点是当信息资源的存放地点发生变化时，必须对URL作相应的改变。因此人们正在研究新的信息资源表示方法。</p><p>URN</p><p>URN（统一资源名称）是标准格式的URI，指的是资源而不指定其位置或是否存在。这个例子来自RFC3986:urn:oasis:names:specification:docbook:dtd:xml:4.1.2</p><p>URN与URL之间仍存在重大区别：</p><ul><li><p>  URN对一项资源予以持久性的识别。</p></li><li><p>  URL主要为资源标识路径。路径可能随着时间的推移发生改变，原因有二：首先，可于特定URL获取的资源可能发生改变（互联网上的内容变更非常频繁）。另外，资源可能被移至其它定位，也可能同时出现在多个定位。因此，URL往往并不具有唯一性或持久性。</p></li></ul><p>因此，URL与URN的设计相似，宗旨不同。</p><p>URN的设计旨在确保与现行标准标识符系统（例如ISSN或任何其它新标准系统）具有互操作性。因此，URN拥有与标识符系统挂钩的命名空间，有别于其它持久性标识符系统（例如DOI前缀并不代表任何标识符系统，而是指明提供标识符的相关组织) 。URL与URI则完全不考虑传统标识符系统。因此，一项期刊的URN基于其ISSN号，URN:ISSN 命名空间则适用ISSN相关规则。相反的，期刊主页的URL往往与ISSN号无关。</p><p>URN的结构</p><p>URN采用URI语法。</p><p>URN:NID:NSS</p><p>因此，URN至少包括三个部分：</p><ul><li><p>  URN：URN首先标注URN方案Scheme</p></li><li><p>  NID：于IANA（互联网号码分配机构）注册的命名空间标识符</p></li><li><p>  NSS：NSS（命名空间特定字符串）予以精确标识</p></li></ul><p>ISSN与URN</p><p>ISSN是最早接受URN方案的书目标识符，以期通过标准方式在互联网上进行使用和表达。每一个ISSN号都可根据以下语法以URN形式予以表达：</p><ul><li><p>  URN:ISSN:xxxx-xxxx</p></li><li><p>  urn:issn:xxxx-xxxx</p></li><li><p>  UrN:IsSn:xxxx-xxxx</p></li></ul><p>xxxx-xxxx即转化为URN的ISSN号，例如：urn:issn:1234-1231</p><p>建议将URN:ISSN记录于可获取的网络资源（例如在线发布的报刊等）的嵌入元数据中。以HTML文件为例，URN:ISSN应录入于HEAD部分：</p><p>META NAME=”Identifier” SCHEME=”URN:ISSN” CONTENT=”1234-1231”</p><p>URI</p><p>URI是以某种统一的（标准化的）方式标识资源的简单字符串，一般由三部分组成：</p><ul><li><p>  访问资源的命名机制</p></li><li><p>  存放资源的主机名</p></li><li><p>  资源自身的名称，由路径表示</p></li></ul><p>统一资源标志符URI就是在某一规则下能把一个资源独一无二地标识出来。URL是URI的子集。</p><p><img src="https://nimg.ws.126.net/?url=http://dingyue.ws.126.net/2022/0412/465561e7j00ra7dau000ed200bj006mg00bj006m.jpg&thumbnail=660x2147483647&quality=80&type=jpg">  </p><p>典型情况下，这种字符串以scheme开头，语法如下：</p><p><img src="https://nimg.ws.126.net/?url=http://dingyue.ws.126.net/2022/0412/84ced650j00ra7dau000vd200c5005gg00c5005g.jpg&thumbnail=660x2147483647&quality=80&type=jpg">  </p><p>有的URI指向一个资源的内部。这种URI以”#”结束，并跟着一个anchor标志符（称为片断标志符）。</p><p>相对URI不包含任何命名规范信息。它的路径通常指同一台机器上的资源。相对URI可能含有相对路径（如：“..”表示上一层路径），还可以包含片断标志符。</p><p>URI的常见问题</p><ul><li><p>  难以输入，URI不必要的冗长</p></li><li><p>  莫明其妙的大写字母</p></li><li><p>  不常见的标点符号</p></li><li><p>  在纸介质上显示很困难，一些字符在纸上打印出来不容易辨认</p></li><li><p>  主机和端口的问题除了scheme-specific部分，domain和port也可能给用户带来困惑。</p></li></ul><p>不成熟的技术：Data URI</p><p>Data URI是由RFC 2397定义的一种把小文件直接嵌入文档的方案。通过如下语法就可以把小文件变成指定编码直接嵌入到页面中：</p><p>data:[][;base64],</p><p>MIME-type：指定嵌入数据的MIME。其形式是[type]/[subtype]; parameter，比如png图片对应的MIME是image/png。parameter可以用來指定附加的信息，更多情況下是用于指定text/plain和text/htm等的文字编码方式的charset参数。默认是text/plain;charset=US-ASCII。</p><p>base64：声明后面的数据的编码是base64的，否则数据必须要用百分号编码（即对内容进行urlencode）。</p><p>Data URI的优点：</p><ul><li><p>  减少HTTP请求数，没有了TCP连接消耗和同一域名下浏览器的并发数限制。</p></li><li><p>  对于小文件会降低带宽。虽然编码后数据量会增加，但是却减少了http头，当http头的数据量大于文件编码的增量，那么就会降低带宽。</p></li><li><p>  对于HTTPS站点，HTTPS和HTTP混用会有安全提示，而HTTPS相对于HTTP来讲开销要大更多，所以Data URI在这方面的优势更明显。</p></li><li><p>  可以把整个多媒体页面保存为一个文件。</p></li></ul><p>Data URI的缺点：</p><ul><li><p>  无法被重复利用，同一个文档应用多次同一个内容，则需要重复多次，数据量大量增加，增加了下载时间。</p></li><li><p>  无法被独自缓存，所以其包含文档重新加载时，它也要重新加载。</p></li><li><p>  客户端需要重新解码和显示，增加了点消耗。不支持数据压缩，base64编码会增加1/3大小，而urlencode后数据量会增加更多。</p></li><li><p>  不利于安全软件的过滤，同时也存在一定的安全隐患。</p></li></ul><p>转换工具：Data URI Generator</p><p>优秀的URI不会改变</p><p>什么样的URI称得上优秀的URI？优秀的URI就是不需要改变的URI。是什么迫使URI做出改变？不改变的是URI：改变的是人。理论上人们没有什么原因去改变URI，但是在实际运行中却存在着成百上千的原因。从理论上讲，域名的所有者拥有该域名下的所有URI。理论上您域名下的所有URI是完全由您控制的，所以你是可以按照自己喜欢的方式使URI变得稳定。迫使一个文件地址消失的原因是域名过期或服务器没有在继续运行。这就是为了会有这么多改来改去的链接。其中的一部分是由于缺乏远见导致的。下面是您可以听到的一些原因。</p><ul><li><p>  为了使网站更好，我们刚改版了网站。</p></li><li><p>  我们有大量过期的、保密的、无效的文档需要进行区分。</p></li><li><p>  我们发现不得不移动文件。</p></li><li><p>  我们曾经使用的是一个CGI脚本，现在我们使用的是一个二进制程序。</p></li><li><p>  我不认为URI是需要持久的，需要持久的那是URN。</p></li></ul><p>当你在服务器上修改了URI，你不会知道还有多少人会使用旧的URI。他们可能把你的链接发布到了其他网站上，他们可能把你的链接存为了书签。他们可能把你的URI告诉了别人。当一些人点击链接，但是发现链接无法打开的时候，他们就会对网站拥有者失去信心。他们会因为不能完成自己想要的目标而沮丧。</p><p>我该怎么去设计URI?</p><p>使一个URI可以持续2年、20年、200年，这是一个网站管理员的责任。这需要思想、组织和承诺。一般来说URI改变时因为文档里的一些信息发生了改变，这和URI的设计至关重要的。文件的创建日期这是不会改变的。这对分离旧的系统和新的系统非常有用。这能很好的让你开始设计一个URI。即使这个文件会被多次修改，但是他还是只会有一个创建日期。唯一例外的是一个网页是故意“最新”的，例如频道的首页。</p><p><a href="http://www.example.com/money/moneydaily/latest/">http://www.example.com/money/moneydaily/latest/</a></p><p>此URI不需要日期的主要原因是此页面时不断更新的，如果你需要者页面的存档，存档地址可以是</p><p><a href="http://www.example.com/money/moneydaily/1998/981212.moneyonline.html">http://www.example.com/money/moneydaily/1998/981212.moneyonline.html</a></p><p>（这个URI看上去不错，除了”98″和“.html”有些多余）</p><p>哪些信息需要被抛弃？</p><p>在使用日期以后，把任何信息放入URI都有可能带来问题。</p><ul><li><p>  作者的名字：著作权可能会因为版本的修改而改变，比如团队里的某些人离开使事务被转手。</p></li><li><p>  标题：这个是非常棘手的，他总是现在看起来非常合适，但是过些时间久需要改变。</p></li><li><p>  状态：如”old”,”new”,”latest”等，文件很可能会改变状态。</p></li><li><p>  访问权限：一个文件的访问权限可能会因为情况而改变，不要将文档放在”public”、”team”下。</p></li><li><p>  文件扩展名：即使是”.html”也有可能会改变。</p></li><li><p>  程序机制：如”cgi”和”exec”</p></li><li><p>  磁盘名称：这个也有用使用的！</p></li></ul><p>按文章主题进行分类</p><p>这是非常危险的操作。通常情况下，你URI中的文档分类是按你正在进行的工作进行区分的。这就可能带来隐患，你从事的领域可能会在今后发生变化。在W3C，我们期望吧“MarkUp”修改为“Markup”，后来又期望修改为“HTML”，我们不能保证现在的命名在以后是否适用。</p><p>按主题分类这是一个非常理想的分类方案，包括把整个互联网进行分类一样，这是一个非常不错的解决办法，但是从长远看存在着严重的缺陷。每个人对语言中的每个聚类的主题词都有不同的理解，网络之间的主题关系，并不是像树型那么简单。事实上，当你在你的URI中绑定分类时，未来你很有可能去改变这个分类，到时候URI就需要跟随着改变。</p><p>在URI中使用主题进行分类的一个原因是你需要一个名称作为URI的一个部分来组织内容，比如内容细分，通常来说在日期存在（日期在左边）的情况下还是非常安全的，1998/pics可以理解为，我们在1998年的照片。而不是照片中1998年我们在做什么。</p><p>不要忘记你的域名</p><p>请记住，这不仅适用于URI“路径”，同时也使用与服务器名称。在域名中无论代表公司，或文件状态，或访问级别，或者安全级别划分，要非常非常小心，特别是在使用多个域名访问一个文件的时候，不要忘记，你可以在服务器端使用重定向。</p><p>URL即UI</p><p>尽管APP和小程序在替代WEB网站。但WEB网站最终难以被完全替代。未来的很多年，URL还将成为用户界面的一部分。所以一个可用性好的网站需要：</p><ul><li><p>  一个容易记忆及拼写的域名</p></li><li><p>  简短的URL网址</p></li><li><p>  容易输入的URL</p></li><li><p>  可视化的URL结构</p></li><li><p>  用户可以删除URL最后的一层到达上级目录</p></li><li><p>  URL保持不变</p></li></ul><p>用户不需要像服务器一样了解每个URL，事实上更多的人是通过大概的印象访问网站的：</p><ul><li><p>  很多人会在没有访问网站前猜测网站的域名，所以你最好使用公司名称或品牌作为域名</p></li><li><p>  更多的人更喜欢记住网站名而不是将网站添加到书签，所以最好注册一个易于拼写的域名</p></li><li><p>  在用户将你的URL通过邮件告知别人时，保证你的URL要少于78个字符，因为如果URL过程可能会造成换行</p></li><li><p>  如果很多人通过输入那么最好使用简短的URL</p></li><li><p>  不要再URL中大下写混用，因为很多人会忽视大小写，但是部分服务器不会</p></li><li><p>  在服务器上进行拼写检查来减少由于拼写错误造成的问题</p></li></ul><p>来自第三网站的外链对流量很重要，所以在生成你的URL的时候要考虑到易于传播。</p><ul><li><p>  保证所有的URL都是持续可以访问的，且链向的页面不做改变。</p></li><li><p>  不要把文件的URL改来改去， 保证同一个文件前后只有一个URL。</p></li></ul><p>很多人考虑是否.COM域名是否要比.CN（国别域名）要好？是的，很多人已经习惯了域名以.COM结尾。这是由于早期由美国人开发的浏览器会自动补全.COM（现在苹果的iPad上默认也有.COM按钮），基于这种情况，我的建议是：</p><ul><li><p>  如果网站是英文的或国际性最好使用.com域名</p></li><li><p>  如果网站使用的是其他语言可以使用国别域名代替</p></li><li><p>  如果网站内容是区域性的，无所谓使用哪种域名</p></li></ul><p>国别域名相比.COM域名主要优势是，还有很多可以注册的简短的、易记的域名。</p><p>从长远的发展来看，需要大量的名称（按照人类语言习惯）来识别世界上每个实体。新的顶级域名会不断出现，但由于旧的用户习惯，旧的浏览器或软件还是会存在很多年，所以好的域名还是会影响很多年。</p><p>怎样设计一个好的URL</p><p>URL是网站UI的一部分，因此，可用的网站应该满足这些URL要求：</p><ul><li><p>  简单，好记的域名</p></li><li><p>  简短（short）的URL</p></li><li><p>  容易录入的URI</p></li><li><p>  URL能反应站点的结构</p></li><li><p>  URL是可以被用户猜测和hack的（也鼓励用户如此）</p></li><li><p>  永久链接</p></li></ul><p>记住下面四句话，你就知道应该设计什么样的URL了。</p><ul><li><p>  URL应当是用户友好的</p></li><li><p>  URL应当是可读的</p></li><li><p>  URL应当是可预测的</p></li><li><p>  URL应当是统一的</p></li></ul><p>网址根目录（level section）是非常珍贵的</p><p>对于任何一个URL而言，它最用价值的方面是在他的根目录（level section），我的观点是她必须在你写任何代码前确定下来，他会确定你网站最后是怎么组织起来的。当你想建立新的站点的时候，一定要想好哪些根目录的网址是需要保留的。</p><p>命名空间是一个非常有用的拓展网址方案</p><p>命名空间是一个建立容易记忆的良好网址结构的方案。那命名空间是什么意思呢？下面是一个例子：</p><p><a href="https://github.com/pallets/flask/issues">https://github.com/pallets/flask/issues</a></p><p>在上面的URL中，pallets/flask是命名空间。为什么这个是有用的？因为任何跟在命名空间后面的部分都将成为level section。在可以在任何 / 后面跟上/issues或/wiki来生成页面。</p><p>为了命名空间的通用性，保持命名空间的简洁，不要将内容加在前面或后面，类似/feature/ / 或/ / /feature.</p><p>查询字符串对排序和过滤非常的有用</p><p>网站都有一些查询字符串，很多网站使用多个查询字符串。他们通常使用同一的模式来对页面或内容进行排序或过滤（sort=alpha&amp;dir=desc），他们可以是URL更加简单和易记。</p><p>需要记住的是，在URL上没有带任何查询字符串时需要显示一个不同的页面。</p><p>非ASCII字符出现在网址中</p><p>非 ASCII字符不但难以输入，而且还难以记忆。URL是为人设计的，不是为搜索引擎设计的。在URL中堆砌关键词的手法，并不罕见，比如下面的URL：这样的URL在Google 2003年修改算法前对SEO很有效，但是一些SEO教程上现在还是叫你将关键词写入URL。他们错了，忽略他们。</p><p>除此之外，你还需要记住以下两点：</p><ul><li><p>  下划线很不好，请在URL中使用中划线。</p></li><li><p>  在URL中使用一些短的、通俗的词，如果一段URL中有中划线会特殊的字符，那它可能有些长。</p></li></ul><p>URL是为人使用的，也是为人设计的。</p><p>一个URL就是一个协议</p><p>一个URL是一个协议，你需要让他保存做够长的时间。一旦有人点击了你的URL，他们就是和你签署有了一个协议，他们期望下次再打开这个网址的时候看到同样的内容。在你的URL公布出去以后，不要轻易的去修改它，如果你真的迫不得已要去修改它，那么请对原来的URL做跳转。</p><p>任何页面都需要有个URL</p><p>在理想的情况下，每个单独的页面都需要一个URL，这个URL在复制到别的浏览器的时候要还可以访问。事实上这样做是完全不可能的，直到新的HTML5浏览器历史记录Javascript API的出现，这里有两种方法：</p><ul><li><p>  onReplaceState：这个方法取代了浏览器历史记录中的URL，使URL留下后退按钮。</p></li><li><p>  onPushState：这个方法能push一个新的URL到浏览器历史记录，用来更换浏览器中的历史堆栈。</p></li></ul><p>这两个新的方法可以改变浏览器中的访问历史，有了这个新的特征，我们需要为页面设计后退页面。在使用前需要问自己：这个动作是否需要产生新的内容或用不同的方法显示相同的内容。</p><ul><li><p>  生成新的内容：你应该使用onPushState（如分页链接）</p></li><li><p>  用不同的方法显示相同的内容：你应该使用onReplaceState（如排序了过滤）</p></li></ul><p>通过自己的判断，想想你需要实现怎样的效果。</p><p>链接需要看上去像个链接</p><p>很多生成链接的方法如、，如果你点击它们它们会打开新的页面，当你将鼠标放在标签时，你的浏览器状态栏就会告诉你URL地址是什么。在使用onReplaceState和onPushState时不要破坏这样的规则。</p><p>POST后的网站需要转向</p><p>过去很多开发人员喜欢生成不能再次使用的URL，这种URL也称为Post-specific URLs，当你提交一个表单的时候你不会发现地址栏中的URL会发生任何变化，当你将复制URL重新打开后却得到一个错误的页面。这样的URL本身没有任何错误，他们的主要作用是进行重定向和在API中使用，并不应该给用户使用。</p><p>一定要短</p><p>为了URI能被方便的录入，写下，拼写和记忆，URI 要尽可能的短，根据w3c 提供的参考数据，一个URI的长度最好不要超过80个字节（这并非一个技术限制，经验和统计提供的数据），包括schema和host,port等。</p><p>大小写策略</p><p>URI的大小写策略要适当，要么全部小写，要么首字母大写，应避免混乱的大小写组合，在Unix 世界，文件路径队大小写是敏感的，而在Windows 世界，则不对大小写敏感。</p><p>允许URL管理URL映射</p><p>管理员可以重新组织服务器上的文件系统结构，而无需改动URI，这就需要URI和真实的服务器文件系统结构之间有一个映射机制。而不是生硬的对应。这种映射机制可以通过如下技术手段实现：</p><ul><li><p>  Aliases，别名，Apache上的目录别名，IIS上的虚拟目录</p></li><li><p>  Symbolic links，符号链接，Unix世界的符号链接</p></li><li><p>  Table or database of mappings，数据库映射，URI和文件系统结构的对应关系存储在数据库中。</p></li></ul><p>标准的重定向</p><p>管理员可以简单的通过修改HTTP 状态代码来实现服务器文件系统结构变更之后的URL兼容，可以利用的HTTP Status Code有：</p><ul><li><p>  301 Moved Permanently ([RFC2616] section 10.3.2)</p></li><li><p>  302 Found (undefined redirect scheme, [RFC2616] Section 10.3.3)</p></li><li><p>  Temporary Redirect ([RFC2616] Section 10.3.8)</p></li></ul><p>用独立的URI</p><p>技术无关的URI</p><ul><li><p>  提供动态内容服务时，应使用技术无关的URI。即URI不暴露服务器端使用的脚本语言，平台引擎，而这些语言，平台，引擎的变化也不会导致URI的变更。因此，sevelet,cgi-bin之类的单词不应该出现在URI 中。</p></li><li><p>  提供静态内容服务时，应当隐去文件的扩展名取而代之的技术是content-negotiation, proxy, 和URI mapping</p></li></ul><p>身份标志和Session机制</p><ul><li><p>  使用标准的身份认证机制，而不是每个用户一个特定的URI</p></li><li><p>  使用标准的Session机制，而不是把Session ID放在URI中使用</p></li></ul><p>内容变更时使用标准转向：</p><ul><li><p>  对变更的内容使用标准的重定向</p></li><li><p>  对删除的资源使用 HTTP 410</p></li></ul><p>提供索引代理：索引策略</p><ul><li><p>  Content-Location</p></li><li><p>  Content-MD5</p></li></ul><p>提供适当的缓存信息：</p><ul><li><p>  缓存相关的HTTP头</p></li><li><p>  缓存策略</p></li><li><p>  缓存生成内容HTTP HEAD和HTTP GET</p></li></ul><p>总结</p><ul><li><p>  URI 是Web UI 的一部分，应当像对待网站Logo 和公司品牌一样对待它</p></li><li><p>  URI 是网站和普通用户之间的唯一接口，应当像对待你的商务电话号码一样对待它</p></li></ul><p>URL中井号的作用</p><ul><li><p>  井号在URL中指定的是页面中的一个位置。井号作为页面定位符出现在URL中，浏览器读取这个URL后，会自动将位置滚动至指定区域。</p></li><li><p>  井号后面的数据不会发送到HTTP请求中。井号后面的参数是针对浏览器起作用的而不是服务器端。</p></li><li><p>  任何位于井号后面的字符都是位置标识符。不管第一个井号后面跟的是什么参数，只要是在井号后面的参数一律看成是位置标识符。比如这样一个链接（<a href="http://example.com/?color=#fff&amp;;shape=circle%EF%BC%89%EF%BC%8C%E5%90%8E%E9%9D%A2%E8%B7%9F%E7%9A%84%E5%8F%82%E6%95%B0%E6%98%AF%E9%A2%9C%E8%89%B2%E5%92%8C%E5%BD%A2%E7%8A%B6%EF%BC%8C%E4%BD%86%E6%98%AF%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%8D%B4%E5%B9%B6%E4%B8%8D%E8%83%BD%E7%90%86%E8%A7%A3URL%E4%B8%AD%E7%9A%84%E5%90%AB%E4%B9%89%E3%80%82%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A5%E6%94%B6%E5%88%B0%E7%9A%84%E5%8F%AA%E6%98%AF%EF%BC%9Ahttp://example.com/?color=">http://example.com/?color=#fff&amp;;shape=circle），后面跟的参数是颜色和形状，但是服务器却并不能理解URL中的含义。服务器接收到的只是：http://example.com/?color=</a></p></li><li><p>  改变井号后面的参数不会触发页面的重新加载但是会留下一个历史记录。仅改变井号后面的内容，只会使浏览器滚动到相应的位置，并不会重现加载页面。浏览器并不会去重新请求页面，但是此操作会在浏览器的历史记录中添加一次记录，即你可以通过返回按钮回到上次的位置。这个特性对Ajax来说特别的有用，可以通过设置不同井号值，来表示不同的访问状态，并返回不同的内容给用户。</p></li><li><p>  可以通过javascript使用location.hash来改变井号后面的值。window.location.hash这个属性可以对URL中的井号参数进行修改，基于这个原理，我们可以在不重载页面的前提下创造一条新的访问记录。除此之外，HTML 5新增的onhashchange事件，当#值发生变化时，就会触发这个事件。</p></li><li><p>  Googlebot对井号的过滤机制。默认情况下Google在索引页面的时候会忽略井号后面的参数，同时也不会去执行页面中的javascript。然而谷歌为了支持对Ajax生成内容的索引，定义了如果在URL中使用“#!”，则Google会自动将其后面的内容转成查询字符串_escaped_fragment_的值。比如最新的twitter URL：<a href="http://twitter.com/#!/username%EF%BC%8CGoogle%E4%BC%9A%E8%87%AA%E5%8A%A8%E8%AF%B7%E6%B1%82http://twitter.com/?\_escaped\_fragment\_=/username%E6%9D%A5%E8%8E%B7%E5%8F%96Ajax%E5%86%85%E5%AE%B9%E3%80%82">http://twitter.com/#!/username，Google会自动请求http://twitter.com/?\_escaped\_fragment\_=/username来获取Ajax内容。</a></p></li></ul><p>实例：Flickr API 中的URL规则</p><p>Flickr API中的URL规则非常值得我们学习，下面就来揭开Flickr URL的神秘面纱。</p><p>Flickr图片地址</p><p>URL主要有下面三类：</p><ul><li><p>  <a href="http://farm{farm-id}.static.flickr.com/%7Bserver-id%7D/%7Bid%7D/_%7Bsecret%7D.jpg">http://farm{farm-id}.static.flickr.com/{server-id}/{id}\_{secret}.jpg</a></p></li><li><p>  <a href="http://farm{farm-id}.static.flickr.com/%7Bserver-id%7D/%7Bid%7D/_%7Bsecret%7D/_/[mstzb/].jpg">http://farm{farm-id}.static.flickr.com/{server-id}/{id}\_{secret}\_\[mstzb\].jpg</a></p></li><li><p>  <a href="http://farm{farm-id}.static.flickr.com/%7Bserver-id%7D/%7Bid%7D/_%7Bo-secret%7D/_o.(jpg|gif|png)">http://farm{farm-id}.static.flickr.com/{server-id}/{id}\_{o-secret}\_o.(jpg|gif|png)</a></p></li></ul><p>尺寸字母后缀说明：</p><p>s small square,小正方形,75×75 t thumbnail,缩微图,最长边为100 m small 小图,最长边为240 – medium,中图,最长边为500 z medium 640,中等尺寸640,最长边为640 b large,大图,最长边为1024 o original image,原始图片,可能是jpg,或是png,或是gif</p><p>注意：原始图片有些不同，他们有自己的密钥，在返回数据中被称为originalsecret，除此之外还包含原始图片格式，被称为originalformat。这些值都会在向API请求原始图片时返回。</p><p>以下为图片地址URL示例：</p><p><a href="http://farm1.static.flickr.com/2/1418878/_1e92283336/_m.jpg">http://farm1.static.flickr.com/2/1418878\_1e92283336\_m.jpg</a></p><ul><li><p>  farm-id: 1</p></li><li><p>  server-id: 2</p></li><li><p>  photo-id: 1418878</p></li><li><p>  secret: 1e92283336</p></li><li><p>  size: m</p></li></ul><p>Flickr网页地址URL</p><p>个人档案及相片页面的URL使用NSID（带@ 符号的数字）或自定义URL（需要设置），可以通过请求flickr.people.getInfo获取自定义URL。不管用户是否设置自定义URL，NSID一直是有效的。所以你可以使用用户ID来进行所有的请求。</p><p>你可以非常轻松的创建个人档案、影集、所有照片、个人相片或影集的URL：</p><ul><li><p>  <a href="http://www.flickr.com/people/%7Buser-id%7D/">http://www.flickr.com/people/{user-id}/</a> – profile</p></li><li><p>  <a href="http://www.flickr.com/photos/%7Buser-id%7D/">http://www.flickr.com/photos/{user-id}/</a> – photostream</p></li><li><p>  <a href="http://www.flickr.com/photos/%7Buser-id%7D/%7Bphoto-id%7D">http://www.flickr.com/photos/{user-id}/{photo-id}</a> – individual photo</p></li><li><p>  <a href="http://www.flickr.com/photos/%7Buser-id%7D/sets/">http://www.flickr.com/photos/{user-id}/sets/</a> – all photosets</p></li><li><p>  <a href="http://www.flickr.com/photos/%7Buser-id%7D/sets/%7Bphotoset-id%7D">http://www.flickr.com/photos/{user-id}/sets/{photoset-id}</a> – single photoset</p></li></ul><p>同样还可以构建其他页面，比如用户在登录的情况，可以让他们链向 <a href="http://www.flickr.com/photos/me//">http://www.flickr.com/photos/me/\</a>* 或 <a href="http://www.flickr.com/people/me//">http://www.flickr.com/people/me/\</a>* ，將使用其自己的ID 取代「me」。</p><p>链接示例：</p><ul><li><p>  <a href="http://www.flickr.com/photos/12037949754@N01/">http://www.flickr.com/photos/12037949754@N01/</a></p></li><li><p>  <a href="http://www.flickr.com/photos/12037949754@N01/155761353/">http://www.flickr.com/photos/12037949754@N01/155761353/</a></p></li><li><p>  <a href="http://www.flickr.com/photos/12037949754@N01/sets/">http://www.flickr.com/photos/12037949754@N01/sets/</a></p></li><li><p>  <a href="http://www.flickr.com/photos/12037949754@N01/sets/72157594162136485/">http://www.flickr.com/photos/12037949754@N01/sets/72157594162136485/</a></p></li></ul><p>短网址服务</p><p>Flickr 针对上传的图片提供短网址服务。Flickr上每张相片均拥有经数学计算的简短URL：<a href="http://flic.kr/p/%7Bbase58-photo-id%7D">http://flic.kr/p/{base58-photo-id}</a></p><p>利用Base58将数字和字母进行组合对照片ID进行压缩。Base58和base62[0-9a-zA-Z]差不多，只是为了更加利于辨认，删除了容易混淆的0, O, I,和 l。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;来源: IT架构师联盟  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;URL设计，这是一个非常重要但是往往容易给忽略的部分，也比较少架构师会去关注或者重视。在整个系统架构中，有时候一个好的URL设计对整个系统会起到一个好的作用。&lt;/p&gt;
&lt;/bloc</summary>
      
    
    
    
    <category term="优化" scheme="http://zhangyu.info/categories/%E4%BC%98%E5%8C%96/"/>
    
    
    <category term="优化" scheme="http://zhangyu.info/tags/%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
</feed>
