{"meta":{"title":"张天师","subtitle":"","description":"专业，团队","author":"张天师","url":"http://zhangyu.info","root":"/"},"pages":[{"title":"about","date":"2021-03-15T13:48:47.000Z","updated":"2021-03-15T15:05:42.638Z","comments":true,"path":"about/index.html","permalink":"http://zhangyu.info/about/index.html","excerpt":"","text":"本博客hexo主题基于hexo-theme-3-hexo 修改而来 https://github.com/yelog/hexo-theme-3-hexo"}],"posts":[{"title":"云服务器ECS选购指南及省钱法宝","slug":"云服务器ECS选购指南及省钱法宝","date":"2022-03-07T16:00:00.000Z","updated":"2022-03-08T17:02:32.013Z","comments":true,"path":"2022/03/08/云服务器ECS选购指南及省钱法宝/","link":"","permalink":"http://zhangyu.info/2022/03/08/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8ECS%E9%80%89%E8%B4%AD%E6%8C%87%E5%8D%97%E5%8F%8A%E7%9C%81%E9%92%B1%E6%B3%95%E5%AE%9D/","excerpt":"","text":"云服务器ECS选购指南及省钱法宝（强烈建议收藏） 作者 | 阿**里云弹性计算产品专家 马小婷** https://developer.aliyun.com/article/872102 今天给大家带来的分享是如何购买云服务器ECS以及怎么买更省钱，分为四个部分： 第一部分介绍云服务器ECS的基本概念，告诉大家购买ECS实例时看哪些参数。就像小书生要买一部手机，会关注内存大小、CPU频率、屏幕分辨率、相机参数等，选购ECS实例同样可以通过参数选择来满足自己的上云需求。 第二部分介绍接云服务器ECS实例规格族，详细介绍阿里云主要的ECS产品系列。（时间紧张的情况下可以跳到第三部分） 第三部分详细讲解ECS的选型技巧，具体讲解不同场景（如大数据/数据库等）下如何选择ECS实例，或者某个ECS实例适用于怎样的生产、工作场景，重点干货部分，不容错过。 第四部分介绍如何省钱省力的来使用ECS，在满足自己需要的前提下，让你上云省钱更经济。 01 云服务器ECS基础概念 云服务器的基础概念第一部分会给大家介绍云服务器的一些基本概念。 在开始前，大家可以回想一下，我们自己购买笔记本电脑的时候会考虑哪些因素？我自己会先选择品牌，一般情况下在确定了品牌之后，接下来就会考虑硬件配置，主要是物理硬件的配置和软件的配置。 硬件配置上，我首先会考虑计算性能，像CPU和内存的大小、CPU的型号等；第二就是存储，笔记本电脑的磁盘有多大；第三部分就是网络能力，比如网卡有几个，对于玩游戏的同学来说，显卡配置也很重要。除了硬件配置外，我也会考虑电脑的操作系统是什么样的，比如Mac OS， windows或ubuntu等。而拿到电脑之后，我们首先会做一些基础应用软件的安装和配置，包括防火墙等保证我们整个应用环境的安全性。 这是我在现实生活中去购买一台物理电脑的流程，其实这些概念在云上也是适用的，比如说我们在选择一些物理硬件的参数的时候，选CPU和内存，对应在云上的话，就是选择ECS实例的 CPU 和内存大小以及 CPU 的型号。 存储这一块，磁盘在云上对应的概念就是块存储，在云上块存储其实是包含两个概念，一个概念是云盘，一个概念是本地盘。有一个跟我们现实生活中不太一样的点，是云上的块存储，我们在购买的过程中需要指定用作系统盘还是用作数据盘的。而现实生活中买了一个电脑里面是有一块磁盘，然后我们自己会把磁盘分成系统盘还是数据盘，但在云上的系统盘和数据盘是需要分开购买的，这是一点点区别。 在网络这一块其实也是类似的，云上提供弹性网卡，让用户通过访问云服务器就能够联通到网上。 除了这些物理硬件以外，要让一个云服务器真正的跑起来，跟现实生活一样，我们也需要去安装一个操作系统，这个操作系统在云上的概念就是镜像，阿里云提供多种不同的镜像版本供大家选择。 除此以外，云服务器还会有一些特殊的概念，比如安全组，本质上是通过一些规则来限定访问的流量，即被哪些应用可以访问。 我们在买一个电脑之后，这个物理机在手上，你想要什么时候使用就可以什么时候使用。在云上买完一个云服务器之后，因为这个服务器是在云端或者说在远端，我们访问云服务器的方式就跟我们平时打开一个电脑不太一样，我们需要通过阿里云的控制台或者通过远程连接的工具来登录到我们的云服务器上去。 还有一个小概念是云上的容灾备份能力，就是快照。现实生活中，如果我们的电脑磁盘出现了故障，数据出现了损坏就无能为力了，或者只能够找专业的人把数据能够找回来，但是不能够保证说所有的数据都能找回来。云上有快照这样一个概念，它的意思是说对云盘的某一个时间点的数据拍一张照，本质上就是会把磁盘上所有的数据记录下来，如果出现了问题，我们就可以通过快照，快速的回滚到某一个时间点的数据，这样能够保证在业务出现了问题的情况下，快速做灾备的恢复。 整体介绍完云服务器的基本概念之后，接下详细介绍一下云服务器的存储和网络的概念。 云上的三种存储方式第一种是前面已经介绍的块存储的模式，用户创建了一个块存储之后，可以把块存储挂载到实例上，就跟自己使用笔记本电脑过程中，电脑自带的磁盘不够用了，去买移动硬盘来插上来类似。块存储有三种类型，包括普通的高效云盘，还有SSD云盘，以及超高性能超低延迟的ESSD云盘。 第二种存储方式是文件存储，每一个块存储只能够挂载到一个云服务器上，而每个文件存储可以被多台ECS使用。 第三种存储形态是对象存储形态OSS，这个就类似于百度云盘，使用这种存储的方式，更多的通过一个链接来做文件的读取。 云上的网络网络部分主要是两个概念，专有网络VPC和交换机。 第一个是专有网络VPC，专有网络是在云上为用户划分一个私有网络，用户通过创建VPC可以创建逻辑上彻底隔离的一个网络环境，每一个VPC都是由一个路由器以及一个以上的交换机组成的。用户一旦创建了一个VPC专有网络，阿里云会自动为用户创建一个对应的路由器，来完成VPC下所有网络的转发。同一个VPC下的实例之间的内网是互通的，即在同一个VPC下实例之间可以通过内网IP地址来互相访问。 第二个概念是交换机，前面已经介绍了，一个VPC至少有一个路由器。交换机是专有网络的基础网络设备，用来连接不同的实例资源，我们可以通过交换机，在每一个可用区创建多个交换机来划分子网，然后多个交换机之间是可以通过路由器来实现连接和转发。以上是存储和网络的一些基础的概念。 云服务器ECS的使用流程下面我们介绍一下使用ECS的流程。 一个ECS的实例，我们可以把它理解成一台虚拟机，它包含内存、磁盘、网络和操作系统等软硬件。而一个ECS服务器实例是多大的规格，底层的物理硬件是什么样子的，是由对应的实例规格和实例规格族来决定的。实例规格族代表了实例适用的业务场景，它决定了CPU和内存配比，以及底层的物理硬件是什么样子的。实例规格代表的是实例的大小，比如说 CPU的数量是多少。 在确定了实例规格之后，我们还需要去选择对应的存储，因为只有CPU和内存的话，数据是没有办法存放的，所以就会有一个块存储。块存储有两种，一种是云盘，一种是本地盘。云盘其实是云上的一种三副本的存储形态，能够给用户提供高可用的能力。云盘主要用来做系统盘和数据盘，只需要像物理盘一样把它格式化就可以使用了，而本地盘可能更多的主要是用来做数据盘。 选择完了计算存储，我们接下来就要看对应的操作系统，云上的操作系统指的是镜像，目前阿里云提供多种镜像的来源，包括官方提供的这种公共镜像、第三方市场提供的镜像、用户自定义镜像，还允许不同的用户之间共享镜像。 网络方面阿里云会有一个网络带宽，用户可以直接指定。 我们把实例的计算、存储、网络以及操作系统等参数制定好之后，就可以创建一个跟我们物理的笔记本电脑一样的云服务器。 创建完之后，我们通过阿里云的控制台，或者是通过阿里云的APP，可以直接连接和访问已购买的云服务器。 02 ECS实例规格族介绍 第二部分我会给大家介绍一下ECS实例的规格族是怎么命名的，大家可能在这一块会有比较多的疑问。目前阿里云提供几百种实例规格，所以在选择的过程中会眼花缭乱，其实只要理解了ECS的实例规格族的命名方式，和它的信息布局，我们就能够很好的选型了。 实例的架构类型、规格分类与详细信息 在阿里云控制台的购买页面上可以看到，实例规格族的选择上分成三大模块：架构、分类、具体信息。最上面就是我们的实例规格架构的类型，有三种架构类型，分别是通用的X86的架构、异构计算（像GPU或者是FPGA、NPU等）、阿里云自研的神龙裸金属架构。 在每种架构下面会有实例规格的分类，从上图可以看到在X86的这种计算型态下，分成了7大类实例规格，不同实例规格代表了不同的硬件配置，选择任何一个实例规格的分类之后，我们可以看到对应实例规格的详细信息，这些信息主要分为四部分： 第一个就是实例规格族的详细信息，包括对应的规格族和实例规格的代称，这里可以通过点击小问号，能够看到实例规格族的一些详细的描述。第二部分是 CPU和内存大小的信息，这里是大家在选型的过程中会比较关注的。第三部分是实例的网络能力信息，包括实例内网的带宽和收发包的能力。第四部分是CPU的处理型号的信息，包括处理器的主频和睿频这两部分信息。 企业级实例 VS 入门级实例 在控制台的购买页面上可以看到，ECS的实例规格族特别多，单纯从CPU和内存是无法判断它们的区别，所以我们需要从宏观上来看。阿里云ECS的实例规格整体是分成两大类，一类是企业级实例，一类是入门级实例。 企业级实例是阿里云在2016年9月份才推出的，其特点是vCPU是独享的，也就意味着我们创建一个企业级实例的时候，实例vCPU与我们底层物理的 CPU是绑定了的，底层的物理CPU就不可能再分配给其他的实例了，所以企业级的实例不会出现资源的争抢，因此能保证性能稳定，并且企业级实例提供了非常严格的SLA性能保证。 而入门级实例就是vCPU跟底层的物理的CPU是不绑定的，意味着可能每个vCPU是随机分配到底层的空闲的一个物理CPU上，如果同一个物理的物理服务器上有多个共享入门级实例的话，不同的实例就会出现资源的争抢，导致CPU的性能不稳定。 因为入门级实例存在性能不稳定的特性，所以阿里云现在仅仅提供一种入门级实例，就是在X86架构中的共享型实例， 而X86架构中的其他实例规格，以及异构架构和神龙架构中的所有实例，都是属于企业级实例。 由于企业级实例性能稳定，并且有严格的SLA的保证，所以它比较适合于对业务稳定性有比较高的要求的场景。入门级实例由于不能够保证性能稳定性，所以价格相对便宜，比较适合于一些对性能没有严格要求，或者在某些时段下才会有性能突发要求的场景，比如有些轻负载的应用或者是微服务。 共享型实例在介绍完ECS实例大的分类之后，我们来看一下共享型实例的具体信息。 我们前面讲到了只有X86架构下的共享型实例才是入门级实例。这类实例比前面实例在四要素以外多出一个参数，即“平均基准的CPU计算性能”，基准性能即实例能够持续提供的CPU性能。 共享型实例也就是入门级实例，分成两大类，第一类是属于标准的共享型实例， CPU是不绑定的，只提供基准CPU性能，所以当出现资源的争抢，是否能超出基准性能是没有保障。 另外一种特殊的共享型实例，名为突发性能型的共享实例，它主要就是照顾到某些应用在绝大多数的时候CPU的使用率可能都不高，负载都不高，但是在某些时候可能会有临时的突发的高性能要求，所以阿里云会提供突发性能的参数，所以您在购买共享型实例的时候，能够通过突发性性能来获得高于平均基准CPU性能的能力。 突发性能型的共享实例，如果应用实际用量低于了平均的基准性能，会获得对应的CPU的积分，如果在某些场景下性能要求突然提升之后，比如实例对应的 CPU的使用率超过了20%，会消耗之前累积的CPU的积分，去提升计算性能，让计算性能不会受到影响，这个是突发性能的共享型实例独有的特性。 两个特殊的实例规格除了共享型的入门级实例以外，阿里云还有两个实例规格比较特殊，就是大数据型和本地SSD。 这两种实例规格会附带一个本地存储，大数据型实例的本地存储是HDD盘，本地SSD新增的本地存储是具有非常高I/O吞吐，并且有低延迟的本地SSD盘，具体的信息大家可以在阿里云控制台查看。 企业级实例规格家谱 下面介绍企业级实例规格的家谱，方便我们快速了解各个实例家族的“亲属”关系。企业级实例规格族分成三大块，第一大块是X86计算，除了共享型以外，包括通用、计算、内存、高主频、本地SSD和大数据型都属于我们的企业级实例，企业级实例每年都在不停地迭代，所以会分成不同的代系，我们在后面会详细介绍不同的代际之间的区别。异构计算里面所有的GPU和FPGA都是属于企业级的实例，裸金属和高性能计算也是一样的。 首先，我们来介绍X86的实例规格的命名方式，分成了5种： 第一种实例规格是通用型，顾名思义就是什么场景都能够用，所以这种型号的代称是g系列，它的vCPU和内存的一个配比是1:4。 第二种实例规格是计算型，顾名思义就是在某些场景下对CPU算力的要求会更高一点，所以它的vCPU和内存的配比是1:2，然后简称为c系列。 第三种类型是内存型，提供更多的内存能力，所以它的CPU和内存的配比是1:8，也简称为r系列，r是RAM的简称 第四种和第五种分别是大数据型和本地SSD型，这两种的CPU和内存的配比都是1:4，只是它们配的本地盘的类型是不一样的，导致它们的技能和适合的场景也是不一样的。所以大数据型的简称是d，本地SSD型简称是i。 在这5个基础的实例规格上面，我们会去做一些额外的能力提升，比如说在通用型、计算型和内存型这三种类型下，增加了一些高主频的能力，正常的 CPU的主频应该是2.5G赫兹，但是我们有一些可以是做到3.2G赫兹，这种加上高主频的能力就变成了高主频型，会在前面去加上一个hf这样的一个标识。 随着技术的演进，神龙架构的神龙卡也是在不断地迭代和改善，搭载了第三代的神龙卡可以整体提升通用型、计算型和内存型这三种实例规格的性能，所以就会出现一个平衡增强型。对于大数据型的话，做了计算和存储的分离，形成了大数据存储型，简称为d2，而 d2s是在大数据的基础上，做了一些网络能力的增强，就变成了一个网络增强型。 实例规格的命名方式和规律大家通过下图能够看到阿里云实例规格的命名方式和规律。 普通的X86实例规格名称是分成了三段，第一部分表示的是产品名称，ECS是阿里云的产品；第二部分表示了实例的规格和代系，前面已经讲过hfg表示是在通用型的基础上增加了高主频的能力，然后6代表的是什么？其实它代表的是我们产品的代系，可以根据产品的代系推算对应的产品的一个新旧，比如说6代表第6代，5代表的是第5代，这个数字越大代表它是更新的一个代系，它底层的物理硬件也会越新，它的性价比相对而言也会越高。 最后一部分是实例的规格，表示的是实例的vCPU的核数，large代表2个vCPU， xlarge代表4个 vCPU，2xlarge代表的是8个vCPU，以此类推。 了解了以上命名规律，就能通过实例规格族的名称推断出来当前这个实例的CPU是什么型号、它的是什么样的代系，以及它的 CPU的数量是多少。 GPU命名规则也是类似的，只有一个不一样的点，GPU名称的的中间这一部分会提供CPU和GPU的的配比关系，因为 GPU是除了CPU以外还会提供一个额外的GPU的卡。所以我们也是直接可以通过它的规格族的格式，能够去推断出来它底层的物理的配置。 03 ECS实例选型实战 第三部分给大家实战讲一下如何做云服务器ECS的选型。 简述各种规格实例的适用场景 X86计算: • X86的通用型、计算型和存储型三种实例，CPU和内存的配比比较一致，所以比较适合做一些中小型的数据库，或者是一些数据处理的任务。• c系列的话，主要是计算型，所以比较适合于做一些计算要求比较多的，比如说做一些外部应用，或者做一些批量计算，或者是一些高性能的科学计算类的。• r系列的话，因为它的内存比较多，所以比较适合于做一些数据库或者数据分析的应用。• 高主频实例规格也是比较适合于对CPU的主频有比较高要求的高性能科学计算。• 本地SSD类型，更多的适合于做一些关系型数据库或者是NoSQL数据库的• 而D系列的大数据型，可能更适合于做一些大数据集群的一个场景，比如说像这种Map Reduce这种。 在异构这一块，分成了两大类: • GPU比较适合于做深度学习或者是图像视频的可视化的处理;• FPGA就比较适合于做图像的转码，或者音视频的解码。 裸金属和高性能计算: • 更垂直和性能要求更高的一些场景，像一些高性能的数据库或者高性能科学计算场景。 下面我们举几个例子详细介绍一下选型方法。 X86实例选型推荐 我们可以把一个web应用分成以下几个层次，每个层次做对应的推荐： • 对于Apache和Nginx的web服务器，，因为它主要做一些计算处理，所以推荐是使用一些计算型的，比如说c5、c6这样的；• 对于像 spring cloud或者说MQ这样的中间件的话，它是属于对于计算和存储的诉求都比较正常的，所以我们是推荐一些通用性的，比如说g6这样的实例规格；• 而应用型因为是属于比较通用的场景，所以G6系列就能够满足；• Redis和Memcache这种缓存应用，对内存的要求是比较高的，所以我们推荐使用内存型的，像r系列；• 对于关系型数据库，我们是可以直接使用内存型，比如说r系列配上我们的SSD云盘；• 对于NoSQL，我们推荐本地SSD型的，比如I系列；• 对于大数据的话，类似于HDFS或spark的这种，我们也有专门的大数据型的，像d系列这种的来处理;• 对于最底层的机器学习的，比如MXNet这种训练框架，会有对应的专门的GPU计算型。 GPU实例选型推荐GPU云服务器的场景主要分成两大类，第一大类是人工智能，或者叫机器学习，第二块是图形图像的处理。在机器学习里面也会分成两个场景，一个是训练，一个是推理。所以对于不同细分的垂直领域，我们给了一些规格的推荐，具体可见下图。 下面我们介绍两个相对而言比较复杂的选型场景。 大数据场景实例选型实战 第一个复杂场景是大数据的场景，类似于Hadoop、Spark这种大数据集群搭建的时候，如果我们自己手动做搭建，会把过程分成三大块：第一大块就是集群的管理节点的实例规格选型，第二块是集群的计算节点的选型，第三块是集群的数据节点的选型。 • 管理节点是比较通用的场景，所以直接选择g系列就能够很好地处理管理的任务；• 计算节点更多的是属于比较偏正常的业务负载，所以可以把g系列作为主要的选择，搭配SSD云盘；• 数据节点对存储的吞吐和网络的吞吐有比较高的要求，所以推荐使用 d系列，搭配对应的本地盘，能够完成这种数据的读取量； 所以整体来说，在同样一个大数据的集群里面，不同的任务有不同的特征，所以会选择不同的实例规格。 数据库场景实例选型实战 第二个复杂场景是关于数据库选型的： • 对于普通的业务，负载比较轻的数据库，有专门的通用型g系列，或者内存型r系列搭配高效云盘和SSD云盘就能处理，性价比会比较高。因为g系列和本地盘或者本地SSD比起来，价格还是很有优势的。高效云盘和SSD云盘的整体性能，其实也是能够满足日常数据库的场景的。• 对于业务负载要求非常高的集群，推荐本地SSD的 i 系列搭载NVMe SSD的云盘，能够实现存储的高IOPS和低延时，能够满足重载数据库的性能要求。 X86 第6代vs第5代 实例价格对比除了性能以外，大家也会关注价格，这里有一个X86里面第6代和第5代的一个价格的对比。 可以看到除了计算型的实例在某些区域下，第6代实例会比第5代10实例的价格会略高4%以外，通用通用型和内存型的包月价格，第6代普遍比第5代要便宜2%-12%，所以整体来说的话，第6代不仅仅是性能有20%的提升，而且绝大多数的产品会更便宜。 而按量付费的话，第6代的价格比第5代的价格会低37%-47%，这其实是一个非常大的让利的空间。所以在选择按量去购买ECS的时候，选择第6代会比第5代要便宜的要便宜的更多。 选型实战总结总结选型方法，有三个法则，大家可以记在心里面，在选型的过程中运用。 第一个法则是相同大小的企业级的实例比入门级的实例性能更稳定，但是入门级的实例性价比更高，因为企业级的实例它是独占了vCPU，不存在一个资源的争抢，有性能的保障，但是对于一些个人或者中小网站的应用，如果对性能的诉求并不是那么强的话，选择入门级的实例其实是一个更好的选择。 第二个法则是在相同的实例规格下，新一代的实例规格比老一代的实例规格性价比更高，这是因为新一代的实例规格，做了很多技术的演进和更新换代，能够给公有云用户释放更多的技术红利。 第三个法则是选型时不仅仅要选择合适的实例规格，而且还需要搭载合适的块存储，才能够让云上的应用达到预期的性能。云上会提供4种不同的块存储，包括高效云盘、SSD云盘、ESSD云盘和本地盘，不同的类型盘的IOPS和吞吐是不一样的，所以不仅仅要选合适的实例规格，还要选择合适的块存储，才能够形成合力，达到最佳的性能。 04 ECS省钱省力之道 在购买云服务器的时候，除了要做实例规格的选型，让选择的实例规格和业务的匹配度更高以外，我们还需要去考虑能不能更便宜，能不能够快速完成资源的交付，所以最后一部分给大家介绍一下ECS省钱省力的技巧。 省钱大法第一个是省钱大法，省钱大法意思是选好了实例规格，还需要选择最适合的付费方式，才能够得到更好优化成本。阿里云目前提供7种付费方式，例如节省计划（Saving Plan）、包年包月、预留实例券、按量付费、抢占式实例等。 如何选择合适的付费方式呢？有一个攻略，就是我们需要根据业务的稳定性和峰谷的波动情况，来选择最适合的付费方式。像节省计划、包年包月、预留实例券就比较适合于稳定的业务负载；有状态并且是动态变化的业务负载的话，可以使用按量付费；而对于完全没有状态，并且具有很高的容灾能力的，可以使用抢占式的实例来交付，因为抢占式实例的价格是可以做到按量付费实例的10% 的。 省力之道第二个是省力之道。在云上购买资源的时候，有时候会批量购买，阿里云会提供多种自动化的资源交付模式和工具，能够实现一次配置重复使用，从而提升整个云上部署的速度和效率。 比如通过控制台做批量的交付；通过部署集可以完成底层具有容灾能力的算力集群的交付；通过弹性伸缩和弹性供应，能自动化地完成资源的交付；而通过资源编排，可以把多种不同的资源组合交付。 上云选型四步走 总结一下，上云的过程中，我们需要走好四步： 第一步：对自己的业务特征做一些分析，包括对性能的要求，对网络的要求，形成一个基本的判断；第二步：针对业务特征来选择对应的ECS实例规格；第三步：选择对应的一个付费方式，只有选择最合适的付费方式，才能够实现云上的成本最优；第四步：选择合适的交付方式，帮我们省时省力地完成资源的交付。 省钱法宝的更多分享，请参考：阿里云万郁香：多样付费选择构筑成本最优的弹性体验","categories":[{"name":"阿里云","slug":"阿里云","permalink":"http://zhangyu.info/categories/%E9%98%BF%E9%87%8C%E4%BA%91/"}],"tags":[{"name":"ECS","slug":"ECS","permalink":"http://zhangyu.info/tags/ECS/"}]},{"title":"开启shareProcessNamespace后容器异常","slug":"cotainer-init","date":"2021-05-30T16:00:00.000Z","updated":"2021-05-31T12:41:15.290Z","comments":true,"path":"2021/05/31/cotainer-init/","link":"","permalink":"http://zhangyu.info/2021/05/31/cotainer-init/","excerpt":"","text":"https://qingwave.github.io/cotainer-init/ 背景目前k8s不支持容器启动顺序，部分业务通过开启shareProcessNamespace监控某些进程状态。当开启共享pid后，有用户反馈某个容器主进程退出，但是容器并没有重启，执行exec会卡住，现象参考issue 复现 创建deployment apiVersion: apps/v1 kind: Deployment metadata: labels: app: nginx name: nginx spec: selector: matchLabels: app: nginx template: metadata: labels: app: nginx name: nginx spec: shareProcessNamespace: true containers: image: nginx:alpinename: nginx 查看进程信息 由于开启了shareProcessNamespace, pause变为pid 1, nginx daemonpid为6, ppid为containerd-shim # 查看容器内进程 / # ps -efo “pid,ppid,comm,args” PID PPID COMMAND COMMAND 1 0 pause /pause 6 0 nginx nginx: master process nginx -g daemon off; 11 6 nginx nginx: worker process 12 6 nginx nginx: worker process 13 6 nginx nginx: worker process 14 6 nginx nginx: worker process 15 0 sh sh 47 15 ps ps -efo pid,ppid,comm,args 删除主进程 子进程被pid 1回收, 有时也会被containerd-shim回收 / # kill -9 6 / # / # ps -efo “pid,ppid,comm,args” PID PPID COMMAND COMMAND 1 0 pause /pause 11 1 nginx nginx: worker process 12 1 nginx nginx: worker process 13 1 nginx nginx: worker process 14 1 nginx nginx: worker process 15 0 sh sh 48 15 ps ps -efo pid,ppid,comm,args docker hang 此时对此容器执行docker命令(inspect, logs, exec)将卡住， 同样通过kubectl执行会超时。 分析在未开启shareProcessNamespace的容器中，主进程退出pid 1, 此pid namespace销毁，系统会kill其下的所有进程。开启后，pid 1为pause进程，容器主进程退出，由于共享pid namespace，其他进程没有退出变成孤儿进程。此时调用docker相关接口去操作容器，docker首先去找主进程，但主进程已经不存在了，导致异常(待确认)。 清理掉这些孤儿进程容器便会正常退出，可以kill掉这些进程或者killpause进程，即可恢复。 方案有没有优雅的方式解决此种问题，如果主进程退出子进程也一起退出便符合预期，这就需要进程管理工具来实现，在宿主机中有systemd、god，容器中也有类似的工具即init进程(传递信息，回收子进程)，常见的有 docker init, docker自带的init进程(即tini) tini, 可回收孤儿进程/僵尸进程，kill进程组等 dumb-init, 可管理进程，重写信号等 经过测试，tini进程只能回收前台程序，对于后台程序则无能为力(例如nohup, &amp;启动的程序)，dumb-init在主进程退出时，会传递信号给子进程，符合预期。 开启dumb-init进程的dockerfile如下，tini也类似 FROM nginx:alpine # tini# RUN apk add –no-cache tini# ENTRYPOINT [“/sbin/tini”, “-s”, “-g”, “–”] # dumb-initRUN wget -O /usr/bin/dumb-init https://github.com/Yelp/dumb-init/releases/download/v1.2.2/dumb-init\\_1.2.2\\_amd64RUN chmod +x /usr/bin/dumb-initENTRYPOINT [“/usr/bin/dumb-init”, “-v”, “–”] CMD [“nginx”, “-g”, “daemon off;”] init方式对于此问题是一种临时的解决方案，需要docker从根本上解决此种情况。容器推荐单进程运行，但某些情况必须要运行多进程，如果不想处理处理传递回收进程等，可以通过init进程，无需更改代码即可实现。 参考[1] https://github.com/Yelp/dumb-init[2] https://github.com/krallin/tini[3] https://github.com/kubernetes/kubernetes/issues/92214","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://zhangyu.info/categories/Kubernetes/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://zhangyu.info/tags/Kubernetes/"}]},{"title":"k8s中shell脚本启动如何传递信号","slug":"docker-shell-signal","date":"2021-05-30T16:00:00.000Z","updated":"2021-05-31T12:43:18.387Z","comments":true,"path":"2021/05/31/docker-shell-signal/","link":"","permalink":"http://zhangyu.info/2021/05/31/docker-shell-signal/","excerpt":"","text":"https://qingwave.github.io/docker-shell-signal/ 背景在k8s或docker中，有时候我们需要通过shell来启动程序，但是默认shell不会传递信号（sigterm）给子进程，当在pod终止时应用无法优雅退出，直到最大时间时间后强制退出（kill -9）。 分析普通情况下，大多业务的启动命令如下 command: [“binary”, “-flags”, …] 主进程做为1号进程会收到sigterm信号，优雅退出(需要程序捕获信号); 而通过脚本启动时，shell作为1号进程，不会显示传递信号给子进程，造成子进程无法优雅退出，直到最大退出时间后强制终止。 解决方案exec如何只需一个进程收到信号，可通过exec，exec会替换当前shell进程，即pid不变 # do somethingexec binay -flags … 正常情况测试命令如下，使用sleep来模拟应用sh -c &#39;echo &quot;start&quot;; sleep 100&#39;：pstree展示如下，sleep进程会生成一个子进程 bash(28701)───sh(24588)───sleep(24589) 通过exec运行后，命令sh -c &#39;echo &quot;start&quot;; exec sleep 100&#39; bash(28701)───sleep(24664) 加入exec后，sleep进程替换了shell进程，没有生成子进程 此种方式可以收到信号，但只适用于一个子进程的情况 trap在shell中可以显示通过trap捕捉信号传递给子进程 echo “start”binary -flags… &amp;pid=”$!” _kill() { echo “receive sigterm” kill $pid #传递给子进程 wait $pid exit 0} trap _kill SIGTERM #捕获信号wait #等待子进程退出 此种方式需要改动启动脚本，显示传递信号给子进程 docker-initdocker-init即在docker启动时加入--init参数，docker-int会作为一号进程，会向子进程传递信号并且会回收僵尸进程。 遗憾的是k8s并不支持--init参数，用户可在镜像中声明init进程，更多可参考container-init RUN wget -O /usr/bin/dumb-init https://github.com/Yelp/dumb-init/releases/download/v1.2.2/dumb-init\\_1.2.2\\_amd64RUN chmod +x /usr/bin/dumb-initENTRYPOINT [“/usr/bin/dumb-init”, “-v”, “–”] CMD [“nginx”, “-g”, “daemon off;”]","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://zhangyu.info/categories/Kubernetes/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://zhangyu.info/tags/Kubernetes/"}]},{"title":"在Kubernetes中实施审计策略","slug":"enforce-audit-policy-in-k8s","date":"2021-05-30T16:00:00.000Z","updated":"2021-05-31T12:49:59.507Z","comments":true,"path":"2021/05/31/enforce-audit-policy-in-k8s/","link":"","permalink":"http://zhangyu.info/2021/05/31/enforce-audit-policy-in-k8s/","excerpt":"","text":"在Kubernetes 中实施审计策略 作者：Vinod Kumar Nair 翻译：Bach (K8sMeetup) 校对：星空下的文仔 如果我们想检查 Kubernetes 生产环境中的以下活动： 谁登录了 Kubernetes 集群？ 哪个服务帐户或用户访问了集群中的哪些资源？ 谁创建了 secret 或 configmap？ 谁看了 ETCD 的 secrets ，或者其他更多？ 那么在 Kubernetes 中执行审计策略（Audit Policy）是非常正确的选择。 典型的 Kubernetes 环境 没有审计策略的 Kubernetes 启用后，审计记录将在 kube-apiserver 组件内开始其生命周期。每个请求在其执行的每个阶段都会生成一个审计事件，然后根据特定策略对其进行预处理，并写入后端。该策略确定记录的内容，后端将保留记录。当前的后端实现包括日志文件和 webhooks。 每个请求都可以记录一个关联的阶段（stage）。定义的阶段有： RequestReceived - 此阶段对应审计处理器接收到请求后，并且在委托给其余处理器之前生成的事件。 ResponseStarted - 在响应消息的头部发送后，响应消息体发送前生成的事件。只有长时间运行的请求（例如 watch）才会生成这个阶段。 ResponseComplete - 当响应消息体完成并且没有更多数据需要传输的时候。 Panic - 当 panic 发生时生成。 审计策略规则和级别 审计策略定义了有关应该记录哪些事件以及应包含哪些数据的规则。审核策略对象结构在 audit.k8s.ioAPI 组中定义。处理事件时，会按顺序将其与规则列表进行比较。第一个匹配规则设置事件的级别（audit levels）。定义的审核级别有： None - 符合这条规则的日志将不会记录。 Metadata - 记录请求的元数据（请求的用户、时间戳、资源、动词等等），但是不记录请求或者响应的消息体。 Request - 记录事件的元数据和请求的消息体，但是不记录响应的消息体。这不适用于非资源类型的请求。 RequestResponse - 记录事件的元数据，请求和响应的消息体。这不适用于非资源类型的请求。 下面是一个典型的审计策略文件： Log all requests at the Metadata level.apiVersion: audit.k8s.io/v1kind: Policyrules:- level: Metadata 复杂一点就是： apiVersion: audit.k8s.io/v1kind: PolicyomitStages: “RequestReceived”rules: level: RequestResponseresources: group: “”resources: [“pods”] level: Metadataresources: group: “”resources: [“pods/log”, “pods/status”] level: Noneresources: group: “”resources: [“configmaps”]resourceNames: [“controller-leader”] level: Noneusers: [“system:kube-proxy”]verbs: [“watch”]resources: group: “” # core API groupresources: [“endpoints”, “services”] level: NoneuserGroups: [“system:authenticated”]nonResourceURLs: “/api*“ # Wildcard matching. “/version” level: Requestresources: group: “” # core API groupresources: [“configmaps”]namespaces: [“kube-system”] level: Metadataresources: group: “” # core API groupresources: [“secrets”, “configmaps”] level: Requestresources: group: “” # core API group group: “extensions” # Version of group should NOT be included. level: MetadataomitStages: “RequestReceived” 架构-Kubernetes 中的审计策略 Kubernetes 启用了审计策略 我们可以使用 Webhooks 将审核日志发送到文件或远程 Web API。 在本文中，我们将强制 kube api-server 将审核日志发送到文件。 在 Kubernetes 中启用审计策略（对于审计日志文件） 创建审计策略 YAML 文件：前往 Kubernetes 集群，并使用以下规则创建 audit-policy.yaml： apiVersion: audit.k8s.io/v1kind: Policyrules: Log the request body of configmap changes in kube-system. level: Requestresources: group: “” # core API groupresources: [“configmaps”]namespaces: [“kube-system”] Log configmap and secret changes in all other namespaces at the Metadata level. level: Metadataresources: group: “” # core API groupresources: [“secrets”, “configmaps”] A catch-all rule to log all other requests at the Metadata level. level: MetadataomitStages: “RequestReceived” 更新 kube api-server 清单文件： - kube-apiserver - –advertise-address=10.156.0.6 - –audit-policy-file=/etc/kubernetes/audit-policy.yaml - –audit-log-path=/var/log/audit.log mountPath: /etc/kubernetes/audit-policy.yamlname: auditreadOnly: true— mountPath: /var/log/audit.logname: audit-logreadOnly: false-–volumes: name: audithostPath: path: /etc/kubernetes/audit-policy.yaml type: File name: audit-loghostPath: path: /var/log/audit.log type: FileOrCreate k8s-api-server —清单文件 k8s-api-server —清单文件 就这样，转到生成的审计日志文件。 在这个案例中，这是 audit.log。我们可以看到在阶段级别捕获的有关 Kubernetes 集群的审计日志信息，如以下示例中所示： { “kind”:”Event”, “apiVersion”:”audit.k8s.io/v1”, “level”:”Metadata”, “auditID”:”a42fa658-f143–43d8-b5e6–4e101d3e15ea”, “stage”:”ResponseComplete”, “requestURI”:”/api/v1/namespaces/default/secrets?fieldManager=kubectl-create”, “verb”:”create”, “user”:{ “username”:”kubernetes-admin”, “groups”:[ “system:masters”, “system:authenticated” ] }, “sourceIPs”:[ “10.156.0.2” ], “userAgent”:”kubectl/v1.20.2 (linux/amd64) kubernetes/faecb19”, “objectRef”:{ “resource”:”secrets”, “namespace”:”default”, “name”:”test-secret”, “apiVersion”:”v1” }, “responseStatus”:{ “metadata”:{ }, “code”:201 }, “requestReceivedTimestamp”:”2021–04–03T13:50:37.009656Z”, “stageTimestamp”:”2021–04–03T13:50:38.040874Z”, “annotations”:{ “authorization.k8s.io/decision”:”allow”, “authorization.k8s.io/reason”:”” }}{ “kind”:”Event”, “apiVersion”:”audit.k8s.io/v1”, “level”:”Metadata”, “auditID”:”f1466b01–9b68–45ec-b3bb-b440397f6481”, “stage”:”ResponseComplete”, “requestURI”:”/api/v1/namespaces/default/secrets/test-secret”, “verb”:”get”, “user”:{ “username”:”kubernetes-admin”, “groups”:[ “system:masters”, “system:authenticated” ] }, “sourceIPs”:[ “10.156.0.2” ], “userAgent”:”kubectl/v1.20.2 (linux/amd64) kubernetes/faecb19”, “objectRef”:{ “resource”:”secrets”, “namespace”:”default”, “name”:”test-secret”, “apiVersion”:”v1” }, “responseStatus”:{ “metadata”:{ }, “code”:200 }, “requestReceivedTimestamp”:”2021–04–03T13:51:08.603724Z”, “stageTimestamp”:”2021–04–03T13:51:08.607716Z”, “annotations”:{ “authorization.k8s.io/decision”:”allow”, “authorization.k8s.io/reason”:”” }}{ “kind”:”Event”, “apiVersion”:”audit.k8s.io/v1”, “level”:”Metadata”, “auditID”:”30be8c70-fda6–44de-8a83–3fe56161d44e”, “stage”:”ResponseComplete”, “requestURI”:”/api/v1/namespaces/default/secrets/test-secret”, “verb”:”get”, “user”:{ “username”:”kubernetes-admin”, “groups”:[ “system:masters”, “system:authenticated” ] }, “sourceIPs”:[ “10.156.0.2” ], “userAgent”:”kubectl/v1.20.2 (linux/amd64) kubernetes/faecb19”, “objectRef”:{ “resource”:”secrets”, “namespace”:”default”, “name”:”test-secret”, “apiVersion”:”v1” }, “responseStatus”:{ “metadata”:{ }, “code”:200 }, “requestReceivedTimestamp”:”2021–04–03T13:54:57.867317Z”, “stageTimestamp”:”2021–04–03T13:54:57.871369Z”, “annotations”:{ “authorization.k8s.io/decision”:”allow”, “authorization.k8s.io/reason”:”” }} 此外， 我们可以使用以下 kube-apiserver 标志配置 Log 审计后端，来更改审计日志文件的状态： --audit-log-maxage 定义保留旧审计日志文件的最大天数。 --audit-log-maxbackup 定义要保留的审计日志文件的最大数量。 --audit-log-maxsize 定义审计日志文件的最大大小（兆字节）。 总结 审计策略会检查 Kubernetes 集群中发生的所有请求、响应。这是一个最佳实践，应在早期阶段就启用。在本文示例中，和大家展示了如何将审计数据发送到文件。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://zhangyu.info/categories/Kubernetes/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://zhangyu.info/tags/Kubernetes/"}]},{"title":"Cilium网络概述","slug":"Cilium-Network-Overview","date":"2021-05-25T16:00:00.000Z","updated":"2021-05-26T02:49:26.327Z","comments":true,"path":"2021/05/26/Cilium-Network-Overview/","link":"","permalink":"http://zhangyu.info/2021/05/26/Cilium-Network-Overview/","excerpt":"","text":"Cilium 对系统的要求比较高，例如内核的版本要求Linux kernel &gt;= 4.9.17 受限于eBPF比较新，且需要的内核版本较高，因此目前还没有被kubernetes大规模推广，但该网络方案是一个大趋势。 目前calico已经支持eBPF模式(不建议生产使用)，且阿里云的Terway插件也是基于eBPF。 Google 声明GKE将选择 Cilium作为 GKE 网络的数据面V2以便增加其容器安全性和可观测性。 GKE 使用 Cilium 的声明: https://cloud.google.com/blog/products/containers-kubernetes/bringing-ebpf-and-cilium-to-google-kubernetes-engine 原文链接：https://mp.weixin.qq.com/s/NrlxI5uMqQQ3sDrrPSKhZA Cilium是一种开源网络实现方案，与其他网络方案不同的是，Cilium着重强调了其在网络安全上的优势，可以透明的对Kubernetes等容器管理平台上的应用程序服务之间的网络连接进行安全防护。 Cilium在设计和实现上，基于Linux的一种新的内核技术eBPF，可以在Linux内部动态插入强大的安全性、可见性和网络控制逻辑，相应的安全策略可以在不修改应用程序代码或容器配置的情况下进行应用和更新。 Cilium在其官网上对产品的定位称为“API-aware Networking and Security”，因此可以看出，其特性主要包括这三方面： 提供Kubernetes中基本的网络互连互通的能力，实现容器集群中包括Pod、Service等在内的基础网络连通功能； 依托eBPF，实现Kubernetes中网络的可观察性以及基本的网络隔离、故障排查等安全策略； 依托eBPF，突破传统主机防火墙仅支持L3、L4微隔离的限制，支持基于API的网络安全过滤能力。Cilium提供了一种简单而有效的方法来定义和执行基于容器/Pod身份（Identity Based）的网络层和应用层（比如HTTP/gRPC/Kafka等）安全策略。 架构Cilium官方给出了如下的参考架构，Cilium位于容器编排系统和Linux Kernel之间，向上可以通过编排平台为容器进行网络以及相应的安全配置，向下可以通过在Linux内核挂载eBPF程序，来控制容器网络的转发行为以及安全策略执行。 图1 Cilium架构 在Cilium的架构中，除了Key-Value数据存储之外，主要组件包括Cilium Agent和Cilium Operator，还有一个客户端的命令行工具Cilium CLI。 Cilium Agent作为整个架构中最核心的组件，通过DaemonSet的方式，以特权容器的模式，运行在集群的每个主机上。Cilium Agent作为用户空间守护程序，通过插件与容器运行时和容器编排系统进行交互，进而为本机上的容器进行网络以及安全的相关配置。同时提供了开放的API，供其他组件进行调用。 Cilium Agent在进行网络和安全的相关配置时，采用eBPF程序进行实现。Cilium Agent结合容器标识和相关的策略，生成eBPF程序，并将eBPF程序编译为字节码，将它们传递到Linux内核。 图2 Cilium部署架构 Cilium Operator 主要负责管理集群中的任务，尽可能的保证以集群为单位，而不是单独的以节点为单位进行任务处理。主要包括，通过etcd为节点之间同步资源信息、确保Pod的DNS可以被Cilium管理、集群NetworkPolicy的管理和更新等。 组网模式Cilium提供多种组网模式，默认采用基于VXLAN的Overlay组网。除此之外，还包括： 通过BGP路由的方式，实现集群间Pod的组网和互联； 在AWS的ENI（Elastic Network Interfaces）模式下部署使用Cilium； Flannel和Cilium的集成部署； 采用基于ipvlan的组网，而不是默认的基于veth； Cluster Mesh组网，实现跨多个Kubernetes集群的网络连通和安全性等多种组网模式。 本文将针对默认的基于vxlan的overlay组网，进行深度的原理和数据包路径分析。 Overlay组网使用官方给出的yaml文件，通过下述命令，实现Cilium的快速部署。 root@u18-161:~# kubectl create -f https://raw.githubusercontent.com/cilium/cilium/v1.6.5/install/kubernetes/quick-install.yaml 部署成功后，我们可以发现，在集群的每个主机上，启动了一个Cilium Agent（cilium-k54qt，cilium-v7fx4），整个集群启动了一个Cilium Operator（cilium-operator-cdb4d8bb6-8mj5w）。 root@u18-161:~# kubectl get pods –all-namespaces -o wide | grep ciliumNAMESPACE NAME READY STATUS RESTARTS AGE IP NODEkube-system cilium-k54qt 1/1 Running 0 80d 192.168.19.161 u18-161kube-system cilium-v7fx4 1/1 Running 0 80d 192.168.19.162 u18-162kube-system cilium-operator-cdb4d8bb6-8mj5w 1/1 Running 1 80d 192.168.19.162 u18-162 在这种默认的组网情况下，主机上的网络发生了以下变化：在主机的root命名空间，新增了如下图所示的四个虚拟网络接口，其中cilium_vxlan主要是处理对数据包的vxlan隧道操作，采用metadata模式，并不会为这个接口分配ip地址；cilium_host作为主机上该子网的一个网关，并且在node-161为其自动分配了IP地址10.244.0.26/32，cilium_net和cilium_host作为一对veth而创建，还有一个lxc_health。 在每个主机上，可以进入Cilium Agent，查看其隧道配置。比如进入主机node-161上的Cilium Agent cilium-k54qt，运行cilium bpf tunnel list，可以看到，其为集群中的另一台主机node-162（192.168.19.162）上的虚拟网络10.244.1.0创建了一个隧道。同样在node-162上也有一条这样的隧道配置。 图3 Cilium默认Overlay组网 接下来创建Pod1和Pod2运行于node-161，Pod3和Pod4运行于node-162。其与主机的root命名空间，通过veth-pair连接，如下图所示。 图4 测试环境组网示例 进入Pod1，可以发现，Cilium已经为其分配了IP地址，并且设置了默认的路由，默认路由指向了本机的cilium_host。初始状态Pod内的arp表为空。 root@u18-161:~# kubectl exec -it test-1-7cd5798f46-vzf9s -n test-1 bashroot@test-1-7cd5798f46-vzf9s:/# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 10.244.0.26 0.0.0.0 UG 0 0 0 eth010.244.0.26 0.0.0.0 255.255.255.255 UH 0 0 0 eth0root@test-1-7cd5798f46-vzf9s:/# arproot@test-1-7cd5798f46-vzf9s:/# 在Pod1中ping Pod2，通过抓包可以发现，Pod发出的ARP请求，其对应的ARP响应直接通过其对端的veth-pair 接口返回（52:c6:5e:ef:6e:97和5e:2d:20:9d:b1:a8是Pod1对应的veth-pair）。这个ARP响应是通过Cilium Agent通过挂载的eBPF程序实现的自动应答，并且将veth-pair对端的MAC地址返回，避免了虚拟网络中的ARP广播问题。 No. Time Source Destination Protocol Length Info133 39.536478 52:c6:5e:ef:6e:97 5e:2d:20:9d:b1:a8 ARP 42 Who has 10.244.0.26 Tell 10.244.0.71134 39.536617 5e:2d:20:9d:b1:a8 52:c6:5e:ef:6e:97 ARP 42 10.244.0.26 is at 5e:2d:20:9d:b1:a8 主机内Pod通信分析完组网状态之后，那么同一个主机内，两个Pod间通信的情况，就很容易理解了。例如，Pod1向Pod2发包，其数据通路如下图所示Pod1 –&gt; eth0 –&gt; lxc909734ef58f7 –&gt; lxc7c0fcdd49dd0 –&gt; eth0 –&gt; Pod2。 图5 主机内Pod通信路径 跨主机Pod通信在这种Overlay组网模式下，Pod跨节点之间的通信，通过vxlan实现隧道的封装，其数据路径如下图所示pod1 –&gt; eth0 –&gt; lxc909734ef58f7 –&gt; cilium_vxlan –&gt; eth0(node-161) –&gt; eth0(node-162) –&gt; cilium_vxlan –&gt; lxc2df34a40a888 –&gt; eth0 –&gt; pod3。 图6 跨主机节点Pod通信路径 我们在cilium_vxlan虚拟网络接口上抓包，如下所示。从抓包分析可以看出，Linux内核将Pod1发出的原始数据包发送到cilium_vxlan进行隧道相关的封包、解包处理，然后再将其送往主机的物理网卡eth0。 图7 cilium_vxlan抓包 在物理网卡eth0抓包可以发现，Pod1出发的数据包经过cilium_vxlan的封装处理之后，其源目的地址已经变成物理主机node-161和node-162，这是经典的overlay封装。同时，还可以发现，cilium_vxlan除了对数据包进行了隧道封装之外，还将原始数据包进行了TLS加密处理，保障了数据包在主机外的物理网络中的安全性。 图8 node-161 eth0抓包 API感知的安全性安全可视化与分析Cilium在1.17版本之后，推出并开源了其网络可视化组件Hubble，Hubble是建立在Cilium和eBPF之上，以一种完全透明的方式，提供网络基础设施通信以及应用行为的深度可视化，是一个应用于云原生工作负载，完全分布式的网络和安全可观察性平台。 Hubble能够利用Cilium提供的eBPF数据路径，获得对Kubernetes应用和服务网络流量的深度可见性。这些网络流量信息可以对接Hubble CLI、UI工具，可以通过交互式的方式快速发现诊断相关的网络问题与安全问题。Hubble除了自身的监控工具，还可以对接像Prometheus、Grafana等主流的云原生监控体系，实现可扩展的监控策略。 图9 Hubble架构图 从上图的架构以及Hubble部署可以看出，Hubble在Cilium Agent之上，以DaemonSet的方式运行自己的Agent，笔者这里的部署示例采用Hubble UI来操作和展示相关的网络以及安全数据。 root@u18-163:~# kubectl get pods –all-namespaces -o wide | grep hubblekube-system hubble-5tvzc 1/1 Running 16 66d 10.244.1.209 u18-164 kube-system hubble-k9ft8 1/1 Running 0 34m 10.244.0.198 u18-163 kube-system hubble-ui-5f9fc85849-x7lnl 1/1 Running 4 67d 10.244.0.109 u18-163 依托于Hubble深入的对网络数据和行为的可观察性，其可以为网络和安全运维人员提供以下相关能力： 服务依赖关系和通信映射拓扑：比如，可以知道哪些服务之间在相互通信？这些服务通信的频率是多少？服务依赖关系图是什么样的？正在进行什么HTTP调用？服务正在消费或生产哪些Kafka的Topic等。 运行时的网络监控和告警：比如，可以知道是否有网络通信失败了？为什么通信会失败？是DNS的问题？还是应用程序得问题？还是网络问题？是在第4层(TCP)或第7层(HTTP)的发生的通信中断等；哪些服务在过去5分钟内遇到了DNS解析的问题？哪些服务最近经历了TCP连接中断或看到连接超时 TCP SYN请求的未回答率是多少 等等。 应用程序的监控：比如，可以知道针对特定的服务或跨集群服务，HTTP 4xx或者5xx响应码速率是多少？在我的集群中HTTP请求和响应之间的第95和第99百分位延迟是多少 哪些服务的性能最差 两个服务之间的延迟是什么 等等这些问题。 安全可观察性：比如，可以知道哪些服务的连接因为网络策略而被阻塞？从集群外部访问了哪些服务？哪些服务解析了特定的DNS名称？等等。 图10 Hubble界面功能 从上图Hubble的界面，我们可以简单的看出其部分功能和数据，比如，可以直观的显示出网路和服务之间的通信关系，可以查看Flows的多种详细数据指标，可以查看对应的安全策略情况，可以通过namespace对观测结果进行过滤等等。 微隔离默认情况下，Cilium与其他网络插件一样，提供了整个集群网络的完全互联互通，用户需要根据自己的应用服务情况设定相应的安全隔离策略。如下图所示，每当用户新创建一个Pod，或者新增加一条安全策略，Cilium Agent会在主机对应的虚拟网卡驱动加载相应的eBPF程序，实现网络连通以及根据安全策略对数据包进行过滤。比如，可以通过采用下面的NetworkPolicy实现一个基本的L3/L4层网络安全策略。 apiVersion: “cilium.io/v2”kind: CiliumNetworkPolicydescription: “L3-L4 policy to restrict deathstar access to empire ships only”metadata:name: “rule1”spec:endpointSelector: matchLabels: org: empire class: deathstaringress: fromEndpoints: matchLabels: org: empire toPorts: ports: port: “80” protocol: TCP 图11 Cilium网络隔离方案示意图 然而，在微服务架构中，一个基于微服务的应用程序通常被分割成一些独立的服务，这些服务通过API（使用HTTP、gRPC、Kafka等轻量级协议）实现彼此的通信。因此，仅实现在L3/L4层的网络安全策略，缺乏对于微服务层的可见性以及对API的细粒度隔离访问控制，在微服务架构中是不够的。 我们可以看如下这个例子，Job Postings这个服务暴露了其服务的健康检查、以及一些增、删、改、查的API。Gordon作为一个求职者，需要访问Job Postings提供的Jobs相关信息。按照传统的L3/L4层的隔离方法，可以通过iptables -s 10.1.1.1 -p tcp –dport 80 -j ACCEPT，允许Gordon来访问Job Postings在80端口提供的HTTP服务。但是这样的网络规则，导致Gordon同样可以访问包括发布信息、修改信息、甚至是删除信息等其他接口。这样的情况肯定是我们的服务设计者所不希望发生的，同时也存在着严重的安全隐患。 图12 L7微隔离示例 因此，实现微服务间的L7层隔离，实现其对应的API级别的访问控制，是微服务网络微隔离的一个重要部分。Cilium在为Docker和Kubernetes等基于Linux的容器框架提供了支持API层面的网络安全过滤能力。通过使用eBPF，Cilium提供了一种简单而有效的方法来定义和执行基于容器/pod身份的网络层和应用层安全策略。我们可以通过采用下面的NetworkPolicy实现一个L7层网络安全策略。 图13 Cilium实现微服务安全 apiVersion: “cilium.io/v2”kind: CiliumNetworkPolicydescription: “L7 policy to restrict access to specific HTTP call”metadata:name: “rule1”spec: endpointSelector: matchLabels: org: empire class: deathstaringress: fromEndpoints: matchLabels: org: empiretoPorts: ports: port: “80”protocol: TCPrules: http: method: “POST” path: “/v1/request-landing” Cilium还提供了一种基于Proxy的实现方式，可以更方便的对L7协议进行扩展。如下图所示，Cilium Agent采用eBPF实现对数据包的重定向，将需要进行过滤的数据包首先转发至Proxy代理，Proxy代理根据其相应的过滤规则，对收到的数据包进行过滤，然后再将其发回至数据包的原始路径，而Proxy代理进行过滤的规则，则通过Cilium Agent进行下发和管理。 当需要扩展协议时，只需要在Proxy代理中，增加对新协议的处理解析逻辑以及规则处置逻辑，即可实现相应的过滤能力。 图14 L7层访问控制协议扩展原理图 总结Cilium是一个基于eBPF和XDP的高性能网络方案，本文着重介绍了其原理以及默认的overlay组网通信。除了基本的网络通信能力外，Cilium还包含了基于eBPF的负载均衡能力，L3/L4/L7的安全策略能力等相关的内容，后续会进行更详细的实践分析。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://zhangyu.info/categories/Kubernetes/"}],"tags":[{"name":"Cilium","slug":"Cilium","permalink":"http://zhangyu.info/tags/Cilium/"}]},{"title":"快速生成k8s的yaml配置的4种方法","slug":"generating-yaml-for-k8s","date":"2021-05-18T16:00:00.000Z","updated":"2021-05-19T07:34:35.208Z","comments":true,"path":"2021/05/19/generating-yaml-for-k8s/","link":"","permalink":"http://zhangyu.info/2021/05/19/generating-yaml-for-k8s/","excerpt":"","text":"[快速生成kubernetes(k8s)的yaml配置的4种方法](https://www.toutiao.com/i6952422377816965639/ wid=1621396706552) 快速生成k8s的yaml配置的4种方法1、通过kubectl命令行快速生成一个deployment及service的yaml标准配置 #我们在后面加上`--dry-run -o yaml` --dry-run代表这条命令不会实际在K8s执行，-o yaml是会将试运行结果以yaml的格式打印出来，这样我们就能轻松获得yaml配置了 # kubectl create deployment nginx --image=nginx --dry-run -o yaml apiVersion: apps/v1 # &lt;--- apiVersion 是当前配置格式的版本 kind: Deployment #&lt;--- kind 是要创建的资源类型，这里是 Deployment metadata: #&lt;--- metadata 是该资源的元数据，name 是必需的元数据项 creationTimestamp: null labels: app: nginx name: nginx spec: #&lt;--- spec 部分是该 Deployment 的规格说明 replicas: 1 #&lt;--- replicas 指明副本数量，默认为 1 selector: matchLabels: app: nginx strategy: &#123;&#125; template: #&lt;--- template 定义 Pod 的模板，这是配置文件的重要部分 metadata: #&lt;--- metadata 定义 Pod 的元数据，至少要定义一个 label。label 的 key 和 value 可以任意指定 creationTimestamp: null labels: app: nginx spec: #&lt;--- spec 描述 Pod 的规格，此部分定义 Pod 中每一个容器的属性，name 和 image 是必需的 containers: - image: nginx name: nginx resources: &#123;&#125; status: &#123;&#125; # 基于上面的deployment服务生成service的yaml配置 # kubectl expose deployment nginx --port=80 --target-port=80 --dry-run -o yaml apiVersion: v1 kind: Service metadata: creationTimestamp: null labels: app: nginx name: nginx spec: ports: - port: 80 protocol: TCP targetPort: 80 selector: app: nginx status: loadBalancer: &#123;&#125; 2、利用helm查看各种官方标准复杂的yaml配置以供参考 # 以查看rabbitmq集群安装的配置举例 # 首先添加chart仓库 helm repo add aliyun-apphub https://apphub.aliyuncs.com helm repo update # 这里我们在后面加上 --dry-run --debug 就是模拟安装并且打印输出所有的yaml配置 helm install -n rq rabbitmq-ha aliyun-apphub/rabbitmq-ha --dry-run --debug 3、将docker-compose转成k8s的yaml格式配置 # 下载二进制包 # https://github.com/kubernetes/kompose/releases # 开始转发yaml配置 ./kompose-linux-amd64 -f docker-compose.yml convert 4、docker命令输出转换成对应的yaml文件示例 这里以 Prometheus Node Exporter 为例演示如何运行自己的 DaemonSet。 Prometheus 是流行的系统监控方案，Node Exporter 是 Prometheus 的 agent，以 Daemon 的形式运行在每个被监控节点上。 如果是直接在 Docker 中运行 Node Exporter 容器，命令为： docker run -d \\ -v &quot;/proc:/host/proc&quot; \\ -v &quot;/sys:/host/sys&quot; \\ -v &quot;/:/rootfs&quot; \\ --net=host \\ prom/node-exporter \\ --path.procfs /host/proc \\ --path.sysfs /host/sys \\ --collector.filesystem.ignored-mount-points &quot;^/(sys|proc|dev|host|etc)($|/)&quot; 将其转换为 DaemonSet 的 YAML 配置文件 node_exporter.yml： apiVersion: extensions/v1beta1 kind: DaemonSet metadata: name: node-exporter-daemonset spec: template: metadata: labels: app: prometheus spec: hostNetwork: true # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 1 直接使用 Host 的网络 containers: - name: node-exporter image: prom/node-exporter imagePullPolicy: IfNotPresent command: # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 2 设置容器启动命令 - /bin/node_exporter - --path.procfs - /host/proc - --path.sysfs - /host/sys - --collector.filesystem.ignored-mount-points - ^/(sys|proc|dev|host|etc)($|/) volumeMounts: # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 3 通过Volume将Host路径/proc、/sys 和 / 映射到容器中 - name: proc mountPath: /host/proc - name: sys mountPath: /host/sys - name: root mountPath: /rootfs volumes: - name: proc hostPath: path: /proc - name: sys hostPath: path: /sys - name: root hostPath: path: /","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://zhangyu.info/categories/Kubernetes/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://zhangyu.info/tags/Kubernetes/"}]},{"title":"使用fklek搭建Kubernetes日志收集工具栈","slug":"fklek-to-k8s-log","date":"2021-04-27T16:00:00.000Z","updated":"2021-04-28T05:58:46.365Z","comments":true,"path":"2021/04/28/fklek-to-k8s-log/","link":"","permalink":"http://zhangyu.info/2021/04/28/fklek-to-k8s-log/","excerpt":"","text":"使用 Fluentd+Kafka+Logstash+Elasticsearch+Kibana搭建 Kubernetes 日志收集工具栈 https://mp.weixin.qq.com/s/lPeYavvFJ6GdivkT0iwTGw","categories":[{"name":"日志","slug":"日志","permalink":"http://zhangyu.info/categories/%E6%97%A5%E5%BF%97/"}],"tags":[{"name":"日志","slug":"日志","permalink":"http://zhangyu.info/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"只有黑话，才能拯救互联网人","slug":"只有黑话才能拯救互联网人","date":"2021-04-26T16:00:00.000Z","updated":"2021-04-27T05:40:09.445Z","comments":true,"path":"2021/04/27/只有黑话才能拯救互联网人/","link":"","permalink":"http://zhangyu.info/2021/04/27/%E5%8F%AA%E6%9C%89%E9%BB%91%E8%AF%9D%E6%89%8D%E8%83%BD%E6%8B%AF%E6%95%91%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA/","excerpt":"","text":"只有黑话，才能拯救互联网人 原创 东半球第二正经の 牛顿顿顿 4月8日 最近，一鸣同学在字节年会上怒斥了公司报告中的 “ 互联网黑话 “ 现象，我看了一眼他举的例子，整个人当场就被生态化反了： 给大家念一段我用咱们双月会材料里摘出来的词，拼凑出来的一段话： 过去我们主要依靠推荐技术赋予的信息分发能力、跨端联动抖头西、分多个产品自研，实现深度共建，形成组合拳，打造内容生态闭环，以此赋能客户用户创造价值。未来我们要增加横向不同场景价值，延长服 务链路。同时纵深满足用户需求，借助人类年龄的自然势能，在小中青多个年龄用户深度渗透。另外通过加强基建投入，多种阵地相关产品完善经营价值链路，建立对外用户持久影响力。 黑话不是没见过，但这种级别的，堪称 “ 互联网黑神话 “，玉皇大帝来了也只能喊一声： 你这个颗粒度的输出，很难击穿我的心智啊。 为了发力，拆解，抨击这个现象，我和阿半紧张的孵化了一整宿，通过增强耦合性，我们一起进行了串联，拉通，输出，为这篇稿子赋能。 我对阿半个说，写完稿子咱们就联动，我喜欢在后面发力，你最好给我一个抓手，我要牢抓你的两个突出点，两手抓两手都要硬，我们对齐水位，聚焦痛点，打通要害，完成闭环，你要提高感知度，我们一起达到引爆点。 阿半当时脸就红了，发出了灵魂的拷问： 那个务实、奋进、用结果说话，承载着年轻人光荣与梦想的互联网死哪儿去了？ 1 为什么这些互联网人在职场不讲人话，整天搞这些 “ 务虚 “ 的八股文 “ 黑话 “？ 因为，黑话是最好的 “ 职场遮羞布 “。 大厂今天 OKR，明天 361，大搞周报文化，甚至早有早报，晚有晚报，月有月报，仔细一看，全是福报。 原来是为了汇报工作写 PPT，现在为了写 PPT 写 PPT。 入行互联网，别的没学会，先成了 PPT 精装师，模板搬运工。 但问题是，大部分人的工作价值感是很低的，一周搞不出什么东西来，很多人既没有 Power 也没有 Point。 那么如何让自己平庸的，低效的无价值工作，听上去，稍微有那么点价值和深度呢？ 这时候就需要点专业的 “ 黑话 “ 来装点门面了。 我今天虽然别的没干，找人修了个打印机，但只要用黑话包装一下，就成了： “ 联动协同多部门，多维度发力支撑办公场景，打造硬件故障紧急处理 SOP，提前布局对接团队，以易用性组合拳为抓手，提高团队运作效率。”装神弄鬼，故弄玄虚，把简单的东西讲复杂还不容易吗？ 2 大厂里那些大大小小的领导，嘴里的黑话也越来越高了。 为什么？ 别觉得当上了领导，就有真本事，输出个 “ 洞察 “： 这几年的互联网人，尤其是大厂的中层，草包含量越来越高。 越是废物，越热衷拼凑这些，晦涩难懂，佶屈聱牙，专业色彩浓厚的 “ 术语 “ 为自己 “ 赋魅 “。 他们自己都没意识到，能当上领导，完全不是因为能力强，只是运气好，沾上了时代尿频一样洒下的红利。 很多中层高 P，无非就是出生早一点，毕业早一点，在早期混进了大厂。 大厂也有年功序列制，公司高速成长，新的管理岗缺口自然就会出现，哪怕做不出什么成绩来，只要你苟的聪明，同届有本事的人跳出去闯了，那就是剩者为王。 老人们的职场，就像坐电梯往上升，就算你是条狗，跟着走，也能干成保卫科科长。 这就是时代红利滋中了你。 不管是时代的红利也好，空降兵也好，外行领导内行也好，越来越多的草包领导们面临同一个困境： 不够屌，怎么才能装逼呢？ 如果完全不专业，那至少也要想办法让自己 “ 看起来 “ 专业。 赋魅的本质，就是包装。 搓澡不叫搓澡，叫人体表皮组织研究； 搬砖不叫搬砖，叫研究物质空间位置转移的科研项目； 贴膜不叫贴膜，叫智能数字通讯设备表面高分子化合物平面处理； 互联网黑话是对酒囊饭袋最好的包装。 3 更重要的是：务虚是最安全的。 这几年一个趋势，大佬们也不爱讲真话了。 其实，早些年，很多互联网大佬其实还是讲人话的，不仅讲，还十分爱讲。 一鸣同学当年喜欢出来谈延迟满足，王兴在写了一万多条饭否传经布道，黄峥甚至开公众号写连载，当年，讲的都是大实话。 然后呢？ “ 悔创阿里 “” 不知妻美 “” 一无所有 “” 普通家庭 “” 名下无房 “” 顺便挣钱 “ 实话很快遭到了反噬，各路媒体围观解读，挖坟打脸。 难看吗？很难看。 这个时候，老一辈的生存哲学才发出了闪闪的光芒。 《是，大臣》里面有句名台词 “ 如果人们不知道你在干什么，他们就不知道你做错了什么。” 多说多错，少说少错，不说不错。 非要你讲呢？那就尽量让说了和没说一样。 黑话，闪闪发光。 互联网黑话只是一种职场文化，或者说是生存哲学吗？ 不，黑话的背后，隐藏着一个冰冷的现实： 互联网来到了 “ 守成时代 “。 群雄逐鹿，尘埃将落。 各个赛道上的大厂已经划完了地盘，站稳了脚跟，那些最暴利的业务早就被大厂吃干抹净。 甚至连不怎么挣钱，曾经让他们不屑一顾的边缘业务都成了大厂的爪牙们争夺的焦点。 扩张逼近边界，格局固化，增量见顶。 那个曾经改变无数普通年轻人命运窗口要关闭了，一个充满光荣与梦想的时代要落幕了。 我国的互联网普及率，用了不到 15 年的时间，就从 2006 年的 10% 增长到了 70%。 在这 15 年里，无数怀着理想的年轻人涌进来。 互联网一度是年轻人的理想国。 你讨厌传统行业里的蝇营狗苟你可以来这里； 现实里一无所有，迷惘无依，你可以来这里； 不需要你有一个区长父亲，不需要你有一个企业家母亲，有一腔热血，这里就有梦可以给你做。 然后一代年轻人用青春和热血敲下一行行代码，开发出一个又一个改变我们生活的应用，用 996 和青春饲喂出一个又一个世界级的互联网巨鳄和独角兽。 然后，没有了然后。 存量和守成的时代，是一个不说人话和逆向淘汰的时代。 “Talk is cheap， Show me the code” 的时代结束了。 那个普通人可以闪闪发光的时代也结束了。","categories":[{"name":"胡说八道","slug":"胡说八道","permalink":"http://zhangyu.info/categories/%E8%83%A1%E8%AF%B4%E5%85%AB%E9%81%93/"}],"tags":[{"name":"黑话","slug":"黑话","permalink":"http://zhangyu.info/tags/%E9%BB%91%E8%AF%9D/"}]},{"title":"漫画一个NB互联网项目的上线过程","slug":"漫画一个NB互联网项目的上线过程","date":"2021-04-26T16:00:00.000Z","updated":"2022-03-08T15:16:48.955Z","comments":true,"path":"2021/04/27/漫画一个NB互联网项目的上线过程/","link":"","permalink":"http://zhangyu.info/2021/04/27/%E6%BC%AB%E7%94%BB%E4%B8%80%E4%B8%AANB%E4%BA%92%E8%81%94%E7%BD%91%E9%A1%B9%E7%9B%AE%E7%9A%84%E4%B8%8A%E7%BA%BF%E8%BF%87%E7%A8%8B/","excerpt":"","text":"##漫画 一个NB互联网项目的上线过程 作者 | 苏南 来源 | 前端布道师（ID：honeyBadger8） 今天这篇漫画讲述的是一个大型项目，从需求诞生到进入实际开发、对外发布的过程… 本期漫画情节纯属虚构 如有雷同，纯属巧合. 我们经常会看到某某知名互联网公司开产品发布会，又或者某些分享会上，演讲者常常会提到我们公司的项目致力于解决用户的某一痛点，并且采用了当下最顶尖的云服务部署、微服务架构、模块化开发、大数据精准分析等互联网黑话，但这些华丽的外表背后真的如此吗？ 可能也只有身在其中的程序员才最清楚了吧，当然也不排除部分公司确实做的非常好。但是绝大部分的公司都很难做到流程标准化，项目长远规划，都只是一味的追求快，快、意味着时间的减少，而程序员前期的规划、架构也随之被抛在脑后，为了完成需求编码而编码，压根没有时间去思考项目长远的开发问题… 话说，你工作中的项目状态是如画中的王大拿这样的吗？","categories":[{"name":"胡说八道","slug":"胡说八道","permalink":"http://zhangyu.info/categories/%E8%83%A1%E8%AF%B4%E5%85%AB%E9%81%93/"}],"tags":[{"name":"上线","slug":"上线","permalink":"http://zhangyu.info/tags/%E4%B8%8A%E7%BA%BF/"}]},{"title":"Pulsar vs Kafka，CTO 如何抉择","slug":"comparing-pulsar-and-kafka-from-a-ctos-point-of-view","date":"2021-04-23T16:00:00.000Z","updated":"2021-04-25T08:20:42.115Z","comments":true,"path":"2021/04/24/comparing-pulsar-and-kafka-from-a-ctos-point-of-view/","link":"","permalink":"http://zhangyu.info/2021/04/24/comparing-pulsar-and-kafka-from-a-ctos-point-of-view/","excerpt":"","text":"https://dzone.com/articles/comparing-pulsar-and-kafka-from-a-ctos-point-of-vi 作者 | Jesse Anderson译者 | Sijiahttps://mp.weixin.qq.com/s?src=11&amp;timestamp=1619338804&amp;ver=3029&amp;signature=LstPwE5cJ7yKmBlTCfazpUH3EqJ3tPgHscCjhRBoc1lJ1IHTlI57lOKONxCKmfLeWlqDAKdaKutZXVdxm3XEVFDvKt2z3fNX6eoKV0qMt在评估新技术时，高层管理人员的视角通常与中层管理人员、架构师、数据工程师等有所不同。高层管理人员不仅要关注基准测试结果、产品支持的特性，还要从长远角度考虑新技术的可靠性，新技术能够为企业带来哪些竞争优势，以及是否可以缩短上市时间、节约开销。 我是 Big Data Institute 的常务董事，技术评估是我的一项主要工作。我们帮助企业根据业务需求选择并落地最合适的技术。我们不与供应商合作，因此客户尤为看中我们能够客观地评估不同的技术。 在本文中，我将从 CTO 的视角出发，对比 Apache Pulsar 和 Apache Kafka。只进行理论上的对比空洞无效，也不能帮助我们作出决策，实际用例才真正值得参考。所以，在本文中，我会通过一些常见的实际使用场景来对比 Pulsar 和 Kafka，即简单消息使用场景、复杂消息使用场景和高级消息使用场景。在这些实际使用场景下，Pulsar 和 Kafka 的表现能够帮助我们更好地理解二者的性能和优势，进而作出决策。 简单消息使用场景假设有一个企业，之前从未使用过消息系统，现在需要通过一个简单的消息系统，将消息从位置 A 发送到位置 B，但不需要复制消息。 数据架构师团队在深入研究 Pulsar 和 Kafka 的业务案例后，得出如下结论：在这一使用场景中，Pulsar 和 Kafka 都没有绝对优势。并且，他们认为在短时间内，该使用场景基本不会发生改变。 对于类似这样的简单消息使用场景而言，我也赞同 Pulsar 和 Kafka 都没有绝对优势。仅从技术角度出发，Pulsar 和 Kafka 这一回合打成平局，那么我们只能考虑成本。二者的运营成本、员工培训成本分别是多少？我打算根据 Kafka 或 Pulsar 的服务提供商的收费标准进行对比。对比开销时，选好服务提供商也可以在一定程度上减少运营成本和员工培训成本。Kafka 的云服务提供商，我参考了使用 Kafka API（Azure）的 Confluent Cloud、MSK（AWS）和 Event Hubs。Pulsar 的云服务提供商，我选择 StreamNative Cloud。 对比结果出于稳妥考虑，我们决定选择 Kafka API。目前，已有多种技术支持非 Kafka broker 使用 Kafka API 或传输协议。使用 Kafka API，非 Kafka broker 可通过添加新库支持 Kafka 的传输协议，保证对 Kafka API 的兼容性，从而最大化技术选择的多样性。例如，可以通过修改 Kafka API 的实现重新编译或通过 Pulsar broker 解析 Kafka 的协议（KOP），将 Pulsar 用作 Kafka 的后端。 我们在对比单位成本后，选择了成本效益高的一方。Kafka API 可以保证后端质量，用户在后端之间的数据移动不会受到影响，有效规避风险。即使社区不活跃，技术热度不高，我们的使用也不会受到影响。 复杂消息使用场景假设一个公司需要复杂消息系统。由于需要处理世界各地的数据，必须支持跨地域复制。该企业一直在使用消息系统，因此对实时系统的复杂性有一定的了解，也发现了当前消息系统的不足之处。因此该企业对消息系统的要求是能够处理高级的消息传递和复杂的消息特性。 数据架构师团队和股东以及业务部门详细讨论了当前和未来需求。最后得出的结论是，Pulsar 和 Kafka 各有优势。同时，他们认为随着时间的推移，该使用场景和数据量都会有所增长。 在这种情况下，Pulsar 和 Kafka 难分胜负。要想作出正确决策，必须深入研究二者的使用场景。 跨地域复制Kafka 既提供私有的（价格高）跨地域复制，也提供开源的（附加服务）跨地域复制解决方案。私有的跨地域复制解决方案为其内置特性，但价格高昂。开源的解决方案（MirrorMaker）实际上就是数据复制，但由于不是其内置特性，会增加运营开销。 Pulsar 提供开源内置的跨地域复制特性，支持复杂的复制策略。对于使用场景和数据量都在增加的企业而言，显然，支持内置跨地域复制策略的 Pulsar 完胜。 就跨地域复制而言，我们选择 Pulsar。 复杂消息由于企业正在向新消息平台迁移，消息系统最好可以处理新使用场景。数据架构师团队一直在了解各个平台，尝试寻找最佳解决方案。在当前使用的消息系统中，一旦出现处理错误，必须重新生成消息，再手动重试，因此最好还可以引入消息延迟发送。另外，当前消息系统的 schema 实施功能也有待加强，各个团队选择不同的 schema 实现时，团队合作的难度显著增加。 Kafka 没有内置死信队列特性，一旦消息处理失败，必须手动处理，或修改代码重试。Kafka 也没有延迟发送消息的内置机制，延迟发送消息流程复杂、工作量大。另外，Kafka 没有内置 schema 实施机制，导致云服务提供商分别提供了不同的 schema 解决方案。 Pulsar 内置死信队列特性，当消息处理失败，收到否认 ack 时，Pulsar 可以自动重试，但次数有限。Pulsar 也支持延迟发送消息，可以设定延迟时间。对于 Pulsar 而言，schema 级别高，因此 Pulsar 有内置 schema 注册，Pulsar API 也原生支持 schema。 就复杂消息而言，我们选择 Pulsar。 高级消息传递随着对架构的深入了解，我们发现为了确保均匀分配资源，需要循环发送同一 topic 上的数据，并且需要通过排序确保消息有序排列。 Kafka 不能分发消息给指定的 consumer。当 consumer 接收到不属于它消费的消息时，要保证这些消息被正确消费，我们只能重新发送这些消息到额外的 topic 中，但这样会造成数据冗余，增加使用成本。因此，我们需要可以制定路由规则发送给指定 consumer 的产品。 Pulsar broker 可以通过制定的路由规则，把一个 topic 的不同消息根据路由规则发送到指定的 consumer 中。Pulsar broker 轻松实现了我们的目标，无需任何额外工作。 就高级消息传递而言，我们选择 Pulsar。 部署和社区为了全面比较 Pulsar 和 Kafka，我们还需要看一下二者的部署数量和社区概况。 从服务市场来看，Kafka 的提供商更多，销售和支持 Kafka 产品的团队也更多。Kafka 和 Pulsar 的开源社区都积极活跃，但 Kafka 的社区规模更大。 从使用市场来看，Kafka 和 Pulsar 都已部署在大公司的大型生产环境中。在生产环境中部署 Kafka 的公司在数量上更胜一筹。 从用户数量来看，Kafka 的用户更多。但是，数据工程师团队认为， Kafka 的使用者可以轻松学习 Pulsar。 就服务支持和社区而言，我们选择 Kafka。但值得一提的是，Pulsar 社区正在迅速发展。 对比结果由于 Pulsar 和 Kafka 在这一使用场景中都有明显的优劣势，决策难度大大增加。 Pulsar 可以在社区和部署上奋起直追，Kafka 则可以努力丰富产品特性。 在作出决策前，我们先来总结一下，该企业在技术上最看重哪方面；在技术方面，我们是否需要做最保守的选择。根据以往的经验，新的开源技术会带来更多惊喜，因此我们更倾向于选择 Pulsar。 如果选择 Kafka，我们需要承担向业务赞助商坦诚“我们无法处理这一使用场景”的风险。甚至，即使支付大笔资金购买跨地域复制许可，也无法保证顺利实现客户的需求。业务团队最终可能需要花大量时间（甚至几个月）来编写、完善、测试他们的工作方案。 如果选择 Pulsar，我们可以告诉业务赞助商“一切尽在掌握中”。由于 Pulsar 的各项内置特性都已经过测试，使用团队可以在短时间内完成部署。 在这种情况下，因为我们不需要 Kafka API 的独有特性，所以我们没有使用支持 Kafka 协议（KOP）的 Pulsar Broker，而是选择 Pulsar API，因为 Pulsar API 支持所有我们需要 Kafka API 提供的功能。 决策如下：选择 Pulsar，可以优先处理业务请求，开发团队只专注编写代码，而不是解决其他问题。选择 Pulsar 的同时，也关注 Pulsar 社区和提供商的动态。 如果采取保守决策选择 Kafka，需要接受可能无法实现某些使用场景的事实。对于相似的使用场景，我们采取相应解决方案。调整项目时间规划，增加实行预期解决方案的时间。联系运营团队，确保可以承受执行预期解决方案的开销。 高级消息使用场景假设一个公司已经在使用多种消息和队列系统。从运营、架构和开销的角度来看，我们认为有必要迁移到单个系统。同时，我们也希望降低运营成本。 数据架构师团队在和股东以及业务部门详细讨论了当前和未来需求后，给出的结论是，Pulsar 和 Kafka 各有优势。 队列和消息最大的难题是 RabbitMQ 系统。我们使用 RabbitMQ 发送太多消息，RabbitMQ 已经无法满足需求。我们调整了 RabbitMQ 的代码，将消息缓冲在内存中，并继续创建新集群来处理负载。但是我们需要的不是变通方法，而是一个能够处理大规模消息的系统。 数据架构师在研究这一使用场景时，得出结论：新系统必须可以同时处理消息流模型和队列模型。我们不仅需要继续使用 RabbitMQ 处理消息，也需要更高级的消息技术。 Kafka 擅长消息传递，也可以处理大规模消息流，但是无法处理队列。开发团队可以尝试一些解决方案，但这样就不能实现使用单个系统的预期目标。要处理队列使用场景，就同时需要 Kafka 集群和 RabbitMQ 集群。Kafka 集群更像一个缓冲区，可以有效防止 RabbitMQ 集群过载。但是 Kafka 不支持原生 RabbitMQ，我们需要与提供商合作或自己编写代码，才可以实现在 Kafka 和 RabbitMQ 之间移动数据。 Pulsar 可以在同一集群中处理队列和消息，还支持扩展集群。Pulsar 可以将所有消息流模型和队列模型的使用场景整合到一个集群中。用户可以继续使用 RabbitMQ 代码，Pulsar 支持 RabbitMQ 连接器，或者在 broker 中使用 StreamNative 开发的 AoP（AMQP 协议处理插件），该插件已获得 Apache 许可。 如果不想继续使用 RabbitMQ 代码，则可以使用 Pulsar API。Pulsar API 具有和 RabbitMQ 相同的队列功能。用户需要对代码进行相应修改，工作量取决于原代码的结构和细节，修改代码后，还需要对代码进行评估测试。 就队列模型和消息流模型而言，我们选择 Pulsar。 高级保留数据架构师分析了数据使用情况，发现 99.99% 的数据在首次使用后就未被读取。但是，他们决定采取保守策略，保留消息一周。虽然决定存储数据一周，但我们不希望增加太多运营成本。分层存储可以保存数据到本地，然后卸载其他数据到 S3，降低长期保存数据的成本。 Kafka 团队正在开发分层存储，但 Kafka 目前还不支持这一特性。一些服务商提供私有分层存储，但我们不确定是否可以直接用于生产环境中。 分层存储是 Pulsar 的原生特性，可以直接用于生产环境。目前已有多个企业在生产环境中部署该特性。 就分层存储而言，我们选择 Pulsar。Kafka 正在全力开发分层存储，这一特性的重要性不言而喻。 路由 Topic由于我们使用多个 topic 来分解数据，我们期待新系统可以创建大量 topic。数据架构师认为，我们起初需要 10 万个 topic，随着时间的推移，这个数字将会涨到 50 万。 Kafka 集群支持创建的分区数量有限且每个 topic 至少需要一个分区。Kafka 正在增加可支持 topic 的数量，但新特性尚未发布。另外，Kafka 没有命名空间和多租户，因此无法基于 topic 对资源进行分片，十万个 topic 需要存储在同一个命名空间中。 一些企业的确在使用 Kafka 集群存储甚至更多的 topic，同时进行了资源分片。但他们放弃使用单一集群，同时还需要为此支付费用。 Pulsar 支持存储数百万个 topic，这一功能早已发布并投入生产环境。Pulsar 支持命名空间和多租户，用户可以为每个 topic 设置资源配额，进而节约开销。 就 topic 而言，我们选择 Pulsar。 路由由于我们假设该企业曾经使用 RabbitMQ，在设计上，一般通过 broker 路由机制把 topic 上的数据转发到不同的 topic 中。例如，有一个用于存储世界范围数据的 topic，而 RabbitMQ broker 把它处理成以国家为单位的 topic。 数据架构师团队深入研究了如何在消息系统中使用单一 topic 存储世界范围的数据。他们发现当接收数据量增大时，下游 consumer 无法继续处理数据。对每个下游系统进行反序列化、查看数据，再丢弃数据的流程繁杂，且费时费力。 Kafka 将所有数据存储在单一 topic 中，但是，当 consumer 需要过滤的数据量增加或集群过载时，这个方法不可行。我们通常需要进行水平缩放，增加 consumer 数量，才可以读取全局 topic 并做进一步处理。用户只能选择：编写自定义 consumer / producer，编写 Kafka Streams 程序，或使用专有 KSQL。 Pulsar 支持使用 Pulsar Functions 或自定义 consumer / producer 进行路由，因此可以先读取全局 topic，再将数据保存到以国家为单位的特定 topic 上。使用独立 topic，consumer 可以按需订阅 topic，只接收相关消息。 就路由而言，我们选择 Pulsar。 最终决策时间是影响最终决策的主要原因。我们是否有时间让 Kafka 赶上 Pulsar？我们是否有时间让数据工程师来实现 Kafka 的解决方案？等待会让公司错失良机，延缓增加新的使用场景，影响业务发展。 最终决策：我们选择 Pulsar。 时间充足情况下的决策：延迟使用新架构。给 Kafka 半年时间，看 Kafka 是否可以在性能上赶超 Pulsar。如果可以，我们将在生产环境中测试这些新特性，评估稳定性。如果 Kafka 不能让人眼前一亮，我们仍然会选择 Pulsar。 结语本文涉及的三个使用场景都是我在实际工作中遇到的，希望本文给出的解决方案可以为您提供参考，帮助您根据具体使用场景进行技术评估。 原文链接： https://dzone.com/articles/comparing-pulsar-and-kafka-from-a-ctos-point-of-vi","categories":[{"name":"消息系统","slug":"消息系统","permalink":"http://zhangyu.info/categories/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Pulsar","slug":"Pulsar","permalink":"http://zhangyu.info/tags/Pulsar/"}]},{"title":"生产环境中的Kubernetes最佳实践","slug":"kubernetes-best-practices-in-production","date":"2021-04-20T16:00:00.000Z","updated":"2021-04-21T08:50:20.907Z","comments":true,"path":"2021/04/21/kubernetes-best-practices-in-production/","link":"","permalink":"http://zhangyu.info/2021/04/21/kubernetes-best-practices-in-production/","excerpt":"","text":"生产环境中的Kubernetes最佳实践https://mp.weixin.qq.com/s?__biz=MzA5OTAyNzQ2OA==&amp;mid=2649721992&amp;idx=1&amp;sn=31b9a4352a147a1fa585b8d8ef4c68b0&amp;scene=21#wechat_redirect（翻译：易理林）https://my.oschina.net/u/1787735/blog/4870582 DevOps从提出到现在，已经走过了一段很长的路。包括Docker和Kubernetes在内的多种平台也已经帮助企业用前所未有的速度实现了软件应用的交付。同时，随着应用的容器化构建和发布比率不断上升，作为事实上的容器编排工具，Kubernetes在企业用户中备受欢迎和广泛认可。 Kubernetes具有支持伸缩、零中断部署、服务发现、自动更迭和自动回滚等卓越功能特性。在管理大规模容器部署方面，Kubernetes因支持资源和工作负载的灵活分配能力，而成为了企业的必选工具，在生产环境中广泛应用。但与此同时，Kubernetes的应用需要操作人员花许多时间来熟悉和掌握它，存在一定技术门槛。鉴于目前许多公司都希望在生产中使用Kubernetes，因此有必要率先梳理这方面的最佳实践。在本文中，我们将介绍Kubernetes在生产环境中的一些最佳实践。 生产环境中Kubernetes表现 根据Garner的预测，到2022年时，全球超过75%的组织将在生产环境中运行容器化应用。这个比率在当前还不足30%，而预计到2025年时，这个比率将在2022年的基础上，继续增长到85%。快速增长的一个主要原因是云原生的软件应用在基础设施自动化、DevOps、专业操作技能方面的需求越来越强烈，而且这些工具和技术在企业的IT组织中往往很难找到。 其次，业界普遍认为在生产环境中运行容器并不容易，需要大量的计算资源和相关工作投入。目前市场上有多款容器编排平台产品可供选择，但已经获得了主要云提供商的支持和认可的平台只有Kubernetes。 再次，Kubernetes、容器化和微服务给企业用户带来的技术受益的同时，也带来了新的安全挑战。Kubernetes的Pod具备在所有基础设施类之间快速切换的能力，从而导致更多的内部流量和与之相关的安全风险，加上Kubernetes被攻击面往往比我们预期的更大，以及Kubernetes的高度动态和临时的环境与原有安全工具的融合差距等因素，可以预测使用Kubernetes并非是一件容易的事情。 最后，Kubernetes丰富的功能导致它的学习曲线复杂而陡峭，在生产环境中的操作需应尽可能小心和谨慎。企业如果没有熟悉这方面的专业人员，可以考虑外购Kubernetes-as-a-service（KaaS）提供商的服务，获取Kubernetes最佳实践。但假设用户是完全依靠自己的能力，管理生产环境中的Kubernetes集群，在这种情况下，理解和实现Kubernetes最佳实践尤其重要，特别是在可观察性、日志记录、集群监控和安全配置等方面。 综上所述，非常有必要开发一套Kubernetes管理策略，以实现在安全性、监视、网络、容器生命周期管理和平台选择等方面应用最佳实践。如下是Kubernetes应用管理需要重点考虑的措施。 使用服务状态探针进行健康检查 管理大型分布式系统是一件复杂的工作，尤其是出现问题的时候。因此为了确保应用的实例工作正常，配置Kubernetes健康检查至关重要。通过创建自定义运行状况检查，可以更好地满足用户的环境和应用的检测需要。服务状态探针包括服务就绪探针和服务活性探针。 Readiness-就绪探针：目的是让Kubernetes知道应用程序是否准备好提供服务。Kubernetes始终会在确认准备就绪探针通过检测后，然后才允许向POD发送服务请求流量。 Liveness-存活探针：目的是帮助用户确认应用程序是否正常存活，如果应用出现了异常，Kubernetes将启动新的Pod，替换异常的Pod。 资源管理 为单个容器指定资源需求和资源限制是一个很好的实践。另一个好的实践是为不同团队、部门、应用程序和客户端，划分独立的Kubernetes命名空间环境。提供相对独立的运行资源环境，减少资源使用冲突。 资源使用 Kubernetes资源使用情况掌握了生产环境中容器/Pod的资源数量使用情况。因此，密切关注Pod和容器的资源使用情况非常重要，资源使用越多，运行成本就越高。 资源利用 运维团队通常致力于优化和最大化Pod分配资源的利用百分比。资源使用情况往往也是Kubernetes优化程度的重要指标之一。可以说，优化最好的Kubernetes环境，内部运行容器的平均CPU利用率也是最优的。 开启RBAC策略 基于角色的访问控制（RBAC）是系统或网络中限制用户和应用程序的接入或访问的一种控制方法。 Kubernetes 从1.8版本开始，引入了RBAC访问控制技术，使用rbac.authorization.k8s.io程序API创建授权策略。RBAC的授权使用包括开启访问用户或帐户、添加/删除权限、设置规则等。它为Kubernetes集群添加了一个额外的安全层，限制哪些访问可以到达Kubernetes集群的生产环境。 集群配置和负载均衡 生产级Kubernetes基础设施通常需要具备高可用性，具备多控制节点、多etcd集群等关键特性。此类集群特性的配置实现通常需要借助如Terraform或Ansible等工具实现。 通常情况下，当集群的所有配置都完成，并创建了Pod时，此时的Pod基本都会配置有负载均衡器，用于将流量路由到适当的应用服务。但这其中的负载均衡器并不是Kubernetes项目的默认配置，而是由Kubernetes Ingress控制器的扩展集成工具提供的。 标注Kubernetes对象 为Kubernetes的Pod等对象打上键/值对类型的标签，通常可以用来标记重要的对象属性，特别是对用户意义重大的属性。因此，在生产环境中使用Kubernetes时，不能忽视的重要实践就是利用标签功能，它们可以帮助实现Kubernetes对象的批量查询和批量操作。同时，标签还具有将Kubernetes对象组织成集群的独特作用，这样做的一个最佳实践应用就是能够根据应用对Pod进行分组管理。除此之外，标签没有数量和内容的限制，运维团队可以任意创建和使用。 设置网络策略 网络策略设置对于生产环境中的Kubernetes平台非常重要。 网络策略本质上也是一种对象，让用户能够声明和决定哪些流量是允许或禁止传输的。Kubernetes能够阻止所有不需要的和不合规的流量。因此，强烈建议Kubernetes将网络策略配置作为基本和必要的安全措施之一，执行定义和限制集群中的网络流量。 Kubernetes中的每条网络策略都被定义成一个授权连接列表。无论何时创建的网络策略，平台全部的Pod都有权利建立或接受该连接列表。简单来说，网络策略其实就是授权和允许连接的请求白名单，无论是“输入”还是“输出”到Pod，在至少有一条网络策略允许的情况下，到该Pod流量才被允许通行。 集群监控与日志 监控对于运行状态的Kubernetes至关重要，它直接影响到平台配置、性能和流量的安全。能够帮助用户及时掌握平台状态，执行问题诊断、确保运行合规，是平台运行的必要功能部署。在开启集群监视时，必须在平台的每一层都开启日志记录，让产生的日志能够执行安全、审计和性能分析。 采用无状态应用 虽然这种观念正随着Kubernetes应用组织的增加在不断改变，但管理和运行无状态应用要比有状态应用要容易很多。事实上，对于刚接触Kubernetes的团队，建议一开始就采用无状态应用的设计。同时，还建议采用无状态的后端程序，从而让开发人员更有效地部署应用程序，实现服务的零停机时间。但前提是需要开发团队确保后端没有长时间运行的连接，不会影响到运行环境的弹性扩展。无状态应用还被认为具备根据业务需要进行简便迁移和快速扩展的能力。 启用自动扩展 Kubernetes的服务部署拥有3个自动扩展能力：Pod水平自动扩展（HPA），Pod垂直自动扩展（VPA）和集群自动扩展。 Pod水平自动扩展能够基于CPU的利用率，自动扩展运行应用的Pod数量，调整副本控制器、副本集或状态配置。 Pod垂直自动扩展建议为应用设定适当的CPU，内存的需求值和上限值。VPA能够根据情况，自动伸缩配置适当的资源数量。 集群自动扩展能够伸缩工作节点的资源池规模，从而根据当前的资源使用情况，自动调整Kubernetes集群的大小。 控制镜像拉取来源 如果允许Pod从公共库中拉取镜像，而不知道其真正运行内容的时候，用户应该控制所运行容器集群的资源，以避免资源使用的失控。而如果是从受信任的注册节点提取镜像，则可以在注册节点上采用控制策略，限制只允许提取安全且经过认证的镜像。 保持持续学习 对应用程序的状态不断评估、学习和改进。例如，通过查看容器的历史内存使用情况，确定可以分配更少的内存来节省成本。 重点保护核心服务 使用Pod优先级功能，可以为不同的服务设置重要度。例如，可以配置RabbitMQ Pod的优先级高于应用程序Pod，以获得更好的稳定性。或为输入控制器Pod配置比数据处理Pod更高的重要度，以保持服务的可用性。 保证服务零停机 服务的零停机能力可以通过全方位HA架构，支持集群和服务的零停机升级。从而为客户获得更高的服务可用性提供了保证。使用Pod反亲和性配置，确保多个副本Pod被调度到不同的节点上，从而保证计划和非计划的集群节点停机不会影响服务的可用性，或使用Pod中断预备能力，确保在可用成本内，保留最少的副本数量。 为失败指定计划 借用一句名言来理解如果应对硬件故障。硬件最终会失败，软件最终会运行。–（迈克尔·哈顿） “Hardware eventually fails. Software eventually works.”（Michael Hartung）。 结论 业界共知的Kubernetes，实际上已经是DevOps的标配编配平台。生产环境中运行的Kubernetes环境必须具备可用性、可伸缩性、安全性、弹性、资源管理和监控等功能和性能特征。由于许多公司都在生产中使用Kubernetes，因此建议遵循上面提到的Kubernetes最佳实践，以便顺利、可靠地运维和管理应用程序。 原文链接：https://containerjournal.com/topics/container-management/kubernetes-best-practices-in-production/","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://zhangyu.info/categories/Kubernetes/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://zhangyu.info/tags/Kubernetes/"}]},{"title":"你的技术成长战略是什么","slug":"jishuchengzhang","date":"2021-04-18T16:00:00.000Z","updated":"2021-04-19T16:03:49.781Z","comments":true,"path":"2021/04/19/jishuchengzhang/","link":"","permalink":"http://zhangyu.info/2021/04/19/jishuchengzhang/","excerpt":"","text":"你的技术成长战略是什么?_架构师波波的专栏-CSDN博客 https://blog.csdn.net/yang75108/article/details/112511324?spm=1001.2014.3001.5502) 一、前言在波波的微信技术交流群里头，经常有学员问关于技术人该如何学习成长的问题，虽然是微信交流，但我依然可以感受到小伙伴们焦虑的心情。 技术人为啥焦虑？恕我直言，说白了是胆识不足格局太小。胆就是胆量，焦虑的人一般对未来的不确定性怀有恐惧。识就是见识，焦虑的人一般看不清楚周围世界，也看不清自己和适合自己的道路。格局也称志向，容易焦虑的人通常视野窄志向小。如果从战略和管理的视角来看，就是对自己和周围世界的认知不足，没有一个清晰和长期的学习成长战略，也没有可执行的阶段性目标计划+严格的执行。 因为问此类问题的学员很多，让我感觉有点烦了，为了避免重复回答，所以我专门总结梳理了这篇长文，试图统一来回答这类问题。如果后面还有学员问类似问题，我会引导他们来读这篇文章，然后让他们用三个月、一年甚至更长的时间，去思考和回答这样一个问题：你的技术成长战略究竟是什么？如果你想清楚了这个问题，有清晰和可落地的答案，那么恭喜你，你只需按部就班执行就好，根本无需焦虑，你实现自己的战略目标并做出成就只是一个时间问题；否则，你仍然需要通过不断磨炼+思考，务必去搞清楚这个人生的大问题！！！ 下面我们来看一些行业技术大牛是怎么做的。 二、跟技术大牛学成长战略我们知道软件设计是有设计模式(Design Pattern)的，其实技术人的成长也是有成长模式(Growth Pattern)的。波波经常在Linkedin上看一些技术大牛的成长履历，探究其中的成长模式，从而启发制定自己的技术成长战略。 当然，很少有技术大牛会清晰地告诉你他们的技术成长战略，以及每一年的细分落地计划。但是，这并不妨碍我们通过他们的过往履历和产出成果，去溯源他们的技术成长战略。实际上，越是牛逼的技术人，他们的技术成长战略和路径越是清晰，我们越容易从中探究出一些成功的模式。 2.1 系统性能专家案例国内的开发者大都热衷于系统性能优化，有些人甚至三句话离不开高性能/高并发，但真正能深入这个领域，做到专家级水平的却寥寥无几。 我这边要特别介绍的这个技术大牛叫Brendan Gregg(布兰登·格雷格)，他是系统性能领域经典书《System Performance: Enterprise and the Cloud》(中文版《性能之巅：洞悉系统、企业和云计算》)的作者，也是著名的性能分析利器火焰图(Flame Graph)的作者。Brendan Gregg目前是Netflix公司的高级性能架构师，已经在Netflix工作近7年，之前他是Joynet公司的Lead Performance Engineer。总体上，他已经在系统性能领域深耕超过10年，Brendan Gregg的过往履历可以在linkedin上看到。在这10年间，除了书籍以外，Brendan Gregg还产出了超过上百份和系统性能相关的技术文档，演讲视频/ppt，还有各种工具软件，相关内容都整整齐齐地分享在他的技术博客上，可以说他是一个非常高产的技术大牛。 上图来自Brendan Gregg的新书《BPF Performance Tools: Linux System and Application Observability》，其中红色标注的是他开发的各种性能工具。从这个图可以看出，Brendan Gregg对系统性能领域的掌握程度，已经深挖到了硬件、操作系统和应用的每一个角落，可以说是360度无死角，整个计算机系统对他来说几乎都是透明的。波波认为，Brendan Gregg是名副其实的，世界级的，系统性能领域的大神级人物。 2.2 从开源到企业案例我要分享的第二个技术大牛是Jay Kreps(杰·克雷普斯)，他是知名的开源消息中间件Kafka的创始人/架构师，也是Confluent公司的联合创始人和CEO，Confluent公司是围绕Kafka开发企业级产品和服务的技术公司。 从Linkedin的履历上我们可以看出，Jay Kreps之前在Linkedin工作了7年多(2007.6 ~ 2014. 9)，从高级工程师、工程主管，一直做到首席资深工程师。Kafka大致是在2010年，Jay Kreps在Linkedin发起的一个项目，解决Linkedin内部的大数据采集、存储和消费问题。之后，他和他的团队一直专注Kafka的打磨，开源(2011年初)和社区生态的建设。到2014年底，Kafka在社区已经非常成功，有了一个比较大的用户群，于是Jay Kreps就和几个早期作者一起离开了Linkedin，成立了Confluent公司，开始了Kafka和周边产品的企业化服务道路。今年(2020.4月)，Confluent公司已经获得E轮2.5亿美金融资，公司估值达到45亿美金。从Kafka诞生到现在，Jay Kreps差不多在这个产品和公司上投入了整整10年。 上图是Confluent创始人三人组，一个非常有意思的组合，一个中国人(左)，一个印度人(右)，中间的Jay Kreps是美国人。 我之所以对Kafka和Jay Kreps的印象特别深刻，是因为在2012年下半年，我在携程框架部也是专门搞大数据采集的，我还开发过一套功能类似Kafka的Log Collector + Agent产品。我记得同时期有不止4个同类型的开源产品：Facebook Scribe、Apache Chukwa、Apache Flume和Apache Kafka。现在回头看，只有Kafka走到现在发展得最好，这个和创始人的专注和持续投入是分不开的，当然背后和几个创始人的技术大格局也是分不开的。 当年我对战略性思维几乎没有概念，还处在什么技术都想学、认为各种项目做得越多越牛的阶段。搞了半年的数据采集以后，我就掉头搞其它“更有趣”的项目去了(从这个事情的侧面，也可以看出我当年的技术格局是很小的)。中间我陆续关注过Jay的一些创业动向，但是没想到他能把Confluent公司发展到目前这个规模。现在回想，其实在十年前，Jay Kreps对自己的技术成长就有比较明确的战略性规划，也具有大的技术格局和成事的一些必要特质。Jay Kreps和Kafka给我上了一堂生动的技术战略和实践课。 2.3 技术媒体大V案例介绍到这里，有些同学可能会反驳说：波波你讲的这些大牛都是学历背景好，功底扎实起点高，所以他们才更能成功。其实不然，这里我再要介绍一位技术媒体界的大V叫Brad Traversy(布拉德·特沃西)，大家可以看他的Linkedin简历，背景很一般，学历差不多是一个非正规的社区大学(相当于大专)，没有正规大厂工作经历，有限几份工作一直是在做网站外包。但是Brad Traversy目前是技术媒体领域的一个大V，当前他在Youtube上有138万多的订阅量，10年累计输出Web开发和编程相关教学视频超过800个。Brad Traversy也是Udemy上的一个成功讲师，目前已经在Udemy上累计输出课程14门，购课学生数量近25万。Brad Traversy目前是自由职业者，他的Youtube广告+Udemy课程的收入相当不错。 就是这样一位技术媒体大V，你很难想象，在年轻的时候，贴在他身上的标签是：不良少年，酗酒，抽烟，吸毒，纹身，进监狱。。。直到结婚后的第一个孩子诞生，他才开始担起责任做出改变，然后凭借对技术的一腔热情，开始在Youtube平台上持续输出免费课程。从此他找到了适合自己的战略目标，然后人生开始发生各种积极的变化。。。如果大家对Brad Traversy的过往经历感兴趣，推荐观看他在Youtube上的自述视频《My Struggles &amp; Success》。 我粗略浏览了Brad Traversy在Youtube上的所有视频，10年总计输出800+视频，平均每年80+。第一个视频提交于2010年8月，刚开始几年几乎没有订阅量，2017年1月订阅量才到50k，这中间差不多隔了6年。2017.10月订阅量猛增到200k，2018年3月订阅量到300k。当前2021.1月，订阅量达到138万。可以认为从2017开始，也就是在积累了6～7年后，他的订阅量开始出现拐点。如果把这些数据画出来，将会是一条非常漂亮的复利曲线。 2.4 案例小结Brendan Gregg，Jay Kreps和Brad Traversy三个人走的技术路线各不相同，但是他们的成功具有共性或者说模式： 找到了适合自己的长期战略目标，例如： Brendan Gregg: 成为系统性能领域顶级专家 Jay Kreps：开创基于Kafka开源消息队列的企业服务公司，并将公司做到上市 Brad Traversy: 成为技术媒体领域大V和课程讲师，并以此作为自己的职业 **专注深耕一个(或有限几个相关的)细分领域(Niche)**，保持定力，不随便切换领域： Brendan Gregg：系统性能领域 Jay Kreps: 消息中间件/实时计算领域+创业 Brad Traversy: 技术媒体/教学领域，方向Web开发 + 编程语言 长期投入，三人都持续投入了10年。 **年度细分计划+持续可量化的价值产出(Persistent &amp; Measurable Value Output)**： Brendan Gregg：除公司日常工作产出以外，每年有超过10份以上的技术文档和演讲视频产出，平均每年有2.5个开源工具产出。十年共产出书籍2本，其中《System Performance》已经更新到第二版。 Jay Kreps：总体有开源产品+公司产出，1本书产出，每年有Kafka和周边产品发版若干。 Brad Traversy: 每年有Youtube免费视频产出（平均每年80+）+Udemy收费视频课产出(平均每年1.5门)。 以终为始是牛人和普通人的一大区别。普通人通常走一步算一步，很少长远规划。牛人通常是先有远大目标，然后采用倒推法，将大目标细化到每年/月/周的详细落地计划。Brendan Gregg，Jay Kreps和Brad Traversy三人都是以终为始的典型。 上面总结了几位技术大牛的成长模式，其中一个要点是：这些大牛的成长都是通过持续有价值产出Persistent Valuable Output来驱动的。持续产出为啥如此重要，这个还要从下面的学习金字塔说起。 三、学习金字塔和刻意训练 学习金字塔是美国缅因州国家训练实验室的研究成果，它认为： 我们平时上课听讲之后，学习内容平均留存率大致只有5%左右； 书本阅读的平均留存率大致只有10%左右； 学习配上视听效果的课程，平均留存率大致在20%左右， 老师实际动手做实验演示后的平均留存率大致在30%左右； 小组讨论(尤其是辩论后)的平均留存率可以达到50%左右； 在实践中实际应用所学之后，平均留存率可以达到75%左右； 在实践的基础上，再把所学梳理出来，转而再传授给他人后，平均留存率可以达到90%左右。 上面列出的7种学习方法，前四种称为被动学习，后三种称为主动学习。拿学游泳做个类比，被动学习相当于你看别人游泳，而主动学习则是你自己要下水去游。我们知道游泳或者跑步之类的运动是要燃烧身体卡路里的，这样才能达到锻炼身体和长肌肉的效果(肌肉是卡路里燃烧的结果)。如果你只是看别人游泳，自己不实际去游，是不会长肌肉的。同样的，主动学习也是要燃烧脑部卡路里的，这样才能达到训练大脑和长脑部“肌肉”的效果。 我们也知道，燃烧身体的卡路里，通常会让人感觉不舒适，如果燃烧身体卡路里会让人感觉舒适的话，估计这个世界上应该不会有胖子这类人。同样，燃烧脑部卡路里也会让人感觉不适、紧张、出汗或语无伦次，如果燃烧脑部卡路里会让人感觉舒适的话，估计这个世界上人人都很聪明，人人都能发挥最大潜能。当然，这些不舒适是短期的，长期会使你更健康和聪明。波波一直认为，人与人之间的先天身体其实都差不多，但是后天身体素质和能力有差异，这些差异，很大程度是由后天对身体和大脑的训练质量、频度和强度所造成的。 明白这个道理之后，心智成熟和自律的人就会对自己进行持续地刻意训练。这个刻意训练包括对身体的训练，比如波波现在每天坚持跑步3km，走3km，每天做60个仰卧起坐，5分钟平板撑等，每天保持让身体燃烧一定量的卡路里。刻意训练也包括对大脑的训练，比如波波现在每天做项目写代码coding(训练脑+手)，平均每天在B站上输出十分钟免费视频(训练脑+口头表达)，另外有定期总结输出公众号文章(训练脑+文字表达)，还有每天打半小时左右的平衡球(下图)或古墓丽影游戏(训练小脑+手)，每天保持让大脑燃烧一定量的卡路里，并保持一定强度(适度不适感)。如果你对刻意训练的专业原理和方法论感兴趣，推荐看书籍《刻意练习》。 注意，如果你平时从来不做举重锻炼的，那么某天突然做举重会很不适应甚至受伤。脑部训练也是一样的，如果你从来没有做过视频输出，那么刚开始做会很不适应，做出来的视频质量会很差。不过没有关系，任何训练都是一个循序渐进，不断强化的过程。等大脑相关区域的”肌肉”长出来以后，会逐步进入正循环，后面会越来越顺畅，相关”肌肉”会越来越发达。所以，和健身一样，健脑也不能遇到困难就放弃，需要循序渐进(Incremental)+持续地(Persistent)刻意训练。 理解了学习金字塔和刻意训练以后，现在再来看Brendan Gregg，Jay Kreps和Brad Traversy这些大牛的做法，他们的学习成长都是建立在持续有价值产出的基础上的，这些产出都是刻意训练+燃烧脑部卡路里的成果。他们的产出要么是建立在实践基础上的产出，例如Jay Kreps的Kafka开源项目和Confluent公司；要么是在实践的基础上，再整理传授给其他人的产出，例如，Brendan Greeg的技术演讲ppt/视频，书籍，还有Brad Traversy的教学视频等等。换句话说，他们一直在学习金字塔的5～7层主动和高效地学习。并且，他们的学习产出还可以获得用户使用，有客户价值(Customer Value)，有用户就有反馈和度量。记住，有反馈和度量的学习，也称闭环学习，它是能够不断改进提升的；反之，没有反馈和度量的学习，无法改进提升。 现在，你也应该明白，晒个书单秀个技能图谱很简单，读个书上个课也不难。但是要你给出5～10年的总体技术成长战略，再基于这个战略给出每年的细分落地计划(尤其是产出计划)，然后再严格按计划执行，这的确是很难的事情。这需要大量的实践训练+深度思考，要燃烧大量的脑部卡路里！但这是上天设置的进化法则，成长为真正的技术大牛如同成长为一流的运动员，是需要通过燃烧与之相匹配量的卡路里来交换的。成长为真正的技术大牛，也是需要通过产出与之匹配的社会价值来交换的，只有这样社会才能正常进化。你推进了社会进化，社会才会回馈你。如果不是这样，社会就无法正常进化。 四、战略思维的诞生 一般毕业生刚进入企业工作的时候，思考大都是以天/星期/月为单位的，基本上都是今天学个什么技术，明天学个什么语言，很少会去思考一年甚至更长的目标。这是个眼前漆黑看不到的懵懂时期，捕捉到机会点的能力和概率都非常小。 工作了三年以后，悟性好的人通常会以一年为思考周期，制定和实施一些年度计划。这个时期是相信天赋和比拼能力的阶段，可以捕捉到一些小机会。 工作了五年以后，一些悟性好的人会产生出一定的胆识和眼光，他们会以3～5年为周期来制定和实施计划，开始主动布局去捕捉一些中型机会点。 工作了十年以后，悟性高的人会看到模式和规则变化，例如看出行业发展模式，还有人才的成长模式等，于是开始诞生出战略性思维。然后他们会以5～10年为周期来制定和实施自己的战略计划，开始主动布局去捕捉一些中大机会点。Brendan Gregg，Jay Kreps和Brad Traversy都是属于这个阶段的人。 当然还有很少一些更牛的时代精英，他们能够看透时代和人性，他们的思考是以一生甚至更长时间为单位的，这些超人不在本文讨论范围内。 五、建议 现在大学生毕业的年龄一般在22～23岁，那么在工作了十年后，也就是在你32～33岁的时候，你差不多也看了十年了，应该对自己和周围的世界(你的行业和领域)有一个比较深刻的领悟，需要开始为下一个十年去做战略布局了。如果你到这个年纪还懵懵懂懂，今天抓东明天抓西，那么只能说你的胆识格局是相当的低。在当前IT行业竞争这么激烈的情况下，到35岁被下岗可能就在眼前。 有了战略性思考，你就会以5～10年为周期去布局谋划你的战略。以Brendan Gregg，Jay Kreps和Brad Traversy这些大牛为例，人生若真的要干点成就出来，投入周期一般都要十年。从33岁开始，你大致有3个十年，因为到60岁以后，一般人都老眼昏花干不了大事了。如果你悟性差一点，到40岁才开始规划，那么你大致还有2个十年。如果你规划好了，这2～3个十年可以成就不小的事业。否则，你很可能一生无所作为，或者一直在帮助成全别人的事业。 考虑到人生能干事业的时间也就是2～3个十年，你会发现人生其实很短暂，这时候你会把精力都投入到实现你的十年战略上去，没有时间再浪费在比如网上的闲聊和扯皮争论上去。 “图难于其易，为大于其细。天下难事必作于易，天下大事必作于细。是以圣人终不为大，故能成其大。”～道德经。有了十年战略方向，下一步是每年的细分落地计划，尤其是产出计划。这个计划主要应该工作在学习金字塔的5/6/7层。产出应该是刻意训练+燃烧卡路里的结果，每天让身体和大脑都保持燃烧一定量的卡路里。 产出应该有客户价值，自己能学习(自己成长进化)，对别人还有用(推动社会成长进化)，这样可以得到用户回馈和度量，形成一个闭环，可以持续改进和提升你的学习。 “少则得，多则惑”～道德经。少即是多，深耕一个(或有限几个相关的)领域。所有细分计划应该紧密围绕你的战略展开。克制内心欲望，不要贪多和分心，不要被喧嚣的世界所迷惑。 战略方向+细分计划都要写下来，定期review优化。 “曲则全、枉则直”～道德经。战略实现不是直线的，而是曲折迂回的。战略方向和细分计划通常要按需调整，尤其在早期，但是最终要收敛。如果老是变不收敛，就是缺乏战略定力，是个必须思考和解决的大问题。 别人的成长战略可以参考，但是不要刻意去模仿，你有你自己的颜色，你应该成为独一无二的你。 “合抱之木，生于毫末；九层之台，起于蔂土；千里之行，始于足下”～道德经。战略方向和细分计划明确了，接下来就是按部就班执行，十年如一日铁打不动。 做长期主义者和时间的朋友，”任何一个人，不管你的能量强弱，放眼于足够长的时间，你都可以通过长期主义这种行为模式，成为时间的朋友”～罗振宇。 最后，战略目标的实现也和种树一样是生长出来的，需要时间耐心栽培，记住慢就是快。焦虑纠结的时候，像念经一样默念王阳明《传习录》中的教诲： 立志用功，如种树然。方其根芽，犹未有干；及其有干，尚未有枝；枝而后叶，叶而后花实。初种根时，只管栽培灌溉。勿作枝想，勿作花想，勿作实想。悬想何益？但不忘栽培之功，怕没有枝叶花实？ 译文： 实现战略目标，就像种树一样。刚开始只是一个小根芽，树干还没有长出来；树干长出来了，枝叶才能慢慢长出来；枝叶长出来，然后才能开花和结果。刚开始种树的时候，只管栽培灌溉，别老是纠结枝什么时候长出来，花什么时候开，果实什么时候结出来。纠结有什么好处呢？只要你坚持投入栽培，还怕没有枝叶花实吗？","categories":[{"name":"职业发展","slug":"职业发展","permalink":"http://zhangyu.info/categories/%E8%81%8C%E4%B8%9A%E5%8F%91%E5%B1%95/"}],"tags":[{"name":"职业发展","slug":"职业发展","permalink":"http://zhangyu.info/tags/%E8%81%8C%E4%B8%9A%E5%8F%91%E5%B1%95/"}]},{"title":"使用nerdctl玩转containerd","slug":"nerdctl-to-containerd","date":"2021-04-11T16:00:00.000Z","updated":"2021-04-12T13:02:31.269Z","comments":true,"path":"2021/04/12/nerdctl-to-containerd/","link":"","permalink":"http://zhangyu.info/2021/04/12/nerdctl-to-containerd/","excerpt":"","text":"参考https://mp.weixin.qq.com/s/ZKoO041TqyR2guVooPegrg 从行业趋势来看，Docker 已经和 Kubernetes 社区渐行渐远，以?Containerd?为代表的实现了?CRI?接口的容器运行时将会受到 Kubernetes 的青睐。但纯粹使用 Containerd 还是有诸多困扰，比如不方便通过 CLI 来创建管理容器，有了?nerdctl?这个 CLI 工具，就就可以填补 Containerd 易用性的空缺 现有 CLI 的不足虽然 Docker 能干的事情，现在 Containerd 都能干，但 Containerd 还有一个非常明显的缺陷：CLI 不够友好。它无法像 Docker 和 Podman 一样通过一条简单的命令启动一个容器，它的两个 CLI 工具 ctr 和 crictl都无法实现这么一件非常简单的需求，而这个需求是大多数人都需要的，我总不能为了在本地测试容器而专门部署一个 Kubernetes 集群吧？ ctr 的设计对人类不太友好，例如缺少以下这些和 Docker 类似的功能： docker run -p &lt;PORT&gt; docker run --restart=always 通过凭证文件 ~/.docker/config.json 来拉取镜像 docker logs 除此之外还有一个 CLI 工具叫 crictl，和 ctr 一样不太友好。 为了解决这个痛点，Containerd 官方推出了一个新的 CLI 叫 nerdctl。nerdctl 的使用体验和 docker 一样顺滑 ##安裝nerdctl 你可以从?https://github.com/containerd/nerdctl中下载最新的可执行文件，每一个版本都有两种可用的发行版： `nerdctl--linux-amd64.tar.gz?: 只包含 nerdctl。 `nerdctl-full--linux-amd64.tar.gz?: 包含了 nerdctl 和相关依赖组件（containerd, runc, ###CNI, …）。 如果你已经安装了 Containerd，只需要选择前一个发行版，否则就选择完整版。 这里选择完整版nerdctl-full-0.7.3-linux-amd64.tar.gzcd /opt wget https://github.com/containerd/nerdctl/releases/download/v0.7.3/nerdctl-full-0.7.3-linux-amd64.tar.gz tar -C /usr/local -xzf nerdctl-full-0.7.3-linux-amd64.tar.gz mkdir -p /etc/containerd containerd config default &gt; /etc/containerd/config.toml sed -i “s#k8s.gcr.io#registry.aliyuncs.com/k8sxio#g” /etc/containerd/config.toml sed -i “s/systemd_cgroup = false/systemd_cgroup = true/g” /etc/containerd/config.toml export REGISTRY_MIRROR=https://registry.cn-hangzhou.aliyuncs.com sed -i “s#https://registry-1.docker.io#${REGISTRY_MIRROR}#g&quot; /etc/containerd/config.toml mkdir -p /data/containerd-data-root sed -i “s#/var/lib/containerd#/data/containerd-data-root#g” /etc/containerd/config.toml sed -i “s#oom_score = 0#oom_score = -999#g” /etc/containerd/config.toml sed -i “/containerd.runtimes.runc.options/a\\ SystemdCgroup = true” /etc/containerd/config.toml sed -i “s#/opt/cni/bin#/usr/local/libexec/cni#g” /etc/containerd/config.toml 123456789101112添加私有仓库harbor---自定义--可选[plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry] [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors] [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors.&quot;harbor.testtest.com&quot;] endpoint &#x3D; [&quot;https:&#x2F;&#x2F;harbor.testtest.com&quot;] [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.configs] [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.configs.&quot;harbor.testtest.com&quot;.tls] insecure_skip_verify &#x3D; true [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.configs.&quot;harbor.testtest.com&quot;.auth] username &#x3D; &quot;admin&quot; password &#x3D; &quot;Harbor12345&quot; systemctl daemon-reload systemctl enable –now containerd systemctl status containerd containerd –version ###普通用户Rootless 切换到普通用户 比如su - admin 执行 containerd-rootless-setuptool.sh install 强烈建议在Rootless模式下启用cgroup v2 请参阅https://rootlesscontaine.rs/getting-started/common/cgroup2/","categories":[{"name":"containerd","slug":"containerd","permalink":"http://zhangyu.info/categories/containerd/"}],"tags":[{"name":"containerd","slug":"containerd","permalink":"http://zhangyu.info/tags/containerd/"}]},{"title":"Kubernetes网络和云厂商实践浅析","slug":"Kubernetes-network","date":"2021-04-08T16:00:00.000Z","updated":"2021-04-09T03:00:20.304Z","comments":true,"path":"2021/04/09/Kubernetes-network/","link":"","permalink":"http://zhangyu.info/2021/04/09/Kubernetes-network/","excerpt":"","text":"Kubernetes网络和云厂商实践浅析 原创 张向阳 云网漫步 2020-11-22https://mp.weixin.qq.com/s?src=11&amp;timestamp=1617936055&amp;ver=2997&amp;signature=czoNtYoc1oSn7KtlQknWvo*D*Q0GOWU2VI3rEKh6YtE9kSX4TOoMWQLrj8cPiKi9jDE-u4SIMSdM1iYpGw63aXBXZlz7XHUcOgrTiL335Qm9mxs0cJFYp7j1VpUx6IkF&amp;new=1 0 前言Kubernetes 是一个可移植的、可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化。Kubernetes 源于希腊语，意为 &quot;舵手&quot; 或 &quot;飞行员&quot;，Google 在 2014 年开源了 Kubernetes 项目，Kubernetes 建立在 Google 在大规模运行生产工作负载方面拥有十几年的经验的基础上（Brog系统），结合了社区中最好的想法和实践。 为了能实现Kubernetes有效的管理大规模的容器，需要优秀网络技术的支撑，本文主要从Kubernetes网络的角度去介绍Kubernetes网络的需求、网络模型、实现技术、云厂商Kubernetes的网络实践。 1 Kubernetes网络系统需求集群网络系统是 Kubernetes 的核心部分，它需要解决下面四个问题。 Pod内容器间通信。 Pod 间通信。 Pod 和服务间通信。 外部和服务间通信。 Kubernetes 的宗旨就是在应用之间共享机器，共享机器需要两个应用之间不能使用相同的端口，但是在多个应用开发者之间去大规模地协调端口是件很困难的事情，尤其是还要让用户暴露在他们控制范围之外的集群级别的问题上。同时动态分配端口也会给系统带来很多复杂度，每个应用都需要设置一个端口的参数，而 API服务器还需要知道如何将动态端口数值插入到配置模块中，服务也需要知道如何找到对方等等。 与其去解决这些问题，Kubernetes 选择了其他不同的方法，下面我们介绍一下Kubernetes 网络模型。 2 Kubernetes 网络模型 Kubernetes 对所有网络设施的实施，都需要满足以下的基本要求（除非有设置一些特定的网络分段策略）： 节点上的 Pod 可以不通过 NAT 和其他任何节点上的 Pod 通信。 节点上的代理（例如，系统守护进程、kubelet）可以和节点上的所有Pod通信。 每一个Pod都有它自己的IP地址，这就意味着不需要显式地在每个Pod之间创建链接，也不需要处理容器端口到主机端口之间的映射。这样将创建一个干净的、向后兼容的模型，在这个模型里，从端口分配、命名、服务发现、负载均衡、应用配置和迁移的角度来看，Pod可以被视作虚拟机或者物理主机。同时还和 Kubernetes 的实现廉价的从虚拟机向容器迁移的初衷相兼容，如果你的工作开始是在虚拟机中运行的，你的虚拟机有一个 IP，这样就可以和其他的虚拟机进行通信，这是基本相同的模型。 3 Kubernetes 网络技术 从上文看出，每个pod有自己唯一的IP地址，可通过一个扁平的、非NAT网络和其他Pod通信。Kubernetes是如何做到这一点呢？其实，Kubernetes不负责这块，网络是有Container Network Interface（CNI）插件进行管理。CNI是 CNCF 旗下的一个项目，由一组用于配置 Linux 容器的网络接口的规范和库组成，同时还包含了一些插件，CNI 仅关心容器创建时的网络分配，和当容器被删除时释放网络资源，如下图所示。 Kubernetes网络实现模型很多，从本质上看，使用网络技术有两大类，路由方案和Overlay网络方案。 3.1 Pod3.1.1 Pod内container(容器)通信 Pod中管理着一组容器，这些容器共享同一个网络命名空间。Pod中的每个容器拥有与Pod相同的IP和port地址空间，并且由于他们在同一个网络命名空间，他们之间可以通过localhost相互访问。 每个Pod容器有一个pause容器其有独立的网络命名空间，在Pod内启动容器时候使用 –net=container就可以让当前容器加入到Pod容器拥有的网络命名空间（pause容器）。 3.1.2 同节点的Pod通信 每个Pod拥有一个ip地址，不同的Pod之间可以直接使用改ip与彼此进行通讯。在同一个Node上，从Pod的视角看，它存在于自己的网络命名空间中，并且需要与该Node上的其他网络命名空间上的Pod进行通信。 为了让多个Pod的网络命名空间链接起来，会创建一下veth pair对，veth对的一端链接到宿主机的网络命名空间，另一端链接到Pod的网络命名空间，并重新命名为eth0。 宿主机网络命名空间的接口会绑定到容器运行时配置使用的网络桥接上。从网桥的地址段中去IP地址赋值给容器的eth0接口。应用的任何运行在容器内部的程序都会发送数据到eht0网络接口，数据从宿主机命名空间的另外一个veth接口出来，然后发送给网桥。 3.1.3 不同节点的Pod通信 不同节点上的pod能够通信，需要把这些节点的网桥以某种方式连接起来，有多种连接不同节点上的网桥的方式，例如通过三层路由，或者Overlay网络（隧道技术，例如GRE和VxLAN等）。 路由方案 Overlay方案 pod通常需要对来自集群内部其他pod，以及来自集群外部的客户端的HTTP请求作出反应。pod需要一种寻找其他pod的方法来使用其他pod提供的服务。而在Kubernetes的网络中，有特殊的地方。 一个服务经常会起多个pod，你到底访问那个pod的ip呢？ pod经常会因为各种原因被调度，调度后一个pod的ip会发生变化。 pod的ip是虚拟的且局域的，在集群内部访问没有问题，但是从Kubernetes集群的外部如何访问pod的ip呢？ 为了解决第1，2的问题，Kubernetes提供了一种资源类型，服务（service）。为了解决第3个问题，Kubernetes有将服务的类型设置为NodePort，将服务的类型设置为LoadBanlance，创建一个Ingress资源。 3.2 Service Kubernetes的service（服务）是一种为一组功能相同的pod提供单一不变的接入点的资源。当服务存在时，它的ip地址和端口不会变化，客户端通过IP地址和端口号建立连接，这些连接会被路由到提供该服务的任意一个pod上。通过这种方式，客户端不需要知道每个单独的提供服务的pod的地址，这样这些pod可以在集群中随时被创建或者移除。 Kubernetes的服务需要解决两个主要问题。 服务怎么做负载均衡？ 服务怎么被发现？ 3.2.1 负载均衡 在 Kubernetes 集群中，每个 Node 运行一个 kube-proxy 进程。kube-proxy 负责为 Service 实现了一种 VIP的形式。其实，服务并不是和pod直接相连的，它们之间是一种EndPoint资源。EndPoint资源就是暴露一个服务的IP地址和端口列表。 3.2.1.1 userspace 代理模式 kube-proxy 会监视 Kubernetes 主控节点对 Service 对象和 Endpoints 对象的添加和移除操作。对每个 Service，它会在本地 Node 上打开一个端口（随机选择）。任何连接到“代理端口”的请求，都会被代理到 Service 的后端 Pods 中的某个上面（如 Endpoints 所报告的一样）。使用哪个后端 Pod，是 kube-proxy 基于 SessionAffinity 来确定的。 最后，它配置 iptables 规则，捕获到达该 Service 的 clusterIP（是虚拟 IP） 和 Port 的请求，并重定向到代理端口，代理端口再代理请求到后端Pod。默认情况下，用户空间模式下的 kube-proxy 通过轮转算法选择后端。 3.2.1.2 iptables 代理模式 kube-proxy 会监视 Kubernetes 控制节点对 Service 对象和 Endpoints 对象的添加和移除。对每个 Service，它会配置 iptables 规则，从而捕获到达该 Service 的 clusterIP 和端口的请求，进而将请求重定向到 Service 的一组后端中的某个 Pod 上面。对于每个 Endpoints 对象，它也会配置 iptables 规则，这个规则会选择一个后端组合。默认的策略是，kube-proxy 在 iptables 模式下随机选择一个后端。 使用 iptables 处理流量具有较低的系统开销，因为流量由 Linux netfilter 处理， 而无需在用户空间和内核空间之间切换。这种方法也可能更可靠。 如果 kube-proxy 在 iptables 模式下运行，并且所选的第一个 Pod 没有响应， 则连接失败。这与用户空间模式不同：在这种情况下，kube-proxy 将检测到与第一个 Pod 的连接已失败， 并会自动使用其他后端 Pod 重试。 3.2.1.3 IPVS 代理模式 在 ipvs 模式下，kube-proxy监视Kubernetes服务和端点，调用 netlink 接口相应地创建 IPVS 规则， 并定期将 IPVS 规则与 Kubernetes 服务和端点同步。该控制循环可确保IPVS 状态与所需状态匹配。访问服务时，IPVS 将流量定向到后端Pod之一。 IPVS代理模式基于类似于 iptables 模式的 netfilter 挂钩函数， 但是使用哈希表作为基础数据结构，并且在内核空间中工作。与iptables 模式下的 kube-proxy 相比，IPVS 模式下的 kube-proxy 重定向通信的延迟要短，并且在同步代理规则时具有更好的性能。与其他代理模式相比，IPVS 模式还支持更高的网络流量吞吐量。IPVS提供了更多选项来平衡后端Pod的流量。 3.2.2 服务发现Kubernetes 支持两种基本的服务发现模式 —— 环境变量和 DNS。 通过环境变量发现服务 在pod开始运行的时候，Kubernetes会初始化一系列的环境变量指向现在存在的服务 注：当您具有需要访问服务的Pod时，并且您正在使用环境变量方法将端口和群集 IP 发布到客户端 Pod 时，必须在客户端 Pod 出现 之前 创建服务。否则，这些客户端 Pod 将不会设定其环境变量。 通过DNS发现服务 支持群集的 DNS 服务器监视 Kubernetes API 中的新服务，并为每个服务创建一组 DNS 记录。如果在整个群集中都启用了 DNS，则所有 Pod 都应该能够通过其 DNS 名称自动解析服务。 3.2.3 发布服务 对一些应用（如前端）的某些部分，可能希望通过外部 Kubernetes 集群外部 IP 地址暴露 Service。 Kubernetes ServiceTypes 允许指定一个需要的类型的 Service，默认是 ClusterIP类型。 ClusterIP：通过集群的内部 IP 暴露服务，选择该值，服务只能够在集群内部可以访问，这也是默认的 ServiceType。 NodePort：通过每个 Node 上的 IP 和静态端口（NodePort）暴露服务。NodePort 服务会路由到 ClusterIP 服务，这个 ClusterIP 服务会自动创建。通过请求 &lt;NodeIP&gt;:&lt;NodePort&gt;，可以从集群的外部访问一个 NodePort 服务。 LoadBalancer：使用云提供商的负载均衡器，可以向外部暴露服务。外部的负载均衡器可以路由到 NodePort 服务和 ClusterIP 服务。 3.3 Ingress 我们也可以使用 Ingress 来暴露自己的服务。 为什么需要Ingress呢？一个重要的原因是每个LoadBalancer服务都需要自己的负载均衡器，以及独有的公用IP地址，而Ingress只需要一个公网IP就能为很多服务提供访问。例如，当客户端向Ingress发送HTTP请求时，Ingress会根据请求的主机和路径决定请求转发到的服务。 客户端先执行DNS查询，DNS服务器返回了Ingress控制器的IP地址。 客户端然后向Ingress控制器发送HTTP请求，并在Host头部中指定访问的域名。 控制器从该Host头部确认客户端尝试访问哪个服务，通过与该服务关联的Endpoint对象查看pod IP，并将客户端的请求转发给其中一个pod。 4. 云厂商Kubernetes实践4.1 AWS Kubernetes网络方案 AWS上搭建Kubernetes集群环境有两种方式，一种是使用托管服务Amazon Elastic Kubernetes Service (Amazon EKS) ，一种是自建K8S集群。可以使用Amazon VPC CNI插件管理Pod的网络地址和通信。 EKS网络架构 4.1.1 VPC CNI插件 AWS VPC CNI 为 Kubernetes 集群提供了集成的 AWS 虚拟私有云（VPC）网络，使用该 CNI 插件，可使 Kubernetes Pod 拥有与在 VPC 网络上相同的 IP 地址。CNI 将 AWS 弹性网络接口（ENI）分配给每个 Kubernetes 节点，并将每个 ENI 的辅助 IP 范围用于该节点上的 Pod 。 Kubernetes 的 Amazon VPC 容器网络接口 (CNI) 插件随每个节点一起部署，插件包含两个主要组件。 **L-IPAM 守护程序**\\-负责创建网络接口并将网络接口附加到 Amazon EC2 实例,将辅助 IP 地址分配给网络接口,并在每个节点上维护 IP 地址的地址池,以便在安排时分配到 Kubernetes Pod。 **CNI 插件** – 负责连接主机网络(例如,配置网络接口和虚拟以太网对)并向 Pod 命名空间添加正确的网络接口。 4.1.2 Pod通信 VPC 内的通信（如 Pod 到 Pod）在私有 IP 地址之间是直接通信。 4.1.2 Pod和外部通信 当流量以 VPC 外部的地址为目标时,默认情况下,Kubernetes 的 Amazon VPC CNI 插件将每个 Pod 的私有 IP 地址转换为分配给 Pod 在其上运行的 节点的主 网络接口Amazon EC2(网络接口)的主私有IP地址，有如下两种方式。 4.1.3 Ingress AWS ALB Ingress 控制器将在Kubernetes 用户声明集群上的 Ingress 资源时触发创建 ALB 以及必要的 AWS 支持资源。Ingress 资源通过 ALB 将 HTTP\\[s\\] 流量路由至集群内的不同终端节点。 控制器观察来自 API 服务器的进站事件。如果发现 Ingress 资源满足要求，则将开始创建 AWS 资源。 为 Ingress 资源创建 ALB。 为 Ingress 资源中指定的每个后端创建目标组。 为 Ingress 资源注释中指定的每个端口创建侦听器。如果未指定端口，则将使用合理的默认值（80 或 443）。 为 Ingress 资源中指定的每个路径创建规则。这将确保指向特定路径的流量将被路由至所创建的正确目标组。 4.2 GCP Kubernetes网络方案Google Kubernetes Engine (GKE) 提供了一个托管环境，可以使用 Google 基础架构在其中部署、管理和扩缩容器化应用。 4.2.1 Pod通信 4.2.2 Service 4.2.3 Loadbalancer 具体细节，参考GCP的官方文档。 https://cloud.google.com/kubernetes-engine/docs/concepts/network-overview 4.3 阿里云Kubernetes网络方案 阿里云容器服务产品线的整体架构 本章节是介绍阿里云容器服务Kubernetes版ACK（Alibaba Cloud Container Service for Kubernetes）。 4.3.1 网络模型 容器服务将Kubernetes网络和阿里云VPC的深度集成，提供了稳定高性能的容器网络。在容器服务中，支持以下类型的互联互通。 同一个容器集群中，Pod之间相互访问。 同一个容器集群中，Pod访问Service。 同一个容器集群中，ECS访问Service。 Pod直接访问同一个VPC下的ECS。 同一个VPC下的ECS直接访问Pod。 4.3.2 阿里云Terway网络插件 Terway网络插件是阿里云容器服务的网络插件，功能上完全兼容Flannel。 支持将阿里云的弹性网卡分配给容器。 支持基于Kubernetes标准的NetworkPolicy来定义容器间的访问策略，兼容Calico的Network Policy。 在Terway网络插件中，每个Pod拥有自己网络栈和IP地址。同一台ECS内的Pod之间通信，直接通过机器内部的转发，跨ECS的Pod通信，报文通过VPC的vRouter转发。由于不需要使用VxLAN等的隧道技术封装报文，因此具有较高的通信性能。 4.4 腾讯云Kubernetes网络方案腾讯云容器服务（Tencent Kubernetes Engine ，TKE）基于原生 kubernetes 提供以容器为核心的、高度可扩展的高性能容器管理服务。 本章节主要参考以下文章，公众号：腾讯云原生 公众号文章：腾讯云容器服务TKE推出新一代零损耗容器网络 4.4.1 GlobalRouter 模式 基于 vpc 实现的全局路由模式，目前是 TKE 默认网络方案。该模式依托于 vpc 底层路由能力，不需要在节点上配置 vxlan 等 overlay 设备，就可实现容器网络 和 vpc 网络的互访，并且相比于 calico/flannel 等网络方案，没有额外的解封包，性能也会更好。 4.4.1 VPC-CNI 模式 TKE 基于 CNI 和 VPC 弹性网卡实现的容器网络能力，适用于 Pod 固定 IP，CLB 直通 Pod，Pod 直绑 EIP 等场景。该网络模式下，容器与节点分布在同一网络平面，容器 IP 为 IPAMD 组件所分配的弹性网卡 IP。 4.4.3 VPC-CNI-**独立网卡** 依托于弹性网卡，将绑定到节点的弹性网卡通过 CNI 配置到容器网络命名空间，实现容器直接独享使用弹性网卡。 4.5 其他CNI插件 参考链接 https://kubernetes.io/zh/docs/concepts/cluster-administration/networking/ 5 总结 本文主要介绍了Kubernetes的网络实现，包括pod的通信，服务（service），Ingress的实现，也简要介绍了云厂商的CNI插件的实现方法。Kubernetes还有其他优秀的网络插件，各个插件的实现方式有所不同，不过Kubernetes网络模型是不变。 最后欢迎大家留言沟通交流。 6 参考文献Kubernetes集群网络系统 https://kubernetes.io/zh/docs/concepts/cluster-administration/networking/ Amazon EKS https://docs.amazonaws.cn/eks/latest/userguide/external-snat.html Amazon VPC CNI https://aws.amazon.com/cn/blogs/china/use-amazon-vpc-cni-build-default-net-kubernetes-groups/ Google Kubernetes Engine (GKE) https://cloud.google.com/kubernetes-engine/docs/concepts/network-overview kubernetes网络和CNI简介 https://www.jianshu.com/p/88062fa25083 Understanding kubernetes networking: pods https://medium.com/google-cloud/understanding-kubernetes-networking-pods-7117dd28727 containernetworking/cni https://github.com/containernetworking/cni Amazon Elastic Container Service https://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html CNI - Container Network Interface（容器网络接口） https://jimmysong.io/kubernetes-handbook/concepts/cni.html containernetworking/cni https://github.com/containernetworking/cni","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://zhangyu.info/categories/Kubernetes/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://zhangyu.info/tags/Kubernetes/"}]},{"title":"Kubernetes Ingress 控制器的技术选型技巧","slug":"Technical-selection-of-Kubernetes-Ingress-controller","date":"2021-04-07T16:00:00.000Z","updated":"2021-04-08T08:56:51.700Z","comments":true,"path":"2021/04/08/Technical-selection-of-Kubernetes-Ingress-controller/","link":"","permalink":"http://zhangyu.info/2021/04/08/Technical-selection-of-Kubernetes-Ingress-controller/","excerpt":"","text":"Kubernetes Ingress 控制器的技术选型技巧 作者：厉辉，腾讯云中间件API网关核心研发成员 在 Kubernetes 的实践、部署中，为了解决 Pod 迁移、Node Pod 端口、域名动态分配等问题，需要开发人员选择合适的 Ingress 解决方案。面对市场上众多Ingress产品，开发者该如何分辨它们的优缺点？又该如何结合自身的技术栈选择合适的技术方案呢？在本文中，腾讯云中间件核心研发工程师厉辉将为你介绍如何进行 Kubernates Ingress 控制器的技术选型。 名词解释 阅读本文需要熟悉以下基本概念： 集群：是指容器运行所需云资源的集合，包含了若干台云服务器、负载均衡器等云资源。 实例（Pod）：由相关的一个或多个容器构成一个实例，这些容器共享相同的存储和网络空间。 工作负载（Node）：Kubernetes 资源对象，用于管理 Pod 副本的创建、调度以及整个生命周期的自动控制。 服务（Service）：由多个相同配置的实例（Pod）和访问这些实例（Pod）的规则组成的微服务。 Ingress：Ingress 是用于将外部 HTTP（S）流量路由到服务（Service）的规则集合。 Kubernetes 访问现状 Kubernetes 的外部访问方式 在 Kubernetes 中，服务跟 Pod IP 主要供服务在集群内访问使用，对于集群外的应用是不可见的。怎么解决这个问题呢？为了让外部的应用能够访问 Kubernetes 集群中的服务，通常解决办法是 NodePort 和 LoadBalancer。 这两种方案其实各自都存在一些缺点： NodePort 的缺点是一个端口只能挂载一个 Service，而且为了更高的可用性，需要额外搭建一个负载均衡。 LoadBalancer 的缺点则是每个服务都必须要有一个自己的 IP，不论是内网 IP 或者外网 IP。更多情况下，为了保证 LoadBalancer 的能力，一般需要依赖于云服务商。 在Kubernetes的实践、部署中，为了解决像 Pod 迁移、Node Pod 端口、域名动态分配，或者是 Pod 后台地址动态更新这种问题，就产生了 Ingress 解决方案 Nginx Ingress 的缺点 Ingress 是Kubernetes中非常重要的外网流量入口。在Kubernetes中所推荐的默认值为Nginx Ingress，为了与后面Nginx 提供的商业版 Ingress 区分开来，我就称它为Kubernetes Ingress。 Kubernetes Ingress，顾名思义基于 Nginx 的平台，Nginx 现在是世界上最流行的 Nginx HTTP Sever，相信大家都对 Nginx 也比较熟悉，这是一个优点。它还有一个优点是 Nginx Ingress 接入 Kubernetes 集群所需的配置非常少，而且有很多文档来指引你如何使用它。这对于大部分刚接触 Kubernetes 的人或者创业公司来说，Nginx Ingress 的确是一个非常好的选择。 但是当 Nginx Ingress 在一些大环境上使用时，就会出现很多问题： 第一个问题：Nginx Ingress用了一些 OpenResty 的特性，但最终配置加载还是依赖于原有的 Nginx config reload。当路由配置非常大时，Nginx reload 会耗时很久，时间长达几秒甚至十几秒，这样就会严重影响业务，甚至造成业务中断。 第二个问题：Nginx Ingress 的插件开发非常困难。如果你认为 Nginx Ingress 本身插件不够用，需要使用一些定制化插件，这个额外的开发任务对程序员来说是十分痛苦的。因为Nginx Ingress自身的插件能力和可扩展性非常差。 Ingress 选型原则 既然发现了 Nginx Ingress 有很多问题，那是不是考虑选择其他开源的、更好用的 Ingress？市场上比 Kubernetes Ingress 好用的Ingress起码有十几家，那么如何从这么多 Ingress 中选择适合自己的呢？ Ingress 自身是基于 HTTP 网关的，市面上 HTTP 网关主要有这么几种：Nginx、Golang 原生的网关，以及新崛起的 Envoy 。但是每个开发人员所擅长的技术栈不同，所以适合的 Ingress 也会不一样。 那么问题来了，我们如何选择一个更加好用的 Ingress 呢？或者缩小点范围，熟悉 Nginx 或 OpenResty 的开发人员，应该选择哪一个 Ingress 呢？ 下面来介绍一下我对 Ingress 控制器选型的一些经验。 选型原则 1.基本特点 首先我认为Ingress 控制器应该具备以下基本功能，如果连这些功能都没有，那完全可以直接pass。 必须开源的，不开源的无法使用。 Kubernetes 中Pod 变化非常频繁，服务发现非常重要。 现在 HTTPS 已经很普及了，TLS 或者 SSL 的能力也非常重要，比如证书管理的功能。 支持 WebSocket 等常见协议，在某些情况下，可能还需要支持 HTTP2 、QUIC 等协议。 2.基础软件前面有提到，每个人擅长的技术平台不一样，所以选择自己更加熟悉的 HTTP 网关也显得至关重要。比如 Nginx、HAProxy、Envoy 或者是 Golang 原生网关。因为你熟悉它的原理，在使用中可以实现快速落地。 在生产环境上，高性能是一个很重要的特性，但比之更重要的是高可用。这意味着你选择的网关，它的可用性、稳定性一定要非常强，只有这样，服务才能稳定。 3.功能需求抛开上述两点，就是公司业务对网关的特殊需求。你选择一个开源产品，最好肯定是开箱能用的。比如你需要 GRPC 协议转换的能力，那当然希望选的网关具备这样的功能。这里简单列一下影响选择的因素： 协议：是否支持 HTTP2、HTTP3； 负载均衡算法：最基本的WRR、一致性哈希负载均衡算法是否能够满足需求，还是需要更加复杂的类似EWMA负载均衡算法。 鉴权限流：仅需要简单的鉴权，或更进阶的鉴权方式。又或者需要集成，能够快速的开发出像腾讯云 IM 的鉴权功能。Kubernetes Ingress除了前面我们提到的存在Nginx reload 耗时长、插件扩展能力差的问题，另外它还存在后端节点调整权重的能力不够灵活的问题。 选择 APISIX 相比Kubernetes Ingress，我个人更推荐 APISIX 作为Ingress ?controller。虽然它在功能上比 Kong 会少很多，但是 APISIX 很好的路由能力、灵活的插件能力，以及本身的高性能，能够弥补在 Ingress 选型上的一些缺点。对于基于 Nginx 或 Openresty 开发的程序员，如果对现在的 Ingress 不满意，我推荐你们去使用 APISIX 作为 Ingress。 如何将 APISIX 作为 Ingress 呢？我们首先要做出一个区分，Ingress 是 Kubernetes 名称的定义或者规则定义，Ingress controller 是将 Kubernetes 集群状态同步到网关的一个组件。但 APISIX 本身只是 API 网关，怎么把 APISIX 实现成 Ingress controller 呢？我们先来简要了解一下如何实现 Ingress。 实现 Ingress，本质上就只有两部分内容： 第一部分：需要将 Kubernetes 集群中的配置、或 Kubernetes 集群中的状态同步到 APISIX 集群。 第二部分：需要将 APISIX中 的一些概念，比如像服务、upstream 等概念定义为 Kubernetes 中的 CRD。 如果实现了第二部分，通过 Kubernetes Ingress 的配置，便可以很快的产生 APISIX。通过 APISIX Ingress controller 就可以产生 APISIX 相关的配置。当前为了快速的将 APISIX 落地为能够支持 Kubernetes 的 Ingress ，我们创建了一个开源项目，叫 Ingress Controller。 ingress controller 架构图 上图为Ingress controller 项目的整体架构图。左边部分为 Kubernetes 集群，这里可以导入一些 yaml 文件，对 Kubernetes 的配置进行变更。右边部分则是 APISIX 集群，以及它的控制面和数据面。从架构图中可以看出，APISIX Ingress 充当了 Kubernetes 集群以及 APISIX 集群之间的连接者。它主要负责监听 Kubernetes 集群中节点的变化，将集群中的状态同步到 APISIX 集群。另外，由于Kubernetes 倡导所有组件都要具备高可用的特性，所以在 APISIX Ingress 设计之初，我们通过双节点或多节点的模式来保证 APISIX ?Ingress Controller 的保障高可用。 总结 各类 Ingress 横向对比 相对于市面上流行的 Ingress 控制器，我们简单对比来看看 APISIX ingress 有什么优缺点。上图是外国开发人员针对 Kubernetes Ingress 选型做的一张表格。我在原来表格的基础上，结合自己的理解，将 APISIX Ingress 的功能加入了进来。我们可以看到，最左边的是APISIX，后边就是 Kubernetes Ingress 和 Kong Ingress，后面的 Traefik，就是基于 Golang 的 Ingress。HAproxy 是比较常见的，过去是比较流行的负载均衡器。Istio 和 Ambassador 是国外非常流行的两个Ingress。 接下来我们总结下这些 Ingress各自的优缺点： APISIX Ingress：APISIX Ingress 的优点前面也提到了，它具有非常强大的路由能力、灵活的插件拓展能力，在性能上表现也非常优秀。同时，它的缺点也非常明显，尽管APISIX开源后有非常多的功能，但是缺少落地案例，没有相关的文档指引大家如何使用这些功能。 Kubernetes Ingress：即 Kubernetes 推荐默认使用的 Nginx Ingress。它的主要优点为简单、易接入。缺点是Nginx reload耗时长的问题根本无法解决。另外，虽然可用插件很多，但插件扩展能力非常弱。 Nginx Ingress：主要优点是在于它完全支持 TCP 和 UDP 协议，但是缺失了鉴权方式、流量调度等其他功能。 Kong：其本身就是一个 API 网关，它也算是开创了先河，将 API 网关引入到 Kubernetes 中当 Ingress。另外相对边缘网关，Kong 在鉴权、限流、灰度部署等方面做得非常好。Kong Ingress 还有一个很大的优点：提供了一些 API、服务的定义，可以抽象成 Kubernetes 的 CRD，通过K8S Ingress 配置便可完成同步状态至 Kong 集群。缺点就是部署特别困难，另外在高可用方面，与 APISIX 相比也是相形见绌。 Traefik ：基于 Golang 的 Ingress，它本身是一个微服务网关，在 Ingress 的场景应用比较多。他的主要平台基于 Golang，自身支持的协议也非常多，总体来说是没有什么缺点。如果大家熟悉 Golang 的话，也推荐一用。 HAproxy：是一个久负盛名的负载均衡器。它主要优点是具有非常强大的负载均衡能力，其他方面并不占优势。 Istio Ingress 和 Ambassador Ingress 都是基于非常流行的 Envoy。说实话，我认为这两个 Ingress 没有什么缺点，可能唯一的缺点是他们基于 Envoy 平台，大家对这个平台都不是很熟悉，上手门槛会比较高。 综上所述，大家在了解了各个 Ingress 的优劣势后，可以结合自身情况快速选择适合自己的 Ingress。 来自 “ ITPUB博客 ” ，链接：http://blog.itpub.net/31559354/viewspace-2677027/","categories":[{"name":"Ingress","slug":"Ingress","permalink":"http://zhangyu.info/categories/Ingress/"}],"tags":[{"name":"Ingress","slug":"Ingress","permalink":"http://zhangyu.info/tags/Ingress/"}]},{"title":"Kubernetes入门-进阶实战","slug":"Kubernetes-remen","date":"2021-04-07T16:00:00.000Z","updated":"2021-04-08T09:59:59.264Z","comments":true,"path":"2021/04/08/Kubernetes-remen/","link":"","permalink":"http://zhangyu.info/2021/04/08/Kubernetes-remen/","excerpt":"","text":"Kubernetes 入门&amp;进阶实战 作者：oonamao毛江云，腾讯 CSIG 应用开发工程师 本文组织方式： 1.?K8S?是什么，即作用和目的。涉及?K8S?架构的整理，Master?和?Node?之间的关系，以及?K8S?几个重要的组件：API?Server、Scheduler、Controller、etcd?等。2.?K8S?的重要概念，即?K8S?的?API?对象，也就是常常听到的?Pod、Deployment、Service?等。3.?如何配置?kubectl，介绍kubectl工具和配置办法。4.?如何用kubectl?部署服务。5.?如何用kubectl?查看、更新/编辑、删除服务。6.?如何用kubectl?排查部署在K8S集群上的服务出现的问题 I. K8S 概览1.1 K8S 是什么？K8S 是Kubernetes的全称，官方称其是： Kubernetes is an open source system for managing containerized applications across multiple hosts. It provides basic mechanisms for deployment, maintenance, and scaling of applications. 用于自动部署、扩展和管理“容器化（containerized）应用程序”的开源系统。 翻译成大白话就是：“K8 是 S 负责自动化运维管理多个 Docker 程序的集群”。那么问题来了：Docker 运行可方便了，为什么要用 K8S，它有什么优势？ 插一句题外话： 为什么 Kubernetes 要叫 Kubernetes 呢？维基百科已经交代了（老美对星际是真的痴迷）： Kubernetes（在希腊语意为“舵手”或“驾驶员”）由 Joe Beda、Brendan Burns 和 Craig McLuckie 创立，并由其他谷歌工程师，包括 Brian Grant 和 Tim Hockin 等进行加盟创作，并由谷歌在 2014 年首次对外宣布 。该系统的开发和设计都深受谷歌的 Borg 系统的影响，其许多顶级贡献者之前也是 Borg 系统的开发者。在谷歌内部，Kubernetes 的原始代号曾经是Seven，即星际迷航中的 Borg（博格人）。Kubernetes 标识中舵轮有七个轮辐就是对该项目代号的致意。 为什么 Kubernetes 的缩写是 K8S 呢？我个人赞同Why Kubernetes is Abbreviated k8s中说的观点“嘛，写全称也太累了吧，不如整个缩写”。其实只保留首位字符，用具体数字来替代省略的字符个数的做法，还是比较常见的。 1.2 为什么是 K8S?试想下传统的后端部署办法：把程序包（包括可执行二进制文件、配置文件等）放到服务器上，接着运行启动脚本把程序跑起来，同时启动守护脚本定期检查程序运行状态、必要的话重新拉起程序。 有问题吗？显然有！最大的一个问题在于：**如果服务的请求量上来，已部署的服务响应不过来怎么办？**传统的做法往往是，如果请求量、内存、CPU 超过阈值做了告警，运维马上再加几台服务器，部署好服务之后，接入负载均衡来分担已有服务的压力。 问题出现了：从监控告警到部署服务，中间需要人力介入！那么，有没有办法自动完成服务的部署、更新、卸载和扩容、缩容呢？ 这，就是 K8S 要做的事情：自动化运维管理 Docker（容器化）程序。 1.3 K8S 怎么做？我们已经知道了 K8S 的核心功能：自动化运维管理多个容器化程序。那么 K8S 怎么做到的呢？这里，我们从宏观架构上来学习 K8S 的设计思想。首先看下图，图片来自文章Components of Kubernetes Architecture： K8S 是属于主从设备模型（Master-Slave 架构），即有 Master 节点负责核心的调度、管理和运维，Slave 节点则在执行用户的程序。但是在 K8S 中，主节点一般被称为Master Node 或者 Head Node（本文采用 Master Node 称呼方式），而从节点则被称为Worker Node 或者 Node（本文采用 Worker Node 称呼方式）。 要注意一点：Master Node 和 Worker Node 是分别安装了 K8S 的 Master 和 Woker 组件的实体服务器，每个 Node 都对应了一台实体服务器（虽然 Master Node 可以和其中一个 Worker Node 安装在同一台服务器，但是建议 Master Node 单独部署），所有 Master Node 和 Worker Node 组成了 K8S 集群，同一个集群可能存在多个 Master Node 和 Worker Node。 首先来看Master Node都有哪些组件： API Server。K8S 的请求入口服务。API Server 负责接收 K8S 所有请求（来自 UI 界面或者 CLI 命令行工具），然后，API Server 根据用户的具体请求，去通知其他组件干活。 Scheduler。K8S 所有 Worker Node 的调度器。当用户要部署服务时，Scheduler 会选择最合适的 Worker Node（服务器）来部署。 Controller Manager。K8S 所有 Worker Node 的监控器。Controller Manager 有很多具体的 Controller，在文章Components of Kubernetes Architecture中提到的有 Node Controller、Service Controller、Volume Controller 等。Controller 负责监控和调整在 Worker Node 上部署的服务的状态，比如用户要求 A 服务部署 2 个副本，那么当其中一个服务挂了的时候，Controller 会马上调整，让 Scheduler 再选择一个 Worker Node 重新部署服务。 etcd。K8S 的存储服务。etcd 存储了 K8S 的关键配置和用户配置，K8S 中仅 API Server 才具备读写权限，其他组件必须通过 API Server 的接口才能读写数据（见Kubernetes Works Like an Operating System）。 接着来看Worker Node的组件，笔者更赞同HOW DO APPLICATIONS RUN ON KUBERNETES文章中提到的组件介绍： Kubelet。Worker Node 的监视器，以及与 Master Node 的通讯器。Kubelet 是 Master Node 安插在 Worker Node 上的“眼线”，它会定期向 Worker Node 汇报自己 Node 上运行的服务的状态，并接受来自 Master Node 的指示采取调整措施。 Kube-Proxy。K8S 的网络代理。私以为称呼为 Network-Proxy 可能更适合？Kube-Proxy 负责 Node 在 K8S 的网络通讯、以及对外部网络流量的负载均衡。 Container Runtime。Worker Node 的运行环境。即安装了容器化所需的软件环境确保容器化程序能够跑起来，比如 Docker Engine。大白话就是帮忙装好了 Docker 运行环境。 Logging Layer。K8S 的监控状态收集器。私以为称呼为 Monitor 可能更合适？Logging Layer 负责采集 Node 上所有服务的 CPU、内存、磁盘、网络等监控项信息。 Add-Ons。K8S 管理运维 Worker Node 的插件组件。有些文章认为 Worker Node 只有三大组件，不包含 Add-On，但笔者认为 K8S 系统提供了 Add-On 机制，让用户可以扩展更多定制化功能，是很不错的亮点。 总结来看，K8S 的 Master Node 具备：请求入口管理（API Server），Worker Node 调度（Scheduler），监控和自动调节（Controller Manager），以及存储功能（etcd）；而 K8S 的 Worker Node 具备：状态和监控收集（Kubelet），网络和负载均衡（Kube-Proxy）、保障容器化运行环境（Container Runtime）、以及定制化功能（Add-Ons）。 到这里，相信你已经对 K8S 究竟是做什么的，有了大概认识。接下来，再来认识下 K8S 的 Deployment、Pod、Replica Set、Service 等，但凡谈到 K8S，就绕不开这些名词，而这些名词也是最让 K8S 新手们感到头疼、困惑的。 II. K8S 重要概念2.1 Pod 实例官方对于Pod的解释是： Pod是可以在 Kubernetes 中创建和管理的、最小的可部署的计算单元。 这样的解释还是很难让人明白究竟 Pod 是什么，但是对于 K8S 而言，Pod 可以说是所有对象中最重要的概念了！因此，我们必须首先清楚地知道“Pod 是什么”，再去了解其他的对象。 从官方给出的定义，联想下“最小的 xxx 单元”，是不是可以想到本科在学校里学习“进程”的时候，教科书上有一段类似的描述：资源分配的最小单位；还有”线程“的描述是：CPU 调度的最小单位。什么意思呢？”最小 xx 单位“要么就是事物的衡量标准单位，要么就是资源的闭包、集合。前者比如长度米、时间秒；后者比如一个”进程“是存储和计算的闭包，一个”线程“是 CPU 资源（包括寄存器、ALU 等）的闭包。 同样的，Pod 就是 K8S 中一个服务的闭包。这么说的好像还是有点玄乎，更加云里雾里了。简单来说，Pod 可以被理解成一群可以共享网络、存储和计算资源的容器化服务的集合。再打个形象的比喻，在同一个 Pod 里的几个 Docker 服务/程序，好像被部署在同一台机器上，可以通过 localhost 互相访问，并且可以共用 Pod 里的存储资源（这里是指 Docker 可以挂载 Pod 内的数据卷，数据卷的概念，后文会详细讲述，暂时理解为“需要手动 mount 的磁盘”）。笔者总结 Pod 如下图，可以看到：同一个 Pod 之间的 Container 可以通过 localhost 互相访问，并且可以挂载 Pod 内所有的数据卷；但是不同的 Pod 之间的 Container 不能用 localhost 访问，也不能挂载其他 Pod 的数据卷。 对 Pod 有直观的认识之后，接着来看 K8S 中 Pod 究竟长什么样子，具体包括哪些资源？ K8S 中所有的对象都通过 yaml 来表示，笔者从官方网站摘录了一个最简单的 Pod 的 yaml： apiVersion:?v1 kind:?Pod metadata: ??name:?memory-demo ??namespace:?mem-example spec: ??containers: ??-?name:?memory-demo-ctr ????image:?polinux/stress ????resources: ??????limits: ????????memory:?&quot;200Mi&quot; ??????requests: ????????memory:?&quot;100Mi&quot; ????command:?[&quot;stress&quot;] ????args:?[&quot;--vm&quot;,?&quot;1&quot;,?&quot;--vm-bytes&quot;,?&quot;150M&quot;,?&quot;--vm-hang&quot;,?&quot;1&quot;] ????volumeMounts: ????-?name:?redis-storage ??????mountPath:?/data/redis ??volumes: ??-?name:?redis-storage ????emptyDir:?&#123;&#125; 看不懂不必慌张，且耐心听下面的解释： apiVersion记录 K8S 的 API Server 版本，现在看到的都是v1，用户不用管。 kind记录该 yaml 的对象，比如这是一份 Pod 的 yaml 配置文件，那么值内容就是Pod。 metadata记录了 Pod 自身的元数据，比如这个 Pod 的名字、这个 Pod 属于哪个 namespace（命名空间的概念，后文会详述，暂时理解为“同一个命名空间内的对象互相可见”）。 spec记录了 Pod 内部所有的资源的详细信息，看懂这个很重要： containers记录了 Pod 内的容器信息，containers包括了：name容器名，image容器的镜像地址，resources容器需要的 CPU、内存、GPU 等资源，command容器的入口命令，args容器的入口参数，volumeMounts容器要挂载的 Pod 数据卷等。可以看到，上述这些信息都是启动容器的必要和必需的信息。 volumes记录了 Pod 内的数据卷信息，后文会详细介绍 Pod 的数据卷。 2.2 Volume 数据卷 K8S 支持很多类型的 volume 数据卷挂载，具体请参见K8S 卷。前文就“如何理解 volume”提到：“需要手动 mount 的磁盘”，此外，有一点可以帮助理解：数据卷 volume 是 Pod 内部的磁盘资源。 其实，单单就 Volume 来说，不难理解。但是上面还看到了volumeMounts，这俩是什么关系呢？ volume 是 K8S 的对象，对应一个实体的数据卷；而 volumeMounts 只是 container 的挂载点，对应 container 的其中一个参数。但是，volumeMounts 依赖于 volume，只有当 Pod 内有 volume 资源的时候，该 Pod 内部的 container 才可能有 volumeMounts。 2.3 Container 容器本文中提到的镜像 Image、容器 Container，都指代了 Pod 下的一个container。关于 K8S 中的容器，在 2.1Pod 章节都已经交代了，这里无非再啰嗦一句：一个 Pod 内可以有多个容器 container。 在 Pod 中，容器也有分类，对这个感兴趣的同学欢迎自行阅读更多资料： 标准容器 Application Container。 初始化容器 Init Container。 边车容器 Sidecar Container。 临时容器 Ephemeral Container。 一般来说，我们部署的大多是标准容器（ Application Container）。 2.4 Deployment 和 ReplicaSet（简称 RS）除了 Pod 之外，K8S 中最常听到的另一个对象就是 Deployment 了。那么，什么是 Deployment 呢？官方给出了一个要命的解释： 一个 Deployment 控制器为 Pods 和 ReplicaSets 提供声明式的更新能力。 你负责描述 Deployment 中的 _目标状态_，而 Deployment 控制器以受控速率更改实际状态， 使其变为期望状态。你可以定义 Deployment 以创建新的 ReplicaSet，或删除现有 Deployment，并通过新的 Deployment 收养其资源。 翻译一下：Deployment 的作用是管理和控制 Pod 和 ReplicaSet，管控它们运行在用户期望的状态中。哎，打个形象的比喻，** Deployment 就是包工头 **，主要负责监督底下的工人 Pod 干活，确保每时每刻有用户要求数量的 Pod 在工作。如果一旦发现某个工人 Pod 不行了，就赶紧新拉一个 Pod 过来替换它。 新的问题又来了：那什么是 ReplicaSets 呢？ ReplicaSet 的目的是维护一组在任何时候都处于运行状态的 Pod 副本的稳定集合。因此，它通常用来保证给定数量的、完全相同的 Pod 的可用性。 再来翻译下：ReplicaSet 的作用就是管理和控制 Pod，管控他们好好干活。但是，ReplicaSet 受控于 Deployment。形象来说，ReplicaSet 就是总包工头手下的小包工头。 笔者总结得到下面这幅图，希望能帮助理解： 新的问题又来了：如果都是为了管控 Pod 好好干活，为什么要设置 Deployment 和 ReplicaSet 两个层级呢，直接让 Deployment 来管理不可以吗？ 回答：不清楚，但是私以为是因为先有 ReplicaSet，但是使用中发现 ReplicaSet 不够满足要求，于是又整了一个 Deployment（有清楚 Deployment 和 ReplicaSet 联系和区别的小伙伴欢迎留言啊）。 但是，从 K8S 使用者角度来看，用户会直接操作 Deployment 部署服务，而当 Deployment 被部署的时候，K8S 会自动生成要求的 ReplicaSet 和 Pod。在K8S 官方文档中也指出用户只需要关心 Deployment 而不操心 ReplicaSet： This actually means that you may never need to manipulate ReplicaSet objects: use a Deployment instead, and define your application in the spec section. 这实际上意味着您可能永远不需要操作 ReplicaSet 对象：直接使用 Deployments 并在规范部分定义应用程序。 补充说明：在 K8S 中还有一个对象 — ReplicationController（简称 RC），官方文档对它的定义是： ReplicationController 确保在任何时候都有特定数量的 Pod 副本处于运行状态。换句话说，ReplicationController 确保一个 Pod 或一组同类的 Pod 总是可用的。 怎么样，和 ReplicaSet 是不是很相近？在Deployments, ReplicaSets, and pods教程中说“ReplicationController 是 ReplicaSet 的前身”，官方也推荐用 Deployment 取代 ReplicationController 来部署服务。 2.5 Service 和 Ingress吐槽下 K8S 的概念/对象/资源是真的多啊！前文介绍的 Deployment、ReplicationController 和 ReplicaSet 主要管控 Pod 程序服务；那么，Service 和 Ingress 则负责管控 Pod 网络服务。 我们先来看看官方文档中 Service 的定义： 将运行在一组 Pods 上的应用程序公开为网络服务的抽象方法。 使用 Kubernetes，您无需修改应用程序即可使用不熟悉的服务发现机制。Kubernetes 为 Pods 提供自己的 IP 地址，并为一组 Pod 提供相同的 DNS 名， 并且可以在它们之间进行负载均衡。 翻译下：K8S 中的服务（Service）并不是我们常说的“服务”的含义，而更像是网关层，是若干个 Pod 的流量入口、流量均衡器。 那么，为什么要 Service 呢？ 私以为在这一点上，官方文档讲解地非常清楚： Kubernetes Pod 是有生命周期的。它们可以被创建，而且销毁之后不会再启动。如果您使用 Deployment 来运行您的应用程序，则它可以动态创建和销毁 Pod。 每个 Pod 都有自己的 IP 地址，但是在 Deployment 中，在同一时刻运行的 Pod 集合可能与稍后运行该应用程序的 Pod 集合不同。 这导致了一个问题：如果一组 Pod（称为“后端”）为群集内的其他 Pod（称为“前端”）提供功能， 那么前端如何找出并跟踪要连接的 IP 地址，以便前端可以使用工作量的后端部分？ 补充说明：K8S 集群的网络管理和拓扑也有特别的设计，以后会专门出一章节来详细介绍 K8S 中的网络。这里需要清楚一点：K8S 集群内的每一个 Pod 都有自己的 IP（是不是很类似一个 Pod 就是一台服务器，然而事实上是多个 Pod 存在于一台服务器上，只不过是 K8S 做了网络隔离），在 K8S 集群内部还有 DNS 等网络服务（一个 K8S 集群就如同管理了多区域的服务器，可以做复杂的网络拓扑）。 此外，笔者推荐k8s 外网如何访问业务应用对于 Service 的介绍，不过对于新手而言，推荐阅读前半部分对于 service 的介绍即可，后半部分就太复杂了。我这里做了简单的总结： Service 是 K8S 服务的核心，屏蔽了服务细节，统一对外暴露服务接口，真正做到了“微服务”。举个例子，我们的一个服务 A，部署了 3 个备份，也就是 3 个 Pod；对于用户来说，只需要关注一个 Service 的入口就可以，而不需要操心究竟应该请求哪一个 Pod。优势非常明显：一方面外部用户不需要感知因为 Pod 上服务的意外崩溃、K8S 重新拉起 Pod 而造成的 IP 变更，外部用户也不需要感知因升级、变更服务带来的 Pod 替换而造成的 IP 变化，另一方面，Service 还可以做流量负载均衡。 但是，Service 主要负责 K8S 集群内部的网络拓扑。那么集群外部怎么访问集群内部呢？这个时候就需要 Ingress 了，官方文档中的解释是： Ingress 是对集群中服务的外部访问进行管理的 API 对象，典型的访问方式是 HTTP。 Ingress 可以提供负载均衡、SSL 终结和基于名称的虚拟托管。 翻译一下：Ingress 是整个 K8S 集群的接入层，复杂集群内外通讯。 最后，笔者把 Ingress 和 Service 的关系绘制网络拓扑关系图如下，希望对理解这两个概念有所帮助： 2.6 namespace 命名空间和前文介绍的所有的概念都不一样，namespace 跟 Pod 没有直接关系，而是 K8S 另一个维度的对象。或者说，前文提到的概念都是为了服务 Pod 的，而 namespace 则是为了服务整个 K8S 集群的。 那么，namespace 是什么呢？ 上官方文档定义： Kubernetes 支持多个虚拟集群，它们底层依赖于同一个物理集群。这些虚拟集群被称为名字空间。 翻译一下：namespace 是为了把一个 K8S 集群划分为若干个资源不可共享的虚拟集群而诞生的。 也就是说，可以通过在 K8S 集群内创建 namespace 来分隔资源和对象。比如我有 2 个业务 A 和 B，那么我可以创建 ns-a 和 ns-b 分别部署业务 A 和 B 的服务，如在 ns-a 中部署了一个 deployment，名字是 hello，返回用户的是“hello a”；在 ns-b 中也部署了一个 deployment，名字恰巧也是 hello，返回用户的是“hello b”（要知道，在同一个 namespace 下 deployment 不能同名；但是不同 namespace 之间没有影响）。前文提到的所有对象，都是在 namespace 下的；当然，也有一些对象是不隶属于 namespace 的，而是在 K8S 集群内全局可见的，官方文档提到的可以通过命令来查看，具体命令的使用办法，笔者会出后续的实战文章来介绍，先贴下命令： `#?位于名字空间中的资源kubectl?api-resources?–namespaced=true #?不在名字空间中的资源kubectl?api-resources?–namespaced=false` 不在 namespace 下的对象有： 在 namespace 下的对象有（部分）： 2.7 其他K8S 的对象实在太多了，2.1-2.6 介绍的是在实际使用 K8S 部署服务最常见的。其他的还有 Job、CronJob 等等，在对 K8S 有了比较清楚的认知之后，再去学习更多的 K8S 对象，不是难事。 III. 配置 kubectl3.1 什么是 kubectl？官方文档中介绍 kubectl 是： Kubectl 是一个命令行接口，用于对 Kubernetes 集群运行命令。Kubectl 的配置文件在$HOME/.kube 目录。我们可以通过设置 KUBECONFIG 环境变量或设置命令参数–kubeconfig 来指定其他位置的 kubeconfig 文件。 也就是说，可以通过 kubectl 来操作 K8S 集群，基本语法： 使用以下语法 kubectl 从终端窗口运行命令： kubectl?[command]?[TYPE]?[NAME]?[flags] 其中 command、TYPE、NAME 和 flags 分别是： command：指定要对一个或多个资源执行的操作，例如 create、get、describe、delete。 TYPE：指定资源类型。资源类型不区分大小写，可以指定单数、复数或缩写形式。例如，以下命令输出相同的结果: ```shell kubectl?get?pod?pod1 kubectl?get?pods?pod1 kubectl?get?po?pod1 ``-?NAME：指定资源的名称。名称区分大小写。如果省略名称，则显示所有资源的详细信息?kubectl get pods。 在对多个资源执行操作时，您可以按类型和名称指定每个资源，或指定一个或多个文件： -?要按类型和名称指定资源：??-?要对所有类型相同的资源进行分组，请执行以下操作：TYPE1 name1 name2 name&lt;#&gt;。?例子：kubectl get pod example-pod1 example-pod2??-?分别指定多个资源类型：TYPE1/name1 TYPE1/name2 TYPE2/name3 TYPE&lt;#&gt;/name&lt;#&gt;。?例子：kubectl get pod/example-pod1 replicationcontroller/example-rc1-?用一个或多个文件指定资源：-f file1 -f file2 -f file&lt;#&gt;??-?使用?YAML?而不是?JSON?因为 YAML 更容易使用，特别是用于配置文件时。?例子：kubectl get -f ./pod.yaml-?flags:?指定可选的参数。例如，可以使用?-s?或?-server?参数指定 Kubernetes API 服务器的地址和端口。`` 就如何使用 kubectl 而言，官方文档已经说得非常清楚。不过对于新手而言，还是需要解释几句： kubectl 是 K8S 的命令行工具，并不需要 kubectl 安装在 K8S 集群的任何 Node 上，但是，需要确保安装 kubectl 的机器和 K8S 的集群能够进行网络互通。 kubectl 是通过本地的配置文件来连接到 K8S 集群的，默认保存在$HOME/.kube 目录下；也可以通过 KUBECONFIG 环境变量或设置命令参数–kubeconfig 来指定其他位置的 kubeconfig 文件【官方文档】。 接下来，一起看看怎么使用 kubectl 吧，切身感受下 kubectl 的使用。 请注意，如何安装 kubectl 的办法有许多非常明确的教程，比如《安装并配置 kubectl》，本文不再赘述。 1.2 怎么配置 kubectl？第一步，必须准备好要连接/使用的 K8S 的配置文件，笔者给出一份杜撰的配置： apiVersion:?v1 clusters: -?cluster: ????certificate-authority-data:?thisisfakecertifcateauthoritydata00000000000 ????server:? ??name:?cls-dev contexts: -?context: ????cluster:?cls-dev ????user:?kubernetes-admin ??name:?kubernetes-admin@test current-context:?kubernetes-admin@test kind:?Config preferences:?&#123;&#125; users: -?name:?kubernetes-admin ??user: ????token:?thisisfaketoken00000 解读如下： clusters记录了 clusters（一个或多个 K8S 集群）信息： name是这个 cluster（K8S 集群）的名称代号 server是这个 cluster（K8S 集群）的访问方式，一般为 IP+PORT certificate-authority-data是证书数据，只有当 cluster（K8S 集群）的连接方式是 https 时，为了安全起见需要证书数据 users记录了访问 cluster（K8S 集群）的账号信息： name是用户账号的名称代号 user/token是用户的 token 认证方式，token 不是用户认证的唯一方式，其他还有账号+密码等。 contexts是上下文信息，包括了 cluster（K8S 集群）和访问 cluster（K8S 集群）的用户账号等信息： name是这个上下文的名称代号 cluster是 cluster（K8S 集群）的名称代号 user是访问 cluster（K8S 集群）的用户账号代号 current-context记录当前 kubectl 默认使用的上下文信息 kind和apiVersion都是固定值，用户不需要关心 preferences则是配置文件的其他设置信息，笔者没有使用过，暂时不提。 第二步，给 kubectl 配置上配置文件。 --kubeconfig参数。第一种办法是每次执行 kubectl 的时候，都带上--kubeconfig=$&#123;CONFIG_PATH&#125;。给一点温馨小提示：每次都带这么一长串的字符非常麻烦，可以用 alias 别名来简化码字量，比如alias k=kubectl --kubeconfig=$&#123;CONFIG_PATH&#125;。 KUBECONFIG环境变量。第二种做法是使用环境变量KUBECONFIG把所有配置文件都记录下来，即export KUBECONFIG=$KUBECONFIG:$&#123;CONFIG_PATH&#125;。接下来就可以放心执行 kubectl 命令了。 $HOME/.kube/config 配置文件。第三种做法是把配置文件的内容放到$HOME/.kube/config 内。具体做法为： 如果$HOME/.kube/config 不存在，那么cp $&#123;CONFIG_PATH&#125; $HOME/.kube/config即可； 如果如果 $HOME/.kube/config已经存在，那么需要把新的配置内容加到 $HOME/.kube/config 下。单单只是cat $&#123;CONFIG_PATH&#125; &gt;&gt; $HOME/.kube/config是不行的，正确的做法是：KUBECONFIG=$HOME/.kube/config:$&#123;CONFIG_PATH&#125; kubectl config view --flatten &gt; $HOME/.kube/config 。解释下这个命令的意思：先把所有的配置文件添加到环境变量KUBECONFIG中，然后执行kubectl config view --flatten打印出有效的配置文件内容，最后覆盖$HOME/.kube/config 即可。 请注意，上述操作的优先级分别是 1&gt;2&gt;3，也就是说，kubectl 会优先检查--kubeconfig，若无则检查KUBECONFIG，若无则最后检查$HOME/.kube/config，如果还是没有，报错。但凡某一步找到了有效的 cluster，就中断检查，去连接 K8S 集群了。 第三步：配置正确的上下文 按照第二步的做法，如果配置文件只有一个 cluster 是没有任何问题的，但是对于有多个 cluster 怎么办呢？到这里，有几个关于配置的必须掌握的命令： kubectl config get-contexts。列出所有上下文信息。 kubectl config current-context。查看当前的上下文信息。其实，命令 1 线束出来的*所指示的就是当前的上下文信息。 kubectl config use-context $&#123;CONTEXT_NAME&#125;。更改上下文信息。 kubectl config set-context $&#123;CONTEXT_NAME&#125;|--current --$&#123;KEY&#125;=$&#123;VALUE&#125;。修改上下文的元素。比如可以修改用户账号、集群信息、连接到 K8S 后所在的 namespace。 关于该命令，还有几点要啰嗦的： config set-context可以修改任何在配置文件中的上下文信息，只需要在命令中指定上下文名称就可以。而–current 则指代当前上下文。 上下文信息所包括的内容有：cluster 集群（名称）、用户账号（名称）、连接到 K8S 后所在的 namespace，因此有config set-context严格意义上的用法： kubectl config set-context [NAME|--current] [--cluster=cluster_nickname] [--user=user_nickname] [--namespace=namespace] [options] （备注：[options]可以通过 kubectl options 查看） 综上，如何操作 kubectl 配置都已交代。 IV. kubectl 部署服务K8S 核心功能就是部署运维容器化服务，因此最重要的就是如何又快又好地部署自己的服务了。本章会介绍如何部署 Pod 和 Deployment。 2.1 如何部署 Pod？通过 kubectl 部署 Pod 的办法分为两步：1). 准备 Pod 的 yaml 文件；2). 执行 kubectl 命令部署 第一步：准备 Pod 的 yaml 文件。关于 Pod 的 yaml 文件初步解释，本系列上一篇文章《K8S 系列一：概念入门》已经有了初步介绍，这里再复习下： apiVersion:?v1 kind:?Pod metadata: ??name:?memory-demo ??namespace:?mem-example spec: ??containers: ??-?name:?memory-demo-ctr ????image:?polinux/stress ????resources: ??????limits: ????????memory:?&quot;200Mi&quot; ??????requests: ????????memory:?&quot;100Mi&quot; ????command:?[&quot;stress&quot;] ????args:?[&quot;--vm&quot;,?&quot;1&quot;,?&quot;--vm-bytes&quot;,?&quot;150M&quot;,?&quot;--vm-hang&quot;,?&quot;1&quot;] ????volumeMounts: ????-?name:?redis-storage ??????mountPath:?/data/redis ??volumes: ??-?name:?redis-storage ????emptyDir:?&#123;&#125; 继续解读： metadata，对于新入门的同学来说，需要重点掌握的两个字段： name。这个 Pod 的名称，后面到 K8S 集群中查找 Pod 的关键字段。 namespace。命名空间，即该 Pod 隶属于哪个 namespace 下，关于 Pod 和 namespace 的关系，上一篇文章已经交代了。 spec记录了 Pod 内部所有的资源的详细信息，这里我们重点查看containers下的几个重要字段： name。Pod 下该容器名称，后面查找 Pod 下的容器的关键字段。 image。容器的镜像地址，K8S 会根据这个字段去拉取镜像。 resources。容器化服务涉及到的 CPU、内存、GPU 等资源要求。可以看到有limits和requests两个子项，那么这两者有什么区别吗，该怎么使用？在What’s the difference between Pod resources.limits and resources.requests in Kubernetes?回答了： limits是 K8S 为该容器至多分配的资源配额；而requests则是 K8S 为该容器至少分配的资源配额。打个比方，配置中要求了 memory 的requests为 100M，而此时如果 K8S 集群中所有的 Node 的可用内存都不足 100M，那么部署服务会失败；又如果有一个 Node 的内存有 16G 充裕，可以部署该 Pod，而在运行中，该容器服务发生了内存泄露，那么一旦超过 200M 就会因为 OOM 被 kill，尽管此时该机器上还有 15G+的内存。 command。容器的入口命令。对于这个笔者还存在很多困惑不解的地方，暂时挖个坑，有清楚的同学欢迎留言。 args。容器的入口参数。同上，有清楚的同学欢迎留言。 volumeMounts。容器要挂载的 Pod 数据卷等。请务必记住：Pod 的数据卷只有被容器挂载后才能使用！ 第二步：执行 kubectl 命令部署。有了 Pod 的 yaml 文件之后，就可以用 kubectl 部署了，命令非常简单：kubectl create -f $&#123;POD_YAML&#125;。 随后，会提示该命令是否执行成功，比如 yaml 内容不符合要求，则会提示哪一行有问题： 修正后，再次部署： 2.2 如何部署 Deployment？第一步：准备 Deployment 的 yaml 文件。首先来看 Deployment 的 yaml 文件内容： apiVersion:?extensions/v1beta1 ?kind:?Deployment ?metadata: ???name:?rss-site ???namespace:?mem-example ?spec: ???replicas:?2 ???template: ?????metadata: ???????labels: ?????????app:?web ?????spec: ??????containers: ???????-?name:?memory-demo-ctr ?????????image:?polinux/stress ?????????resources: ?????????limits: ???????????emory:?&quot;200Mi&quot; ?????????requests: ???????????memory:?&quot;100Mi&quot; ?????????command:?[&quot;stress&quot;] ?????????args:?[&quot;--vm&quot;,?&quot;1&quot;,?&quot;--vm-bytes&quot;,?&quot;150M&quot;,?&quot;--vm-hang&quot;,?&quot;1&quot;] ?????????volumeMounts: ?????????-?name:?redis-storage ???????????mountPath:?/data/redis ?????volumes: ?????-?name:?redis-storage ???????emptyDir:?&#123;&#125; 继续来看几个重要的字段： metadata同 Pod 的 yaml，这里提一点：如果没有指明 namespace，那么就是用 kubectl 默认的 namespace（如果 kubectl 配置文件中没有指明 namespace，那么就是 default 空间）。 spec，可以看到 Deployment 的spec字段是在 Pod 的spec内容外“包了一层”，那就来看 Deployment 有哪些需要注意的： metadata，新手同学先不管这边的信息。 spec，会发现这完完全全是上文提到的 Pod 的spec内容，在这里写明了 Deployment 下属管理的每个 Pod 的具体内容。 replicas。副本个数。也就是该 Deployment 需要起多少个相同的 Pod，如果用户成功在 K8S 中配置了 n（n&gt;1）个，那么 Deployment 会确保在集群中始终有 n 个服务在运行。 template。 第二步：执行 kubectl 命令部署。Deployment 的部署办法同 Pod：kubectl create -f $&#123;DEPLOYMENT_YAML&#125;。由此可见，K8S 会根据配置文件中的kind字段来判断具体要创建的是什么资源。 这里插一句题外话：部署完 deployment 之后，可以查看到自动创建了 ReplicaSet 和 Pod，如下图所示： 还有一个有趣的事情：通过 Deployment 部署的服务，其下属的 RS 和 Pod 命名是有规则的。读者朋友们自己总结发现哦。 综上，如何部署一个 Pod 或者 Deployment 就结束了。 V. kubectl 查看、更新/编辑、删除服务作为 K8S 使用者而言，更关心的问题应该是本章所要讨论的话题：如何通过 kubectl 查看、更新/编辑、删除在 K8S 上部署着的服务。 3.1 如何查看服务？请务必记得一个事情：在 K8S 中，一个独立的服务即对应一个 Pod。即，当我们说要 xxx 一个服务的就是，也就是操作一个 Pod。而与 Pod 服务相关的且需要用户关心的，有 Deployment。 通过 kubectl 查看服务的基本命令是： `$ kubectl?get|describe?${RESOURCE}?[-o?${FORMAT}]?-n=${NAMESPACE} ${RESOURCE}有:?pod、deployment、replicaset(rs)` 在此之前，还有一个需要回忆的事情是：Deployment、ReplicaSet 和 Pod 之间的关系 - 层层隶属；以及这些资源和 namespace 的关系是 - 隶属。如下图所示。 因此，要查看一个服务，也就是一个 Pod，必须首先指定 namespace！那么，如何查看集群中所有的 namespace 呢？kubectl get ns： 于是，只需要通过-n=$&#123;NAMESPACE&#125;就可以指定自己要操作的资源所在的 namespace。比如查看 Pod：kubectl get pod -n=oona-test，同理，查看 Deployment：kubectl get deployment -n=oona-test。 问题又来了：如果已经忘记自己所部属的服务所在的 namespace 怎么办？这么多 namespace，一个一个查看过来吗？ kubectl get pod --all-namespaces 这样子就可以看到所有 namespace 下面部署的 Pod 了！同理，要查找所有的命名空间下的 Deployment 的命令是：kubectl get deployment --all-namespaces。 于是，就可以开心地查看 Pod：kubectl get pod [-o wide] -n=oona-test，或者查看 Deployment：kubectl get deployment [-o wide] -n=oona-test。 哎，这里是否加-o wide有什么区别吗？实际操作下就明白了，其他资源亦然： 哎，我们看到之前部署的 Pod 服务 memory-demo 显示的“ImagePullBackOff”是怎么回事呢？先不着急，我们慢慢看下去。 3.2 如何更新/编辑服务？两种办法：1). 修改 yaml 文件后通过 kubectl 更新；2). 通过 kubectl 直接编辑 K8S 上的服务。 方法一：修改 yaml 文件后通过 kubectl 更新。我们看到，创建一个 Pod 或者 Deployment 的命令是kubectl create -f $&#123;YAML&#125;。但是，如果 K8S 集群当前的 namespace 下已经有该服务的话，会提示资源已经存在： 通过 kubectl 更新的命令是kubectl apply -f $&#123;YAML&#125;，我们再来试一试： （备注：命令kubectl apply -f $&#123;YAML&#125;也可以用于首次创建一个服务哦） 方法二：通过 kubectl 直接编辑 K8S 上的服务。命令为kubectl edit $&#123;RESOURCE&#125; $&#123;NAME&#125;，比如修改刚刚的 Pod 的命令为kubectl edit pod memory-demo，然后直接编辑自己要修改的内容即可。 但是请注意，无论方法一还是方法二，能修改的内容还是有限的，从笔者实战下来的结论是：只能修改/更新镜像的地址和个别几个字段。如果修改其他字段，会报错： The Pod “memory-demo” is invalid: spec: Forbidden: pod updates may not change fields other than spec.containers[*].image, spec.initContainers[*].image, spec.activeDeadlineSeconds or spec.tolerations (only additions to existing tolerations) 如果真的要修改其他字段怎么办呢？恐怕只能删除服务后重新部署了。 3.3 如何删除服务？在 K8S 上删除服务的操作非常简单，命令为kubectl delete $&#123;RESOURCE&#125; $&#123;NAME&#125;。比如删除一个 Pod 是：kubectl delete pod memory-demo，再比如删除一个 Deployment 的命令是：kubectl delete deployment $&#123;DEPLOYMENT_NAME&#125;。但是，请注意： 如果只部署了一个 Pod，那么直接删除该 Pod 即可； 如果是通过 Deployment 部署的服务，那么仅仅删除 Pod 是不行的，正确的删除方式应该是：先删除 Deployment，再删除 Pod。 关于第二点应该不难想象：仅仅删除了 Pod 但是 Deployment 还在的话，Deployment 定时会检查其下属的所有 Pod，如果发现失败了则会再拉起。因此，会发现过一会儿，新的 Pod 又被拉起来了。 另外，还有一个事情：有时候会发现一个 Pod 总也删除不了，这个时候很有可能要实施强制删除措施，命令为kubectl delete pod --force --grace-period=0 $&#123;POD_NAME&#125;。 VI. kubectl 排查服务问题上文说道：部署的服务 memory-demo 失败了，是怎么回事呢？本章就会带大家一起来看看常见的 K8S 中服务部署失败、服务起来了但是不正常运行都怎么排查呢？ 首先，祭出笔者最爱的一张 K8S 排查手册，来自博客《Kubernetes Deployment 故障排除图解指南》： 哈哈哈，对于新手同学来说，上图还是不够友好，下面我们简单来看两个例子： 4.1 K8S 上部署服务失败了怎么排查？请一定记住这个命令：kubectl describe $&#123;RESOURCE&#125; $&#123;NAME&#125;。比如刚刚的 Pod 服务 memory-demo，我们来看： 拉到最后看到Events部分，会显示出 K8S 在部署这个服务过程的关键日志。这里我们可以看到是拉取镜像失败了，好吧，大家可以换一个可用的镜像再试试。 一般来说，通过kubectl describe pod $&#123;POD_NAME&#125;已经能定位绝大部分部署失败的问题了，当然，具体问题还是得具体分析。大家如果遇到具体的报错，欢迎分享交流。 4.2 K8S 上部署的服务不正常怎么排查？如果服务部署成功了，且状态为running，那么就需要进入 Pod 内部的容器去查看自己的服务日志了： 查看 Pod 内部某个 container 打印的日志：kubectl log $&#123;POD_NAME&#125; -c $&#123;CONTAINER_NAME&#125;。 进入 Pod 内部某个 container：kubectl exec -it [options] $&#123;POD_NAME&#125; -c $&#123;CONTAINER_NAME&#125; [args]，嗯，这个命令的作用是通过 kubectl 执行了docker exec xxx进入到容器实例内部。之后，就是用户检查自己服务的日志来定位问题。 显然，线上可能会遇到更复杂的问题，需要借助更多更强大的命令和工具。 写在后面本文希望能够帮助对 K8S 不了解的新手快速了解 K8S。笔者一边写文章，一边查阅和整理 K8S 资料，过程中越发感觉 K8S 架构的完备、设计的精妙，是值得深入研究的，K8S 大受欢迎是有道理的。 来自 “ ITPUB博客 ” ，链接：http://blog.itpub.net/31559354/viewspace-2746071/","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://zhangyu.info/categories/Kubernetes/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://zhangyu.info/tags/Kubernetes/"}]},{"title":"Flannel-Calico怎么选择","slug":"Flannel-Calico","date":"2021-03-23T16:00:00.000Z","updated":"2021-05-26T03:01:53.590Z","comments":true,"path":"2021/03/24/Flannel-Calico/","link":"","permalink":"http://zhangyu.info/2021/03/24/Flannel-Calico/","excerpt":"","text":"网络插件怎么选择 Kubernetes中常见的网络插件有哪些？1.flannel：能提供ip地址，但不支持网络策略 2.calico：既提供ip地址，又支持网络策略 3.canal：flannel和calico结合，通过flannel提供ip地址，calico提供网络策略 4.Cilium 着重强调网络安全，实现Kubernetes中网络的可观察性以及基本的网络隔离、故障排查等安全策略； 突破传统主机防火墙仅支持L3、L4微隔离的限制，支持基于API的网络安全过滤能力。 什么叫做网络策略？网络策略：可以达到多租户网络隔离，可以控制入网和出网流量，入网和出网ip访问的一种策略 各种CNI网络方案的差异对比参考https://helpcdn.aliyun.com/document_detail/97621.html flannel和calico网络性能分析官方指标如下 flannel host-gw = flannel vxlan-directrouting = calico bgp&gt; calico ipip &gt; flannel vxlan-vxlan&gt;flannel-udp 官方推荐使用的网络方案：所有节点在同一个网段推荐使用calico的bgp模式和flannel的host-gw模式 结论：1.如果需要多集群的跨网络分段的网络，选择Calico 2.如果需要管理网络策略，做网络隔离等，选择Calico 3.大部分公司生产环境业务不复杂的，开发测试环境就几台机器的，不存在多数据中心的。 选择用Flannel 就行了。 部署在公有云上，封装 backend 选择vxlan-directrouting。 部署在私有云上，封装 backend 选择host-gw。 参考Kubernetes集群网络规划 https://helpcdn.aliyun.com/document_detail/86500.html 使用网络策略（Network Policy） https://helpcdn.aliyun.com/document_detail/97621.html","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://zhangyu.info/categories/Kubernetes/"}],"tags":[{"name":"flannel","slug":"flannel","permalink":"http://zhangyu.info/tags/flannel/"}]},{"title":"nginx核心知识100讲知识图谱","slug":"nginx-knowledge-graph","date":"2021-03-14T16:00:00.000Z","updated":"2021-03-15T15:07:57.974Z","comments":true,"path":"2021/03/15/nginx-knowledge-graph/","link":"","permalink":"http://zhangyu.info/2021/03/15/nginx-knowledge-graph/","excerpt":"","text":"nginx核心知识100讲知识图谱","categories":[{"name":"nginx","slug":"nginx","permalink":"http://zhangyu.info/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://zhangyu.info/tags/nginx/"}]},{"title":"性能之癫-优化你的程序","slug":"performance-optimize-your-program","date":"2021-03-14T16:00:00.000Z","updated":"2021-03-15T15:33:48.965Z","comments":true,"path":"2021/03/15/performance-optimize-your-program/","link":"","permalink":"http://zhangyu.info/2021/03/15/performance-optimize-your-program/","excerpt":"","text":"原创 码砖杂役性能之巅-优化你的程序​ outline：关注&amp;指标&amp;度量，基础理论知识，工具&amp;方法，最佳实践，参考资料性能优化关注：CPU、内存、磁盘IO、网络IO等四个方面。性能指标：吞吐率、响应时间、QPS/IOPS、TP99、资源使用率是我们经常关注的指标。时间度量：从cpu cycle到网络IO，自上到下，时间量级越大。监控、分析、优化，三部曲，以终为始，循环往复。优化性能，需要一些系统编程知识。提升处理能力、减少计算量是优化的2个根本方向。优化大师格雷格画的图，吊炸天，你应该很熟悉，gregg亲手实现了一些工具。借助工具定位性能瓶颈。gprof2dot.py可以处理多种采样输出数据 建议使用perf等非侵入式的profiling工具。perf不仅仅可以定位cpu瓶颈，还可以查看很多方面，比如缺页，分支预测失败，上下文切换等。IO瓶颈，你应该知道的知识。有关锁的知识，你应该知道的。多线程的学问很大内存管理的方方面面最佳实践，没有足够理由，你不应该违背。你应该懂得的。 关于排序，你应该知道的。这些资料不错，你值得拥有。 如果对你有帮助，请帮忙转发，让更多朋友收益。 一般性原则依据数据而不是凭空猜测忌过早优化忌过度优化深入理解业务性能优化是持久战选择合适的衡量指标、测试用例、测试环境性能优化的层次需求阶段设计阶段实现阶段一般性方法缓存并发惰性批量，合并更高效的实现缩小解空间性能优化与代码质量总结依据数据而不是凭空猜测 这是性能优化的第一原则，当我们怀疑性能有问题的时候，应该通过测试、日志、profillig来分析出哪里有问题，有的放矢，而不是凭感觉、撞运气。一个系统有了性能问题，瓶颈有可能是CPU，有可能是内存，有可能是IO（磁盘IO，网络IO），大方向的定位可以使用top以及stat系列来定位（vmstat，iostat，netstat…），针对单个进程，可以使用pidstat来分析。 在本文中，主要讨论的是CPU相关的性能问题。按照80/20定律，绝大多数的时间都耗费在少量的代码片段里面，找出这些代码唯一可靠的办法就是profile，我所知的编程语言，都有相关的profile工具，熟练使用这些profile工具是性能优化的第一步。 忌过早优化 The real problem is that programmers have spent far too much time worrying about efficiency in the wrong places and at the wrong times; premature optimization is the root of all evil (or at least most of it) in programming.我并不十分清楚Donald Knuth说出这句名言的上下文环境，但我自己是十分认同这个观念的。在我的工作环境（以及典型的互联网应用开发）与编程模式下，追求的是快速的迭代与试错，过早的优化往往是无用功。而且，过早的优化很容易拍脑袋，优化的点往往不是真正的性能瓶颈。 忌过度优化 As performance is part of the specification of a program – a program that is unusably slow is not fit for purpose性能优化的目标是追求合适的性价比。 在不同的阶段，我们对系统的性能会有一定的要求，比如吞吐量要达到多少多少。如果达不到这个指标，就需要去优化。如果能满足预期，那么就无需花费时间精力去优化，比如只有几十个人使用的内部系统，就不用按照十万在线的目标去优化。 而且，后面也会提到，一些优化方法是“有损”的，可能会对代码的可读性、可维护性有副作用。这个时候，就更不能过度优化。 深入理解业务 代码是服务于业务的，也许是服务于最终用户，也许是服务于其他程序员。不了解业务，很难理解系统的流程，很难找出系统设计的不足之处。后面还会提及对业务理解的重要性。 性能优化是持久战 当核心业务方向明确之后，就应该开始关注性能问题，当项目上线之后，更应该持续的进行性能检测与优化。 现在的互联网产品，不再是一锤子买卖，在上线之后还需要持续的开发，用户的涌入也会带来性能问题。因此需要自动化的检测性能问题，保持稳定的测试环境，持续的发现并解决性能问题，而不是被动地等到用户的投诉。 选择合适的衡量指标、测试用例、测试环境 正因为性能优化是一个长期的行为，所以需要固定衡量指标、测试用例、测试环境，这样才能客观反映性能的实际情况，也能展现出优化的效果。 衡量性能有很多指标，比如系统响应时间、系统吞吐量、系统并发量。不同的系统核心指标是不一样的，首先要明确本系统的核心性能诉求，固定测试用例；其次也要兼顾其他指标，不能顾此失彼。 测试环境也很重要，有一次突然发现我们的QPS高了许多，但是程序压根儿没优化，查了半天，才发现是换了一个更牛逼的物理机做测试服务器。","categories":[{"name":"优化","slug":"优化","permalink":"http://zhangyu.info/categories/%E4%BC%98%E5%8C%96/"}],"tags":[{"name":"性能","slug":"性能","permalink":"http://zhangyu.info/tags/%E6%80%A7%E8%83%BD/"}]}],"categories":[{"name":"阿里云","slug":"阿里云","permalink":"http://zhangyu.info/categories/%E9%98%BF%E9%87%8C%E4%BA%91/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://zhangyu.info/categories/Kubernetes/"},{"name":"日志","slug":"日志","permalink":"http://zhangyu.info/categories/%E6%97%A5%E5%BF%97/"},{"name":"胡说八道","slug":"胡说八道","permalink":"http://zhangyu.info/categories/%E8%83%A1%E8%AF%B4%E5%85%AB%E9%81%93/"},{"name":"消息系统","slug":"消息系统","permalink":"http://zhangyu.info/categories/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F/"},{"name":"职业发展","slug":"职业发展","permalink":"http://zhangyu.info/categories/%E8%81%8C%E4%B8%9A%E5%8F%91%E5%B1%95/"},{"name":"containerd","slug":"containerd","permalink":"http://zhangyu.info/categories/containerd/"},{"name":"Ingress","slug":"Ingress","permalink":"http://zhangyu.info/categories/Ingress/"},{"name":"nginx","slug":"nginx","permalink":"http://zhangyu.info/categories/nginx/"},{"name":"优化","slug":"优化","permalink":"http://zhangyu.info/categories/%E4%BC%98%E5%8C%96/"}],"tags":[{"name":"ECS","slug":"ECS","permalink":"http://zhangyu.info/tags/ECS/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://zhangyu.info/tags/Kubernetes/"},{"name":"Cilium","slug":"Cilium","permalink":"http://zhangyu.info/tags/Cilium/"},{"name":"日志","slug":"日志","permalink":"http://zhangyu.info/tags/%E6%97%A5%E5%BF%97/"},{"name":"黑话","slug":"黑话","permalink":"http://zhangyu.info/tags/%E9%BB%91%E8%AF%9D/"},{"name":"上线","slug":"上线","permalink":"http://zhangyu.info/tags/%E4%B8%8A%E7%BA%BF/"},{"name":"Pulsar","slug":"Pulsar","permalink":"http://zhangyu.info/tags/Pulsar/"},{"name":"职业发展","slug":"职业发展","permalink":"http://zhangyu.info/tags/%E8%81%8C%E4%B8%9A%E5%8F%91%E5%B1%95/"},{"name":"containerd","slug":"containerd","permalink":"http://zhangyu.info/tags/containerd/"},{"name":"Ingress","slug":"Ingress","permalink":"http://zhangyu.info/tags/Ingress/"},{"name":"flannel","slug":"flannel","permalink":"http://zhangyu.info/tags/flannel/"},{"name":"nginx","slug":"nginx","permalink":"http://zhangyu.info/tags/nginx/"},{"name":"性能","slug":"性能","permalink":"http://zhangyu.info/tags/%E6%80%A7%E8%83%BD/"}]}